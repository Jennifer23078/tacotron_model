
-----------------------------------------------------------------
Starting new training run
-----------------------------------------------------------------
[2020-05-11 16:13:43.031]  Loaded metadata for 1804 examples (1.72 hours)
[2020-05-11 16:13:44.948]  Initialized Tacotron model. Dimensions: 
[2020-05-11 16:13:44.948]  Tacotron 모델을 초기화했습니다.
[2020-05-11 16:13:44.948]    embedding:               256
[2020-05-11 16:13:44.948]    prenet out:              128
[2020-05-11 16:13:44.948]    encoder out:             256
[2020-05-11 16:13:44.948]    attention out:           256
[2020-05-11 16:13:44.948]    concat attn & out:       512
[2020-05-11 16:13:44.948]    decoder cell out:        256
[2020-05-11 16:13:44.948]    decoder out (5 frames):  400
[2020-05-11 16:13:44.948]    decoder out (1 frame):   80
[2020-05-11 16:13:44.948]    postnet out:             256
[2020-05-11 16:13:44.948]    linear out:              1025

-----------------------------------------------------------------
Starting new training run
-----------------------------------------------------------------
[2020-05-11 16:15:25.348]  Loaded metadata for 1804 examples (1.72 hours)
[2020-05-11 16:15:27.249]  Initialized Tacotron model. Dimensions: 
[2020-05-11 16:15:27.249]  Tacotron 모델을 초기화했습니다.
[2020-05-11 16:15:27.249]    embedding:               256
[2020-05-11 16:15:27.249]    prenet out:              128
[2020-05-11 16:15:27.249]    encoder out:             256
[2020-05-11 16:15:27.249]    attention out:           256
[2020-05-11 16:15:27.250]    concat attn & out:       512
[2020-05-11 16:15:27.250]    decoder cell out:        256
[2020-05-11 16:15:27.250]    decoder out (5 frames):  400
[2020-05-11 16:15:27.250]    decoder out (1 frame):   80
[2020-05-11 16:15:27.250]    postnet out:             256
[2020-05-11 16:15:27.250]    linear out:              1025
[2020-05-11 16:15:37.165]  Resuming from checkpoint: ./logs-tacotron/model.ckpt-140550
[2020-05-11 16:15:39.051]  Generated 32 batches of size 32 in 1.885 sec
[2020-05-11 16:15:43.346]  Step 140551  [6.175 sec/step, loss=0.10259, avg_loss=0.10259, mel_loss=0.04815, linear_loss=0.05444]
[2020-05-11 16:15:44.720]  Step 140552  [3.774 sec/step, loss=0.09465, avg_loss=0.09862, mel_loss=0.04357, linear_loss=0.05108]
[2020-05-11 16:15:45.950]  Step 140553  [2.926 sec/step, loss=0.09326, avg_loss=0.09683, mel_loss=0.04245, linear_loss=0.05081]
[2020-05-11 16:15:46.905]  Step 140554  [2.434 sec/step, loss=0.09006, avg_loss=0.09514, mel_loss=0.04127, linear_loss=0.04878]
[2020-05-11 16:15:59.044]  Step 140555  [4.374 sec/step, loss=0.10791, avg_loss=0.09769, mel_loss=0.05214, linear_loss=0.05577]
[2020-05-11 16:16:04.474]  Step 140556  [4.547 sec/step, loss=0.10157, avg_loss=0.09834, mel_loss=0.04784, linear_loss=0.05372]
[2020-05-11 16:16:09.259]  Step 140557  [4.581 sec/step, loss=0.10449, avg_loss=0.09922, mel_loss=0.04955, linear_loss=0.05494]
[2020-05-11 16:16:10.099]  Step 140558  [4.113 sec/step, loss=0.07981, avg_loss=0.09679, mel_loss=0.03701, linear_loss=0.04280]
[2020-05-11 16:16:13.611]  Step 140559  [4.046 sec/step, loss=0.10200, avg_loss=0.09737, mel_loss=0.04804, linear_loss=0.05396]
[2020-05-11 16:16:18.316]  Step 140560  [4.112 sec/step, loss=0.10368, avg_loss=0.09800, mel_loss=0.04893, linear_loss=0.05475]
[2020-05-11 16:16:25.666]  Step 140561  [4.406 sec/step, loss=0.10432, avg_loss=0.09858, mel_loss=0.05001, linear_loss=0.05431]
[2020-05-11 16:16:29.154]  Step 140562  [4.330 sec/step, loss=0.10146, avg_loss=0.09882, mel_loss=0.04745, linear_loss=0.05401]
[2020-05-11 16:16:30.777]  Step 140563  [4.122 sec/step, loss=0.09635, avg_loss=0.09863, mel_loss=0.04461, linear_loss=0.05175]
[2020-05-11 16:16:32.393]  Step 140564  [3.943 sec/step, loss=0.09673, avg_loss=0.09849, mel_loss=0.04475, linear_loss=0.05198]
[2020-05-11 16:16:33.375]  Step 140565  [3.745 sec/step, loss=0.08462, avg_loss=0.09757, mel_loss=0.03838, linear_loss=0.04624]
[2020-05-11 16:16:35.547]  Step 140566  [3.647 sec/step, loss=0.09827, avg_loss=0.09761, mel_loss=0.04577, linear_loss=0.05249]
[2020-05-11 16:16:38.081]  Step 140567  [3.581 sec/step, loss=0.09928, avg_loss=0.09771, mel_loss=0.04612, linear_loss=0.05315]
[2020-05-11 16:16:39.850]  Step 140568  [3.481 sec/step, loss=0.09677, avg_loss=0.09766, mel_loss=0.04472, linear_loss=0.05205]
[2020-05-11 16:16:40.624]  Step 140569  [3.338 sec/step, loss=0.08442, avg_loss=0.09696, mel_loss=0.03827, linear_loss=0.04616]
[2020-05-11 16:16:43.007]  Step 140570  [3.290 sec/step, loss=0.09757, avg_loss=0.09699, mel_loss=0.04530, linear_loss=0.05227]
[2020-05-11 16:16:44.940]  Step 140571  [3.226 sec/step, loss=0.09901, avg_loss=0.09709, mel_loss=0.04595, linear_loss=0.05307]
[2020-05-11 16:16:53.681]  Step 140572  [3.477 sec/step, loss=0.10494, avg_loss=0.09744, mel_loss=0.05079, linear_loss=0.05415]
[2020-05-11 16:16:55.671]  Step 140573  [3.412 sec/step, loss=0.09906, avg_loss=0.09751, mel_loss=0.04572, linear_loss=0.05334]
[2020-05-11 16:16:58.770]  Step 140574  [3.399 sec/step, loss=0.10293, avg_loss=0.09774, mel_loss=0.04828, linear_loss=0.05466]
[2020-05-11 16:16:59.302]  Step 140575  [3.284 sec/step, loss=0.08373, avg_loss=0.09718, mel_loss=0.03872, linear_loss=0.04501]
[2020-05-11 16:17:05.026]  Step 140576  [3.378 sec/step, loss=0.10516, avg_loss=0.09749, mel_loss=0.05005, linear_loss=0.05510]
[2020-05-11 16:17:10.250]  Step 140577  [3.446 sec/step, loss=0.10387, avg_loss=0.09772, mel_loss=0.04949, linear_loss=0.05438]
[2020-05-11 16:17:12.888]  Step 140578  [3.417 sec/step, loss=0.10177, avg_loss=0.09787, mel_loss=0.04755, linear_loss=0.05421]
[2020-05-11 16:17:17.757]  Exiting due to exception: Incompatible shapes: [32,1015,80] vs. [32,1000,80]
	 [[Node: model/optimizer/gradients/model/loss/sub_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device="/job:localhost/replica:0/task:0/cpu:0"](model/optimizer/gradients/model/loss/sub_grad/Shape, model/optimizer/gradients/model/loss/sub_grad/Shape_1)]]

Caused by op 'model/optimizer/gradients/model/loss/sub_grad/BroadcastGradientArgs', defined at:
  File "train.py", line 118, in <module>
    main()
  File "train.py", line 114, in main
    train(log_dir, args)
  File "train.py", line 45, in train
    model.add_optimizer(global_step)
  File "/tacotron1/models/tacotron.py", line 179, in add_optimizer
    gradients, variables = zip(*optimizer.compute_gradients(self.loss))
  File "/home/dudwn9983/.local/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py", line 386, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File "/home/dudwn9983/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py", line 542, in gradients
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File "/home/dudwn9983/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py", line 348, in _MaybeCompile
    return grad_fn()  # Exit early
  File "/home/dudwn9983/.local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py", line 542, in <lambda>
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File "/home/dudwn9983/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py", line 700, in _SubGrad
    rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)
  File "/home/dudwn9983/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py", line 393, in _broadcast_gradient_args
    name=name)
  File "/home/dudwn9983/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 767, in apply_op
    op_def=op_def)
  File "/home/dudwn9983/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "/home/dudwn9983/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

...which was originally created as op 'model/loss/sub', defined at:
  File "train.py", line 118, in <module>
    main()
[elided 0 identical lines from previous traceback]
  File "train.py", line 114, in main
    train(log_dir, args)
  File "train.py", line 44, in train
    model.add_loss()
  File "/tacotron1/models/tacotron.py", line 166, in add_loss
    self.mel_loss = tf.reduce_mean(tf.abs(self.mel_targets - self.mel_outputs))
  File "/home/dudwn9983/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py", line 865, in binary_op_wrapper
    return func(x, y, name=name)
  File "/home/dudwn9983/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py", line 2629, in _sub
    result = _op_def_lib.apply_op("Sub", x=x, y=y, name=name)
  File "/home/dudwn9983/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py", line 767, in apply_op
    op_def=op_def)
  File "/home/dudwn9983/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "/home/dudwn9983/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Incompatible shapes: [32,1015,80] vs. [32,1000,80]
	 [[Node: model/optimizer/gradients/model/loss/sub_grad/BroadcastGradientArgs = BroadcastGradientArgs[T=DT_INT32, _device="/job:localhost/replica:0/task:0/cpu:0"](model/optimizer/gradients/model/loss/sub_grad/Shape, model/optimizer/gradients/model/loss/sub_grad/Shape_1)]]

[2020-05-11 16:17:29.810]  Generated 32 batches of size 32 in 34.136 sec

-----------------------------------------------------------------
Starting new training run
-----------------------------------------------------------------
[2020-05-11 16:36:50.986]  Loaded metadata for 1804 examples (1.72 hours)
[2020-05-11 16:36:53.153]  Initialized Tacotron model. Dimensions: 
[2020-05-11 16:36:53.154]  Tacotron 모델을 초기화했습니다.
[2020-05-11 16:36:53.154]    embedding:               256
[2020-05-11 16:36:53.154]    prenet out:              128
[2020-05-11 16:36:53.154]    encoder out:             256
[2020-05-11 16:36:53.154]    attention out:           256
[2020-05-11 16:36:53.154]    concat attn & out:       512
[2020-05-11 16:36:53.154]    decoder cell out:        256
[2020-05-11 16:36:53.154]    decoder out (5 frames):  400
[2020-05-11 16:36:53.154]    decoder out (1 frame):   80
[2020-05-11 16:36:53.154]    postnet out:             256
[2020-05-11 16:36:53.154]    linear out:              1025
[2020-05-11 16:37:04.750]  Resuming from checkpoint: ./logs-tacotron/model.ckpt-140550
[2020-05-11 16:37:22.325]  Generated 32 batches of size 32 in 17.575 sec
[2020-05-11 16:37:24.877]  Step 140551  [20.121 sec/step, loss=0.09430, avg_loss=0.09430, mel_loss=0.04359, linear_loss=0.05071]
[2020-05-11 16:37:26.891]  Step 140552  [11.067 sec/step, loss=0.09310, avg_loss=0.09370, mel_loss=0.04242, linear_loss=0.05068]
[2020-05-11 16:37:36.040]  Step 140553  [10.428 sec/step, loss=0.10445, avg_loss=0.09728, mel_loss=0.04986, linear_loss=0.05459]
[2020-05-11 16:37:37.296]  Step 140554  [8.135 sec/step, loss=0.08379, avg_loss=0.09391, mel_loss=0.03780, linear_loss=0.04599]
[2020-05-11 16:37:47.812]  Step 140555  [8.611 sec/step, loss=0.10485, avg_loss=0.09610, mel_loss=0.05084, linear_loss=0.05401]
[2020-05-11 16:37:49.988]  Step 140556  [7.538 sec/step, loss=0.09866, avg_loss=0.09652, mel_loss=0.04583, linear_loss=0.05283]
[2020-05-11 16:37:50.988]  Step 140557  [6.604 sec/step, loss=0.08474, avg_loss=0.09484, mel_loss=0.03857, linear_loss=0.04617]
[2020-05-11 16:37:52.625]  Step 140558  [5.983 sec/step, loss=0.09536, avg_loss=0.09491, mel_loss=0.04410, linear_loss=0.05126]
[2020-05-11 16:37:54.606]  Step 140559  [5.539 sec/step, loss=0.09832, avg_loss=0.09528, mel_loss=0.04554, linear_loss=0.05278]
[2020-05-11 16:37:55.670]  Step 140560  [5.091 sec/step, loss=0.08998, avg_loss=0.09475, mel_loss=0.04110, linear_loss=0.04888]
[2020-05-11 16:37:59.453]  Step 140561  [4.972 sec/step, loss=0.10331, avg_loss=0.09553, mel_loss=0.04859, linear_loss=0.05472]
[2020-05-11 16:38:00.595]  Step 140562  [4.653 sec/step, loss=0.09023, avg_loss=0.09509, mel_loss=0.04120, linear_loss=0.04903]
[2020-05-11 16:38:08.290]  Step 140563  [4.887 sec/step, loss=0.10731, avg_loss=0.09603, mel_loss=0.05180, linear_loss=0.05551]
[2020-05-11 16:38:09.896]  Step 140564  [4.653 sec/step, loss=0.09667, avg_loss=0.09608, mel_loss=0.04472, linear_loss=0.05195]
[2020-05-11 16:38:10.721]  Step 140565  [4.397 sec/step, loss=0.07906, avg_loss=0.09494, mel_loss=0.03662, linear_loss=0.04244]
[2020-05-11 16:38:16.930]  Step 140566  [4.511 sec/step, loss=0.10443, avg_loss=0.09553, mel_loss=0.05003, linear_loss=0.05440]
[2020-05-11 16:38:17.883]  Step 140567  [4.301 sec/step, loss=0.09055, avg_loss=0.09524, mel_loss=0.04173, linear_loss=0.04882]
[2020-05-11 16:38:20.915]  Step 140568  [4.231 sec/step, loss=0.10283, avg_loss=0.09566, mel_loss=0.04837, linear_loss=0.05446]
[2020-05-11 16:38:24.320]  Step 140569  [4.187 sec/step, loss=0.10279, avg_loss=0.09604, mel_loss=0.04819, linear_loss=0.05459]
[2020-05-11 16:38:25.688]  Step 140570  [4.046 sec/step, loss=0.09448, avg_loss=0.09596, mel_loss=0.04345, linear_loss=0.05103]
[2020-05-11 16:38:26.213]  Step 140571  [3.879 sec/step, loss=0.08311, avg_loss=0.09535, mel_loss=0.03859, linear_loss=0.04452]
[2020-05-11 16:38:38.414]  Step 140572  [4.257 sec/step, loss=0.09480, avg_loss=0.09532, mel_loss=0.04679, linear_loss=0.04801]
[2020-05-11 16:38:40.400]  Step 140573  [4.158 sec/step, loss=0.09956, avg_loss=0.09551, mel_loss=0.04591, linear_loss=0.05365]
[2020-05-11 16:38:43.883]  Step 140574  [4.130 sec/step, loss=0.10146, avg_loss=0.09576, mel_loss=0.04749, linear_loss=0.05396]
[2020-05-11 16:38:45.680]  Step 140575  [4.037 sec/step, loss=0.09676, avg_loss=0.09580, mel_loss=0.04484, linear_loss=0.05192]
[2020-05-11 16:38:48.607]  Step 140576  [3.994 sec/step, loss=0.10175, avg_loss=0.09602, mel_loss=0.04792, linear_loss=0.05383]
[2020-05-11 16:38:51.239]  Step 140577  [3.944 sec/step, loss=0.10150, avg_loss=0.09623, mel_loss=0.04762, linear_loss=0.05388]
[2020-05-11 16:38:55.525]  Step 140578  [3.956 sec/step, loss=0.10176, avg_loss=0.09642, mel_loss=0.04815, linear_loss=0.05360]
[2020-05-11 16:38:57.898]  Step 140579  [3.901 sec/step, loss=0.09819, avg_loss=0.09649, mel_loss=0.04543, linear_loss=0.05275]
[2020-05-11 16:39:02.916]  Step 140580  [3.938 sec/step, loss=0.10387, avg_loss=0.09673, mel_loss=0.04947, linear_loss=0.05440]
[2020-05-11 16:39:07.578]  Step 140581  [3.962 sec/step, loss=0.10440, avg_loss=0.09698, mel_loss=0.04943, linear_loss=0.05497]
[2020-05-11 16:39:07.873]  Generated 32 batches of size 32 in 27.469 sec
[2020-05-11 16:39:10.149]  Step 140582  [3.918 sec/step, loss=0.09920, avg_loss=0.09705, mel_loss=0.04595, linear_loss=0.05325]
[2020-05-11 16:39:12.076]  Step 140583  [3.858 sec/step, loss=0.10021, avg_loss=0.09714, mel_loss=0.04568, linear_loss=0.05454]
[2020-05-11 16:39:13.439]  Step 140584  [3.785 sec/step, loss=0.09719, avg_loss=0.09715, mel_loss=0.04399, linear_loss=0.05320]
[2020-05-11 16:39:16.493]  Step 140585  [3.764 sec/step, loss=0.10612, avg_loss=0.09740, mel_loss=0.04915, linear_loss=0.05697]
[2020-05-11 16:39:20.847]  Step 140586  [3.780 sec/step, loss=0.10915, avg_loss=0.09773, mel_loss=0.05191, linear_loss=0.05724]
[2020-05-11 16:39:22.679]  Step 140587  [3.727 sec/step, loss=0.09921, avg_loss=0.09777, mel_loss=0.04533, linear_loss=0.05388]
[2020-05-11 16:39:23.818]  Step 140588  [3.659 sec/step, loss=0.09309, avg_loss=0.09765, mel_loss=0.04183, linear_loss=0.05126]
[2020-05-11 16:39:25.915]  Step 140589  [3.619 sec/step, loss=0.10219, avg_loss=0.09776, mel_loss=0.04718, linear_loss=0.05501]
[2020-05-11 16:39:26.787]  Step 140590  [3.551 sec/step, loss=0.09127, avg_loss=0.09760, mel_loss=0.04092, linear_loss=0.05035]
[2020-05-11 16:39:33.763]  Step 140591  [3.634 sec/step, loss=0.10728, avg_loss=0.09784, mel_loss=0.05155, linear_loss=0.05573]
[2020-05-11 16:39:35.517]  Step 140592  [3.589 sec/step, loss=0.09964, avg_loss=0.09788, mel_loss=0.04513, linear_loss=0.05451]
[2020-05-11 16:39:38.225]  Step 140593  [3.569 sec/step, loss=0.10089, avg_loss=0.09795, mel_loss=0.04650, linear_loss=0.05439]
[2020-05-11 16:39:41.770]  Step 140594  [3.568 sec/step, loss=0.10598, avg_loss=0.09813, mel_loss=0.04966, linear_loss=0.05633]
[2020-05-11 16:39:44.163]  Step 140595  [3.542 sec/step, loss=0.10337, avg_loss=0.09825, mel_loss=0.04775, linear_loss=0.05562]
[2020-05-11 16:39:47.424]  Step 140596  [3.536 sec/step, loss=0.10713, avg_loss=0.09844, mel_loss=0.04987, linear_loss=0.05726]
[2020-05-11 16:39:54.044]  Step 140597  [3.602 sec/step, loss=0.10798, avg_loss=0.09864, mel_loss=0.05178, linear_loss=0.05620]
[2020-05-11 16:39:54.623]  Step 140598  [3.539 sec/step, loss=0.08353, avg_loss=0.09833, mel_loss=0.03819, linear_loss=0.04535]
[2020-05-11 16:39:58.286]  Step 140599  [3.541 sec/step, loss=0.10920, avg_loss=0.09855, mel_loss=0.05132, linear_loss=0.05788]
[2020-05-11 16:39:59.560]  Step 140600  [3.496 sec/step, loss=0.09380, avg_loss=0.09846, mel_loss=0.04296, linear_loss=0.05084]
[2020-05-11 16:39:59.560]  Writing summary at step: 140600
[2020-05-11 16:40:04.784]  Saving checkpoint to: ./logs-tacotron/model.ckpt-140600
[2020-05-11 16:40:06.028]  Saving audio and alignment...
[2020-05-11 16:40:09.135]  Input: 패기가 넘치게 되죠~______________________
[2020-05-11 16:40:14.388]  Step 140601  [3.530 sec/step, loss=0.10632, avg_loss=0.09861, mel_loss=0.05057, linear_loss=0.05574]
[2020-05-11 16:40:18.363]  Step 140602  [3.539 sec/step, loss=0.10648, avg_loss=0.09876, mel_loss=0.05008, linear_loss=0.05640]
[2020-05-11 16:40:19.947]  Step 140603  [3.502 sec/step, loss=0.10184, avg_loss=0.09882, mel_loss=0.04632, linear_loss=0.05552]
[2020-05-11 16:40:20.968]  Step 140604  [3.456 sec/step, loss=0.09095, avg_loss=0.09867, mel_loss=0.04142, linear_loss=0.04953]
[2020-05-11 16:40:29.975]  Step 140605  [3.557 sec/step, loss=0.10300, avg_loss=0.09875, mel_loss=0.04965, linear_loss=0.05336]
[2020-05-11 16:40:32.187]  Step 140606  [3.533 sec/step, loss=0.10274, avg_loss=0.09882, mel_loss=0.04760, linear_loss=0.05514]
[2020-05-11 16:40:37.752]  Step 140607  [3.569 sec/step, loss=0.10827, avg_loss=0.09899, mel_loss=0.05149, linear_loss=0.05678]
[2020-05-11 16:40:38.535]  Step 140608  [3.521 sec/step, loss=0.08851, avg_loss=0.09881, mel_loss=0.03995, linear_loss=0.04856]
[2020-05-11 16:40:53.358]  Step 140609  [3.712 sec/step, loss=0.08277, avg_loss=0.09854, mel_loss=0.04048, linear_loss=0.04229]
[2020-05-11 16:40:56.357]  Step 140610  [3.700 sec/step, loss=0.10397, avg_loss=0.09863, mel_loss=0.04849, linear_loss=0.05548]
[2020-05-11 16:40:57.194]  Step 140611  [3.653 sec/step, loss=0.08490, avg_loss=0.09840, mel_loss=0.03800, linear_loss=0.04690]
[2020-05-11 16:41:00.741]  Step 140612  [3.652 sec/step, loss=0.10551, avg_loss=0.09852, mel_loss=0.04951, linear_loss=0.05600]
[2020-05-11 16:41:09.474]  Generated 32 batches of size 32 in 49.523 sec
[2020-05-11 16:41:10.669]  Step 140613  [3.751 sec/step, loss=0.09061, avg_loss=0.09839, mel_loss=0.04098, linear_loss=0.04964]
[2020-05-11 16:41:14.311]  Step 140614  [3.749 sec/step, loss=0.10503, avg_loss=0.09850, mel_loss=0.04912, linear_loss=0.05591]
[2020-05-11 16:41:26.450]  Step 140615  [3.879 sec/step, loss=0.09167, avg_loss=0.09839, mel_loss=0.04456, linear_loss=0.04711]
[2020-05-11 16:41:27.805]  Step 140616  [3.840 sec/step, loss=0.09703, avg_loss=0.09837, mel_loss=0.04423, linear_loss=0.05280]
[2020-05-11 16:41:30.633]  Step 140617  [3.825 sec/step, loss=0.10290, avg_loss=0.09844, mel_loss=0.04809, linear_loss=0.05481]
[2020-05-11 16:41:31.197]  Step 140618  [3.777 sec/step, loss=0.07647, avg_loss=0.09811, mel_loss=0.03520, linear_loss=0.04127]
[2020-05-11 16:41:32.027]  Step 140619  [3.734 sec/step, loss=0.08467, avg_loss=0.09792, mel_loss=0.03842, linear_loss=0.04625]
[2020-05-11 16:41:34.156]  Step 140620  [3.712 sec/step, loss=0.09984, avg_loss=0.09795, mel_loss=0.04618, linear_loss=0.05366]
[2020-05-11 16:41:35.417]  Step 140621  [3.677 sec/step, loss=0.09198, avg_loss=0.09786, mel_loss=0.04198, linear_loss=0.05000]
[2020-05-11 16:41:37.796]  Step 140622  [3.659 sec/step, loss=0.10091, avg_loss=0.09790, mel_loss=0.04658, linear_loss=0.05433]
[2020-05-11 16:41:38.686]  Step 140623  [3.621 sec/step, loss=0.09194, avg_loss=0.09782, mel_loss=0.04162, linear_loss=0.05031]
[2020-05-11 16:41:39.487]  Step 140624  [3.583 sec/step, loss=0.08602, avg_loss=0.09766, mel_loss=0.03903, linear_loss=0.04699]
[2020-05-11 16:41:41.007]  Step 140625  [3.555 sec/step, loss=0.09690, avg_loss=0.09765, mel_loss=0.04414, linear_loss=0.05275]
[2020-05-11 16:41:42.044]  Step 140626  [3.522 sec/step, loss=0.08844, avg_loss=0.09753, mel_loss=0.04014, linear_loss=0.04830]
[2020-05-11 16:41:49.556]  Step 140627  [3.574 sec/step, loss=0.10787, avg_loss=0.09767, mel_loss=0.05233, linear_loss=0.05554]
[2020-05-11 16:41:52.728]  Step 140628  [3.569 sec/step, loss=0.10683, avg_loss=0.09778, mel_loss=0.05007, linear_loss=0.05676]
[2020-05-11 16:41:54.359]  Step 140629  [3.544 sec/step, loss=0.09733, avg_loss=0.09778, mel_loss=0.04460, linear_loss=0.05272]
[2020-05-11 16:41:58.949]  Step 140630  [3.557 sec/step, loss=0.10571, avg_loss=0.09788, mel_loss=0.05014, linear_loss=0.05556]
[2020-05-11 16:42:07.681]  Step 140631  [3.621 sec/step, loss=0.10460, avg_loss=0.09796, mel_loss=0.05045, linear_loss=0.05415]
[2020-05-11 16:42:13.904]  Step 140632  [3.653 sec/step, loss=0.10497, avg_loss=0.09805, mel_loss=0.05019, linear_loss=0.05479]
[2020-05-11 16:42:19.420]  Step 140633  [3.676 sec/step, loss=0.10477, avg_loss=0.09813, mel_loss=0.04962, linear_loss=0.05514]
[2020-05-11 16:42:22.177]  Step 140634  [3.665 sec/step, loss=0.10280, avg_loss=0.09818, mel_loss=0.04778, linear_loss=0.05502]
[2020-05-11 16:42:24.160]  Step 140635  [3.645 sec/step, loss=0.09954, avg_loss=0.09820, mel_loss=0.04574, linear_loss=0.05380]
[2020-05-11 16:42:27.156]  Step 140636  [3.637 sec/step, loss=0.10545, avg_loss=0.09828, mel_loss=0.04960, linear_loss=0.05585]
[2020-05-11 16:42:28.573]  Step 140637  [3.612 sec/step, loss=0.09316, avg_loss=0.09822, mel_loss=0.04323, linear_loss=0.04993]
[2020-05-11 16:42:32.671]  Step 140638  [3.617 sec/step, loss=0.10552, avg_loss=0.09831, mel_loss=0.04982, linear_loss=0.05570]
[2020-05-11 16:42:34.726]  Step 140639  [3.600 sec/step, loss=0.09763, avg_loss=0.09830, mel_loss=0.04476, linear_loss=0.05287]
[2020-05-11 16:42:40.060]  Step 140640  [3.619 sec/step, loss=0.10494, avg_loss=0.09837, mel_loss=0.05002, linear_loss=0.05492]
[2020-05-11 16:42:43.447]  Step 140641  [3.616 sec/step, loss=0.10314, avg_loss=0.09843, mel_loss=0.04815, linear_loss=0.05499]
[2020-05-11 16:42:47.738]  Step 140642  [3.624 sec/step, loss=0.10614, avg_loss=0.09851, mel_loss=0.05027, linear_loss=0.05587]
[2020-05-11 16:42:49.937]  Generated 32 batches of size 32 in 25.772 sec
[2020-05-11 16:42:50.316]  Step 140643  [3.613 sec/step, loss=0.10053, avg_loss=0.09853, mel_loss=0.04645, linear_loss=0.05408]
[2020-05-11 16:42:52.053]  Step 140644  [3.593 sec/step, loss=0.10007, avg_loss=0.09855, mel_loss=0.04560, linear_loss=0.05447]
[2020-05-11 16:42:53.697]  Step 140645  [3.572 sec/step, loss=0.09800, avg_loss=0.09854, mel_loss=0.04483, linear_loss=0.05316]
[2020-05-11 16:42:56.778]  Step 140646  [3.567 sec/step, loss=0.10394, avg_loss=0.09860, mel_loss=0.04870, linear_loss=0.05525]
[2020-05-11 16:42:58.756]  Step 140647  [3.551 sec/step, loss=0.10231, avg_loss=0.09864, mel_loss=0.04757, linear_loss=0.05474]
[2020-05-11 16:43:00.117]  Step 140648  [3.528 sec/step, loss=0.09428, avg_loss=0.09859, mel_loss=0.04321, linear_loss=0.05107]
[2020-05-11 16:43:01.586]  Step 140649  [3.507 sec/step, loss=0.09634, avg_loss=0.09857, mel_loss=0.04396, linear_loss=0.05238]
[2020-05-11 16:43:02.623]  Step 140650  [3.483 sec/step, loss=0.09262, avg_loss=0.09851, mel_loss=0.04223, linear_loss=0.05040]
[2020-05-11 16:43:02.623]  Writing summary at step: 140650
[2020-05-11 16:43:06.786]  Saving checkpoint to: ./logs-tacotron/model.ckpt-140650
[2020-05-11 16:43:07.979]  Saving audio and alignment...
[2020-05-11 16:43:15.657]  Input: 음악이 주는 감동 우리 마음속에 담아서 일상을 살아가는 그리고 위로가 되주죠~______________________
[2020-05-11 16:43:18.459]  Step 140651  [3.309 sec/step, loss=0.10123, avg_loss=0.09858, mel_loss=0.04717, linear_loss=0.05405]
[2020-05-11 16:43:20.615]  Step 140652  [3.311 sec/step, loss=0.10065, avg_loss=0.09865, mel_loss=0.04715, linear_loss=0.05350]
[2020-05-11 16:43:26.495]  Step 140653  [3.278 sec/step, loss=0.10491, avg_loss=0.09866, mel_loss=0.05026, linear_loss=0.05465]
[2020-05-11 16:43:28.236]  Step 140654  [3.283 sec/step, loss=0.09820, avg_loss=0.09880, mel_loss=0.04490, linear_loss=0.05330]
[2020-05-11 16:43:28.797]  Step 140655  [3.184 sec/step, loss=0.08107, avg_loss=0.09856, mel_loss=0.03733, linear_loss=0.04374]
[2020-05-11 16:43:29.918]  Step 140656  [3.173 sec/step, loss=0.09297, avg_loss=0.09851, mel_loss=0.04270, linear_loss=0.05027]
[2020-05-11 16:43:44.303]  Step 140657  [3.307 sec/step, loss=0.08423, avg_loss=0.09850, mel_loss=0.04143, linear_loss=0.04279]
[2020-05-11 16:43:45.343]  Step 140658  [3.301 sec/step, loss=0.09380, avg_loss=0.09849, mel_loss=0.04236, linear_loss=0.05144]
[2020-05-11 16:43:49.887]  Step 140659  [3.326 sec/step, loss=0.10678, avg_loss=0.09857, mel_loss=0.05057, linear_loss=0.05621]
[2020-05-11 16:43:52.019]  Step 140660  [3.337 sec/step, loss=0.09970, avg_loss=0.09867, mel_loss=0.04555, linear_loss=0.05415]
[2020-05-11 16:43:52.969]  Step 140661  [3.309 sec/step, loss=0.08911, avg_loss=0.09853, mel_loss=0.03998, linear_loss=0.04913]
[2020-05-11 16:43:56.712]  Step 140662  [3.335 sec/step, loss=0.10353, avg_loss=0.09866, mel_loss=0.04845, linear_loss=0.05508]
[2020-05-11 16:44:01.525]  Step 140663  [3.306 sec/step, loss=0.10546, avg_loss=0.09864, mel_loss=0.04986, linear_loss=0.05561]
[2020-05-11 16:44:04.754]  Step 140664  [3.322 sec/step, loss=0.10357, avg_loss=0.09871, mel_loss=0.04824, linear_loss=0.05534]
[2020-05-11 16:44:05.547]  Step 140665  [3.322 sec/step, loss=0.08552, avg_loss=0.09878, mel_loss=0.03895, linear_loss=0.04657]
[2020-05-11 16:44:07.311]  Generated 32 batches of size 32 in 1.759 sec
[2020-05-11 16:44:08.189]  Step 140666  [3.286 sec/step, loss=0.09796, avg_loss=0.09871, mel_loss=0.04533, linear_loss=0.05263]
[2020-05-11 16:44:09.725]  Step 140667  [3.292 sec/step, loss=0.09776, avg_loss=0.09878, mel_loss=0.04433, linear_loss=0.05343]
[2020-05-11 16:44:17.153]  Step 140668  [3.336 sec/step, loss=0.10397, avg_loss=0.09879, mel_loss=0.04999, linear_loss=0.05399]
[2020-05-11 16:44:25.551]  Step 140669  [3.386 sec/step, loss=0.10307, avg_loss=0.09880, mel_loss=0.04977, linear_loss=0.05330]
[2020-05-11 16:44:27.433]  Step 140670  [3.391 sec/step, loss=0.09846, avg_loss=0.09884, mel_loss=0.04541, linear_loss=0.05305]
[2020-05-11 16:44:30.980]  Step 140671  [3.421 sec/step, loss=0.10761, avg_loss=0.09908, mel_loss=0.05043, linear_loss=0.05718]
[2020-05-11 16:44:34.409]  Step 140672  [3.334 sec/step, loss=0.10138, avg_loss=0.09915, mel_loss=0.04774, linear_loss=0.05365]
[2020-05-11 16:44:35.211]  Step 140673  [3.322 sec/step, loss=0.08150, avg_loss=0.09897, mel_loss=0.03690, linear_loss=0.04460]
[2020-05-11 16:44:37.616]  Step 140674  [3.311 sec/step, loss=0.10266, avg_loss=0.09898, mel_loss=0.04757, linear_loss=0.05510]
[2020-05-11 16:44:42.971]  Step 140675  [3.347 sec/step, loss=0.10710, avg_loss=0.09908, mel_loss=0.05105, linear_loss=0.05605]
[2020-05-11 16:44:46.599]  Step 140676  [3.354 sec/step, loss=0.10696, avg_loss=0.09913, mel_loss=0.05023, linear_loss=0.05673]
[2020-05-11 16:44:47.635]  Step 140677  [3.338 sec/step, loss=0.08776, avg_loss=0.09900, mel_loss=0.03994, linear_loss=0.04781]
[2020-05-11 16:44:48.377]  Step 140678  [3.302 sec/step, loss=0.08043, avg_loss=0.09878, mel_loss=0.03741, linear_loss=0.04302]
[2020-05-11 16:44:49.715]  Step 140679  [3.292 sec/step, loss=0.09379, avg_loss=0.09874, mel_loss=0.04294, linear_loss=0.05086]
[2020-05-11 16:44:50.867]  Step 140680  [3.253 sec/step, loss=0.09046, avg_loss=0.09861, mel_loss=0.04073, linear_loss=0.04973]
[2020-05-11 16:44:52.787]  Step 140681  [3.226 sec/step, loss=0.10047, avg_loss=0.09857, mel_loss=0.04610, linear_loss=0.05437]
[2020-05-11 16:44:56.921]  Step 140682  [3.241 sec/step, loss=0.10491, avg_loss=0.09862, mel_loss=0.04956, linear_loss=0.05535]
[2020-05-11 16:45:00.326]  Step 140683  [3.256 sec/step, loss=0.10375, avg_loss=0.09866, mel_loss=0.04830, linear_loss=0.05545]
[2020-05-11 16:45:02.770]  Step 140684  [3.267 sec/step, loss=0.10148, avg_loss=0.09870, mel_loss=0.04689, linear_loss=0.05459]
[2020-05-11 16:45:06.225]  Step 140685  [3.271 sec/step, loss=0.10321, avg_loss=0.09867, mel_loss=0.04829, linear_loss=0.05492]
[2020-05-11 16:45:08.142]  Step 140686  [3.247 sec/step, loss=0.09923, avg_loss=0.09857, mel_loss=0.04521, linear_loss=0.05401]
[2020-05-11 16:45:12.217]  Step 140687  [3.269 sec/step, loss=0.10619, avg_loss=0.09864, mel_loss=0.04990, linear_loss=0.05629]
[2020-05-11 16:45:13.007]  Step 140688  [3.266 sec/step, loss=0.08010, avg_loss=0.09851, mel_loss=0.03640, linear_loss=0.04370]
[2020-05-11 16:45:20.555]  Step 140689  [3.320 sec/step, loss=0.10698, avg_loss=0.09856, mel_loss=0.05147, linear_loss=0.05551]
[2020-05-11 16:45:22.310]  Step 140690  [3.329 sec/step, loss=0.09923, avg_loss=0.09864, mel_loss=0.04529, linear_loss=0.05393]
[2020-05-11 16:45:23.919]  Step 140691  [3.275 sec/step, loss=0.09907, avg_loss=0.09856, mel_loss=0.04541, linear_loss=0.05365]
[2020-05-11 16:45:35.670]  Step 140692  [3.375 sec/step, loss=0.09823, avg_loss=0.09854, mel_loss=0.04814, linear_loss=0.05008]
[2020-05-11 16:45:44.713]  Step 140693  [3.439 sec/step, loss=0.10360, avg_loss=0.09857, mel_loss=0.05008, linear_loss=0.05352]
[2020-05-11 16:45:47.130]  Step 140694  [3.427 sec/step, loss=0.10168, avg_loss=0.09853, mel_loss=0.04711, linear_loss=0.05457]
[2020-05-11 16:45:50.020]  Step 140695  [3.432 sec/step, loss=0.10340, avg_loss=0.09853, mel_loss=0.04802, linear_loss=0.05538]
[2020-05-11 16:45:55.755]  Step 140696  [3.457 sec/step, loss=0.10747, avg_loss=0.09853, mel_loss=0.05135, linear_loss=0.05612]
[2020-05-11 16:45:58.510]  Step 140697  [3.418 sec/step, loss=0.10185, avg_loss=0.09847, mel_loss=0.04761, linear_loss=0.05423]
[2020-05-11 16:46:00.286]  Generated 32 batches of size 32 in 1.771 sec
[2020-05-11 16:46:00.762]  Step 140698  [3.435 sec/step, loss=0.10086, avg_loss=0.09864, mel_loss=0.04687, linear_loss=0.05399]
[2020-05-11 16:46:02.319]  Step 140699  [3.414 sec/step, loss=0.09565, avg_loss=0.09851, mel_loss=0.04424, linear_loss=0.05141]
[2020-05-11 16:46:05.639]  Step 140700  [3.434 sec/step, loss=0.10460, avg_loss=0.09862, mel_loss=0.04894, linear_loss=0.05566]
[2020-05-11 16:46:05.639]  Writing summary at step: 140700
[2020-05-11 16:46:06.592]  Saving checkpoint to: ./logs-tacotron/model.ckpt-140700
[2020-05-11 16:46:07.754]  Saving audio and alignment...
[2020-05-11 16:46:09.568]  Input: 이천십육~_________
[2020-05-11 16:46:16.412]  Step 140701  [3.450 sec/step, loss=0.10642, avg_loss=0.09862, mel_loss=0.05124, linear_loss=0.05519]
[2020-05-11 16:46:17.661]  Step 140702  [3.423 sec/step, loss=0.09367, avg_loss=0.09849, mel_loss=0.04303, linear_loss=0.05063]
[2020-05-11 16:46:22.465]  Step 140703  [3.455 sec/step, loss=0.10304, avg_loss=0.09850, mel_loss=0.04864, linear_loss=0.05440]
[2020-05-11 16:46:24.011]  Step 140704  [3.461 sec/step, loss=0.09708, avg_loss=0.09856, mel_loss=0.04485, linear_loss=0.05223]
[2020-05-11 16:46:28.210]  Step 140705  [3.412 sec/step, loss=0.10449, avg_loss=0.09858, mel_loss=0.04913, linear_loss=0.05535]
[2020-05-11 16:46:30.716]  Step 140706  [3.415 sec/step, loss=0.09903, avg_loss=0.09854, mel_loss=0.04564, linear_loss=0.05339]
[2020-05-11 16:46:33.698]  Step 140707  [3.390 sec/step, loss=0.10435, avg_loss=0.09850, mel_loss=0.04906, linear_loss=0.05529]
[2020-05-11 16:46:35.344]  Step 140708  [3.398 sec/step, loss=0.09778, avg_loss=0.09859, mel_loss=0.04460, linear_loss=0.05318]
[2020-05-11 16:46:39.280]  Step 140709  [3.289 sec/step, loss=0.10561, avg_loss=0.09882, mel_loss=0.04961, linear_loss=0.05600]
[2020-05-11 16:46:41.191]  Step 140710  [3.278 sec/step, loss=0.10088, avg_loss=0.09879, mel_loss=0.04632, linear_loss=0.05456]
[2020-05-11 16:46:42.168]  Step 140711  [3.280 sec/step, loss=0.08712, avg_loss=0.09881, mel_loss=0.03957, linear_loss=0.04755]
[2020-05-11 16:46:50.081]  Step 140712  [3.324 sec/step, loss=0.10646, avg_loss=0.09882, mel_loss=0.05156, linear_loss=0.05490]
[2020-05-11 16:46:53.273]  Step 140713  [3.256 sec/step, loss=0.10391, avg_loss=0.09896, mel_loss=0.04821, linear_loss=0.05570]
[2020-05-11 16:46:53.825]  Step 140714  [3.225 sec/step, loss=0.07795, avg_loss=0.09869, mel_loss=0.03583, linear_loss=0.04212]
[2020-05-11 16:47:07.774]  Step 140715  [3.243 sec/step, loss=0.08897, avg_loss=0.09866, mel_loss=0.04330, linear_loss=0.04568]
[2020-05-11 16:47:09.978]  Step 140716  [3.252 sec/step, loss=0.09491, avg_loss=0.09864, mel_loss=0.04324, linear_loss=0.05167]
[2020-05-11 16:47:19.840]  Step 140717  [3.322 sec/step, loss=0.10645, avg_loss=0.09867, mel_loss=0.05138, linear_loss=0.05508]
[2020-05-11 16:47:22.588]  Step 140718  [3.344 sec/step, loss=0.10255, avg_loss=0.09893, mel_loss=0.04799, linear_loss=0.05456]
[2020-05-11 16:47:27.473]  Step 140719  [3.385 sec/step, loss=0.10557, avg_loss=0.09914, mel_loss=0.04980, linear_loss=0.05577]
[2020-05-11 16:47:33.026]  Step 140720  [3.419 sec/step, loss=0.10357, avg_loss=0.09918, mel_loss=0.04920, linear_loss=0.05437]
[2020-05-11 16:47:34.358]  Step 140721  [3.420 sec/step, loss=0.09661, avg_loss=0.09923, mel_loss=0.04397, linear_loss=0.05264]
[2020-05-11 16:47:37.931]  Step 140722  [3.431 sec/step, loss=0.10566, avg_loss=0.09927, mel_loss=0.04929, linear_loss=0.05638]
[2020-05-11 16:47:39.562]  Step 140723  [3.439 sec/step, loss=0.09450, avg_loss=0.09930, mel_loss=0.04338, linear_loss=0.05112]
[2020-05-11 16:47:40.721]  Step 140724  [3.442 sec/step, loss=0.09506, avg_loss=0.09939, mel_loss=0.04352, linear_loss=0.05154]
[2020-05-11 16:47:42.881]  Step 140725  [3.449 sec/step, loss=0.09853, avg_loss=0.09941, mel_loss=0.04562, linear_loss=0.05292]
[2020-05-11 16:47:44.113]  Step 140726  [3.451 sec/step, loss=0.08507, avg_loss=0.09937, mel_loss=0.03852, linear_loss=0.04655]
[2020-05-11 16:47:47.800]  Step 140727  [3.413 sec/step, loss=0.09982, avg_loss=0.09929, mel_loss=0.04670, linear_loss=0.05313]
[2020-05-11 16:47:53.107]  Generated 32 batches of size 32 in 5.292 sec
[2020-05-11 16:47:55.002]  Step 140728  [3.453 sec/step, loss=0.10546, avg_loss=0.09928, mel_loss=0.04985, linear_loss=0.05560]
[2020-05-11 16:48:00.362]  Step 140729  [3.490 sec/step, loss=0.10383, avg_loss=0.09934, mel_loss=0.04830, linear_loss=0.05553]
[2020-05-11 16:48:07.828]  Step 140730  [3.519 sec/step, loss=0.10475, avg_loss=0.09933, mel_loss=0.05016, linear_loss=0.05458]
[2020-05-11 16:48:08.968]  Step 140731  [3.443 sec/step, loss=0.09450, avg_loss=0.09923, mel_loss=0.04315, linear_loss=0.05136]
[2020-05-11 16:48:11.909]  Step 140732  [3.410 sec/step, loss=0.10389, avg_loss=0.09922, mel_loss=0.04830, linear_loss=0.05559]
[2020-05-11 16:48:12.814]  Step 140733  [3.364 sec/step, loss=0.08977, avg_loss=0.09907, mel_loss=0.04080, linear_loss=0.04898]
[2020-05-11 16:48:13.576]  Step 140734  [3.344 sec/step, loss=0.08055, avg_loss=0.09885, mel_loss=0.03726, linear_loss=0.04330]
[2020-05-11 16:48:15.294]  Step 140735  [3.341 sec/step, loss=0.09730, avg_loss=0.09883, mel_loss=0.04447, linear_loss=0.05283]
[2020-05-11 16:48:17.399]  Step 140736  [3.333 sec/step, loss=0.10184, avg_loss=0.09879, mel_loss=0.04744, linear_loss=0.05439]
[2020-05-11 16:48:19.278]  Step 140737  [3.337 sec/step, loss=0.09677, avg_loss=0.09883, mel_loss=0.04434, linear_loss=0.05242]
[2020-05-11 16:48:22.826]  Step 140738  [3.332 sec/step, loss=0.10387, avg_loss=0.09881, mel_loss=0.04876, linear_loss=0.05511]
[2020-05-11 16:48:24.392]  Step 140739  [3.327 sec/step, loss=0.09730, avg_loss=0.09881, mel_loss=0.04483, linear_loss=0.05247]
[2020-05-11 16:48:30.820]  Step 140740  [3.338 sec/step, loss=0.10536, avg_loss=0.09881, mel_loss=0.05043, linear_loss=0.05493]
[2020-05-11 16:48:32.489]  Step 140741  [3.321 sec/step, loss=0.09927, avg_loss=0.09877, mel_loss=0.04550, linear_loss=0.05377]
[2020-05-11 16:48:33.228]  Step 140742  [3.285 sec/step, loss=0.08446, avg_loss=0.09856, mel_loss=0.03796, linear_loss=0.04650]
[2020-05-11 16:48:38.472]  Step 140743  [3.312 sec/step, loss=0.10506, avg_loss=0.09860, mel_loss=0.05017, linear_loss=0.05489]
[2020-05-11 16:48:39.244]  Step 140744  [3.302 sec/step, loss=0.07904, avg_loss=0.09839, mel_loss=0.03678, linear_loss=0.04226]
[2020-05-11 16:48:40.241]  Step 140745  [3.296 sec/step, loss=0.08922, avg_loss=0.09830, mel_loss=0.04050, linear_loss=0.04871]
[2020-05-11 16:48:45.782]  Step 140746  [3.320 sec/step, loss=0.10696, avg_loss=0.09833, mel_loss=0.05088, linear_loss=0.05608]
[2020-05-11 16:48:47.917]  Step 140747  [3.322 sec/step, loss=0.09974, avg_loss=0.09831, mel_loss=0.04609, linear_loss=0.05365]
[2020-05-11 16:48:50.673]  Step 140748  [3.336 sec/step, loss=0.10246, avg_loss=0.09839, mel_loss=0.04772, linear_loss=0.05474]
[2020-05-11 16:48:53.697]  Step 140749  [3.351 sec/step, loss=0.10360, avg_loss=0.09846, mel_loss=0.04832, linear_loss=0.05528]
[2020-05-11 16:49:01.296]  Step 140750  [3.417 sec/step, loss=0.10607, avg_loss=0.09860, mel_loss=0.05079, linear_loss=0.05528]
[2020-05-11 16:49:01.296]  Writing summary at step: 140750
[2020-05-11 16:49:03.967]  Saving checkpoint to: ./logs-tacotron/model.ckpt-140750
[2020-05-11 16:49:05.464]  Saving audio and alignment...
[2020-05-11 16:49:08.051]  Input: 모음을 끄는 것이라고 했습~
[2020-05-11 16:49:22.711]  Step 140751  [3.535 sec/step, loss=0.08160, avg_loss=0.09840, mel_loss=0.03999, linear_loss=0.04161]
[2020-05-11 16:49:26.052]  Step 140752  [3.547 sec/step, loss=0.10521, avg_loss=0.09845, mel_loss=0.04943, linear_loss=0.05578]
[2020-05-11 16:49:27.799]  Step 140753  [3.506 sec/step, loss=0.09809, avg_loss=0.09838, mel_loss=0.04484, linear_loss=0.05325]
[2020-05-11 16:49:29.039]  Step 140754  [3.501 sec/step, loss=0.09218, avg_loss=0.09832, mel_loss=0.04195, linear_loss=0.05023]
[2020-05-11 16:49:33.334]  Step 140755  [3.538 sec/step, loss=0.10535, avg_loss=0.09856, mel_loss=0.04969, linear_loss=0.05566]
[2020-05-11 16:49:34.794]  Step 140756  [3.542 sec/step, loss=0.09488, avg_loss=0.09858, mel_loss=0.04355, linear_loss=0.05133]
[2020-05-11 16:49:35.589]  Step 140757  [3.406 sec/step, loss=0.08611, avg_loss=0.09860, mel_loss=0.03885, linear_loss=0.04726]
[2020-05-11 16:49:37.369]  Generated 32 batches of size 32 in 1.776 sec
[2020-05-11 16:49:37.664]  Step 140758  [3.416 sec/step, loss=0.09968, avg_loss=0.09866, mel_loss=0.04567, linear_loss=0.05401]
[2020-05-11 16:49:38.684]  Step 140759  [3.381 sec/step, loss=0.09029, avg_loss=0.09849, mel_loss=0.04097, linear_loss=0.04933]
[2020-05-11 16:49:42.240]  Step 140760  [3.395 sec/step, loss=0.10512, avg_loss=0.09855, mel_loss=0.04958, linear_loss=0.05554]
[2020-05-11 16:49:44.469]  Step 140761  [3.408 sec/step, loss=0.10029, avg_loss=0.09866, mel_loss=0.04623, linear_loss=0.05406]
[2020-05-11 16:49:53.422]  Step 140762  [3.460 sec/step, loss=0.10464, avg_loss=0.09867, mel_loss=0.05075, linear_loss=0.05389]
[2020-05-11 16:49:55.854]  Step 140763  [3.436 sec/step, loss=0.10031, avg_loss=0.09862, mel_loss=0.04640, linear_loss=0.05391]
[2020-05-11 16:50:00.394]  Step 140764  [3.449 sec/step, loss=0.10744, avg_loss=0.09866, mel_loss=0.05089, linear_loss=0.05655]
[2020-05-11 16:50:04.085]  Step 140765  [3.478 sec/step, loss=0.10478, avg_loss=0.09885, mel_loss=0.04926, linear_loss=0.05552]
[2020-05-11 16:50:05.186]  Step 140766  [3.463 sec/step, loss=0.09189, avg_loss=0.09879, mel_loss=0.04119, linear_loss=0.05070]
[2020-05-11 16:50:07.531]  Step 140767  [3.471 sec/step, loss=0.10161, avg_loss=0.09883, mel_loss=0.04713, linear_loss=0.05447]
[2020-05-11 16:50:09.112]  Step 140768  [3.412 sec/step, loss=0.09940, avg_loss=0.09878, mel_loss=0.04582, linear_loss=0.05358]
[2020-05-11 16:50:11.244]  Step 140769  [3.350 sec/step, loss=0.10020, avg_loss=0.09875, mel_loss=0.04652, linear_loss=0.05368]
[2020-05-11 16:50:12.343]  Step 140770  [3.342 sec/step, loss=0.09157, avg_loss=0.09868, mel_loss=0.04108, linear_loss=0.05049]
[2020-05-11 16:50:13.672]  Step 140771  [3.320 sec/step, loss=0.09426, avg_loss=0.09855, mel_loss=0.04291, linear_loss=0.05135]
[2020-05-11 16:50:17.687]  Step 140772  [3.326 sec/step, loss=0.10779, avg_loss=0.09861, mel_loss=0.05073, linear_loss=0.05707]
[2020-05-11 16:50:19.425]  Step 140773  [3.335 sec/step, loss=0.09786, avg_loss=0.09878, mel_loss=0.04454, linear_loss=0.05332]
[2020-05-11 16:50:23.881]  Step 140774  [3.356 sec/step, loss=0.10621, avg_loss=0.09881, mel_loss=0.05018, linear_loss=0.05603]
[2020-05-11 16:50:24.667]  Step 140775  [3.310 sec/step, loss=0.08486, avg_loss=0.09859, mel_loss=0.03854, linear_loss=0.04632]
[2020-05-11 16:50:26.023]  Step 140776  [3.287 sec/step, loss=0.09476, avg_loss=0.09847, mel_loss=0.04385, linear_loss=0.05091]
[2020-05-11 16:50:27.956]  Step 140777  [3.296 sec/step, loss=0.10078, avg_loss=0.09860, mel_loss=0.04632, linear_loss=0.05445]
[2020-05-11 16:50:29.844]  Step 140778  [3.308 sec/step, loss=0.09847, avg_loss=0.09878, mel_loss=0.04489, linear_loss=0.05358]
[2020-05-11 16:50:33.427]  Step 140779  [3.330 sec/step, loss=0.10434, avg_loss=0.09889, mel_loss=0.04897, linear_loss=0.05537]
[2020-05-11 16:50:35.842]  Step 140780  [3.343 sec/step, loss=0.10106, avg_loss=0.09899, mel_loss=0.04667, linear_loss=0.05438]
[2020-05-11 16:50:42.800]  Step 140781  [3.393 sec/step, loss=0.10575, avg_loss=0.09904, mel_loss=0.05071, linear_loss=0.05504]
[2020-05-11 16:50:43.354]  Step 140782  [3.357 sec/step, loss=0.07690, avg_loss=0.09876, mel_loss=0.03513, linear_loss=0.04177]
[2020-05-11 16:50:44.228]  Step 140783  [3.332 sec/step, loss=0.08968, avg_loss=0.09862, mel_loss=0.04064, linear_loss=0.04904]
[2020-05-11 16:50:47.112]  Step 140784  [3.336 sec/step, loss=0.10217, avg_loss=0.09863, mel_loss=0.04776, linear_loss=0.05441]
[2020-05-11 16:50:55.232]  Step 140785  [3.383 sec/step, loss=0.10422, avg_loss=0.09864, mel_loss=0.05034, linear_loss=0.05388]
[2020-05-11 16:50:58.693]  Step 140786  [3.398 sec/step, loss=0.10173, avg_loss=0.09867, mel_loss=0.04744, linear_loss=0.05429]
[2020-05-11 16:51:13.146]  Step 140787  [3.502 sec/step, loss=0.07776, avg_loss=0.09838, mel_loss=0.03815, linear_loss=0.03961]
[2020-05-11 16:51:18.312]  Step 140788  [3.546 sec/step, loss=0.10464, avg_loss=0.09863, mel_loss=0.04941, linear_loss=0.05523]
[2020-05-11 16:51:19.570]  Step 140789  [3.483 sec/step, loss=0.09386, avg_loss=0.09850, mel_loss=0.04265, linear_loss=0.05121]
[2020-05-11 16:51:21.342]  Generated 32 batches of size 32 in 1.767 sec
[2020-05-11 16:51:25.923]  Step 140790  [3.529 sec/step, loss=0.10394, avg_loss=0.09854, mel_loss=0.04963, linear_loss=0.05431]
[2020-05-11 16:51:31.429]  Step 140791  [3.568 sec/step, loss=0.10382, avg_loss=0.09859, mel_loss=0.04914, linear_loss=0.05468]
[2020-05-11 16:51:32.988]  Step 140792  [3.466 sec/step, loss=0.09723, avg_loss=0.09858, mel_loss=0.04466, linear_loss=0.05257]
[2020-05-11 16:51:35.991]  Step 140793  [3.406 sec/step, loss=0.10374, avg_loss=0.09858, mel_loss=0.04833, linear_loss=0.05541]
[2020-05-11 16:51:36.745]  Step 140794  [3.389 sec/step, loss=0.08388, avg_loss=0.09840, mel_loss=0.03824, linear_loss=0.04564]
[2020-05-11 16:51:39.439]  Step 140795  [3.387 sec/step, loss=0.10338, avg_loss=0.09840, mel_loss=0.04838, linear_loss=0.05500]
[2020-05-11 16:51:42.815]  Step 140796  [3.364 sec/step, loss=0.10232, avg_loss=0.09835, mel_loss=0.04767, linear_loss=0.05465]
[2020-05-11 16:51:47.078]  Step 140797  [3.379 sec/step, loss=0.10419, avg_loss=0.09837, mel_loss=0.04904, linear_loss=0.05515]
[2020-05-11 16:51:48.094]  Step 140798  [3.366 sec/step, loss=0.08959, avg_loss=0.09826, mel_loss=0.04087, linear_loss=0.04872]
[2020-05-11 16:51:51.263]  Step 140799  [3.382 sec/step, loss=0.10622, avg_loss=0.09837, mel_loss=0.04972, linear_loss=0.05651]
[2020-05-11 16:51:52.014]  Step 140800  [3.357 sec/step, loss=0.07848, avg_loss=0.09811, mel_loss=0.03666, linear_loss=0.04182]
[2020-05-11 16:51:52.014]  Writing summary at step: 140800
[2020-05-11 16:51:52.880]  Saving checkpoint to: ./logs-tacotron/model.ckpt-140800
[2020-05-11 16:51:54.060]  Saving audio and alignment...
[2020-05-11 16:51:56.442]  Input: 추울바알~________________________
[2020-05-11 16:51:57.863]  Step 140801  [3.302 sec/step, loss=0.09588, avg_loss=0.09800, mel_loss=0.04366, linear_loss=0.05222]
[2020-05-11 16:52:00.491]  Step 140802  [3.316 sec/step, loss=0.10108, avg_loss=0.09808, mel_loss=0.04683, linear_loss=0.05424]
[2020-05-11 16:52:02.435]  Step 140803  [3.288 sec/step, loss=0.09876, avg_loss=0.09803, mel_loss=0.04519, linear_loss=0.05357]
[2020-05-11 16:52:05.910]  Step 140804  [3.307 sec/step, loss=0.10250, avg_loss=0.09809, mel_loss=0.04792, linear_loss=0.05458]
[2020-05-11 16:52:11.686]  Step 140805  [3.323 sec/step, loss=0.10607, avg_loss=0.09810, mel_loss=0.05078, linear_loss=0.05529]
[2020-05-11 16:52:12.491]  Step 140806  [3.306 sec/step, loss=0.08513, avg_loss=0.09796, mel_loss=0.03889, linear_loss=0.04624]
[2020-05-11 16:52:15.000]  Step 140807  [3.301 sec/step, loss=0.09940, avg_loss=0.09791, mel_loss=0.04571, linear_loss=0.05370]
[2020-05-11 16:52:22.586]  Step 140808  [3.360 sec/step, loss=0.10634, avg_loss=0.09800, mel_loss=0.05109, linear_loss=0.05526]
[2020-05-11 16:52:25.725]  Step 140809  [3.352 sec/step, loss=0.10538, avg_loss=0.09800, mel_loss=0.04949, linear_loss=0.05589]
[2020-05-11 16:52:38.104]  Step 140810  [3.457 sec/step, loss=0.09588, avg_loss=0.09795, mel_loss=0.04707, linear_loss=0.04881]
[2020-05-11 16:52:39.207]  Step 140811  [3.458 sec/step, loss=0.09152, avg_loss=0.09799, mel_loss=0.04158, linear_loss=0.04993]
[2020-05-11 16:52:46.034]  Step 140812  [3.447 sec/step, loss=0.10645, avg_loss=0.09799, mel_loss=0.05087, linear_loss=0.05558]
[2020-05-11 16:52:51.513]  Step 140813  [3.470 sec/step, loss=0.10911, avg_loss=0.09804, mel_loss=0.05198, linear_loss=0.05713]
[2020-05-11 16:52:54.362]  Step 140814  [3.493 sec/step, loss=0.10405, avg_loss=0.09830, mel_loss=0.04855, linear_loss=0.05550]
[2020-05-11 16:52:55.566]  Step 140815  [3.366 sec/step, loss=0.09209, avg_loss=0.09834, mel_loss=0.04180, linear_loss=0.05029]
[2020-05-11 16:53:04.734]  Step 140816  [3.435 sec/step, loss=0.10494, avg_loss=0.09844, mel_loss=0.05080, linear_loss=0.05415]
[2020-05-11 16:53:08.436]  Step 140817  [3.374 sec/step, loss=0.10378, avg_loss=0.09841, mel_loss=0.04850, linear_loss=0.05528]
[2020-05-11 16:53:12.621]  Step 140818  [3.388 sec/step, loss=0.10261, avg_loss=0.09841, mel_loss=0.04804, linear_loss=0.05456]
[2020-05-11 16:53:17.125]  Step 140819  [3.384 sec/step, loss=0.10566, avg_loss=0.09841, mel_loss=0.05000, linear_loss=0.05566]
[2020-05-11 16:53:18.188]  Step 140820  [3.340 sec/step, loss=0.08819, avg_loss=0.09826, mel_loss=0.04001, linear_loss=0.04818]
[2020-05-11 16:53:18.847]  Generated 32 batches of size 32 in 1.717 sec
[2020-05-11 16:53:20.348]  Step 140821  [3.348 sec/step, loss=0.09901, avg_loss=0.09828, mel_loss=0.04590, linear_loss=0.05312]
[2020-05-11 16:53:22.122]  Step 140822  [3.330 sec/step, loss=0.09739, avg_loss=0.09820, mel_loss=0.04453, linear_loss=0.05286]
[2020-05-11 16:53:27.016]  Step 140823  [3.362 sec/step, loss=0.10323, avg_loss=0.09829, mel_loss=0.04882, linear_loss=0.05442]
[2020-05-11 16:53:29.099]  Step 140824  [3.372 sec/step, loss=0.09904, avg_loss=0.09833, mel_loss=0.04531, linear_loss=0.05373]
[2020-05-11 16:53:30.111]  Step 140825  [3.360 sec/step, loss=0.08621, avg_loss=0.09820, mel_loss=0.03911, linear_loss=0.04710]
[2020-05-11 16:53:32.438]  Step 140826  [3.371 sec/step, loss=0.09919, avg_loss=0.09834, mel_loss=0.04594, linear_loss=0.05325]
[2020-05-11 16:53:34.082]  Step 140827  [3.351 sec/step, loss=0.09513, avg_loss=0.09830, mel_loss=0.04366, linear_loss=0.05147]
[2020-05-11 16:53:35.749]  Step 140828  [3.295 sec/step, loss=0.09707, avg_loss=0.09821, mel_loss=0.04442, linear_loss=0.05265]
[2020-05-11 16:53:38.533]  Step 140829  [3.270 sec/step, loss=0.10072, avg_loss=0.09818, mel_loss=0.04657, linear_loss=0.05416]
[2020-05-11 16:53:40.185]  Step 140830  [3.212 sec/step, loss=0.09800, avg_loss=0.09811, mel_loss=0.04478, linear_loss=0.05322]
[2020-05-11 16:53:42.210]  Step 140831  [3.220 sec/step, loss=0.09824, avg_loss=0.09815, mel_loss=0.04534, linear_loss=0.05290]
[2020-05-11 16:53:43.978]  Step 140832  [3.209 sec/step, loss=0.09742, avg_loss=0.09809, mel_loss=0.04469, linear_loss=0.05274]
[2020-05-11 16:53:47.418]  Step 140833  [3.234 sec/step, loss=0.10383, avg_loss=0.09823, mel_loss=0.04851, linear_loss=0.05532]
[2020-05-11 16:53:48.432]  Step 140834  [3.237 sec/step, loss=0.08748, avg_loss=0.09830, mel_loss=0.03971, linear_loss=0.04777]
[2020-05-11 16:53:49.204]  Step 140835  [3.227 sec/step, loss=0.08439, avg_loss=0.09817, mel_loss=0.03836, linear_loss=0.04603]
[2020-05-11 16:53:56.643]  Step 140836  [3.280 sec/step, loss=0.10718, avg_loss=0.09822, mel_loss=0.05166, linear_loss=0.05552]
[2020-05-11 16:54:00.822]  Step 140837  [3.303 sec/step, loss=0.10485, avg_loss=0.09830, mel_loss=0.04919, linear_loss=0.05566]
[2020-05-11 16:54:01.388]  Step 140838  [3.274 sec/step, loss=0.08037, avg_loss=0.09807, mel_loss=0.03730, linear_loss=0.04308]
[2020-05-11 16:54:02.368]  Step 140839  [3.268 sec/step, loss=0.09334, avg_loss=0.09803, mel_loss=0.04216, linear_loss=0.05117]
[2020-05-11 16:54:15.437]  Step 140840  [3.334 sec/step, loss=0.08959, avg_loss=0.09787, mel_loss=0.04379, linear_loss=0.04581]
[2020-05-11 16:54:16.276]  Step 140841  [3.326 sec/step, loss=0.08251, avg_loss=0.09770, mel_loss=0.03739, linear_loss=0.04513]
[2020-05-11 16:54:23.183]  Step 140842  [3.387 sec/step, loss=0.10754, avg_loss=0.09793, mel_loss=0.05171, linear_loss=0.05583]
[2020-05-11 16:54:24.757]  Step 140843  [3.351 sec/step, loss=0.09588, avg_loss=0.09784, mel_loss=0.04371, linear_loss=0.05218]
[2020-05-11 16:54:33.803]  Step 140844  [3.434 sec/step, loss=0.10484, avg_loss=0.09810, mel_loss=0.05063, linear_loss=0.05421]
[2020-05-11 16:54:38.697]  Step 140845  [3.473 sec/step, loss=0.10353, avg_loss=0.09824, mel_loss=0.04893, linear_loss=0.05461]
[2020-05-11 16:54:41.626]  Step 140846  [3.446 sec/step, loss=0.10345, avg_loss=0.09821, mel_loss=0.04802, linear_loss=0.05543]
[2020-05-11 16:54:42.884]  Step 140847  [3.438 sec/step, loss=0.09203, avg_loss=0.09813, mel_loss=0.04211, linear_loss=0.04993]
[2020-05-11 16:54:46.394]  Step 140848  [3.445 sec/step, loss=0.10342, avg_loss=0.09814, mel_loss=0.04858, linear_loss=0.05484]
[2020-05-11 16:54:49.585]  Step 140849  [3.447 sec/step, loss=0.10412, avg_loss=0.09814, mel_loss=0.04877, linear_loss=0.05535]
[2020-05-11 16:54:54.753]  Step 140850  [3.423 sec/step, loss=0.10669, avg_loss=0.09815, mel_loss=0.05101, linear_loss=0.05569]
[2020-05-11 16:54:54.753]  Writing summary at step: 140850
[2020-05-11 16:54:56.240]  Saving checkpoint to: ./logs-tacotron/model.ckpt-140850
[2020-05-11 16:54:57.533]  Saving audio and alignment...
[2020-05-11 16:54:59.506]  Generated 32 batches of size 32 in 1.485 sec
[2020-05-11 16:55:01.211]  Input: 제가 단상까지 딱 세 걸음~___________________
[2020-05-11 16:55:06.943]  Step 140851  [3.333 sec/step, loss=0.10565, avg_loss=0.09839, mel_loss=0.05035, linear_loss=0.05530]
[2020-05-11 16:55:09.460]  Step 140852  [3.325 sec/step, loss=0.10134, avg_loss=0.09835, mel_loss=0.04682, linear_loss=0.05452]
[2020-05-11 16:55:10.562]  Step 140853  [3.319 sec/step, loss=0.09186, avg_loss=0.09829, mel_loss=0.04143, linear_loss=0.05042]
[2020-05-11 16:55:11.929]  Step 140854  [3.320 sec/step, loss=0.09622, avg_loss=0.09833, mel_loss=0.04390, linear_loss=0.05231]
[2020-05-11 16:55:14.151]  Step 140855  [3.299 sec/step, loss=0.10005, avg_loss=0.09828, mel_loss=0.04619, linear_loss=0.05386]
[2020-05-11 16:55:18.598]  Step 140856  [3.329 sec/step, loss=0.10567, avg_loss=0.09839, mel_loss=0.04998, linear_loss=0.05569]
[2020-05-11 16:55:21.070]  Step 140857  [3.346 sec/step, loss=0.10065, avg_loss=0.09853, mel_loss=0.04672, linear_loss=0.05393]
[2020-05-11 16:55:24.821]  Step 140858  [3.362 sec/step, loss=0.10566, avg_loss=0.09859, mel_loss=0.04967, linear_loss=0.05599]
[2020-05-11 16:55:25.944]  Step 140859  [3.364 sec/step, loss=0.09319, avg_loss=0.09862, mel_loss=0.04188, linear_loss=0.05131]
[2020-05-11 16:55:29.102]  Step 140860  [3.360 sec/step, loss=0.10570, avg_loss=0.09863, mel_loss=0.04905, linear_loss=0.05665]
[2020-05-11 16:55:33.126]  Step 140861  [3.377 sec/step, loss=0.10413, avg_loss=0.09866, mel_loss=0.04886, linear_loss=0.05527]
[2020-05-11 16:55:38.935]  Step 140862  [3.346 sec/step, loss=0.10588, avg_loss=0.09868, mel_loss=0.05033, linear_loss=0.05555]
[2020-05-11 16:55:41.579]  Step 140863  [3.348 sec/step, loss=0.10052, avg_loss=0.09868, mel_loss=0.04686, linear_loss=0.05365]
[2020-05-11 16:55:48.296]  Step 140864  [3.370 sec/step, loss=0.10381, avg_loss=0.09864, mel_loss=0.04994, linear_loss=0.05387]
[2020-05-11 16:55:49.334]  Step 140865  [3.343 sec/step, loss=0.08831, avg_loss=0.09848, mel_loss=0.03989, linear_loss=0.04842]
[2020-05-11 16:55:51.104]  Step 140866  [3.350 sec/step, loss=0.09597, avg_loss=0.09852, mel_loss=0.04438, linear_loss=0.05159]
[2020-05-11 16:56:05.286]  Step 140867  [3.468 sec/step, loss=0.07895, avg_loss=0.09829, mel_loss=0.03861, linear_loss=0.04033]
[2020-05-11 16:56:07.512]  Step 140868  [3.475 sec/step, loss=0.10133, avg_loss=0.09831, mel_loss=0.04698, linear_loss=0.05435]
[2020-05-11 16:56:08.341]  Step 140869  [3.462 sec/step, loss=0.08775, avg_loss=0.09819, mel_loss=0.03963, linear_loss=0.04812]
[2020-05-11 16:56:08.917]  Step 140870  [3.457 sec/step, loss=0.08029, avg_loss=0.09807, mel_loss=0.03693, linear_loss=0.04335]
[2020-05-11 16:56:11.133]  Step 140871  [3.466 sec/step, loss=0.10131, avg_loss=0.09814, mel_loss=0.04646, linear_loss=0.05485]
[2020-05-11 16:56:12.750]  Step 140872  [3.442 sec/step, loss=0.09942, avg_loss=0.09806, mel_loss=0.04569, linear_loss=0.05373]
[2020-05-11 16:56:14.094]  Step 140873  [3.438 sec/step, loss=0.09681, avg_loss=0.09805, mel_loss=0.04441, linear_loss=0.05239]
[2020-05-11 16:56:18.482]  Step 140874  [3.437 sec/step, loss=0.10687, avg_loss=0.09806, mel_loss=0.05066, linear_loss=0.05621]
[2020-05-11 16:56:23.223]  Step 140875  [3.476 sec/step, loss=0.10453, avg_loss=0.09825, mel_loss=0.04930, linear_loss=0.05523]
[2020-05-11 16:56:26.305]  Step 140876  [3.494 sec/step, loss=0.10220, avg_loss=0.09833, mel_loss=0.04793, linear_loss=0.05427]
[2020-05-11 16:56:28.948]  Step 140877  [3.501 sec/step, loss=0.10050, avg_loss=0.09833, mel_loss=0.04645, linear_loss=0.05405]
[2020-05-11 16:56:32.643]  Step 140878  [3.519 sec/step, loss=0.10141, avg_loss=0.09835, mel_loss=0.04722, linear_loss=0.05419]
[2020-05-11 16:56:37.987]  Step 140879  [3.537 sec/step, loss=0.10636, avg_loss=0.09837, mel_loss=0.05014, linear_loss=0.05622]
[2020-05-11 16:56:39.960]  Step 140880  [3.532 sec/step, loss=0.10048, avg_loss=0.09837, mel_loss=0.04644, linear_loss=0.05405]
[2020-05-11 16:56:43.673]  Step 140881  [3.500 sec/step, loss=0.10526, avg_loss=0.09836, mel_loss=0.04923, linear_loss=0.05602]
[2020-05-11 16:56:44.813]  Step 140882  [3.505 sec/step, loss=0.09577, avg_loss=0.09855, mel_loss=0.04344, linear_loss=0.05233]
[2020-05-11 16:56:45.428]  Generated 32 batches of size 32 in 1.750 sec
[2020-05-11 16:56:53.059]  Step 140883  [3.579 sec/step, loss=0.10401, avg_loss=0.09870, mel_loss=0.05012, linear_loss=0.05390]
[2020-05-11 16:56:56.121]  Step 140884  [3.581 sec/step, loss=0.10201, avg_loss=0.09869, mel_loss=0.04751, linear_loss=0.05450]
[2020-05-11 16:56:57.654]  Step 140885  [3.515 sec/step, loss=0.09535, avg_loss=0.09861, mel_loss=0.04338, linear_loss=0.05197]
[2020-05-11 16:56:59.564]  Step 140886  [3.500 sec/step, loss=0.09784, avg_loss=0.09857, mel_loss=0.04467, linear_loss=0.05317]
[2020-05-11 16:57:00.489]  Step 140887  [3.364 sec/step, loss=0.08830, avg_loss=0.09867, mel_loss=0.03992, linear_loss=0.04839]
[2020-05-11 16:57:01.263]  Step 140888  [3.320 sec/step, loss=0.07967, avg_loss=0.09842, mel_loss=0.03633, linear_loss=0.04335]
[2020-05-11 16:57:02.601]  Step 140889  [3.321 sec/step, loss=0.09423, avg_loss=0.09843, mel_loss=0.04281, linear_loss=0.05142]
[2020-05-11 16:57:06.194]  Step 140890  [3.294 sec/step, loss=0.10358, avg_loss=0.09842, mel_loss=0.04862, linear_loss=0.05496]
[2020-05-11 16:57:07.666]  Step 140891  [3.253 sec/step, loss=0.09433, avg_loss=0.09833, mel_loss=0.04332, linear_loss=0.05100]
[2020-05-11 16:57:11.151]  Step 140892  [3.273 sec/step, loss=0.10193, avg_loss=0.09837, mel_loss=0.04764, linear_loss=0.05429]
[2020-05-11 16:57:12.828]  Step 140893  [3.259 sec/step, loss=0.09774, avg_loss=0.09831, mel_loss=0.04430, linear_loss=0.05345]
[2020-05-11 16:57:14.100]  Step 140894  [3.264 sec/step, loss=0.09280, avg_loss=0.09840, mel_loss=0.04246, linear_loss=0.05034]
[2020-05-11 16:57:14.994]  Step 140895  [3.246 sec/step, loss=0.08738, avg_loss=0.09824, mel_loss=0.03930, linear_loss=0.04808]
[2020-05-11 16:57:20.365]  Step 140896  [3.266 sec/step, loss=0.10595, avg_loss=0.09828, mel_loss=0.05025, linear_loss=0.05570]
[2020-05-11 16:57:24.109]  Step 140897  [3.261 sec/step, loss=0.10419, avg_loss=0.09828, mel_loss=0.04896, linear_loss=0.05523]
[2020-05-11 16:57:25.117]  Step 140898  [3.261 sec/step, loss=0.08773, avg_loss=0.09826, mel_loss=0.03975, linear_loss=0.04798]
[2020-05-11 16:57:31.874]  Step 140899  [3.297 sec/step, loss=0.10604, avg_loss=0.09826, mel_loss=0.05071, linear_loss=0.05533]
[2020-05-11 16:57:40.712]  Step 140900  [3.378 sec/step, loss=0.10405, avg_loss=0.09852, mel_loss=0.05018, linear_loss=0.05387]
[2020-05-11 16:57:40.712]  Writing summary at step: 140900
[2020-05-11 16:57:42.095]  Saving checkpoint to: ./logs-tacotron/model.ckpt-140900
[2020-05-11 16:57:43.298]  Saving audio and alignment...
[2020-05-11 16:57:46.710]  Input: 벤젠입니다 이런 걸로 다 바꾸고요~________
[2020-05-11 16:57:50.152]  Step 140901  [3.398 sec/step, loss=0.10342, avg_loss=0.09859, mel_loss=0.04826, linear_loss=0.05516]
[2020-05-11 16:57:50.740]  Step 140902  [3.378 sec/step, loss=0.07839, avg_loss=0.09836, mel_loss=0.03666, linear_loss=0.04174]
[2020-05-11 16:57:51.602]  Step 140903  [3.367 sec/step, loss=0.08506, avg_loss=0.09823, mel_loss=0.03854, linear_loss=0.04652]
[2020-05-11 16:58:08.181]  Step 140904  [3.498 sec/step, loss=0.08307, avg_loss=0.09803, mel_loss=0.04093, linear_loss=0.04214]
[2020-05-11 16:58:10.948]  Step 140905  [3.468 sec/step, loss=0.09607, avg_loss=0.09793, mel_loss=0.04437, linear_loss=0.05169]
[2020-05-11 16:58:12.248]  Step 140906  [3.473 sec/step, loss=0.08696, avg_loss=0.09795, mel_loss=0.03911, linear_loss=0.04784]
[2020-05-11 16:58:13.969]  Step 140907  [3.465 sec/step, loss=0.08995, avg_loss=0.09786, mel_loss=0.04051, linear_loss=0.04944]
[2020-05-11 16:58:21.049]  Step 140908  [3.460 sec/step, loss=0.10505, avg_loss=0.09784, mel_loss=0.04967, linear_loss=0.05538]
[2020-05-11 16:58:26.020]  Step 140909  [3.478 sec/step, loss=0.10410, avg_loss=0.09783, mel_loss=0.04882, linear_loss=0.05528]
[2020-05-11 16:58:28.914]  Step 140910  [3.383 sec/step, loss=0.10129, avg_loss=0.09789, mel_loss=0.04715, linear_loss=0.05414]
[2020-05-11 16:58:32.125]  Step 140911  [3.404 sec/step, loss=0.10520, avg_loss=0.09802, mel_loss=0.04920, linear_loss=0.05599]
[2020-05-11 16:58:33.860]  Step 140912  [3.353 sec/step, loss=0.09687, avg_loss=0.09793, mel_loss=0.04446, linear_loss=0.05241]
[2020-05-11 16:58:33.929]  Generated 32 batches of size 32 in 1.799 sec
[2020-05-11 16:58:36.420]  Step 140913  [3.324 sec/step, loss=0.09907, avg_loss=0.09783, mel_loss=0.04533, linear_loss=0.05374]
[2020-05-11 16:58:38.400]  Step 140914  [3.316 sec/step, loss=0.09731, avg_loss=0.09776, mel_loss=0.04443, linear_loss=0.05288]
[2020-05-11 16:58:40.790]  Step 140915  [3.327 sec/step, loss=0.10184, avg_loss=0.09786, mel_loss=0.04753, linear_loss=0.05431]
[2020-05-11 16:58:43.755]  Step 140916  [3.265 sec/step, loss=0.10273, avg_loss=0.09783, mel_loss=0.04752, linear_loss=0.05521]
[2020-05-11 16:58:45.907]  Step 140917  [3.250 sec/step, loss=0.09960, avg_loss=0.09779, mel_loss=0.04593, linear_loss=0.05368]
[2020-05-11 16:58:51.746]  Step 140918  [3.266 sec/step, loss=0.10707, avg_loss=0.09784, mel_loss=0.05098, linear_loss=0.05609]
[2020-05-11 16:58:56.472]  Step 140919  [3.269 sec/step, loss=0.10713, avg_loss=0.09785, mel_loss=0.05071, linear_loss=0.05642]
[2020-05-11 16:59:04.185]  Step 140920  [3.335 sec/step, loss=0.10486, avg_loss=0.09802, mel_loss=0.05018, linear_loss=0.05468]
[2020-05-11 16:59:05.931]  Step 140921  [3.331 sec/step, loss=0.09741, avg_loss=0.09800, mel_loss=0.04473, linear_loss=0.05268]
[2020-05-11 16:59:12.506]  Step 140922  [3.379 sec/step, loss=0.10536, avg_loss=0.09808, mel_loss=0.05011, linear_loss=0.05525]
[2020-05-11 16:59:13.561]  Step 140923  [3.341 sec/step, loss=0.09515, avg_loss=0.09800, mel_loss=0.04323, linear_loss=0.05193]
[2020-05-11 16:59:14.312]  Step 140924  [3.327 sec/step, loss=0.08645, avg_loss=0.09787, mel_loss=0.03921, linear_loss=0.04724]
[2020-05-11 16:59:23.363]  Step 140925  [3.408 sec/step, loss=0.10589, avg_loss=0.09807, mel_loss=0.05151, linear_loss=0.05438]
[2020-05-11 16:59:25.248]  Step 140926  [3.403 sec/step, loss=0.09718, avg_loss=0.09805, mel_loss=0.04428, linear_loss=0.05290]
[2020-05-11 16:59:26.562]  Step 140927  [3.400 sec/step, loss=0.09420, avg_loss=0.09804, mel_loss=0.04292, linear_loss=0.05128]
[2020-05-11 16:59:30.918]  Step 140928  [3.427 sec/step, loss=0.10367, avg_loss=0.09811, mel_loss=0.04866, linear_loss=0.05501]
[2020-05-11 16:59:32.071]  Step 140929  [3.411 sec/step, loss=0.09398, avg_loss=0.09804, mel_loss=0.04233, linear_loss=0.05165]
[2020-05-11 16:59:34.635]  Step 140930  [3.420 sec/step, loss=0.10082, avg_loss=0.09807, mel_loss=0.04689, linear_loss=0.05393]
[2020-05-11 16:59:40.410]  Step 140931  [3.457 sec/step, loss=0.10570, avg_loss=0.09814, mel_loss=0.05042, linear_loss=0.05528]
[2020-05-11 16:59:41.366]  Step 140932  [3.449 sec/step, loss=0.09275, avg_loss=0.09810, mel_loss=0.04218, linear_loss=0.05058]
[2020-05-11 16:59:42.200]  Step 140933  [3.423 sec/step, loss=0.08377, avg_loss=0.09790, mel_loss=0.03875, linear_loss=0.04501]
[2020-05-11 16:59:44.575]  Step 140934  [3.437 sec/step, loss=0.09918, avg_loss=0.09801, mel_loss=0.04584, linear_loss=0.05334]
[2020-05-11 16:59:47.709]  Step 140935  [3.460 sec/step, loss=0.10304, avg_loss=0.09820, mel_loss=0.04786, linear_loss=0.05518]
[2020-05-11 16:59:52.548]  Step 140936  [3.434 sec/step, loss=0.10347, avg_loss=0.09816, mel_loss=0.04893, linear_loss=0.05454]
[2020-05-11 16:59:54.988]  Step 140937  [3.417 sec/step, loss=0.09752, avg_loss=0.09809, mel_loss=0.04501, linear_loss=0.05251]
[2020-05-11 17:00:02.188]  Step 140938  [3.483 sec/step, loss=0.10512, avg_loss=0.09834, mel_loss=0.05043, linear_loss=0.05469]
[2020-05-11 17:00:05.955]  Step 140939  [3.511 sec/step, loss=0.10426, avg_loss=0.09845, mel_loss=0.04884, linear_loss=0.05542]
[2020-05-11 17:00:09.420]  Step 140940  [3.415 sec/step, loss=0.10475, avg_loss=0.09860, mel_loss=0.04868, linear_loss=0.05606]
[2020-05-11 17:00:10.878]  Step 140941  [3.421 sec/step, loss=0.09822, avg_loss=0.09875, mel_loss=0.04538, linear_loss=0.05284]
[2020-05-11 17:00:12.217]  Step 140942  [3.366 sec/step, loss=0.09654, avg_loss=0.09864, mel_loss=0.04401, linear_loss=0.05253]
[2020-05-11 17:00:15.484]  Step 140943  [3.382 sec/step, loss=0.10463, avg_loss=0.09873, mel_loss=0.04877, linear_loss=0.05586]
[2020-05-11 17:00:17.182]  Generated 32 batches of size 32 in 1.693 sec
[2020-05-11 17:00:18.437]  Step 140944  [3.322 sec/step, loss=0.10463, avg_loss=0.09873, mel_loss=0.04889, linear_loss=0.05573]
[2020-05-11 17:00:21.865]  Step 140945  [3.307 sec/step, loss=0.10182, avg_loss=0.09871, mel_loss=0.04770, linear_loss=0.05412]
[2020-05-11 17:00:27.294]  Step 140946  [3.332 sec/step, loss=0.10518, avg_loss=0.09873, mel_loss=0.05011, linear_loss=0.05507]
[2020-05-11 17:00:29.311]  Step 140947  [3.339 sec/step, loss=0.09960, avg_loss=0.09881, mel_loss=0.04566, linear_loss=0.05394]
[2020-05-11 17:00:30.318]  Step 140948  [3.314 sec/step, loss=0.08569, avg_loss=0.09863, mel_loss=0.03903, linear_loss=0.04667]
[2020-05-11 17:00:32.468]  Step 140949  [3.304 sec/step, loss=0.09921, avg_loss=0.09858, mel_loss=0.04586, linear_loss=0.05335]
[2020-05-11 17:00:47.173]  Step 140950  [3.399 sec/step, loss=0.08250, avg_loss=0.09834, mel_loss=0.04053, linear_loss=0.04196]
[2020-05-11 17:00:47.173]  Writing summary at step: 140950
[2020-05-11 17:00:48.813]  Saving checkpoint to: ./logs-tacotron/model.ckpt-140950
[2020-05-11 17:00:50.036]  Saving audio and alignment...
[2020-05-11 17:00:51.443]  Input: 다음~________
[2020-05-11 17:00:52.612]  Step 140951  [3.354 sec/step, loss=0.08997, avg_loss=0.09818, mel_loss=0.04091, linear_loss=0.04906]
[2020-05-11 17:00:53.810]  Step 140952  [3.341 sec/step, loss=0.09237, avg_loss=0.09809, mel_loss=0.04211, linear_loss=0.05026]
[2020-05-11 17:00:55.432]  Step 140953  [3.346 sec/step, loss=0.09799, avg_loss=0.09815, mel_loss=0.04466, linear_loss=0.05334]
[2020-05-11 17:01:07.810]  Step 140954  [3.456 sec/step, loss=0.08767, avg_loss=0.09807, mel_loss=0.04248, linear_loss=0.04519]
[2020-05-11 17:01:16.123]  Step 140955  [3.517 sec/step, loss=0.10333, avg_loss=0.09810, mel_loss=0.04992, linear_loss=0.05341]
[2020-05-11 17:01:18.993]  Step 140956  [3.501 sec/step, loss=0.10171, avg_loss=0.09806, mel_loss=0.04728, linear_loss=0.05444]
[2020-05-11 17:01:20.045]  Step 140957  [3.487 sec/step, loss=0.08731, avg_loss=0.09793, mel_loss=0.03964, linear_loss=0.04766]
[2020-05-11 17:01:20.882]  Step 140958  [3.458 sec/step, loss=0.08306, avg_loss=0.09770, mel_loss=0.03753, linear_loss=0.04554]
[2020-05-11 17:01:22.229]  Step 140959  [3.460 sec/step, loss=0.09782, avg_loss=0.09775, mel_loss=0.04476, linear_loss=0.05306]
[2020-05-11 17:01:26.239]  Step 140960  [3.468 sec/step, loss=0.10365, avg_loss=0.09773, mel_loss=0.04864, linear_loss=0.05501]
[2020-05-11 17:01:30.845]  Step 140961  [3.474 sec/step, loss=0.10671, avg_loss=0.09775, mel_loss=0.05032, linear_loss=0.05639]
[2020-05-11 17:01:32.615]  Step 140962  [3.434 sec/step, loss=0.09754, avg_loss=0.09767, mel_loss=0.04422, linear_loss=0.05332]
[2020-05-11 17:01:33.647]  Step 140963  [3.418 sec/step, loss=0.08782, avg_loss=0.09754, mel_loss=0.03959, linear_loss=0.04822]
[2020-05-11 17:01:35.189]  Step 140964  [3.366 sec/step, loss=0.09516, avg_loss=0.09745, mel_loss=0.04374, linear_loss=0.05142]
[2020-05-11 17:01:38.753]  Step 140965  [3.391 sec/step, loss=0.10485, avg_loss=0.09762, mel_loss=0.04894, linear_loss=0.05591]
[2020-05-11 17:01:44.075]  Step 140966  [3.427 sec/step, loss=0.10478, avg_loss=0.09771, mel_loss=0.04968, linear_loss=0.05510]
[2020-05-11 17:01:48.406]  Step 140967  [3.328 sec/step, loss=0.10450, avg_loss=0.09796, mel_loss=0.04921, linear_loss=0.05530]
[2020-05-11 17:01:51.891]  Step 140968  [3.341 sec/step, loss=0.10319, avg_loss=0.09798, mel_loss=0.04836, linear_loss=0.05482]
[2020-05-11 17:01:53.811]  Step 140969  [3.352 sec/step, loss=0.09840, avg_loss=0.09809, mel_loss=0.04493, linear_loss=0.05346]
[2020-05-11 17:01:56.486]  Step 140970  [3.373 sec/step, loss=0.10317, avg_loss=0.09832, mel_loss=0.04767, linear_loss=0.05550]
[2020-05-11 17:01:57.047]  Step 140971  [3.356 sec/step, loss=0.07868, avg_loss=0.09809, mel_loss=0.03668, linear_loss=0.04200]
[2020-05-11 17:01:57.856]  Step 140972  [3.348 sec/step, loss=0.08351, avg_loss=0.09793, mel_loss=0.03774, linear_loss=0.04577]
[2020-05-11 17:02:00.086]  Step 140973  [3.357 sec/step, loss=0.09995, avg_loss=0.09796, mel_loss=0.04623, linear_loss=0.05373]
[2020-05-11 17:02:01.735]  Generated 32 batches of size 32 in 1.644 sec
[2020-05-11 17:02:06.821]  Step 140974  [3.380 sec/step, loss=0.10515, avg_loss=0.09795, mel_loss=0.05041, linear_loss=0.05475]
[2020-05-11 17:02:10.470]  Step 140975  [3.370 sec/step, loss=0.10577, avg_loss=0.09796, mel_loss=0.04961, linear_loss=0.05616]
[2020-05-11 17:02:16.062]  Step 140976  [3.395 sec/step, loss=0.10458, avg_loss=0.09798, mel_loss=0.04962, linear_loss=0.05496]
[2020-05-11 17:02:18.152]  Step 140977  [3.389 sec/step, loss=0.09906, avg_loss=0.09797, mel_loss=0.04578, linear_loss=0.05329]
[2020-05-11 17:02:20.191]  Step 140978  [3.373 sec/step, loss=0.10022, avg_loss=0.09796, mel_loss=0.04602, linear_loss=0.05420]
[2020-05-11 17:02:21.902]  Step 140979  [3.336 sec/step, loss=0.09745, avg_loss=0.09787, mel_loss=0.04470, linear_loss=0.05275]
[2020-05-11 17:02:24.918]  Step 140980  [3.347 sec/step, loss=0.10294, avg_loss=0.09789, mel_loss=0.04815, linear_loss=0.05479]
[2020-05-11 17:02:32.366]  Step 140981  [3.384 sec/step, loss=0.10691, avg_loss=0.09791, mel_loss=0.05147, linear_loss=0.05545]
[2020-05-11 17:02:34.927]  Step 140982  [3.398 sec/step, loss=0.10252, avg_loss=0.09798, mel_loss=0.04720, linear_loss=0.05532]
[2020-05-11 17:02:38.882]  Step 140983  [3.355 sec/step, loss=0.10497, avg_loss=0.09799, mel_loss=0.04939, linear_loss=0.05558]
[2020-05-11 17:02:41.009]  Step 140984  [3.346 sec/step, loss=0.10064, avg_loss=0.09797, mel_loss=0.04600, linear_loss=0.05464]
[2020-05-11 17:02:44.551]  Step 140985  [3.366 sec/step, loss=0.10169, avg_loss=0.09804, mel_loss=0.04740, linear_loss=0.05429]
[2020-05-11 17:02:46.750]  Step 140986  [3.369 sec/step, loss=0.09850, avg_loss=0.09804, mel_loss=0.04552, linear_loss=0.05298]
[2020-05-11 17:03:00.022]  Step 140987  [3.492 sec/step, loss=0.08926, avg_loss=0.09805, mel_loss=0.04351, linear_loss=0.04574]
[2020-05-11 17:03:08.835]  Step 140988  [3.573 sec/step, loss=0.10265, avg_loss=0.09828, mel_loss=0.04937, linear_loss=0.05327]
[2020-05-11 17:03:11.366]  Step 140989  [3.585 sec/step, loss=0.10033, avg_loss=0.09834, mel_loss=0.04600, linear_loss=0.05433]
[2020-05-11 17:03:14.160]  Step 140990  [3.577 sec/step, loss=0.10165, avg_loss=0.09832, mel_loss=0.04750, linear_loss=0.05415]
[2020-05-11 17:03:15.181]  Step 140991  [3.572 sec/step, loss=0.09133, avg_loss=0.09829, mel_loss=0.04160, linear_loss=0.04973]
[2020-05-11 17:03:19.845]  Step 140992  [3.584 sec/step, loss=0.10501, avg_loss=0.09832, mel_loss=0.04956, linear_loss=0.05546]
[2020-05-11 17:03:21.682]  Step 140993  [3.586 sec/step, loss=0.09841, avg_loss=0.09833, mel_loss=0.04488, linear_loss=0.05353]
[2020-05-11 17:03:22.449]  Step 140994  [3.581 sec/step, loss=0.08032, avg_loss=0.09821, mel_loss=0.03706, linear_loss=0.04326]
[2020-05-11 17:03:24.110]  Step 140995  [3.588 sec/step, loss=0.09447, avg_loss=0.09828, mel_loss=0.04319, linear_loss=0.05128]
[2020-05-11 17:03:30.388]  Step 140996  [3.597 sec/step, loss=0.10554, avg_loss=0.09827, mel_loss=0.05035, linear_loss=0.05519]
[2020-05-11 17:03:33.968]  Step 140997  [3.596 sec/step, loss=0.10448, avg_loss=0.09828, mel_loss=0.04880, linear_loss=0.05568]
[2020-05-11 17:03:35.975]  Step 140998  [3.606 sec/step, loss=0.09670, avg_loss=0.09837, mel_loss=0.04476, linear_loss=0.05195]
[2020-05-11 17:03:37.681]  Step 140999  [3.555 sec/step, loss=0.10011, avg_loss=0.09831, mel_loss=0.04554, linear_loss=0.05457]
[2020-05-11 17:03:43.252]  Step 141000  [3.522 sec/step, loss=0.10479, avg_loss=0.09831, mel_loss=0.04948, linear_loss=0.05531]
[2020-05-11 17:03:43.252]  Writing summary at step: 141000
[2020-05-11 17:03:50.756]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141000
[2020-05-11 17:03:51.966]  Saving audio and alignment...
[2020-05-11 17:03:55.923]  Input: 이렇게 주어가 두개가 연달아 있을 때는~______________
[2020-05-11 17:03:58.813]  Step 141001  [3.517 sec/step, loss=0.10479, avg_loss=0.09833, mel_loss=0.04884, linear_loss=0.05595]
[2020-05-11 17:03:59.830]  Step 141002  [3.521 sec/step, loss=0.09142, avg_loss=0.09846, mel_loss=0.04088, linear_loss=0.05054]
[2020-05-11 17:04:01.227]  Step 141003  [3.527 sec/step, loss=0.09399, avg_loss=0.09855, mel_loss=0.04309, linear_loss=0.05089]
[2020-05-11 17:04:02.747]  Step 141004  [3.376 sec/step, loss=0.09474, avg_loss=0.09866, mel_loss=0.04306, linear_loss=0.05168]
[2020-05-11 17:04:02.988]  Generated 32 batches of size 32 in 1.756 sec
[2020-05-11 17:04:07.104]  Step 141005  [3.392 sec/step, loss=0.10637, avg_loss=0.09877, mel_loss=0.05030, linear_loss=0.05607]
[2020-05-11 17:04:07.784]  Step 141006  [3.386 sec/step, loss=0.08940, avg_loss=0.09879, mel_loss=0.04085, linear_loss=0.04854]
[2020-05-11 17:04:10.899]  Step 141007  [3.400 sec/step, loss=0.10534, avg_loss=0.09894, mel_loss=0.04914, linear_loss=0.05620]
[2020-05-11 17:04:15.912]  Step 141008  [3.379 sec/step, loss=0.10542, avg_loss=0.09895, mel_loss=0.04956, linear_loss=0.05586]
[2020-05-11 17:04:17.072]  Step 141009  [3.341 sec/step, loss=0.08929, avg_loss=0.09880, mel_loss=0.04003, linear_loss=0.04926]
[2020-05-11 17:04:18.305]  Step 141010  [3.324 sec/step, loss=0.09411, avg_loss=0.09873, mel_loss=0.04272, linear_loss=0.05139]
[2020-05-11 17:04:22.532]  Step 141011  [3.334 sec/step, loss=0.10389, avg_loss=0.09872, mel_loss=0.04860, linear_loss=0.05529]
[2020-05-11 17:04:23.351]  Step 141012  [3.325 sec/step, loss=0.08807, avg_loss=0.09863, mel_loss=0.03980, linear_loss=0.04826]
[2020-05-11 17:04:32.288]  Step 141013  [3.389 sec/step, loss=0.10496, avg_loss=0.09869, mel_loss=0.05058, linear_loss=0.05439]
[2020-05-11 17:04:35.829]  Step 141014  [3.405 sec/step, loss=0.10127, avg_loss=0.09873, mel_loss=0.04724, linear_loss=0.05403]
[2020-05-11 17:04:43.393]  Step 141015  [3.456 sec/step, loss=0.10584, avg_loss=0.09877, mel_loss=0.05088, linear_loss=0.05495]
[2020-05-11 17:04:43.968]  Step 141016  [3.432 sec/step, loss=0.07752, avg_loss=0.09851, mel_loss=0.03569, linear_loss=0.04183]
[2020-05-11 17:04:46.211]  Step 141017  [3.433 sec/step, loss=0.09755, avg_loss=0.09849, mel_loss=0.04493, linear_loss=0.05262]
[2020-05-11 17:04:47.665]  Step 141018  [3.390 sec/step, loss=0.09699, avg_loss=0.09839, mel_loss=0.04482, linear_loss=0.05217]
[2020-05-11 17:04:48.991]  Step 141019  [3.356 sec/step, loss=0.09634, avg_loss=0.09828, mel_loss=0.04417, linear_loss=0.05217]
[2020-05-11 17:04:50.032]  Step 141020  [3.289 sec/step, loss=0.08992, avg_loss=0.09813, mel_loss=0.04075, linear_loss=0.04917]
[2020-05-11 17:04:50.879]  Step 141021  [3.280 sec/step, loss=0.08804, avg_loss=0.09804, mel_loss=0.04003, linear_loss=0.04802]
[2020-05-11 17:04:51.487]  Step 141022  [3.220 sec/step, loss=0.08890, avg_loss=0.09788, mel_loss=0.04050, linear_loss=0.04840]
[2020-05-11 17:04:54.360]  Step 141023  [3.238 sec/step, loss=0.10229, avg_loss=0.09795, mel_loss=0.04746, linear_loss=0.05484]
[2020-05-11 17:04:59.652]  Step 141024  [3.284 sec/step, loss=0.10630, avg_loss=0.09815, mel_loss=0.05074, linear_loss=0.05557]
[2020-05-11 17:05:03.878]  Step 141025  [3.235 sec/step, loss=0.10279, avg_loss=0.09812, mel_loss=0.04807, linear_loss=0.05472]
[2020-05-11 17:05:05.454]  Step 141026  [3.232 sec/step, loss=0.09725, avg_loss=0.09812, mel_loss=0.04478, linear_loss=0.05247]
[2020-05-11 17:05:12.189]  Step 141027  [3.287 sec/step, loss=0.10514, avg_loss=0.09823, mel_loss=0.05039, linear_loss=0.05475]
[2020-05-11 17:05:13.358]  Step 141028  [3.255 sec/step, loss=0.09299, avg_loss=0.09812, mel_loss=0.04224, linear_loss=0.05075]
[2020-05-11 17:05:15.355]  Step 141029  [3.263 sec/step, loss=0.09745, avg_loss=0.09815, mel_loss=0.04493, linear_loss=0.05253]
[2020-05-11 17:05:18.764]  Step 141030  [3.272 sec/step, loss=0.10274, avg_loss=0.09817, mel_loss=0.04812, linear_loss=0.05462]
[2020-05-11 17:05:20.887]  Step 141031  [3.235 sec/step, loss=0.09950, avg_loss=0.09811, mel_loss=0.04591, linear_loss=0.05359]
[2020-05-11 17:05:22.186]  Step 141032  [3.239 sec/step, loss=0.09301, avg_loss=0.09811, mel_loss=0.04246, linear_loss=0.05055]
[2020-05-11 17:05:23.137]  Step 141033  [3.240 sec/step, loss=0.08987, avg_loss=0.09817, mel_loss=0.04116, linear_loss=0.04870]
[2020-05-11 17:05:27.804]  Step 141034  [3.263 sec/step, loss=0.10404, avg_loss=0.09822, mel_loss=0.04891, linear_loss=0.05514]
[2020-05-11 17:05:30.972]  Step 141035  [3.263 sec/step, loss=0.10439, avg_loss=0.09824, mel_loss=0.04864, linear_loss=0.05575]
[2020-05-11 17:05:32.641]  Generated 32 batches of size 32 in 1.664 sec
[2020-05-11 17:05:33.415]  Step 141036  [3.239 sec/step, loss=0.10079, avg_loss=0.09821, mel_loss=0.04670, linear_loss=0.05409]
[2020-05-11 17:05:47.141]  Step 141037  [3.352 sec/step, loss=0.08062, avg_loss=0.09804, mel_loss=0.03954, linear_loss=0.04107]
[2020-05-11 17:05:52.789]  Step 141038  [3.336 sec/step, loss=0.10421, avg_loss=0.09803, mel_loss=0.04964, linear_loss=0.05457]
[2020-05-11 17:05:53.612]  Step 141039  [3.307 sec/step, loss=0.08346, avg_loss=0.09782, mel_loss=0.03767, linear_loss=0.04579]
[2020-05-11 17:05:56.663]  Step 141040  [3.303 sec/step, loss=0.10428, avg_loss=0.09782, mel_loss=0.04818, linear_loss=0.05610]
[2020-05-11 17:05:58.493]  Step 141041  [3.306 sec/step, loss=0.09696, avg_loss=0.09781, mel_loss=0.04432, linear_loss=0.05264]
[2020-05-11 17:06:01.056]  Step 141042  [3.319 sec/step, loss=0.10094, avg_loss=0.09785, mel_loss=0.04693, linear_loss=0.05401]
[2020-05-11 17:06:04.770]  Step 141043  [3.323 sec/step, loss=0.10554, avg_loss=0.09786, mel_loss=0.04912, linear_loss=0.05641]
[2020-05-11 17:06:06.563]  Step 141044  [3.312 sec/step, loss=0.09576, avg_loss=0.09777, mel_loss=0.04390, linear_loss=0.05185]
[2020-05-11 17:06:10.741]  Step 141045  [3.319 sec/step, loss=0.10360, avg_loss=0.09779, mel_loss=0.04841, linear_loss=0.05518]
[2020-05-11 17:06:19.446]  Step 141046  [3.352 sec/step, loss=0.10401, avg_loss=0.09778, mel_loss=0.05031, linear_loss=0.05370]
[2020-05-11 17:06:22.677]  Step 141047  [3.364 sec/step, loss=0.10408, avg_loss=0.09782, mel_loss=0.04875, linear_loss=0.05533]
[2020-05-11 17:06:23.558]  Step 141048  [3.363 sec/step, loss=0.08004, avg_loss=0.09777, mel_loss=0.03675, linear_loss=0.04329]
[2020-05-11 17:06:24.716]  Step 141049  [3.353 sec/step, loss=0.08929, avg_loss=0.09767, mel_loss=0.04028, linear_loss=0.04901]
[2020-05-11 17:06:29.984]  Step 141050  [3.258 sec/step, loss=0.10312, avg_loss=0.09787, mel_loss=0.04893, linear_loss=0.05419]
[2020-05-11 17:06:29.984]  Writing summary at step: 141050
[2020-05-11 17:06:36.734]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141050
[2020-05-11 17:06:37.950]  Saving audio and alignment...
[2020-05-11 17:06:42.618]  Input: 좀 의아함이 컸던 그런 원고입니다 함께 보시죠~_______________
[2020-05-11 17:06:57.702]  Step 141051  [3.398 sec/step, loss=0.08042, avg_loss=0.09778, mel_loss=0.03949, linear_loss=0.04094]
[2020-05-11 17:07:01.405]  Step 141052  [3.423 sec/step, loss=0.10498, avg_loss=0.09790, mel_loss=0.04923, linear_loss=0.05576]
[2020-05-11 17:07:03.163]  Step 141053  [3.424 sec/step, loss=0.09818, avg_loss=0.09790, mel_loss=0.04478, linear_loss=0.05340]
[2020-05-11 17:07:10.597]  Step 141054  [3.375 sec/step, loss=0.10620, avg_loss=0.09809, mel_loss=0.05102, linear_loss=0.05517]
[2020-05-11 17:07:13.985]  Step 141055  [3.325 sec/step, loss=0.10207, avg_loss=0.09808, mel_loss=0.04762, linear_loss=0.05445]
[2020-05-11 17:07:15.024]  Step 141056  [3.307 sec/step, loss=0.08791, avg_loss=0.09794, mel_loss=0.03963, linear_loss=0.04828]
[2020-05-11 17:07:19.291]  Step 141057  [3.339 sec/step, loss=0.10654, avg_loss=0.09813, mel_loss=0.05044, linear_loss=0.05610]
[2020-05-11 17:07:21.570]  Step 141058  [3.354 sec/step, loss=0.10031, avg_loss=0.09830, mel_loss=0.04634, linear_loss=0.05397]
[2020-05-11 17:07:22.405]  Step 141059  [3.348 sec/step, loss=0.08200, avg_loss=0.09815, mel_loss=0.03685, linear_loss=0.04516]
[2020-05-11 17:07:24.940]  Step 141060  [3.334 sec/step, loss=0.09800, avg_loss=0.09809, mel_loss=0.04501, linear_loss=0.05299]
[2020-05-11 17:07:29.585]  Step 141061  [3.334 sec/step, loss=0.10610, avg_loss=0.09808, mel_loss=0.04998, linear_loss=0.05612]
[2020-05-11 17:07:30.940]  Step 141062  [3.330 sec/step, loss=0.09642, avg_loss=0.09807, mel_loss=0.04389, linear_loss=0.05253]
[2020-05-11 17:07:33.721]  Step 141063  [3.347 sec/step, loss=0.10176, avg_loss=0.09821, mel_loss=0.04727, linear_loss=0.05450]
[2020-05-11 17:07:35.344]  Step 141064  [3.348 sec/step, loss=0.09698, avg_loss=0.09823, mel_loss=0.04426, linear_loss=0.05271]
[2020-05-11 17:07:38.835]  Step 141065  [3.348 sec/step, loss=0.10205, avg_loss=0.09820, mel_loss=0.04768, linear_loss=0.05437]
[2020-05-11 17:07:39.961]  Step 141066  [3.306 sec/step, loss=0.09171, avg_loss=0.09807, mel_loss=0.04184, linear_loss=0.04987]
[2020-05-11 17:07:40.776]  Generated 32 batches of size 32 in 1.936 sec
[2020-05-11 17:07:45.390]  Step 141067  [3.317 sec/step, loss=0.10421, avg_loss=0.09807, mel_loss=0.04946, linear_loss=0.05475]
[2020-05-11 17:07:47.462]  Step 141068  [3.302 sec/step, loss=0.09835, avg_loss=0.09802, mel_loss=0.04547, linear_loss=0.05288]
[2020-05-11 17:07:48.696]  Step 141069  [3.296 sec/step, loss=0.09254, avg_loss=0.09796, mel_loss=0.04184, linear_loss=0.05070]
[2020-05-11 17:07:49.253]  Step 141070  [3.274 sec/step, loss=0.07784, avg_loss=0.09771, mel_loss=0.03610, linear_loss=0.04174]
[2020-05-11 17:07:51.437]  Step 141071  [3.291 sec/step, loss=0.09922, avg_loss=0.09791, mel_loss=0.04555, linear_loss=0.05367]
[2020-05-11 17:07:53.095]  Step 141072  [3.299 sec/step, loss=0.09758, avg_loss=0.09805, mel_loss=0.04479, linear_loss=0.05279]
[2020-05-11 17:07:55.011]  Step 141073  [3.296 sec/step, loss=0.09766, avg_loss=0.09803, mel_loss=0.04465, linear_loss=0.05301]
[2020-05-11 17:07:56.464]  Step 141074  [3.243 sec/step, loss=0.09362, avg_loss=0.09792, mel_loss=0.04280, linear_loss=0.05082]
[2020-05-11 17:07:58.398]  Step 141075  [3.226 sec/step, loss=0.09799, avg_loss=0.09784, mel_loss=0.04461, linear_loss=0.05338]
[2020-05-11 17:07:59.211]  Step 141076  [3.178 sec/step, loss=0.08389, avg_loss=0.09763, mel_loss=0.03829, linear_loss=0.04561]
[2020-05-11 17:08:02.622]  Step 141077  [3.191 sec/step, loss=0.10445, avg_loss=0.09768, mel_loss=0.04868, linear_loss=0.05577]
[2020-05-11 17:08:03.587]  Step 141078  [3.181 sec/step, loss=0.08616, avg_loss=0.09754, mel_loss=0.03916, linear_loss=0.04700]
[2020-05-11 17:08:05.516]  Step 141079  [3.183 sec/step, loss=0.09684, avg_loss=0.09754, mel_loss=0.04405, linear_loss=0.05280]
[2020-05-11 17:08:07.313]  Step 141080  [3.171 sec/step, loss=0.09593, avg_loss=0.09747, mel_loss=0.04381, linear_loss=0.05212]
[2020-05-11 17:08:08.570]  Step 141081  [3.109 sec/step, loss=0.09406, avg_loss=0.09734, mel_loss=0.04319, linear_loss=0.05088]
[2020-05-11 17:08:10.112]  Step 141082  [3.099 sec/step, loss=0.09420, avg_loss=0.09726, mel_loss=0.04321, linear_loss=0.05099]
[2020-05-11 17:08:18.422]  Step 141083  [3.142 sec/step, loss=0.10336, avg_loss=0.09724, mel_loss=0.04966, linear_loss=0.05370]
[2020-05-11 17:08:25.592]  Step 141084  [3.193 sec/step, loss=0.10502, avg_loss=0.09728, mel_loss=0.05019, linear_loss=0.05483]
[2020-05-11 17:08:43.162]  Step 141085  [3.333 sec/step, loss=0.09606, avg_loss=0.09723, mel_loss=0.04707, linear_loss=0.04899]
[2020-05-11 17:08:43.912]  Step 141086  [3.318 sec/step, loss=0.08701, avg_loss=0.09711, mel_loss=0.03909, linear_loss=0.04792]
[2020-05-11 17:08:47.495]  Step 141087  [3.221 sec/step, loss=0.10367, avg_loss=0.09726, mel_loss=0.04826, linear_loss=0.05541]
[2020-05-11 17:08:51.133]  Step 141088  [3.170 sec/step, loss=0.10631, avg_loss=0.09729, mel_loss=0.04980, linear_loss=0.05651]
[2020-05-11 17:08:53.996]  Step 141089  [3.173 sec/step, loss=0.10226, avg_loss=0.09731, mel_loss=0.04787, linear_loss=0.05438]
[2020-05-11 17:08:56.970]  Step 141090  [3.175 sec/step, loss=0.10195, avg_loss=0.09732, mel_loss=0.04757, linear_loss=0.05438]
[2020-05-11 17:08:58.072]  Step 141091  [3.176 sec/step, loss=0.09137, avg_loss=0.09732, mel_loss=0.04110, linear_loss=0.05028]
[2020-05-11 17:09:00.403]  Step 141092  [3.152 sec/step, loss=0.10178, avg_loss=0.09728, mel_loss=0.04702, linear_loss=0.05476]
[2020-05-11 17:09:01.159]  Step 141093  [3.141 sec/step, loss=0.08026, avg_loss=0.09710, mel_loss=0.03647, linear_loss=0.04379]
[2020-05-11 17:09:02.129]  Step 141094  [3.144 sec/step, loss=0.08838, avg_loss=0.09718, mel_loss=0.03984, linear_loss=0.04854]
[2020-05-11 17:09:06.261]  Step 141095  [3.168 sec/step, loss=0.10494, avg_loss=0.09729, mel_loss=0.04967, linear_loss=0.05528]
[2020-05-11 17:09:10.316]  Step 141096  [3.146 sec/step, loss=0.10523, avg_loss=0.09728, mel_loss=0.04913, linear_loss=0.05609]
[2020-05-11 17:09:11.658]  Step 141097  [3.124 sec/step, loss=0.09653, avg_loss=0.09721, mel_loss=0.04425, linear_loss=0.05228]
[2020-05-11 17:09:13.456]  Generated 32 batches of size 32 in 1.793 sec
[2020-05-11 17:09:13.951]  Step 141098  [3.126 sec/step, loss=0.10130, avg_loss=0.09725, mel_loss=0.04697, linear_loss=0.05433]
[2020-05-11 17:09:16.667]  Step 141099  [3.137 sec/step, loss=0.10137, avg_loss=0.09726, mel_loss=0.04672, linear_loss=0.05465]
[2020-05-11 17:09:19.084]  Step 141100  [3.105 sec/step, loss=0.10080, avg_loss=0.09722, mel_loss=0.04646, linear_loss=0.05434]
[2020-05-11 17:09:19.084]  Writing summary at step: 141100
[2020-05-11 17:09:26.711]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141100
[2020-05-11 17:09:27.903]  Saving audio and alignment...
[2020-05-11 17:09:34.696]  Input: 그러나 파리 최고의 인기 배우가 무명의 작곡가를 상대할리 없었겠죠~_________________________
[2020-05-11 17:09:36.138]  Step 141101  [3.091 sec/step, loss=0.09692, avg_loss=0.09714, mel_loss=0.04449, linear_loss=0.05244]
[2020-05-11 17:09:38.135]  Step 141102  [3.100 sec/step, loss=0.09858, avg_loss=0.09722, mel_loss=0.04490, linear_loss=0.05368]
[2020-05-11 17:09:43.394]  Step 141103  [3.139 sec/step, loss=0.10859, avg_loss=0.09736, mel_loss=0.05166, linear_loss=0.05693]
[2020-05-11 17:09:48.972]  Step 141104  [3.180 sec/step, loss=0.10531, avg_loss=0.09747, mel_loss=0.04997, linear_loss=0.05534]
[2020-05-11 17:09:56.685]  Step 141105  [3.213 sec/step, loss=0.10526, avg_loss=0.09746, mel_loss=0.05034, linear_loss=0.05492]
[2020-05-11 17:10:05.742]  Step 141106  [3.297 sec/step, loss=0.10700, avg_loss=0.09763, mel_loss=0.05191, linear_loss=0.05509]
[2020-05-11 17:10:07.890]  Step 141107  [3.287 sec/step, loss=0.10052, avg_loss=0.09759, mel_loss=0.04630, linear_loss=0.05422]
[2020-05-11 17:10:08.693]  Step 141108  [3.245 sec/step, loss=0.08687, avg_loss=0.09740, mel_loss=0.03919, linear_loss=0.04768]
[2020-05-11 17:10:10.154]  Step 141109  [3.248 sec/step, loss=0.09386, avg_loss=0.09745, mel_loss=0.04303, linear_loss=0.05083]
[2020-05-11 17:10:11.202]  Step 141110  [3.246 sec/step, loss=0.08649, avg_loss=0.09737, mel_loss=0.03942, linear_loss=0.04707]
[2020-05-11 17:10:16.575]  Step 141111  [3.258 sec/step, loss=0.10485, avg_loss=0.09738, mel_loss=0.04988, linear_loss=0.05497]
[2020-05-11 17:10:20.000]  Step 141112  [3.284 sec/step, loss=0.10172, avg_loss=0.09752, mel_loss=0.04760, linear_loss=0.05411]
[2020-05-11 17:10:22.052]  Step 141113  [3.215 sec/step, loss=0.09731, avg_loss=0.09744, mel_loss=0.04472, linear_loss=0.05259]
[2020-05-11 17:10:22.738]  Step 141114  [3.186 sec/step, loss=0.08163, avg_loss=0.09724, mel_loss=0.03710, linear_loss=0.04453]
[2020-05-11 17:10:25.215]  Step 141115  [3.136 sec/step, loss=0.09882, avg_loss=0.09717, mel_loss=0.04551, linear_loss=0.05330]
[2020-05-11 17:10:26.370]  Step 141116  [3.141 sec/step, loss=0.09006, avg_loss=0.09730, mel_loss=0.04066, linear_loss=0.04940]
[2020-05-11 17:10:28.018]  Step 141117  [3.135 sec/step, loss=0.09805, avg_loss=0.09730, mel_loss=0.04494, linear_loss=0.05311]
[2020-05-11 17:10:30.412]  Step 141118  [3.145 sec/step, loss=0.10088, avg_loss=0.09734, mel_loss=0.04682, linear_loss=0.05406]
[2020-05-11 17:10:35.229]  Step 141119  [3.180 sec/step, loss=0.10436, avg_loss=0.09742, mel_loss=0.04911, linear_loss=0.05525]
[2020-05-11 17:10:36.993]  Step 141120  [3.187 sec/step, loss=0.09820, avg_loss=0.09750, mel_loss=0.04471, linear_loss=0.05349]
[2020-05-11 17:10:38.252]  Step 141121  [3.191 sec/step, loss=0.09273, avg_loss=0.09755, mel_loss=0.04214, linear_loss=0.05059]
[2020-05-11 17:10:41.075]  Step 141122  [3.213 sec/step, loss=0.10531, avg_loss=0.09772, mel_loss=0.04893, linear_loss=0.05638]
[2020-05-11 17:10:45.260]  Step 141123  [3.226 sec/step, loss=0.10431, avg_loss=0.09774, mel_loss=0.04885, linear_loss=0.05546]
[2020-05-11 17:10:51.741]  Step 141124  [3.238 sec/step, loss=0.10891, avg_loss=0.09776, mel_loss=0.05214, linear_loss=0.05677]
[2020-05-11 17:10:54.883]  Step 141125  [3.227 sec/step, loss=0.10351, avg_loss=0.09777, mel_loss=0.04814, linear_loss=0.05537]
[2020-05-11 17:10:57.511]  Step 141126  [3.238 sec/step, loss=0.10081, avg_loss=0.09780, mel_loss=0.04687, linear_loss=0.05394]
[2020-05-11 17:11:12.150]  Step 141127  [3.317 sec/step, loss=0.08252, avg_loss=0.09758, mel_loss=0.04035, linear_loss=0.04218]
[2020-05-11 17:11:13.567]  Step 141128  [3.319 sec/step, loss=0.09604, avg_loss=0.09761, mel_loss=0.04381, linear_loss=0.05223]
[2020-05-11 17:11:14.071]  Generated 32 batches of size 32 in 1.916 sec
[2020-05-11 17:11:17.339]  Step 141129  [3.337 sec/step, loss=0.10524, avg_loss=0.09769, mel_loss=0.04917, linear_loss=0.05606]
[2020-05-11 17:11:23.206]  Step 141130  [3.362 sec/step, loss=0.10622, avg_loss=0.09772, mel_loss=0.05057, linear_loss=0.05565]
[2020-05-11 17:11:24.804]  Step 141131  [3.356 sec/step, loss=0.09720, avg_loss=0.09770, mel_loss=0.04461, linear_loss=0.05259]
[2020-05-11 17:11:25.359]  Step 141132  [3.349 sec/step, loss=0.08079, avg_loss=0.09758, mel_loss=0.03735, linear_loss=0.04344]
[2020-05-11 17:11:29.776]  Step 141133  [3.384 sec/step, loss=0.10641, avg_loss=0.09774, mel_loss=0.05029, linear_loss=0.05612]
[2020-05-11 17:11:33.110]  Step 141134  [3.370 sec/step, loss=0.10171, avg_loss=0.09772, mel_loss=0.04749, linear_loss=0.05422]
[2020-05-11 17:11:33.992]  Step 141135  [3.348 sec/step, loss=0.09106, avg_loss=0.09758, mel_loss=0.04091, linear_loss=0.05015]
[2020-05-11 17:11:35.907]  Step 141136  [3.342 sec/step, loss=0.09853, avg_loss=0.09756, mel_loss=0.04547, linear_loss=0.05306]
[2020-05-11 17:11:37.020]  Step 141137  [3.216 sec/step, loss=0.09200, avg_loss=0.09768, mel_loss=0.04145, linear_loss=0.05055]
[2020-05-11 17:11:39.847]  Step 141138  [3.188 sec/step, loss=0.10300, avg_loss=0.09766, mel_loss=0.04814, linear_loss=0.05486]
[2020-05-11 17:11:42.281]  Step 141139  [3.204 sec/step, loss=0.10005, avg_loss=0.09783, mel_loss=0.04632, linear_loss=0.05373]
[2020-05-11 17:11:56.398]  Step 141140  [3.315 sec/step, loss=0.08155, avg_loss=0.09760, mel_loss=0.04038, linear_loss=0.04117]
[2020-05-11 17:12:04.164]  Step 141141  [3.374 sec/step, loss=0.10622, avg_loss=0.09770, mel_loss=0.05092, linear_loss=0.05530]
[2020-05-11 17:12:05.290]  Step 141142  [3.360 sec/step, loss=0.09326, avg_loss=0.09762, mel_loss=0.04204, linear_loss=0.05122]
[2020-05-11 17:12:08.410]  Step 141143  [3.354 sec/step, loss=0.10314, avg_loss=0.09759, mel_loss=0.04793, linear_loss=0.05521]
[2020-05-11 17:12:10.157]  Step 141144  [3.353 sec/step, loss=0.09662, avg_loss=0.09760, mel_loss=0.04378, linear_loss=0.05283]
[2020-05-11 17:12:11.116]  Step 141145  [3.321 sec/step, loss=0.09056, avg_loss=0.09747, mel_loss=0.04063, linear_loss=0.04993]
[2020-05-11 17:12:11.674]  Step 141146  [3.240 sec/step, loss=0.07754, avg_loss=0.09721, mel_loss=0.03585, linear_loss=0.04169]
[2020-05-11 17:12:13.028]  Step 141147  [3.221 sec/step, loss=0.09509, avg_loss=0.09712, mel_loss=0.04308, linear_loss=0.05201]
[2020-05-11 17:12:13.972]  Step 141148  [3.221 sec/step, loss=0.09066, avg_loss=0.09722, mel_loss=0.04116, linear_loss=0.04950]
[2020-05-11 17:12:14.804]  Step 141149  [3.218 sec/step, loss=0.08662, avg_loss=0.09720, mel_loss=0.03943, linear_loss=0.04719]
[2020-05-11 17:12:16.918]  Step 141150  [3.187 sec/step, loss=0.10072, avg_loss=0.09717, mel_loss=0.04597, linear_loss=0.05475]
[2020-05-11 17:12:16.918]  Writing summary at step: 141150
[2020-05-11 17:12:18.778]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141150
[2020-05-11 17:12:19.993]  Saving audio and alignment...
[2020-05-11 17:12:31.188]  Input: 사전에 원고를 받아서 당일 진행만하거나 직접 행사 원고까지 작성하는 경우가 있을 수 있는데요~_______________________________________________
[2020-05-11 17:12:34.772]  Step 141151  [3.072 sec/step, loss=0.10461, avg_loss=0.09742, mel_loss=0.04854, linear_loss=0.05607]
[2020-05-11 17:12:40.324]  Step 141152  [3.090 sec/step, loss=0.10547, avg_loss=0.09742, mel_loss=0.04998, linear_loss=0.05550]
[2020-05-11 17:12:46.372]  Step 141153  [3.133 sec/step, loss=0.10472, avg_loss=0.09749, mel_loss=0.04983, linear_loss=0.05488]
[2020-05-11 17:12:51.476]  Step 141154  [3.110 sec/step, loss=0.10494, avg_loss=0.09747, mel_loss=0.04933, linear_loss=0.05561]
[2020-05-11 17:12:54.168]  Step 141155  [3.103 sec/step, loss=0.10224, avg_loss=0.09747, mel_loss=0.04762, linear_loss=0.05461]
[2020-05-11 17:12:58.660]  Step 141156  [3.137 sec/step, loss=0.10509, avg_loss=0.09765, mel_loss=0.04950, linear_loss=0.05559]
[2020-05-11 17:13:00.207]  Step 141157  [3.110 sec/step, loss=0.09795, avg_loss=0.09756, mel_loss=0.04464, linear_loss=0.05331]
[2020-05-11 17:13:02.023]  Generated 32 batches of size 32 in 1.811 sec
[2020-05-11 17:13:04.558]  Step 141158  [3.131 sec/step, loss=0.10366, avg_loss=0.09759, mel_loss=0.04873, linear_loss=0.05493]
[2020-05-11 17:13:08.243]  Step 141159  [3.159 sec/step, loss=0.10420, avg_loss=0.09782, mel_loss=0.04872, linear_loss=0.05548]
[2020-05-11 17:13:09.954]  Step 141160  [3.151 sec/step, loss=0.09696, avg_loss=0.09781, mel_loss=0.04414, linear_loss=0.05283]
[2020-05-11 17:13:11.330]  Step 141161  [3.118 sec/step, loss=0.09319, avg_loss=0.09768, mel_loss=0.04247, linear_loss=0.05072]
[2020-05-11 17:13:14.909]  Step 141162  [3.141 sec/step, loss=0.10018, avg_loss=0.09771, mel_loss=0.04678, linear_loss=0.05339]
[2020-05-11 17:13:15.669]  Step 141163  [3.120 sec/step, loss=0.08894, avg_loss=0.09759, mel_loss=0.04002, linear_loss=0.04892]
[2020-05-11 17:13:19.018]  Step 141164  [3.138 sec/step, loss=0.10663, avg_loss=0.09768, mel_loss=0.04958, linear_loss=0.05706]
[2020-05-11 17:13:21.391]  Step 141165  [3.126 sec/step, loss=0.09880, avg_loss=0.09765, mel_loss=0.04586, linear_loss=0.05295]
[2020-05-11 17:13:23.369]  Step 141166  [3.135 sec/step, loss=0.09964, avg_loss=0.09773, mel_loss=0.04537, linear_loss=0.05427]
[2020-05-11 17:13:24.983]  Step 141167  [3.097 sec/step, loss=0.09779, avg_loss=0.09767, mel_loss=0.04487, linear_loss=0.05292]
[2020-05-11 17:13:29.173]  Step 141168  [3.118 sec/step, loss=0.10418, avg_loss=0.09772, mel_loss=0.04869, linear_loss=0.05549]
[2020-05-11 17:13:32.640]  Step 141169  [3.140 sec/step, loss=0.10196, avg_loss=0.09782, mel_loss=0.04748, linear_loss=0.05448]
[2020-05-11 17:13:33.781]  Step 141170  [3.146 sec/step, loss=0.09218, avg_loss=0.09796, mel_loss=0.04183, linear_loss=0.05035]
[2020-05-11 17:13:34.414]  Step 141171  [3.131 sec/step, loss=0.08334, avg_loss=0.09780, mel_loss=0.03867, linear_loss=0.04467]
[2020-05-11 17:13:39.243]  Step 141172  [3.162 sec/step, loss=0.10328, avg_loss=0.09786, mel_loss=0.04863, linear_loss=0.05465]
[2020-05-11 17:13:41.362]  Step 141173  [3.164 sec/step, loss=0.09920, avg_loss=0.09787, mel_loss=0.04577, linear_loss=0.05343]
[2020-05-11 17:13:43.802]  Step 141174  [3.174 sec/step, loss=0.09913, avg_loss=0.09793, mel_loss=0.04534, linear_loss=0.05378]
[2020-05-11 17:13:46.458]  Step 141175  [3.182 sec/step, loss=0.09980, avg_loss=0.09795, mel_loss=0.04608, linear_loss=0.05372]
[2020-05-11 17:13:47.947]  Step 141176  [3.188 sec/step, loss=0.09466, avg_loss=0.09806, mel_loss=0.04311, linear_loss=0.05155]
[2020-05-11 17:13:56.216]  Step 141177  [3.237 sec/step, loss=0.10229, avg_loss=0.09803, mel_loss=0.04926, linear_loss=0.05303]
[2020-05-11 17:13:59.227]  Step 141178  [3.257 sec/step, loss=0.10398, avg_loss=0.09821, mel_loss=0.04859, linear_loss=0.05539]
[2020-05-11 17:14:01.244]  Step 141179  [3.258 sec/step, loss=0.09852, avg_loss=0.09823, mel_loss=0.04552, linear_loss=0.05300]
[2020-05-11 17:14:03.141]  Step 141180  [3.259 sec/step, loss=0.09668, avg_loss=0.09824, mel_loss=0.04426, linear_loss=0.05243]
[2020-05-11 17:14:06.323]  Step 141181  [3.278 sec/step, loss=0.10391, avg_loss=0.09834, mel_loss=0.04845, linear_loss=0.05546]
[2020-05-11 17:14:13.413]  Step 141182  [3.334 sec/step, loss=0.10536, avg_loss=0.09845, mel_loss=0.05029, linear_loss=0.05507]
[2020-05-11 17:14:14.755]  Step 141183  [3.264 sec/step, loss=0.09789, avg_loss=0.09839, mel_loss=0.04451, linear_loss=0.05339]
[2020-05-11 17:14:15.584]  Step 141184  [3.201 sec/step, loss=0.08698, avg_loss=0.09821, mel_loss=0.03912, linear_loss=0.04787]
[2020-05-11 17:14:18.414]  Step 141185  [3.053 sec/step, loss=0.10126, avg_loss=0.09826, mel_loss=0.04687, linear_loss=0.05439]
[2020-05-11 17:14:22.820]  Step 141186  [3.090 sec/step, loss=0.10698, avg_loss=0.09846, mel_loss=0.05048, linear_loss=0.05650]
[2020-05-11 17:14:35.105]  Step 141187  [3.177 sec/step, loss=0.08873, avg_loss=0.09831, mel_loss=0.04304, linear_loss=0.04569]
[2020-05-11 17:14:36.174]  Step 141188  [3.151 sec/step, loss=0.09078, avg_loss=0.09816, mel_loss=0.04083, linear_loss=0.04996]
[2020-05-11 17:14:37.138]  Step 141189  [3.132 sec/step, loss=0.08833, avg_loss=0.09802, mel_loss=0.03963, linear_loss=0.04870]
[2020-05-11 17:14:39.248]  Generated 32 batches of size 32 in 2.105 sec
[2020-05-11 17:14:40.954]  Step 141190  [3.141 sec/step, loss=0.10467, avg_loss=0.09805, mel_loss=0.04892, linear_loss=0.05575]
[2020-05-11 17:14:46.910]  Step 141191  [3.189 sec/step, loss=0.10425, avg_loss=0.09818, mel_loss=0.04970, linear_loss=0.05455]
[2020-05-11 17:14:50.640]  Step 141192  [3.203 sec/step, loss=0.10516, avg_loss=0.09821, mel_loss=0.04936, linear_loss=0.05580]
[2020-05-11 17:14:55.847]  Step 141193  [3.248 sec/step, loss=0.10470, avg_loss=0.09845, mel_loss=0.04938, linear_loss=0.05532]
[2020-05-11 17:14:57.098]  Step 141194  [3.251 sec/step, loss=0.09496, avg_loss=0.09852, mel_loss=0.04329, linear_loss=0.05167]
[2020-05-11 17:14:59.299]  Step 141195  [3.231 sec/step, loss=0.09908, avg_loss=0.09846, mel_loss=0.04584, linear_loss=0.05325]
[2020-05-11 17:15:00.268]  Step 141196  [3.200 sec/step, loss=0.08965, avg_loss=0.09831, mel_loss=0.04080, linear_loss=0.04885]
[2020-05-11 17:15:02.014]  Step 141197  [3.205 sec/step, loss=0.09529, avg_loss=0.09829, mel_loss=0.04402, linear_loss=0.05128]
[2020-05-11 17:15:02.538]  Step 141198  [3.187 sec/step, loss=0.08339, avg_loss=0.09811, mel_loss=0.03804, linear_loss=0.04535]
[2020-05-11 17:15:03.883]  Step 141199  [3.173 sec/step, loss=0.09597, avg_loss=0.09806, mel_loss=0.04361, linear_loss=0.05236]
[2020-05-11 17:15:06.131]  Step 141200  [3.171 sec/step, loss=0.10058, avg_loss=0.09806, mel_loss=0.04672, linear_loss=0.05386]
[2020-05-11 17:15:06.131]  Writing summary at step: 141200
[2020-05-11 17:15:10.814]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141200
[2020-05-11 17:15:12.040]  Saving audio and alignment...
[2020-05-11 17:15:16.542]  Input: 프로답 전문적이다라는 인상을 주는 것입니다~____________
[2020-05-11 17:15:18.704]  Step 141201  [3.179 sec/step, loss=0.09789, avg_loss=0.09807, mel_loss=0.04494, linear_loss=0.05294]
[2020-05-11 17:15:27.377]  Step 141202  [3.245 sec/step, loss=0.10462, avg_loss=0.09813, mel_loss=0.05037, linear_loss=0.05425]
[2020-05-11 17:15:28.250]  Step 141203  [3.202 sec/step, loss=0.08141, avg_loss=0.09786, mel_loss=0.03647, linear_loss=0.04494]
[2020-05-11 17:15:29.893]  Step 141204  [3.162 sec/step, loss=0.09982, avg_loss=0.09780, mel_loss=0.04557, linear_loss=0.05425]
[2020-05-11 17:15:32.878]  Step 141205  [3.115 sec/step, loss=0.10180, avg_loss=0.09777, mel_loss=0.04706, linear_loss=0.05474]
[2020-05-11 17:15:36.552]  Step 141206  [3.061 sec/step, loss=0.10465, avg_loss=0.09774, mel_loss=0.04881, linear_loss=0.05584]
[2020-05-11 17:15:37.677]  Step 141207  [3.051 sec/step, loss=0.09320, avg_loss=0.09767, mel_loss=0.04214, linear_loss=0.05105]
[2020-05-11 17:15:38.595]  Step 141208  [3.052 sec/step, loss=0.09054, avg_loss=0.09771, mel_loss=0.04083, linear_loss=0.04971]
[2020-05-11 17:15:39.867]  Step 141209  [3.050 sec/step, loss=0.09134, avg_loss=0.09768, mel_loss=0.04181, linear_loss=0.04953]
[2020-05-11 17:15:46.635]  Step 141210  [3.107 sec/step, loss=0.10683, avg_loss=0.09788, mel_loss=0.05108, linear_loss=0.05576]
[2020-05-11 17:15:48.025]  Step 141211  [3.067 sec/step, loss=0.09684, avg_loss=0.09780, mel_loss=0.04461, linear_loss=0.05223]
[2020-05-11 17:15:48.834]  Step 141212  [3.041 sec/step, loss=0.08726, avg_loss=0.09766, mel_loss=0.03951, linear_loss=0.04776]
[2020-05-11 17:15:50.330]  Step 141213  [3.036 sec/step, loss=0.09537, avg_loss=0.09764, mel_loss=0.04332, linear_loss=0.05205]
[2020-05-11 17:15:54.136]  Step 141214  [3.067 sec/step, loss=0.10223, avg_loss=0.09785, mel_loss=0.04772, linear_loss=0.05451]
[2020-05-11 17:15:59.407]  Step 141215  [3.095 sec/step, loss=0.10385, avg_loss=0.09790, mel_loss=0.04922, linear_loss=0.05463]
[2020-05-11 17:16:07.084]  Step 141216  [3.160 sec/step, loss=0.10654, avg_loss=0.09806, mel_loss=0.05144, linear_loss=0.05510]
[2020-05-11 17:16:08.965]  Step 141217  [3.162 sec/step, loss=0.09828, avg_loss=0.09806, mel_loss=0.04496, linear_loss=0.05333]
[2020-05-11 17:16:10.733]  Step 141218  [3.156 sec/step, loss=0.09793, avg_loss=0.09803, mel_loss=0.04445, linear_loss=0.05348]
[2020-05-11 17:16:16.425]  Step 141219  [3.165 sec/step, loss=0.10581, avg_loss=0.09805, mel_loss=0.05036, linear_loss=0.05545]
[2020-05-11 17:16:17.018]  Step 141220  [3.153 sec/step, loss=0.08179, avg_loss=0.09788, mel_loss=0.03783, linear_loss=0.04396]
[2020-05-11 17:16:18.421]  Generated 32 batches of size 32 in 1.990 sec
[2020-05-11 17:16:19.109]  Step 141221  [3.162 sec/step, loss=0.09886, avg_loss=0.09795, mel_loss=0.04522, linear_loss=0.05364]
[2020-05-11 17:16:22.323]  Step 141222  [3.165 sec/step, loss=0.10256, avg_loss=0.09792, mel_loss=0.04762, linear_loss=0.05495]
[2020-05-11 17:16:35.522]  Step 141223  [3.256 sec/step, loss=0.09165, avg_loss=0.09779, mel_loss=0.04477, linear_loss=0.04688]
[2020-05-11 17:16:38.045]  Step 141224  [3.216 sec/step, loss=0.09872, avg_loss=0.09769, mel_loss=0.04549, linear_loss=0.05323]
[2020-05-11 17:16:42.439]  Step 141225  [3.229 sec/step, loss=0.10491, avg_loss=0.09770, mel_loss=0.04954, linear_loss=0.05537]
[2020-05-11 17:16:43.508]  Step 141226  [3.213 sec/step, loss=0.08681, avg_loss=0.09756, mel_loss=0.03965, linear_loss=0.04716]
[2020-05-11 17:16:46.943]  Step 141227  [3.101 sec/step, loss=0.10207, avg_loss=0.09776, mel_loss=0.04705, linear_loss=0.05501]
[2020-05-11 17:16:49.650]  Step 141228  [3.114 sec/step, loss=0.10087, avg_loss=0.09781, mel_loss=0.04643, linear_loss=0.05444]
[2020-05-11 17:16:51.576]  Step 141229  [3.095 sec/step, loss=0.09930, avg_loss=0.09775, mel_loss=0.04520, linear_loss=0.05410]
[2020-05-11 17:16:52.759]  Step 141230  [3.048 sec/step, loss=0.09255, avg_loss=0.09761, mel_loss=0.04185, linear_loss=0.05069]
[2020-05-11 17:16:55.292]  Step 141231  [3.058 sec/step, loss=0.10079, avg_loss=0.09765, mel_loss=0.04647, linear_loss=0.05432]
[2020-05-11 17:16:57.948]  Step 141232  [3.079 sec/step, loss=0.10160, avg_loss=0.09786, mel_loss=0.04722, linear_loss=0.05439]
[2020-05-11 17:16:58.746]  Step 141233  [3.043 sec/step, loss=0.08643, avg_loss=0.09766, mel_loss=0.03882, linear_loss=0.04761]
[2020-05-11 17:16:59.753]  Step 141234  [3.019 sec/step, loss=0.08425, avg_loss=0.09748, mel_loss=0.03796, linear_loss=0.04629]
[2020-05-11 17:17:00.599]  Step 141235  [3.019 sec/step, loss=0.08335, avg_loss=0.09740, mel_loss=0.03795, linear_loss=0.04541]
[2020-05-11 17:17:09.476]  Step 141236  [3.089 sec/step, loss=0.10133, avg_loss=0.09743, mel_loss=0.04852, linear_loss=0.05281]
[2020-05-11 17:17:13.185]  Step 141237  [3.115 sec/step, loss=0.10465, avg_loss=0.09756, mel_loss=0.04896, linear_loss=0.05569]
[2020-05-11 17:17:15.021]  Step 141238  [3.105 sec/step, loss=0.09528, avg_loss=0.09748, mel_loss=0.04359, linear_loss=0.05169]
[2020-05-11 17:17:18.672]  Step 141239  [3.117 sec/step, loss=0.10186, avg_loss=0.09750, mel_loss=0.04767, linear_loss=0.05419]
[2020-05-11 17:17:21.792]  Step 141240  [3.007 sec/step, loss=0.10501, avg_loss=0.09773, mel_loss=0.04899, linear_loss=0.05602]
[2020-05-11 17:17:23.817]  Step 141241  [2.949 sec/step, loss=0.09793, avg_loss=0.09765, mel_loss=0.04501, linear_loss=0.05291]
[2020-05-11 17:17:25.970]  Step 141242  [2.960 sec/step, loss=0.10157, avg_loss=0.09773, mel_loss=0.04679, linear_loss=0.05478]
[2020-05-11 17:17:29.368]  Step 141243  [2.963 sec/step, loss=0.10419, avg_loss=0.09775, mel_loss=0.04838, linear_loss=0.05582]
[2020-05-11 17:17:32.304]  Step 141244  [2.974 sec/step, loss=0.10211, avg_loss=0.09780, mel_loss=0.04727, linear_loss=0.05484]
[2020-05-11 17:17:38.454]  Step 141245  [3.026 sec/step, loss=0.10230, avg_loss=0.09792, mel_loss=0.04882, linear_loss=0.05348]
[2020-05-11 17:17:43.748]  Step 141246  [3.074 sec/step, loss=0.10685, avg_loss=0.09821, mel_loss=0.05049, linear_loss=0.05636]
[2020-05-11 17:17:46.066]  Step 141247  [3.083 sec/step, loss=0.09985, avg_loss=0.09826, mel_loss=0.04574, linear_loss=0.05411]
[2020-05-11 17:18:00.388]  Step 141248  [3.217 sec/step, loss=0.07853, avg_loss=0.09814, mel_loss=0.03836, linear_loss=0.04017]
[2020-05-11 17:18:01.765]  Step 141249  [3.223 sec/step, loss=0.09314, avg_loss=0.09820, mel_loss=0.04223, linear_loss=0.05090]
[2020-05-11 17:18:08.916]  Step 141250  [3.273 sec/step, loss=0.10463, avg_loss=0.09824, mel_loss=0.04981, linear_loss=0.05481]
[2020-05-11 17:18:08.916]  Writing summary at step: 141250
[2020-05-11 17:18:09.914]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141250
[2020-05-11 17:18:11.181]  Saving audio and alignment...
[2020-05-11 17:18:13.236]  Generated 32 batches of size 32 in 1.534 sec
[2020-05-11 17:18:14.486]  Input: 습도가 조금만 높아도~_________________
[2020-05-11 17:18:15.674]  Step 141251  [3.249 sec/step, loss=0.09047, avg_loss=0.09810, mel_loss=0.04071, linear_loss=0.04977]
[2020-05-11 17:18:19.978]  Step 141252  [3.237 sec/step, loss=0.10562, avg_loss=0.09810, mel_loss=0.04948, linear_loss=0.05614]
[2020-05-11 17:18:24.203]  Step 141253  [3.218 sec/step, loss=0.10277, avg_loss=0.09808, mel_loss=0.04810, linear_loss=0.05467]
[2020-05-11 17:18:28.789]  Step 141254  [3.213 sec/step, loss=0.10537, avg_loss=0.09809, mel_loss=0.04956, linear_loss=0.05581]
[2020-05-11 17:18:30.217]  Step 141255  [3.200 sec/step, loss=0.09573, avg_loss=0.09802, mel_loss=0.04383, linear_loss=0.05190]
[2020-05-11 17:18:30.778]  Step 141256  [3.161 sec/step, loss=0.07371, avg_loss=0.09771, mel_loss=0.03395, linear_loss=0.03976]
[2020-05-11 17:18:35.755]  Step 141257  [3.195 sec/step, loss=0.10447, avg_loss=0.09777, mel_loss=0.04938, linear_loss=0.05509]
[2020-05-11 17:18:37.573]  Step 141258  [3.170 sec/step, loss=0.09539, avg_loss=0.09769, mel_loss=0.04356, linear_loss=0.05183]
[2020-05-11 17:18:38.421]  Step 141259  [3.142 sec/step, loss=0.08344, avg_loss=0.09748, mel_loss=0.03722, linear_loss=0.04622]
[2020-05-11 17:18:39.344]  Step 141260  [3.134 sec/step, loss=0.09020, avg_loss=0.09741, mel_loss=0.04078, linear_loss=0.04942]
[2020-05-11 17:18:42.764]  Step 141261  [3.154 sec/step, loss=0.10060, avg_loss=0.09749, mel_loss=0.04617, linear_loss=0.05444]
[2020-05-11 17:18:45.308]  Step 141262  [3.144 sec/step, loss=0.09481, avg_loss=0.09743, mel_loss=0.04329, linear_loss=0.05152]
[2020-05-11 17:18:50.090]  Step 141263  [3.184 sec/step, loss=0.10260, avg_loss=0.09757, mel_loss=0.04788, linear_loss=0.05471]
[2020-05-11 17:18:55.530]  Step 141264  [3.205 sec/step, loss=0.10015, avg_loss=0.09751, mel_loss=0.04653, linear_loss=0.05362]
[2020-05-11 17:18:57.747]  Step 141265  [3.204 sec/step, loss=0.09464, avg_loss=0.09746, mel_loss=0.04351, linear_loss=0.05114]
[2020-05-11 17:19:03.016]  Step 141266  [3.236 sec/step, loss=0.10470, avg_loss=0.09752, mel_loss=0.04918, linear_loss=0.05552]
[2020-05-11 17:19:05.213]  Step 141267  [3.242 sec/step, loss=0.09961, avg_loss=0.09753, mel_loss=0.04604, linear_loss=0.05358]
[2020-05-11 17:19:20.109]  Step 141268  [3.349 sec/step, loss=0.08389, avg_loss=0.09733, mel_loss=0.04113, linear_loss=0.04276]
[2020-05-11 17:19:22.472]  Step 141269  [3.338 sec/step, loss=0.10132, avg_loss=0.09732, mel_loss=0.04684, linear_loss=0.05447]
[2020-05-11 17:19:23.587]  Step 141270  [3.338 sec/step, loss=0.09095, avg_loss=0.09731, mel_loss=0.04084, linear_loss=0.05011]
[2020-05-11 17:19:25.340]  Step 141271  [3.349 sec/step, loss=0.09563, avg_loss=0.09743, mel_loss=0.04355, linear_loss=0.05208]
[2020-05-11 17:19:32.100]  Step 141272  [3.369 sec/step, loss=0.10509, avg_loss=0.09745, mel_loss=0.05035, linear_loss=0.05474]
[2020-05-11 17:19:35.430]  Step 141273  [3.381 sec/step, loss=0.10452, avg_loss=0.09751, mel_loss=0.04852, linear_loss=0.05600]
[2020-05-11 17:19:36.726]  Step 141274  [3.369 sec/step, loss=0.09499, avg_loss=0.09746, mel_loss=0.04325, linear_loss=0.05174]
[2020-05-11 17:19:37.486]  Step 141275  [3.350 sec/step, loss=0.08435, avg_loss=0.09731, mel_loss=0.03752, linear_loss=0.04683]
[2020-05-11 17:19:40.917]  Step 141276  [3.370 sec/step, loss=0.10381, avg_loss=0.09740, mel_loss=0.04832, linear_loss=0.05549]
[2020-05-11 17:19:42.500]  Step 141277  [3.303 sec/step, loss=0.09799, avg_loss=0.09736, mel_loss=0.04481, linear_loss=0.05317]
[2020-05-11 17:19:43.672]  Step 141278  [3.284 sec/step, loss=0.09330, avg_loss=0.09725, mel_loss=0.04233, linear_loss=0.05097]
[2020-05-11 17:19:52.599]  Step 141279  [3.353 sec/step, loss=0.10296, avg_loss=0.09730, mel_loss=0.04953, linear_loss=0.05343]
[2020-05-11 17:19:56.615]  Step 141280  [3.375 sec/step, loss=0.10383, avg_loss=0.09737, mel_loss=0.04849, linear_loss=0.05534]
[2020-05-11 17:19:58.509]  Step 141281  [3.362 sec/step, loss=0.09603, avg_loss=0.09729, mel_loss=0.04363, linear_loss=0.05240]
[2020-05-11 17:20:00.225]  Generated 32 batches of size 32 in 1.711 sec
[2020-05-11 17:20:01.382]  Step 141282  [3.320 sec/step, loss=0.10070, avg_loss=0.09724, mel_loss=0.04700, linear_loss=0.05370]
[2020-05-11 17:20:09.015]  Step 141283  [3.383 sec/step, loss=0.10526, avg_loss=0.09732, mel_loss=0.05037, linear_loss=0.05488]
[2020-05-11 17:20:11.140]  Step 141284  [3.396 sec/step, loss=0.09864, avg_loss=0.09743, mel_loss=0.04559, linear_loss=0.05305]
[2020-05-11 17:20:11.700]  Step 141285  [3.373 sec/step, loss=0.07839, avg_loss=0.09720, mel_loss=0.03629, linear_loss=0.04210]
[2020-05-11 17:20:17.439]  Step 141286  [3.386 sec/step, loss=0.10536, avg_loss=0.09719, mel_loss=0.04997, linear_loss=0.05539]
[2020-05-11 17:20:22.610]  Step 141287  [3.315 sec/step, loss=0.10369, avg_loss=0.09734, mel_loss=0.04915, linear_loss=0.05454]
[2020-05-11 17:20:24.600]  Step 141288  [3.324 sec/step, loss=0.09872, avg_loss=0.09742, mel_loss=0.04533, linear_loss=0.05339]
[2020-05-11 17:20:28.847]  Step 141289  [3.357 sec/step, loss=0.10467, avg_loss=0.09758, mel_loss=0.04909, linear_loss=0.05558]
[2020-05-11 17:20:29.891]  Step 141290  [3.329 sec/step, loss=0.08619, avg_loss=0.09740, mel_loss=0.03875, linear_loss=0.04744]
[2020-05-11 17:20:30.387]  Step 141291  [3.275 sec/step, loss=0.08543, avg_loss=0.09721, mel_loss=0.03904, linear_loss=0.04640]
[2020-05-11 17:20:31.912]  Step 141292  [3.253 sec/step, loss=0.09316, avg_loss=0.09709, mel_loss=0.04251, linear_loss=0.05065]
[2020-05-11 17:20:32.592]  Step 141293  [3.207 sec/step, loss=0.07839, avg_loss=0.09682, mel_loss=0.03569, linear_loss=0.04270]
[2020-05-11 17:20:34.627]  Step 141294  [3.215 sec/step, loss=0.09941, avg_loss=0.09687, mel_loss=0.04586, linear_loss=0.05354]
[2020-05-11 17:20:38.183]  Step 141295  [3.229 sec/step, loss=0.10685, avg_loss=0.09695, mel_loss=0.04992, linear_loss=0.05694]
[2020-05-11 17:20:42.152]  Step 141296  [3.259 sec/step, loss=0.10401, avg_loss=0.09709, mel_loss=0.04856, linear_loss=0.05545]
[2020-05-11 17:20:43.113]  Step 141297  [3.251 sec/step, loss=0.09250, avg_loss=0.09706, mel_loss=0.04152, linear_loss=0.05098]
[2020-05-11 17:20:44.509]  Step 141298  [3.260 sec/step, loss=0.09410, avg_loss=0.09717, mel_loss=0.04296, linear_loss=0.05114]
[2020-05-11 17:20:50.109]  Step 141299  [3.302 sec/step, loss=0.10565, avg_loss=0.09727, mel_loss=0.05016, linear_loss=0.05549]
[2020-05-11 17:20:53.106]  Step 141300  [3.310 sec/step, loss=0.10113, avg_loss=0.09727, mel_loss=0.04664, linear_loss=0.05449]
[2020-05-11 17:20:53.106]  Writing summary at step: 141300
[2020-05-11 17:20:54.847]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141300
[2020-05-11 17:20:56.073]  Saving audio and alignment...
[2020-05-11 17:20:58.974]  Input: 다음 줄에 선물 시작~__________________
[2020-05-11 17:21:04.279]  Step 141301  [3.341 sec/step, loss=0.10566, avg_loss=0.09735, mel_loss=0.04988, linear_loss=0.05577]
[2020-05-11 17:21:06.932]  Step 141302  [3.281 sec/step, loss=0.10107, avg_loss=0.09731, mel_loss=0.04654, linear_loss=0.05453]
[2020-05-11 17:21:15.405]  Step 141303  [3.357 sec/step, loss=0.10432, avg_loss=0.09754, mel_loss=0.05047, linear_loss=0.05385]
[2020-05-11 17:21:17.833]  Step 141304  [3.365 sec/step, loss=0.09841, avg_loss=0.09753, mel_loss=0.04531, linear_loss=0.05310]
[2020-05-11 17:21:29.783]  Step 141305  [3.454 sec/step, loss=0.09133, avg_loss=0.09742, mel_loss=0.04427, linear_loss=0.04706]
[2020-05-11 17:21:36.023]  Step 141306  [3.480 sec/step, loss=0.10545, avg_loss=0.09743, mel_loss=0.05024, linear_loss=0.05521]
[2020-05-11 17:21:37.243]  Step 141307  [3.481 sec/step, loss=0.09367, avg_loss=0.09744, mel_loss=0.04207, linear_loss=0.05161]
[2020-05-11 17:21:40.585]  Step 141308  [3.505 sec/step, loss=0.10308, avg_loss=0.09756, mel_loss=0.04824, linear_loss=0.05484]
[2020-05-11 17:21:41.891]  Step 141309  [3.506 sec/step, loss=0.09577, avg_loss=0.09761, mel_loss=0.04342, linear_loss=0.05236]
[2020-05-11 17:21:42.692]  Step 141310  [3.446 sec/step, loss=0.08403, avg_loss=0.09738, mel_loss=0.03813, linear_loss=0.04590]
[2020-05-11 17:21:43.667]  Step 141311  [3.442 sec/step, loss=0.09368, avg_loss=0.09735, mel_loss=0.04287, linear_loss=0.05081]
[2020-05-11 17:21:45.402]  Generated 32 batches of size 32 in 1.731 sec
[2020-05-11 17:21:45.917]  Step 141312  [3.456 sec/step, loss=0.09860, avg_loss=0.09746, mel_loss=0.04539, linear_loss=0.05321]
[2020-05-11 17:21:48.783]  Step 141313  [3.470 sec/step, loss=0.10056, avg_loss=0.09751, mel_loss=0.04670, linear_loss=0.05386]
[2020-05-11 17:21:52.420]  Step 141314  [3.468 sec/step, loss=0.10658, avg_loss=0.09756, mel_loss=0.04983, linear_loss=0.05674]
[2020-05-11 17:21:55.876]  Step 141315  [3.450 sec/step, loss=0.10184, avg_loss=0.09754, mel_loss=0.04774, linear_loss=0.05410]
[2020-05-11 17:22:00.020]  Step 141316  [3.415 sec/step, loss=0.10459, avg_loss=0.09752, mel_loss=0.04960, linear_loss=0.05499]
[2020-05-11 17:22:01.999]  Step 141317  [3.416 sec/step, loss=0.09511, avg_loss=0.09748, mel_loss=0.04363, linear_loss=0.05147]
[2020-05-11 17:22:06.872]  Step 141318  [3.447 sec/step, loss=0.10428, avg_loss=0.09755, mel_loss=0.04921, linear_loss=0.05507]
[2020-05-11 17:22:07.987]  Step 141319  [3.401 sec/step, loss=0.08990, avg_loss=0.09739, mel_loss=0.04066, linear_loss=0.04924]
[2020-05-11 17:22:15.532]  Step 141320  [3.471 sec/step, loss=0.10444, avg_loss=0.09762, mel_loss=0.05009, linear_loss=0.05435]
[2020-05-11 17:22:17.181]  Step 141321  [3.466 sec/step, loss=0.09731, avg_loss=0.09760, mel_loss=0.04456, linear_loss=0.05275]
[2020-05-11 17:22:20.142]  Step 141322  [3.464 sec/step, loss=0.10083, avg_loss=0.09758, mel_loss=0.04722, linear_loss=0.05361]
[2020-05-11 17:22:20.749]  Step 141323  [3.338 sec/step, loss=0.07951, avg_loss=0.09746, mel_loss=0.03707, linear_loss=0.04245]
[2020-05-11 17:22:24.116]  Step 141324  [3.346 sec/step, loss=0.10434, avg_loss=0.09752, mel_loss=0.04864, linear_loss=0.05570]
[2020-05-11 17:22:28.020]  Step 141325  [3.341 sec/step, loss=0.10371, avg_loss=0.09751, mel_loss=0.04818, linear_loss=0.05553]
[2020-05-11 17:22:29.568]  Step 141326  [3.346 sec/step, loss=0.09645, avg_loss=0.09760, mel_loss=0.04432, linear_loss=0.05214]
[2020-05-11 17:22:35.847]  Step 141327  [3.374 sec/step, loss=0.10320, avg_loss=0.09761, mel_loss=0.04914, linear_loss=0.05406]
[2020-05-11 17:22:40.376]  Step 141328  [3.393 sec/step, loss=0.10548, avg_loss=0.09766, mel_loss=0.04967, linear_loss=0.05581]
[2020-05-11 17:22:43.441]  Step 141329  [3.404 sec/step, loss=0.10398, avg_loss=0.09771, mel_loss=0.04824, linear_loss=0.05575]
[2020-05-11 17:22:44.564]  Step 141330  [3.403 sec/step, loss=0.09244, avg_loss=0.09770, mel_loss=0.04201, linear_loss=0.05043]
[2020-05-11 17:22:46.544]  Step 141331  [3.398 sec/step, loss=0.09793, avg_loss=0.09768, mel_loss=0.04495, linear_loss=0.05298]
[2020-05-11 17:22:50.798]  Step 141332  [3.414 sec/step, loss=0.10320, avg_loss=0.09769, mel_loss=0.04835, linear_loss=0.05485]
[2020-05-11 17:22:51.756]  Step 141333  [3.415 sec/step, loss=0.08917, avg_loss=0.09772, mel_loss=0.04037, linear_loss=0.04880]
[2020-05-11 17:22:59.781]  Step 141334  [3.486 sec/step, loss=0.10320, avg_loss=0.09791, mel_loss=0.04961, linear_loss=0.05360]
[2020-05-11 17:23:01.918]  Step 141335  [3.499 sec/step, loss=0.09828, avg_loss=0.09806, mel_loss=0.04533, linear_loss=0.05295]
[2020-05-11 17:23:05.354]  Step 141336  [3.444 sec/step, loss=0.10153, avg_loss=0.09806, mel_loss=0.04746, linear_loss=0.05406]
[2020-05-11 17:23:06.689]  Step 141337  [3.420 sec/step, loss=0.09492, avg_loss=0.09796, mel_loss=0.04335, linear_loss=0.05157]
[2020-05-11 17:23:07.524]  Step 141338  [3.410 sec/step, loss=0.08377, avg_loss=0.09785, mel_loss=0.03780, linear_loss=0.04597]
[2020-05-11 17:23:09.341]  Step 141339  [3.392 sec/step, loss=0.09765, avg_loss=0.09781, mel_loss=0.04450, linear_loss=0.05315]
[2020-05-11 17:23:22.290]  Step 141340  [3.490 sec/step, loss=0.08768, avg_loss=0.09763, mel_loss=0.04277, linear_loss=0.04490]
[2020-05-11 17:23:27.974]  Step 141341  [3.527 sec/step, loss=0.10445, avg_loss=0.09770, mel_loss=0.04942, linear_loss=0.05503]
[2020-05-11 17:23:28.726]  Step 141342  [3.513 sec/step, loss=0.08838, avg_loss=0.09757, mel_loss=0.03988, linear_loss=0.04850]
[2020-05-11 17:23:30.955]  Step 141343  [3.501 sec/step, loss=0.10038, avg_loss=0.09753, mel_loss=0.04647, linear_loss=0.05391]
[2020-05-11 17:23:32.705]  Generated 32 batches of size 32 in 1.745 sec
[2020-05-11 17:23:32.773]  Step 141344  [3.490 sec/step, loss=0.09735, avg_loss=0.09748, mel_loss=0.04453, linear_loss=0.05283]
[2020-05-11 17:23:35.356]  Step 141345  [3.454 sec/step, loss=0.09928, avg_loss=0.09745, mel_loss=0.04593, linear_loss=0.05335]
[2020-05-11 17:23:42.210]  Step 141346  [3.470 sec/step, loss=0.10557, avg_loss=0.09744, mel_loss=0.05054, linear_loss=0.05502]
[2020-05-11 17:23:43.509]  Step 141347  [3.460 sec/step, loss=0.09235, avg_loss=0.09736, mel_loss=0.04198, linear_loss=0.05037]
[2020-05-11 17:23:45.902]  Step 141348  [3.341 sec/step, loss=0.09836, avg_loss=0.09756, mel_loss=0.04518, linear_loss=0.05318]
[2020-05-11 17:23:46.853]  Step 141349  [3.336 sec/step, loss=0.08782, avg_loss=0.09751, mel_loss=0.03902, linear_loss=0.04880]
[2020-05-11 17:23:47.890]  Step 141350  [3.275 sec/step, loss=0.09313, avg_loss=0.09739, mel_loss=0.04184, linear_loss=0.05129]
[2020-05-11 17:23:47.890]  Writing summary at step: 141350
[2020-05-11 17:23:53.035]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141350
[2020-05-11 17:23:54.242]  Saving audio and alignment...
[2020-05-11 17:23:59.705]  Input: 누군가 내 말에 귀를 기울이게 만드려면 두 가지가 필요해요~______________
[2020-05-11 17:24:01.481]  Step 141351  [3.281 sec/step, loss=0.09671, avg_loss=0.09745, mel_loss=0.04435, linear_loss=0.05235]
[2020-05-11 17:24:02.375]  Step 141352  [3.247 sec/step, loss=0.08778, avg_loss=0.09728, mel_loss=0.03956, linear_loss=0.04823]
[2020-05-11 17:24:05.194]  Step 141353  [3.233 sec/step, loss=0.10456, avg_loss=0.09729, mel_loss=0.04847, linear_loss=0.05608]
[2020-05-11 17:24:12.652]  Step 141354  [3.262 sec/step, loss=0.10427, avg_loss=0.09728, mel_loss=0.05003, linear_loss=0.05424]
[2020-05-11 17:24:14.023]  Step 141355  [3.261 sec/step, loss=0.09434, avg_loss=0.09727, mel_loss=0.04309, linear_loss=0.05125]
[2020-05-11 17:24:15.630]  Step 141356  [3.271 sec/step, loss=0.09936, avg_loss=0.09753, mel_loss=0.04576, linear_loss=0.05360]
[2020-05-11 17:24:17.598]  Step 141357  [3.241 sec/step, loss=0.09907, avg_loss=0.09747, mel_loss=0.04498, linear_loss=0.05409]
[2020-05-11 17:24:22.163]  Step 141358  [3.269 sec/step, loss=0.10491, avg_loss=0.09757, mel_loss=0.04935, linear_loss=0.05556]
[2020-05-11 17:24:23.142]  Step 141359  [3.270 sec/step, loss=0.09135, avg_loss=0.09765, mel_loss=0.04164, linear_loss=0.04971]
[2020-05-11 17:24:27.396]  Step 141360  [3.303 sec/step, loss=0.10361, avg_loss=0.09778, mel_loss=0.04871, linear_loss=0.05490]
[2020-05-11 17:24:28.150]  Step 141361  [3.277 sec/step, loss=0.07986, avg_loss=0.09757, mel_loss=0.03690, linear_loss=0.04296]
[2020-05-11 17:24:30.617]  Step 141362  [3.276 sec/step, loss=0.09766, avg_loss=0.09760, mel_loss=0.04481, linear_loss=0.05284]
[2020-05-11 17:24:33.333]  Step 141363  [3.255 sec/step, loss=0.09984, avg_loss=0.09757, mel_loss=0.04620, linear_loss=0.05364]
[2020-05-11 17:24:37.332]  Step 141364  [3.241 sec/step, loss=0.10558, avg_loss=0.09763, mel_loss=0.04942, linear_loss=0.05616]
[2020-05-11 17:24:46.096]  Step 141365  [3.306 sec/step, loss=0.10803, avg_loss=0.09776, mel_loss=0.05218, linear_loss=0.05584]
[2020-05-11 17:24:49.321]  Step 141366  [3.286 sec/step, loss=0.10288, avg_loss=0.09774, mel_loss=0.04761, linear_loss=0.05526]
[2020-05-11 17:24:52.931]  Step 141367  [3.300 sec/step, loss=0.10502, avg_loss=0.09780, mel_loss=0.04918, linear_loss=0.05584]
[2020-05-11 17:24:55.889]  Step 141368  [3.181 sec/step, loss=0.10203, avg_loss=0.09798, mel_loss=0.04719, linear_loss=0.05484]
[2020-05-11 17:24:56.681]  Step 141369  [3.165 sec/step, loss=0.08475, avg_loss=0.09781, mel_loss=0.03840, linear_loss=0.04635]
[2020-05-11 17:24:58.604]  Step 141370  [3.173 sec/step, loss=0.10035, avg_loss=0.09791, mel_loss=0.04638, linear_loss=0.05397]
[2020-05-11 17:25:04.182]  Step 141371  [3.211 sec/step, loss=0.10405, avg_loss=0.09799, mel_loss=0.04921, linear_loss=0.05484]
[2020-05-11 17:25:05.354]  Step 141372  [3.155 sec/step, loss=0.09421, avg_loss=0.09788, mel_loss=0.04272, linear_loss=0.05149]
[2020-05-11 17:25:05.987]  Step 141373  [3.129 sec/step, loss=0.08534, avg_loss=0.09769, mel_loss=0.03852, linear_loss=0.04682]
[2020-05-11 17:25:07.754]  Generated 32 batches of size 32 in 1.762 sec
[2020-05-11 17:25:08.207]  Step 141374  [3.138 sec/step, loss=0.10003, avg_loss=0.09774, mel_loss=0.04625, linear_loss=0.05378]
[2020-05-11 17:25:11.626]  Step 141375  [3.164 sec/step, loss=0.10187, avg_loss=0.09792, mel_loss=0.04773, linear_loss=0.05414]
[2020-05-11 17:25:25.605]  Step 141376  [3.270 sec/step, loss=0.08116, avg_loss=0.09769, mel_loss=0.03992, linear_loss=0.04124]
[2020-05-11 17:25:26.723]  Step 141377  [3.265 sec/step, loss=0.08998, avg_loss=0.09761, mel_loss=0.04034, linear_loss=0.04964]
[2020-05-11 17:25:28.179]  Step 141378  [3.268 sec/step, loss=0.09481, avg_loss=0.09763, mel_loss=0.04315, linear_loss=0.05165]
[2020-05-11 17:25:34.880]  Step 141379  [3.246 sec/step, loss=0.10513, avg_loss=0.09765, mel_loss=0.05023, linear_loss=0.05490]
[2020-05-11 17:25:36.509]  Step 141380  [3.222 sec/step, loss=0.09794, avg_loss=0.09759, mel_loss=0.04466, linear_loss=0.05329]
[2020-05-11 17:25:41.377]  Step 141381  [3.252 sec/step, loss=0.10569, avg_loss=0.09768, mel_loss=0.05001, linear_loss=0.05569]
[2020-05-11 17:25:43.752]  Step 141382  [3.247 sec/step, loss=0.09806, avg_loss=0.09766, mel_loss=0.04544, linear_loss=0.05262]
[2020-05-11 17:25:46.247]  Step 141383  [3.195 sec/step, loss=0.09814, avg_loss=0.09759, mel_loss=0.04495, linear_loss=0.05318]
[2020-05-11 17:25:47.261]  Step 141384  [3.184 sec/step, loss=0.09008, avg_loss=0.09750, mel_loss=0.04036, linear_loss=0.04972]
[2020-05-11 17:25:48.475]  Step 141385  [3.191 sec/step, loss=0.08867, avg_loss=0.09760, mel_loss=0.04024, linear_loss=0.04843]
[2020-05-11 17:25:56.796]  Step 141386  [3.217 sec/step, loss=0.10236, avg_loss=0.09757, mel_loss=0.04925, linear_loss=0.05312]
[2020-05-11 17:25:59.353]  Step 141387  [3.190 sec/step, loss=0.10146, avg_loss=0.09755, mel_loss=0.04693, linear_loss=0.05454]
[2020-05-11 17:25:59.910]  Step 141388  [3.176 sec/step, loss=0.07889, avg_loss=0.09735, mel_loss=0.03651, linear_loss=0.04238]
[2020-05-11 17:26:00.704]  Step 141389  [3.142 sec/step, loss=0.08161, avg_loss=0.09712, mel_loss=0.03692, linear_loss=0.04469]
[2020-05-11 17:26:01.604]  Step 141390  [3.140 sec/step, loss=0.09102, avg_loss=0.09717, mel_loss=0.04098, linear_loss=0.05004]
[2020-05-11 17:26:06.253]  Step 141391  [3.182 sec/step, loss=0.10519, avg_loss=0.09737, mel_loss=0.04934, linear_loss=0.05585]
[2020-05-11 17:26:08.422]  Step 141392  [3.188 sec/step, loss=0.09977, avg_loss=0.09744, mel_loss=0.04606, linear_loss=0.05371]
[2020-05-11 17:26:09.522]  Step 141393  [3.192 sec/step, loss=0.09158, avg_loss=0.09757, mel_loss=0.04132, linear_loss=0.05025]
[2020-05-11 17:26:13.710]  Step 141394  [3.214 sec/step, loss=0.10403, avg_loss=0.09761, mel_loss=0.04883, linear_loss=0.05520]
[2020-05-11 17:26:15.607]  Step 141395  [3.197 sec/step, loss=0.09901, avg_loss=0.09753, mel_loss=0.04493, linear_loss=0.05408]
[2020-05-11 17:26:18.712]  Step 141396  [3.189 sec/step, loss=0.10330, avg_loss=0.09753, mel_loss=0.04845, linear_loss=0.05484]
[2020-05-11 17:26:25.978]  Step 141397  [3.252 sec/step, loss=0.10728, avg_loss=0.09768, mel_loss=0.05154, linear_loss=0.05574]
[2020-05-11 17:26:32.532]  Step 141398  [3.303 sec/step, loss=0.10491, avg_loss=0.09778, mel_loss=0.05009, linear_loss=0.05482]
[2020-05-11 17:26:35.387]  Step 141399  [3.276 sec/step, loss=0.10132, avg_loss=0.09774, mel_loss=0.04695, linear_loss=0.05437]
[2020-05-11 17:26:37.411]  Step 141400  [3.266 sec/step, loss=0.09772, avg_loss=0.09771, mel_loss=0.04482, linear_loss=0.05290]
[2020-05-11 17:26:37.411]  Writing summary at step: 141400
[2020-05-11 17:26:40.816]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141400
[2020-05-11 17:26:42.051]  Saving audio and alignment...
[2020-05-11 17:26:47.364]  Input: 거의 대부분에 초보 방송인들이 갖고 있는 문제점인데요~__________
[2020-05-11 17:26:52.553]  Step 141401  [3.265 sec/step, loss=0.10416, avg_loss=0.09769, mel_loss=0.04931, linear_loss=0.05485]
[2020-05-11 17:27:06.839]  Step 141402  [3.381 sec/step, loss=0.08082, avg_loss=0.09749, mel_loss=0.03971, linear_loss=0.04111]
[2020-05-11 17:27:10.522]  Step 141403  [3.333 sec/step, loss=0.10372, avg_loss=0.09748, mel_loss=0.04834, linear_loss=0.05538]
[2020-05-11 17:27:12.518]  Step 141404  [3.329 sec/step, loss=0.09780, avg_loss=0.09748, mel_loss=0.04457, linear_loss=0.05323]
[2020-05-11 17:27:12.956]  Generated 32 batches of size 32 in 2.428 sec
[2020-05-11 17:27:14.018]  Step 141405  [3.224 sec/step, loss=0.09450, avg_loss=0.09751, mel_loss=0.04343, linear_loss=0.05106]
[2020-05-11 17:27:15.369]  Step 141406  [3.176 sec/step, loss=0.09484, avg_loss=0.09740, mel_loss=0.04341, linear_loss=0.05143]
[2020-05-11 17:27:17.781]  Step 141407  [3.187 sec/step, loss=0.10024, avg_loss=0.09747, mel_loss=0.04638, linear_loss=0.05385]
[2020-05-11 17:27:21.938]  Step 141408  [3.196 sec/step, loss=0.10303, avg_loss=0.09747, mel_loss=0.04826, linear_loss=0.05477]
[2020-05-11 17:27:22.786]  Step 141409  [3.191 sec/step, loss=0.08284, avg_loss=0.09734, mel_loss=0.03713, linear_loss=0.04571]
[2020-05-11 17:27:28.407]  Step 141410  [3.239 sec/step, loss=0.10417, avg_loss=0.09754, mel_loss=0.04921, linear_loss=0.05496]
[2020-05-11 17:27:30.221]  Step 141411  [3.248 sec/step, loss=0.09729, avg_loss=0.09758, mel_loss=0.04428, linear_loss=0.05301]
[2020-05-11 17:27:31.883]  Step 141412  [3.242 sec/step, loss=0.09530, avg_loss=0.09754, mel_loss=0.04350, linear_loss=0.05180]
[2020-05-11 17:27:33.545]  Step 141413  [3.230 sec/step, loss=0.09914, avg_loss=0.09753, mel_loss=0.04544, linear_loss=0.05371]
[2020-05-11 17:27:36.847]  Step 141414  [3.226 sec/step, loss=0.10332, avg_loss=0.09750, mel_loss=0.04811, linear_loss=0.05521]
[2020-05-11 17:27:38.369]  Step 141415  [3.207 sec/step, loss=0.09619, avg_loss=0.09744, mel_loss=0.04409, linear_loss=0.05211]
[2020-05-11 17:27:45.686]  Step 141416  [3.239 sec/step, loss=0.10580, avg_loss=0.09745, mel_loss=0.05087, linear_loss=0.05493]
[2020-05-11 17:27:50.269]  Step 141417  [3.265 sec/step, loss=0.10477, avg_loss=0.09755, mel_loss=0.04901, linear_loss=0.05576]
[2020-05-11 17:27:52.817]  Step 141418  [3.242 sec/step, loss=0.09906, avg_loss=0.09750, mel_loss=0.04555, linear_loss=0.05352]
[2020-05-11 17:27:56.641]  Step 141419  [3.269 sec/step, loss=0.10359, avg_loss=0.09763, mel_loss=0.04814, linear_loss=0.05545]
[2020-05-11 17:27:57.488]  Step 141420  [3.202 sec/step, loss=0.08274, avg_loss=0.09742, mel_loss=0.03786, linear_loss=0.04488]
[2020-05-11 17:28:00.090]  Step 141421  [3.211 sec/step, loss=0.10146, avg_loss=0.09746, mel_loss=0.04738, linear_loss=0.05408]
[2020-05-11 17:28:01.389]  Step 141422  [3.195 sec/step, loss=0.09203, avg_loss=0.09737, mel_loss=0.04178, linear_loss=0.05025]
[2020-05-11 17:28:04.737]  Step 141423  [3.222 sec/step, loss=0.10071, avg_loss=0.09758, mel_loss=0.04680, linear_loss=0.05391]
[2020-05-11 17:28:05.738]  Step 141424  [3.198 sec/step, loss=0.09178, avg_loss=0.09746, mel_loss=0.04103, linear_loss=0.05075]
[2020-05-11 17:28:06.489]  Step 141425  [3.167 sec/step, loss=0.08197, avg_loss=0.09724, mel_loss=0.03715, linear_loss=0.04482]
[2020-05-11 17:28:09.395]  Step 141426  [3.180 sec/step, loss=0.10472, avg_loss=0.09732, mel_loss=0.04856, linear_loss=0.05616]
[2020-05-11 17:28:11.760]  Step 141427  [3.141 sec/step, loss=0.09831, avg_loss=0.09727, mel_loss=0.04535, linear_loss=0.05297]
[2020-05-11 17:28:13.703]  Step 141428  [3.115 sec/step, loss=0.09708, avg_loss=0.09719, mel_loss=0.04413, linear_loss=0.05295]
[2020-05-11 17:28:18.915]  Step 141429  [3.137 sec/step, loss=0.10525, avg_loss=0.09720, mel_loss=0.05003, linear_loss=0.05522]
[2020-05-11 17:28:21.088]  Step 141430  [3.147 sec/step, loss=0.09890, avg_loss=0.09727, mel_loss=0.04551, linear_loss=0.05339]
[2020-05-11 17:28:26.643]  Step 141431  [3.183 sec/step, loss=0.10434, avg_loss=0.09733, mel_loss=0.04899, linear_loss=0.05534]
[2020-05-11 17:28:27.729]  Step 141432  [3.151 sec/step, loss=0.09088, avg_loss=0.09721, mel_loss=0.04102, linear_loss=0.04986]
[2020-05-11 17:28:29.793]  Step 141433  [3.162 sec/step, loss=0.09986, avg_loss=0.09731, mel_loss=0.04571, linear_loss=0.05414]
[2020-05-11 17:28:31.657]  Step 141434  [3.101 sec/step, loss=0.09702, avg_loss=0.09725, mel_loss=0.04398, linear_loss=0.05303]
[2020-05-11 17:28:32.878]  Step 141435  [3.092 sec/step, loss=0.09403, avg_loss=0.09721, mel_loss=0.04267, linear_loss=0.05136]
[2020-05-11 17:28:34.637]  Step 141436  [3.075 sec/step, loss=0.09438, avg_loss=0.09714, mel_loss=0.04306, linear_loss=0.05132]
[2020-05-11 17:28:34.907]  Generated 32 batches of size 32 in 2.024 sec
[2020-05-11 17:28:35.758]  Step 141437  [3.073 sec/step, loss=0.09488, avg_loss=0.09714, mel_loss=0.04255, linear_loss=0.05233]
[2020-05-11 17:28:36.526]  Step 141438  [3.072 sec/step, loss=0.07756, avg_loss=0.09707, mel_loss=0.03554, linear_loss=0.04202]
[2020-05-11 17:28:40.822]  Step 141439  [3.097 sec/step, loss=0.10530, avg_loss=0.09715, mel_loss=0.04961, linear_loss=0.05569]
[2020-05-11 17:28:47.072]  Step 141440  [3.030 sec/step, loss=0.10495, avg_loss=0.09732, mel_loss=0.05017, linear_loss=0.05478]
[2020-05-11 17:29:00.373]  Step 141441  [3.106 sec/step, loss=0.08733, avg_loss=0.09715, mel_loss=0.04188, linear_loss=0.04545]
[2020-05-11 17:29:14.446]  Step 141442  [3.239 sec/step, loss=0.10305, avg_loss=0.09730, mel_loss=0.04959, linear_loss=0.05346]
[2020-05-11 17:29:18.842]  Step 141443  [3.261 sec/step, loss=0.10221, avg_loss=0.09732, mel_loss=0.04755, linear_loss=0.05467]
[2020-05-11 17:29:22.672]  Step 141444  [3.281 sec/step, loss=0.10555, avg_loss=0.09740, mel_loss=0.04929, linear_loss=0.05627]
[2020-05-11 17:29:23.836]  Step 141445  [3.267 sec/step, loss=0.09049, avg_loss=0.09731, mel_loss=0.04083, linear_loss=0.04966]
[2020-05-11 17:29:24.883]  Step 141446  [3.209 sec/step, loss=0.09206, avg_loss=0.09718, mel_loss=0.04120, linear_loss=0.05086]
[2020-05-11 17:29:26.845]  Step 141447  [3.215 sec/step, loss=0.09702, avg_loss=0.09722, mel_loss=0.04449, linear_loss=0.05253]
[2020-05-11 17:29:33.675]  Step 141448  [3.260 sec/step, loss=0.10367, avg_loss=0.09728, mel_loss=0.04917, linear_loss=0.05450]
[2020-05-11 17:29:36.707]  Step 141449  [3.281 sec/step, loss=0.10169, avg_loss=0.09741, mel_loss=0.04704, linear_loss=0.05465]
[2020-05-11 17:29:40.300]  Step 141450  [3.306 sec/step, loss=0.10466, avg_loss=0.09753, mel_loss=0.04882, linear_loss=0.05584]
[2020-05-11 17:29:40.300]  Writing summary at step: 141450
[2020-05-11 17:29:47.939]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141450
[2020-05-11 17:29:49.204]  Saving audio and alignment...
[2020-05-11 17:29:50.931]  Input: 하게 만들어~_______
[2020-05-11 17:29:52.231]  Step 141451  [3.301 sec/step, loss=0.09639, avg_loss=0.09753, mel_loss=0.04397, linear_loss=0.05243]
[2020-05-11 17:29:54.034]  Step 141452  [3.311 sec/step, loss=0.09800, avg_loss=0.09763, mel_loss=0.04499, linear_loss=0.05301]
[2020-05-11 17:29:59.317]  Step 141453  [3.335 sec/step, loss=0.10363, avg_loss=0.09762, mel_loss=0.04899, linear_loss=0.05463]
[2020-05-11 17:30:01.721]  Step 141454  [3.285 sec/step, loss=0.09986, avg_loss=0.09758, mel_loss=0.04588, linear_loss=0.05399]
[2020-05-11 17:30:03.469]  Step 141455  [3.288 sec/step, loss=0.09574, avg_loss=0.09759, mel_loss=0.04354, linear_loss=0.05219]
[2020-05-11 17:30:06.272]  Step 141456  [3.300 sec/step, loss=0.10047, avg_loss=0.09760, mel_loss=0.04656, linear_loss=0.05392]
[2020-05-11 17:30:09.630]  Step 141457  [3.314 sec/step, loss=0.10261, avg_loss=0.09764, mel_loss=0.04780, linear_loss=0.05481]
[2020-05-11 17:30:11.250]  Step 141458  [3.285 sec/step, loss=0.09795, avg_loss=0.09757, mel_loss=0.04465, linear_loss=0.05330]
[2020-05-11 17:30:12.683]  Step 141459  [3.289 sec/step, loss=0.09671, avg_loss=0.09762, mel_loss=0.04410, linear_loss=0.05260]
[2020-05-11 17:30:15.355]  Step 141460  [3.274 sec/step, loss=0.09922, avg_loss=0.09758, mel_loss=0.04596, linear_loss=0.05326]
[2020-05-11 17:30:19.334]  Step 141461  [3.306 sec/step, loss=0.10436, avg_loss=0.09782, mel_loss=0.04895, linear_loss=0.05542]
[2020-05-11 17:30:20.665]  Step 141462  [3.294 sec/step, loss=0.09453, avg_loss=0.09779, mel_loss=0.04309, linear_loss=0.05144]
[2020-05-11 17:30:21.418]  Step 141463  [3.275 sec/step, loss=0.08244, avg_loss=0.09762, mel_loss=0.03766, linear_loss=0.04478]
[2020-05-11 17:30:26.959]  Step 141464  [3.290 sec/step, loss=0.10422, avg_loss=0.09760, mel_loss=0.04937, linear_loss=0.05485]
[2020-05-11 17:30:27.534]  Step 141465  [3.208 sec/step, loss=0.07778, avg_loss=0.09730, mel_loss=0.03587, linear_loss=0.04191]
[2020-05-11 17:30:28.326]  Step 141466  [3.184 sec/step, loss=0.08645, avg_loss=0.09714, mel_loss=0.03859, linear_loss=0.04787]
[2020-05-11 17:30:29.218]  Generated 32 batches of size 32 in 1.679 sec
[2020-05-11 17:30:30.559]  Step 141467  [3.170 sec/step, loss=0.10102, avg_loss=0.09710, mel_loss=0.04647, linear_loss=0.05454]
[2020-05-11 17:30:34.635]  Step 141468  [3.181 sec/step, loss=0.10335, avg_loss=0.09711, mel_loss=0.04847, linear_loss=0.05487]
[2020-05-11 17:30:35.600]  Step 141469  [3.183 sec/step, loss=0.09020, avg_loss=0.09716, mel_loss=0.04108, linear_loss=0.04912]
[2020-05-11 17:30:38.989]  Step 141470  [3.198 sec/step, loss=0.10260, avg_loss=0.09719, mel_loss=0.04798, linear_loss=0.05463]
[2020-05-11 17:30:47.608]  Step 141471  [3.228 sec/step, loss=0.10413, avg_loss=0.09719, mel_loss=0.04995, linear_loss=0.05418]
[2020-05-11 17:30:52.129]  Step 141472  [3.262 sec/step, loss=0.10559, avg_loss=0.09730, mel_loss=0.04976, linear_loss=0.05582]
[2020-05-11 17:30:54.235]  Step 141473  [3.276 sec/step, loss=0.09713, avg_loss=0.09742, mel_loss=0.04446, linear_loss=0.05267]
[2020-05-11 17:31:08.346]  Step 141474  [3.395 sec/step, loss=0.08123, avg_loss=0.09723, mel_loss=0.03999, linear_loss=0.04124]
[2020-05-11 17:31:09.628]  Step 141475  [3.374 sec/step, loss=0.09194, avg_loss=0.09713, mel_loss=0.04160, linear_loss=0.05034]
[2020-05-11 17:31:11.000]  Step 141476  [3.248 sec/step, loss=0.09279, avg_loss=0.09725, mel_loss=0.04225, linear_loss=0.05054]
[2020-05-11 17:31:13.877]  Step 141477  [3.265 sec/step, loss=0.10050, avg_loss=0.09735, mel_loss=0.04643, linear_loss=0.05407]
[2020-05-11 17:31:19.129]  Step 141478  [3.303 sec/step, loss=0.10497, avg_loss=0.09745, mel_loss=0.04984, linear_loss=0.05512]
[2020-05-11 17:31:19.890]  Step 141479  [3.244 sec/step, loss=0.08703, avg_loss=0.09727, mel_loss=0.03895, linear_loss=0.04808]
[2020-05-11 17:31:20.855]  Step 141480  [3.237 sec/step, loss=0.08825, avg_loss=0.09718, mel_loss=0.03963, linear_loss=0.04862]
[2020-05-11 17:31:22.836]  Step 141481  [3.209 sec/step, loss=0.09865, avg_loss=0.09711, mel_loss=0.04525, linear_loss=0.05340]
[2020-05-11 17:31:24.406]  Step 141482  [3.200 sec/step, loss=0.09381, avg_loss=0.09706, mel_loss=0.04267, linear_loss=0.05114]
[2020-05-11 17:31:25.032]  Step 141483  [3.182 sec/step, loss=0.08351, avg_loss=0.09692, mel_loss=0.03796, linear_loss=0.04554]
[2020-05-11 17:31:26.070]  Step 141484  [3.182 sec/step, loss=0.08959, avg_loss=0.09691, mel_loss=0.04026, linear_loss=0.04933]
[2020-05-11 17:31:28.662]  Step 141485  [3.196 sec/step, loss=0.10133, avg_loss=0.09704, mel_loss=0.04667, linear_loss=0.05466]
[2020-05-11 17:31:31.834]  Step 141486  [3.144 sec/step, loss=0.10446, avg_loss=0.09706, mel_loss=0.04881, linear_loss=0.05565]
[2020-05-11 17:31:40.609]  Step 141487  [3.206 sec/step, loss=0.10436, avg_loss=0.09709, mel_loss=0.05076, linear_loss=0.05360]
[2020-05-11 17:31:44.319]  Step 141488  [3.238 sec/step, loss=0.10319, avg_loss=0.09733, mel_loss=0.04810, linear_loss=0.05509]
[2020-05-11 17:31:45.919]  Step 141489  [3.246 sec/step, loss=0.09696, avg_loss=0.09748, mel_loss=0.04429, linear_loss=0.05267]
[2020-05-11 17:31:53.327]  Step 141490  [3.311 sec/step, loss=0.10631, avg_loss=0.09764, mel_loss=0.05099, linear_loss=0.05532]
[2020-05-11 17:31:56.903]  Step 141491  [3.300 sec/step, loss=0.10390, avg_loss=0.09762, mel_loss=0.04849, linear_loss=0.05542]
[2020-05-11 17:31:58.788]  Step 141492  [3.298 sec/step, loss=0.09651, avg_loss=0.09759, mel_loss=0.04375, linear_loss=0.05276]
[2020-05-11 17:32:03.262]  Step 141493  [3.331 sec/step, loss=0.10414, avg_loss=0.09772, mel_loss=0.04938, linear_loss=0.05477]
[2020-05-11 17:32:09.872]  Step 141494  [3.356 sec/step, loss=0.10527, avg_loss=0.09773, mel_loss=0.05035, linear_loss=0.05492]
[2020-05-11 17:32:10.396]  Step 141495  [3.342 sec/step, loss=0.07655, avg_loss=0.09751, mel_loss=0.03542, linear_loss=0.04114]
[2020-05-11 17:32:14.648]  Step 141496  [3.353 sec/step, loss=0.10191, avg_loss=0.09749, mel_loss=0.04783, linear_loss=0.05408]
[2020-05-11 17:32:16.383]  Step 141497  [3.298 sec/step, loss=0.09798, avg_loss=0.09740, mel_loss=0.04470, linear_loss=0.05328]
[2020-05-11 17:32:17.573]  Step 141498  [3.244 sec/step, loss=0.09270, avg_loss=0.09728, mel_loss=0.04215, linear_loss=0.05055]
[2020-05-11 17:32:18.056]  Generated 32 batches of size 32 in 1.668 sec
[2020-05-11 17:32:20.570]  Step 141499  [3.246 sec/step, loss=0.10397, avg_loss=0.09730, mel_loss=0.04848, linear_loss=0.05549]
[2020-05-11 17:32:21.526]  Step 141500  [3.235 sec/step, loss=0.08800, avg_loss=0.09721, mel_loss=0.03938, linear_loss=0.04862]
[2020-05-11 17:32:21.526]  Writing summary at step: 141500
[2020-05-11 17:32:27.123]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141500
[2020-05-11 17:32:28.391]  Saving audio and alignment...
[2020-05-11 17:32:46.440]  Input: 제가 합격할 가능성이 단 영점 일퍼센트라 할지라도 그 꿈이 실현됐을때 제가 얻을 행복감은 천이고 만이고 백만입니다~_____________________________________________
[2020-05-11 17:32:48.774]  Step 141501  [3.207 sec/step, loss=0.09909, avg_loss=0.09716, mel_loss=0.04582, linear_loss=0.05327]
[2020-05-11 17:32:52.370]  Step 141502  [3.100 sec/step, loss=0.10168, avg_loss=0.09736, mel_loss=0.04754, linear_loss=0.05414]
[2020-05-11 17:32:54.454]  Step 141503  [3.084 sec/step, loss=0.09982, avg_loss=0.09733, mel_loss=0.04611, linear_loss=0.05370]
[2020-05-11 17:32:56.838]  Step 141504  [3.088 sec/step, loss=0.09816, avg_loss=0.09733, mel_loss=0.04505, linear_loss=0.05311]
[2020-05-11 17:32:59.241]  Step 141505  [3.097 sec/step, loss=0.09858, avg_loss=0.09737, mel_loss=0.04553, linear_loss=0.05306]
[2020-05-11 17:33:01.600]  Step 141506  [3.107 sec/step, loss=0.10321, avg_loss=0.09745, mel_loss=0.04715, linear_loss=0.05606]
[2020-05-11 17:33:02.434]  Step 141507  [3.091 sec/step, loss=0.08269, avg_loss=0.09728, mel_loss=0.03749, linear_loss=0.04520]
[2020-05-11 17:33:03.547]  Step 141508  [3.060 sec/step, loss=0.09075, avg_loss=0.09715, mel_loss=0.04067, linear_loss=0.05008]
[2020-05-11 17:33:05.565]  Step 141509  [3.072 sec/step, loss=0.09816, avg_loss=0.09731, mel_loss=0.04534, linear_loss=0.05281]
[2020-05-11 17:33:06.119]  Step 141510  [3.021 sec/step, loss=0.08016, avg_loss=0.09707, mel_loss=0.03721, linear_loss=0.04294]
[2020-05-11 17:33:13.721]  Step 141511  [3.079 sec/step, loss=0.10677, avg_loss=0.09716, mel_loss=0.05147, linear_loss=0.05530]
[2020-05-11 17:33:14.801]  Step 141512  [3.073 sec/step, loss=0.08791, avg_loss=0.09709, mel_loss=0.03989, linear_loss=0.04802]
[2020-05-11 17:33:18.082]  Step 141513  [3.090 sec/step, loss=0.10545, avg_loss=0.09715, mel_loss=0.04896, linear_loss=0.05649]
[2020-05-11 17:33:19.968]  Step 141514  [3.076 sec/step, loss=0.09871, avg_loss=0.09711, mel_loss=0.04534, linear_loss=0.05337]
[2020-05-11 17:33:21.255]  Step 141515  [3.073 sec/step, loss=0.09235, avg_loss=0.09707, mel_loss=0.04185, linear_loss=0.05050]
[2020-05-11 17:33:22.790]  Step 141516  [3.015 sec/step, loss=0.09736, avg_loss=0.09698, mel_loss=0.04440, linear_loss=0.05296]
[2020-05-11 17:33:26.860]  Step 141517  [3.010 sec/step, loss=0.10425, avg_loss=0.09698, mel_loss=0.04896, linear_loss=0.05529]
[2020-05-11 17:33:28.149]  Step 141518  [2.998 sec/step, loss=0.09775, avg_loss=0.09696, mel_loss=0.04423, linear_loss=0.05352]
[2020-05-11 17:33:36.673]  Step 141519  [3.045 sec/step, loss=0.10397, avg_loss=0.09697, mel_loss=0.05026, linear_loss=0.05371]
[2020-05-11 17:33:38.535]  Step 141520  [3.055 sec/step, loss=0.09709, avg_loss=0.09711, mel_loss=0.04430, linear_loss=0.05280]
[2020-05-11 17:33:42.371]  Step 141521  [3.067 sec/step, loss=0.10536, avg_loss=0.09715, mel_loss=0.04909, linear_loss=0.05626]
[2020-05-11 17:33:54.352]  Step 141522  [3.174 sec/step, loss=0.09329, avg_loss=0.09716, mel_loss=0.04566, linear_loss=0.04763]
[2020-05-11 17:33:55.816]  Step 141523  [3.155 sec/step, loss=0.09408, avg_loss=0.09710, mel_loss=0.04324, linear_loss=0.05084]
[2020-05-11 17:33:56.693]  Step 141524  [3.154 sec/step, loss=0.07928, avg_loss=0.09697, mel_loss=0.03562, linear_loss=0.04366]
[2020-05-11 17:34:03.049]  Step 141525  [3.210 sec/step, loss=0.10449, avg_loss=0.09720, mel_loss=0.04984, linear_loss=0.05465]
[2020-05-11 17:34:04.100]  Step 141526  [3.191 sec/step, loss=0.09176, avg_loss=0.09707, mel_loss=0.04139, linear_loss=0.05037]
[2020-05-11 17:34:06.833]  Step 141527  [3.195 sec/step, loss=0.09945, avg_loss=0.09708, mel_loss=0.04618, linear_loss=0.05327]
[2020-05-11 17:34:08.536]  Generated 32 batches of size 32 in 1.698 sec
[2020-05-11 17:34:11.510]  Step 141528  [3.222 sec/step, loss=0.10602, avg_loss=0.09717, mel_loss=0.04985, linear_loss=0.05616]
[2020-05-11 17:34:16.589]  Step 141529  [3.221 sec/step, loss=0.10421, avg_loss=0.09716, mel_loss=0.04908, linear_loss=0.05513]
[2020-05-11 17:34:18.273]  Step 141530  [3.216 sec/step, loss=0.09787, avg_loss=0.09715, mel_loss=0.04483, linear_loss=0.05304]
[2020-05-11 17:34:21.708]  Step 141531  [3.195 sec/step, loss=0.10502, avg_loss=0.09716, mel_loss=0.04895, linear_loss=0.05607]
[2020-05-11 17:34:24.576]  Step 141532  [3.213 sec/step, loss=0.10208, avg_loss=0.09727, mel_loss=0.04764, linear_loss=0.05445]
[2020-05-11 17:34:30.144]  Step 141533  [3.248 sec/step, loss=0.10483, avg_loss=0.09732, mel_loss=0.04958, linear_loss=0.05525]
[2020-05-11 17:34:33.441]  Step 141534  [3.262 sec/step, loss=0.10158, avg_loss=0.09736, mel_loss=0.04717, linear_loss=0.05441]
[2020-05-11 17:34:36.468]  Step 141535  [3.280 sec/step, loss=0.10435, avg_loss=0.09747, mel_loss=0.04855, linear_loss=0.05580]
[2020-05-11 17:34:38.673]  Step 141536  [3.285 sec/step, loss=0.09748, avg_loss=0.09750, mel_loss=0.04478, linear_loss=0.05270]
[2020-05-11 17:34:47.289]  Step 141537  [3.360 sec/step, loss=0.10316, avg_loss=0.09758, mel_loss=0.04981, linear_loss=0.05335]
[2020-05-11 17:34:49.821]  Step 141538  [3.377 sec/step, loss=0.09778, avg_loss=0.09778, mel_loss=0.04479, linear_loss=0.05300]
[2020-05-11 17:34:55.428]  Step 141539  [3.390 sec/step, loss=0.10427, avg_loss=0.09777, mel_loss=0.04940, linear_loss=0.05487]
[2020-05-11 17:34:57.034]  Step 141540  [3.344 sec/step, loss=0.09680, avg_loss=0.09769, mel_loss=0.04434, linear_loss=0.05246]
[2020-05-11 17:34:57.584]  Step 141541  [3.216 sec/step, loss=0.07912, avg_loss=0.09761, mel_loss=0.03655, linear_loss=0.04257]
[2020-05-11 17:35:05.039]  Step 141542  [3.150 sec/step, loss=0.10470, avg_loss=0.09762, mel_loss=0.05031, linear_loss=0.05439]
[2020-05-11 17:35:06.974]  Step 141543  [3.126 sec/step, loss=0.09854, avg_loss=0.09759, mel_loss=0.04507, linear_loss=0.05347]
[2020-05-11 17:35:08.149]  Step 141544  [3.099 sec/step, loss=0.09356, avg_loss=0.09747, mel_loss=0.04227, linear_loss=0.05130]
[2020-05-11 17:35:09.140]  Step 141545  [3.097 sec/step, loss=0.08976, avg_loss=0.09746, mel_loss=0.04058, linear_loss=0.04917]
[2020-05-11 17:35:12.094]  Step 141546  [3.116 sec/step, loss=0.10228, avg_loss=0.09756, mel_loss=0.04720, linear_loss=0.05508]
[2020-05-11 17:35:14.280]  Step 141547  [3.119 sec/step, loss=0.09645, avg_loss=0.09756, mel_loss=0.04455, linear_loss=0.05190]
[2020-05-11 17:35:15.275]  Step 141548  [3.060 sec/step, loss=0.08927, avg_loss=0.09741, mel_loss=0.04045, linear_loss=0.04882]
[2020-05-11 17:35:19.378]  Step 141549  [3.071 sec/step, loss=0.10238, avg_loss=0.09742, mel_loss=0.04803, linear_loss=0.05435]
[2020-05-11 17:35:22.033]  Step 141550  [3.062 sec/step, loss=0.10145, avg_loss=0.09739, mel_loss=0.04701, linear_loss=0.05444]
[2020-05-11 17:35:22.033]  Writing summary at step: 141550
[2020-05-11 17:35:26.421]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141550
[2020-05-11 17:35:27.634]  Saving audio and alignment...
[2020-05-11 17:35:36.513]  Input: 김무성 의원과 주호영 대표 권한대행 겸 원내대표등 바른정당 국회의원 아홉명이~____________________________________________
[2020-05-11 17:35:38.241]  Step 141551  [3.066 sec/step, loss=0.09816, avg_loss=0.09741, mel_loss=0.04456, linear_loss=0.05359]
[2020-05-11 17:35:50.625]  Step 141552  [3.172 sec/step, loss=0.08931, avg_loss=0.09732, mel_loss=0.04331, linear_loss=0.04599]
[2020-05-11 17:35:51.698]  Step 141553  [3.130 sec/step, loss=0.09217, avg_loss=0.09720, mel_loss=0.04143, linear_loss=0.05075]
[2020-05-11 17:35:52.500]  Step 141554  [3.114 sec/step, loss=0.08800, avg_loss=0.09709, mel_loss=0.03970, linear_loss=0.04830]
[2020-05-11 17:35:53.864]  Step 141555  [3.110 sec/step, loss=0.09420, avg_loss=0.09707, mel_loss=0.04254, linear_loss=0.05166]
[2020-05-11 17:35:55.321]  Step 141556  [3.096 sec/step, loss=0.09338, avg_loss=0.09700, mel_loss=0.04266, linear_loss=0.05071]
[2020-05-11 17:36:00.636]  Step 141557  [3.116 sec/step, loss=0.10395, avg_loss=0.09701, mel_loss=0.04903, linear_loss=0.05493]
[2020-05-11 17:36:02.403]  Generated 32 batches of size 32 in 1.763 sec
[2020-05-11 17:36:04.179]  Step 141558  [3.135 sec/step, loss=0.10127, avg_loss=0.09705, mel_loss=0.04700, linear_loss=0.05428]
[2020-05-11 17:36:07.620]  Step 141559  [3.155 sec/step, loss=0.10387, avg_loss=0.09712, mel_loss=0.04864, linear_loss=0.05523]
[2020-05-11 17:36:10.768]  Step 141560  [3.160 sec/step, loss=0.10491, avg_loss=0.09717, mel_loss=0.04901, linear_loss=0.05589]
[2020-05-11 17:36:11.555]  Step 141561  [3.128 sec/step, loss=0.08071, avg_loss=0.09694, mel_loss=0.03603, linear_loss=0.04467]
[2020-05-11 17:36:15.216]  Step 141562  [3.151 sec/step, loss=0.10448, avg_loss=0.09704, mel_loss=0.04862, linear_loss=0.05586]
[2020-05-11 17:36:17.011]  Step 141563  [3.162 sec/step, loss=0.09512, avg_loss=0.09716, mel_loss=0.04324, linear_loss=0.05189]
[2020-05-11 17:36:21.692]  Step 141564  [3.153 sec/step, loss=0.10450, avg_loss=0.09717, mel_loss=0.04888, linear_loss=0.05562]
[2020-05-11 17:36:24.021]  Step 141565  [3.171 sec/step, loss=0.10129, avg_loss=0.09740, mel_loss=0.04710, linear_loss=0.05419]
[2020-05-11 17:36:26.034]  Step 141566  [3.183 sec/step, loss=0.09818, avg_loss=0.09752, mel_loss=0.04491, linear_loss=0.05327]
[2020-05-11 17:36:26.853]  Step 141567  [3.169 sec/step, loss=0.08286, avg_loss=0.09734, mel_loss=0.03734, linear_loss=0.04553]
[2020-05-11 17:36:28.397]  Step 141568  [3.143 sec/step, loss=0.09577, avg_loss=0.09726, mel_loss=0.04371, linear_loss=0.05206]
[2020-05-11 17:36:33.023]  Step 141569  [3.180 sec/step, loss=0.10316, avg_loss=0.09739, mel_loss=0.04839, linear_loss=0.05477]
[2020-05-11 17:36:37.096]  Step 141570  [3.187 sec/step, loss=0.10412, avg_loss=0.09741, mel_loss=0.04861, linear_loss=0.05551]
[2020-05-11 17:36:38.400]  Step 141571  [3.114 sec/step, loss=0.08965, avg_loss=0.09726, mel_loss=0.04098, linear_loss=0.04867]
[2020-05-11 17:36:40.813]  Step 141572  [3.093 sec/step, loss=0.09816, avg_loss=0.09719, mel_loss=0.04515, linear_loss=0.05300]
[2020-05-11 17:36:43.534]  Step 141573  [3.099 sec/step, loss=0.09924, avg_loss=0.09721, mel_loss=0.04598, linear_loss=0.05326]
[2020-05-11 17:36:50.379]  Step 141574  [3.026 sec/step, loss=0.10456, avg_loss=0.09744, mel_loss=0.04973, linear_loss=0.05482]
[2020-05-11 17:36:52.561]  Step 141575  [3.035 sec/step, loss=0.09833, avg_loss=0.09751, mel_loss=0.04524, linear_loss=0.05309]
[2020-05-11 17:36:56.021]  Step 141576  [3.056 sec/step, loss=0.10210, avg_loss=0.09760, mel_loss=0.04771, linear_loss=0.05438]
[2020-05-11 17:36:56.551]  Step 141577  [3.033 sec/step, loss=0.07828, avg_loss=0.09738, mel_loss=0.03581, linear_loss=0.04247]
[2020-05-11 17:37:00.694]  Step 141578  [3.021 sec/step, loss=0.10354, avg_loss=0.09736, mel_loss=0.04842, linear_loss=0.05513]
[2020-05-11 17:37:08.455]  Step 141579  [3.091 sec/step, loss=0.10298, avg_loss=0.09752, mel_loss=0.04898, linear_loss=0.05401]
[2020-05-11 17:37:11.352]  Step 141580  [3.111 sec/step, loss=0.09967, avg_loss=0.09764, mel_loss=0.04611, linear_loss=0.05356]
[2020-05-11 17:37:20.391]  Step 141581  [3.181 sec/step, loss=0.10499, avg_loss=0.09770, mel_loss=0.05047, linear_loss=0.05452]
[2020-05-11 17:37:21.426]  Step 141582  [3.176 sec/step, loss=0.09176, avg_loss=0.09768, mel_loss=0.04131, linear_loss=0.05045]
[2020-05-11 17:37:24.710]  Step 141583  [3.203 sec/step, loss=0.10365, avg_loss=0.09788, mel_loss=0.04785, linear_loss=0.05580]
[2020-05-11 17:37:26.337]  Step 141584  [3.208 sec/step, loss=0.09527, avg_loss=0.09794, mel_loss=0.04345, linear_loss=0.05182]
[2020-05-11 17:37:27.192]  Step 141585  [3.191 sec/step, loss=0.08513, avg_loss=0.09778, mel_loss=0.03862, linear_loss=0.04651]
[2020-05-11 17:37:30.919]  Step 141586  [3.197 sec/step, loss=0.10439, avg_loss=0.09777, mel_loss=0.04895, linear_loss=0.05545]
[2020-05-11 17:37:31.767]  Step 141587  [3.117 sec/step, loss=0.08173, avg_loss=0.09755, mel_loss=0.03719, linear_loss=0.04454]
[2020-05-11 17:37:33.794]  Step 141588  [3.101 sec/step, loss=0.09740, avg_loss=0.09749, mel_loss=0.04407, linear_loss=0.05333]
[2020-05-11 17:37:35.606]  Step 141589  [3.103 sec/step, loss=0.09958, avg_loss=0.09752, mel_loss=0.04531, linear_loss=0.05427]
[2020-05-11 17:37:37.264]  Generated 32 batches of size 32 in 1.653 sec
[2020-05-11 17:37:40.980]  Step 141590  [3.082 sec/step, loss=0.10427, avg_loss=0.09750, mel_loss=0.04938, linear_loss=0.05490]
[2020-05-11 17:37:42.155]  Step 141591  [3.058 sec/step, loss=0.09137, avg_loss=0.09737, mel_loss=0.04180, linear_loss=0.04957]
[2020-05-11 17:37:56.763]  Step 141592  [3.186 sec/step, loss=0.08592, avg_loss=0.09727, mel_loss=0.04209, linear_loss=0.04383]
[2020-05-11 17:38:02.655]  Step 141593  [3.200 sec/step, loss=0.10329, avg_loss=0.09726, mel_loss=0.04882, linear_loss=0.05446]
[2020-05-11 17:38:04.423]  Step 141594  [3.151 sec/step, loss=0.09573, avg_loss=0.09716, mel_loss=0.04342, linear_loss=0.05231]
[2020-05-11 17:38:07.446]  Step 141595  [3.176 sec/step, loss=0.10187, avg_loss=0.09741, mel_loss=0.04670, linear_loss=0.05517]
[2020-05-11 17:38:09.546]  Step 141596  [3.155 sec/step, loss=0.09808, avg_loss=0.09738, mel_loss=0.04473, linear_loss=0.05335]
[2020-05-11 17:38:10.875]  Step 141597  [3.151 sec/step, loss=0.09613, avg_loss=0.09736, mel_loss=0.04381, linear_loss=0.05232]
[2020-05-11 17:38:11.803]  Step 141598  [3.148 sec/step, loss=0.08844, avg_loss=0.09731, mel_loss=0.03950, linear_loss=0.04894]
[2020-05-11 17:38:13.120]  Step 141599  [3.131 sec/step, loss=0.09611, avg_loss=0.09724, mel_loss=0.04348, linear_loss=0.05263]
[2020-05-11 17:38:13.677]  Step 141600  [3.127 sec/step, loss=0.07768, avg_loss=0.09713, mel_loss=0.03553, linear_loss=0.04215]
[2020-05-11 17:38:13.677]  Writing summary at step: 141600
[2020-05-11 17:38:15.704]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141600
[2020-05-11 17:38:16.931]  Saving audio and alignment...
[2020-05-11 17:38:19.916]  Input: 그 말 참 꽃 같네~______________________
[2020-05-11 17:38:24.004]  Step 141601  [3.145 sec/step, loss=0.10404, avg_loss=0.09718, mel_loss=0.04867, linear_loss=0.05537]
[2020-05-11 17:38:25.695]  Step 141602  [3.126 sec/step, loss=0.09585, avg_loss=0.09712, mel_loss=0.04399, linear_loss=0.05186]
[2020-05-11 17:38:31.817]  Step 141603  [3.166 sec/step, loss=0.10412, avg_loss=0.09717, mel_loss=0.04960, linear_loss=0.05452]
[2020-05-11 17:38:32.479]  Step 141604  [3.149 sec/step, loss=0.08084, avg_loss=0.09699, mel_loss=0.03668, linear_loss=0.04416]
[2020-05-11 17:38:36.790]  Step 141605  [3.168 sec/step, loss=0.10539, avg_loss=0.09706, mel_loss=0.04958, linear_loss=0.05581]
[2020-05-11 17:38:37.928]  Step 141606  [3.156 sec/step, loss=0.08861, avg_loss=0.09692, mel_loss=0.03950, linear_loss=0.04911]
[2020-05-11 17:38:42.638]  Step 141607  [3.195 sec/step, loss=0.10575, avg_loss=0.09715, mel_loss=0.04981, linear_loss=0.05595]
[2020-05-11 17:38:54.850]  Step 141608  [3.306 sec/step, loss=0.09108, avg_loss=0.09715, mel_loss=0.04439, linear_loss=0.04669]
[2020-05-11 17:38:56.315]  Step 141609  [3.300 sec/step, loss=0.09323, avg_loss=0.09710, mel_loss=0.04276, linear_loss=0.05047]
[2020-05-11 17:38:57.576]  Step 141610  [3.307 sec/step, loss=0.09227, avg_loss=0.09722, mel_loss=0.04173, linear_loss=0.05054]
[2020-05-11 17:39:00.184]  Step 141611  [3.257 sec/step, loss=0.10143, avg_loss=0.09717, mel_loss=0.04716, linear_loss=0.05427]
[2020-05-11 17:39:03.075]  Step 141612  [3.275 sec/step, loss=0.10381, avg_loss=0.09733, mel_loss=0.04820, linear_loss=0.05561]
[2020-05-11 17:39:05.032]  Step 141613  [3.262 sec/step, loss=0.09801, avg_loss=0.09725, mel_loss=0.04493, linear_loss=0.05308]
[2020-05-11 17:39:13.608]  Step 141614  [3.329 sec/step, loss=0.10298, avg_loss=0.09730, mel_loss=0.04945, linear_loss=0.05353]
[2020-05-11 17:39:22.957]  Step 141615  [3.410 sec/step, loss=0.10577, avg_loss=0.09743, mel_loss=0.05065, linear_loss=0.05512]
[2020-05-11 17:39:25.412]  Step 141616  [3.419 sec/step, loss=0.09461, avg_loss=0.09740, mel_loss=0.04289, linear_loss=0.05171]
[2020-05-11 17:39:33.528]  Step 141617  [3.459 sec/step, loss=0.10416, avg_loss=0.09740, mel_loss=0.04932, linear_loss=0.05484]
[2020-05-11 17:39:36.991]  Step 141618  [3.481 sec/step, loss=0.09623, avg_loss=0.09739, mel_loss=0.04386, linear_loss=0.05237]
[2020-05-11 17:39:40.850]  Step 141619  [3.434 sec/step, loss=0.10401, avg_loss=0.09739, mel_loss=0.04867, linear_loss=0.05534]
[2020-05-11 17:39:41.698]  Step 141620  [3.424 sec/step, loss=0.08587, avg_loss=0.09727, mel_loss=0.03860, linear_loss=0.04727]
[2020-05-11 17:39:42.580]  Generated 32 batches of size 32 in 1.726 sec
[2020-05-11 17:39:42.802]  Step 141621  [3.397 sec/step, loss=0.08545, avg_loss=0.09708, mel_loss=0.03849, linear_loss=0.04696]
[2020-05-11 17:39:45.959]  Step 141622  [3.309 sec/step, loss=0.10318, avg_loss=0.09717, mel_loss=0.04798, linear_loss=0.05520]
[2020-05-11 17:39:49.474]  Step 141623  [3.329 sec/step, loss=0.10061, avg_loss=0.09724, mel_loss=0.04693, linear_loss=0.05368]
[2020-05-11 17:39:52.948]  Step 141624  [3.355 sec/step, loss=0.10173, avg_loss=0.09746, mel_loss=0.04759, linear_loss=0.05414]
[2020-05-11 17:39:58.701]  Step 141625  [3.349 sec/step, loss=0.10399, avg_loss=0.09746, mel_loss=0.04916, linear_loss=0.05483]
[2020-05-11 17:40:00.841]  Step 141626  [3.360 sec/step, loss=0.10018, avg_loss=0.09754, mel_loss=0.04608, linear_loss=0.05410]
[2020-05-11 17:40:01.878]  Step 141627  [3.343 sec/step, loss=0.09088, avg_loss=0.09746, mel_loss=0.04119, linear_loss=0.04969]
[2020-05-11 17:40:04.259]  Step 141628  [3.320 sec/step, loss=0.09803, avg_loss=0.09738, mel_loss=0.04519, linear_loss=0.05284]
[2020-05-11 17:40:06.390]  Step 141629  [3.291 sec/step, loss=0.09946, avg_loss=0.09733, mel_loss=0.04570, linear_loss=0.05376]
[2020-05-11 17:40:14.163]  Step 141630  [3.351 sec/step, loss=0.10469, avg_loss=0.09740, mel_loss=0.05005, linear_loss=0.05463]
[2020-05-11 17:40:16.222]  Step 141631  [3.338 sec/step, loss=0.09728, avg_loss=0.09732, mel_loss=0.04464, linear_loss=0.05264]
[2020-05-11 17:40:19.616]  Step 141632  [3.343 sec/step, loss=0.10001, avg_loss=0.09730, mel_loss=0.04633, linear_loss=0.05369]
[2020-05-11 17:40:26.014]  Step 141633  [3.351 sec/step, loss=0.10282, avg_loss=0.09728, mel_loss=0.04886, linear_loss=0.05395]
[2020-05-11 17:40:29.664]  Step 141634  [3.355 sec/step, loss=0.10325, avg_loss=0.09730, mel_loss=0.04790, linear_loss=0.05535]
[2020-05-11 17:40:31.291]  Step 141635  [3.341 sec/step, loss=0.09637, avg_loss=0.09722, mel_loss=0.04380, linear_loss=0.05257]
[2020-05-11 17:40:36.536]  Step 141636  [3.371 sec/step, loss=0.10203, avg_loss=0.09726, mel_loss=0.04825, linear_loss=0.05377]
[2020-05-11 17:40:38.919]  Step 141637  [3.309 sec/step, loss=0.09817, avg_loss=0.09721, mel_loss=0.04535, linear_loss=0.05283]
[2020-05-11 17:40:40.355]  Step 141638  [3.298 sec/step, loss=0.09266, avg_loss=0.09716, mel_loss=0.04201, linear_loss=0.05065]
[2020-05-11 17:40:40.915]  Step 141639  [3.247 sec/step, loss=0.07607, avg_loss=0.09688, mel_loss=0.03463, linear_loss=0.04144]
[2020-05-11 17:40:55.253]  Step 141640  [3.375 sec/step, loss=0.07860, avg_loss=0.09670, mel_loss=0.03851, linear_loss=0.04009]
[2020-05-11 17:40:56.116]  Step 141641  [3.378 sec/step, loss=0.08154, avg_loss=0.09672, mel_loss=0.03694, linear_loss=0.04460]
[2020-05-11 17:40:57.349]  Step 141642  [3.316 sec/step, loss=0.09244, avg_loss=0.09660, mel_loss=0.04183, linear_loss=0.05060]
[2020-05-11 17:41:02.953]  Step 141643  [3.352 sec/step, loss=0.10345, avg_loss=0.09665, mel_loss=0.04883, linear_loss=0.05462]
[2020-05-11 17:41:05.969]  Step 141644  [3.371 sec/step, loss=0.10303, avg_loss=0.09674, mel_loss=0.04798, linear_loss=0.05505]
[2020-05-11 17:41:14.323]  Step 141645  [3.444 sec/step, loss=0.10357, avg_loss=0.09688, mel_loss=0.04971, linear_loss=0.05386]
[2020-05-11 17:41:15.377]  Step 141646  [3.425 sec/step, loss=0.08801, avg_loss=0.09674, mel_loss=0.03983, linear_loss=0.04818]
[2020-05-11 17:41:17.814]  Step 141647  [3.428 sec/step, loss=0.10092, avg_loss=0.09678, mel_loss=0.04646, linear_loss=0.05446]
[2020-05-11 17:41:21.850]  Step 141648  [3.458 sec/step, loss=0.10302, avg_loss=0.09692, mel_loss=0.04773, linear_loss=0.05529]
[2020-05-11 17:41:22.839]  Step 141649  [3.427 sec/step, loss=0.08978, avg_loss=0.09679, mel_loss=0.04022, linear_loss=0.04956]
[2020-05-11 17:41:24.610]  Step 141650  [3.418 sec/step, loss=0.09534, avg_loss=0.09673, mel_loss=0.04364, linear_loss=0.05170]
[2020-05-11 17:41:24.610]  Writing summary at step: 141650
[2020-05-11 17:41:29.367]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141650
[2020-05-11 17:41:30.620]  Saving audio and alignment...
[2020-05-11 17:41:32.614]  Generated 32 batches of size 32 in 1.498 sec
[2020-05-11 17:41:33.653]  Input: 자 키워드 앞에서는 여러분~___
[2020-05-11 17:41:37.985]  Step 141651  [3.444 sec/step, loss=0.10235, avg_loss=0.09678, mel_loss=0.04768, linear_loss=0.05467]
[2020-05-11 17:41:40.757]  Step 141652  [3.348 sec/step, loss=0.09938, avg_loss=0.09688, mel_loss=0.04595, linear_loss=0.05342]
[2020-05-11 17:41:41.615]  Step 141653  [3.346 sec/step, loss=0.08216, avg_loss=0.09678, mel_loss=0.03672, linear_loss=0.04544]
[2020-05-11 17:41:44.996]  Step 141654  [3.372 sec/step, loss=0.10405, avg_loss=0.09694, mel_loss=0.04835, linear_loss=0.05569]
[2020-05-11 17:41:46.151]  Step 141655  [3.370 sec/step, loss=0.08829, avg_loss=0.09688, mel_loss=0.03970, linear_loss=0.04858]
[2020-05-11 17:41:47.872]  Step 141656  [3.372 sec/step, loss=0.09577, avg_loss=0.09690, mel_loss=0.04386, linear_loss=0.05191]
[2020-05-11 17:41:49.818]  Step 141657  [3.339 sec/step, loss=0.09620, avg_loss=0.09682, mel_loss=0.04387, linear_loss=0.05233]
[2020-05-11 17:41:52.747]  Step 141658  [3.333 sec/step, loss=0.10260, avg_loss=0.09684, mel_loss=0.04758, linear_loss=0.05502]
[2020-05-11 17:41:58.082]  Step 141659  [3.352 sec/step, loss=0.10420, avg_loss=0.09684, mel_loss=0.04908, linear_loss=0.05511]
[2020-05-11 17:41:59.941]  Step 141660  [3.339 sec/step, loss=0.09644, avg_loss=0.09676, mel_loss=0.04374, linear_loss=0.05269]
[2020-05-11 17:42:02.555]  Step 141661  [3.357 sec/step, loss=0.09910, avg_loss=0.09694, mel_loss=0.04551, linear_loss=0.05359]
[2020-05-11 17:42:08.342]  Step 141662  [3.378 sec/step, loss=0.10351, avg_loss=0.09693, mel_loss=0.04882, linear_loss=0.05469]
[2020-05-11 17:42:11.851]  Step 141663  [3.395 sec/step, loss=0.10118, avg_loss=0.09699, mel_loss=0.04722, linear_loss=0.05397]
[2020-05-11 17:42:14.661]  Step 141664  [3.377 sec/step, loss=0.09904, avg_loss=0.09694, mel_loss=0.04594, linear_loss=0.05310]
[2020-05-11 17:42:16.111]  Step 141665  [3.368 sec/step, loss=0.09506, avg_loss=0.09687, mel_loss=0.04347, linear_loss=0.05159]
[2020-05-11 17:42:17.489]  Step 141666  [3.361 sec/step, loss=0.09366, avg_loss=0.09683, mel_loss=0.04259, linear_loss=0.05107]
[2020-05-11 17:42:18.247]  Step 141667  [3.361 sec/step, loss=0.08410, avg_loss=0.09684, mel_loss=0.03795, linear_loss=0.04615]
[2020-05-11 17:42:32.663]  Step 141668  [3.490 sec/step, loss=0.08296, avg_loss=0.09671, mel_loss=0.04042, linear_loss=0.04254]
[2020-05-11 17:42:33.535]  Step 141669  [3.452 sec/step, loss=0.08753, avg_loss=0.09656, mel_loss=0.03929, linear_loss=0.04824]
[2020-05-11 17:42:34.476]  Step 141670  [3.421 sec/step, loss=0.08954, avg_loss=0.09641, mel_loss=0.04037, linear_loss=0.04917]
[2020-05-11 17:42:38.491]  Step 141671  [3.448 sec/step, loss=0.10586, avg_loss=0.09657, mel_loss=0.04962, linear_loss=0.05623]
[2020-05-11 17:42:40.494]  Step 141672  [3.444 sec/step, loss=0.09923, avg_loss=0.09658, mel_loss=0.04536, linear_loss=0.05387]
[2020-05-11 17:42:49.539]  Step 141673  [3.507 sec/step, loss=0.10239, avg_loss=0.09661, mel_loss=0.04937, linear_loss=0.05302]
[2020-05-11 17:42:52.727]  Step 141674  [3.470 sec/step, loss=0.10158, avg_loss=0.09659, mel_loss=0.04713, linear_loss=0.05445]
[2020-05-11 17:42:55.165]  Step 141675  [3.473 sec/step, loss=0.09950, avg_loss=0.09660, mel_loss=0.04555, linear_loss=0.05394]
[2020-05-11 17:42:58.860]  Step 141676  [3.475 sec/step, loss=0.10317, avg_loss=0.09661, mel_loss=0.04785, linear_loss=0.05532]
[2020-05-11 17:42:59.920]  Step 141677  [3.481 sec/step, loss=0.09125, avg_loss=0.09674, mel_loss=0.04133, linear_loss=0.04992]
[2020-05-11 17:43:01.699]  Step 141678  [3.457 sec/step, loss=0.09610, avg_loss=0.09666, mel_loss=0.04319, linear_loss=0.05290]
[2020-05-11 17:43:03.863]  Step 141679  [3.401 sec/step, loss=0.09756, avg_loss=0.09661, mel_loss=0.04462, linear_loss=0.05294]
[2020-05-11 17:43:04.715]  Step 141680  [3.381 sec/step, loss=0.08569, avg_loss=0.09647, mel_loss=0.03844, linear_loss=0.04725]
[2020-05-11 17:43:07.061]  Step 141681  [3.314 sec/step, loss=0.09848, avg_loss=0.09640, mel_loss=0.04541, linear_loss=0.05307]
[2020-05-11 17:43:08.750]  Generated 32 batches of size 32 in 1.684 sec
[2020-05-11 17:43:12.065]  Step 141682  [3.353 sec/step, loss=0.10550, avg_loss=0.09654, mel_loss=0.04945, linear_loss=0.05605]
[2020-05-11 17:43:12.898]  Step 141683  [3.329 sec/step, loss=0.08062, avg_loss=0.09631, mel_loss=0.03743, linear_loss=0.04319]
[2020-05-11 17:43:14.287]  Step 141684  [3.326 sec/step, loss=0.09144, avg_loss=0.09627, mel_loss=0.04157, linear_loss=0.04987]
[2020-05-11 17:43:17.389]  Step 141685  [3.349 sec/step, loss=0.10286, avg_loss=0.09645, mel_loss=0.04770, linear_loss=0.05516]
[2020-05-11 17:43:18.491]  Step 141686  [3.323 sec/step, loss=0.09229, avg_loss=0.09633, mel_loss=0.04152, linear_loss=0.05077]
[2020-05-11 17:43:22.583]  Step 141687  [3.355 sec/step, loss=0.10385, avg_loss=0.09655, mel_loss=0.04885, linear_loss=0.05500]
[2020-05-11 17:43:24.201]  Step 141688  [3.351 sec/step, loss=0.09624, avg_loss=0.09654, mel_loss=0.04444, linear_loss=0.05181]
[2020-05-11 17:43:31.335]  Step 141689  [3.404 sec/step, loss=0.10674, avg_loss=0.09661, mel_loss=0.05095, linear_loss=0.05579]
[2020-05-11 17:43:38.068]  Step 141690  [3.418 sec/step, loss=0.10545, avg_loss=0.09662, mel_loss=0.05051, linear_loss=0.05494]
[2020-05-11 17:43:42.844]  Step 141691  [3.454 sec/step, loss=0.10438, avg_loss=0.09675, mel_loss=0.04894, linear_loss=0.05544]
[2020-05-11 17:43:48.299]  Step 141692  [3.362 sec/step, loss=0.10579, avg_loss=0.09695, mel_loss=0.04978, linear_loss=0.05602]
[2020-05-11 17:43:55.034]  Step 141693  [3.371 sec/step, loss=0.10582, avg_loss=0.09698, mel_loss=0.05054, linear_loss=0.05528]
[2020-05-11 17:43:57.046]  Step 141694  [3.373 sec/step, loss=0.09737, avg_loss=0.09699, mel_loss=0.04453, linear_loss=0.05284]
[2020-05-11 17:44:00.676]  Step 141695  [3.379 sec/step, loss=0.10376, avg_loss=0.09701, mel_loss=0.04832, linear_loss=0.05544]
[2020-05-11 17:44:01.430]  Step 141696  [3.366 sec/step, loss=0.08354, avg_loss=0.09687, mel_loss=0.03781, linear_loss=0.04573]
[2020-05-11 17:44:05.557]  Step 141697  [3.394 sec/step, loss=0.10360, avg_loss=0.09694, mel_loss=0.04826, linear_loss=0.05534]
[2020-05-11 17:44:08.674]  Step 141698  [3.416 sec/step, loss=0.10243, avg_loss=0.09708, mel_loss=0.04735, linear_loss=0.05508]
[2020-05-11 17:44:11.131]  Step 141699  [3.427 sec/step, loss=0.09770, avg_loss=0.09710, mel_loss=0.04489, linear_loss=0.05280]
[2020-05-11 17:44:12.302]  Step 141700  [3.433 sec/step, loss=0.09001, avg_loss=0.09722, mel_loss=0.04051, linear_loss=0.04950]
[2020-05-11 17:44:12.302]  Writing summary at step: 141700
[2020-05-11 17:44:15.189]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141700
[2020-05-11 17:44:16.679]  Saving audio and alignment...
[2020-05-11 17:44:24.774]  Input: 엠씨나 기타 장르에서 감정이 부족하세요 그렇다면 고개를 활용해 보세요 즉~________________________________
[2020-05-11 17:44:26.863]  Step 141701  [3.413 sec/step, loss=0.09881, avg_loss=0.09717, mel_loss=0.04533, linear_loss=0.05348]
[2020-05-11 17:44:29.486]  Step 141702  [3.423 sec/step, loss=0.09848, avg_loss=0.09719, mel_loss=0.04527, linear_loss=0.05321]
[2020-05-11 17:44:31.756]  Step 141703  [3.384 sec/step, loss=0.09803, avg_loss=0.09713, mel_loss=0.04490, linear_loss=0.05313]
[2020-05-11 17:44:33.589]  Step 141704  [3.396 sec/step, loss=0.09741, avg_loss=0.09730, mel_loss=0.04429, linear_loss=0.05312]
[2020-05-11 17:44:35.215]  Step 141705  [3.369 sec/step, loss=0.09730, avg_loss=0.09722, mel_loss=0.04426, linear_loss=0.05303]
[2020-05-11 17:44:38.596]  Step 141706  [3.391 sec/step, loss=0.10250, avg_loss=0.09736, mel_loss=0.04748, linear_loss=0.05503]
[2020-05-11 17:44:42.012]  Step 141707  [3.378 sec/step, loss=0.10137, avg_loss=0.09731, mel_loss=0.04711, linear_loss=0.05426]
[2020-05-11 17:44:43.765]  Step 141708  [3.274 sec/step, loss=0.09590, avg_loss=0.09736, mel_loss=0.04363, linear_loss=0.05228]
[2020-05-11 17:44:45.070]  Step 141709  [3.272 sec/step, loss=0.09441, avg_loss=0.09737, mel_loss=0.04286, linear_loss=0.05155]
[2020-05-11 17:44:58.821]  Step 141710  [3.397 sec/step, loss=0.07818, avg_loss=0.09723, mel_loss=0.03827, linear_loss=0.03991]
[2020-05-11 17:44:59.582]  Step 141711  [3.379 sec/step, loss=0.08053, avg_loss=0.09702, mel_loss=0.03632, linear_loss=0.04421]
[2020-05-11 17:45:01.281]  Generated 32 batches of size 32 in 1.685 sec
[2020-05-11 17:45:04.059]  Step 141712  [3.394 sec/step, loss=0.10408, avg_loss=0.09703, mel_loss=0.04881, linear_loss=0.05527]
[2020-05-11 17:45:05.175]  Step 141713  [3.386 sec/step, loss=0.09112, avg_loss=0.09696, mel_loss=0.04095, linear_loss=0.05016]
[2020-05-11 17:45:06.535]  Step 141714  [3.314 sec/step, loss=0.09552, avg_loss=0.09688, mel_loss=0.04351, linear_loss=0.05201]
[2020-05-11 17:45:07.560]  Step 141715  [3.231 sec/step, loss=0.08870, avg_loss=0.09671, mel_loss=0.03982, linear_loss=0.04888]
[2020-05-11 17:45:14.942]  Step 141716  [3.280 sec/step, loss=0.10422, avg_loss=0.09681, mel_loss=0.04986, linear_loss=0.05436]
[2020-05-11 17:45:23.296]  Step 141717  [3.282 sec/step, loss=0.10326, avg_loss=0.09680, mel_loss=0.04950, linear_loss=0.05376]
[2020-05-11 17:45:24.295]  Step 141718  [3.258 sec/step, loss=0.08816, avg_loss=0.09672, mel_loss=0.03963, linear_loss=0.04853]
[2020-05-11 17:45:25.794]  Step 141719  [3.234 sec/step, loss=0.09589, avg_loss=0.09664, mel_loss=0.04373, linear_loss=0.05216]
[2020-05-11 17:45:26.595]  Step 141720  [3.234 sec/step, loss=0.08650, avg_loss=0.09664, mel_loss=0.03877, linear_loss=0.04773]
[2020-05-11 17:45:27.544]  Step 141721  [3.232 sec/step, loss=0.09125, avg_loss=0.09670, mel_loss=0.04126, linear_loss=0.04999]
[2020-05-11 17:45:29.502]  Step 141722  [3.220 sec/step, loss=0.09769, avg_loss=0.09665, mel_loss=0.04454, linear_loss=0.05315]
[2020-05-11 17:45:31.841]  Step 141723  [3.208 sec/step, loss=0.10085, avg_loss=0.09665, mel_loss=0.04645, linear_loss=0.05440]
[2020-05-11 17:45:36.142]  Step 141724  [3.217 sec/step, loss=0.10278, avg_loss=0.09666, mel_loss=0.04812, linear_loss=0.05466]
[2020-05-11 17:45:40.765]  Step 141725  [3.205 sec/step, loss=0.10439, avg_loss=0.09666, mel_loss=0.04928, linear_loss=0.05511]
[2020-05-11 17:45:43.544]  Step 141726  [3.212 sec/step, loss=0.10088, avg_loss=0.09667, mel_loss=0.04693, linear_loss=0.05395]
[2020-05-11 17:45:51.216]  Step 141727  [3.278 sec/step, loss=0.10489, avg_loss=0.09681, mel_loss=0.04994, linear_loss=0.05495]
[2020-05-11 17:46:04.314]  Step 141728  [3.385 sec/step, loss=0.09176, avg_loss=0.09675, mel_loss=0.04477, linear_loss=0.04699]
[2020-05-11 17:46:05.408]  Step 141729  [3.375 sec/step, loss=0.08832, avg_loss=0.09664, mel_loss=0.03953, linear_loss=0.04879]
[2020-05-11 17:46:07.124]  Step 141730  [3.314 sec/step, loss=0.09660, avg_loss=0.09655, mel_loss=0.04378, linear_loss=0.05282]
[2020-05-11 17:46:16.244]  Step 141731  [3.385 sec/step, loss=0.10398, avg_loss=0.09662, mel_loss=0.05016, linear_loss=0.05382]
[2020-05-11 17:46:17.879]  Step 141732  [3.367 sec/step, loss=0.09477, avg_loss=0.09657, mel_loss=0.04293, linear_loss=0.05184]
[2020-05-11 17:46:19.681]  Step 141733  [3.321 sec/step, loss=0.09634, avg_loss=0.09650, mel_loss=0.04362, linear_loss=0.05271]
[2020-05-11 17:46:22.389]  Step 141734  [3.312 sec/step, loss=0.10134, avg_loss=0.09649, mel_loss=0.04696, linear_loss=0.05438]
[2020-05-11 17:46:24.839]  Step 141735  [3.320 sec/step, loss=0.09809, avg_loss=0.09650, mel_loss=0.04484, linear_loss=0.05325]
[2020-05-11 17:46:26.946]  Step 141736  [3.289 sec/step, loss=0.09660, avg_loss=0.09645, mel_loss=0.04444, linear_loss=0.05216]
[2020-05-11 17:46:27.764]  Step 141737  [3.273 sec/step, loss=0.08320, avg_loss=0.09630, mel_loss=0.03740, linear_loss=0.04580]
[2020-05-11 17:46:29.136]  Step 141738  [3.272 sec/step, loss=0.08966, avg_loss=0.09627, mel_loss=0.04053, linear_loss=0.04913]
[2020-05-11 17:46:32.165]  Step 141739  [3.297 sec/step, loss=0.10191, avg_loss=0.09653, mel_loss=0.04726, linear_loss=0.05465]
[2020-05-11 17:46:37.864]  Step 141740  [3.211 sec/step, loss=0.10298, avg_loss=0.09677, mel_loss=0.04865, linear_loss=0.05433]
[2020-05-11 17:46:39.122]  Step 141741  [3.215 sec/step, loss=0.08965, avg_loss=0.09685, mel_loss=0.04089, linear_loss=0.04876]
[2020-05-11 17:46:40.028]  Step 141742  [3.211 sec/step, loss=0.08368, avg_loss=0.09676, mel_loss=0.03761, linear_loss=0.04607]
[2020-05-11 17:46:40.625]  Step 141743  [3.161 sec/step, loss=0.08510, avg_loss=0.09658, mel_loss=0.03831, linear_loss=0.04679]
[2020-05-11 17:46:42.272]  Generated 32 batches of size 32 in 1.642 sec
[2020-05-11 17:46:46.009]  Step 141744  [3.185 sec/step, loss=0.10223, avg_loss=0.09657, mel_loss=0.04829, linear_loss=0.05394]
[2020-05-11 17:46:49.615]  Step 141745  [3.138 sec/step, loss=0.10462, avg_loss=0.09658, mel_loss=0.04881, linear_loss=0.05581]
[2020-05-11 17:46:51.054]  Step 141746  [3.141 sec/step, loss=0.09304, avg_loss=0.09663, mel_loss=0.04238, linear_loss=0.05067]
[2020-05-11 17:46:54.521]  Step 141747  [3.152 sec/step, loss=0.10185, avg_loss=0.09664, mel_loss=0.04713, linear_loss=0.05471]
[2020-05-11 17:46:55.041]  Step 141748  [3.117 sec/step, loss=0.08199, avg_loss=0.09643, mel_loss=0.03794, linear_loss=0.04404]
[2020-05-11 17:46:58.312]  Step 141749  [3.139 sec/step, loss=0.10544, avg_loss=0.09659, mel_loss=0.04943, linear_loss=0.05601]
[2020-05-11 17:47:00.484]  Step 141750  [3.143 sec/step, loss=0.09906, avg_loss=0.09663, mel_loss=0.04542, linear_loss=0.05364]
[2020-05-11 17:47:00.484]  Writing summary at step: 141750
[2020-05-11 17:47:06.896]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141750
[2020-05-11 17:47:08.148]  Saving audio and alignment...
[2020-05-11 17:47:14.020]  Input: 자 계속해서 부산 엠비씨와 울산 엠비씨 기출질문 다섯~________________
[2020-05-11 17:47:16.375]  Step 141751  [3.124 sec/step, loss=0.09994, avg_loss=0.09660, mel_loss=0.04603, linear_loss=0.05391]
[2020-05-11 17:47:17.755]  Step 141752  [3.110 sec/step, loss=0.09378, avg_loss=0.09655, mel_loss=0.04265, linear_loss=0.05112]
[2020-05-11 17:47:19.511]  Step 141753  [3.119 sec/step, loss=0.09829, avg_loss=0.09671, mel_loss=0.04474, linear_loss=0.05356]
[2020-05-11 17:47:21.964]  Step 141754  [3.109 sec/step, loss=0.09976, avg_loss=0.09666, mel_loss=0.04567, linear_loss=0.05409]
[2020-05-11 17:47:23.550]  Step 141755  [3.114 sec/step, loss=0.09728, avg_loss=0.09675, mel_loss=0.04420, linear_loss=0.05308]
[2020-05-11 17:47:27.253]  Step 141756  [3.133 sec/step, loss=0.10429, avg_loss=0.09684, mel_loss=0.04875, linear_loss=0.05555]
[2020-05-11 17:47:29.163]  Step 141757  [3.133 sec/step, loss=0.09708, avg_loss=0.09685, mel_loss=0.04411, linear_loss=0.05298]
[2020-05-11 17:47:31.279]  Step 141758  [3.125 sec/step, loss=0.09843, avg_loss=0.09681, mel_loss=0.04507, linear_loss=0.05336]
[2020-05-11 17:47:32.071]  Step 141759  [3.080 sec/step, loss=0.08053, avg_loss=0.09657, mel_loss=0.03602, linear_loss=0.04450]
[2020-05-11 17:47:36.279]  Step 141760  [3.103 sec/step, loss=0.10289, avg_loss=0.09663, mel_loss=0.04798, linear_loss=0.05490]
[2020-05-11 17:47:37.094]  Step 141761  [3.085 sec/step, loss=0.08554, avg_loss=0.09650, mel_loss=0.03851, linear_loss=0.04703]
[2020-05-11 17:47:40.595]  Step 141762  [3.062 sec/step, loss=0.10202, avg_loss=0.09648, mel_loss=0.04738, linear_loss=0.05464]
[2020-05-11 17:47:45.466]  Step 141763  [3.076 sec/step, loss=0.10327, avg_loss=0.09651, mel_loss=0.04840, linear_loss=0.05486]
[2020-05-11 17:47:51.273]  Step 141764  [3.106 sec/step, loss=0.10596, avg_loss=0.09657, mel_loss=0.05015, linear_loss=0.05581]
[2020-05-11 17:47:54.177]  Step 141765  [3.120 sec/step, loss=0.10096, avg_loss=0.09663, mel_loss=0.04687, linear_loss=0.05409]
[2020-05-11 17:47:57.771]  Step 141766  [3.142 sec/step, loss=0.10415, avg_loss=0.09674, mel_loss=0.04838, linear_loss=0.05577]
[2020-05-11 17:47:58.786]  Step 141767  [3.145 sec/step, loss=0.08568, avg_loss=0.09675, mel_loss=0.03828, linear_loss=0.04740]
[2020-05-11 17:48:03.079]  Step 141768  [3.044 sec/step, loss=0.10505, avg_loss=0.09697, mel_loss=0.04946, linear_loss=0.05559]
[2020-05-11 17:48:05.131]  Step 141769  [3.056 sec/step, loss=0.09751, avg_loss=0.09707, mel_loss=0.04435, linear_loss=0.05316]
[2020-05-11 17:48:06.487]  Step 141770  [3.060 sec/step, loss=0.09440, avg_loss=0.09712, mel_loss=0.04316, linear_loss=0.05124]
[2020-05-11 17:48:07.655]  Step 141771  [3.031 sec/step, loss=0.09169, avg_loss=0.09698, mel_loss=0.04119, linear_loss=0.05050]
[2020-05-11 17:48:08.753]  Step 141772  [3.022 sec/step, loss=0.09200, avg_loss=0.09691, mel_loss=0.04117, linear_loss=0.05083]
[2020-05-11 17:48:11.821]  Step 141773  [2.962 sec/step, loss=0.10332, avg_loss=0.09692, mel_loss=0.04796, linear_loss=0.05536]
[2020-05-11 17:48:13.539]  Generated 32 batches of size 32 in 1.713 sec
[2020-05-11 17:48:18.162]  Step 141774  [2.994 sec/step, loss=0.10665, avg_loss=0.09697, mel_loss=0.05056, linear_loss=0.05609]
[2020-05-11 17:48:18.771]  Step 141775  [2.976 sec/step, loss=0.08034, avg_loss=0.09678, mel_loss=0.03681, linear_loss=0.04353]
[2020-05-11 17:48:21.657]  Step 141776  [2.968 sec/step, loss=0.09930, avg_loss=0.09674, mel_loss=0.04580, linear_loss=0.05351]
[2020-05-11 17:48:23.386]  Step 141777  [2.974 sec/step, loss=0.09453, avg_loss=0.09677, mel_loss=0.04299, linear_loss=0.05153]
[2020-05-11 17:48:26.854]  Step 141778  [2.991 sec/step, loss=0.10463, avg_loss=0.09686, mel_loss=0.04875, linear_loss=0.05588]
[2020-05-11 17:48:39.536]  Step 141779  [3.096 sec/step, loss=0.08736, avg_loss=0.09676, mel_loss=0.04247, linear_loss=0.04489]
[2020-05-11 17:48:46.453]  Step 141780  [3.157 sec/step, loss=0.10504, avg_loss=0.09695, mel_loss=0.05024, linear_loss=0.05481]
[2020-05-11 17:48:47.429]  Step 141781  [3.143 sec/step, loss=0.09072, avg_loss=0.09687, mel_loss=0.04093, linear_loss=0.04980]
[2020-05-11 17:48:55.784]  Step 141782  [3.177 sec/step, loss=0.10215, avg_loss=0.09684, mel_loss=0.04870, linear_loss=0.05345]
[2020-05-11 17:48:57.161]  Step 141783  [3.182 sec/step, loss=0.09569, avg_loss=0.09699, mel_loss=0.04368, linear_loss=0.05201]
[2020-05-11 17:49:03.018]  Step 141784  [3.227 sec/step, loss=0.10573, avg_loss=0.09713, mel_loss=0.05012, linear_loss=0.05562]
[2020-05-11 17:49:05.654]  Step 141785  [3.222 sec/step, loss=0.09875, avg_loss=0.09709, mel_loss=0.04571, linear_loss=0.05304]
[2020-05-11 17:49:10.498]  Step 141786  [3.260 sec/step, loss=0.10452, avg_loss=0.09721, mel_loss=0.04913, linear_loss=0.05538]
[2020-05-11 17:49:13.881]  Step 141787  [3.253 sec/step, loss=0.10039, avg_loss=0.09718, mel_loss=0.04627, linear_loss=0.05411]
[2020-05-11 17:49:17.507]  Step 141788  [3.273 sec/step, loss=0.10156, avg_loss=0.09723, mel_loss=0.04718, linear_loss=0.05438]
[2020-05-11 17:49:19.987]  Step 141789  [3.226 sec/step, loss=0.09792, avg_loss=0.09714, mel_loss=0.04526, linear_loss=0.05266]
[2020-05-11 17:49:20.940]  Step 141790  [3.168 sec/step, loss=0.08424, avg_loss=0.09693, mel_loss=0.03805, linear_loss=0.04619]
[2020-05-11 17:49:22.903]  Step 141791  [3.140 sec/step, loss=0.09903, avg_loss=0.09688, mel_loss=0.04579, linear_loss=0.05325]
[2020-05-11 17:49:24.469]  Step 141792  [3.101 sec/step, loss=0.09600, avg_loss=0.09678, mel_loss=0.04350, linear_loss=0.05250]
[2020-05-11 17:49:32.187]  Step 141793  [3.111 sec/step, loss=0.10615, avg_loss=0.09678, mel_loss=0.05103, linear_loss=0.05512]
[2020-05-11 17:49:33.855]  Step 141794  [3.108 sec/step, loss=0.09693, avg_loss=0.09678, mel_loss=0.04435, linear_loss=0.05258]
[2020-05-11 17:49:38.547]  Step 141795  [3.118 sec/step, loss=0.10382, avg_loss=0.09678, mel_loss=0.04842, linear_loss=0.05541]
[2020-05-11 17:49:40.230]  Step 141796  [3.128 sec/step, loss=0.09042, avg_loss=0.09685, mel_loss=0.04112, linear_loss=0.04930]
[2020-05-11 17:49:41.068]  Step 141797  [3.095 sec/step, loss=0.07785, avg_loss=0.09659, mel_loss=0.03560, linear_loss=0.04225]
[2020-05-11 17:49:43.226]  Step 141798  [3.085 sec/step, loss=0.09486, avg_loss=0.09651, mel_loss=0.04302, linear_loss=0.05185]
[2020-05-11 17:49:46.707]  Step 141799  [3.095 sec/step, loss=0.09688, avg_loss=0.09651, mel_loss=0.04455, linear_loss=0.05233]
[2020-05-11 17:49:54.798]  Step 141800  [3.165 sec/step, loss=0.10346, avg_loss=0.09664, mel_loss=0.04866, linear_loss=0.05480]
[2020-05-11 17:49:54.798]  Writing summary at step: 141800
[2020-05-11 17:49:58.250]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141800
[2020-05-11 17:49:59.540]  Saving audio and alignment...
[2020-05-11 17:50:01.078]  Input: 쉬어~______________________________
[2020-05-11 17:50:16.075]  Step 141801  [3.294 sec/step, loss=0.08570, avg_loss=0.09651, mel_loss=0.04199, linear_loss=0.04371]
[2020-05-11 17:50:19.268]  Step 141802  [3.299 sec/step, loss=0.10178, avg_loss=0.09654, mel_loss=0.04709, linear_loss=0.05469]
[2020-05-11 17:50:23.753]  Step 141803  [3.322 sec/step, loss=0.10634, avg_loss=0.09663, mel_loss=0.05005, linear_loss=0.05629]
[2020-05-11 17:50:24.611]  Step 141804  [3.312 sec/step, loss=0.08500, avg_loss=0.09650, mel_loss=0.03823, linear_loss=0.04677]
[2020-05-11 17:50:25.691]  Generated 32 batches of size 32 in 1.932 sec
[2020-05-11 17:50:28.938]  Step 141805  [3.339 sec/step, loss=0.10147, avg_loss=0.09654, mel_loss=0.04738, linear_loss=0.05409]
[2020-05-11 17:50:30.817]  Step 141806  [3.324 sec/step, loss=0.09754, avg_loss=0.09649, mel_loss=0.04464, linear_loss=0.05290]
[2020-05-11 17:50:33.686]  Step 141807  [3.318 sec/step, loss=0.10181, avg_loss=0.09650, mel_loss=0.04749, linear_loss=0.05432]
[2020-05-11 17:50:35.472]  Step 141808  [3.319 sec/step, loss=0.09448, avg_loss=0.09648, mel_loss=0.04267, linear_loss=0.05182]
[2020-05-11 17:50:44.667]  Step 141809  [3.398 sec/step, loss=0.10498, avg_loss=0.09659, mel_loss=0.05062, linear_loss=0.05436]
[2020-05-11 17:50:45.977]  Step 141810  [3.273 sec/step, loss=0.08886, avg_loss=0.09670, mel_loss=0.03996, linear_loss=0.04890]
[2020-05-11 17:50:47.126]  Step 141811  [3.277 sec/step, loss=0.09017, avg_loss=0.09679, mel_loss=0.04055, linear_loss=0.04963]
[2020-05-11 17:50:53.683]  Step 141812  [3.298 sec/step, loss=0.10545, avg_loss=0.09681, mel_loss=0.05025, linear_loss=0.05520]
[2020-05-11 17:51:01.148]  Step 141813  [3.361 sec/step, loss=0.10627, avg_loss=0.09696, mel_loss=0.05080, linear_loss=0.05547]
[2020-05-11 17:51:04.471]  Step 141814  [3.381 sec/step, loss=0.10412, avg_loss=0.09704, mel_loss=0.04816, linear_loss=0.05596]
[2020-05-11 17:51:05.550]  Step 141815  [3.381 sec/step, loss=0.09315, avg_loss=0.09709, mel_loss=0.04172, linear_loss=0.05143]
[2020-05-11 17:51:06.954]  Step 141816  [3.322 sec/step, loss=0.09354, avg_loss=0.09698, mel_loss=0.04284, linear_loss=0.05071]
[2020-05-11 17:51:08.717]  Step 141817  [3.256 sec/step, loss=0.09701, avg_loss=0.09692, mel_loss=0.04383, linear_loss=0.05318]
[2020-05-11 17:51:12.341]  Step 141818  [3.282 sec/step, loss=0.10395, avg_loss=0.09708, mel_loss=0.04830, linear_loss=0.05565]
[2020-05-11 17:51:14.503]  Step 141819  [3.289 sec/step, loss=0.09968, avg_loss=0.09712, mel_loss=0.04573, linear_loss=0.05395]
[2020-05-11 17:51:15.503]  Step 141820  [3.291 sec/step, loss=0.08771, avg_loss=0.09713, mel_loss=0.03954, linear_loss=0.04817]
[2020-05-11 17:51:18.214]  Step 141821  [3.308 sec/step, loss=0.09850, avg_loss=0.09720, mel_loss=0.04527, linear_loss=0.05323]
[2020-05-11 17:51:19.088]  Step 141822  [3.297 sec/step, loss=0.07977, avg_loss=0.09702, mel_loss=0.03584, linear_loss=0.04393]
[2020-05-11 17:51:19.647]  Step 141823  [3.280 sec/step, loss=0.07551, avg_loss=0.09677, mel_loss=0.03446, linear_loss=0.04105]
[2020-05-11 17:51:20.949]  Step 141824  [3.250 sec/step, loss=0.09558, avg_loss=0.09669, mel_loss=0.04336, linear_loss=0.05222]
[2020-05-11 17:51:26.220]  Step 141825  [3.256 sec/step, loss=0.10458, avg_loss=0.09670, mel_loss=0.04944, linear_loss=0.05514]
[2020-05-11 17:51:30.514]  Step 141826  [3.271 sec/step, loss=0.10327, avg_loss=0.09672, mel_loss=0.04831, linear_loss=0.05495]
[2020-05-11 17:51:36.176]  Step 141827  [3.251 sec/step, loss=0.10302, avg_loss=0.09670, mel_loss=0.04868, linear_loss=0.05434]
[2020-05-11 17:51:44.304]  Step 141828  [3.201 sec/step, loss=0.10305, avg_loss=0.09681, mel_loss=0.04956, linear_loss=0.05349]
[2020-05-11 17:51:51.126]  Step 141829  [3.259 sec/step, loss=0.10411, avg_loss=0.09697, mel_loss=0.04959, linear_loss=0.05451]
[2020-05-11 17:52:04.262]  Step 141830  [3.373 sec/step, loss=0.08606, avg_loss=0.09687, mel_loss=0.04176, linear_loss=0.04430]
[2020-05-11 17:52:06.752]  Step 141831  [3.307 sec/step, loss=0.09971, avg_loss=0.09682, mel_loss=0.04578, linear_loss=0.05393]
[2020-05-11 17:52:08.978]  Step 141832  [3.313 sec/step, loss=0.09750, avg_loss=0.09685, mel_loss=0.04483, linear_loss=0.05267]
[2020-05-11 17:52:10.536]  Step 141833  [3.310 sec/step, loss=0.09479, avg_loss=0.09684, mel_loss=0.04356, linear_loss=0.05123]
[2020-05-11 17:52:11.331]  Step 141834  [3.291 sec/step, loss=0.08633, avg_loss=0.09669, mel_loss=0.03892, linear_loss=0.04741]
[2020-05-11 17:52:13.312]  Step 141835  [3.286 sec/step, loss=0.09897, avg_loss=0.09670, mel_loss=0.04503, linear_loss=0.05395]
[2020-05-11 17:52:15.023]  Generated 32 batches of size 32 in 1.706 sec
[2020-05-11 17:52:16.436]  Step 141836  [3.296 sec/step, loss=0.10327, avg_loss=0.09676, mel_loss=0.04770, linear_loss=0.05557]
[2020-05-11 17:52:19.852]  Step 141837  [3.322 sec/step, loss=0.10366, avg_loss=0.09697, mel_loss=0.04870, linear_loss=0.05495]
[2020-05-11 17:52:21.738]  Step 141838  [3.328 sec/step, loss=0.09683, avg_loss=0.09704, mel_loss=0.04384, linear_loss=0.05300]
[2020-05-11 17:52:22.759]  Step 141839  [3.308 sec/step, loss=0.08932, avg_loss=0.09691, mel_loss=0.04045, linear_loss=0.04886]
[2020-05-11 17:52:25.445]  Step 141840  [3.277 sec/step, loss=0.10019, avg_loss=0.09688, mel_loss=0.04649, linear_loss=0.05370]
[2020-05-11 17:52:30.019]  Step 141841  [3.311 sec/step, loss=0.10408, avg_loss=0.09703, mel_loss=0.04895, linear_loss=0.05514]
[2020-05-11 17:52:31.716]  Step 141842  [3.318 sec/step, loss=0.09516, avg_loss=0.09714, mel_loss=0.04335, linear_loss=0.05182]
[2020-05-11 17:52:32.927]  Step 141843  [3.325 sec/step, loss=0.09139, avg_loss=0.09721, mel_loss=0.04119, linear_loss=0.05021]
[2020-05-11 17:52:36.954]  Step 141844  [3.311 sec/step, loss=0.10445, avg_loss=0.09723, mel_loss=0.04867, linear_loss=0.05577]
[2020-05-11 17:52:37.719]  Step 141845  [3.283 sec/step, loss=0.08499, avg_loss=0.09703, mel_loss=0.03896, linear_loss=0.04603]
[2020-05-11 17:52:39.039]  Step 141846  [3.281 sec/step, loss=0.09603, avg_loss=0.09706, mel_loss=0.04364, linear_loss=0.05238]
[2020-05-11 17:52:53.247]  Step 141847  [3.389 sec/step, loss=0.07921, avg_loss=0.09684, mel_loss=0.03854, linear_loss=0.04068]
[2020-05-11 17:52:55.401]  Step 141848  [3.405 sec/step, loss=0.09895, avg_loss=0.09701, mel_loss=0.04548, linear_loss=0.05347]
[2020-05-11 17:52:57.167]  Step 141849  [3.390 sec/step, loss=0.09586, avg_loss=0.09691, mel_loss=0.04358, linear_loss=0.05228]
[2020-05-11 17:52:59.575]  Step 141850  [3.393 sec/step, loss=0.09823, avg_loss=0.09690, mel_loss=0.04495, linear_loss=0.05328]
[2020-05-11 17:52:59.575]  Writing summary at step: 141850
[2020-05-11 17:53:02.361]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141850
[2020-05-11 17:53:03.628]  Saving audio and alignment...
[2020-05-11 17:53:08.526]  Input: 그것보다는 붉은색 주가 상승을 의미하는~__________________________
[2020-05-11 17:53:15.756]  Step 141851  [3.441 sec/step, loss=0.10545, avg_loss=0.09696, mel_loss=0.05022, linear_loss=0.05523]
[2020-05-11 17:53:20.294]  Step 141852  [3.473 sec/step, loss=0.10474, avg_loss=0.09707, mel_loss=0.04915, linear_loss=0.05559]
[2020-05-11 17:53:21.194]  Step 141853  [3.464 sec/step, loss=0.08816, avg_loss=0.09696, mel_loss=0.03939, linear_loss=0.04877]
[2020-05-11 17:53:22.883]  Step 141854  [3.457 sec/step, loss=0.09571, avg_loss=0.09692, mel_loss=0.04371, linear_loss=0.05200]
[2020-05-11 17:53:23.438]  Step 141855  [3.446 sec/step, loss=0.07745, avg_loss=0.09673, mel_loss=0.03515, linear_loss=0.04231]
[2020-05-11 17:53:26.912]  Step 141856  [3.444 sec/step, loss=0.10031, avg_loss=0.09669, mel_loss=0.04700, linear_loss=0.05330]
[2020-05-11 17:53:30.837]  Step 141857  [3.464 sec/step, loss=0.10383, avg_loss=0.09675, mel_loss=0.04856, linear_loss=0.05527]
[2020-05-11 17:53:31.693]  Step 141858  [3.452 sec/step, loss=0.08175, avg_loss=0.09659, mel_loss=0.03651, linear_loss=0.04523]
[2020-05-11 17:53:37.355]  Step 141859  [3.500 sec/step, loss=0.10505, avg_loss=0.09683, mel_loss=0.04952, linear_loss=0.05553]
[2020-05-11 17:53:38.916]  Step 141860  [3.474 sec/step, loss=0.10027, avg_loss=0.09681, mel_loss=0.04538, linear_loss=0.05488]
[2020-05-11 17:53:40.948]  Step 141861  [3.486 sec/step, loss=0.09790, avg_loss=0.09693, mel_loss=0.04485, linear_loss=0.05306]
[2020-05-11 17:53:45.797]  Step 141862  [3.499 sec/step, loss=0.10335, avg_loss=0.09694, mel_loss=0.04852, linear_loss=0.05483]
[2020-05-11 17:53:46.926]  Step 141863  [3.462 sec/step, loss=0.08821, avg_loss=0.09679, mel_loss=0.03991, linear_loss=0.04830]
[2020-05-11 17:53:55.054]  Step 141864  [3.485 sec/step, loss=0.10406, avg_loss=0.09677, mel_loss=0.04973, linear_loss=0.05433]
[2020-05-11 17:54:01.200]  Step 141865  [3.518 sec/step, loss=0.10400, avg_loss=0.09680, mel_loss=0.04937, linear_loss=0.05463]
[2020-05-11 17:54:02.881]  Generated 32 batches of size 32 in 1.675 sec
[2020-05-11 17:54:04.854]  Step 141866  [3.518 sec/step, loss=0.10369, avg_loss=0.09680, mel_loss=0.04817, linear_loss=0.05551]
[2020-05-11 17:54:06.825]  Step 141867  [3.528 sec/step, loss=0.09474, avg_loss=0.09689, mel_loss=0.04318, linear_loss=0.05157]
[2020-05-11 17:54:09.748]  Step 141868  [3.514 sec/step, loss=0.10112, avg_loss=0.09685, mel_loss=0.04649, linear_loss=0.05463]
[2020-05-11 17:54:10.904]  Step 141869  [3.505 sec/step, loss=0.09441, avg_loss=0.09682, mel_loss=0.04303, linear_loss=0.05138]
[2020-05-11 17:54:12.483]  Step 141870  [3.507 sec/step, loss=0.09158, avg_loss=0.09679, mel_loss=0.04158, linear_loss=0.05000]
[2020-05-11 17:54:13.710]  Step 141871  [3.508 sec/step, loss=0.09418, avg_loss=0.09682, mel_loss=0.04247, linear_loss=0.05170]
[2020-05-11 17:54:17.899]  Step 141872  [3.539 sec/step, loss=0.10209, avg_loss=0.09692, mel_loss=0.04761, linear_loss=0.05448]
[2020-05-11 17:54:20.590]  Step 141873  [3.535 sec/step, loss=0.09800, avg_loss=0.09686, mel_loss=0.04533, linear_loss=0.05268]
[2020-05-11 17:54:21.612]  Step 141874  [3.482 sec/step, loss=0.08929, avg_loss=0.09669, mel_loss=0.04007, linear_loss=0.04921]
[2020-05-11 17:54:25.895]  Step 141875  [3.519 sec/step, loss=0.10502, avg_loss=0.09694, mel_loss=0.04931, linear_loss=0.05570]
[2020-05-11 17:54:26.857]  Step 141876  [3.499 sec/step, loss=0.08931, avg_loss=0.09684, mel_loss=0.03973, linear_loss=0.04958]
[2020-05-11 17:54:28.588]  Step 141877  [3.499 sec/step, loss=0.09575, avg_loss=0.09685, mel_loss=0.04340, linear_loss=0.05235]
[2020-05-11 17:54:40.785]  Step 141878  [3.587 sec/step, loss=0.09280, avg_loss=0.09673, mel_loss=0.04523, linear_loss=0.04757]
[2020-05-11 17:54:42.778]  Step 141879  [3.480 sec/step, loss=0.09727, avg_loss=0.09683, mel_loss=0.04450, linear_loss=0.05276]
[2020-05-11 17:54:46.281]  Step 141880  [3.446 sec/step, loss=0.10064, avg_loss=0.09679, mel_loss=0.04652, linear_loss=0.05412]
[2020-05-11 17:54:50.973]  Step 141881  [3.483 sec/step, loss=0.10296, avg_loss=0.09691, mel_loss=0.04815, linear_loss=0.05481]
[2020-05-11 17:54:54.627]  Step 141882  [3.436 sec/step, loss=0.10376, avg_loss=0.09692, mel_loss=0.04836, linear_loss=0.05540]
[2020-05-11 17:54:59.868]  Step 141883  [3.475 sec/step, loss=0.10487, avg_loss=0.09702, mel_loss=0.04947, linear_loss=0.05540]
[2020-05-11 17:55:00.661]  Step 141884  [3.424 sec/step, loss=0.08298, avg_loss=0.09679, mel_loss=0.03745, linear_loss=0.04553]
[2020-05-11 17:55:06.911]  Step 141885  [3.460 sec/step, loss=0.10516, avg_loss=0.09685, mel_loss=0.05003, linear_loss=0.05513]
[2020-05-11 17:55:10.303]  Step 141886  [3.446 sec/step, loss=0.10432, avg_loss=0.09685, mel_loss=0.04829, linear_loss=0.05604]
[2020-05-11 17:55:13.240]  Step 141887  [3.441 sec/step, loss=0.10317, avg_loss=0.09688, mel_loss=0.04784, linear_loss=0.05533]
[2020-05-11 17:55:17.368]  Step 141888  [3.446 sec/step, loss=0.10307, avg_loss=0.09689, mel_loss=0.04814, linear_loss=0.05494]
[2020-05-11 17:55:19.874]  Step 141889  [3.446 sec/step, loss=0.09968, avg_loss=0.09691, mel_loss=0.04567, linear_loss=0.05401]
[2020-05-11 17:55:21.520]  Step 141890  [3.453 sec/step, loss=0.09239, avg_loss=0.09699, mel_loss=0.04217, linear_loss=0.05022]
[2020-05-11 17:55:22.453]  Step 141891  [3.443 sec/step, loss=0.08898, avg_loss=0.09689, mel_loss=0.04013, linear_loss=0.04886]
[2020-05-11 17:55:31.361]  Step 141892  [3.516 sec/step, loss=0.10202, avg_loss=0.09695, mel_loss=0.04921, linear_loss=0.05281]
[2020-05-11 17:55:33.746]  Step 141893  [3.463 sec/step, loss=0.10067, avg_loss=0.09690, mel_loss=0.04626, linear_loss=0.05441]
[2020-05-11 17:55:35.570]  Step 141894  [3.465 sec/step, loss=0.09915, avg_loss=0.09692, mel_loss=0.04527, linear_loss=0.05388]
[2020-05-11 17:55:36.411]  Step 141895  [3.426 sec/step, loss=0.08324, avg_loss=0.09671, mel_loss=0.03717, linear_loss=0.04607]
[2020-05-11 17:55:38.361]  Step 141896  [3.429 sec/step, loss=0.09844, avg_loss=0.09679, mel_loss=0.04475, linear_loss=0.05369]
[2020-05-11 17:55:39.384]  Step 141897  [3.431 sec/step, loss=0.09087, avg_loss=0.09692, mel_loss=0.04068, linear_loss=0.05019]
[2020-05-11 17:55:41.067]  Generated 32 batches of size 32 in 1.679 sec
[2020-05-11 17:55:41.695]  Step 141898  [3.432 sec/step, loss=0.09561, avg_loss=0.09693, mel_loss=0.04388, linear_loss=0.05173]
[2020-05-11 17:55:43.117]  Step 141899  [3.412 sec/step, loss=0.09418, avg_loss=0.09690, mel_loss=0.04275, linear_loss=0.05143]
[2020-05-11 17:55:43.679]  Step 141900  [3.336 sec/step, loss=0.07764, avg_loss=0.09665, mel_loss=0.03604, linear_loss=0.04160]
[2020-05-11 17:55:43.679]  Writing summary at step: 141900
[2020-05-11 17:55:49.305]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141900
[2020-05-11 17:55:50.602]  Saving audio and alignment...
[2020-05-11 17:55:52.846]  Input: 네 소화 가능합니다~________
[2020-05-11 17:55:55.465]  Step 141901  [3.212 sec/step, loss=0.09876, avg_loss=0.09678, mel_loss=0.04559, linear_loss=0.05317]
[2020-05-11 17:55:58.595]  Step 141902  [3.212 sec/step, loss=0.10324, avg_loss=0.09679, mel_loss=0.04825, linear_loss=0.05499]
[2020-05-11 17:56:05.929]  Step 141903  [3.240 sec/step, loss=0.10441, avg_loss=0.09677, mel_loss=0.05005, linear_loss=0.05436]
[2020-05-11 17:56:07.280]  Step 141904  [3.245 sec/step, loss=0.09177, avg_loss=0.09684, mel_loss=0.04153, linear_loss=0.05024]
[2020-05-11 17:56:11.552]  Step 141905  [3.245 sec/step, loss=0.10271, avg_loss=0.09685, mel_loss=0.04782, linear_loss=0.05489]
[2020-05-11 17:56:13.751]  Step 141906  [3.248 sec/step, loss=0.09734, avg_loss=0.09685, mel_loss=0.04508, linear_loss=0.05226]
[2020-05-11 17:56:17.397]  Step 141907  [3.256 sec/step, loss=0.10461, avg_loss=0.09688, mel_loss=0.04880, linear_loss=0.05581]
[2020-05-11 17:56:23.830]  Step 141908  [3.302 sec/step, loss=0.10118, avg_loss=0.09695, mel_loss=0.04815, linear_loss=0.05303]
[2020-05-11 17:56:31.239]  Step 141909  [3.284 sec/step, loss=0.10412, avg_loss=0.09694, mel_loss=0.04983, linear_loss=0.05428]
[2020-05-11 17:56:32.368]  Step 141910  [3.283 sec/step, loss=0.09083, avg_loss=0.09696, mel_loss=0.04075, linear_loss=0.05008]
[2020-05-11 17:56:33.170]  Step 141911  [3.279 sec/step, loss=0.08379, avg_loss=0.09689, mel_loss=0.03768, linear_loss=0.04611]
[2020-05-11 17:56:38.226]  Step 141912  [3.264 sec/step, loss=0.10054, avg_loss=0.09684, mel_loss=0.04702, linear_loss=0.05352]
[2020-05-11 17:56:40.223]  Step 141913  [3.209 sec/step, loss=0.09867, avg_loss=0.09677, mel_loss=0.04502, linear_loss=0.05365]
[2020-05-11 17:56:41.402]  Step 141914  [3.188 sec/step, loss=0.09241, avg_loss=0.09665, mel_loss=0.04185, linear_loss=0.05057]
[2020-05-11 17:56:43.149]  Step 141915  [3.195 sec/step, loss=0.09624, avg_loss=0.09668, mel_loss=0.04352, linear_loss=0.05272]
[2020-05-11 17:56:44.731]  Step 141916  [3.196 sec/step, loss=0.09568, avg_loss=0.09670, mel_loss=0.04340, linear_loss=0.05228]
[2020-05-11 17:56:45.256]  Step 141917  [3.184 sec/step, loss=0.08369, avg_loss=0.09657, mel_loss=0.03774, linear_loss=0.04595]
[2020-05-11 17:56:47.153]  Step 141918  [3.167 sec/step, loss=0.09600, avg_loss=0.09649, mel_loss=0.04330, linear_loss=0.05270]
[2020-05-11 17:56:52.715]  Step 141919  [3.201 sec/step, loss=0.10364, avg_loss=0.09653, mel_loss=0.04906, linear_loss=0.05458]
[2020-05-11 17:56:57.344]  Step 141920  [3.237 sec/step, loss=0.10356, avg_loss=0.09669, mel_loss=0.04849, linear_loss=0.05507]
[2020-05-11 17:56:58.184]  Step 141921  [3.218 sec/step, loss=0.07934, avg_loss=0.09650, mel_loss=0.03614, linear_loss=0.04320]
[2020-05-11 17:57:00.288]  Step 141922  [3.231 sec/step, loss=0.09745, avg_loss=0.09667, mel_loss=0.04431, linear_loss=0.05314]
[2020-05-11 17:57:01.641]  Step 141923  [3.239 sec/step, loss=0.09101, avg_loss=0.09683, mel_loss=0.04113, linear_loss=0.04988]
[2020-05-11 17:57:04.015]  Step 141924  [3.249 sec/step, loss=0.10032, avg_loss=0.09688, mel_loss=0.04604, linear_loss=0.05428]
[2020-05-11 17:57:07.041]  Step 141925  [3.227 sec/step, loss=0.10214, avg_loss=0.09685, mel_loss=0.04715, linear_loss=0.05499]
[2020-05-11 17:57:15.863]  Step 141926  [3.272 sec/step, loss=0.10422, avg_loss=0.09686, mel_loss=0.05001, linear_loss=0.05422]
[2020-05-11 17:57:19.311]  Step 141927  [3.250 sec/step, loss=0.10250, avg_loss=0.09686, mel_loss=0.04737, linear_loss=0.05513]
[2020-05-11 17:57:21.016]  Generated 32 batches of size 32 in 1.694 sec
[2020-05-11 17:57:22.066]  Step 141928  [3.196 sec/step, loss=0.10141, avg_loss=0.09684, mel_loss=0.04679, linear_loss=0.05462]
[2020-05-11 17:57:23.071]  Step 141929  [3.138 sec/step, loss=0.08960, avg_loss=0.09669, mel_loss=0.04056, linear_loss=0.04904]
[2020-05-11 17:57:26.108]  Step 141930  [3.037 sec/step, loss=0.10420, avg_loss=0.09688, mel_loss=0.04825, linear_loss=0.05595]
[2020-05-11 17:57:27.501]  Step 141931  [3.026 sec/step, loss=0.09334, avg_loss=0.09681, mel_loss=0.04260, linear_loss=0.05074]
[2020-05-11 17:57:30.193]  Step 141932  [3.031 sec/step, loss=0.10003, avg_loss=0.09684, mel_loss=0.04645, linear_loss=0.05358]
[2020-05-11 17:57:33.655]  Step 141933  [3.050 sec/step, loss=0.10155, avg_loss=0.09691, mel_loss=0.04727, linear_loss=0.05428]
[2020-05-11 17:57:35.313]  Step 141934  [3.058 sec/step, loss=0.09710, avg_loss=0.09701, mel_loss=0.04416, linear_loss=0.05294]
[2020-05-11 17:57:36.170]  Step 141935  [3.047 sec/step, loss=0.08427, avg_loss=0.09687, mel_loss=0.03788, linear_loss=0.04639]
[2020-05-11 17:57:50.514]  Step 141936  [3.159 sec/step, loss=0.08224, avg_loss=0.09666, mel_loss=0.04042, linear_loss=0.04181]
[2020-05-11 17:57:54.279]  Step 141937  [3.163 sec/step, loss=0.10286, avg_loss=0.09665, mel_loss=0.04781, linear_loss=0.05505]
[2020-05-11 17:57:55.086]  Step 141938  [3.152 sec/step, loss=0.08553, avg_loss=0.09653, mel_loss=0.03798, linear_loss=0.04756]
[2020-05-11 17:57:57.228]  Step 141939  [3.163 sec/step, loss=0.09866, avg_loss=0.09663, mel_loss=0.04557, linear_loss=0.05309]
[2020-05-11 17:58:03.899]  Step 141940  [3.203 sec/step, loss=0.10554, avg_loss=0.09668, mel_loss=0.05021, linear_loss=0.05533]
[2020-05-11 17:58:08.800]  Step 141941  [3.206 sec/step, loss=0.10206, avg_loss=0.09666, mel_loss=0.04802, linear_loss=0.05405]
[2020-05-11 17:58:13.047]  Step 141942  [3.232 sec/step, loss=0.10191, avg_loss=0.09673, mel_loss=0.04752, linear_loss=0.05439]
[2020-05-11 17:58:14.289]  Step 141943  [3.232 sec/step, loss=0.09183, avg_loss=0.09673, mel_loss=0.04129, linear_loss=0.05054]
[2020-05-11 17:58:16.103]  Step 141944  [3.210 sec/step, loss=0.09591, avg_loss=0.09665, mel_loss=0.04349, linear_loss=0.05242]
[2020-05-11 17:58:17.220]  Step 141945  [3.214 sec/step, loss=0.08900, avg_loss=0.09669, mel_loss=0.03972, linear_loss=0.04927]
[2020-05-11 17:58:22.610]  Step 141946  [3.254 sec/step, loss=0.10556, avg_loss=0.09678, mel_loss=0.04994, linear_loss=0.05562]
[2020-05-11 17:58:25.419]  Step 141947  [3.140 sec/step, loss=0.09937, avg_loss=0.09698, mel_loss=0.04572, linear_loss=0.05365]
[2020-05-11 17:58:26.454]  Step 141948  [3.129 sec/step, loss=0.08879, avg_loss=0.09688, mel_loss=0.03974, linear_loss=0.04904]
[2020-05-11 17:58:28.825]  Step 141949  [3.135 sec/step, loss=0.10051, avg_loss=0.09693, mel_loss=0.04621, linear_loss=0.05430]
[2020-05-11 17:58:30.717]  Step 141950  [3.130 sec/step, loss=0.09736, avg_loss=0.09692, mel_loss=0.04426, linear_loss=0.05309]
[2020-05-11 17:58:30.717]  Writing summary at step: 141950
[2020-05-11 17:58:39.651]  Saving checkpoint to: ./logs-tacotron/model.ckpt-141950
[2020-05-11 17:58:40.954]  Saving audio and alignment...
[2020-05-11 17:58:42.425]  Input: 오늘의~______
[2020-05-11 17:58:47.143]  Step 141951  [3.105 sec/step, loss=0.10660, avg_loss=0.09693, mel_loss=0.05042, linear_loss=0.05619]
[2020-05-11 17:58:52.806]  Step 141952  [3.116 sec/step, loss=0.10548, avg_loss=0.09694, mel_loss=0.04979, linear_loss=0.05568]
[2020-05-11 17:58:56.161]  Step 141953  [3.141 sec/step, loss=0.10230, avg_loss=0.09708, mel_loss=0.04731, linear_loss=0.05499]
[2020-05-11 17:58:57.546]  Step 141954  [3.138 sec/step, loss=0.09372, avg_loss=0.09706, mel_loss=0.04255, linear_loss=0.05117]
[2020-05-11 17:59:10.968]  Step 141955  [3.266 sec/step, loss=0.08641, avg_loss=0.09715, mel_loss=0.04187, linear_loss=0.04454]
[2020-05-11 17:59:13.530]  Step 141956  [3.257 sec/step, loss=0.09775, avg_loss=0.09713, mel_loss=0.04474, linear_loss=0.05301]
[2020-05-11 17:59:14.562]  Step 141957  [3.228 sec/step, loss=0.08724, avg_loss=0.09696, mel_loss=0.03936, linear_loss=0.04788]
[2020-05-11 17:59:16.301]  Step 141958  [3.237 sec/step, loss=0.09635, avg_loss=0.09711, mel_loss=0.04402, linear_loss=0.05233]
[2020-05-11 17:59:16.318]  Generated 32 batches of size 32 in 1.751 sec
[2020-05-11 17:59:18.325]  Step 141959  [3.201 sec/step, loss=0.09564, avg_loss=0.09701, mel_loss=0.04373, linear_loss=0.05191]
[2020-05-11 17:59:19.708]  Step 141960  [3.199 sec/step, loss=0.09493, avg_loss=0.09696, mel_loss=0.04330, linear_loss=0.05163]
[2020-05-11 17:59:21.252]  Step 141961  [3.194 sec/step, loss=0.09363, avg_loss=0.09692, mel_loss=0.04262, linear_loss=0.05101]
[2020-05-11 17:59:22.037]  Step 141962  [3.153 sec/step, loss=0.08623, avg_loss=0.09674, mel_loss=0.03890, linear_loss=0.04732]
[2020-05-11 17:59:29.391]  Step 141963  [3.216 sec/step, loss=0.10660, avg_loss=0.09693, mel_loss=0.05086, linear_loss=0.05574]
[2020-05-11 17:59:32.971]  Step 141964  [3.170 sec/step, loss=0.10354, avg_loss=0.09692, mel_loss=0.04806, linear_loss=0.05548]
[2020-05-11 17:59:36.389]  Step 141965  [3.143 sec/step, loss=0.10030, avg_loss=0.09689, mel_loss=0.04676, linear_loss=0.05355]
[2020-05-11 17:59:39.334]  Step 141966  [3.136 sec/step, loss=0.10356, avg_loss=0.09688, mel_loss=0.04802, linear_loss=0.05554]
[2020-05-11 17:59:53.512]  Step 141967  [3.258 sec/step, loss=0.08136, avg_loss=0.09675, mel_loss=0.03972, linear_loss=0.04164]
[2020-05-11 18:00:02.750]  Step 141968  [3.321 sec/step, loss=0.10673, avg_loss=0.09681, mel_loss=0.05090, linear_loss=0.05583]
[2020-05-11 18:00:05.818]  Step 141969  [3.340 sec/step, loss=0.09788, avg_loss=0.09684, mel_loss=0.04475, linear_loss=0.05313]
[2020-05-11 18:00:08.205]  Step 141970  [3.348 sec/step, loss=0.09674, avg_loss=0.09689, mel_loss=0.04369, linear_loss=0.05305]
[2020-05-11 18:00:11.522]  Step 141971  [3.369 sec/step, loss=0.09764, avg_loss=0.09693, mel_loss=0.04438, linear_loss=0.05325]
[2020-05-11 18:00:20.176]  Step 141972  [3.414 sec/step, loss=0.10535, avg_loss=0.09696, mel_loss=0.05040, linear_loss=0.05495]
[2020-05-11 18:00:23.152]  Step 141973  [3.417 sec/step, loss=0.10209, avg_loss=0.09700, mel_loss=0.04712, linear_loss=0.05497]
[2020-05-11 18:00:24.486]  Step 141974  [3.420 sec/step, loss=0.09021, avg_loss=0.09701, mel_loss=0.04090, linear_loss=0.04931]
[2020-05-11 18:00:25.305]  Step 141975  [3.385 sec/step, loss=0.08628, avg_loss=0.09682, mel_loss=0.03879, linear_loss=0.04749]
[2020-05-11 18:00:29.050]  Step 141976  [3.413 sec/step, loss=0.10448, avg_loss=0.09697, mel_loss=0.04869, linear_loss=0.05579]
[2020-05-11 18:00:32.229]  Step 141977  [3.427 sec/step, loss=0.10427, avg_loss=0.09706, mel_loss=0.04845, linear_loss=0.05582]
[2020-05-11 18:00:34.003]  Step 141978  [3.323 sec/step, loss=0.09460, avg_loss=0.09708, mel_loss=0.04283, linear_loss=0.05176]
[2020-05-11 18:00:35.865]  Step 141979  [3.322 sec/step, loss=0.09486, avg_loss=0.09705, mel_loss=0.04303, linear_loss=0.05183]
[2020-05-11 18:00:37.000]  Step 141980  [3.298 sec/step, loss=0.08872, avg_loss=0.09693, mel_loss=0.03973, linear_loss=0.04900]
[2020-05-11 18:00:40.400]  Step 141981  [3.285 sec/step, loss=0.10084, avg_loss=0.09691, mel_loss=0.04679, linear_loss=0.05405]
[2020-05-11 18:00:42.878]  Step 141982  [3.274 sec/step, loss=0.09716, avg_loss=0.09685, mel_loss=0.04461, linear_loss=0.05255]
[2020-05-11 18:00:48.290]  Step 141983  [3.275 sec/step, loss=0.10292, avg_loss=0.09683, mel_loss=0.04838, linear_loss=0.05454]
[2020-05-11 18:00:54.187]  Step 141984  [3.326 sec/step, loss=0.10374, avg_loss=0.09704, mel_loss=0.04903, linear_loss=0.05471]
[2020-05-11 18:01:03.371]  Step 141985  [3.356 sec/step, loss=0.10503, avg_loss=0.09703, mel_loss=0.05053, linear_loss=0.05449]
[2020-05-11 18:01:04.408]  Step 141986  [3.332 sec/step, loss=0.08524, avg_loss=0.09684, mel_loss=0.03865, linear_loss=0.04660]
[2020-05-11 18:01:05.198]  Step 141987  [3.311 sec/step, loss=0.07809, avg_loss=0.09659, mel_loss=0.03485, linear_loss=0.04324]
[2020-05-11 18:01:07.752]  Step 141988  [3.295 sec/step, loss=0.09942, avg_loss=0.09656, mel_loss=0.04545, linear_loss=0.05397]
[2020-05-11 18:01:08.765]  Step 141989  [3.280 sec/step, loss=0.08770, avg_loss=0.09644, mel_loss=0.03914, linear_loss=0.04856]
[2020-05-11 18:01:10.419]  Generated 32 batches of size 32 in 1.650 sec
[2020-05-11 18:01:13.538]  Step 141990  [3.311 sec/step, loss=0.10329, avg_loss=0.09655, mel_loss=0.04854, linear_loss=0.05475]
[2020-05-11 18:01:15.121]  Step 141991  [3.318 sec/step, loss=0.09603, avg_loss=0.09662, mel_loss=0.04362, linear_loss=0.05241]
[2020-05-11 18:01:15.876]  Step 141992  [3.236 sec/step, loss=0.07619, avg_loss=0.09636, mel_loss=0.03458, linear_loss=0.04161]
[2020-05-11 18:01:20.195]  Step 141993  [3.255 sec/step, loss=0.10407, avg_loss=0.09639, mel_loss=0.04870, linear_loss=0.05538]
[2020-05-11 18:01:21.536]  Step 141994  [3.251 sec/step, loss=0.09417, avg_loss=0.09634, mel_loss=0.04264, linear_loss=0.05154]
[2020-05-11 18:01:25.642]  Step 141995  [3.283 sec/step, loss=0.10296, avg_loss=0.09654, mel_loss=0.04771, linear_loss=0.05525]
[2020-05-11 18:01:27.943]  Step 141996  [3.287 sec/step, loss=0.09764, avg_loss=0.09653, mel_loss=0.04506, linear_loss=0.05258]
[2020-05-11 18:01:31.527]  Step 141997  [3.312 sec/step, loss=0.09964, avg_loss=0.09662, mel_loss=0.04624, linear_loss=0.05340]
[2020-05-11 18:01:34.337]  Step 141998  [3.317 sec/step, loss=0.09950, avg_loss=0.09666, mel_loss=0.04591, linear_loss=0.05360]
[2020-05-11 18:01:39.032]  Step 141999  [3.350 sec/step, loss=0.10381, avg_loss=0.09675, mel_loss=0.04872, linear_loss=0.05509]
[2020-05-11 18:01:52.342]  Step 142000  [3.478 sec/step, loss=0.08687, avg_loss=0.09685, mel_loss=0.04230, linear_loss=0.04457]
[2020-05-11 18:01:52.342]  Writing summary at step: 142000
[2020-05-11 18:01:54.821]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142000
[2020-05-11 18:01:56.112]  Saving audio and alignment...
[2020-05-11 18:01:58.785]  Input: 현미 식초가 완성된다~__________
[2020-05-11 18:02:01.573]  Step 142001  [3.479 sec/step, loss=0.09866, avg_loss=0.09685, mel_loss=0.04567, linear_loss=0.05300]
[2020-05-11 18:02:02.459]  Step 142002  [3.457 sec/step, loss=0.08766, avg_loss=0.09669, mel_loss=0.03927, linear_loss=0.04839]
[2020-05-11 18:02:06.581]  Step 142003  [3.425 sec/step, loss=0.10191, avg_loss=0.09666, mel_loss=0.04748, linear_loss=0.05443]
[2020-05-11 18:02:09.981]  Step 142004  [3.445 sec/step, loss=0.10508, avg_loss=0.09680, mel_loss=0.04928, linear_loss=0.05579]
[2020-05-11 18:02:16.092]  Step 142005  [3.464 sec/step, loss=0.10428, avg_loss=0.09681, mel_loss=0.04976, linear_loss=0.05452]
[2020-05-11 18:02:16.633]  Step 142006  [3.447 sec/step, loss=0.07933, avg_loss=0.09663, mel_loss=0.03672, linear_loss=0.04261]
[2020-05-11 18:02:18.832]  Step 142007  [3.433 sec/step, loss=0.10005, avg_loss=0.09659, mel_loss=0.04598, linear_loss=0.05406]
[2020-05-11 18:02:20.894]  Step 142008  [3.389 sec/step, loss=0.09835, avg_loss=0.09656, mel_loss=0.04494, linear_loss=0.05341]
[2020-05-11 18:02:21.610]  Step 142009  [3.322 sec/step, loss=0.08501, avg_loss=0.09637, mel_loss=0.03914, linear_loss=0.04587]
[2020-05-11 18:02:27.113]  Step 142010  [3.366 sec/step, loss=0.10306, avg_loss=0.09649, mel_loss=0.04852, linear_loss=0.05455]
[2020-05-11 18:02:28.668]  Step 142011  [3.373 sec/step, loss=0.09837, avg_loss=0.09664, mel_loss=0.04501, linear_loss=0.05337]
[2020-05-11 18:02:29.685]  Step 142012  [3.333 sec/step, loss=0.08812, avg_loss=0.09651, mel_loss=0.03997, linear_loss=0.04815]
[2020-05-11 18:02:31.722]  Step 142013  [3.333 sec/step, loss=0.09604, avg_loss=0.09649, mel_loss=0.04387, linear_loss=0.05217]
[2020-05-11 18:02:35.084]  Step 142014  [3.355 sec/step, loss=0.10247, avg_loss=0.09659, mel_loss=0.04760, linear_loss=0.05487]
[2020-05-11 18:02:43.526]  Step 142015  [3.422 sec/step, loss=0.10076, avg_loss=0.09663, mel_loss=0.04845, linear_loss=0.05232]
[2020-05-11 18:02:45.265]  Step 142016  [3.424 sec/step, loss=0.09651, avg_loss=0.09664, mel_loss=0.04367, linear_loss=0.05285]
[2020-05-11 18:02:52.027]  Step 142017  [3.486 sec/step, loss=0.10576, avg_loss=0.09686, mel_loss=0.05025, linear_loss=0.05551]
[2020-05-11 18:02:53.336]  Step 142018  [3.480 sec/step, loss=0.09378, avg_loss=0.09684, mel_loss=0.04266, linear_loss=0.05111]
[2020-05-11 18:02:56.356]  Step 142019  [3.455 sec/step, loss=0.10229, avg_loss=0.09682, mel_loss=0.04729, linear_loss=0.05501]
[2020-05-11 18:02:58.075]  Generated 32 batches of size 32 in 1.714 sec
[2020-05-11 18:02:58.270]  Step 142020  [3.427 sec/step, loss=0.09637, avg_loss=0.09675, mel_loss=0.04421, linear_loss=0.05217]
[2020-05-11 18:03:01.737]  Step 142021  [3.454 sec/step, loss=0.10426, avg_loss=0.09700, mel_loss=0.04831, linear_loss=0.05595]
[2020-05-11 18:03:05.867]  Step 142022  [3.474 sec/step, loss=0.10367, avg_loss=0.09706, mel_loss=0.04857, linear_loss=0.05511]
[2020-05-11 18:03:06.677]  Step 142023  [3.469 sec/step, loss=0.08104, avg_loss=0.09696, mel_loss=0.03619, linear_loss=0.04485]
[2020-05-11 18:03:07.782]  Step 142024  [3.456 sec/step, loss=0.09109, avg_loss=0.09687, mel_loss=0.04092, linear_loss=0.05016]
[2020-05-11 18:03:10.660]  Step 142025  [3.454 sec/step, loss=0.10056, avg_loss=0.09686, mel_loss=0.04662, linear_loss=0.05394]
[2020-05-11 18:03:11.874]  Step 142026  [3.378 sec/step, loss=0.09076, avg_loss=0.09672, mel_loss=0.04062, linear_loss=0.05015]
[2020-05-11 18:03:16.856]  Step 142027  [3.394 sec/step, loss=0.10381, avg_loss=0.09674, mel_loss=0.04914, linear_loss=0.05468]
[2020-05-11 18:03:18.176]  Step 142028  [3.379 sec/step, loss=0.09553, avg_loss=0.09668, mel_loss=0.04356, linear_loss=0.05197]
[2020-05-11 18:03:19.139]  Step 142029  [3.379 sec/step, loss=0.08815, avg_loss=0.09666, mel_loss=0.03950, linear_loss=0.04865]
[2020-05-11 18:03:23.232]  Step 142030  [3.389 sec/step, loss=0.10232, avg_loss=0.09664, mel_loss=0.04752, linear_loss=0.05480]
[2020-05-11 18:03:24.541]  Step 142031  [3.389 sec/step, loss=0.09343, avg_loss=0.09664, mel_loss=0.04181, linear_loss=0.05161]
[2020-05-11 18:03:27.291]  Step 142032  [3.389 sec/step, loss=0.09892, avg_loss=0.09663, mel_loss=0.04580, linear_loss=0.05312]
[2020-05-11 18:03:28.690]  Step 142033  [3.369 sec/step, loss=0.09242, avg_loss=0.09654, mel_loss=0.04197, linear_loss=0.05045]
[2020-05-11 18:03:35.455]  Step 142034  [3.420 sec/step, loss=0.10355, avg_loss=0.09661, mel_loss=0.04914, linear_loss=0.05440]
[2020-05-11 18:03:37.320]  Step 142035  [3.430 sec/step, loss=0.09823, avg_loss=0.09675, mel_loss=0.04465, linear_loss=0.05359]
[2020-05-11 18:03:40.252]  Step 142036  [3.316 sec/step, loss=0.10262, avg_loss=0.09695, mel_loss=0.04717, linear_loss=0.05544]
[2020-05-11 18:03:41.034]  Step 142037  [3.286 sec/step, loss=0.08723, avg_loss=0.09679, mel_loss=0.03926, linear_loss=0.04797]
[2020-05-11 18:03:42.705]  Step 142038  [3.294 sec/step, loss=0.09510, avg_loss=0.09689, mel_loss=0.04358, linear_loss=0.05153]
[2020-05-11 18:03:43.784]  Step 142039  [3.284 sec/step, loss=0.09000, avg_loss=0.09680, mel_loss=0.04045, linear_loss=0.04955]
[2020-05-11 18:03:49.927]  Step 142040  [3.279 sec/step, loss=0.10533, avg_loss=0.09680, mel_loss=0.04973, linear_loss=0.05561]
[2020-05-11 18:03:51.142]  Step 142041  [3.242 sec/step, loss=0.08777, avg_loss=0.09666, mel_loss=0.03931, linear_loss=0.04847]
[2020-05-11 18:04:08.327]  Step 142042  [3.371 sec/step, loss=0.08218, avg_loss=0.09646, mel_loss=0.04005, linear_loss=0.04212]
[2020-05-11 18:04:16.313]  Step 142043  [3.438 sec/step, loss=0.10469, avg_loss=0.09659, mel_loss=0.05003, linear_loss=0.05465]
[2020-05-11 18:04:19.473]  Step 142044  [3.452 sec/step, loss=0.10269, avg_loss=0.09666, mel_loss=0.04760, linear_loss=0.05509]
[2020-05-11 18:04:21.681]  Step 142045  [3.463 sec/step, loss=0.09761, avg_loss=0.09674, mel_loss=0.04483, linear_loss=0.05278]
[2020-05-11 18:04:25.119]  Step 142046  [3.443 sec/step, loss=0.10266, avg_loss=0.09671, mel_loss=0.04735, linear_loss=0.05530]
[2020-05-11 18:04:26.660]  Step 142047  [3.431 sec/step, loss=0.09505, avg_loss=0.09667, mel_loss=0.04335, linear_loss=0.05170]
[2020-05-11 18:04:35.486]  Step 142048  [3.509 sec/step, loss=0.10253, avg_loss=0.09681, mel_loss=0.04904, linear_loss=0.05349]
[2020-05-11 18:04:39.156]  Step 142049  [3.522 sec/step, loss=0.10402, avg_loss=0.09684, mel_loss=0.04865, linear_loss=0.05537]
[2020-05-11 18:04:41.546]  Step 142050  [3.527 sec/step, loss=0.09958, avg_loss=0.09686, mel_loss=0.04557, linear_loss=0.05401]
[2020-05-11 18:04:41.546]  Writing summary at step: 142050
[2020-05-11 18:04:42.701]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142050
[2020-05-11 18:04:44.007]  Saving audio and alignment...
[2020-05-11 18:04:46.174]  Input: 반미~_____________________________
[2020-05-11 18:04:46.301]  Generated 32 batches of size 32 in 1.768 sec
[2020-05-11 18:04:48.684]  Step 142051  [3.504 sec/step, loss=0.09909, avg_loss=0.09679, mel_loss=0.04535, linear_loss=0.05374]
[2020-05-11 18:04:53.334]  Step 142052  [3.494 sec/step, loss=0.10343, avg_loss=0.09677, mel_loss=0.04859, linear_loss=0.05484]
[2020-05-11 18:04:55.091]  Step 142053  [3.478 sec/step, loss=0.09626, avg_loss=0.09671, mel_loss=0.04335, linear_loss=0.05290]
[2020-05-11 18:04:57.099]  Step 142054  [3.485 sec/step, loss=0.09835, avg_loss=0.09676, mel_loss=0.04505, linear_loss=0.05330]
[2020-05-11 18:05:01.357]  Step 142055  [3.393 sec/step, loss=0.10466, avg_loss=0.09694, mel_loss=0.04903, linear_loss=0.05563]
[2020-05-11 18:05:01.921]  Step 142056  [3.373 sec/step, loss=0.07881, avg_loss=0.09675, mel_loss=0.03628, linear_loss=0.04253]
[2020-05-11 18:05:05.346]  Step 142057  [3.397 sec/step, loss=0.10320, avg_loss=0.09691, mel_loss=0.04794, linear_loss=0.05526]
[2020-05-11 18:05:10.517]  Step 142058  [3.431 sec/step, loss=0.10339, avg_loss=0.09698, mel_loss=0.04852, linear_loss=0.05487]
[2020-05-11 18:05:13.314]  Step 142059  [3.439 sec/step, loss=0.09998, avg_loss=0.09702, mel_loss=0.04600, linear_loss=0.05397]
[2020-05-11 18:05:17.714]  Step 142060  [3.469 sec/step, loss=0.10433, avg_loss=0.09712, mel_loss=0.04868, linear_loss=0.05565]
[2020-05-11 18:05:19.021]  Step 142061  [3.467 sec/step, loss=0.09343, avg_loss=0.09711, mel_loss=0.04213, linear_loss=0.05130]
[2020-05-11 18:05:23.204]  Step 142062  [3.501 sec/step, loss=0.10052, avg_loss=0.09726, mel_loss=0.04695, linear_loss=0.05357]
[2020-05-11 18:05:24.796]  Step 142063  [3.443 sec/step, loss=0.09439, avg_loss=0.09713, mel_loss=0.04295, linear_loss=0.05144]
[2020-05-11 18:05:26.782]  Step 142064  [3.427 sec/step, loss=0.09835, avg_loss=0.09708, mel_loss=0.04475, linear_loss=0.05360]
[2020-05-11 18:05:28.943]  Step 142065  [3.415 sec/step, loss=0.09763, avg_loss=0.09706, mel_loss=0.04463, linear_loss=0.05300]
[2020-05-11 18:05:30.684]  Step 142066  [3.403 sec/step, loss=0.09617, avg_loss=0.09698, mel_loss=0.04332, linear_loss=0.05285]
[2020-05-11 18:05:33.592]  Step 142067  [3.290 sec/step, loss=0.10391, avg_loss=0.09721, mel_loss=0.04792, linear_loss=0.05599]
[2020-05-11 18:05:37.044]  Step 142068  [3.232 sec/step, loss=0.09933, avg_loss=0.09713, mel_loss=0.04559, linear_loss=0.05374]
[2020-05-11 18:05:38.958]  Step 142069  [3.220 sec/step, loss=0.09783, avg_loss=0.09713, mel_loss=0.04477, linear_loss=0.05307]
[2020-05-11 18:05:44.127]  Step 142070  [3.248 sec/step, loss=0.10464, avg_loss=0.09721, mel_loss=0.04923, linear_loss=0.05540]
[2020-05-11 18:05:46.594]  Step 142071  [3.240 sec/step, loss=0.09697, avg_loss=0.09721, mel_loss=0.04423, linear_loss=0.05275]
[2020-05-11 18:05:59.775]  Step 142072  [3.285 sec/step, loss=0.08431, avg_loss=0.09699, mel_loss=0.04076, linear_loss=0.04355]
[2020-05-11 18:06:01.133]  Step 142073  [3.269 sec/step, loss=0.09599, avg_loss=0.09693, mel_loss=0.04336, linear_loss=0.05263]
[2020-05-11 18:06:03.424]  Step 142074  [3.278 sec/step, loss=0.09937, avg_loss=0.09703, mel_loss=0.04591, linear_loss=0.05346]
[2020-05-11 18:06:07.126]  Step 142075  [3.307 sec/step, loss=0.10271, avg_loss=0.09719, mel_loss=0.04795, linear_loss=0.05476]
[2020-05-11 18:06:08.236]  Step 142076  [3.281 sec/step, loss=0.09199, avg_loss=0.09706, mel_loss=0.04140, linear_loss=0.05059]
[2020-05-11 18:06:16.015]  Step 142077  [3.327 sec/step, loss=0.10110, avg_loss=0.09703, mel_loss=0.04839, linear_loss=0.05271]
[2020-05-11 18:06:16.590]  Step 142078  [3.315 sec/step, loss=0.07865, avg_loss=0.09687, mel_loss=0.03592, linear_loss=0.04274]
[2020-05-11 18:06:20.035]  Step 142079  [3.331 sec/step, loss=0.10238, avg_loss=0.09695, mel_loss=0.04747, linear_loss=0.05492]
[2020-05-11 18:06:23.138]  Step 142080  [3.350 sec/step, loss=0.10280, avg_loss=0.09709, mel_loss=0.04762, linear_loss=0.05519]
[2020-05-11 18:06:30.354]  Step 142081  [3.389 sec/step, loss=0.10408, avg_loss=0.09712, mel_loss=0.04969, linear_loss=0.05439]
[2020-05-11 18:06:31.665]  Step 142082  [3.377 sec/step, loss=0.09261, avg_loss=0.09708, mel_loss=0.04185, linear_loss=0.05076]
[2020-05-11 18:06:32.244]  Generated 32 batches of size 32 in 1.884 sec
[2020-05-11 18:06:32.375]  Step 142083  [3.330 sec/step, loss=0.07812, avg_loss=0.09683, mel_loss=0.03532, linear_loss=0.04280]
[2020-05-11 18:06:37.154]  Step 142084  [3.319 sec/step, loss=0.10131, avg_loss=0.09680, mel_loss=0.04757, linear_loss=0.05374]
[2020-05-11 18:06:37.946]  Step 142085  [3.235 sec/step, loss=0.08535, avg_loss=0.09661, mel_loss=0.03863, linear_loss=0.04672]
[2020-05-11 18:06:39.767]  Step 142086  [3.243 sec/step, loss=0.09550, avg_loss=0.09671, mel_loss=0.04319, linear_loss=0.05231]
[2020-05-11 18:06:40.793]  Step 142087  [3.245 sec/step, loss=0.08881, avg_loss=0.09682, mel_loss=0.03985, linear_loss=0.04896]
[2020-05-11 18:06:41.692]  Step 142088  [3.228 sec/step, loss=0.08805, avg_loss=0.09670, mel_loss=0.03956, linear_loss=0.04849]
[2020-05-11 18:06:47.370]  Step 142089  [3.275 sec/step, loss=0.10442, avg_loss=0.09687, mel_loss=0.04939, linear_loss=0.05503]
[2020-05-11 18:06:48.953]  Step 142090  [3.243 sec/step, loss=0.09623, avg_loss=0.09680, mel_loss=0.04351, linear_loss=0.05273]
[2020-05-11 18:06:51.431]  Step 142091  [3.252 sec/step, loss=0.09861, avg_loss=0.09683, mel_loss=0.04520, linear_loss=0.05341]
[2020-05-11 18:06:53.442]  Step 142092  [3.265 sec/step, loss=0.09809, avg_loss=0.09704, mel_loss=0.04460, linear_loss=0.05349]
[2020-05-11 18:06:55.043]  Step 142093  [3.238 sec/step, loss=0.09702, avg_loss=0.09697, mel_loss=0.04424, linear_loss=0.05278]
[2020-05-11 18:06:56.125]  Step 142094  [3.235 sec/step, loss=0.08781, avg_loss=0.09691, mel_loss=0.03911, linear_loss=0.04869]
[2020-05-11 18:06:59.033]  Step 142095  [3.223 sec/step, loss=0.09946, avg_loss=0.09688, mel_loss=0.04621, linear_loss=0.05325]
[2020-05-11 18:07:07.762]  Step 142096  [3.287 sec/step, loss=0.10338, avg_loss=0.09693, mel_loss=0.04955, linear_loss=0.05383]
[2020-05-11 18:07:09.482]  Step 142097  [3.269 sec/step, loss=0.09658, avg_loss=0.09690, mel_loss=0.04376, linear_loss=0.05282]
[2020-05-11 18:07:10.284]  Step 142098  [3.249 sec/step, loss=0.08278, avg_loss=0.09674, mel_loss=0.03718, linear_loss=0.04560]
[2020-05-11 18:07:13.892]  Step 142099  [3.238 sec/step, loss=0.10388, avg_loss=0.09674, mel_loss=0.04827, linear_loss=0.05562]
[2020-05-11 18:07:14.457]  Step 142100  [3.110 sec/step, loss=0.07578, avg_loss=0.09663, mel_loss=0.03462, linear_loss=0.04116]
[2020-05-11 18:07:14.457]  Writing summary at step: 142100
[2020-05-11 18:07:18.433]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142100
[2020-05-11 18:07:19.734]  Saving audio and alignment...
[2020-05-11 18:07:24.079]  Input: 백일달러 달러 육십사센트를 기록했다고 밝혔습~
[2020-05-11 18:07:31.394]  Step 142101  [3.155 sec/step, loss=0.10472, avg_loss=0.09669, mel_loss=0.04991, linear_loss=0.05481]
[2020-05-11 18:07:45.377]  Step 142102  [3.286 sec/step, loss=0.08026, avg_loss=0.09661, mel_loss=0.03940, linear_loss=0.04086]
[2020-05-11 18:07:51.138]  Step 142103  [3.303 sec/step, loss=0.10638, avg_loss=0.09666, mel_loss=0.05044, linear_loss=0.05594]
[2020-05-11 18:07:52.536]  Step 142104  [3.283 sec/step, loss=0.09323, avg_loss=0.09654, mel_loss=0.04237, linear_loss=0.05087]
[2020-05-11 18:07:54.112]  Step 142105  [3.237 sec/step, loss=0.09452, avg_loss=0.09644, mel_loss=0.04300, linear_loss=0.05152]
[2020-05-11 18:07:57.472]  Step 142106  [3.266 sec/step, loss=0.10074, avg_loss=0.09665, mel_loss=0.04676, linear_loss=0.05398]
[2020-05-11 18:08:02.855]  Step 142107  [3.297 sec/step, loss=0.10340, avg_loss=0.09669, mel_loss=0.04867, linear_loss=0.05473]
[2020-05-11 18:08:05.959]  Step 142108  [3.308 sec/step, loss=0.10210, avg_loss=0.09673, mel_loss=0.04714, linear_loss=0.05497]
[2020-05-11 18:08:09.323]  Step 142109  [3.334 sec/step, loss=0.10423, avg_loss=0.09692, mel_loss=0.04842, linear_loss=0.05581]
[2020-05-11 18:08:11.476]  Step 142110  [3.301 sec/step, loss=0.09995, avg_loss=0.09689, mel_loss=0.04625, linear_loss=0.05370]
[2020-05-11 18:08:15.929]  Step 142111  [3.330 sec/step, loss=0.10385, avg_loss=0.09694, mel_loss=0.04905, linear_loss=0.05480]
[2020-05-11 18:08:17.298]  Step 142112  [3.333 sec/step, loss=0.08983, avg_loss=0.09696, mel_loss=0.04086, linear_loss=0.04897]
[2020-05-11 18:08:17.651]  Generated 32 batches of size 32 in 1.717 sec
[2020-05-11 18:08:18.287]  Step 142113  [3.323 sec/step, loss=0.09100, avg_loss=0.09691, mel_loss=0.04118, linear_loss=0.04982]
[2020-05-11 18:08:20.597]  Step 142114  [3.312 sec/step, loss=0.09889, avg_loss=0.09687, mel_loss=0.04495, linear_loss=0.05395]
[2020-05-11 18:08:21.769]  Step 142115  [3.240 sec/step, loss=0.09081, avg_loss=0.09677, mel_loss=0.04098, linear_loss=0.04983]
[2020-05-11 18:08:26.646]  Step 142116  [3.271 sec/step, loss=0.10209, avg_loss=0.09683, mel_loss=0.04769, linear_loss=0.05440]
[2020-05-11 18:08:27.463]  Step 142117  [3.212 sec/step, loss=0.08418, avg_loss=0.09661, mel_loss=0.03772, linear_loss=0.04646]
[2020-05-11 18:08:34.221]  Step 142118  [3.266 sec/step, loss=0.10550, avg_loss=0.09673, mel_loss=0.05002, linear_loss=0.05548]
[2020-05-11 18:08:35.236]  Step 142119  [3.246 sec/step, loss=0.08586, avg_loss=0.09657, mel_loss=0.03838, linear_loss=0.04747]
[2020-05-11 18:08:37.141]  Step 142120  [3.246 sec/step, loss=0.09724, avg_loss=0.09657, mel_loss=0.04398, linear_loss=0.05326]
[2020-05-11 18:08:38.209]  Step 142121  [3.222 sec/step, loss=0.09196, avg_loss=0.09645, mel_loss=0.04099, linear_loss=0.05097]
[2020-05-11 18:08:43.708]  Step 142122  [3.236 sec/step, loss=0.10404, avg_loss=0.09645, mel_loss=0.04900, linear_loss=0.05504]
[2020-05-11 18:08:44.521]  Step 142123  [3.236 sec/step, loss=0.08682, avg_loss=0.09651, mel_loss=0.03899, linear_loss=0.04782]
[2020-05-11 18:08:47.527]  Step 142124  [3.255 sec/step, loss=0.10325, avg_loss=0.09663, mel_loss=0.04784, linear_loss=0.05541]
[2020-05-11 18:08:52.397]  Step 142125  [3.275 sec/step, loss=0.10192, avg_loss=0.09665, mel_loss=0.04753, linear_loss=0.05439]
[2020-05-11 18:08:53.407]  Step 142126  [3.273 sec/step, loss=0.08809, avg_loss=0.09662, mel_loss=0.03912, linear_loss=0.04897]
[2020-05-11 18:08:54.691]  Step 142127  [3.236 sec/step, loss=0.09286, avg_loss=0.09651, mel_loss=0.04197, linear_loss=0.05089]
[2020-05-11 18:09:08.314]  Step 142128  [3.359 sec/step, loss=0.08733, avg_loss=0.09643, mel_loss=0.04247, linear_loss=0.04486]
[2020-05-11 18:09:12.488]  Step 142129  [3.391 sec/step, loss=0.10267, avg_loss=0.09657, mel_loss=0.04770, linear_loss=0.05496]
[2020-05-11 18:09:14.124]  Step 142130  [3.366 sec/step, loss=0.09621, avg_loss=0.09651, mel_loss=0.04375, linear_loss=0.05246]
[2020-05-11 18:09:16.372]  Step 142131  [3.376 sec/step, loss=0.09712, avg_loss=0.09655, mel_loss=0.04419, linear_loss=0.05293]
[2020-05-11 18:09:18.840]  Step 142132  [3.373 sec/step, loss=0.09866, avg_loss=0.09655, mel_loss=0.04511, linear_loss=0.05355]
[2020-05-11 18:09:24.863]  Step 142133  [3.419 sec/step, loss=0.10362, avg_loss=0.09666, mel_loss=0.04914, linear_loss=0.05447]
[2020-05-11 18:09:25.892]  Step 142134  [3.362 sec/step, loss=0.08789, avg_loss=0.09650, mel_loss=0.03965, linear_loss=0.04825]
[2020-05-11 18:09:30.283]  Step 142135  [3.387 sec/step, loss=0.10632, avg_loss=0.09658, mel_loss=0.05010, linear_loss=0.05622]
[2020-05-11 18:09:33.870]  Step 142136  [3.393 sec/step, loss=0.10497, avg_loss=0.09661, mel_loss=0.04880, linear_loss=0.05617]
[2020-05-11 18:09:42.555]  Step 142137  [3.472 sec/step, loss=0.10069, avg_loss=0.09674, mel_loss=0.04840, linear_loss=0.05229]
[2020-05-11 18:09:46.612]  Step 142138  [3.496 sec/step, loss=0.10306, avg_loss=0.09682, mel_loss=0.04818, linear_loss=0.05488]
[2020-05-11 18:09:47.989]  Step 142139  [3.499 sec/step, loss=0.09250, avg_loss=0.09685, mel_loss=0.04184, linear_loss=0.05066]
[2020-05-11 18:09:51.436]  Step 142140  [3.472 sec/step, loss=0.09990, avg_loss=0.09679, mel_loss=0.04624, linear_loss=0.05365]
[2020-05-11 18:09:53.174]  Step 142141  [3.478 sec/step, loss=0.09611, avg_loss=0.09688, mel_loss=0.04352, linear_loss=0.05260]
[2020-05-11 18:09:54.310]  Step 142142  [3.317 sec/step, loss=0.09018, avg_loss=0.09696, mel_loss=0.04037, linear_loss=0.04981]
[2020-05-11 18:09:57.563]  Step 142143  [3.270 sec/step, loss=0.10254, avg_loss=0.09693, mel_loss=0.04751, linear_loss=0.05503]
[2020-05-11 18:09:59.317]  Generated 32 batches of size 32 in 1.749 sec
[2020-05-11 18:10:00.503]  Step 142144  [3.268 sec/step, loss=0.10147, avg_loss=0.09692, mel_loss=0.04676, linear_loss=0.05470]
[2020-05-11 18:10:02.938]  Step 142145  [3.270 sec/step, loss=0.09936, avg_loss=0.09694, mel_loss=0.04561, linear_loss=0.05375]
[2020-05-11 18:10:04.820]  Step 142146  [3.254 sec/step, loss=0.09723, avg_loss=0.09689, mel_loss=0.04375, linear_loss=0.05348]
[2020-05-11 18:10:07.530]  Step 142147  [3.266 sec/step, loss=0.09872, avg_loss=0.09692, mel_loss=0.04564, linear_loss=0.05308]
[2020-05-11 18:10:08.270]  Step 142148  [3.185 sec/step, loss=0.07960, avg_loss=0.09669, mel_loss=0.03693, linear_loss=0.04268]
[2020-05-11 18:10:09.765]  Step 142149  [3.163 sec/step, loss=0.09450, avg_loss=0.09660, mel_loss=0.04273, linear_loss=0.05177]
[2020-05-11 18:10:18.799]  Step 142150  [3.230 sec/step, loss=0.10542, avg_loss=0.09666, mel_loss=0.05041, linear_loss=0.05501]
[2020-05-11 18:10:18.799]  Writing summary at step: 142150
[2020-05-11 18:10:21.965]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142150
[2020-05-11 18:10:26.211]  Saving audio and alignment...
[2020-05-11 18:10:28.298]  Input: 되셨습니까~__________
[2020-05-11 18:10:30.613]  Step 142151  [3.228 sec/step, loss=0.09956, avg_loss=0.09666, mel_loss=0.04606, linear_loss=0.05350]
[2020-05-11 18:10:38.643]  Step 142152  [3.262 sec/step, loss=0.10404, avg_loss=0.09667, mel_loss=0.04942, linear_loss=0.05462]
[2020-05-11 18:10:41.051]  Step 142153  [3.268 sec/step, loss=0.09849, avg_loss=0.09669, mel_loss=0.04488, linear_loss=0.05361]
[2020-05-11 18:10:44.156]  Step 142154  [3.279 sec/step, loss=0.10276, avg_loss=0.09673, mel_loss=0.04772, linear_loss=0.05505]
[2020-05-11 18:10:46.871]  Step 142155  [3.264 sec/step, loss=0.09991, avg_loss=0.09669, mel_loss=0.04627, linear_loss=0.05364]
[2020-05-11 18:10:48.429]  Step 142156  [3.274 sec/step, loss=0.09382, avg_loss=0.09684, mel_loss=0.04291, linear_loss=0.05092]
[2020-05-11 18:10:53.814]  Step 142157  [3.293 sec/step, loss=0.10712, avg_loss=0.09688, mel_loss=0.05064, linear_loss=0.05648]
[2020-05-11 18:10:58.289]  Step 142158  [3.286 sec/step, loss=0.10174, avg_loss=0.09686, mel_loss=0.04753, linear_loss=0.05421]
[2020-05-11 18:11:12.616]  Step 142159  [3.402 sec/step, loss=0.08186, avg_loss=0.09668, mel_loss=0.03991, linear_loss=0.04195]
[2020-05-11 18:11:13.359]  Step 142160  [3.365 sec/step, loss=0.08712, avg_loss=0.09651, mel_loss=0.03878, linear_loss=0.04834]
[2020-05-11 18:11:20.049]  Step 142161  [3.419 sec/step, loss=0.10539, avg_loss=0.09663, mel_loss=0.05012, linear_loss=0.05527]
[2020-05-11 18:11:23.490]  Step 142162  [3.411 sec/step, loss=0.10101, avg_loss=0.09663, mel_loss=0.04684, linear_loss=0.05417]
[2020-05-11 18:11:24.599]  Step 142163  [3.407 sec/step, loss=0.09123, avg_loss=0.09660, mel_loss=0.04086, linear_loss=0.05036]
[2020-05-11 18:11:25.159]  Step 142164  [3.392 sec/step, loss=0.07670, avg_loss=0.09638, mel_loss=0.03516, linear_loss=0.04154]
[2020-05-11 18:11:26.759]  Step 142165  [3.387 sec/step, loss=0.09856, avg_loss=0.09639, mel_loss=0.04456, linear_loss=0.05400]
[2020-05-11 18:11:35.477]  Step 142166  [3.456 sec/step, loss=0.10546, avg_loss=0.09648, mel_loss=0.05060, linear_loss=0.05486]
[2020-05-11 18:11:37.361]  Step 142167  [3.446 sec/step, loss=0.09584, avg_loss=0.09640, mel_loss=0.04351, linear_loss=0.05233]
[2020-05-11 18:11:41.532]  Step 142168  [3.453 sec/step, loss=0.10293, avg_loss=0.09644, mel_loss=0.04786, linear_loss=0.05507]
[2020-05-11 18:11:42.284]  Step 142169  [3.442 sec/step, loss=0.08314, avg_loss=0.09629, mel_loss=0.03732, linear_loss=0.04582]
[2020-05-11 18:11:44.298]  Step 142170  [3.410 sec/step, loss=0.09658, avg_loss=0.09621, mel_loss=0.04418, linear_loss=0.05240]
[2020-05-11 18:11:46.586]  Step 142171  [3.408 sec/step, loss=0.09766, avg_loss=0.09622, mel_loss=0.04499, linear_loss=0.05267]
[2020-05-11 18:11:51.436]  Step 142172  [3.325 sec/step, loss=0.10255, avg_loss=0.09640, mel_loss=0.04824, linear_loss=0.05431]
[2020-05-11 18:11:52.653]  Step 142173  [3.324 sec/step, loss=0.09339, avg_loss=0.09638, mel_loss=0.04243, linear_loss=0.05096]
[2020-05-11 18:11:54.377]  Generated 32 batches of size 32 in 1.719 sec
[2020-05-11 18:11:56.357]  Step 142174  [3.338 sec/step, loss=0.10359, avg_loss=0.09642, mel_loss=0.04820, linear_loss=0.05539]
[2020-05-11 18:11:59.249]  Step 142175  [3.330 sec/step, loss=0.10049, avg_loss=0.09640, mel_loss=0.04664, linear_loss=0.05386]
[2020-05-11 18:12:04.906]  Step 142176  [3.375 sec/step, loss=0.10526, avg_loss=0.09653, mel_loss=0.04985, linear_loss=0.05541]
[2020-05-11 18:12:05.851]  Step 142177  [3.307 sec/step, loss=0.08768, avg_loss=0.09639, mel_loss=0.03965, linear_loss=0.04802]
[2020-05-11 18:12:06.753]  Step 142178  [3.310 sec/step, loss=0.08267, avg_loss=0.09643, mel_loss=0.03686, linear_loss=0.04581]
[2020-05-11 18:12:08.087]  Step 142179  [3.289 sec/step, loss=0.09150, avg_loss=0.09633, mel_loss=0.04128, linear_loss=0.05022]
[2020-05-11 18:12:09.835]  Step 142180  [3.276 sec/step, loss=0.09619, avg_loss=0.09626, mel_loss=0.04351, linear_loss=0.05268]
[2020-05-11 18:12:13.275]  Step 142181  [3.238 sec/step, loss=0.10047, avg_loss=0.09622, mel_loss=0.04660, linear_loss=0.05387]
[2020-05-11 18:12:14.643]  Step 142182  [3.238 sec/step, loss=0.09434, avg_loss=0.09624, mel_loss=0.04289, linear_loss=0.05145]
[2020-05-11 18:12:17.367]  Step 142183  [3.258 sec/step, loss=0.09800, avg_loss=0.09644, mel_loss=0.04513, linear_loss=0.05287]
[2020-05-11 18:12:20.503]  Step 142184  [3.242 sec/step, loss=0.10174, avg_loss=0.09644, mel_loss=0.04709, linear_loss=0.05465]
[2020-05-11 18:12:26.846]  Step 142185  [3.298 sec/step, loss=0.10492, avg_loss=0.09664, mel_loss=0.04972, linear_loss=0.05520]
[2020-05-11 18:12:27.799]  Step 142186  [3.289 sec/step, loss=0.08869, avg_loss=0.09657, mel_loss=0.03938, linear_loss=0.04931]
[2020-05-11 18:12:29.894]  Step 142187  [3.300 sec/step, loss=0.09727, avg_loss=0.09666, mel_loss=0.04450, linear_loss=0.05277]
[2020-05-11 18:12:30.931]  Step 142188  [3.301 sec/step, loss=0.09068, avg_loss=0.09668, mel_loss=0.04075, linear_loss=0.04994]
[2020-05-11 18:12:32.506]  Step 142189  [3.260 sec/step, loss=0.09560, avg_loss=0.09659, mel_loss=0.04328, linear_loss=0.05232]
[2020-05-11 18:12:33.053]  Step 142190  [3.250 sec/step, loss=0.07496, avg_loss=0.09638, mel_loss=0.03442, linear_loss=0.04054]
[2020-05-11 18:12:34.338]  Step 142191  [3.238 sec/step, loss=0.09327, avg_loss=0.09633, mel_loss=0.04187, linear_loss=0.05141]
[2020-05-11 18:12:37.779]  Step 142192  [3.252 sec/step, loss=0.09986, avg_loss=0.09635, mel_loss=0.04625, linear_loss=0.05361]
[2020-05-11 18:12:39.670]  Step 142193  [3.255 sec/step, loss=0.09712, avg_loss=0.09635, mel_loss=0.04380, linear_loss=0.05331]
[2020-05-11 18:12:45.264]  Step 142194  [3.300 sec/step, loss=0.10443, avg_loss=0.09651, mel_loss=0.04931, linear_loss=0.05512]
[2020-05-11 18:12:54.085]  Step 142195  [3.359 sec/step, loss=0.10354, avg_loss=0.09655, mel_loss=0.04947, linear_loss=0.05407]
[2020-05-11 18:12:56.251]  Step 142196  [3.293 sec/step, loss=0.09668, avg_loss=0.09649, mel_loss=0.04421, linear_loss=0.05247]
[2020-05-11 18:12:58.262]  Step 142197  [3.296 sec/step, loss=0.09853, avg_loss=0.09651, mel_loss=0.04509, linear_loss=0.05344]
[2020-05-11 18:13:00.012]  Step 142198  [3.306 sec/step, loss=0.09550, avg_loss=0.09663, mel_loss=0.04333, linear_loss=0.05216]
[2020-05-11 18:13:00.795]  Step 142199  [3.278 sec/step, loss=0.08285, avg_loss=0.09642, mel_loss=0.03724, linear_loss=0.04561]
[2020-05-11 18:13:04.010]  Step 142200  [3.304 sec/step, loss=0.10145, avg_loss=0.09668, mel_loss=0.04717, linear_loss=0.05428]
[2020-05-11 18:13:04.010]  Writing summary at step: 142200
[2020-05-11 18:13:06.454]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142200
[2020-05-11 18:13:07.754]  Saving audio and alignment...
[2020-05-11 18:13:17.826]  Input: 으음 저는 예전에 어떤 음악회 행사 진행 그리고 대본 작성을 함께 만든 적이 있는데요~_____________________________________________
[2020-05-11 18:13:19.326]  Step 142201  [3.246 sec/step, loss=0.09406, avg_loss=0.09657, mel_loss=0.04250, linear_loss=0.05156]
[2020-05-11 18:13:23.714]  Step 142202  [3.150 sec/step, loss=0.10373, avg_loss=0.09681, mel_loss=0.04878, linear_loss=0.05495]
[2020-05-11 18:13:24.347]  Step 142203  [3.099 sec/step, loss=0.08033, avg_loss=0.09655, mel_loss=0.03666, linear_loss=0.04367]
[2020-05-11 18:13:26.344]  Generated 32 batches of size 32 in 1.992 sec
[2020-05-11 18:13:29.103]  Step 142204  [3.132 sec/step, loss=0.10336, avg_loss=0.09665, mel_loss=0.04817, linear_loss=0.05519]
[2020-05-11 18:13:34.363]  Step 142205  [3.169 sec/step, loss=0.10309, avg_loss=0.09673, mel_loss=0.04828, linear_loss=0.05481]
[2020-05-11 18:13:37.992]  Step 142206  [3.172 sec/step, loss=0.10367, avg_loss=0.09676, mel_loss=0.04841, linear_loss=0.05526]
[2020-05-11 18:13:51.946]  Step 142207  [3.258 sec/step, loss=0.08120, avg_loss=0.09654, mel_loss=0.03979, linear_loss=0.04141]
[2020-05-11 18:13:54.825]  Step 142208  [3.255 sec/step, loss=0.10233, avg_loss=0.09654, mel_loss=0.04712, linear_loss=0.05522]
[2020-05-11 18:13:55.795]  Step 142209  [3.231 sec/step, loss=0.08975, avg_loss=0.09640, mel_loss=0.04030, linear_loss=0.04945]
[2020-05-11 18:13:56.952]  Step 142210  [3.221 sec/step, loss=0.08717, avg_loss=0.09627, mel_loss=0.03906, linear_loss=0.04811]
[2020-05-11 18:14:01.095]  Step 142211  [3.218 sec/step, loss=0.10246, avg_loss=0.09626, mel_loss=0.04759, linear_loss=0.05487]
[2020-05-11 18:14:02.443]  Step 142212  [3.218 sec/step, loss=0.09554, avg_loss=0.09631, mel_loss=0.04352, linear_loss=0.05201]
[2020-05-11 18:14:07.374]  Step 142213  [3.257 sec/step, loss=0.10152, avg_loss=0.09642, mel_loss=0.04757, linear_loss=0.05395]
[2020-05-11 18:14:10.981]  Step 142214  [3.270 sec/step, loss=0.10267, avg_loss=0.09646, mel_loss=0.04768, linear_loss=0.05498]
[2020-05-11 18:14:11.852]  Step 142215  [3.267 sec/step, loss=0.08291, avg_loss=0.09638, mel_loss=0.03707, linear_loss=0.04584]
[2020-05-11 18:14:14.002]  Step 142216  [3.240 sec/step, loss=0.09834, avg_loss=0.09634, mel_loss=0.04487, linear_loss=0.05347]
[2020-05-11 18:14:14.873]  Step 142217  [3.241 sec/step, loss=0.08307, avg_loss=0.09633, mel_loss=0.03706, linear_loss=0.04601]
[2020-05-11 18:14:23.564]  Step 142218  [3.260 sec/step, loss=0.10090, avg_loss=0.09628, mel_loss=0.04816, linear_loss=0.05274]
[2020-05-11 18:14:25.114]  Step 142219  [3.265 sec/step, loss=0.09218, avg_loss=0.09635, mel_loss=0.04201, linear_loss=0.05016]
[2020-05-11 18:14:26.782]  Step 142220  [3.263 sec/step, loss=0.09669, avg_loss=0.09634, mel_loss=0.04394, linear_loss=0.05275]
[2020-05-11 18:14:31.233]  Step 142221  [3.297 sec/step, loss=0.10571, avg_loss=0.09648, mel_loss=0.04949, linear_loss=0.05622]
[2020-05-11 18:14:38.430]  Step 142222  [3.314 sec/step, loss=0.10602, avg_loss=0.09650, mel_loss=0.05043, linear_loss=0.05558]
[2020-05-11 18:14:40.855]  Step 142223  [3.330 sec/step, loss=0.09977, avg_loss=0.09663, mel_loss=0.04575, linear_loss=0.05402]
[2020-05-11 18:14:44.904]  Step 142224  [3.340 sec/step, loss=0.10027, avg_loss=0.09660, mel_loss=0.04675, linear_loss=0.05352]
[2020-05-11 18:14:48.556]  Step 142225  [3.328 sec/step, loss=0.10453, avg_loss=0.09662, mel_loss=0.04879, linear_loss=0.05575]
[2020-05-11 18:14:50.288]  Step 142226  [3.335 sec/step, loss=0.09726, avg_loss=0.09672, mel_loss=0.04413, linear_loss=0.05314]
[2020-05-11 18:14:51.345]  Step 142227  [3.333 sec/step, loss=0.09192, avg_loss=0.09671, mel_loss=0.04106, linear_loss=0.05086]
[2020-05-11 18:14:54.170]  Step 142228  [3.225 sec/step, loss=0.09996, avg_loss=0.09683, mel_loss=0.04634, linear_loss=0.05362]
[2020-05-11 18:14:55.415]  Step 142229  [3.196 sec/step, loss=0.09021, avg_loss=0.09671, mel_loss=0.04084, linear_loss=0.04937]
[2020-05-11 18:14:58.816]  Step 142230  [3.214 sec/step, loss=0.10145, avg_loss=0.09676, mel_loss=0.04716, linear_loss=0.05428]
[2020-05-11 18:15:02.263]  Step 142231  [3.226 sec/step, loss=0.10414, avg_loss=0.09683, mel_loss=0.04823, linear_loss=0.05591]
[2020-05-11 18:15:03.159]  Step 142232  [3.210 sec/step, loss=0.08848, avg_loss=0.09673, mel_loss=0.03965, linear_loss=0.04883]
[2020-05-11 18:15:05.647]  Step 142233  [3.174 sec/step, loss=0.09944, avg_loss=0.09669, mel_loss=0.04545, linear_loss=0.05399]
[2020-05-11 18:15:06.642]  Step 142234  [3.174 sec/step, loss=0.09121, avg_loss=0.09672, mel_loss=0.04090, linear_loss=0.05031]
[2020-05-11 18:15:12.444]  Step 142235  [3.188 sec/step, loss=0.10643, avg_loss=0.09672, mel_loss=0.05031, linear_loss=0.05612]
[2020-05-11 18:15:13.878]  Step 142236  [3.167 sec/step, loss=0.09408, avg_loss=0.09661, mel_loss=0.04238, linear_loss=0.05170]
[2020-05-11 18:15:14.169]  Generated 32 batches of size 32 in 1.720 sec
[2020-05-11 18:15:14.659]  Step 142237  [3.088 sec/step, loss=0.08008, avg_loss=0.09641, mel_loss=0.03626, linear_loss=0.04381]
[2020-05-11 18:15:17.644]  Step 142238  [3.077 sec/step, loss=0.10185, avg_loss=0.09639, mel_loss=0.04711, linear_loss=0.05473]
[2020-05-11 18:15:19.830]  Step 142239  [3.085 sec/step, loss=0.09770, avg_loss=0.09645, mel_loss=0.04486, linear_loss=0.05284]
[2020-05-11 18:15:25.375]  Step 142240  [3.106 sec/step, loss=0.10515, avg_loss=0.09650, mel_loss=0.04978, linear_loss=0.05537]
[2020-05-11 18:15:26.992]  Step 142241  [3.105 sec/step, loss=0.09531, avg_loss=0.09649, mel_loss=0.04309, linear_loss=0.05222]
[2020-05-11 18:15:40.074]  Step 142242  [3.224 sec/step, loss=0.08580, avg_loss=0.09645, mel_loss=0.04138, linear_loss=0.04442]
[2020-05-11 18:15:42.641]  Step 142243  [3.217 sec/step, loss=0.10169, avg_loss=0.09644, mel_loss=0.04721, linear_loss=0.05448]
[2020-05-11 18:15:44.552]  Step 142244  [3.207 sec/step, loss=0.09480, avg_loss=0.09637, mel_loss=0.04269, linear_loss=0.05211]
[2020-05-11 18:15:45.354]  Step 142245  [3.191 sec/step, loss=0.08632, avg_loss=0.09624, mel_loss=0.03838, linear_loss=0.04795]
[2020-05-11 18:15:48.921]  Step 142246  [3.208 sec/step, loss=0.10409, avg_loss=0.09631, mel_loss=0.04832, linear_loss=0.05578]
[2020-05-11 18:15:53.103]  Step 142247  [3.222 sec/step, loss=0.10377, avg_loss=0.09636, mel_loss=0.04854, linear_loss=0.05523]
[2020-05-11 18:15:55.217]  Step 142248  [3.236 sec/step, loss=0.09880, avg_loss=0.09655, mel_loss=0.04542, linear_loss=0.05338]
[2020-05-11 18:16:01.804]  Step 142249  [3.287 sec/step, loss=0.10469, avg_loss=0.09665, mel_loss=0.04967, linear_loss=0.05501]
[2020-05-11 18:16:03.990]  Step 142250  [3.219 sec/step, loss=0.09863, avg_loss=0.09659, mel_loss=0.04553, linear_loss=0.05310]
[2020-05-11 18:16:03.990]  Writing summary at step: 142250
[2020-05-11 18:16:07.113]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142250
[2020-05-11 18:16:08.367]  Saving audio and alignment...
[2020-05-11 18:16:11.187]  Input: 종결 어미가 똑같으면 안 됩니다~____
[2020-05-11 18:16:12.602]  Step 142251  [3.210 sec/step, loss=0.09300, avg_loss=0.09652, mel_loss=0.04213, linear_loss=0.05087]
[2020-05-11 18:16:14.212]  Step 142252  [3.145 sec/step, loss=0.09754, avg_loss=0.09646, mel_loss=0.04450, linear_loss=0.05304]
[2020-05-11 18:16:17.498]  Step 142253  [3.154 sec/step, loss=0.10088, avg_loss=0.09648, mel_loss=0.04647, linear_loss=0.05441]
[2020-05-11 18:16:21.981]  Step 142254  [3.168 sec/step, loss=0.10387, avg_loss=0.09649, mel_loss=0.04890, linear_loss=0.05497]
[2020-05-11 18:16:23.341]  Step 142255  [3.154 sec/step, loss=0.09184, avg_loss=0.09641, mel_loss=0.04141, linear_loss=0.05043]
[2020-05-11 18:16:26.703]  Step 142256  [3.172 sec/step, loss=0.10198, avg_loss=0.09649, mel_loss=0.04737, linear_loss=0.05461]
[2020-05-11 18:16:35.429]  Step 142257  [3.206 sec/step, loss=0.10120, avg_loss=0.09643, mel_loss=0.04870, linear_loss=0.05250]
[2020-05-11 18:16:37.425]  Step 142258  [3.181 sec/step, loss=0.09776, avg_loss=0.09639, mel_loss=0.04441, linear_loss=0.05334]
[2020-05-11 18:16:41.178]  Step 142259  [3.075 sec/step, loss=0.10341, avg_loss=0.09661, mel_loss=0.04784, linear_loss=0.05558]
[2020-05-11 18:16:43.758]  Step 142260  [3.094 sec/step, loss=0.09890, avg_loss=0.09673, mel_loss=0.04549, linear_loss=0.05341]
[2020-05-11 18:16:44.964]  Step 142261  [3.039 sec/step, loss=0.09213, avg_loss=0.09659, mel_loss=0.04157, linear_loss=0.05056]
[2020-05-11 18:16:45.750]  Step 142262  [3.012 sec/step, loss=0.08310, avg_loss=0.09641, mel_loss=0.03746, linear_loss=0.04564]
[2020-05-11 18:16:50.629]  Step 142263  [3.050 sec/step, loss=0.10304, avg_loss=0.09653, mel_loss=0.04838, linear_loss=0.05466]
[2020-05-11 18:16:56.141]  Step 142264  [3.099 sec/step, loss=0.10320, avg_loss=0.09680, mel_loss=0.04858, linear_loss=0.05462]
[2020-05-11 18:16:56.700]  Step 142265  [3.089 sec/step, loss=0.07790, avg_loss=0.09659, mel_loss=0.03603, linear_loss=0.04187]
[2020-05-11 18:16:58.568]  Generated 32 batches of size 32 in 1.863 sec
[2020-05-11 18:17:04.205]  Step 142266  [3.077 sec/step, loss=0.10342, avg_loss=0.09657, mel_loss=0.04916, linear_loss=0.05426]
[2020-05-11 18:17:05.307]  Step 142267  [3.069 sec/step, loss=0.08581, avg_loss=0.09647, mel_loss=0.03870, linear_loss=0.04711]
[2020-05-11 18:17:19.124]  Step 142268  [3.166 sec/step, loss=0.08024, avg_loss=0.09624, mel_loss=0.03929, linear_loss=0.04095]
[2020-05-11 18:17:20.112]  Step 142269  [3.168 sec/step, loss=0.08732, avg_loss=0.09629, mel_loss=0.03909, linear_loss=0.04823]
[2020-05-11 18:17:22.558]  Step 142270  [3.172 sec/step, loss=0.09840, avg_loss=0.09630, mel_loss=0.04523, linear_loss=0.05316]
[2020-05-11 18:17:26.014]  Step 142271  [3.184 sec/step, loss=0.10035, avg_loss=0.09633, mel_loss=0.04645, linear_loss=0.05390]
[2020-05-11 18:17:27.129]  Step 142272  [3.147 sec/step, loss=0.09137, avg_loss=0.09622, mel_loss=0.04075, linear_loss=0.05062]
[2020-05-11 18:17:29.026]  Step 142273  [3.153 sec/step, loss=0.09531, avg_loss=0.09624, mel_loss=0.04299, linear_loss=0.05231]
[2020-05-11 18:17:30.750]  Step 142274  [3.134 sec/step, loss=0.09605, avg_loss=0.09616, mel_loss=0.04336, linear_loss=0.05270]
[2020-05-11 18:17:32.729]  Step 142275  [3.124 sec/step, loss=0.09638, avg_loss=0.09612, mel_loss=0.04401, linear_loss=0.05237]
[2020-05-11 18:17:45.676]  Step 142276  [3.197 sec/step, loss=0.08950, avg_loss=0.09596, mel_loss=0.04334, linear_loss=0.04616]
[2020-05-11 18:17:49.409]  Step 142277  [3.225 sec/step, loss=0.10281, avg_loss=0.09612, mel_loss=0.04765, linear_loss=0.05516]
[2020-05-11 18:17:51.145]  Step 142278  [3.234 sec/step, loss=0.09642, avg_loss=0.09625, mel_loss=0.04354, linear_loss=0.05287]
[2020-05-11 18:17:53.583]  Step 142279  [3.245 sec/step, loss=0.09847, avg_loss=0.09632, mel_loss=0.04457, linear_loss=0.05390]
[2020-05-11 18:17:54.570]  Step 142280  [3.237 sec/step, loss=0.08612, avg_loss=0.09622, mel_loss=0.03843, linear_loss=0.04769]
[2020-05-11 18:17:58.791]  Step 142281  [3.245 sec/step, loss=0.10546, avg_loss=0.09627, mel_loss=0.04941, linear_loss=0.05604]
[2020-05-11 18:18:00.898]  Step 142282  [3.252 sec/step, loss=0.09721, avg_loss=0.09630, mel_loss=0.04438, linear_loss=0.05283]
[2020-05-11 18:18:02.125]  Step 142283  [3.237 sec/step, loss=0.09112, avg_loss=0.09623, mel_loss=0.04141, linear_loss=0.04971]
[2020-05-11 18:18:03.220]  Step 142284  [3.217 sec/step, loss=0.09096, avg_loss=0.09612, mel_loss=0.04029, linear_loss=0.05066]
[2020-05-11 18:18:08.052]  Step 142285  [3.202 sec/step, loss=0.10288, avg_loss=0.09610, mel_loss=0.04821, linear_loss=0.05468]
[2020-05-11 18:18:12.246]  Step 142286  [3.234 sec/step, loss=0.10332, avg_loss=0.09625, mel_loss=0.04798, linear_loss=0.05534]
[2020-05-11 18:18:15.823]  Step 142287  [3.249 sec/step, loss=0.10215, avg_loss=0.09630, mel_loss=0.04739, linear_loss=0.05476]
[2020-05-11 18:18:17.971]  Step 142288  [3.260 sec/step, loss=0.09928, avg_loss=0.09638, mel_loss=0.04552, linear_loss=0.05377]
[2020-05-11 18:18:21.414]  Step 142289  [3.279 sec/step, loss=0.10185, avg_loss=0.09645, mel_loss=0.04746, linear_loss=0.05439]
[2020-05-11 18:18:27.012]  Step 142290  [3.329 sec/step, loss=0.10434, avg_loss=0.09674, mel_loss=0.04946, linear_loss=0.05488]
[2020-05-11 18:18:29.955]  Step 142291  [3.346 sec/step, loss=0.10283, avg_loss=0.09684, mel_loss=0.04749, linear_loss=0.05534]
[2020-05-11 18:18:32.760]  Step 142292  [3.339 sec/step, loss=0.09725, avg_loss=0.09681, mel_loss=0.04506, linear_loss=0.05220]
[2020-05-11 18:18:39.591]  Step 142293  [3.389 sec/step, loss=0.10635, avg_loss=0.09690, mel_loss=0.05045, linear_loss=0.05590]
[2020-05-11 18:18:40.606]  Step 142294  [3.343 sec/step, loss=0.08625, avg_loss=0.09672, mel_loss=0.03882, linear_loss=0.04743]
[2020-05-11 18:18:45.882]  Step 142295  [3.308 sec/step, loss=0.10354, avg_loss=0.09672, mel_loss=0.04827, linear_loss=0.05527]
[2020-05-11 18:18:54.855]  Step 142296  [3.376 sec/step, loss=0.10244, avg_loss=0.09678, mel_loss=0.04900, linear_loss=0.05344]
[2020-05-11 18:18:55.393]  Step 142297  [3.361 sec/step, loss=0.08309, avg_loss=0.09662, mel_loss=0.03750, linear_loss=0.04559]
[2020-05-11 18:18:56.957]  Step 142298  [3.359 sec/step, loss=0.09310, avg_loss=0.09660, mel_loss=0.04231, linear_loss=0.05080]
[2020-05-11 18:18:57.351]  Generated 32 batches of size 32 in 1.953 sec
[2020-05-11 18:18:59.438]  Step 142299  [3.376 sec/step, loss=0.09945, avg_loss=0.09677, mel_loss=0.04510, linear_loss=0.05436]
[2020-05-11 18:19:07.095]  Step 142300  [3.420 sec/step, loss=0.10465, avg_loss=0.09680, mel_loss=0.04964, linear_loss=0.05501]
[2020-05-11 18:19:07.095]  Writing summary at step: 142300
[2020-05-11 18:19:07.925]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142300
[2020-05-11 18:19:09.189]  Saving audio and alignment...
[2020-05-11 18:19:11.748]  Input: 소리 내서 읽기부터 할까요~_______
[2020-05-11 18:19:13.346]  Step 142301  [3.421 sec/step, loss=0.09477, avg_loss=0.09680, mel_loss=0.04303, linear_loss=0.05174]
[2020-05-11 18:19:16.520]  Step 142302  [3.409 sec/step, loss=0.10148, avg_loss=0.09678, mel_loss=0.04689, linear_loss=0.05459]
[2020-05-11 18:19:17.355]  Step 142303  [3.411 sec/step, loss=0.08047, avg_loss=0.09678, mel_loss=0.03649, linear_loss=0.04397]
[2020-05-11 18:19:19.174]  Step 142304  [3.382 sec/step, loss=0.09664, avg_loss=0.09672, mel_loss=0.04403, linear_loss=0.05261]
[2020-05-11 18:19:36.061]  Step 142305  [3.498 sec/step, loss=0.07895, avg_loss=0.09647, mel_loss=0.03859, linear_loss=0.04037]
[2020-05-11 18:19:37.190]  Step 142306  [3.473 sec/step, loss=0.08862, avg_loss=0.09632, mel_loss=0.03971, linear_loss=0.04891]
[2020-05-11 18:19:38.107]  Step 142307  [3.343 sec/step, loss=0.08551, avg_loss=0.09637, mel_loss=0.03793, linear_loss=0.04757]
[2020-05-11 18:19:41.888]  Step 142308  [3.352 sec/step, loss=0.10155, avg_loss=0.09636, mel_loss=0.04723, linear_loss=0.05432]
[2020-05-11 18:19:45.483]  Step 142309  [3.378 sec/step, loss=0.10251, avg_loss=0.09649, mel_loss=0.04752, linear_loss=0.05499]
[2020-05-11 18:19:46.503]  Step 142310  [3.377 sec/step, loss=0.08762, avg_loss=0.09649, mel_loss=0.03945, linear_loss=0.04817]
[2020-05-11 18:19:53.949]  Step 142311  [3.410 sec/step, loss=0.10430, avg_loss=0.09651, mel_loss=0.04971, linear_loss=0.05459]
[2020-05-11 18:19:56.805]  Step 142312  [3.425 sec/step, loss=0.09964, avg_loss=0.09655, mel_loss=0.04593, linear_loss=0.05371]
[2020-05-11 18:19:59.258]  Step 142313  [3.400 sec/step, loss=0.09763, avg_loss=0.09651, mel_loss=0.04483, linear_loss=0.05280]
[2020-05-11 18:20:00.009]  Step 142314  [3.372 sec/step, loss=0.08631, avg_loss=0.09635, mel_loss=0.03849, linear_loss=0.04782]
[2020-05-11 18:20:05.631]  Step 142315  [3.419 sec/step, loss=0.10316, avg_loss=0.09655, mel_loss=0.04871, linear_loss=0.05445]
[2020-05-11 18:20:07.351]  Step 142316  [3.415 sec/step, loss=0.09517, avg_loss=0.09652, mel_loss=0.04319, linear_loss=0.05198]
[2020-05-11 18:20:11.944]  Step 142317  [3.452 sec/step, loss=0.10422, avg_loss=0.09673, mel_loss=0.04877, linear_loss=0.05545]
[2020-05-11 18:20:13.175]  Step 142318  [3.377 sec/step, loss=0.09150, avg_loss=0.09664, mel_loss=0.04124, linear_loss=0.05026]
[2020-05-11 18:20:16.485]  Step 142319  [3.395 sec/step, loss=0.10401, avg_loss=0.09676, mel_loss=0.04819, linear_loss=0.05582]
[2020-05-11 18:20:19.068]  Step 142320  [3.404 sec/step, loss=0.10110, avg_loss=0.09680, mel_loss=0.04659, linear_loss=0.05451]
[2020-05-11 18:20:20.887]  Step 142321  [3.378 sec/step, loss=0.09618, avg_loss=0.09670, mel_loss=0.04342, linear_loss=0.05275]
[2020-05-11 18:20:25.183]  Step 142322  [3.349 sec/step, loss=0.10170, avg_loss=0.09666, mel_loss=0.04762, linear_loss=0.05408]
[2020-05-11 18:20:25.744]  Step 142323  [3.330 sec/step, loss=0.07763, avg_loss=0.09644, mel_loss=0.03538, linear_loss=0.04225]
[2020-05-11 18:20:29.424]  Step 142324  [3.326 sec/step, loss=0.10221, avg_loss=0.09646, mel_loss=0.04727, linear_loss=0.05494]
[2020-05-11 18:20:31.569]  Step 142325  [3.311 sec/step, loss=0.09644, avg_loss=0.09638, mel_loss=0.04372, linear_loss=0.05273]
[2020-05-11 18:20:33.731]  Step 142326  [3.316 sec/step, loss=0.09124, avg_loss=0.09632, mel_loss=0.04106, linear_loss=0.05018]
[2020-05-11 18:20:41.908]  Step 142327  [3.387 sec/step, loss=0.10264, avg_loss=0.09643, mel_loss=0.04821, linear_loss=0.05443]
[2020-05-11 18:20:44.668]  Step 142328  [3.386 sec/step, loss=0.09424, avg_loss=0.09637, mel_loss=0.04297, linear_loss=0.05127]
[2020-05-11 18:20:45.214]  Generated 32 batches of size 32 in 3.296 sec
[2020-05-11 18:20:46.368]  Step 142329  [3.391 sec/step, loss=0.09547, avg_loss=0.09642, mel_loss=0.04346, linear_loss=0.05201]
[2020-05-11 18:20:48.733]  Step 142330  [3.380 sec/step, loss=0.09685, avg_loss=0.09637, mel_loss=0.04466, linear_loss=0.05219]
[2020-05-11 18:20:50.691]  Step 142331  [3.366 sec/step, loss=0.09883, avg_loss=0.09632, mel_loss=0.04512, linear_loss=0.05371]
[2020-05-11 18:20:51.519]  Step 142332  [3.365 sec/step, loss=0.08273, avg_loss=0.09626, mel_loss=0.03724, linear_loss=0.04548]
[2020-05-11 18:20:57.787]  Step 142333  [3.403 sec/step, loss=0.10215, avg_loss=0.09629, mel_loss=0.04845, linear_loss=0.05370]
[2020-05-11 18:21:01.099]  Step 142334  [3.426 sec/step, loss=0.09994, avg_loss=0.09638, mel_loss=0.04612, linear_loss=0.05382]
[2020-05-11 18:21:08.855]  Step 142335  [3.445 sec/step, loss=0.10364, avg_loss=0.09635, mel_loss=0.04964, linear_loss=0.05400]
[2020-05-11 18:21:11.007]  Step 142336  [3.453 sec/step, loss=0.09896, avg_loss=0.09640, mel_loss=0.04511, linear_loss=0.05384]
[2020-05-11 18:21:16.812]  Step 142337  [3.503 sec/step, loss=0.10322, avg_loss=0.09663, mel_loss=0.04881, linear_loss=0.05441]
[2020-05-11 18:21:20.849]  Step 142338  [3.513 sec/step, loss=0.10428, avg_loss=0.09666, mel_loss=0.04832, linear_loss=0.05596]
[2020-05-11 18:21:22.175]  Step 142339  [3.505 sec/step, loss=0.09082, avg_loss=0.09659, mel_loss=0.04119, linear_loss=0.04964]
[2020-05-11 18:21:26.286]  Step 142340  [3.490 sec/step, loss=0.10327, avg_loss=0.09657, mel_loss=0.04831, linear_loss=0.05496]
[2020-05-11 18:21:28.214]  Step 142341  [3.493 sec/step, loss=0.09779, avg_loss=0.09659, mel_loss=0.04411, linear_loss=0.05368]
[2020-05-11 18:21:28.971]  Step 142342  [3.370 sec/step, loss=0.08068, avg_loss=0.09654, mel_loss=0.03641, linear_loss=0.04426]
[2020-05-11 18:21:30.090]  Step 142343  [3.356 sec/step, loss=0.09058, avg_loss=0.09643, mel_loss=0.04069, linear_loss=0.04988]
[2020-05-11 18:21:31.712]  Step 142344  [3.353 sec/step, loss=0.09879, avg_loss=0.09647, mel_loss=0.04460, linear_loss=0.05419]
[2020-05-11 18:21:44.453]  Step 142345  [3.472 sec/step, loss=0.09249, avg_loss=0.09653, mel_loss=0.04493, linear_loss=0.04757]
[2020-05-11 18:21:45.462]  Step 142346  [3.447 sec/step, loss=0.08835, avg_loss=0.09637, mel_loss=0.03966, linear_loss=0.04869]
[2020-05-11 18:21:47.023]  Step 142347  [3.420 sec/step, loss=0.09550, avg_loss=0.09629, mel_loss=0.04328, linear_loss=0.05222]
[2020-05-11 18:21:49.687]  Step 142348  [3.426 sec/step, loss=0.09752, avg_loss=0.09628, mel_loss=0.04473, linear_loss=0.05279]
[2020-05-11 18:21:57.259]  Step 142349  [3.436 sec/step, loss=0.10411, avg_loss=0.09627, mel_loss=0.04973, linear_loss=0.05438]
[2020-05-11 18:22:04.039]  Step 142350  [3.482 sec/step, loss=0.10565, avg_loss=0.09634, mel_loss=0.05037, linear_loss=0.05528]
[2020-05-11 18:22:04.039]  Writing summary at step: 142350
[2020-05-11 18:22:04.855]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142350
[2020-05-11 18:22:06.150]  Saving audio and alignment...
[2020-05-11 18:22:10.943]  Input: 온도에서 습도까지 모든 것이 완벽해야~_________________________
[2020-05-11 18:22:12.873]  Step 142351  [3.487 sec/step, loss=0.09746, avg_loss=0.09639, mel_loss=0.04423, linear_loss=0.05323]
[2020-05-11 18:22:21.907]  Step 142352  [3.561 sec/step, loss=0.10239, avg_loss=0.09644, mel_loss=0.04924, linear_loss=0.05315]
[2020-05-11 18:22:27.266]  Step 142353  [3.582 sec/step, loss=0.10488, avg_loss=0.09648, mel_loss=0.04932, linear_loss=0.05555]
[2020-05-11 18:22:29.387]  Step 142354  [3.558 sec/step, loss=0.09699, avg_loss=0.09641, mel_loss=0.04432, linear_loss=0.05268]
[2020-05-11 18:22:30.133]  Step 142355  [3.552 sec/step, loss=0.07991, avg_loss=0.09629, mel_loss=0.03650, linear_loss=0.04341]
[2020-05-11 18:22:31.344]  Step 142356  [3.531 sec/step, loss=0.09350, avg_loss=0.09620, mel_loss=0.04218, linear_loss=0.05132]
[2020-05-11 18:22:36.022]  Step 142357  [3.490 sec/step, loss=0.10258, avg_loss=0.09622, mel_loss=0.04826, linear_loss=0.05432]
[2020-05-11 18:22:37.846]  Generated 32 batches of size 32 in 1.818 sec
[2020-05-11 18:22:39.694]  Step 142358  [3.507 sec/step, loss=0.10225, avg_loss=0.09626, mel_loss=0.04764, linear_loss=0.05461]
[2020-05-11 18:22:41.052]  Step 142359  [3.483 sec/step, loss=0.09205, avg_loss=0.09615, mel_loss=0.04131, linear_loss=0.05074]
[2020-05-11 18:22:43.253]  Step 142360  [3.479 sec/step, loss=0.09846, avg_loss=0.09614, mel_loss=0.04525, linear_loss=0.05322]
[2020-05-11 18:22:46.219]  Step 142361  [3.497 sec/step, loss=0.10275, avg_loss=0.09625, mel_loss=0.04760, linear_loss=0.05515]
[2020-05-11 18:22:49.114]  Step 142362  [3.518 sec/step, loss=0.09991, avg_loss=0.09642, mel_loss=0.04641, linear_loss=0.05350]
[2020-05-11 18:22:52.539]  Step 142363  [3.503 sec/step, loss=0.09834, avg_loss=0.09637, mel_loss=0.04559, linear_loss=0.05275]
[2020-05-11 18:22:53.529]  Step 142364  [3.458 sec/step, loss=0.08641, avg_loss=0.09620, mel_loss=0.03851, linear_loss=0.04790]
[2020-05-11 18:22:55.282]  Step 142365  [3.470 sec/step, loss=0.09474, avg_loss=0.09637, mel_loss=0.04292, linear_loss=0.05182]
[2020-05-11 18:22:57.669]  Step 142366  [3.419 sec/step, loss=0.09753, avg_loss=0.09631, mel_loss=0.04419, linear_loss=0.05334]
[2020-05-11 18:22:59.349]  Step 142367  [3.425 sec/step, loss=0.09281, avg_loss=0.09638, mel_loss=0.04235, linear_loss=0.05046]
[2020-05-11 18:23:00.900]  Step 142368  [3.302 sec/step, loss=0.09615, avg_loss=0.09654, mel_loss=0.04373, linear_loss=0.05241]
[2020-05-11 18:23:04.572]  Step 142369  [3.329 sec/step, loss=0.10284, avg_loss=0.09670, mel_loss=0.04761, linear_loss=0.05523]
[2020-05-11 18:23:07.465]  Step 142370  [3.333 sec/step, loss=0.10158, avg_loss=0.09673, mel_loss=0.04651, linear_loss=0.05507]
[2020-05-11 18:23:15.738]  Step 142371  [3.381 sec/step, loss=0.10104, avg_loss=0.09674, mel_loss=0.04844, linear_loss=0.05260]
[2020-05-11 18:23:16.298]  Step 142372  [3.376 sec/step, loss=0.07537, avg_loss=0.09658, mel_loss=0.03420, linear_loss=0.04117]
[2020-05-11 18:23:20.802]  Step 142373  [3.402 sec/step, loss=0.10380, avg_loss=0.09666, mel_loss=0.04843, linear_loss=0.05537]
[2020-05-11 18:23:22.853]  Step 142374  [3.405 sec/step, loss=0.09737, avg_loss=0.09667, mel_loss=0.04440, linear_loss=0.05297]
[2020-05-11 18:23:26.826]  Step 142375  [3.425 sec/step, loss=0.10364, avg_loss=0.09675, mel_loss=0.04818, linear_loss=0.05546]
[2020-05-11 18:23:29.339]  Step 142376  [3.321 sec/step, loss=0.09854, avg_loss=0.09684, mel_loss=0.04499, linear_loss=0.05355]
[2020-05-11 18:23:34.579]  Step 142377  [3.336 sec/step, loss=0.10390, avg_loss=0.09685, mel_loss=0.04902, linear_loss=0.05488]
[2020-05-11 18:23:36.784]  Step 142378  [3.341 sec/step, loss=0.09631, avg_loss=0.09685, mel_loss=0.04408, linear_loss=0.05223]
[2020-05-11 18:23:38.139]  Step 142379  [3.330 sec/step, loss=0.09338, avg_loss=0.09680, mel_loss=0.04208, linear_loss=0.05129]
[2020-05-11 18:23:39.610]  Step 142380  [3.335 sec/step, loss=0.09315, avg_loss=0.09687, mel_loss=0.04248, linear_loss=0.05067]
[2020-05-11 18:23:40.423]  Step 142381  [3.300 sec/step, loss=0.08437, avg_loss=0.09666, mel_loss=0.03775, linear_loss=0.04661]
[2020-05-11 18:23:42.220]  Step 142382  [3.297 sec/step, loss=0.09417, avg_loss=0.09662, mel_loss=0.04263, linear_loss=0.05155]
[2020-05-11 18:23:42.977]  Step 142383  [3.293 sec/step, loss=0.08361, avg_loss=0.09655, mel_loss=0.03744, linear_loss=0.04618]
[2020-05-11 18:23:44.076]  Step 142384  [3.293 sec/step, loss=0.08810, avg_loss=0.09652, mel_loss=0.03922, linear_loss=0.04887]
[2020-05-11 18:23:46.708]  Step 142385  [3.271 sec/step, loss=0.09933, avg_loss=0.09649, mel_loss=0.04595, linear_loss=0.05338]
[2020-05-11 18:23:47.582]  Step 142386  [3.238 sec/step, loss=0.08591, avg_loss=0.09631, mel_loss=0.03844, linear_loss=0.04747]
[2020-05-11 18:23:48.734]  Step 142387  [3.213 sec/step, loss=0.09019, avg_loss=0.09619, mel_loss=0.04078, linear_loss=0.04941]
[2020-05-11 18:23:54.591]  Step 142388  [3.250 sec/step, loss=0.10387, avg_loss=0.09624, mel_loss=0.04906, linear_loss=0.05482]
[2020-05-11 18:23:59.407]  Step 142389  [3.264 sec/step, loss=0.10360, avg_loss=0.09626, mel_loss=0.04846, linear_loss=0.05514]
[2020-05-11 18:24:01.023]  Generated 32 batches of size 32 in 1.610 sec
[2020-05-11 18:24:02.592]  Step 142390  [3.240 sec/step, loss=0.10126, avg_loss=0.09622, mel_loss=0.04681, linear_loss=0.05445]
[2020-05-11 18:24:09.317]  Step 142391  [3.278 sec/step, loss=0.10564, avg_loss=0.09625, mel_loss=0.05016, linear_loss=0.05548]
[2020-05-11 18:24:12.767]  Step 142392  [3.284 sec/step, loss=0.10087, avg_loss=0.09629, mel_loss=0.04644, linear_loss=0.05443]
[2020-05-11 18:24:17.037]  Step 142393  [3.259 sec/step, loss=0.10162, avg_loss=0.09624, mel_loss=0.04746, linear_loss=0.05416]
[2020-05-11 18:24:18.976]  Step 142394  [3.268 sec/step, loss=0.09603, avg_loss=0.09634, mel_loss=0.04352, linear_loss=0.05251]
[2020-05-11 18:24:22.420]  Step 142395  [3.250 sec/step, loss=0.10217, avg_loss=0.09633, mel_loss=0.04764, linear_loss=0.05453]
[2020-05-11 18:24:24.747]  Step 142396  [3.183 sec/step, loss=0.09946, avg_loss=0.09630, mel_loss=0.04584, linear_loss=0.05362]
[2020-05-11 18:24:25.702]  Step 142397  [3.187 sec/step, loss=0.09077, avg_loss=0.09637, mel_loss=0.04080, linear_loss=0.04997]
[2020-05-11 18:24:40.630]  Step 142398  [3.321 sec/step, loss=0.07900, avg_loss=0.09623, mel_loss=0.03868, linear_loss=0.04032]
[2020-05-11 18:24:45.549]  Step 142399  [3.345 sec/step, loss=0.10088, avg_loss=0.09625, mel_loss=0.04721, linear_loss=0.05367]
[2020-05-11 18:24:46.880]  Step 142400  [3.282 sec/step, loss=0.09181, avg_loss=0.09612, mel_loss=0.04151, linear_loss=0.05030]
[2020-05-11 18:24:46.881]  Writing summary at step: 142400
[2020-05-11 18:24:52.593]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142400
[2020-05-11 18:24:53.836]  Saving audio and alignment...
[2020-05-11 18:24:58.127]  Input: 프로답 전문적이다라는 인상을 주는 것입니다~_____
[2020-05-11 18:24:59.878]  Step 142401  [3.284 sec/step, loss=0.09432, avg_loss=0.09611, mel_loss=0.04281, linear_loss=0.05152]
[2020-05-11 18:25:01.893]  Step 142402  [3.272 sec/step, loss=0.09659, avg_loss=0.09606, mel_loss=0.04388, linear_loss=0.05271]
[2020-05-11 18:25:04.271]  Step 142403  [3.287 sec/step, loss=0.09892, avg_loss=0.09625, mel_loss=0.04532, linear_loss=0.05361]
[2020-05-11 18:25:06.006]  Step 142404  [3.287 sec/step, loss=0.09596, avg_loss=0.09624, mel_loss=0.04337, linear_loss=0.05258]
[2020-05-11 18:25:08.935]  Step 142405  [3.147 sec/step, loss=0.10345, avg_loss=0.09649, mel_loss=0.04766, linear_loss=0.05579]
[2020-05-11 18:25:17.400]  Step 142406  [3.220 sec/step, loss=0.10195, avg_loss=0.09662, mel_loss=0.04845, linear_loss=0.05350]
[2020-05-11 18:25:19.576]  Step 142407  [3.233 sec/step, loss=0.09924, avg_loss=0.09676, mel_loss=0.04520, linear_loss=0.05403]
[2020-05-11 18:25:20.351]  Step 142408  [3.203 sec/step, loss=0.08652, avg_loss=0.09661, mel_loss=0.03818, linear_loss=0.04835]
[2020-05-11 18:25:26.541]  Step 142409  [3.229 sec/step, loss=0.10326, avg_loss=0.09661, mel_loss=0.04912, linear_loss=0.05414]
[2020-05-11 18:25:28.467]  Step 142410  [3.238 sec/step, loss=0.09560, avg_loss=0.09669, mel_loss=0.04335, linear_loss=0.05225]
[2020-05-11 18:25:31.087]  Step 142411  [3.190 sec/step, loss=0.09760, avg_loss=0.09663, mel_loss=0.04468, linear_loss=0.05292]
[2020-05-11 18:25:32.494]  Step 142412  [3.175 sec/step, loss=0.09050, avg_loss=0.09654, mel_loss=0.04109, linear_loss=0.04941]
[2020-05-11 18:25:46.550]  Step 142413  [3.291 sec/step, loss=0.07773, avg_loss=0.09634, mel_loss=0.03804, linear_loss=0.03969]
[2020-05-11 18:25:50.667]  Step 142414  [3.325 sec/step, loss=0.10065, avg_loss=0.09648, mel_loss=0.04698, linear_loss=0.05367]
[2020-05-11 18:25:54.059]  Step 142415  [3.303 sec/step, loss=0.10224, avg_loss=0.09647, mel_loss=0.04740, linear_loss=0.05484]
[2020-05-11 18:25:54.615]  Step 142416  [3.291 sec/step, loss=0.07797, avg_loss=0.09630, mel_loss=0.03573, linear_loss=0.04224]
[2020-05-11 18:25:58.223]  Step 142417  [3.281 sec/step, loss=0.10394, avg_loss=0.09630, mel_loss=0.04847, linear_loss=0.05547]
[2020-05-11 18:26:03.522]  Step 142418  [3.322 sec/step, loss=0.10505, avg_loss=0.09643, mel_loss=0.04938, linear_loss=0.05567]
[2020-05-11 18:26:06.686]  Step 142419  [3.320 sec/step, loss=0.10230, avg_loss=0.09641, mel_loss=0.04725, linear_loss=0.05505]
[2020-05-11 18:26:07.830]  Step 142420  [3.306 sec/step, loss=0.08897, avg_loss=0.09629, mel_loss=0.03967, linear_loss=0.04930]
[2020-05-11 18:26:08.372]  Generated 32 batches of size 32 in 1.681 sec
[2020-05-11 18:26:12.034]  Step 142421  [3.330 sec/step, loss=0.10454, avg_loss=0.09638, mel_loss=0.04921, linear_loss=0.05533]
[2020-05-11 18:26:19.533]  Step 142422  [3.362 sec/step, loss=0.10454, avg_loss=0.09641, mel_loss=0.04971, linear_loss=0.05483]
[2020-05-11 18:26:23.018]  Step 142423  [3.391 sec/step, loss=0.09971, avg_loss=0.09663, mel_loss=0.04620, linear_loss=0.05351]
[2020-05-11 18:26:23.780]  Step 142424  [3.362 sec/step, loss=0.08243, avg_loss=0.09643, mel_loss=0.03682, linear_loss=0.04561]
[2020-05-11 18:26:25.401]  Step 142425  [3.357 sec/step, loss=0.09470, avg_loss=0.09641, mel_loss=0.04307, linear_loss=0.05163]
[2020-05-11 18:26:26.619]  Step 142426  [3.347 sec/step, loss=0.09182, avg_loss=0.09642, mel_loss=0.04139, linear_loss=0.05043]
[2020-05-11 18:26:27.586]  Step 142427  [3.275 sec/step, loss=0.09143, avg_loss=0.09630, mel_loss=0.04122, linear_loss=0.05022]
[2020-05-11 18:26:28.479]  Step 142428  [3.256 sec/step, loss=0.08466, avg_loss=0.09621, mel_loss=0.03784, linear_loss=0.04682]
[2020-05-11 18:26:33.341]  Step 142429  [3.288 sec/step, loss=0.10256, avg_loss=0.09628, mel_loss=0.04790, linear_loss=0.05467]
[2020-05-11 18:26:36.875]  Step 142430  [3.300 sec/step, loss=0.10272, avg_loss=0.09634, mel_loss=0.04769, linear_loss=0.05503]
[2020-05-11 18:26:43.400]  Step 142431  [3.345 sec/step, loss=0.10356, avg_loss=0.09639, mel_loss=0.04929, linear_loss=0.05427]
[2020-05-11 18:26:45.314]  Step 142432  [3.356 sec/step, loss=0.09570, avg_loss=0.09652, mel_loss=0.04363, linear_loss=0.05207]
[2020-05-11 18:26:48.996]  Step 142433  [3.330 sec/step, loss=0.10275, avg_loss=0.09652, mel_loss=0.04769, linear_loss=0.05506]
[2020-05-11 18:26:52.033]  Step 142434  [3.328 sec/step, loss=0.10257, avg_loss=0.09655, mel_loss=0.04766, linear_loss=0.05491]
[2020-05-11 18:26:53.034]  Step 142435  [3.260 sec/step, loss=0.08451, avg_loss=0.09636, mel_loss=0.03785, linear_loss=0.04666]
[2020-05-11 18:26:57.039]  Step 142436  [3.279 sec/step, loss=0.10436, avg_loss=0.09641, mel_loss=0.04862, linear_loss=0.05573]
[2020-05-11 18:26:58.351]  Step 142437  [3.234 sec/step, loss=0.09116, avg_loss=0.09629, mel_loss=0.04119, linear_loss=0.04997]
[2020-05-11 18:27:11.295]  Step 142438  [3.323 sec/step, loss=0.09308, avg_loss=0.09618, mel_loss=0.04493, linear_loss=0.04814]
[2020-05-11 18:27:18.346]  Step 142439  [3.380 sec/step, loss=0.10445, avg_loss=0.09631, mel_loss=0.04947, linear_loss=0.05498]
[2020-05-11 18:27:20.986]  Step 142440  [3.365 sec/step, loss=0.09935, avg_loss=0.09628, mel_loss=0.04590, linear_loss=0.05345]
[2020-05-11 18:27:24.461]  Step 142441  [3.381 sec/step, loss=0.10070, avg_loss=0.09630, mel_loss=0.04666, linear_loss=0.05404]
[2020-05-11 18:27:26.505]  Step 142442  [3.394 sec/step, loss=0.09731, avg_loss=0.09647, mel_loss=0.04436, linear_loss=0.05294]
[2020-05-11 18:27:27.925]  Step 142443  [3.397 sec/step, loss=0.09717, avg_loss=0.09654, mel_loss=0.04407, linear_loss=0.05310]
[2020-05-11 18:27:29.464]  Step 142444  [3.396 sec/step, loss=0.09308, avg_loss=0.09648, mel_loss=0.04193, linear_loss=0.05115]
[2020-05-11 18:27:33.919]  Step 142445  [3.313 sec/step, loss=0.10470, avg_loss=0.09660, mel_loss=0.04908, linear_loss=0.05562]
[2020-05-11 18:27:36.311]  Step 142446  [3.327 sec/step, loss=0.09762, avg_loss=0.09669, mel_loss=0.04457, linear_loss=0.05305]
[2020-05-11 18:27:37.640]  Step 142447  [3.324 sec/step, loss=0.09433, avg_loss=0.09668, mel_loss=0.04252, linear_loss=0.05181]
[2020-05-11 18:27:39.265]  Step 142448  [3.314 sec/step, loss=0.09702, avg_loss=0.09668, mel_loss=0.04383, linear_loss=0.05319]
[2020-05-11 18:27:40.250]  Step 142449  [3.248 sec/step, loss=0.08544, avg_loss=0.09649, mel_loss=0.03823, linear_loss=0.04721]
[2020-05-11 18:27:40.774]  Step 142450  [3.186 sec/step, loss=0.08078, avg_loss=0.09624, mel_loss=0.03633, linear_loss=0.04445]
[2020-05-11 18:27:40.775]  Writing summary at step: 142450
[2020-05-11 18:27:41.577]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142450
[2020-05-11 18:27:42.849]  Saving audio and alignment...
[2020-05-11 18:27:44.918]  Generated 32 batches of size 32 in 1.594 sec
[2020-05-11 18:27:50.750]  Input: 그래서 시청자분들도 제가 아니라 보도 자체에 집중하실 수 있게 된 것 같아서~__________________________
[2020-05-11 18:27:52.522]  Step 142451  [3.184 sec/step, loss=0.09591, avg_loss=0.09623, mel_loss=0.04333, linear_loss=0.05257]
[2020-05-11 18:27:54.686]  Step 142452  [3.115 sec/step, loss=0.09880, avg_loss=0.09619, mel_loss=0.04535, linear_loss=0.05345]
[2020-05-11 18:27:57.579]  Step 142453  [3.091 sec/step, loss=0.10193, avg_loss=0.09616, mel_loss=0.04707, linear_loss=0.05487]
[2020-05-11 18:27:58.710]  Step 142454  [3.081 sec/step, loss=0.09225, avg_loss=0.09611, mel_loss=0.04093, linear_loss=0.05132]
[2020-05-11 18:28:01.201]  Step 142455  [3.098 sec/step, loss=0.09887, avg_loss=0.09630, mel_loss=0.04495, linear_loss=0.05392]
[2020-05-11 18:28:02.027]  Step 142456  [3.094 sec/step, loss=0.08578, avg_loss=0.09623, mel_loss=0.03849, linear_loss=0.04730]
[2020-05-11 18:28:11.075]  Step 142457  [3.138 sec/step, loss=0.10060, avg_loss=0.09621, mel_loss=0.04871, linear_loss=0.05188]
[2020-05-11 18:28:12.131]  Step 142458  [3.112 sec/step, loss=0.09387, avg_loss=0.09612, mel_loss=0.04219, linear_loss=0.05169]
[2020-05-11 18:28:20.875]  Step 142459  [3.186 sec/step, loss=0.10401, avg_loss=0.09624, mel_loss=0.04974, linear_loss=0.05427]
[2020-05-11 18:28:24.509]  Step 142460  [3.200 sec/step, loss=0.10550, avg_loss=0.09631, mel_loss=0.04914, linear_loss=0.05636]
[2020-05-11 18:28:27.550]  Step 142461  [3.201 sec/step, loss=0.10246, avg_loss=0.09631, mel_loss=0.04728, linear_loss=0.05518]
[2020-05-11 18:28:31.649]  Step 142462  [3.213 sec/step, loss=0.10121, avg_loss=0.09632, mel_loss=0.04665, linear_loss=0.05457]
[2020-05-11 18:28:39.212]  Step 142463  [3.254 sec/step, loss=0.10473, avg_loss=0.09639, mel_loss=0.04988, linear_loss=0.05485]
[2020-05-11 18:28:40.083]  Step 142464  [3.253 sec/step, loss=0.08451, avg_loss=0.09637, mel_loss=0.03772, linear_loss=0.04679]
[2020-05-11 18:28:43.538]  Step 142465  [3.270 sec/step, loss=0.10107, avg_loss=0.09643, mel_loss=0.04702, linear_loss=0.05406]
[2020-05-11 18:28:44.634]  Step 142466  [3.257 sec/step, loss=0.08941, avg_loss=0.09635, mel_loss=0.04035, linear_loss=0.04905]
[2020-05-11 18:28:47.256]  Step 142467  [3.267 sec/step, loss=0.10031, avg_loss=0.09642, mel_loss=0.04587, linear_loss=0.05444]
[2020-05-11 18:28:49.188]  Step 142468  [3.270 sec/step, loss=0.09696, avg_loss=0.09643, mel_loss=0.04397, linear_loss=0.05298]
[2020-05-11 18:28:52.606]  Step 142469  [3.268 sec/step, loss=0.10055, avg_loss=0.09641, mel_loss=0.04637, linear_loss=0.05418]
[2020-05-11 18:28:55.404]  Step 142470  [3.267 sec/step, loss=0.09845, avg_loss=0.09638, mel_loss=0.04561, linear_loss=0.05284]
[2020-05-11 18:28:59.794]  Step 142471  [3.228 sec/step, loss=0.10307, avg_loss=0.09640, mel_loss=0.04819, linear_loss=0.05488]
[2020-05-11 18:29:02.188]  Step 142472  [3.246 sec/step, loss=0.09903, avg_loss=0.09664, mel_loss=0.04561, linear_loss=0.05343]
[2020-05-11 18:29:07.496]  Step 142473  [3.254 sec/step, loss=0.10460, avg_loss=0.09664, mel_loss=0.04919, linear_loss=0.05541]
[2020-05-11 18:29:14.222]  Step 142474  [3.301 sec/step, loss=0.10510, avg_loss=0.09672, mel_loss=0.05000, linear_loss=0.05510]
[2020-05-11 18:29:14.992]  Step 142475  [3.269 sec/step, loss=0.08413, avg_loss=0.09653, mel_loss=0.03809, linear_loss=0.04604]
[2020-05-11 18:29:16.577]  Step 142476  [3.260 sec/step, loss=0.09382, avg_loss=0.09648, mel_loss=0.04269, linear_loss=0.05113]
[2020-05-11 18:29:18.310]  Step 142477  [3.225 sec/step, loss=0.09754, avg_loss=0.09641, mel_loss=0.04400, linear_loss=0.05355]
[2020-05-11 18:29:19.332]  Step 142478  [3.213 sec/step, loss=0.08617, avg_loss=0.09631, mel_loss=0.03892, linear_loss=0.04725]
[2020-05-11 18:29:20.603]  Step 142479  [3.212 sec/step, loss=0.08976, avg_loss=0.09628, mel_loss=0.04047, linear_loss=0.04929]
[2020-05-11 18:29:22.387]  Step 142480  [3.215 sec/step, loss=0.09656, avg_loss=0.09631, mel_loss=0.04375, linear_loss=0.05281]
[2020-05-11 18:29:22.953]  Step 142481  [3.213 sec/step, loss=0.07679, avg_loss=0.09624, mel_loss=0.03527, linear_loss=0.04152]
[2020-05-11 18:29:24.641]  Generated 32 batches of size 32 in 1.681 sec
[2020-05-11 18:29:26.145]  Step 142482  [3.227 sec/step, loss=0.10328, avg_loss=0.09633, mel_loss=0.04800, linear_loss=0.05528]
[2020-05-11 18:29:28.350]  Step 142483  [3.241 sec/step, loss=0.09819, avg_loss=0.09647, mel_loss=0.04526, linear_loss=0.05292]
[2020-05-11 18:29:30.468]  Step 142484  [3.251 sec/step, loss=0.09719, avg_loss=0.09656, mel_loss=0.04443, linear_loss=0.05275]
[2020-05-11 18:29:42.614]  Step 142485  [3.347 sec/step, loss=0.09220, avg_loss=0.09649, mel_loss=0.04507, linear_loss=0.04713]
[2020-05-11 18:29:48.656]  Step 142486  [3.398 sec/step, loss=0.10568, avg_loss=0.09669, mel_loss=0.05005, linear_loss=0.05563]
[2020-05-11 18:29:53.656]  Step 142487  [3.437 sec/step, loss=0.10137, avg_loss=0.09680, mel_loss=0.04741, linear_loss=0.05396]
[2020-05-11 18:29:54.424]  Step 142488  [3.386 sec/step, loss=0.08553, avg_loss=0.09662, mel_loss=0.03790, linear_loss=0.04763]
[2020-05-11 18:29:56.035]  Step 142489  [3.354 sec/step, loss=0.09527, avg_loss=0.09653, mel_loss=0.04339, linear_loss=0.05188]
[2020-05-11 18:29:57.432]  Step 142490  [3.336 sec/step, loss=0.09097, avg_loss=0.09643, mel_loss=0.04114, linear_loss=0.04984]
[2020-05-11 18:29:58.486]  Step 142491  [3.279 sec/step, loss=0.09023, avg_loss=0.09628, mel_loss=0.04002, linear_loss=0.05021]
[2020-05-11 18:30:00.934]  Step 142492  [3.269 sec/step, loss=0.09848, avg_loss=0.09625, mel_loss=0.04489, linear_loss=0.05360]
[2020-05-11 18:30:03.569]  Step 142493  [3.253 sec/step, loss=0.10183, avg_loss=0.09626, mel_loss=0.04722, linear_loss=0.05461]
[2020-05-11 18:30:10.519]  Step 142494  [3.303 sec/step, loss=0.10541, avg_loss=0.09635, mel_loss=0.05022, linear_loss=0.05519]
[2020-05-11 18:30:11.077]  Step 142495  [3.274 sec/step, loss=0.07421, avg_loss=0.09607, mel_loss=0.03399, linear_loss=0.04022]
[2020-05-11 18:30:12.460]  Step 142496  [3.265 sec/step, loss=0.09365, avg_loss=0.09601, mel_loss=0.04259, linear_loss=0.05106]
[2020-05-11 18:30:15.375]  Step 142497  [3.284 sec/step, loss=0.10101, avg_loss=0.09611, mel_loss=0.04652, linear_loss=0.05449]
[2020-05-11 18:30:20.746]  Step 142498  [3.189 sec/step, loss=0.10435, avg_loss=0.09637, mel_loss=0.04927, linear_loss=0.05508]
[2020-05-11 18:30:24.108]  Step 142499  [3.173 sec/step, loss=0.10170, avg_loss=0.09638, mel_loss=0.04724, linear_loss=0.05446]
[2020-05-11 18:30:26.134]  Step 142500  [3.180 sec/step, loss=0.09874, avg_loss=0.09645, mel_loss=0.04517, linear_loss=0.05357]
[2020-05-11 18:30:26.134]  Writing summary at step: 142500
[2020-05-11 18:30:29.346]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142500
[2020-05-11 18:30:30.604]  Saving audio and alignment...
[2020-05-11 18:30:36.328]  Input: 교재인 도서출판 오래에 하루만에 목소리가 좋아지는 책과~________________
[2020-05-11 18:30:38.904]  Step 142501  [3.188 sec/step, loss=0.09662, avg_loss=0.09647, mel_loss=0.04431, linear_loss=0.05231]
[2020-05-11 18:30:39.997]  Step 142502  [3.179 sec/step, loss=0.09136, avg_loss=0.09642, mel_loss=0.04106, linear_loss=0.05030]
[2020-05-11 18:30:49.788]  Step 142503  [3.253 sec/step, loss=0.10077, avg_loss=0.09643, mel_loss=0.04821, linear_loss=0.05256]
[2020-05-11 18:30:55.487]  Step 142504  [3.293 sec/step, loss=0.09995, avg_loss=0.09647, mel_loss=0.04628, linear_loss=0.05367]
[2020-05-11 18:30:58.670]  Step 142505  [3.295 sec/step, loss=0.09528, avg_loss=0.09639, mel_loss=0.04318, linear_loss=0.05210]
[2020-05-11 18:31:00.057]  Step 142506  [3.225 sec/step, loss=0.07610, avg_loss=0.09613, mel_loss=0.03434, linear_loss=0.04176]
[2020-05-11 18:31:03.310]  Step 142507  [3.235 sec/step, loss=0.09691, avg_loss=0.09611, mel_loss=0.04434, linear_loss=0.05257]
[2020-05-11 18:31:18.293]  Step 142508  [3.377 sec/step, loss=0.07868, avg_loss=0.09603, mel_loss=0.03818, linear_loss=0.04050]
[2020-05-11 18:31:24.291]  Step 142509  [3.376 sec/step, loss=0.10126, avg_loss=0.09601, mel_loss=0.04807, linear_loss=0.05319]
[2020-05-11 18:31:25.202]  Step 142510  [3.365 sec/step, loss=0.08701, avg_loss=0.09593, mel_loss=0.03876, linear_loss=0.04826]
[2020-05-11 18:31:29.583]  Step 142511  [3.383 sec/step, loss=0.10519, avg_loss=0.09600, mel_loss=0.04919, linear_loss=0.05600]
[2020-05-11 18:31:31.296]  Generated 32 batches of size 32 in 1.708 sec
[2020-05-11 18:31:31.463]  Step 142512  [3.388 sec/step, loss=0.09591, avg_loss=0.09606, mel_loss=0.04353, linear_loss=0.05238]
[2020-05-11 18:31:33.089]  Step 142513  [3.263 sec/step, loss=0.09429, avg_loss=0.09622, mel_loss=0.04312, linear_loss=0.05117]
[2020-05-11 18:31:34.350]  Step 142514  [3.235 sec/step, loss=0.09184, avg_loss=0.09613, mel_loss=0.04158, linear_loss=0.05026]
[2020-05-11 18:31:39.163]  Step 142515  [3.249 sec/step, loss=0.10202, avg_loss=0.09613, mel_loss=0.04774, linear_loss=0.05428]
[2020-05-11 18:31:40.089]  Step 142516  [3.253 sec/step, loss=0.09134, avg_loss=0.09627, mel_loss=0.04091, linear_loss=0.05043]
[2020-05-11 18:31:40.912]  Step 142517  [3.225 sec/step, loss=0.08461, avg_loss=0.09607, mel_loss=0.03797, linear_loss=0.04664]
[2020-05-11 18:31:42.381]  Step 142518  [3.187 sec/step, loss=0.09275, avg_loss=0.09595, mel_loss=0.04186, linear_loss=0.05090]
[2020-05-11 18:31:46.677]  Step 142519  [3.198 sec/step, loss=0.10127, avg_loss=0.09594, mel_loss=0.04710, linear_loss=0.05417]
[2020-05-11 18:31:48.295]  Step 142520  [3.203 sec/step, loss=0.09751, avg_loss=0.09602, mel_loss=0.04499, linear_loss=0.05252]
[2020-05-11 18:31:49.683]  Step 142521  [3.175 sec/step, loss=0.09250, avg_loss=0.09590, mel_loss=0.04206, linear_loss=0.05044]
[2020-05-11 18:31:55.933]  Step 142522  [3.162 sec/step, loss=0.10370, avg_loss=0.09590, mel_loss=0.04916, linear_loss=0.05454]
[2020-05-11 18:32:01.163]  Step 142523  [3.180 sec/step, loss=0.10403, avg_loss=0.09594, mel_loss=0.04882, linear_loss=0.05521]
[2020-05-11 18:32:03.669]  Step 142524  [3.197 sec/step, loss=0.09926, avg_loss=0.09611, mel_loss=0.04542, linear_loss=0.05383]
[2020-05-11 18:32:04.472]  Step 142525  [3.189 sec/step, loss=0.08530, avg_loss=0.09601, mel_loss=0.03824, linear_loss=0.04706]
[2020-05-11 18:32:18.849]  Step 142526  [3.320 sec/step, loss=0.08086, avg_loss=0.09590, mel_loss=0.03947, linear_loss=0.04139]
[2020-05-11 18:32:20.174]  Step 142527  [3.324 sec/step, loss=0.09111, avg_loss=0.09590, mel_loss=0.04106, linear_loss=0.05005]
[2020-05-11 18:32:23.551]  Step 142528  [3.349 sec/step, loss=0.10176, avg_loss=0.09607, mel_loss=0.04704, linear_loss=0.05472]
[2020-05-11 18:32:24.794]  Step 142529  [3.313 sec/step, loss=0.09084, avg_loss=0.09595, mel_loss=0.04102, linear_loss=0.04982]
[2020-05-11 18:32:29.329]  Step 142530  [3.323 sec/step, loss=0.10345, avg_loss=0.09596, mel_loss=0.04850, linear_loss=0.05495]
[2020-05-11 18:32:30.329]  Step 142531  [3.267 sec/step, loss=0.08982, avg_loss=0.09582, mel_loss=0.04051, linear_loss=0.04931]
[2020-05-11 18:32:32.039]  Step 142532  [3.265 sec/step, loss=0.09763, avg_loss=0.09584, mel_loss=0.04397, linear_loss=0.05366]
[2020-05-11 18:32:33.596]  Step 142533  [3.244 sec/step, loss=0.09516, avg_loss=0.09577, mel_loss=0.04303, linear_loss=0.05213]
[2020-05-11 18:32:41.681]  Step 142534  [3.295 sec/step, loss=0.10363, avg_loss=0.09578, mel_loss=0.04948, linear_loss=0.05415]
[2020-05-11 18:32:45.104]  Step 142535  [3.319 sec/step, loss=0.10253, avg_loss=0.09596, mel_loss=0.04753, linear_loss=0.05500]
[2020-05-11 18:32:48.747]  Step 142536  [3.315 sec/step, loss=0.10500, avg_loss=0.09597, mel_loss=0.04900, linear_loss=0.05600]
[2020-05-11 18:32:50.855]  Step 142537  [3.323 sec/step, loss=0.09839, avg_loss=0.09604, mel_loss=0.04479, linear_loss=0.05360]
[2020-05-11 18:32:54.875]  Step 142538  [3.234 sec/step, loss=0.10477, avg_loss=0.09615, mel_loss=0.04873, linear_loss=0.05604]
[2020-05-11 18:32:56.840]  Step 142539  [3.183 sec/step, loss=0.09673, avg_loss=0.09608, mel_loss=0.04396, linear_loss=0.05276]
[2020-05-11 18:32:58.824]  Step 142540  [3.176 sec/step, loss=0.09720, avg_loss=0.09606, mel_loss=0.04412, linear_loss=0.05308]
[2020-05-11 18:33:06.290]  Step 142541  [3.216 sec/step, loss=0.10602, avg_loss=0.09611, mel_loss=0.05051, linear_loss=0.05551]
[2020-05-11 18:33:09.299]  Step 142542  [3.226 sec/step, loss=0.10055, avg_loss=0.09614, mel_loss=0.04630, linear_loss=0.05425]
[2020-05-11 18:33:10.308]  Step 142543  [3.222 sec/step, loss=0.08975, avg_loss=0.09607, mel_loss=0.04034, linear_loss=0.04941]
[2020-05-11 18:33:12.062]  Generated 32 batches of size 32 in 1.750 sec
[2020-05-11 18:33:14.711]  Step 142544  [3.251 sec/step, loss=0.10309, avg_loss=0.09617, mel_loss=0.04817, linear_loss=0.05492]
[2020-05-11 18:33:17.523]  Step 142545  [3.234 sec/step, loss=0.09756, avg_loss=0.09610, mel_loss=0.04477, linear_loss=0.05279]
[2020-05-11 18:33:20.544]  Step 142546  [3.240 sec/step, loss=0.10358, avg_loss=0.09616, mel_loss=0.04767, linear_loss=0.05591]
[2020-05-11 18:33:21.661]  Step 142547  [3.238 sec/step, loss=0.09353, avg_loss=0.09615, mel_loss=0.04167, linear_loss=0.05187]
[2020-05-11 18:33:23.459]  Step 142548  [3.240 sec/step, loss=0.09535, avg_loss=0.09613, mel_loss=0.04298, linear_loss=0.05237]
[2020-05-11 18:33:25.756]  Step 142549  [3.253 sec/step, loss=0.09686, avg_loss=0.09624, mel_loss=0.04457, linear_loss=0.05228]
[2020-05-11 18:33:26.312]  Step 142550  [3.253 sec/step, loss=0.08102, avg_loss=0.09625, mel_loss=0.03733, linear_loss=0.04369]
[2020-05-11 18:33:26.312]  Writing summary at step: 142550
[2020-05-11 18:33:32.018]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142550
[2020-05-11 18:33:33.279]  Saving audio and alignment...
[2020-05-11 18:33:34.842]  Input: 그래야만~_________________
[2020-05-11 18:33:42.113]  Step 142551  [3.308 sec/step, loss=0.10253, avg_loss=0.09631, mel_loss=0.04860, linear_loss=0.05393]
[2020-05-11 18:33:47.670]  Step 142552  [3.342 sec/step, loss=0.10318, avg_loss=0.09636, mel_loss=0.04834, linear_loss=0.05484]
[2020-05-11 18:34:01.806]  Step 142553  [3.455 sec/step, loss=0.08013, avg_loss=0.09614, mel_loss=0.03897, linear_loss=0.04116]
[2020-05-11 18:34:10.840]  Step 142554  [3.534 sec/step, loss=0.10282, avg_loss=0.09624, mel_loss=0.04909, linear_loss=0.05373]
[2020-05-11 18:34:12.329]  Step 142555  [3.524 sec/step, loss=0.09207, avg_loss=0.09618, mel_loss=0.04154, linear_loss=0.05053]
[2020-05-11 18:34:14.914]  Step 142556  [3.541 sec/step, loss=0.10012, avg_loss=0.09632, mel_loss=0.04637, linear_loss=0.05376]
[2020-05-11 18:34:15.476]  Step 142557  [3.457 sec/step, loss=0.07710, avg_loss=0.09609, mel_loss=0.03483, linear_loss=0.04227]
[2020-05-11 18:34:20.160]  Step 142558  [3.493 sec/step, loss=0.10285, avg_loss=0.09618, mel_loss=0.04808, linear_loss=0.05477]
[2020-05-11 18:34:21.678]  Step 142559  [3.421 sec/step, loss=0.09722, avg_loss=0.09611, mel_loss=0.04402, linear_loss=0.05320]
[2020-05-11 18:34:24.790]  Step 142560  [3.415 sec/step, loss=0.10167, avg_loss=0.09607, mel_loss=0.04732, linear_loss=0.05436]
[2020-05-11 18:34:26.821]  Step 142561  [3.405 sec/step, loss=0.09675, avg_loss=0.09601, mel_loss=0.04398, linear_loss=0.05278]
[2020-05-11 18:34:29.242]  Step 142562  [3.388 sec/step, loss=0.09826, avg_loss=0.09598, mel_loss=0.04470, linear_loss=0.05355]
[2020-05-11 18:34:29.959]  Step 142563  [3.320 sec/step, loss=0.08322, avg_loss=0.09577, mel_loss=0.03772, linear_loss=0.04550]
[2020-05-11 18:34:31.139]  Step 142564  [3.323 sec/step, loss=0.09023, avg_loss=0.09582, mel_loss=0.04081, linear_loss=0.04942]
[2020-05-11 18:34:32.180]  Step 142565  [3.299 sec/step, loss=0.08417, avg_loss=0.09566, mel_loss=0.03785, linear_loss=0.04632]
[2020-05-11 18:34:33.966]  Step 142566  [3.306 sec/step, loss=0.09478, avg_loss=0.09571, mel_loss=0.04316, linear_loss=0.05162]
[2020-05-11 18:34:37.401]  Step 142567  [3.314 sec/step, loss=0.10184, avg_loss=0.09572, mel_loss=0.04694, linear_loss=0.05490]
[2020-05-11 18:34:42.608]  Step 142568  [3.347 sec/step, loss=0.10070, avg_loss=0.09576, mel_loss=0.04746, linear_loss=0.05323]
[2020-05-11 18:34:44.296]  Step 142569  [3.329 sec/step, loss=0.09471, avg_loss=0.09570, mel_loss=0.04305, linear_loss=0.05166]
[2020-05-11 18:34:47.297]  Step 142570  [3.331 sec/step, loss=0.10202, avg_loss=0.09574, mel_loss=0.04686, linear_loss=0.05516]
[2020-05-11 18:34:49.285]  Step 142571  [3.307 sec/step, loss=0.09597, avg_loss=0.09567, mel_loss=0.04355, linear_loss=0.05242]
[2020-05-11 18:34:51.811]  Step 142572  [3.309 sec/step, loss=0.09793, avg_loss=0.09566, mel_loss=0.04482, linear_loss=0.05311]
[2020-05-11 18:34:53.143]  Step 142573  [3.269 sec/step, loss=0.09467, avg_loss=0.09556, mel_loss=0.04252, linear_loss=0.05216]
[2020-05-11 18:34:53.927]  Step 142574  [3.210 sec/step, loss=0.08880, avg_loss=0.09539, mel_loss=0.03996, linear_loss=0.04884]
[2020-05-11 18:34:54.866]  Generated 32 batches of size 32 in 1.717 sec
[2020-05-11 18:35:00.672]  Step 142575  [3.269 sec/step, loss=0.10423, avg_loss=0.09560, mel_loss=0.04925, linear_loss=0.05498]
[2020-05-11 18:35:04.721]  Step 142576  [3.294 sec/step, loss=0.10250, avg_loss=0.09568, mel_loss=0.04761, linear_loss=0.05489]
[2020-05-11 18:35:05.871]  Step 142577  [3.288 sec/step, loss=0.08889, avg_loss=0.09560, mel_loss=0.03951, linear_loss=0.04938]
[2020-05-11 18:35:09.532]  Step 142578  [3.315 sec/step, loss=0.10360, avg_loss=0.09577, mel_loss=0.04836, linear_loss=0.05524]
[2020-05-11 18:35:13.004]  Step 142579  [3.337 sec/step, loss=0.10113, avg_loss=0.09588, mel_loss=0.04662, linear_loss=0.05452]
[2020-05-11 18:35:15.217]  Step 142580  [3.341 sec/step, loss=0.09970, avg_loss=0.09592, mel_loss=0.04558, linear_loss=0.05412]
[2020-05-11 18:35:16.215]  Step 142581  [3.345 sec/step, loss=0.08541, avg_loss=0.09600, mel_loss=0.03787, linear_loss=0.04753]
[2020-05-11 18:35:20.308]  Step 142582  [3.354 sec/step, loss=0.10316, avg_loss=0.09600, mel_loss=0.04829, linear_loss=0.05487]
[2020-05-11 18:35:21.203]  Step 142583  [3.341 sec/step, loss=0.08447, avg_loss=0.09586, mel_loss=0.03779, linear_loss=0.04668]
[2020-05-11 18:35:29.506]  Step 142584  [3.403 sec/step, loss=0.10145, avg_loss=0.09591, mel_loss=0.04847, linear_loss=0.05298]
[2020-05-11 18:35:33.792]  Step 142585  [3.324 sec/step, loss=0.10284, avg_loss=0.09601, mel_loss=0.04797, linear_loss=0.05488]
[2020-05-11 18:35:35.762]  Step 142586  [3.284 sec/step, loss=0.09741, avg_loss=0.09593, mel_loss=0.04437, linear_loss=0.05305]
[2020-05-11 18:35:42.430]  Step 142587  [3.300 sec/step, loss=0.10347, avg_loss=0.09595, mel_loss=0.04919, linear_loss=0.05428]
[2020-05-11 18:35:48.067]  Step 142588  [3.349 sec/step, loss=0.10229, avg_loss=0.09612, mel_loss=0.04818, linear_loss=0.05410]
[2020-05-11 18:35:48.829]  Step 142589  [3.340 sec/step, loss=0.08361, avg_loss=0.09600, mel_loss=0.03729, linear_loss=0.04632]
[2020-05-11 18:35:49.852]  Step 142590  [3.337 sec/step, loss=0.09274, avg_loss=0.09602, mel_loss=0.04147, linear_loss=0.05128]
[2020-05-11 18:35:50.827]  Step 142591  [3.336 sec/step, loss=0.09095, avg_loss=0.09603, mel_loss=0.04102, linear_loss=0.04993]
[2020-05-11 18:35:53.953]  Step 142592  [3.343 sec/step, loss=0.10490, avg_loss=0.09609, mel_loss=0.04823, linear_loss=0.05667]
[2020-05-11 18:35:55.295]  Step 142593  [3.330 sec/step, loss=0.09527, avg_loss=0.09603, mel_loss=0.04319, linear_loss=0.05208]
[2020-05-11 18:35:58.366]  Step 142594  [3.291 sec/step, loss=0.10165, avg_loss=0.09599, mel_loss=0.04674, linear_loss=0.05490]
[2020-05-11 18:35:59.741]  Step 142595  [3.299 sec/step, loss=0.08999, avg_loss=0.09615, mel_loss=0.04041, linear_loss=0.04958]
[2020-05-11 18:36:03.532]  Step 142596  [3.323 sec/step, loss=0.10255, avg_loss=0.09623, mel_loss=0.04768, linear_loss=0.05487]
[2020-05-11 18:36:06.871]  Step 142597  [3.327 sec/step, loss=0.10114, avg_loss=0.09624, mel_loss=0.04681, linear_loss=0.05434]
[2020-05-11 18:36:09.043]  Step 142598  [3.295 sec/step, loss=0.09662, avg_loss=0.09616, mel_loss=0.04426, linear_loss=0.05236]
[2020-05-11 18:36:10.796]  Step 142599  [3.279 sec/step, loss=0.09570, avg_loss=0.09610, mel_loss=0.04318, linear_loss=0.05252]
[2020-05-11 18:36:12.924]  Step 142600  [3.280 sec/step, loss=0.09943, avg_loss=0.09611, mel_loss=0.04551, linear_loss=0.05392]
[2020-05-11 18:36:12.924]  Writing summary at step: 142600
[2020-05-11 18:36:17.563]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142600
[2020-05-11 18:36:19.517]  Saving audio and alignment...
[2020-05-11 18:36:20.933]  Input: 다음~_____________________________
[2020-05-11 18:36:34.018]  Step 142601  [3.385 sec/step, loss=0.08689, avg_loss=0.09601, mel_loss=0.04223, linear_loss=0.04467]
[2020-05-11 18:36:35.684]  Step 142602  [3.391 sec/step, loss=0.09580, avg_loss=0.09605, mel_loss=0.04361, linear_loss=0.05219]
[2020-05-11 18:36:40.946]  Step 142603  [3.346 sec/step, loss=0.10347, avg_loss=0.09608, mel_loss=0.04852, linear_loss=0.05495]
[2020-05-11 18:36:42.741]  Generated 32 batches of size 32 in 1.790 sec
[2020-05-11 18:36:43.735]  Step 142604  [3.317 sec/step, loss=0.09729, avg_loss=0.09605, mel_loss=0.04451, linear_loss=0.05278]
[2020-05-11 18:36:51.206]  Step 142605  [3.360 sec/step, loss=0.10443, avg_loss=0.09614, mel_loss=0.04990, linear_loss=0.05452]
[2020-05-11 18:36:52.800]  Step 142606  [3.362 sec/step, loss=0.09233, avg_loss=0.09631, mel_loss=0.04176, linear_loss=0.05056]
[2020-05-11 18:36:55.148]  Step 142607  [3.353 sec/step, loss=0.09897, avg_loss=0.09633, mel_loss=0.04551, linear_loss=0.05346]
[2020-05-11 18:36:56.360]  Step 142608  [3.215 sec/step, loss=0.08870, avg_loss=0.09643, mel_loss=0.04015, linear_loss=0.04854]
[2020-05-11 18:36:58.258]  Step 142609  [3.174 sec/step, loss=0.09715, avg_loss=0.09639, mel_loss=0.04367, linear_loss=0.05348]
[2020-05-11 18:37:01.100]  Step 142610  [3.193 sec/step, loss=0.09985, avg_loss=0.09651, mel_loss=0.04637, linear_loss=0.05348]
[2020-05-11 18:37:04.644]  Step 142611  [3.185 sec/step, loss=0.10075, avg_loss=0.09647, mel_loss=0.04684, linear_loss=0.05391]
[2020-05-11 18:37:05.444]  Step 142612  [3.174 sec/step, loss=0.08263, avg_loss=0.09634, mel_loss=0.03678, linear_loss=0.04585]
[2020-05-11 18:37:06.002]  Step 142613  [3.163 sec/step, loss=0.07479, avg_loss=0.09614, mel_loss=0.03389, linear_loss=0.04090]
[2020-05-11 18:37:08.366]  Step 142614  [3.175 sec/step, loss=0.09844, avg_loss=0.09621, mel_loss=0.04485, linear_loss=0.05359]
[2020-05-11 18:37:20.542]  Step 142615  [3.248 sec/step, loss=0.08886, avg_loss=0.09608, mel_loss=0.04293, linear_loss=0.04593]
[2020-05-11 18:37:22.722]  Step 142616  [3.261 sec/step, loss=0.09772, avg_loss=0.09614, mel_loss=0.04458, linear_loss=0.05314]
[2020-05-11 18:37:27.002]  Step 142617  [3.295 sec/step, loss=0.10144, avg_loss=0.09631, mel_loss=0.04706, linear_loss=0.05438]
[2020-05-11 18:37:28.095]  Step 142618  [3.292 sec/step, loss=0.09019, avg_loss=0.09628, mel_loss=0.03987, linear_loss=0.05032]
[2020-05-11 18:37:33.081]  Step 142619  [3.298 sec/step, loss=0.10173, avg_loss=0.09629, mel_loss=0.04769, linear_loss=0.05404]
[2020-05-11 18:37:37.011]  Step 142620  [3.322 sec/step, loss=0.10315, avg_loss=0.09634, mel_loss=0.04810, linear_loss=0.05506]
[2020-05-11 18:37:40.485]  Step 142621  [3.342 sec/step, loss=0.10292, avg_loss=0.09645, mel_loss=0.04746, linear_loss=0.05546]
[2020-05-11 18:37:47.976]  Step 142622  [3.355 sec/step, loss=0.10442, avg_loss=0.09646, mel_loss=0.04969, linear_loss=0.05474]
[2020-05-11 18:37:49.216]  Step 142623  [3.315 sec/step, loss=0.08860, avg_loss=0.09630, mel_loss=0.04028, linear_loss=0.04832]
[2020-05-11 18:37:50.022]  Step 142624  [3.298 sec/step, loss=0.08257, avg_loss=0.09613, mel_loss=0.03682, linear_loss=0.04575]
[2020-05-11 18:37:58.027]  Step 142625  [3.370 sec/step, loss=0.10192, avg_loss=0.09630, mel_loss=0.04863, linear_loss=0.05329]
[2020-05-11 18:37:59.033]  Step 142626  [3.236 sec/step, loss=0.08978, avg_loss=0.09639, mel_loss=0.04046, linear_loss=0.04931]
[2020-05-11 18:37:59.672]  Step 142627  [3.229 sec/step, loss=0.08285, avg_loss=0.09631, mel_loss=0.03738, linear_loss=0.04547]
[2020-05-11 18:38:05.803]  Step 142628  [3.257 sec/step, loss=0.10268, avg_loss=0.09632, mel_loss=0.04847, linear_loss=0.05421]
[2020-05-11 18:38:07.716]  Step 142629  [3.264 sec/step, loss=0.09772, avg_loss=0.09638, mel_loss=0.04399, linear_loss=0.05373]
[2020-05-11 18:38:12.190]  Step 142630  [3.263 sec/step, loss=0.10434, avg_loss=0.09639, mel_loss=0.04911, linear_loss=0.05524]
[2020-05-11 18:38:14.415]  Step 142631  [3.275 sec/step, loss=0.09906, avg_loss=0.09649, mel_loss=0.04562, linear_loss=0.05344]
[2020-05-11 18:38:16.185]  Step 142632  [3.276 sec/step, loss=0.09503, avg_loss=0.09646, mel_loss=0.04301, linear_loss=0.05203]
[2020-05-11 18:38:17.095]  Step 142633  [3.269 sec/step, loss=0.08813, avg_loss=0.09639, mel_loss=0.03905, linear_loss=0.04908]
[2020-05-11 18:38:19.072]  Step 142634  [3.208 sec/step, loss=0.09612, avg_loss=0.09631, mel_loss=0.04372, linear_loss=0.05240]
[2020-05-11 18:38:20.402]  Step 142635  [3.187 sec/step, loss=0.09331, avg_loss=0.09622, mel_loss=0.04220, linear_loss=0.05112]
[2020-05-11 18:38:22.108]  Generated 32 batches of size 32 in 1.702 sec
[2020-05-11 18:38:23.328]  Step 142636  [3.180 sec/step, loss=0.10153, avg_loss=0.09619, mel_loss=0.04666, linear_loss=0.05487]
[2020-05-11 18:38:25.924]  Step 142637  [3.185 sec/step, loss=0.10091, avg_loss=0.09621, mel_loss=0.04659, linear_loss=0.05431]
[2020-05-11 18:38:29.392]  Step 142638  [3.180 sec/step, loss=0.09992, avg_loss=0.09616, mel_loss=0.04627, linear_loss=0.05365]
[2020-05-11 18:38:30.802]  Step 142639  [3.174 sec/step, loss=0.09430, avg_loss=0.09614, mel_loss=0.04280, linear_loss=0.05150]
[2020-05-11 18:38:33.871]  Step 142640  [3.185 sec/step, loss=0.10048, avg_loss=0.09617, mel_loss=0.04628, linear_loss=0.05420]
[2020-05-11 18:38:39.436]  Step 142641  [3.166 sec/step, loss=0.10382, avg_loss=0.09615, mel_loss=0.04879, linear_loss=0.05503]
[2020-05-11 18:38:41.157]  Step 142642  [3.153 sec/step, loss=0.09683, avg_loss=0.09611, mel_loss=0.04372, linear_loss=0.05311]
[2020-05-11 18:38:44.377]  Step 142643  [3.175 sec/step, loss=0.10278, avg_loss=0.09624, mel_loss=0.04749, linear_loss=0.05530]
[2020-05-11 18:38:45.985]  Step 142644  [3.147 sec/step, loss=0.09302, avg_loss=0.09614, mel_loss=0.04208, linear_loss=0.05094]
[2020-05-11 18:38:48.744]  Step 142645  [3.147 sec/step, loss=0.09965, avg_loss=0.09616, mel_loss=0.04625, linear_loss=0.05341]
[2020-05-11 18:38:49.606]  Step 142646  [3.125 sec/step, loss=0.07948, avg_loss=0.09592, mel_loss=0.03536, linear_loss=0.04411]
[2020-05-11 18:39:03.837]  Step 142647  [3.256 sec/step, loss=0.08194, avg_loss=0.09581, mel_loss=0.04009, linear_loss=0.04185]
[2020-05-11 18:39:07.924]  Step 142648  [3.279 sec/step, loss=0.10219, avg_loss=0.09588, mel_loss=0.04713, linear_loss=0.05506]
[2020-05-11 18:39:10.603]  Step 142649  [3.283 sec/step, loss=0.09683, avg_loss=0.09588, mel_loss=0.04447, linear_loss=0.05236]
[2020-05-11 18:39:11.349]  Step 142650  [3.285 sec/step, loss=0.08002, avg_loss=0.09587, mel_loss=0.03697, linear_loss=0.04305]
[2020-05-11 18:39:11.349]  Writing summary at step: 142650
[2020-05-11 18:39:12.982]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142650
[2020-05-11 18:39:14.280]  Saving audio and alignment...
[2020-05-11 18:39:17.804]  Input: 그분들은 과연 지금 은주씨 나이에~________
[2020-05-11 18:39:21.260]  Step 142651  [3.247 sec/step, loss=0.09838, avg_loss=0.09582, mel_loss=0.04539, linear_loss=0.05299]
[2020-05-11 18:39:23.506]  Step 142652  [3.213 sec/step, loss=0.09654, avg_loss=0.09576, mel_loss=0.04417, linear_loss=0.05237]
[2020-05-11 18:39:24.850]  Step 142653  [3.086 sec/step, loss=0.08987, avg_loss=0.09586, mel_loss=0.04025, linear_loss=0.04962]
[2020-05-11 18:39:29.782]  Step 142654  [3.045 sec/step, loss=0.10465, avg_loss=0.09587, mel_loss=0.04949, linear_loss=0.05516]
[2020-05-11 18:39:35.378]  Step 142655  [3.086 sec/step, loss=0.10280, avg_loss=0.09598, mel_loss=0.04837, linear_loss=0.05444]
[2020-05-11 18:39:36.327]  Step 142656  [3.069 sec/step, loss=0.08803, avg_loss=0.09586, mel_loss=0.03941, linear_loss=0.04862]
[2020-05-11 18:39:37.471]  Step 142657  [3.075 sec/step, loss=0.08860, avg_loss=0.09597, mel_loss=0.03980, linear_loss=0.04880]
[2020-05-11 18:39:38.513]  Step 142658  [3.039 sec/step, loss=0.08942, avg_loss=0.09584, mel_loss=0.03999, linear_loss=0.04943]
[2020-05-11 18:39:41.900]  Step 142659  [3.057 sec/step, loss=0.10088, avg_loss=0.09588, mel_loss=0.04668, linear_loss=0.05420]
[2020-05-11 18:39:43.404]  Step 142660  [3.041 sec/step, loss=0.09528, avg_loss=0.09581, mel_loss=0.04326, linear_loss=0.05202]
[2020-05-11 18:39:51.065]  Step 142661  [3.098 sec/step, loss=0.10255, avg_loss=0.09587, mel_loss=0.04858, linear_loss=0.05397]
[2020-05-11 18:39:52.099]  Step 142662  [3.084 sec/step, loss=0.08755, avg_loss=0.09576, mel_loss=0.03920, linear_loss=0.04835]
[2020-05-11 18:39:56.904]  Step 142663  [3.125 sec/step, loss=0.10300, avg_loss=0.09596, mel_loss=0.04787, linear_loss=0.05514]
[2020-05-11 18:39:57.671]  Step 142664  [3.120 sec/step, loss=0.08868, avg_loss=0.09595, mel_loss=0.03972, linear_loss=0.04896]
[2020-05-11 18:39:59.505]  Step 142665  [3.128 sec/step, loss=0.09668, avg_loss=0.09607, mel_loss=0.04406, linear_loss=0.05263]
[2020-05-11 18:40:01.153]  Generated 32 batches of size 32 in 1.643 sec
[2020-05-11 18:40:02.707]  Step 142666  [3.143 sec/step, loss=0.10255, avg_loss=0.09615, mel_loss=0.04723, linear_loss=0.05532]
[2020-05-11 18:40:04.087]  Step 142667  [3.122 sec/step, loss=0.09389, avg_loss=0.09607, mel_loss=0.04252, linear_loss=0.05137]
[2020-05-11 18:40:13.222]  Step 142668  [3.161 sec/step, loss=0.10406, avg_loss=0.09610, mel_loss=0.04983, linear_loss=0.05423]
[2020-05-11 18:40:15.808]  Step 142669  [3.170 sec/step, loss=0.10076, avg_loss=0.09616, mel_loss=0.04611, linear_loss=0.05465]
[2020-05-11 18:40:19.948]  Step 142670  [3.182 sec/step, loss=0.10433, avg_loss=0.09619, mel_loss=0.04879, linear_loss=0.05554]
[2020-05-11 18:40:26.688]  Step 142671  [3.229 sec/step, loss=0.10348, avg_loss=0.09626, mel_loss=0.04908, linear_loss=0.05440]
[2020-05-11 18:40:28.694]  Step 142672  [3.224 sec/step, loss=0.09689, avg_loss=0.09625, mel_loss=0.04381, linear_loss=0.05308]
[2020-05-11 18:40:30.392]  Step 142673  [3.228 sec/step, loss=0.09526, avg_loss=0.09626, mel_loss=0.04323, linear_loss=0.05204]
[2020-05-11 18:40:34.073]  Step 142674  [3.257 sec/step, loss=0.10412, avg_loss=0.09641, mel_loss=0.04834, linear_loss=0.05578]
[2020-05-11 18:40:39.387]  Step 142675  [3.242 sec/step, loss=0.10256, avg_loss=0.09639, mel_loss=0.04801, linear_loss=0.05455]
[2020-05-11 18:40:40.150]  Step 142676  [3.209 sec/step, loss=0.08297, avg_loss=0.09620, mel_loss=0.03752, linear_loss=0.04544]
[2020-05-11 18:40:44.017]  Step 142677  [3.237 sec/step, loss=0.10260, avg_loss=0.09634, mel_loss=0.04778, linear_loss=0.05482]
[2020-05-11 18:40:44.924]  Step 142678  [3.209 sec/step, loss=0.08825, avg_loss=0.09618, mel_loss=0.03902, linear_loss=0.04922]
[2020-05-11 18:40:46.034]  Step 142679  [3.185 sec/step, loss=0.09214, avg_loss=0.09609, mel_loss=0.04097, linear_loss=0.05117]
[2020-05-11 18:40:48.086]  Step 142680  [3.184 sec/step, loss=0.09801, avg_loss=0.09608, mel_loss=0.04472, linear_loss=0.05329]
[2020-05-11 18:40:48.613]  Step 142681  [3.179 sec/step, loss=0.07506, avg_loss=0.09597, mel_loss=0.03473, linear_loss=0.04034]
[2020-05-11 18:40:51.126]  Step 142682  [3.163 sec/step, loss=0.10006, avg_loss=0.09594, mel_loss=0.04573, linear_loss=0.05433]
[2020-05-11 18:40:54.136]  Step 142683  [3.184 sec/step, loss=0.10299, avg_loss=0.09613, mel_loss=0.04790, linear_loss=0.05509]
[2020-05-11 18:40:55.359]  Step 142684  [3.114 sec/step, loss=0.09267, avg_loss=0.09604, mel_loss=0.04178, linear_loss=0.05089]
[2020-05-11 18:40:57.956]  Step 142685  [3.097 sec/step, loss=0.09886, avg_loss=0.09600, mel_loss=0.04577, linear_loss=0.05309]
[2020-05-11 18:41:01.616]  Step 142686  [3.114 sec/step, loss=0.10237, avg_loss=0.09605, mel_loss=0.04752, linear_loss=0.05485]
[2020-05-11 18:41:05.912]  Step 142687  [3.090 sec/step, loss=0.10001, avg_loss=0.09601, mel_loss=0.04616, linear_loss=0.05385]
[2020-05-11 18:41:20.335]  Step 142688  [3.178 sec/step, loss=0.10264, avg_loss=0.09602, mel_loss=0.04911, linear_loss=0.05353]
[2020-05-11 18:41:33.102]  Step 142689  [3.298 sec/step, loss=0.09189, avg_loss=0.09610, mel_loss=0.04457, linear_loss=0.04732]
[2020-05-11 18:41:33.913]  Step 142690  [3.296 sec/step, loss=0.08155, avg_loss=0.09599, mel_loss=0.03652, linear_loss=0.04504]
[2020-05-11 18:41:37.323]  Step 142691  [3.320 sec/step, loss=0.10141, avg_loss=0.09609, mel_loss=0.04700, linear_loss=0.05441]
[2020-05-11 18:41:38.974]  Step 142692  [3.305 sec/step, loss=0.09635, avg_loss=0.09601, mel_loss=0.04381, linear_loss=0.05254]
[2020-05-11 18:41:40.733]  Step 142693  [3.309 sec/step, loss=0.09421, avg_loss=0.09600, mel_loss=0.04246, linear_loss=0.05175]
[2020-05-11 18:41:42.904]  Step 142694  [3.301 sec/step, loss=0.09905, avg_loss=0.09597, mel_loss=0.04538, linear_loss=0.05367]
[2020-05-11 18:41:47.629]  Step 142695  [3.334 sec/step, loss=0.10215, avg_loss=0.09609, mel_loss=0.04778, linear_loss=0.05437]
[2020-05-11 18:41:53.257]  Step 142696  [3.352 sec/step, loss=0.10247, avg_loss=0.09609, mel_loss=0.04834, linear_loss=0.05412]
[2020-05-11 18:41:59.644]  Step 142697  [3.383 sec/step, loss=0.10425, avg_loss=0.09612, mel_loss=0.04961, linear_loss=0.05463]
[2020-05-11 18:42:01.099]  Step 142698  [3.376 sec/step, loss=0.09284, avg_loss=0.09608, mel_loss=0.04194, linear_loss=0.05090]
[2020-05-11 18:42:01.369]  Generated 32 batches of size 32 in 1.719 sec
[2020-05-11 18:42:08.504]  Step 142699  [3.432 sec/step, loss=0.10430, avg_loss=0.09617, mel_loss=0.04982, linear_loss=0.05448]
[2020-05-11 18:42:09.537]  Step 142700  [3.421 sec/step, loss=0.08612, avg_loss=0.09604, mel_loss=0.03852, linear_loss=0.04761]
[2020-05-11 18:42:09.537]  Writing summary at step: 142700
[2020-05-11 18:42:11.065]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142700
[2020-05-11 18:42:12.343]  Saving audio and alignment...
[2020-05-11 18:42:15.501]  Input: 다른 처리해 주시고요~_________________________
[2020-05-11 18:42:17.908]  Step 142701  [3.314 sec/step, loss=0.09503, avg_loss=0.09612, mel_loss=0.04328, linear_loss=0.05175]
[2020-05-11 18:42:22.250]  Step 142702  [3.341 sec/step, loss=0.10270, avg_loss=0.09619, mel_loss=0.04809, linear_loss=0.05461]
[2020-05-11 18:42:23.580]  Step 142703  [3.302 sec/step, loss=0.09174, avg_loss=0.09607, mel_loss=0.04128, linear_loss=0.05046]
[2020-05-11 18:42:26.441]  Step 142704  [3.303 sec/step, loss=0.10025, avg_loss=0.09610, mel_loss=0.04600, linear_loss=0.05424]
[2020-05-11 18:42:31.695]  Step 142705  [3.280 sec/step, loss=0.10269, avg_loss=0.09608, mel_loss=0.04826, linear_loss=0.05442]
[2020-05-11 18:42:35.764]  Step 142706  [3.305 sec/step, loss=0.10214, avg_loss=0.09618, mel_loss=0.04729, linear_loss=0.05485]
[2020-05-11 18:42:37.116]  Step 142707  [3.295 sec/step, loss=0.09404, avg_loss=0.09613, mel_loss=0.04260, linear_loss=0.05144]
[2020-05-11 18:42:37.651]  Step 142708  [3.288 sec/step, loss=0.07840, avg_loss=0.09603, mel_loss=0.03590, linear_loss=0.04250]
[2020-05-11 18:42:38.965]  Step 142709  [3.283 sec/step, loss=0.09238, avg_loss=0.09598, mel_loss=0.04159, linear_loss=0.05079]
[2020-05-11 18:42:42.298]  Step 142710  [3.288 sec/step, loss=0.10144, avg_loss=0.09600, mel_loss=0.04683, linear_loss=0.05461]
[2020-05-11 18:42:43.781]  Step 142711  [3.267 sec/step, loss=0.09402, avg_loss=0.09593, mel_loss=0.04234, linear_loss=0.05168]
[2020-05-11 18:42:46.753]  Step 142712  [3.289 sec/step, loss=0.10100, avg_loss=0.09611, mel_loss=0.04638, linear_loss=0.05462]
[2020-05-11 18:42:49.088]  Step 142713  [3.306 sec/step, loss=0.09749, avg_loss=0.09634, mel_loss=0.04460, linear_loss=0.05289]
[2020-05-11 18:42:50.219]  Step 142714  [3.294 sec/step, loss=0.09114, avg_loss=0.09627, mel_loss=0.04091, linear_loss=0.05023]
[2020-05-11 18:42:53.098]  Step 142715  [3.201 sec/step, loss=0.09997, avg_loss=0.09638, mel_loss=0.04608, linear_loss=0.05389]
[2020-05-11 18:42:54.740]  Step 142716  [3.196 sec/step, loss=0.09538, avg_loss=0.09636, mel_loss=0.04368, linear_loss=0.05170]
[2020-05-11 18:42:55.711]  Step 142717  [3.163 sec/step, loss=0.09103, avg_loss=0.09625, mel_loss=0.04108, linear_loss=0.04995]
[2020-05-11 18:42:56.509]  Step 142718  [3.160 sec/step, loss=0.08370, avg_loss=0.09619, mel_loss=0.03737, linear_loss=0.04633]
[2020-05-11 18:42:58.238]  Step 142719  [3.127 sec/step, loss=0.09584, avg_loss=0.09613, mel_loss=0.04366, linear_loss=0.05218]
[2020-05-11 18:43:12.709]  Step 142720  [3.233 sec/step, loss=0.08078, avg_loss=0.09590, mel_loss=0.03955, linear_loss=0.04123]
[2020-05-11 18:43:14.694]  Step 142721  [3.218 sec/step, loss=0.09760, avg_loss=0.09585, mel_loss=0.04441, linear_loss=0.05318]
[2020-05-11 18:43:16.523]  Step 142722  [3.161 sec/step, loss=0.09604, avg_loss=0.09577, mel_loss=0.04370, linear_loss=0.05234]
[2020-05-11 18:43:22.196]  Step 142723  [3.205 sec/step, loss=0.10464, avg_loss=0.09593, mel_loss=0.04930, linear_loss=0.05534]
[2020-05-11 18:43:23.069]  Step 142724  [3.206 sec/step, loss=0.07697, avg_loss=0.09587, mel_loss=0.03430, linear_loss=0.04268]
[2020-05-11 18:43:30.549]  Step 142725  [3.201 sec/step, loss=0.10530, avg_loss=0.09590, mel_loss=0.05032, linear_loss=0.05499]
[2020-05-11 18:43:34.207]  Step 142726  [3.227 sec/step, loss=0.10459, avg_loss=0.09605, mel_loss=0.04861, linear_loss=0.05599]
[2020-05-11 18:43:35.171]  Step 142727  [3.231 sec/step, loss=0.09012, avg_loss=0.09613, mel_loss=0.04019, linear_loss=0.04994]
[2020-05-11 18:43:36.867]  Generated 32 batches of size 32 in 1.691 sec
[2020-05-11 18:43:37.455]  Step 142728  [3.192 sec/step, loss=0.09842, avg_loss=0.09608, mel_loss=0.04521, linear_loss=0.05321]
[2020-05-11 18:43:44.017]  Step 142729  [3.239 sec/step, loss=0.10430, avg_loss=0.09615, mel_loss=0.04931, linear_loss=0.05500]
[2020-05-11 18:43:48.333]  Step 142730  [3.237 sec/step, loss=0.10470, avg_loss=0.09615, mel_loss=0.04896, linear_loss=0.05575]
[2020-05-11 18:43:49.404]  Step 142731  [3.225 sec/step, loss=0.09180, avg_loss=0.09608, mel_loss=0.04101, linear_loss=0.05079]
[2020-05-11 18:43:54.124]  Step 142732  [3.255 sec/step, loss=0.10362, avg_loss=0.09617, mel_loss=0.04839, linear_loss=0.05523]
[2020-05-11 18:43:56.827]  Step 142733  [3.273 sec/step, loss=0.10124, avg_loss=0.09630, mel_loss=0.04650, linear_loss=0.05473]
[2020-05-11 18:44:00.022]  Step 142734  [3.285 sec/step, loss=0.10103, avg_loss=0.09635, mel_loss=0.04685, linear_loss=0.05418]
[2020-05-11 18:44:08.463]  Step 142735  [3.356 sec/step, loss=0.10250, avg_loss=0.09644, mel_loss=0.04916, linear_loss=0.05334]
[2020-05-11 18:44:10.639]  Step 142736  [3.349 sec/step, loss=0.09551, avg_loss=0.09638, mel_loss=0.04363, linear_loss=0.05188]
[2020-05-11 18:44:12.365]  Step 142737  [3.340 sec/step, loss=0.09678, avg_loss=0.09634, mel_loss=0.04395, linear_loss=0.05283]
[2020-05-11 18:44:15.425]  Step 142738  [3.336 sec/step, loss=0.10363, avg_loss=0.09637, mel_loss=0.04778, linear_loss=0.05584]
[2020-05-11 18:44:17.582]  Step 142739  [3.343 sec/step, loss=0.10024, avg_loss=0.09643, mel_loss=0.04570, linear_loss=0.05453]
[2020-05-11 18:44:22.638]  Step 142740  [3.363 sec/step, loss=0.10141, avg_loss=0.09644, mel_loss=0.04761, linear_loss=0.05381]
[2020-05-11 18:44:24.271]  Step 142741  [3.324 sec/step, loss=0.09702, avg_loss=0.09637, mel_loss=0.04380, linear_loss=0.05322]
[2020-05-11 18:44:27.633]  Step 142742  [3.340 sec/step, loss=0.10399, avg_loss=0.09645, mel_loss=0.04832, linear_loss=0.05567]
[2020-05-11 18:44:41.784]  Step 142743  [3.450 sec/step, loss=0.07994, avg_loss=0.09622, mel_loss=0.03898, linear_loss=0.04095]
[2020-05-11 18:44:42.779]  Step 142744  [3.444 sec/step, loss=0.08560, avg_loss=0.09614, mel_loss=0.03824, linear_loss=0.04736]
[2020-05-11 18:44:43.811]  Step 142745  [3.426 sec/step, loss=0.08578, avg_loss=0.09600, mel_loss=0.03872, linear_loss=0.04706]
[2020-05-11 18:44:46.257]  Step 142746  [3.442 sec/step, loss=0.09965, avg_loss=0.09621, mel_loss=0.04551, linear_loss=0.05415]
[2020-05-11 18:44:52.729]  Step 142747  [3.364 sec/step, loss=0.10236, avg_loss=0.09641, mel_loss=0.04846, linear_loss=0.05391]
[2020-05-11 18:45:00.374]  Step 142748  [3.400 sec/step, loss=0.10370, avg_loss=0.09643, mel_loss=0.04940, linear_loss=0.05430]
[2020-05-11 18:45:01.201]  Step 142749  [3.382 sec/step, loss=0.08422, avg_loss=0.09630, mel_loss=0.03771, linear_loss=0.04651]
[2020-05-11 18:45:06.777]  Step 142750  [3.430 sec/step, loss=0.10471, avg_loss=0.09655, mel_loss=0.04930, linear_loss=0.05541]
[2020-05-11 18:45:06.777]  Writing summary at step: 142750
[2020-05-11 18:45:09.718]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142750
[2020-05-11 18:45:11.596]  Saving audio and alignment...
[2020-05-11 18:45:13.847]  Input: 이렇게 적혀 있습니다~_____
[2020-05-11 18:45:15.637]  Step 142751  [3.413 sec/step, loss=0.09705, avg_loss=0.09653, mel_loss=0.04406, linear_loss=0.05299]
[2020-05-11 18:45:17.016]  Step 142752  [3.405 sec/step, loss=0.09193, avg_loss=0.09649, mel_loss=0.04156, linear_loss=0.05036]
[2020-05-11 18:45:26.463]  Step 142753  [3.486 sec/step, loss=0.10357, avg_loss=0.09662, mel_loss=0.04950, linear_loss=0.05408]
[2020-05-11 18:45:31.112]  Step 142754  [3.483 sec/step, loss=0.10327, avg_loss=0.09661, mel_loss=0.04811, linear_loss=0.05515]
[2020-05-11 18:45:33.129]  Step 142755  [3.447 sec/step, loss=0.09639, avg_loss=0.09655, mel_loss=0.04395, linear_loss=0.05245]
[2020-05-11 18:45:35.509]  Step 142756  [3.461 sec/step, loss=0.09735, avg_loss=0.09664, mel_loss=0.04449, linear_loss=0.05286]
[2020-05-11 18:45:37.473]  Step 142757  [3.469 sec/step, loss=0.09652, avg_loss=0.09672, mel_loss=0.04405, linear_loss=0.05248]
[2020-05-11 18:45:38.791]  Step 142758  [3.472 sec/step, loss=0.09177, avg_loss=0.09674, mel_loss=0.04152, linear_loss=0.05025]
[2020-05-11 18:45:39.207]  Generated 32 batches of size 32 in 1.730 sec
[2020-05-11 18:45:42.397]  Step 142759  [3.474 sec/step, loss=0.10392, avg_loss=0.09677, mel_loss=0.04806, linear_loss=0.05585]
[2020-05-11 18:45:43.187]  Step 142760  [3.467 sec/step, loss=0.07908, avg_loss=0.09661, mel_loss=0.03566, linear_loss=0.04342]
[2020-05-11 18:45:46.678]  Step 142761  [3.426 sec/step, loss=0.09952, avg_loss=0.09658, mel_loss=0.04598, linear_loss=0.05355]
[2020-05-11 18:45:50.788]  Step 142762  [3.456 sec/step, loss=0.10217, avg_loss=0.09673, mel_loss=0.04741, linear_loss=0.05476]
[2020-05-11 18:45:51.353]  Step 142763  [3.414 sec/step, loss=0.07876, avg_loss=0.09648, mel_loss=0.03663, linear_loss=0.04213]
[2020-05-11 18:45:55.144]  Step 142764  [3.444 sec/step, loss=0.10340, avg_loss=0.09663, mel_loss=0.04818, linear_loss=0.05522]
[2020-05-11 18:45:57.802]  Step 142765  [3.452 sec/step, loss=0.09817, avg_loss=0.09665, mel_loss=0.04514, linear_loss=0.05303]
[2020-05-11 18:45:59.268]  Step 142766  [3.435 sec/step, loss=0.09307, avg_loss=0.09655, mel_loss=0.04212, linear_loss=0.05095]
[2020-05-11 18:46:00.669]  Step 142767  [3.435 sec/step, loss=0.09132, avg_loss=0.09653, mel_loss=0.04121, linear_loss=0.05011]
[2020-05-11 18:46:01.917]  Step 142768  [3.356 sec/step, loss=0.09027, avg_loss=0.09639, mel_loss=0.04052, linear_loss=0.04975]
[2020-05-11 18:46:04.462]  Step 142769  [3.356 sec/step, loss=0.09760, avg_loss=0.09636, mel_loss=0.04442, linear_loss=0.05318]
[2020-05-11 18:46:06.787]  Step 142770  [3.338 sec/step, loss=0.09700, avg_loss=0.09628, mel_loss=0.04443, linear_loss=0.05257]
[2020-05-11 18:46:07.809]  Step 142771  [3.281 sec/step, loss=0.08782, avg_loss=0.09613, mel_loss=0.03942, linear_loss=0.04840]
[2020-05-11 18:46:09.585]  Step 142772  [3.278 sec/step, loss=0.09667, avg_loss=0.09612, mel_loss=0.04404, linear_loss=0.05262]
[2020-05-11 18:46:10.452]  Step 142773  [3.270 sec/step, loss=0.07883, avg_loss=0.09596, mel_loss=0.03589, linear_loss=0.04294]
[2020-05-11 18:46:11.283]  Step 142774  [3.242 sec/step, loss=0.08284, avg_loss=0.09575, mel_loss=0.03732, linear_loss=0.04552]
[2020-05-11 18:46:12.671]  Step 142775  [3.202 sec/step, loss=0.09453, avg_loss=0.09567, mel_loss=0.04289, linear_loss=0.05164]
[2020-05-11 18:46:15.577]  Step 142776  [3.224 sec/step, loss=0.10208, avg_loss=0.09586, mel_loss=0.04700, linear_loss=0.05508]
[2020-05-11 18:46:17.588]  Step 142777  [3.205 sec/step, loss=0.09730, avg_loss=0.09580, mel_loss=0.04433, linear_loss=0.05297]
[2020-05-11 18:46:19.712]  Step 142778  [3.217 sec/step, loss=0.09770, avg_loss=0.09590, mel_loss=0.04449, linear_loss=0.05322]
[2020-05-11 18:46:20.604]  Step 142779  [3.215 sec/step, loss=0.09019, avg_loss=0.09588, mel_loss=0.04002, linear_loss=0.05017]
[2020-05-11 18:46:27.742]  Step 142780  [3.266 sec/step, loss=0.10531, avg_loss=0.09595, mel_loss=0.05020, linear_loss=0.05511]
[2020-05-11 18:46:41.910]  Step 142781  [3.402 sec/step, loss=0.08112, avg_loss=0.09601, mel_loss=0.03949, linear_loss=0.04163]
[2020-05-11 18:46:45.523]  Step 142782  [3.413 sec/step, loss=0.10408, avg_loss=0.09605, mel_loss=0.04822, linear_loss=0.05586]
[2020-05-11 18:46:47.490]  Step 142783  [3.403 sec/step, loss=0.09668, avg_loss=0.09599, mel_loss=0.04350, linear_loss=0.05317]
[2020-05-11 18:46:48.587]  Step 142784  [3.402 sec/step, loss=0.09195, avg_loss=0.09598, mel_loss=0.04121, linear_loss=0.05074]
[2020-05-11 18:46:49.143]  Step 142785  [3.381 sec/step, loss=0.07801, avg_loss=0.09577, mel_loss=0.03528, linear_loss=0.04274]
[2020-05-11 18:46:54.863]  Step 142786  [3.402 sec/step, loss=0.10306, avg_loss=0.09578, mel_loss=0.04866, linear_loss=0.05440]
[2020-05-11 18:46:57.944]  Step 142787  [3.390 sec/step, loss=0.10378, avg_loss=0.09582, mel_loss=0.04805, linear_loss=0.05573]
[2020-05-11 18:47:01.388]  Step 142788  [3.280 sec/step, loss=0.10311, avg_loss=0.09582, mel_loss=0.04756, linear_loss=0.05555]
[2020-05-11 18:47:05.142]  Step 142789  [3.190 sec/step, loss=0.10170, avg_loss=0.09592, mel_loss=0.04708, linear_loss=0.05462]
[2020-05-11 18:47:06.883]  Generated 32 batches of size 32 in 1.735 sec
[2020-05-11 18:47:06.966]  Step 142790  [3.200 sec/step, loss=0.09679, avg_loss=0.09607, mel_loss=0.04389, linear_loss=0.05290]
[2020-05-11 18:47:15.403]  Step 142791  [3.250 sec/step, loss=0.10377, avg_loss=0.09610, mel_loss=0.04970, linear_loss=0.05407]
[2020-05-11 18:47:19.416]  Step 142792  [3.274 sec/step, loss=0.10242, avg_loss=0.09616, mel_loss=0.04786, linear_loss=0.05456]
[2020-05-11 18:47:23.916]  Step 142793  [3.301 sec/step, loss=0.10380, avg_loss=0.09625, mel_loss=0.04851, linear_loss=0.05528]
[2020-05-11 18:47:26.649]  Step 142794  [3.307 sec/step, loss=0.10035, avg_loss=0.09627, mel_loss=0.04682, linear_loss=0.05353]
[2020-05-11 18:47:32.989]  Step 142795  [3.323 sec/step, loss=0.10413, avg_loss=0.09629, mel_loss=0.04938, linear_loss=0.05475]
[2020-05-11 18:47:34.574]  Step 142796  [3.283 sec/step, loss=0.09603, avg_loss=0.09622, mel_loss=0.04338, linear_loss=0.05265]
[2020-05-11 18:47:39.666]  Step 142797  [3.270 sec/step, loss=0.10325, avg_loss=0.09621, mel_loss=0.04834, linear_loss=0.05490]
[2020-05-11 18:47:43.140]  Step 142798  [3.290 sec/step, loss=0.10045, avg_loss=0.09629, mel_loss=0.04649, linear_loss=0.05396]
[2020-05-11 18:47:56.261]  Step 142799  [3.347 sec/step, loss=0.08514, avg_loss=0.09610, mel_loss=0.04130, linear_loss=0.04384]
[2020-05-11 18:48:01.610]  Step 142800  [3.390 sec/step, loss=0.10329, avg_loss=0.09627, mel_loss=0.04869, linear_loss=0.05460]
[2020-05-11 18:48:01.610]  Writing summary at step: 142800
[2020-05-11 18:48:09.939]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142800
[2020-05-11 18:48:11.254]  Saving audio and alignment...
[2020-05-11 18:48:17.163]  Input: 겠지요 장비 제대로 가지고 직접 체험해보는 우리 강지혜 리포터~__________
[2020-05-11 18:48:19.339]  Step 142801  [3.388 sec/step, loss=0.09441, avg_loss=0.09626, mel_loss=0.04322, linear_loss=0.05119]
[2020-05-11 18:48:23.022]  Step 142802  [3.381 sec/step, loss=0.09927, avg_loss=0.09623, mel_loss=0.04573, linear_loss=0.05354]
[2020-05-11 18:48:25.481]  Step 142803  [3.393 sec/step, loss=0.09881, avg_loss=0.09630, mel_loss=0.04539, linear_loss=0.05342]
[2020-05-11 18:48:26.616]  Step 142804  [3.375 sec/step, loss=0.09176, avg_loss=0.09621, mel_loss=0.04127, linear_loss=0.05050]
[2020-05-11 18:48:32.259]  Step 142805  [3.379 sec/step, loss=0.10252, avg_loss=0.09621, mel_loss=0.04818, linear_loss=0.05435]
[2020-05-11 18:48:34.658]  Step 142806  [3.362 sec/step, loss=0.09763, avg_loss=0.09617, mel_loss=0.04466, linear_loss=0.05296]
[2020-05-11 18:48:35.375]  Step 142807  [3.356 sec/step, loss=0.08462, avg_loss=0.09607, mel_loss=0.03762, linear_loss=0.04700]
[2020-05-11 18:48:40.207]  Step 142808  [3.399 sec/step, loss=0.10273, avg_loss=0.09632, mel_loss=0.04778, linear_loss=0.05495]
[2020-05-11 18:48:40.765]  Step 142809  [3.392 sec/step, loss=0.07558, avg_loss=0.09615, mel_loss=0.03499, linear_loss=0.04059]
[2020-05-11 18:48:42.322]  Step 142810  [3.374 sec/step, loss=0.09529, avg_loss=0.09609, mel_loss=0.04334, linear_loss=0.05195]
[2020-05-11 18:48:44.097]  Step 142811  [3.377 sec/step, loss=0.09442, avg_loss=0.09609, mel_loss=0.04256, linear_loss=0.05186]
[2020-05-11 18:48:47.591]  Step 142812  [3.382 sec/step, loss=0.10091, avg_loss=0.09609, mel_loss=0.04662, linear_loss=0.05429]
[2020-05-11 18:48:55.094]  Step 142813  [3.434 sec/step, loss=0.10366, avg_loss=0.09615, mel_loss=0.04902, linear_loss=0.05464]
[2020-05-11 18:48:59.260]  Step 142814  [3.464 sec/step, loss=0.10290, avg_loss=0.09627, mel_loss=0.04772, linear_loss=0.05518]
[2020-05-11 18:49:05.906]  Step 142815  [3.502 sec/step, loss=0.10293, avg_loss=0.09630, mel_loss=0.04852, linear_loss=0.05442]
[2020-05-11 18:49:07.533]  Step 142816  [3.501 sec/step, loss=0.09470, avg_loss=0.09629, mel_loss=0.04317, linear_loss=0.05153]
[2020-05-11 18:49:10.571]  Step 142817  [3.522 sec/step, loss=0.10237, avg_loss=0.09641, mel_loss=0.04718, linear_loss=0.05519]
[2020-05-11 18:49:11.896]  Step 142818  [3.527 sec/step, loss=0.08979, avg_loss=0.09647, mel_loss=0.04041, linear_loss=0.04938]
[2020-05-11 18:49:12.875]  Step 142819  [3.520 sec/step, loss=0.08756, avg_loss=0.09638, mel_loss=0.03866, linear_loss=0.04890]
[2020-05-11 18:49:14.803]  Step 142820  [3.394 sec/step, loss=0.09444, avg_loss=0.09652, mel_loss=0.04270, linear_loss=0.05174]
[2020-05-11 18:49:15.063]  Generated 32 batches of size 32 in 2.182 sec
[2020-05-11 18:49:15.926]  Step 142821  [3.386 sec/step, loss=0.08873, avg_loss=0.09643, mel_loss=0.03964, linear_loss=0.04909]
[2020-05-11 18:49:18.124]  Step 142822  [3.390 sec/step, loss=0.09641, avg_loss=0.09644, mel_loss=0.04385, linear_loss=0.05256]
[2020-05-11 18:49:18.877]  Step 142823  [3.340 sec/step, loss=0.08587, avg_loss=0.09625, mel_loss=0.03830, linear_loss=0.04757]
[2020-05-11 18:49:21.456]  Step 142824  [3.357 sec/step, loss=0.09862, avg_loss=0.09646, mel_loss=0.04526, linear_loss=0.05336]
[2020-05-11 18:49:22.465]  Step 142825  [3.293 sec/step, loss=0.08567, avg_loss=0.09627, mel_loss=0.03871, linear_loss=0.04696]
[2020-05-11 18:49:23.845]  Step 142826  [3.270 sec/step, loss=0.09415, avg_loss=0.09616, mel_loss=0.04277, linear_loss=0.05138]
[2020-05-11 18:49:27.148]  Step 142827  [3.293 sec/step, loss=0.10416, avg_loss=0.09630, mel_loss=0.04822, linear_loss=0.05593]
[2020-05-11 18:49:31.549]  Step 142828  [3.314 sec/step, loss=0.10433, avg_loss=0.09636, mel_loss=0.04888, linear_loss=0.05545]
[2020-05-11 18:49:33.758]  Step 142829  [3.271 sec/step, loss=0.09600, avg_loss=0.09628, mel_loss=0.04383, linear_loss=0.05217]
[2020-05-11 18:49:36.811]  Step 142830  [3.258 sec/step, loss=0.10206, avg_loss=0.09625, mel_loss=0.04701, linear_loss=0.05505]
[2020-05-11 18:49:51.157]  Step 142831  [3.391 sec/step, loss=0.07837, avg_loss=0.09612, mel_loss=0.03814, linear_loss=0.04023]
[2020-05-11 18:49:53.161]  Step 142832  [3.364 sec/step, loss=0.09643, avg_loss=0.09605, mel_loss=0.04393, linear_loss=0.05250]
[2020-05-11 18:49:55.409]  Step 142833  [3.359 sec/step, loss=0.09995, avg_loss=0.09603, mel_loss=0.04601, linear_loss=0.05394]
[2020-05-11 18:49:59.420]  Step 142834  [3.367 sec/step, loss=0.10232, avg_loss=0.09605, mel_loss=0.04745, linear_loss=0.05488]
[2020-05-11 18:50:00.780]  Step 142835  [3.297 sec/step, loss=0.09240, avg_loss=0.09595, mel_loss=0.04150, linear_loss=0.05090]
[2020-05-11 18:50:03.353]  Step 142836  [3.301 sec/step, loss=0.09700, avg_loss=0.09596, mel_loss=0.04434, linear_loss=0.05266]
[2020-05-11 18:50:07.060]  Step 142837  [3.320 sec/step, loss=0.10263, avg_loss=0.09602, mel_loss=0.04748, linear_loss=0.05515]
[2020-05-11 18:50:12.581]  Step 142838  [3.345 sec/step, loss=0.10190, avg_loss=0.09600, mel_loss=0.04797, linear_loss=0.05393]
[2020-05-11 18:50:19.517]  Step 142839  [3.393 sec/step, loss=0.10507, avg_loss=0.09605, mel_loss=0.04996, linear_loss=0.05512]
[2020-05-11 18:50:22.208]  Step 142840  [3.369 sec/step, loss=0.09979, avg_loss=0.09603, mel_loss=0.04594, linear_loss=0.05385]
[2020-05-11 18:50:22.964]  Step 142841  [3.360 sec/step, loss=0.08146, avg_loss=0.09588, mel_loss=0.03666, linear_loss=0.04480]
[2020-05-11 18:50:24.011]  Step 142842  [3.337 sec/step, loss=0.08497, avg_loss=0.09569, mel_loss=0.03837, linear_loss=0.04660]
[2020-05-11 18:50:25.238]  Step 142843  [3.208 sec/step, loss=0.08980, avg_loss=0.09579, mel_loss=0.04064, linear_loss=0.04916]
[2020-05-11 18:50:26.609]  Step 142844  [3.212 sec/step, loss=0.09283, avg_loss=0.09586, mel_loss=0.04222, linear_loss=0.05061]
[2020-05-11 18:50:29.494]  Step 142845  [3.230 sec/step, loss=0.10057, avg_loss=0.09601, mel_loss=0.04647, linear_loss=0.05410]
[2020-05-11 18:50:31.366]  Step 142846  [3.225 sec/step, loss=0.09370, avg_loss=0.09595, mel_loss=0.04231, linear_loss=0.05139]
[2020-05-11 18:50:31.965]  Step 142847  [3.166 sec/step, loss=0.07247, avg_loss=0.09565, mel_loss=0.03308, linear_loss=0.03939]
[2020-05-11 18:50:41.002]  Step 142848  [3.180 sec/step, loss=0.10248, avg_loss=0.09564, mel_loss=0.04881, linear_loss=0.05367]
[2020-05-11 18:50:42.291]  Step 142849  [3.184 sec/step, loss=0.09033, avg_loss=0.09570, mel_loss=0.03994, linear_loss=0.05039]
[2020-05-11 18:50:43.291]  Step 142850  [3.139 sec/step, loss=0.08669, avg_loss=0.09552, mel_loss=0.03873, linear_loss=0.04796]
[2020-05-11 18:50:43.291]  Writing summary at step: 142850
[2020-05-11 18:50:47.463]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142850
[2020-05-11 18:50:48.781]  Saving audio and alignment...
[2020-05-11 18:50:51.207]  Generated 32 batches of size 32 in 1.893 sec
[2020-05-11 18:50:54.623]  Input: 종결어미를 지금까지는 안정적으로 내리는 것을 배웠을 거예요~______
[2020-05-11 18:51:01.305]  Step 142851  [3.188 sec/step, loss=0.10174, avg_loss=0.09556, mel_loss=0.04825, linear_loss=0.05349]
[2020-05-11 18:51:02.934]  Step 142852  [3.190 sec/step, loss=0.09175, avg_loss=0.09556, mel_loss=0.04137, linear_loss=0.05038]
[2020-05-11 18:51:04.645]  Step 142853  [3.113 sec/step, loss=0.09475, avg_loss=0.09547, mel_loss=0.04294, linear_loss=0.05181]
[2020-05-11 18:51:09.826]  Step 142854  [3.118 sec/step, loss=0.10320, avg_loss=0.09547, mel_loss=0.04823, linear_loss=0.05497]
[2020-05-11 18:51:13.011]  Step 142855  [3.130 sec/step, loss=0.10263, avg_loss=0.09554, mel_loss=0.04730, linear_loss=0.05533]
[2020-05-11 18:51:17.626]  Step 142856  [3.152 sec/step, loss=0.10204, avg_loss=0.09558, mel_loss=0.04738, linear_loss=0.05465]
[2020-05-11 18:51:18.450]  Step 142857  [3.141 sec/step, loss=0.08201, avg_loss=0.09544, mel_loss=0.03648, linear_loss=0.04554]
[2020-05-11 18:51:20.368]  Step 142858  [3.147 sec/step, loss=0.09840, avg_loss=0.09550, mel_loss=0.04449, linear_loss=0.05391]
[2020-05-11 18:51:27.101]  Step 142859  [3.178 sec/step, loss=0.10251, avg_loss=0.09549, mel_loss=0.04806, linear_loss=0.05445]
[2020-05-11 18:51:40.089]  Step 142860  [3.300 sec/step, loss=0.10389, avg_loss=0.09574, mel_loss=0.04980, linear_loss=0.05409]
[2020-05-11 18:51:41.320]  Step 142861  [3.277 sec/step, loss=0.08838, avg_loss=0.09563, mel_loss=0.03971, linear_loss=0.04866]
[2020-05-11 18:51:42.162]  Step 142862  [3.245 sec/step, loss=0.08124, avg_loss=0.09542, mel_loss=0.03644, linear_loss=0.04480]
[2020-05-11 18:51:45.484]  Step 142863  [3.272 sec/step, loss=0.10210, avg_loss=0.09565, mel_loss=0.04731, linear_loss=0.05479]
[2020-05-11 18:51:48.903]  Step 142864  [3.268 sec/step, loss=0.10218, avg_loss=0.09564, mel_loss=0.04750, linear_loss=0.05467]
[2020-05-11 18:51:50.244]  Step 142865  [3.255 sec/step, loss=0.09421, avg_loss=0.09560, mel_loss=0.04229, linear_loss=0.05192]
[2020-05-11 18:51:52.864]  Step 142866  [3.267 sec/step, loss=0.09895, avg_loss=0.09566, mel_loss=0.04549, linear_loss=0.05347]
[2020-05-11 18:51:58.344]  Step 142867  [3.308 sec/step, loss=0.10317, avg_loss=0.09578, mel_loss=0.04860, linear_loss=0.05456]
[2020-05-11 18:52:01.331]  Step 142868  [3.325 sec/step, loss=0.09911, avg_loss=0.09586, mel_loss=0.04532, linear_loss=0.05379]
[2020-05-11 18:52:05.030]  Step 142869  [3.337 sec/step, loss=0.10308, avg_loss=0.09592, mel_loss=0.04770, linear_loss=0.05538]
[2020-05-11 18:52:05.994]  Step 142870  [3.323 sec/step, loss=0.09069, avg_loss=0.09586, mel_loss=0.04060, linear_loss=0.05009]
[2020-05-11 18:52:07.302]  Step 142871  [3.326 sec/step, loss=0.09356, avg_loss=0.09591, mel_loss=0.04203, linear_loss=0.05153]
[2020-05-11 18:52:08.158]  Step 142872  [3.317 sec/step, loss=0.08737, avg_loss=0.09582, mel_loss=0.03869, linear_loss=0.04868]
[2020-05-11 18:52:12.264]  Step 142873  [3.349 sec/step, loss=0.10173, avg_loss=0.09605, mel_loss=0.04734, linear_loss=0.05439]
[2020-05-11 18:52:14.179]  Step 142874  [3.360 sec/step, loss=0.09495, avg_loss=0.09617, mel_loss=0.04281, linear_loss=0.05214]
[2020-05-11 18:52:16.524]  Step 142875  [3.369 sec/step, loss=0.09697, avg_loss=0.09620, mel_loss=0.04431, linear_loss=0.05266]
[2020-05-11 18:52:18.660]  Step 142876  [3.362 sec/step, loss=0.09712, avg_loss=0.09615, mel_loss=0.04434, linear_loss=0.05278]
[2020-05-11 18:52:20.432]  Step 142877  [3.359 sec/step, loss=0.09531, avg_loss=0.09613, mel_loss=0.04278, linear_loss=0.05253]
[2020-05-11 18:52:23.912]  Step 142878  [3.373 sec/step, loss=0.10086, avg_loss=0.09616, mel_loss=0.04653, linear_loss=0.05433]
[2020-05-11 18:52:25.933]  Step 142879  [3.384 sec/step, loss=0.09529, avg_loss=0.09621, mel_loss=0.04321, linear_loss=0.05207]
[2020-05-11 18:52:26.739]  Step 142880  [3.321 sec/step, loss=0.08153, avg_loss=0.09597, mel_loss=0.03658, linear_loss=0.04496]
[2020-05-11 18:52:40.103]  Step 142881  [3.313 sec/step, loss=0.08720, avg_loss=0.09603, mel_loss=0.04218, linear_loss=0.04502]
[2020-05-11 18:52:41.791]  Step 142882  [3.294 sec/step, loss=0.09617, avg_loss=0.09595, mel_loss=0.04368, linear_loss=0.05249]
[2020-05-11 18:52:41.896]  Generated 32 batches of size 32 in 1.787 sec
[2020-05-11 18:52:46.651]  Step 142883  [3.323 sec/step, loss=0.10187, avg_loss=0.09600, mel_loss=0.04752, linear_loss=0.05435]
[2020-05-11 18:52:47.753]  Step 142884  [3.323 sec/step, loss=0.08661, avg_loss=0.09595, mel_loss=0.03862, linear_loss=0.04799]
[2020-05-11 18:52:50.227]  Step 142885  [3.342 sec/step, loss=0.09724, avg_loss=0.09614, mel_loss=0.04418, linear_loss=0.05306]
[2020-05-11 18:52:57.926]  Step 142886  [3.362 sec/step, loss=0.10358, avg_loss=0.09615, mel_loss=0.04914, linear_loss=0.05444]
[2020-05-11 18:52:58.487]  Step 142887  [3.336 sec/step, loss=0.07860, avg_loss=0.09590, mel_loss=0.03554, linear_loss=0.04307]
[2020-05-11 18:53:04.063]  Step 142888  [3.358 sec/step, loss=0.10449, avg_loss=0.09591, mel_loss=0.04876, linear_loss=0.05573]
[2020-05-11 18:53:05.597]  Step 142889  [3.335 sec/step, loss=0.09321, avg_loss=0.09583, mel_loss=0.04242, linear_loss=0.05079]
[2020-05-11 18:53:12.008]  Step 142890  [3.381 sec/step, loss=0.10298, avg_loss=0.09589, mel_loss=0.04854, linear_loss=0.05445]
[2020-05-11 18:53:12.815]  Step 142891  [3.305 sec/step, loss=0.08143, avg_loss=0.09566, mel_loss=0.03631, linear_loss=0.04512]
[2020-05-11 18:53:16.284]  Step 142892  [3.300 sec/step, loss=0.10134, avg_loss=0.09565, mel_loss=0.04668, linear_loss=0.05467]
[2020-05-11 18:53:18.469]  Step 142893  [3.276 sec/step, loss=0.09610, avg_loss=0.09558, mel_loss=0.04379, linear_loss=0.05231]
[2020-05-11 18:53:23.283]  Step 142894  [3.297 sec/step, loss=0.09967, avg_loss=0.09557, mel_loss=0.04627, linear_loss=0.05340]
[2020-05-11 18:53:37.455]  Step 142895  [3.376 sec/step, loss=0.07949, avg_loss=0.09532, mel_loss=0.03866, linear_loss=0.04083]
[2020-05-11 18:53:38.605]  Step 142896  [3.371 sec/step, loss=0.08743, avg_loss=0.09524, mel_loss=0.03906, linear_loss=0.04837]
[2020-05-11 18:53:40.394]  Step 142897  [3.338 sec/step, loss=0.09372, avg_loss=0.09514, mel_loss=0.04219, linear_loss=0.05153]
[2020-05-11 18:53:47.260]  Step 142898  [3.372 sec/step, loss=0.10408, avg_loss=0.09518, mel_loss=0.04922, linear_loss=0.05487]
[2020-05-11 18:53:52.743]  Step 142899  [3.296 sec/step, loss=0.10256, avg_loss=0.09535, mel_loss=0.04807, linear_loss=0.05448]
[2020-05-11 18:53:54.000]  Step 142900  [3.255 sec/step, loss=0.09001, avg_loss=0.09522, mel_loss=0.04049, linear_loss=0.04952]
[2020-05-11 18:53:54.000]  Writing summary at step: 142900
[2020-05-11 18:53:56.475]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142900
[2020-05-11 18:53:57.726]  Saving audio and alignment...
[2020-05-11 18:54:00.435]  Input: 이런 식으로 처리해 주시면~_______
[2020-05-11 18:54:02.671]  Step 142901  [3.255 sec/step, loss=0.09881, avg_loss=0.09526, mel_loss=0.04515, linear_loss=0.05366]
[2020-05-11 18:54:11.576]  Step 142902  [3.308 sec/step, loss=0.10387, avg_loss=0.09531, mel_loss=0.04954, linear_loss=0.05432]
[2020-05-11 18:54:17.339]  Step 142903  [3.341 sec/step, loss=0.10381, avg_loss=0.09536, mel_loss=0.04885, linear_loss=0.05495]
[2020-05-11 18:54:18.986]  Step 142904  [3.346 sec/step, loss=0.09213, avg_loss=0.09536, mel_loss=0.04152, linear_loss=0.05061]
[2020-05-11 18:54:23.219]  Step 142905  [3.332 sec/step, loss=0.09954, avg_loss=0.09533, mel_loss=0.04610, linear_loss=0.05345]
[2020-05-11 18:54:24.617]  Step 142906  [3.322 sec/step, loss=0.09087, avg_loss=0.09527, mel_loss=0.04114, linear_loss=0.04974]
[2020-05-11 18:54:27.350]  Step 142907  [3.342 sec/step, loss=0.09754, avg_loss=0.09540, mel_loss=0.04510, linear_loss=0.05245]
[2020-05-11 18:54:31.588]  Step 142908  [3.336 sec/step, loss=0.10453, avg_loss=0.09541, mel_loss=0.04901, linear_loss=0.05553]
[2020-05-11 18:54:32.342]  Step 142909  [3.338 sec/step, loss=0.07776, avg_loss=0.09544, mel_loss=0.03563, linear_loss=0.04213]
[2020-05-11 18:54:33.147]  Step 142910  [3.330 sec/step, loss=0.08444, avg_loss=0.09533, mel_loss=0.03766, linear_loss=0.04679]
[2020-05-11 18:54:36.671]  Step 142911  [3.348 sec/step, loss=0.10024, avg_loss=0.09538, mel_loss=0.04636, linear_loss=0.05388]
[2020-05-11 18:54:38.340]  Generated 32 batches of size 32 in 1.664 sec
[2020-05-11 18:54:40.388]  Step 142912  [3.350 sec/step, loss=0.10347, avg_loss=0.09541, mel_loss=0.04796, linear_loss=0.05551]
[2020-05-11 18:54:41.403]  Step 142913  [3.285 sec/step, loss=0.08747, avg_loss=0.09525, mel_loss=0.03901, linear_loss=0.04845]
[2020-05-11 18:54:49.030]  Step 142914  [3.320 sec/step, loss=0.10319, avg_loss=0.09525, mel_loss=0.04920, linear_loss=0.05399]
[2020-05-11 18:54:51.881]  Step 142915  [3.282 sec/step, loss=0.09950, avg_loss=0.09522, mel_loss=0.04546, linear_loss=0.05404]
[2020-05-11 18:54:53.839]  Step 142916  [3.285 sec/step, loss=0.09520, avg_loss=0.09522, mel_loss=0.04303, linear_loss=0.05217]
[2020-05-11 18:54:55.468]  Step 142917  [3.271 sec/step, loss=0.09565, avg_loss=0.09515, mel_loss=0.04314, linear_loss=0.05252]
[2020-05-11 18:54:56.513]  Step 142918  [3.268 sec/step, loss=0.08408, avg_loss=0.09510, mel_loss=0.03758, linear_loss=0.04650]
[2020-05-11 18:54:58.557]  Step 142919  [3.279 sec/step, loss=0.09724, avg_loss=0.09519, mel_loss=0.04444, linear_loss=0.05280]
[2020-05-11 18:55:01.601]  Step 142920  [3.290 sec/step, loss=0.09971, avg_loss=0.09525, mel_loss=0.04606, linear_loss=0.05365]
[2020-05-11 18:55:02.363]  Step 142921  [3.286 sec/step, loss=0.08751, avg_loss=0.09524, mel_loss=0.03872, linear_loss=0.04880]
[2020-05-11 18:55:05.463]  Step 142922  [3.295 sec/step, loss=0.10049, avg_loss=0.09528, mel_loss=0.04609, linear_loss=0.05441]
[2020-05-11 18:55:06.821]  Step 142923  [3.302 sec/step, loss=0.09129, avg_loss=0.09533, mel_loss=0.04122, linear_loss=0.05007]
[2020-05-11 18:55:09.295]  Step 142924  [3.300 sec/step, loss=0.09617, avg_loss=0.09531, mel_loss=0.04423, linear_loss=0.05194]
[2020-05-11 18:55:14.651]  Step 142925  [3.344 sec/step, loss=0.10135, avg_loss=0.09546, mel_loss=0.04780, linear_loss=0.05355]
[2020-05-11 18:55:18.220]  Step 142926  [3.366 sec/step, loss=0.10215, avg_loss=0.09554, mel_loss=0.04718, linear_loss=0.05498]
[2020-05-11 18:55:29.759]  Step 142927  [3.448 sec/step, loss=0.09721, avg_loss=0.09547, mel_loss=0.04773, linear_loss=0.04947]
[2020-05-11 18:55:31.639]  Step 142928  [3.423 sec/step, loss=0.09480, avg_loss=0.09538, mel_loss=0.04293, linear_loss=0.05187]
[2020-05-11 18:55:32.462]  Step 142929  [3.409 sec/step, loss=0.08364, avg_loss=0.09525, mel_loss=0.03770, linear_loss=0.04595]
[2020-05-11 18:55:34.451]  Step 142930  [3.398 sec/step, loss=0.09846, avg_loss=0.09522, mel_loss=0.04468, linear_loss=0.05378]
[2020-05-11 18:55:39.333]  Step 142931  [3.304 sec/step, loss=0.10246, avg_loss=0.09546, mel_loss=0.04823, linear_loss=0.05423]
[2020-05-11 18:55:46.005]  Step 142932  [3.351 sec/step, loss=0.10518, avg_loss=0.09555, mel_loss=0.05029, linear_loss=0.05489]
[2020-05-11 18:55:47.506]  Step 142933  [3.343 sec/step, loss=0.09198, avg_loss=0.09547, mel_loss=0.04178, linear_loss=0.05021]
[2020-05-11 18:55:50.498]  Step 142934  [3.333 sec/step, loss=0.10152, avg_loss=0.09546, mel_loss=0.04750, linear_loss=0.05403]
[2020-05-11 18:55:53.900]  Step 142935  [3.353 sec/step, loss=0.09994, avg_loss=0.09553, mel_loss=0.04658, linear_loss=0.05336]
[2020-05-11 18:55:54.793]  Step 142936  [3.336 sec/step, loss=0.08659, avg_loss=0.09543, mel_loss=0.03865, linear_loss=0.04795]
[2020-05-11 18:55:59.221]  Step 142937  [3.344 sec/step, loss=0.10764, avg_loss=0.09548, mel_loss=0.05100, linear_loss=0.05664]
[2020-05-11 18:56:00.977]  Step 142938  [3.306 sec/step, loss=0.09515, avg_loss=0.09541, mel_loss=0.04327, linear_loss=0.05187]
[2020-05-11 18:56:08.904]  Step 142939  [3.316 sec/step, loss=0.10663, avg_loss=0.09543, mel_loss=0.05207, linear_loss=0.05455]
[2020-05-11 18:56:10.560]  Step 142940  [3.306 sec/step, loss=0.09616, avg_loss=0.09539, mel_loss=0.04389, linear_loss=0.05227]
[2020-05-11 18:56:14.326]  Step 142941  [3.336 sec/step, loss=0.10559, avg_loss=0.09563, mel_loss=0.04940, linear_loss=0.05619]
[2020-05-11 18:56:15.487]  Step 142942  [3.337 sec/step, loss=0.09225, avg_loss=0.09571, mel_loss=0.04157, linear_loss=0.05067]
[2020-05-11 18:56:22.982]  Step 142943  [3.400 sec/step, loss=0.10713, avg_loss=0.09588, mel_loss=0.05156, linear_loss=0.05557]
[2020-05-11 18:56:23.585]  Step 142944  [3.392 sec/step, loss=0.07611, avg_loss=0.09571, mel_loss=0.03465, linear_loss=0.04146]
[2020-05-11 18:56:24.692]  Generated 32 batches of size 32 in 1.704 sec
[2020-05-11 18:56:27.888]  Step 142945  [3.406 sec/step, loss=0.10186, avg_loss=0.09573, mel_loss=0.04736, linear_loss=0.05450]
[2020-05-11 18:56:30.871]  Step 142946  [3.417 sec/step, loss=0.10528, avg_loss=0.09584, mel_loss=0.04895, linear_loss=0.05633]
[2020-05-11 18:56:33.590]  Step 142947  [3.438 sec/step, loss=0.09951, avg_loss=0.09611, mel_loss=0.04592, linear_loss=0.05360]
[2020-05-11 18:56:34.643]  Step 142948  [3.358 sec/step, loss=0.09234, avg_loss=0.09601, mel_loss=0.04135, linear_loss=0.05099]
[2020-05-11 18:56:36.737]  Step 142949  [3.367 sec/step, loss=0.10124, avg_loss=0.09612, mel_loss=0.04681, linear_loss=0.05443]
[2020-05-11 18:56:38.203]  Step 142950  [3.371 sec/step, loss=0.09338, avg_loss=0.09619, mel_loss=0.04243, linear_loss=0.05095]
[2020-05-11 18:56:38.203]  Writing summary at step: 142950
[2020-05-11 18:56:39.231]  Saving checkpoint to: ./logs-tacotron/model.ckpt-142950
[2020-05-11 18:56:40.549]  Saving audio and alignment...
[2020-05-11 18:56:44.587]  Input: 그리고 파고다 어학원 그 전임직원~_______________
[2020-05-11 18:56:48.240]  Step 142951  [3.341 sec/step, loss=0.10310, avg_loss=0.09620, mel_loss=0.04796, linear_loss=0.05514]
[2020-05-11 18:56:49.292]  Step 142952  [3.335 sec/step, loss=0.08986, avg_loss=0.09618, mel_loss=0.04038, linear_loss=0.04948]
[2020-05-11 18:56:51.273]  Step 142953  [3.338 sec/step, loss=0.09846, avg_loss=0.09622, mel_loss=0.04494, linear_loss=0.05352]
[2020-05-11 18:56:54.610]  Step 142954  [3.319 sec/step, loss=0.10153, avg_loss=0.09620, mel_loss=0.04747, linear_loss=0.05406]
[2020-05-11 18:56:56.222]  Step 142955  [3.304 sec/step, loss=0.09658, avg_loss=0.09614, mel_loss=0.04364, linear_loss=0.05294]
[2020-05-11 18:56:58.448]  Step 142956  [3.280 sec/step, loss=0.09845, avg_loss=0.09610, mel_loss=0.04538, linear_loss=0.05307]
[2020-05-11 18:57:01.004]  Step 142957  [3.297 sec/step, loss=0.10003, avg_loss=0.09628, mel_loss=0.04588, linear_loss=0.05415]
[2020-05-11 18:57:03.870]  Step 142958  [3.307 sec/step, loss=0.10015, avg_loss=0.09630, mel_loss=0.04616, linear_loss=0.05400]
[2020-05-11 18:57:05.034]  Step 142959  [3.251 sec/step, loss=0.09130, avg_loss=0.09619, mel_loss=0.04098, linear_loss=0.05032]
[2020-05-11 18:57:09.381]  Step 142960  [3.164 sec/step, loss=0.10323, avg_loss=0.09618, mel_loss=0.04824, linear_loss=0.05499]
[2020-05-11 18:57:23.889]  Step 142961  [3.297 sec/step, loss=0.08232, avg_loss=0.09612, mel_loss=0.04030, linear_loss=0.04202]
[2020-05-11 18:57:26.974]  Step 142962  [3.320 sec/step, loss=0.10196, avg_loss=0.09633, mel_loss=0.04703, linear_loss=0.05493]
[2020-05-11 18:57:28.527]  Step 142963  [3.302 sec/step, loss=0.09498, avg_loss=0.09626, mel_loss=0.04317, linear_loss=0.05180]
[2020-05-11 18:57:29.875]  Step 142964  [3.281 sec/step, loss=0.09418, avg_loss=0.09618, mel_loss=0.04257, linear_loss=0.05161]
[2020-05-11 18:57:32.304]  Step 142965  [3.292 sec/step, loss=0.09949, avg_loss=0.09623, mel_loss=0.04550, linear_loss=0.05398]
[2020-05-11 18:57:33.620]  Step 142966  [3.279 sec/step, loss=0.08922, avg_loss=0.09613, mel_loss=0.04050, linear_loss=0.04872]
[2020-05-11 18:57:35.506]  Step 142967  [3.243 sec/step, loss=0.09596, avg_loss=0.09606, mel_loss=0.04341, linear_loss=0.05254]
[2020-05-11 18:57:37.650]  Step 142968  [3.235 sec/step, loss=0.09640, avg_loss=0.09604, mel_loss=0.04390, linear_loss=0.05250]
[2020-05-11 18:57:44.803]  Step 142969  [3.269 sec/step, loss=0.10335, avg_loss=0.09604, mel_loss=0.04905, linear_loss=0.05430]
[2020-05-11 18:57:45.775]  Step 142970  [3.269 sec/step, loss=0.08741, avg_loss=0.09601, mel_loss=0.03927, linear_loss=0.04814]
[2020-05-11 18:57:46.608]  Step 142971  [3.265 sec/step, loss=0.08307, avg_loss=0.09590, mel_loss=0.03707, linear_loss=0.04600]
[2020-05-11 18:57:50.605]  Step 142972  [3.296 sec/step, loss=0.10489, avg_loss=0.09608, mel_loss=0.04876, linear_loss=0.05612]
[2020-05-11 18:57:51.241]  Step 142973  [3.261 sec/step, loss=0.08238, avg_loss=0.09588, mel_loss=0.03712, linear_loss=0.04526]
[2020-05-11 18:57:52.820]  Generated 32 batches of size 32 in 1.575 sec
[2020-05-11 18:57:56.802]  Step 142974  [3.298 sec/step, loss=0.10581, avg_loss=0.09599, mel_loss=0.04981, linear_loss=0.05600]
[2020-05-11 18:57:57.364]  Step 142975  [3.280 sec/step, loss=0.07673, avg_loss=0.09579, mel_loss=0.03549, linear_loss=0.04124]
[2020-05-11 18:57:59.102]  Step 142976  [3.276 sec/step, loss=0.09710, avg_loss=0.09579, mel_loss=0.04384, linear_loss=0.05326]
[2020-05-11 18:58:00.060]  Step 142977  [3.268 sec/step, loss=0.08787, avg_loss=0.09571, mel_loss=0.03921, linear_loss=0.04865]
[2020-05-11 18:58:05.230]  Step 142978  [3.285 sec/step, loss=0.10278, avg_loss=0.09573, mel_loss=0.04826, linear_loss=0.05452]
[2020-05-11 18:58:08.708]  Step 142979  [3.299 sec/step, loss=0.09966, avg_loss=0.09578, mel_loss=0.04634, linear_loss=0.05332]
[2020-05-11 18:58:13.285]  Step 142980  [3.337 sec/step, loss=0.10391, avg_loss=0.09600, mel_loss=0.04846, linear_loss=0.05546]
[2020-05-11 18:58:19.331]  Step 142981  [3.264 sec/step, loss=0.10145, avg_loss=0.09614, mel_loss=0.04807, linear_loss=0.05339]
[2020-05-11 18:58:28.079]  Step 142982  [3.334 sec/step, loss=0.10203, avg_loss=0.09620, mel_loss=0.04900, linear_loss=0.05303]
[2020-05-11 18:58:29.862]  Step 142983  [3.304 sec/step, loss=0.09575, avg_loss=0.09614, mel_loss=0.04342, linear_loss=0.05234]
[2020-05-11 18:58:35.183]  Step 142984  [3.346 sec/step, loss=0.10244, avg_loss=0.09630, mel_loss=0.04819, linear_loss=0.05425]
[2020-05-11 18:58:37.402]  Step 142985  [3.343 sec/step, loss=0.09822, avg_loss=0.09631, mel_loss=0.04518, linear_loss=0.05305]
[2020-05-11 18:58:43.130]  Step 142986  [3.324 sec/step, loss=0.10404, avg_loss=0.09631, mel_loss=0.04886, linear_loss=0.05519]
[2020-05-11 18:58:49.581]  Step 142987  [3.383 sec/step, loss=0.10496, avg_loss=0.09658, mel_loss=0.04980, linear_loss=0.05515]
[2020-05-11 18:58:53.685]  Step 142988  [3.368 sec/step, loss=0.10459, avg_loss=0.09658, mel_loss=0.04889, linear_loss=0.05570]
[2020-05-11 18:58:54.215]  Step 142989  [3.358 sec/step, loss=0.07887, avg_loss=0.09643, mel_loss=0.03598, linear_loss=0.04289]
[2020-05-11 18:58:55.939]  Step 142990  [3.311 sec/step, loss=0.09723, avg_loss=0.09638, mel_loss=0.04334, linear_loss=0.05389]
[2020-05-11 18:58:59.612]  Step 142991  [3.340 sec/step, loss=0.10476, avg_loss=0.09661, mel_loss=0.04869, linear_loss=0.05607]
[2020-05-11 18:59:03.174]  Step 142992  [3.340 sec/step, loss=0.10336, avg_loss=0.09663, mel_loss=0.04784, linear_loss=0.05552]
[2020-05-11 18:59:05.134]  Step 142993  [3.338 sec/step, loss=0.09675, avg_loss=0.09664, mel_loss=0.04369, linear_loss=0.05306]
[2020-05-11 18:59:06.303]  Step 142994  [3.302 sec/step, loss=0.09046, avg_loss=0.09654, mel_loss=0.04075, linear_loss=0.04971]
[2020-05-11 18:59:07.743]  Step 142995  [3.174 sec/step, loss=0.09368, avg_loss=0.09669, mel_loss=0.04239, linear_loss=0.05130]
[2020-05-11 18:59:08.577]  Step 142996  [3.171 sec/step, loss=0.08134, avg_loss=0.09663, mel_loss=0.03704, linear_loss=0.04431]
[2020-05-11 18:59:11.402]  Step 142997  [3.182 sec/step, loss=0.10125, avg_loss=0.09670, mel_loss=0.04677, linear_loss=0.05448]
[2020-05-11 18:59:12.991]  Step 142998  [3.129 sec/step, loss=0.09477, avg_loss=0.09661, mel_loss=0.04292, linear_loss=0.05185]
[2020-05-11 18:59:15.103]  Step 142999  [3.095 sec/step, loss=0.09632, avg_loss=0.09655, mel_loss=0.04402, linear_loss=0.05230]
[2020-05-11 18:59:19.834]  Step 143000  [3.130 sec/step, loss=0.10299, avg_loss=0.09668, mel_loss=0.04815, linear_loss=0.05483]
[2020-05-11 18:59:19.834]  Writing summary at step: 143000
[2020-05-11 18:59:23.289]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143000
[2020-05-11 18:59:24.559]  Saving audio and alignment...
[2020-05-11 18:59:29.816]  Input: 만리장성입니다 이렇게 하지 않고요 이분들에게 친숙한 용여~_____________
[2020-05-11 18:59:31.130]  Step 143001  [3.121 sec/step, loss=0.09339, avg_loss=0.09662, mel_loss=0.04227, linear_loss=0.05113]
[2020-05-11 18:59:38.718]  Step 143002  [3.108 sec/step, loss=0.10315, avg_loss=0.09661, mel_loss=0.04905, linear_loss=0.05410]
[2020-05-11 18:59:50.901]  Step 143003  [3.172 sec/step, loss=0.09173, avg_loss=0.09649, mel_loss=0.04453, linear_loss=0.04720]
[2020-05-11 18:59:51.934]  Step 143004  [3.166 sec/step, loss=0.08563, avg_loss=0.09643, mel_loss=0.03810, linear_loss=0.04753]
[2020-05-11 18:59:52.658]  Generated 32 batches of size 32 in 1.752 sec
[2020-05-11 18:59:53.062]  Step 143005  [3.135 sec/step, loss=0.08847, avg_loss=0.09632, mel_loss=0.03978, linear_loss=0.04869]
[2020-05-11 18:59:55.547]  Step 143006  [3.145 sec/step, loss=0.09875, avg_loss=0.09640, mel_loss=0.04512, linear_loss=0.05363]
[2020-05-11 18:59:58.263]  Step 143007  [3.145 sec/step, loss=0.09701, avg_loss=0.09639, mel_loss=0.04449, linear_loss=0.05252]
[2020-05-11 18:59:59.567]  Step 143008  [3.116 sec/step, loss=0.09206, avg_loss=0.09627, mel_loss=0.04147, linear_loss=0.05058]
[2020-05-11 19:00:03.675]  Step 143009  [3.149 sec/step, loss=0.10265, avg_loss=0.09651, mel_loss=0.04768, linear_loss=0.05498]
[2020-05-11 19:00:06.742]  Step 143010  [3.172 sec/step, loss=0.10157, avg_loss=0.09669, mel_loss=0.04672, linear_loss=0.05485]
[2020-05-11 19:00:07.683]  Step 143011  [3.146 sec/step, loss=0.08860, avg_loss=0.09657, mel_loss=0.03957, linear_loss=0.04903]
[2020-05-11 19:00:16.619]  Step 143012  [3.198 sec/step, loss=0.10320, avg_loss=0.09657, mel_loss=0.04908, linear_loss=0.05412]
[2020-05-11 19:00:17.528]  Step 143013  [3.197 sec/step, loss=0.08344, avg_loss=0.09653, mel_loss=0.03704, linear_loss=0.04640]
[2020-05-11 19:00:22.198]  Step 143014  [3.168 sec/step, loss=0.10413, avg_loss=0.09654, mel_loss=0.04843, linear_loss=0.05569]
[2020-05-11 19:00:26.028]  Step 143015  [3.178 sec/step, loss=0.10156, avg_loss=0.09656, mel_loss=0.04707, linear_loss=0.05449]
[2020-05-11 19:00:31.146]  Step 143016  [3.209 sec/step, loss=0.10278, avg_loss=0.09663, mel_loss=0.04802, linear_loss=0.05476]
[2020-05-11 19:00:33.143]  Step 143017  [3.213 sec/step, loss=0.09675, avg_loss=0.09664, mel_loss=0.04403, linear_loss=0.05272]
[2020-05-11 19:00:36.092]  Step 143018  [3.232 sec/step, loss=0.10202, avg_loss=0.09682, mel_loss=0.04688, linear_loss=0.05514]
[2020-05-11 19:00:44.680]  Step 143019  [3.297 sec/step, loss=0.10158, avg_loss=0.09687, mel_loss=0.04869, linear_loss=0.05288]
[2020-05-11 19:00:46.074]  Step 143020  [3.281 sec/step, loss=0.09461, avg_loss=0.09682, mel_loss=0.04253, linear_loss=0.05208]
[2020-05-11 19:00:52.273]  Step 143021  [3.335 sec/step, loss=0.10245, avg_loss=0.09696, mel_loss=0.04863, linear_loss=0.05382]
[2020-05-11 19:00:55.265]  Step 143022  [3.334 sec/step, loss=0.09759, avg_loss=0.09694, mel_loss=0.04504, linear_loss=0.05255]
[2020-05-11 19:00:58.924]  Step 143023  [3.357 sec/step, loss=0.10037, avg_loss=0.09703, mel_loss=0.04636, linear_loss=0.05402]
[2020-05-11 19:01:02.718]  Step 143024  [3.370 sec/step, loss=0.10112, avg_loss=0.09708, mel_loss=0.04684, linear_loss=0.05428]
[2020-05-11 19:01:04.596]  Step 143025  [3.336 sec/step, loss=0.09604, avg_loss=0.09702, mel_loss=0.04325, linear_loss=0.05279]
[2020-05-11 19:01:05.165]  Step 143026  [3.306 sec/step, loss=0.07473, avg_loss=0.09675, mel_loss=0.03395, linear_loss=0.04077]
[2020-05-11 19:01:06.008]  Step 143027  [3.199 sec/step, loss=0.08036, avg_loss=0.09658, mel_loss=0.03588, linear_loss=0.04448]
[2020-05-11 19:01:07.360]  Step 143028  [3.193 sec/step, loss=0.08861, avg_loss=0.09652, mel_loss=0.03993, linear_loss=0.04868]
[2020-05-11 19:01:14.673]  Step 143029  [3.258 sec/step, loss=0.10327, avg_loss=0.09671, mel_loss=0.04898, linear_loss=0.05429]
[2020-05-11 19:01:16.272]  Step 143030  [3.254 sec/step, loss=0.09435, avg_loss=0.09667, mel_loss=0.04308, linear_loss=0.05127]
[2020-05-11 19:01:17.426]  Step 143031  [3.217 sec/step, loss=0.08879, avg_loss=0.09654, mel_loss=0.03930, linear_loss=0.04950]
[2020-05-11 19:01:19.037]  Step 143032  [3.166 sec/step, loss=0.09125, avg_loss=0.09640, mel_loss=0.04098, linear_loss=0.05027]
[2020-05-11 19:01:20.806]  Step 143033  [3.169 sec/step, loss=0.09462, avg_loss=0.09642, mel_loss=0.04304, linear_loss=0.05158]
[2020-05-11 19:01:23.251]  Step 143034  [3.164 sec/step, loss=0.09833, avg_loss=0.09639, mel_loss=0.04481, linear_loss=0.05352]
[2020-05-11 19:01:24.314]  Step 143035  [3.140 sec/step, loss=0.08927, avg_loss=0.09629, mel_loss=0.04012, linear_loss=0.04915]
[2020-05-11 19:01:25.152]  Step 143036  [3.140 sec/step, loss=0.08232, avg_loss=0.09624, mel_loss=0.03677, linear_loss=0.04555]
[2020-05-11 19:01:26.057]  Generated 32 batches of size 32 in 1.739 sec
[2020-05-11 19:01:28.283]  Step 143037  [3.127 sec/step, loss=0.10274, avg_loss=0.09619, mel_loss=0.04752, linear_loss=0.05522]
[2020-05-11 19:01:30.377]  Step 143038  [3.130 sec/step, loss=0.09905, avg_loss=0.09623, mel_loss=0.04533, linear_loss=0.05372]
[2020-05-11 19:01:35.623]  Step 143039  [3.103 sec/step, loss=0.10516, avg_loss=0.09622, mel_loss=0.04948, linear_loss=0.05568]
[2020-05-11 19:01:38.316]  Step 143040  [3.114 sec/step, loss=0.09906, avg_loss=0.09625, mel_loss=0.04525, linear_loss=0.05381]
[2020-05-11 19:01:39.869]  Step 143041  [3.092 sec/step, loss=0.08693, avg_loss=0.09606, mel_loss=0.03906, linear_loss=0.04787]
[2020-05-11 19:01:46.770]  Step 143042  [3.149 sec/step, loss=0.10205, avg_loss=0.09616, mel_loss=0.04787, linear_loss=0.05418]
[2020-05-11 19:02:03.965]  Step 143043  [3.246 sec/step, loss=0.08099, avg_loss=0.09590, mel_loss=0.03928, linear_loss=0.04171]
[2020-05-11 19:02:06.173]  Step 143044  [3.262 sec/step, loss=0.09558, avg_loss=0.09609, mel_loss=0.04365, linear_loss=0.05193]
[2020-05-11 19:02:10.385]  Step 143045  [3.261 sec/step, loss=0.10345, avg_loss=0.09611, mel_loss=0.04868, linear_loss=0.05477]
[2020-05-11 19:02:13.861]  Step 143046  [3.266 sec/step, loss=0.10221, avg_loss=0.09608, mel_loss=0.04772, linear_loss=0.05449]
[2020-05-11 19:02:16.342]  Step 143047  [3.264 sec/step, loss=0.09844, avg_loss=0.09607, mel_loss=0.04481, linear_loss=0.05362]
[2020-05-11 19:02:23.137]  Step 143048  [3.321 sec/step, loss=0.10233, avg_loss=0.09617, mel_loss=0.04851, linear_loss=0.05382]
[2020-05-11 19:02:24.459]  Step 143049  [3.313 sec/step, loss=0.09238, avg_loss=0.09608, mel_loss=0.04126, linear_loss=0.05112]
[2020-05-11 19:02:26.225]  Step 143050  [3.316 sec/step, loss=0.09465, avg_loss=0.09609, mel_loss=0.04264, linear_loss=0.05201]
[2020-05-11 19:02:26.225]  Writing summary at step: 143050
[2020-05-11 19:02:26.999]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143050
[2020-05-11 19:02:28.328]  Saving audio and alignment...
[2020-05-11 19:02:31.073]  Input: 조금 올려 주셨다가~____________________
[2020-05-11 19:02:34.780]  Step 143051  [3.317 sec/step, loss=0.10487, avg_loss=0.09611, mel_loss=0.04896, linear_loss=0.05590]
[2020-05-11 19:02:36.928]  Step 143052  [3.328 sec/step, loss=0.09768, avg_loss=0.09619, mel_loss=0.04463, linear_loss=0.05304]
[2020-05-11 19:02:40.326]  Step 143053  [3.342 sec/step, loss=0.10088, avg_loss=0.09621, mel_loss=0.04710, linear_loss=0.05378]
[2020-05-11 19:02:41.489]  Step 143054  [3.320 sec/step, loss=0.09016, avg_loss=0.09610, mel_loss=0.04050, linear_loss=0.04966]
[2020-05-11 19:02:42.504]  Step 143055  [3.314 sec/step, loss=0.08636, avg_loss=0.09599, mel_loss=0.03894, linear_loss=0.04742]
[2020-05-11 19:02:43.394]  Step 143056  [3.301 sec/step, loss=0.08550, avg_loss=0.09586, mel_loss=0.03819, linear_loss=0.04731]
[2020-05-11 19:02:46.068]  Step 143057  [3.302 sec/step, loss=0.09792, avg_loss=0.09584, mel_loss=0.04506, linear_loss=0.05286]
[2020-05-11 19:02:50.812]  Step 143058  [3.321 sec/step, loss=0.10413, avg_loss=0.09588, mel_loss=0.04861, linear_loss=0.05552]
[2020-05-11 19:02:52.677]  Step 143059  [3.328 sec/step, loss=0.09535, avg_loss=0.09592, mel_loss=0.04294, linear_loss=0.05241]
[2020-05-11 19:02:59.996]  Step 143060  [3.358 sec/step, loss=0.10302, avg_loss=0.09592, mel_loss=0.04923, linear_loss=0.05379]
[2020-05-11 19:03:05.583]  Step 143061  [3.268 sec/step, loss=0.10476, avg_loss=0.09615, mel_loss=0.04964, linear_loss=0.05512]
[2020-05-11 19:03:06.723]  Step 143062  [3.249 sec/step, loss=0.08891, avg_loss=0.09602, mel_loss=0.04006, linear_loss=0.04885]
[2020-05-11 19:03:08.331]  Step 143063  [3.249 sec/step, loss=0.09526, avg_loss=0.09602, mel_loss=0.04336, linear_loss=0.05190]
[2020-05-11 19:03:11.430]  Step 143064  [3.267 sec/step, loss=0.10305, avg_loss=0.09611, mel_loss=0.04784, linear_loss=0.05521]
[2020-05-11 19:03:12.243]  Step 143065  [3.251 sec/step, loss=0.08214, avg_loss=0.09593, mel_loss=0.03666, linear_loss=0.04548]
[2020-05-11 19:03:14.222]  Step 143066  [3.257 sec/step, loss=0.09747, avg_loss=0.09602, mel_loss=0.04446, linear_loss=0.05301]
[2020-05-11 19:03:17.153]  Step 143067  [3.268 sec/step, loss=0.10170, avg_loss=0.09607, mel_loss=0.04701, linear_loss=0.05469]
[2020-05-11 19:03:19.562]  Step 143068  [3.271 sec/step, loss=0.09730, avg_loss=0.09608, mel_loss=0.04466, linear_loss=0.05265]
[2020-05-11 19:03:24.844]  Step 143069  [3.252 sec/step, loss=0.10257, avg_loss=0.09607, mel_loss=0.04821, linear_loss=0.05436]
[2020-05-11 19:03:33.917]  Step 143070  [3.333 sec/step, loss=0.10345, avg_loss=0.09624, mel_loss=0.04948, linear_loss=0.05397]
[2020-05-11 19:03:47.399]  Step 143071  [3.459 sec/step, loss=0.08846, avg_loss=0.09629, mel_loss=0.04314, linear_loss=0.04532]
[2020-05-11 19:03:47.932]  Step 143072  [3.425 sec/step, loss=0.07427, avg_loss=0.09598, mel_loss=0.03344, linear_loss=0.04083]
[2020-05-11 19:03:49.323]  Step 143073  [3.432 sec/step, loss=0.09206, avg_loss=0.09608, mel_loss=0.04181, linear_loss=0.05026]
[2020-05-11 19:03:53.492]  Step 143074  [3.418 sec/step, loss=0.10101, avg_loss=0.09603, mel_loss=0.04700, linear_loss=0.05401]
[2020-05-11 19:04:18.083]  Generated 32 batches of size 32 in 65.835 sec
[2020-05-11 19:04:20.629]  Step 143075  [3.684 sec/step, loss=0.09821, avg_loss=0.09625, mel_loss=0.04502, linear_loss=0.05319]
[2020-05-11 19:04:24.150]  Step 143076  [3.702 sec/step, loss=0.09984, avg_loss=0.09627, mel_loss=0.04587, linear_loss=0.05397]
[2020-05-11 19:04:26.350]  Step 143077  [3.714 sec/step, loss=0.09766, avg_loss=0.09637, mel_loss=0.04445, linear_loss=0.05322]
[2020-05-11 19:04:27.459]  Step 143078  [3.674 sec/step, loss=0.08960, avg_loss=0.09624, mel_loss=0.03981, linear_loss=0.04979]
[2020-05-11 19:04:28.214]  Step 143079  [3.647 sec/step, loss=0.07962, avg_loss=0.09604, mel_loss=0.03630, linear_loss=0.04332]
[2020-05-11 19:04:35.725]  Step 143080  [3.676 sec/step, loss=0.10665, avg_loss=0.09607, mel_loss=0.05109, linear_loss=0.05556]
[2020-05-11 19:04:37.146]  Step 143081  [3.630 sec/step, loss=0.09099, avg_loss=0.09596, mel_loss=0.04098, linear_loss=0.05001]
[2020-05-11 19:04:37.906]  Step 143082  [3.550 sec/step, loss=0.08392, avg_loss=0.09578, mel_loss=0.03707, linear_loss=0.04685]
[2020-05-11 19:04:39.432]  Step 143083  [3.547 sec/step, loss=0.09758, avg_loss=0.09580, mel_loss=0.04420, linear_loss=0.05339]
[2020-05-11 19:04:41.612]  Step 143084  [3.516 sec/step, loss=0.09752, avg_loss=0.09575, mel_loss=0.04448, linear_loss=0.05304]
[2020-05-11 19:04:42.959]  Step 143085  [3.507 sec/step, loss=0.09036, avg_loss=0.09567, mel_loss=0.04101, linear_loss=0.04935]
[2020-05-11 19:04:43.761]  Step 143086  [3.458 sec/step, loss=0.08213, avg_loss=0.09545, mel_loss=0.03670, linear_loss=0.04543]
[2020-05-11 19:04:47.056]  Step 143087  [3.426 sec/step, loss=0.10104, avg_loss=0.09541, mel_loss=0.04679, linear_loss=0.05426]
[2020-05-11 19:04:48.847]  Step 143088  [3.403 sec/step, loss=0.09582, avg_loss=0.09533, mel_loss=0.04333, linear_loss=0.05250]
[2020-05-11 19:04:54.543]  Step 143089  [3.455 sec/step, loss=0.10499, avg_loss=0.09559, mel_loss=0.04947, linear_loss=0.05552]
[2020-05-11 19:04:57.647]  Step 143090  [3.469 sec/step, loss=0.10028, avg_loss=0.09562, mel_loss=0.04600, linear_loss=0.05428]
[2020-05-11 19:05:03.935]  Step 143091  [3.495 sec/step, loss=0.10409, avg_loss=0.09561, mel_loss=0.04962, linear_loss=0.05447]
[2020-05-11 19:05:04.951]  Step 143092  [3.469 sec/step, loss=0.08689, avg_loss=0.09545, mel_loss=0.03912, linear_loss=0.04777]
[2020-05-11 19:05:07.661]  Step 143093  [3.477 sec/step, loss=0.10018, avg_loss=0.09548, mel_loss=0.04626, linear_loss=0.05392]
[2020-05-11 19:05:11.751]  Step 143094  [3.506 sec/step, loss=0.10384, avg_loss=0.09561, mel_loss=0.04804, linear_loss=0.05580]
[2020-05-11 19:05:14.642]  Step 143095  [3.520 sec/step, loss=0.09919, avg_loss=0.09567, mel_loss=0.04614, linear_loss=0.05305]
[2020-05-11 19:05:19.981]  Step 143096  [3.565 sec/step, loss=0.10496, avg_loss=0.09591, mel_loss=0.04952, linear_loss=0.05544]
[2020-05-11 19:05:22.095]  Step 143097  [3.558 sec/step, loss=0.09786, avg_loss=0.09587, mel_loss=0.04451, linear_loss=0.05335]
[2020-05-11 19:05:23.881]  Step 143098  [3.560 sec/step, loss=0.09420, avg_loss=0.09587, mel_loss=0.04274, linear_loss=0.05145]
[2020-05-11 19:05:25.140]  Step 143099  [3.552 sec/step, loss=0.09157, avg_loss=0.09582, mel_loss=0.04126, linear_loss=0.05031]
[2020-05-11 19:05:27.072]  Step 143100  [3.524 sec/step, loss=0.09780, avg_loss=0.09577, mel_loss=0.04427, linear_loss=0.05353]
[2020-05-11 19:05:27.072]  Writing summary at step: 143100
[2020-05-11 19:05:30.767]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143100
[2020-05-11 19:05:32.058]  Saving audio and alignment...
[2020-05-11 19:05:43.678]  Input: 그런 날들을 버텨내기 위해 이렇게 낮은 음으로 이어 가보시기 바랍니다 그럼 멘트가 아주 세련 되거든요 다시이~_________________________
[2020-05-11 19:05:48.319]  Step 143101  [3.557 sec/step, loss=0.10413, avg_loss=0.09587, mel_loss=0.04865, linear_loss=0.05548]
[2020-05-11 19:05:49.312]  Step 143102  [3.491 sec/step, loss=0.08530, avg_loss=0.09570, mel_loss=0.03812, linear_loss=0.04718]
[2020-05-11 19:06:01.788]  Generated 32 batches of size 32 in 39.689 sec
[2020-05-11 19:06:03.840]  Step 143103  [3.515 sec/step, loss=0.08098, avg_loss=0.09559, mel_loss=0.03981, linear_loss=0.04117]
[2020-05-11 19:06:09.037]  Step 143104  [3.556 sec/step, loss=0.10330, avg_loss=0.09576, mel_loss=0.04825, linear_loss=0.05505]
[2020-05-11 19:06:10.479]  Step 143105  [3.559 sec/step, loss=0.08983, avg_loss=0.09578, mel_loss=0.04041, linear_loss=0.04942]
[2020-05-11 19:06:11.656]  Step 143106  [3.546 sec/step, loss=0.08869, avg_loss=0.09568, mel_loss=0.03949, linear_loss=0.04920]
[2020-05-11 19:06:12.438]  Step 143107  [3.527 sec/step, loss=0.08683, avg_loss=0.09558, mel_loss=0.03835, linear_loss=0.04849]
[2020-05-11 19:06:14.440]  Step 143108  [3.534 sec/step, loss=0.09764, avg_loss=0.09563, mel_loss=0.04423, linear_loss=0.05341]
[2020-05-11 19:06:16.014]  Step 143109  [3.509 sec/step, loss=0.09453, avg_loss=0.09555, mel_loss=0.04285, linear_loss=0.05168]
[2020-05-11 19:06:20.545]  Step 143110  [3.523 sec/step, loss=0.10316, avg_loss=0.09557, mel_loss=0.04807, linear_loss=0.05509]
[2020-05-11 19:06:23.492]  Step 143111  [3.543 sec/step, loss=0.10098, avg_loss=0.09569, mel_loss=0.04664, linear_loss=0.05435]
[2020-05-11 19:06:31.061]  Step 143112  [3.530 sec/step, loss=0.10377, avg_loss=0.09570, mel_loss=0.04946, linear_loss=0.05431]
[2020-05-11 19:06:31.634]  Step 143113  [3.526 sec/step, loss=0.07672, avg_loss=0.09563, mel_loss=0.03515, linear_loss=0.04157]
[2020-05-11 19:06:32.461]  Step 143114  [3.488 sec/step, loss=0.08219, avg_loss=0.09541, mel_loss=0.03649, linear_loss=0.04570]
[2020-05-11 19:06:36.496]  Step 143115  [3.490 sec/step, loss=0.10290, avg_loss=0.09542, mel_loss=0.04811, linear_loss=0.05478]
[2020-05-11 19:06:38.577]  Step 143116  [3.460 sec/step, loss=0.09598, avg_loss=0.09535, mel_loss=0.04374, linear_loss=0.05225]
[2020-05-11 19:06:40.439]  Step 143117  [3.458 sec/step, loss=0.09516, avg_loss=0.09534, mel_loss=0.04275, linear_loss=0.05241]
[2020-05-11 19:06:43.257]  Step 143118  [3.457 sec/step, loss=0.09875, avg_loss=0.09531, mel_loss=0.04555, linear_loss=0.05320]
[2020-05-11 19:06:49.966]  Step 143119  [3.438 sec/step, loss=0.10296, avg_loss=0.09532, mel_loss=0.04903, linear_loss=0.05393]
[2020-05-11 19:06:53.976]  Step 143120  [3.464 sec/step, loss=0.10313, avg_loss=0.09540, mel_loss=0.04826, linear_loss=0.05487]
[2020-05-11 19:06:57.564]  Step 143121  [3.438 sec/step, loss=0.10201, avg_loss=0.09540, mel_loss=0.04717, linear_loss=0.05484]
[2020-05-11 19:07:11.557]  Step 143122  [3.548 sec/step, loss=0.07882, avg_loss=0.09521, mel_loss=0.03837, linear_loss=0.04045]
[2020-05-11 19:07:12.944]  Step 143123  [3.525 sec/step, loss=0.09307, avg_loss=0.09514, mel_loss=0.04209, linear_loss=0.05098]
[2020-05-11 19:07:16.388]  Step 143124  [3.522 sec/step, loss=0.09767, avg_loss=0.09511, mel_loss=0.04494, linear_loss=0.05273]
[2020-05-11 19:07:17.418]  Step 143125  [3.513 sec/step, loss=0.08562, avg_loss=0.09500, mel_loss=0.03833, linear_loss=0.04729]
[2020-05-11 19:07:19.026]  Step 143126  [3.524 sec/step, loss=0.09653, avg_loss=0.09522, mel_loss=0.04367, linear_loss=0.05285]
[2020-05-11 19:07:22.327]  Step 143127  [3.548 sec/step, loss=0.10302, avg_loss=0.09545, mel_loss=0.04768, linear_loss=0.05534]
[2020-05-11 19:07:27.675]  Step 143128  [3.588 sec/step, loss=0.10299, avg_loss=0.09559, mel_loss=0.04848, linear_loss=0.05451]
[2020-05-11 19:07:29.417]  Step 143129  [3.533 sec/step, loss=0.09620, avg_loss=0.09552, mel_loss=0.04333, linear_loss=0.05286]
[2020-05-11 19:07:30.420]  Step 143130  [3.527 sec/step, loss=0.08320, avg_loss=0.09541, mel_loss=0.03714, linear_loss=0.04605]
[2020-05-11 19:07:35.528]  Step 143131  [3.566 sec/step, loss=0.10291, avg_loss=0.09555, mel_loss=0.04813, linear_loss=0.05478]
[2020-05-11 19:07:37.807]  Step 143132  [3.573 sec/step, loss=0.09733, avg_loss=0.09561, mel_loss=0.04468, linear_loss=0.05265]
[2020-05-11 19:07:44.093]  Generated 32 batches of size 32 in 21.761 sec
[2020-05-11 19:07:46.657]  Step 143133  [3.644 sec/step, loss=0.10230, avg_loss=0.09569, mel_loss=0.04865, linear_loss=0.05365]
[2020-05-11 19:07:49.235]  Step 143134  [3.645 sec/step, loss=0.09736, avg_loss=0.09568, mel_loss=0.04460, linear_loss=0.05276]
[2020-05-11 19:07:51.648]  Step 143135  [3.659 sec/step, loss=0.09829, avg_loss=0.09577, mel_loss=0.04454, linear_loss=0.05375]
[2020-05-11 19:07:52.864]  Step 143136  [3.662 sec/step, loss=0.08907, avg_loss=0.09583, mel_loss=0.03992, linear_loss=0.04915]
[2020-05-11 19:07:53.880]  Step 143137  [3.641 sec/step, loss=0.08748, avg_loss=0.09568, mel_loss=0.03925, linear_loss=0.04824]
[2020-05-11 19:07:55.500]  Step 143138  [3.636 sec/step, loss=0.09862, avg_loss=0.09568, mel_loss=0.04403, linear_loss=0.05459]
[2020-05-11 19:07:56.280]  Step 143139  [3.592 sec/step, loss=0.07680, avg_loss=0.09539, mel_loss=0.03433, linear_loss=0.04247]
[2020-05-11 19:07:58.043]  Step 143140  [3.582 sec/step, loss=0.09431, avg_loss=0.09535, mel_loss=0.04287, linear_loss=0.05144]
[2020-05-11 19:07:59.131]  Step 143141  [3.578 sec/step, loss=0.09017, avg_loss=0.09538, mel_loss=0.04019, linear_loss=0.04998]
[2020-05-11 19:07:59.908]  Step 143142  [3.517 sec/step, loss=0.08385, avg_loss=0.09520, mel_loss=0.03727, linear_loss=0.04658]
[2020-05-11 19:08:02.674]  Step 143143  [3.372 sec/step, loss=0.09832, avg_loss=0.09537, mel_loss=0.04492, linear_loss=0.05339]
[2020-05-11 19:08:09.584]  Step 143144  [3.419 sec/step, loss=0.10375, avg_loss=0.09545, mel_loss=0.04913, linear_loss=0.05462]
[2020-05-11 19:08:15.187]  Step 143145  [3.433 sec/step, loss=0.10134, avg_loss=0.09543, mel_loss=0.04774, linear_loss=0.05360]
[2020-05-11 19:08:28.207]  Step 143146  [3.529 sec/step, loss=0.08541, avg_loss=0.09526, mel_loss=0.04123, linear_loss=0.04419]
[2020-05-11 19:08:29.342]  Step 143147  [3.515 sec/step, loss=0.09157, avg_loss=0.09519, mel_loss=0.04121, linear_loss=0.05036]
[2020-05-11 19:08:32.283]  Step 143148  [3.477 sec/step, loss=0.10183, avg_loss=0.09519, mel_loss=0.04684, linear_loss=0.05500]
[2020-05-11 19:08:32.835]  Step 143149  [3.469 sec/step, loss=0.07519, avg_loss=0.09502, mel_loss=0.03410, linear_loss=0.04109]
[2020-05-11 19:08:39.056]  Step 143150  [3.514 sec/step, loss=0.10386, avg_loss=0.09511, mel_loss=0.04918, linear_loss=0.05468]
[2020-05-11 19:08:39.056]  Writing summary at step: 143150
[2020-05-11 19:08:41.115]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143150
[2020-05-11 19:08:42.411]  Saving audio and alignment...
[2020-05-11 19:08:47.636]  Input: 그런 무관심을 확인하는 순간마다 최고로 기분이 좋습니다~_______________
[2020-05-11 19:08:52.444]  Step 143151  [3.525 sec/step, loss=0.10157, avg_loss=0.09508, mel_loss=0.04723, linear_loss=0.05434]
[2020-05-11 19:08:56.832]  Step 143152  [3.547 sec/step, loss=0.10418, avg_loss=0.09514, mel_loss=0.04849, linear_loss=0.05569]
[2020-05-11 19:08:57.708]  Step 143153  [3.522 sec/step, loss=0.08501, avg_loss=0.09498, mel_loss=0.03781, linear_loss=0.04720]
[2020-05-11 19:08:59.038]  Step 143154  [3.523 sec/step, loss=0.09199, avg_loss=0.09500, mel_loss=0.04150, linear_loss=0.05049]
[2020-05-11 19:09:02.168]  Step 143155  [3.545 sec/step, loss=0.10331, avg_loss=0.09517, mel_loss=0.04782, linear_loss=0.05549]
[2020-05-11 19:09:03.561]  Step 143156  [3.550 sec/step, loss=0.09282, avg_loss=0.09524, mel_loss=0.04203, linear_loss=0.05080]
[2020-05-11 19:09:05.173]  Step 143157  [3.539 sec/step, loss=0.09231, avg_loss=0.09519, mel_loss=0.04178, linear_loss=0.05053]
[2020-05-11 19:09:06.917]  Generated 32 batches of size 32 in 1.738 sec
[2020-05-11 19:09:07.677]  Step 143158  [3.517 sec/step, loss=0.09894, avg_loss=0.09514, mel_loss=0.04536, linear_loss=0.05359]
[2020-05-11 19:09:16.405]  Step 143159  [3.585 sec/step, loss=0.10035, avg_loss=0.09519, mel_loss=0.04812, linear_loss=0.05223]
[2020-05-11 19:09:18.336]  Step 143160  [3.531 sec/step, loss=0.09563, avg_loss=0.09511, mel_loss=0.04328, linear_loss=0.05235]
[2020-05-11 19:09:21.773]  Step 143161  [3.510 sec/step, loss=0.10443, avg_loss=0.09511, mel_loss=0.04853, linear_loss=0.05591]
[2020-05-11 19:09:23.929]  Step 143162  [3.520 sec/step, loss=0.09826, avg_loss=0.09520, mel_loss=0.04479, linear_loss=0.05348]
[2020-05-11 19:09:27.394]  Step 143163  [3.539 sec/step, loss=0.10103, avg_loss=0.09526, mel_loss=0.04674, linear_loss=0.05429]
[2020-05-11 19:09:31.419]  Step 143164  [3.548 sec/step, loss=0.10137, avg_loss=0.09524, mel_loss=0.04674, linear_loss=0.05463]
[2020-05-11 19:09:33.895]  Step 143165  [3.564 sec/step, loss=0.09933, avg_loss=0.09541, mel_loss=0.04527, linear_loss=0.05406]
[2020-05-11 19:09:37.595]  Step 143166  [3.582 sec/step, loss=0.10287, avg_loss=0.09547, mel_loss=0.04758, linear_loss=0.05529]
[2020-05-11 19:09:38.932]  Step 143167  [3.566 sec/step, loss=0.09114, avg_loss=0.09536, mel_loss=0.04070, linear_loss=0.05043]
[2020-05-11 19:09:45.594]  Step 143168  [3.608 sec/step, loss=0.10319, avg_loss=0.09542, mel_loss=0.04890, linear_loss=0.05428]
[2020-05-11 19:09:48.270]  Step 143169  [3.582 sec/step, loss=0.09745, avg_loss=0.09537, mel_loss=0.04472, linear_loss=0.05273]
[2020-05-11 19:09:48.796]  Step 143170  [3.497 sec/step, loss=0.07465, avg_loss=0.09508, mel_loss=0.03379, linear_loss=0.04085]
[2020-05-11 19:09:50.149]  Step 143171  [3.375 sec/step, loss=0.09315, avg_loss=0.09513, mel_loss=0.04233, linear_loss=0.05082]
[2020-05-11 19:09:57.563]  Step 143172  [3.444 sec/step, loss=0.10501, avg_loss=0.09544, mel_loss=0.04986, linear_loss=0.05515]
[2020-05-11 19:10:02.332]  Step 143173  [3.478 sec/step, loss=0.10344, avg_loss=0.09555, mel_loss=0.04829, linear_loss=0.05515]
[2020-05-11 19:10:03.351]  Step 143174  [3.446 sec/step, loss=0.08705, avg_loss=0.09541, mel_loss=0.03924, linear_loss=0.04781]
[2020-05-11 19:10:06.381]  Step 143175  [3.205 sec/step, loss=0.10178, avg_loss=0.09545, mel_loss=0.04680, linear_loss=0.05498]
[2020-05-11 19:10:11.979]  Step 143176  [3.226 sec/step, loss=0.10263, avg_loss=0.09547, mel_loss=0.04817, linear_loss=0.05446]
[2020-05-11 19:10:14.221]  Step 143177  [3.227 sec/step, loss=0.09754, avg_loss=0.09547, mel_loss=0.04473, linear_loss=0.05281]
[2020-05-11 19:10:16.359]  Step 143178  [3.237 sec/step, loss=0.09681, avg_loss=0.09555, mel_loss=0.04430, linear_loss=0.05252]
[2020-05-11 19:10:21.615]  Step 143179  [3.282 sec/step, loss=0.10240, avg_loss=0.09577, mel_loss=0.04810, linear_loss=0.05430]
[2020-05-11 19:10:22.727]  Step 143180  [3.218 sec/step, loss=0.08803, avg_loss=0.09559, mel_loss=0.03913, linear_loss=0.04890]
[2020-05-11 19:10:23.600]  Step 143181  [3.212 sec/step, loss=0.08650, avg_loss=0.09554, mel_loss=0.03856, linear_loss=0.04794]
[2020-05-11 19:10:27.111]  Step 143182  [3.240 sec/step, loss=0.10000, avg_loss=0.09570, mel_loss=0.04622, linear_loss=0.05378]
[2020-05-11 19:10:35.973]  Step 143183  [3.313 sec/step, loss=0.10042, avg_loss=0.09573, mel_loss=0.04814, linear_loss=0.05228]
[2020-05-11 19:10:39.977]  Step 143184  [3.332 sec/step, loss=0.10260, avg_loss=0.09578, mel_loss=0.04764, linear_loss=0.05496]
[2020-05-11 19:10:44.323]  Step 143185  [3.362 sec/step, loss=0.10250, avg_loss=0.09590, mel_loss=0.04802, linear_loss=0.05448]
[2020-05-11 19:10:47.940]  Step 143186  [3.390 sec/step, loss=0.10172, avg_loss=0.09610, mel_loss=0.04688, linear_loss=0.05484]
[2020-05-11 19:10:50.380]  Step 143187  [3.381 sec/step, loss=0.09633, avg_loss=0.09605, mel_loss=0.04389, linear_loss=0.05244]
[2020-05-11 19:10:51.599]  Step 143188  [3.375 sec/step, loss=0.09146, avg_loss=0.09601, mel_loss=0.04117, linear_loss=0.05028]
[2020-05-11 19:11:05.981]  Step 143189  [3.462 sec/step, loss=0.08259, avg_loss=0.09578, mel_loss=0.04014, linear_loss=0.04245]
[2020-05-11 19:11:06.865]  Step 143190  [3.440 sec/step, loss=0.08075, avg_loss=0.09559, mel_loss=0.03617, linear_loss=0.04458]
[2020-05-11 19:11:07.772]  Generated 32 batches of size 32 in 1.786 sec
[2020-05-11 19:11:09.814]  Step 143191  [3.407 sec/step, loss=0.10050, avg_loss=0.09555, mel_loss=0.04635, linear_loss=0.05414]
[2020-05-11 19:11:11.571]  Step 143192  [3.414 sec/step, loss=0.09509, avg_loss=0.09564, mel_loss=0.04292, linear_loss=0.05217]
[2020-05-11 19:11:13.632]  Step 143193  [3.408 sec/step, loss=0.09616, avg_loss=0.09560, mel_loss=0.04378, linear_loss=0.05238]
[2020-05-11 19:11:15.214]  Step 143194  [3.383 sec/step, loss=0.09454, avg_loss=0.09550, mel_loss=0.04287, linear_loss=0.05167]
[2020-05-11 19:11:16.916]  Step 143195  [3.371 sec/step, loss=0.09567, avg_loss=0.09547, mel_loss=0.04336, linear_loss=0.05231]
[2020-05-11 19:11:18.929]  Step 143196  [3.337 sec/step, loss=0.09523, avg_loss=0.09537, mel_loss=0.04292, linear_loss=0.05231]
[2020-05-11 19:11:19.826]  Step 143197  [3.325 sec/step, loss=0.08250, avg_loss=0.09522, mel_loss=0.03706, linear_loss=0.04544]
[2020-05-11 19:11:23.334]  Step 143198  [3.342 sec/step, loss=0.10174, avg_loss=0.09529, mel_loss=0.04693, linear_loss=0.05481]
[2020-05-11 19:11:25.346]  Step 143199  [3.350 sec/step, loss=0.09748, avg_loss=0.09535, mel_loss=0.04409, linear_loss=0.05340]
[2020-05-11 19:11:32.029]  Step 143200  [3.397 sec/step, loss=0.10422, avg_loss=0.09541, mel_loss=0.04934, linear_loss=0.05488]
[2020-05-11 19:11:32.029]  Writing summary at step: 143200
[2020-05-11 19:11:34.853]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143200
[2020-05-11 19:11:36.123]  Saving audio and alignment...
[2020-05-11 19:11:43.643]  Input: 이런 주최측 참석자를 기쁘게 해서 아주 큰 보상을 받은 경험이 있습니~_____________________________
[2020-05-11 19:11:47.145]  Step 143201  [3.386 sec/step, loss=0.10179, avg_loss=0.09539, mel_loss=0.04712, linear_loss=0.05467]
[2020-05-11 19:11:48.456]  Step 143202  [3.389 sec/step, loss=0.09052, avg_loss=0.09544, mel_loss=0.04080, linear_loss=0.04972]
[2020-05-11 19:12:06.727]  Step 143203  [3.427 sec/step, loss=0.07997, avg_loss=0.09543, mel_loss=0.03918, linear_loss=0.04079]
[2020-05-11 19:12:07.960]  Step 143204  [3.387 sec/step, loss=0.08401, avg_loss=0.09524, mel_loss=0.03715, linear_loss=0.04686]
[2020-05-11 19:12:17.278]  Step 143205  [3.466 sec/step, loss=0.10303, avg_loss=0.09537, mel_loss=0.04912, linear_loss=0.05391]
[2020-05-11 19:12:18.085]  Step 143206  [3.462 sec/step, loss=0.07743, avg_loss=0.09526, mel_loss=0.03468, linear_loss=0.04275]
[2020-05-11 19:12:19.993]  Step 143207  [3.473 sec/step, loss=0.09518, avg_loss=0.09534, mel_loss=0.04289, linear_loss=0.05229]
[2020-05-11 19:12:21.405]  Step 143208  [3.467 sec/step, loss=0.09168, avg_loss=0.09528, mel_loss=0.04145, linear_loss=0.05023]
[2020-05-11 19:12:26.452]  Step 143209  [3.502 sec/step, loss=0.10148, avg_loss=0.09535, mel_loss=0.04751, linear_loss=0.05396]
[2020-05-11 19:12:29.916]  Step 143210  [3.492 sec/step, loss=0.10039, avg_loss=0.09533, mel_loss=0.04640, linear_loss=0.05399]
[2020-05-11 19:12:30.487]  Step 143211  [3.468 sec/step, loss=0.07693, avg_loss=0.09509, mel_loss=0.03465, linear_loss=0.04228]
[2020-05-11 19:12:31.496]  Step 143212  [3.402 sec/step, loss=0.08517, avg_loss=0.09490, mel_loss=0.03773, linear_loss=0.04745]
[2020-05-11 19:12:33.274]  Step 143213  [3.414 sec/step, loss=0.09487, avg_loss=0.09508, mel_loss=0.04275, linear_loss=0.05213]
[2020-05-11 19:12:35.735]  Step 143214  [3.431 sec/step, loss=0.09829, avg_loss=0.09524, mel_loss=0.04460, linear_loss=0.05369]
[2020-05-11 19:12:37.339]  Step 143215  [3.406 sec/step, loss=0.09291, avg_loss=0.09514, mel_loss=0.04196, linear_loss=0.05095]
[2020-05-11 19:12:41.523]  Step 143216  [3.427 sec/step, loss=0.10122, avg_loss=0.09519, mel_loss=0.04672, linear_loss=0.05450]
[2020-05-11 19:12:47.219]  Step 143217  [3.466 sec/step, loss=0.10378, avg_loss=0.09528, mel_loss=0.04877, linear_loss=0.05501]
[2020-05-11 19:12:48.217]  Step 143218  [3.447 sec/step, loss=0.08928, avg_loss=0.09519, mel_loss=0.03986, linear_loss=0.04941]
[2020-05-11 19:12:51.253]  Step 143219  [3.411 sec/step, loss=0.10112, avg_loss=0.09517, mel_loss=0.04625, linear_loss=0.05487]
[2020-05-11 19:12:52.456]  Step 143220  [3.383 sec/step, loss=0.08776, avg_loss=0.09501, mel_loss=0.03933, linear_loss=0.04843]
[2020-05-11 19:12:53.725]  Generated 32 batches of size 32 in 2.465 sec
[2020-05-11 19:12:53.822]  Step 143221  [3.360 sec/step, loss=0.09072, avg_loss=0.09490, mel_loss=0.04074, linear_loss=0.04997]
[2020-05-11 19:12:58.472]  Step 143222  [3.267 sec/step, loss=0.10263, avg_loss=0.09514, mel_loss=0.04781, linear_loss=0.05482]
[2020-05-11 19:13:00.594]  Step 143223  [3.274 sec/step, loss=0.09691, avg_loss=0.09518, mel_loss=0.04422, linear_loss=0.05269]
[2020-05-11 19:13:09.156]  Step 143224  [3.325 sec/step, loss=0.10055, avg_loss=0.09521, mel_loss=0.04796, linear_loss=0.05259]
[2020-05-11 19:13:10.763]  Step 143225  [3.331 sec/step, loss=0.09493, avg_loss=0.09530, mel_loss=0.04292, linear_loss=0.05200]
[2020-05-11 19:13:13.369]  Step 143226  [3.341 sec/step, loss=0.09986, avg_loss=0.09533, mel_loss=0.04583, linear_loss=0.05404]
[2020-05-11 19:13:17.042]  Step 143227  [3.345 sec/step, loss=0.10267, avg_loss=0.09533, mel_loss=0.04761, linear_loss=0.05506]
[2020-05-11 19:13:19.235]  Step 143228  [3.313 sec/step, loss=0.09819, avg_loss=0.09528, mel_loss=0.04500, linear_loss=0.05318]
[2020-05-11 19:13:22.888]  Step 143229  [3.333 sec/step, loss=0.10283, avg_loss=0.09535, mel_loss=0.04777, linear_loss=0.05506]
[2020-05-11 19:13:28.181]  Step 143230  [3.375 sec/step, loss=0.10058, avg_loss=0.09552, mel_loss=0.04703, linear_loss=0.05355]
[2020-05-11 19:13:32.233]  Step 143231  [3.365 sec/step, loss=0.10335, avg_loss=0.09553, mel_loss=0.04783, linear_loss=0.05552]
[2020-05-11 19:13:34.962]  Step 143232  [3.369 sec/step, loss=0.09865, avg_loss=0.09554, mel_loss=0.04538, linear_loss=0.05327]
[2020-05-11 19:13:41.071]  Step 143233  [3.342 sec/step, loss=0.10076, avg_loss=0.09552, mel_loss=0.04744, linear_loss=0.05333]
[2020-05-11 19:13:43.256]  Step 143234  [3.338 sec/step, loss=0.09555, avg_loss=0.09551, mel_loss=0.04370, linear_loss=0.05186]
[2020-05-11 19:13:45.313]  Step 143235  [3.334 sec/step, loss=0.09727, avg_loss=0.09550, mel_loss=0.04432, linear_loss=0.05296]
[2020-05-11 19:13:49.611]  Step 143236  [3.365 sec/step, loss=0.10222, avg_loss=0.09563, mel_loss=0.04742, linear_loss=0.05480]
[2020-05-11 19:13:52.082]  Step 143237  [3.380 sec/step, loss=0.09690, avg_loss=0.09572, mel_loss=0.04421, linear_loss=0.05270]
[2020-05-11 19:13:53.147]  Step 143238  [3.374 sec/step, loss=0.09189, avg_loss=0.09565, mel_loss=0.04075, linear_loss=0.05114]
[2020-05-11 19:14:01.955]  Step 143239  [3.455 sec/step, loss=0.10142, avg_loss=0.09590, mel_loss=0.04830, linear_loss=0.05312]
[2020-05-11 19:14:03.744]  Step 143240  [3.455 sec/step, loss=0.09578, avg_loss=0.09591, mel_loss=0.04351, linear_loss=0.05227]
[2020-05-11 19:14:05.184]  Step 143241  [3.458 sec/step, loss=0.09413, avg_loss=0.09595, mel_loss=0.04265, linear_loss=0.05148]
[2020-05-11 19:14:06.180]  Step 143242  [3.461 sec/step, loss=0.08749, avg_loss=0.09599, mel_loss=0.03903, linear_loss=0.04846]
[2020-05-11 19:14:07.549]  Step 143243  [3.447 sec/step, loss=0.09343, avg_loss=0.09594, mel_loss=0.04191, linear_loss=0.05152]
[2020-05-11 19:14:10.583]  Step 143244  [3.408 sec/step, loss=0.10266, avg_loss=0.09593, mel_loss=0.04741, linear_loss=0.05524]
[2020-05-11 19:14:11.623]  Step 143245  [3.362 sec/step, loss=0.08643, avg_loss=0.09578, mel_loss=0.03899, linear_loss=0.04745]
[2020-05-11 19:14:19.072]  Step 143246  [3.306 sec/step, loss=0.10382, avg_loss=0.09597, mel_loss=0.04923, linear_loss=0.05459]
[2020-05-11 19:14:21.989]  Step 143247  [3.324 sec/step, loss=0.10172, avg_loss=0.09607, mel_loss=0.04671, linear_loss=0.05501]
[2020-05-11 19:14:24.383]  Step 143248  [3.319 sec/step, loss=0.09983, avg_loss=0.09605, mel_loss=0.04562, linear_loss=0.05421]
[2020-05-11 19:14:25.177]  Step 143249  [3.321 sec/step, loss=0.08229, avg_loss=0.09612, mel_loss=0.03663, linear_loss=0.04566]
[2020-05-11 19:14:29.796]  Step 143250  [3.305 sec/step, loss=0.10247, avg_loss=0.09610, mel_loss=0.04774, linear_loss=0.05473]
[2020-05-11 19:14:29.796]  Writing summary at step: 143250
[2020-05-11 19:14:31.543]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143250
[2020-05-11 19:14:32.840]  Saving audio and alignment...
[2020-05-11 19:14:35.106]  Generated 32 batches of size 32 in 1.722 sec
[2020-05-11 19:14:49.481]  Input: 녹십자라는 그룹의 씨아이 로고가 바로 녹색이 잖아요 따라서 임직원들이 가장 선호하고 친숙하게 느껴지는 색상이기 때문이에요~____________________________________________
[2020-05-11 19:14:51.430]  Step 143251  [3.277 sec/step, loss=0.09540, avg_loss=0.09604, mel_loss=0.04301, linear_loss=0.05239]
[2020-05-11 19:14:52.982]  Step 143252  [3.248 sec/step, loss=0.09415, avg_loss=0.09594, mel_loss=0.04255, linear_loss=0.05160]
[2020-05-11 19:14:56.452]  Step 143253  [3.274 sec/step, loss=0.09859, avg_loss=0.09608, mel_loss=0.04530, linear_loss=0.05329]
[2020-05-11 19:14:57.711]  Step 143254  [3.273 sec/step, loss=0.08907, avg_loss=0.09605, mel_loss=0.04012, linear_loss=0.04895]
[2020-05-11 19:14:58.284]  Step 143255  [3.248 sec/step, loss=0.07614, avg_loss=0.09578, mel_loss=0.03421, linear_loss=0.04194]
[2020-05-11 19:14:59.117]  Step 143256  [3.242 sec/step, loss=0.08267, avg_loss=0.09568, mel_loss=0.03720, linear_loss=0.04547]
[2020-05-11 19:15:04.429]  Step 143257  [3.279 sec/step, loss=0.10456, avg_loss=0.09580, mel_loss=0.04891, linear_loss=0.05565]
[2020-05-11 19:15:07.748]  Step 143258  [3.287 sec/step, loss=0.10401, avg_loss=0.09585, mel_loss=0.04804, linear_loss=0.05597]
[2020-05-11 19:15:12.078]  Step 143259  [3.243 sec/step, loss=0.10111, avg_loss=0.09586, mel_loss=0.04719, linear_loss=0.05393]
[2020-05-11 19:15:13.299]  Step 143260  [3.236 sec/step, loss=0.08930, avg_loss=0.09579, mel_loss=0.04021, linear_loss=0.04909]
[2020-05-11 19:15:15.186]  Step 143261  [3.221 sec/step, loss=0.09351, avg_loss=0.09568, mel_loss=0.04232, linear_loss=0.05119]
[2020-05-11 19:15:17.185]  Step 143262  [3.219 sec/step, loss=0.09675, avg_loss=0.09567, mel_loss=0.04369, linear_loss=0.05307]
[2020-05-11 19:15:18.949]  Step 143263  [3.202 sec/step, loss=0.09620, avg_loss=0.09562, mel_loss=0.04304, linear_loss=0.05316]
[2020-05-11 19:15:22.446]  Step 143264  [3.197 sec/step, loss=0.09963, avg_loss=0.09560, mel_loss=0.04616, linear_loss=0.05347]
[2020-05-11 19:15:23.252]  Step 143265  [3.180 sec/step, loss=0.07856, avg_loss=0.09540, mel_loss=0.03477, linear_loss=0.04378]
[2020-05-11 19:15:30.809]  Step 143266  [3.219 sec/step, loss=0.10378, avg_loss=0.09540, mel_loss=0.04933, linear_loss=0.05445]
[2020-05-11 19:15:31.893]  Step 143267  [3.216 sec/step, loss=0.08886, avg_loss=0.09538, mel_loss=0.03954, linear_loss=0.04933]
[2020-05-11 19:15:34.447]  Step 143268  [3.175 sec/step, loss=0.09685, avg_loss=0.09532, mel_loss=0.04407, linear_loss=0.05278]
[2020-05-11 19:15:36.056]  Step 143269  [3.165 sec/step, loss=0.09088, avg_loss=0.09525, mel_loss=0.04098, linear_loss=0.04989]
[2020-05-11 19:15:41.622]  Step 143270  [3.215 sec/step, loss=0.10013, avg_loss=0.09551, mel_loss=0.04704, linear_loss=0.05310]
[2020-05-11 19:15:44.486]  Step 143271  [3.230 sec/step, loss=0.10067, avg_loss=0.09558, mel_loss=0.04628, linear_loss=0.05438]
[2020-05-11 19:15:53.265]  Step 143272  [3.244 sec/step, loss=0.10304, avg_loss=0.09556, mel_loss=0.04919, linear_loss=0.05386]
[2020-05-11 19:15:57.951]  Step 143273  [3.243 sec/step, loss=0.10211, avg_loss=0.09555, mel_loss=0.04757, linear_loss=0.05455]
[2020-05-11 19:16:00.169]  Step 143274  [3.255 sec/step, loss=0.09507, avg_loss=0.09563, mel_loss=0.04310, linear_loss=0.05198]
[2020-05-11 19:16:03.879]  Step 143275  [3.262 sec/step, loss=0.10298, avg_loss=0.09564, mel_loss=0.04757, linear_loss=0.05541]
[2020-05-11 19:16:08.773]  Step 143276  [3.255 sec/step, loss=0.10291, avg_loss=0.09564, mel_loss=0.04823, linear_loss=0.05468]
[2020-05-11 19:16:10.137]  Step 143277  [3.246 sec/step, loss=0.09149, avg_loss=0.09558, mel_loss=0.04127, linear_loss=0.05022]
[2020-05-11 19:16:11.215]  Step 143278  [3.235 sec/step, loss=0.09030, avg_loss=0.09552, mel_loss=0.04003, linear_loss=0.05027]
[2020-05-11 19:16:15.293]  Step 143279  [3.224 sec/step, loss=0.10125, avg_loss=0.09551, mel_loss=0.04676, linear_loss=0.05449]
[2020-05-11 19:16:18.444]  Step 143280  [3.244 sec/step, loss=0.10076, avg_loss=0.09563, mel_loss=0.04653, linear_loss=0.05423]
[2020-05-11 19:16:25.290]  Step 143281  [3.304 sec/step, loss=0.10368, avg_loss=0.09581, mel_loss=0.04898, linear_loss=0.05470]
[2020-05-11 19:16:27.194]  Generated 32 batches of size 32 in 1.898 sec
[2020-05-11 19:16:27.686]  Step 143282  [3.293 sec/step, loss=0.09829, avg_loss=0.09579, mel_loss=0.04447, linear_loss=0.05381]
[2020-05-11 19:16:28.576]  Step 143283  [3.213 sec/step, loss=0.08248, avg_loss=0.09561, mel_loss=0.03643, linear_loss=0.04605]
[2020-05-11 19:16:42.330]  Step 143284  [3.310 sec/step, loss=0.08431, avg_loss=0.09543, mel_loss=0.04085, linear_loss=0.04345]
[2020-05-11 19:16:42.895]  Step 143285  [3.272 sec/step, loss=0.07696, avg_loss=0.09517, mel_loss=0.03550, linear_loss=0.04146]
[2020-05-11 19:16:44.522]  Step 143286  [3.253 sec/step, loss=0.09509, avg_loss=0.09511, mel_loss=0.04297, linear_loss=0.05212]
[2020-05-11 19:16:45.430]  Step 143287  [3.237 sec/step, loss=0.08644, avg_loss=0.09501, mel_loss=0.03845, linear_loss=0.04798]
[2020-05-11 19:16:48.059]  Step 143288  [3.251 sec/step, loss=0.09850, avg_loss=0.09508, mel_loss=0.04501, linear_loss=0.05349]
[2020-05-11 19:16:51.442]  Step 143289  [3.141 sec/step, loss=0.10137, avg_loss=0.09526, mel_loss=0.04645, linear_loss=0.05492]
[2020-05-11 19:16:52.870]  Step 143290  [3.147 sec/step, loss=0.09153, avg_loss=0.09537, mel_loss=0.04127, linear_loss=0.05026]
[2020-05-11 19:16:54.036]  Step 143291  [3.129 sec/step, loss=0.09058, avg_loss=0.09527, mel_loss=0.04066, linear_loss=0.04992]
[2020-05-11 19:16:54.599]  Step 143292  [3.117 sec/step, loss=0.07634, avg_loss=0.09509, mel_loss=0.03419, linear_loss=0.04215]
[2020-05-11 19:16:59.169]  Step 143293  [3.142 sec/step, loss=0.10352, avg_loss=0.09516, mel_loss=0.04832, linear_loss=0.05519]
[2020-05-11 19:17:00.256]  Step 143294  [3.137 sec/step, loss=0.08861, avg_loss=0.09510, mel_loss=0.03903, linear_loss=0.04957]
[2020-05-11 19:17:05.613]  Step 143295  [3.174 sec/step, loss=0.10251, avg_loss=0.09517, mel_loss=0.04791, linear_loss=0.05461]
[2020-05-11 19:17:08.648]  Step 143296  [3.184 sec/step, loss=0.10099, avg_loss=0.09523, mel_loss=0.04642, linear_loss=0.05456]
[2020-05-11 19:17:10.279]  Step 143297  [3.191 sec/step, loss=0.09402, avg_loss=0.09534, mel_loss=0.04248, linear_loss=0.05155]
[2020-05-11 19:17:11.035]  Step 143298  [3.164 sec/step, loss=0.08637, avg_loss=0.09519, mel_loss=0.03861, linear_loss=0.04776]
[2020-05-11 19:17:24.996]  Step 143299  [3.283 sec/step, loss=0.08292, avg_loss=0.09504, mel_loss=0.04029, linear_loss=0.04263]
[2020-05-11 19:17:27.194]  Step 143300  [3.238 sec/step, loss=0.09591, avg_loss=0.09496, mel_loss=0.04398, linear_loss=0.05193]
[2020-05-11 19:17:27.194]  Writing summary at step: 143300
[2020-05-11 19:17:28.169]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143300
[2020-05-11 19:17:29.872]  Saving audio and alignment...
[2020-05-11 19:17:35.100]  Input: 자 다음은 케이비에스으 본사 기출 인데요~_____________________________
[2020-05-11 19:17:38.080]  Step 143301  [3.233 sec/step, loss=0.10136, avg_loss=0.09495, mel_loss=0.04683, linear_loss=0.05452]
[2020-05-11 19:17:41.855]  Step 143302  [3.258 sec/step, loss=0.10206, avg_loss=0.09507, mel_loss=0.04711, linear_loss=0.05495]
[2020-05-11 19:17:43.251]  Step 143303  [3.089 sec/step, loss=0.09055, avg_loss=0.09518, mel_loss=0.04081, linear_loss=0.04974]
[2020-05-11 19:17:44.575]  Step 143304  [3.090 sec/step, loss=0.09084, avg_loss=0.09524, mel_loss=0.04073, linear_loss=0.05011]
[2020-05-11 19:17:47.371]  Step 143305  [3.025 sec/step, loss=0.09739, avg_loss=0.09519, mel_loss=0.04481, linear_loss=0.05258]
[2020-05-11 19:17:51.024]  Step 143306  [3.053 sec/step, loss=0.10201, avg_loss=0.09543, mel_loss=0.04710, linear_loss=0.05490]
[2020-05-11 19:17:55.376]  Step 143307  [3.078 sec/step, loss=0.10018, avg_loss=0.09548, mel_loss=0.04652, linear_loss=0.05367]
[2020-05-11 19:17:57.307]  Step 143308  [3.083 sec/step, loss=0.09627, avg_loss=0.09553, mel_loss=0.04330, linear_loss=0.05298]
[2020-05-11 19:17:59.793]  Step 143309  [3.057 sec/step, loss=0.09787, avg_loss=0.09549, mel_loss=0.04446, linear_loss=0.05341]
[2020-05-11 19:18:03.189]  Step 143310  [3.057 sec/step, loss=0.10416, avg_loss=0.09553, mel_loss=0.04824, linear_loss=0.05592]
[2020-05-11 19:18:04.038]  Step 143311  [3.059 sec/step, loss=0.08158, avg_loss=0.09558, mel_loss=0.03633, linear_loss=0.04524]
[2020-05-11 19:18:05.695]  Generated 32 batches of size 32 in 1.652 sec
[2020-05-11 19:18:11.581]  Step 143312  [3.125 sec/step, loss=0.10264, avg_loss=0.09575, mel_loss=0.04865, linear_loss=0.05399]
[2020-05-11 19:18:13.370]  Step 143313  [3.125 sec/step, loss=0.09442, avg_loss=0.09575, mel_loss=0.04246, linear_loss=0.05197]
[2020-05-11 19:18:14.325]  Step 143314  [3.110 sec/step, loss=0.08806, avg_loss=0.09565, mel_loss=0.03966, linear_loss=0.04840]
[2020-05-11 19:18:16.738]  Step 143315  [3.118 sec/step, loss=0.09863, avg_loss=0.09570, mel_loss=0.04523, linear_loss=0.05340]
[2020-05-11 19:18:23.225]  Step 143316  [3.141 sec/step, loss=0.10123, avg_loss=0.09570, mel_loss=0.04805, linear_loss=0.05318]
[2020-05-11 19:18:32.248]  Step 143317  [3.174 sec/step, loss=0.10247, avg_loss=0.09569, mel_loss=0.04873, linear_loss=0.05374]
[2020-05-11 19:18:34.327]  Step 143318  [3.185 sec/step, loss=0.09529, avg_loss=0.09575, mel_loss=0.04358, linear_loss=0.05170]
[2020-05-11 19:18:35.931]  Step 143319  [3.171 sec/step, loss=0.09397, avg_loss=0.09568, mel_loss=0.04254, linear_loss=0.05143]
[2020-05-11 19:18:41.565]  Step 143320  [3.215 sec/step, loss=0.10412, avg_loss=0.09584, mel_loss=0.04882, linear_loss=0.05529]
[2020-05-11 19:18:46.178]  Step 143321  [3.247 sec/step, loss=0.10190, avg_loss=0.09595, mel_loss=0.04747, linear_loss=0.05443]
[2020-05-11 19:18:49.844]  Step 143322  [3.238 sec/step, loss=0.10233, avg_loss=0.09595, mel_loss=0.04727, linear_loss=0.05506]
[2020-05-11 19:18:50.681]  Step 143323  [3.225 sec/step, loss=0.08054, avg_loss=0.09579, mel_loss=0.03620, linear_loss=0.04434]
[2020-05-11 19:18:58.948]  Step 143324  [3.222 sec/step, loss=0.10136, avg_loss=0.09580, mel_loss=0.04835, linear_loss=0.05301]
[2020-05-11 19:18:59.856]  Step 143325  [3.215 sec/step, loss=0.08446, avg_loss=0.09569, mel_loss=0.03757, linear_loss=0.04689]
[2020-05-11 19:19:02.023]  Step 143326  [3.210 sec/step, loss=0.09698, avg_loss=0.09566, mel_loss=0.04404, linear_loss=0.05294]
[2020-05-11 19:19:06.128]  Step 143327  [3.215 sec/step, loss=0.10250, avg_loss=0.09566, mel_loss=0.04733, linear_loss=0.05517]
[2020-05-11 19:19:07.158]  Step 143328  [3.203 sec/step, loss=0.08456, avg_loss=0.09552, mel_loss=0.03753, linear_loss=0.04703]
[2020-05-11 19:19:09.499]  Step 143329  [3.190 sec/step, loss=0.09538, avg_loss=0.09545, mel_loss=0.04325, linear_loss=0.05214]
[2020-05-11 19:19:12.772]  Step 143330  [3.170 sec/step, loss=0.10245, avg_loss=0.09547, mel_loss=0.04724, linear_loss=0.05521]
[2020-05-11 19:19:14.517]  Step 143331  [3.147 sec/step, loss=0.09587, avg_loss=0.09539, mel_loss=0.04320, linear_loss=0.05267]
[2020-05-11 19:19:20.201]  Step 143332  [3.176 sec/step, loss=0.10200, avg_loss=0.09543, mel_loss=0.04774, linear_loss=0.05426]
[2020-05-11 19:19:22.162]  Step 143333  [3.135 sec/step, loss=0.09680, avg_loss=0.09539, mel_loss=0.04368, linear_loss=0.05312]
[2020-05-11 19:19:24.093]  Step 143334  [3.132 sec/step, loss=0.09632, avg_loss=0.09539, mel_loss=0.04351, linear_loss=0.05281]
[2020-05-11 19:19:27.611]  Step 143335  [3.147 sec/step, loss=0.09837, avg_loss=0.09541, mel_loss=0.04556, linear_loss=0.05281]
[2020-05-11 19:19:30.061]  Step 143336  [3.128 sec/step, loss=0.09788, avg_loss=0.09536, mel_loss=0.04458, linear_loss=0.05330]
[2020-05-11 19:19:34.244]  Step 143337  [3.145 sec/step, loss=0.10179, avg_loss=0.09541, mel_loss=0.04741, linear_loss=0.05438]
[2020-05-11 19:19:36.948]  Step 143338  [3.162 sec/step, loss=0.09859, avg_loss=0.09548, mel_loss=0.04524, linear_loss=0.05335]
[2020-05-11 19:19:44.483]  Step 143339  [3.149 sec/step, loss=0.10286, avg_loss=0.09549, mel_loss=0.04871, linear_loss=0.05415]
[2020-05-11 19:19:47.452]  Step 143340  [3.161 sec/step, loss=0.10190, avg_loss=0.09555, mel_loss=0.04670, linear_loss=0.05520]
[2020-05-11 19:19:50.227]  Step 143341  [3.174 sec/step, loss=0.09787, avg_loss=0.09559, mel_loss=0.04513, linear_loss=0.05275]
[2020-05-11 19:19:51.628]  Step 143342  [3.178 sec/step, loss=0.09210, avg_loss=0.09564, mel_loss=0.04175, linear_loss=0.05035]
[2020-05-11 19:19:58.428]  Step 143343  [3.233 sec/step, loss=0.10385, avg_loss=0.09574, mel_loss=0.04912, linear_loss=0.05473]
[2020-05-11 19:19:59.741]  Step 143344  [3.215 sec/step, loss=0.08864, avg_loss=0.09560, mel_loss=0.03974, linear_loss=0.04889]
[2020-05-11 19:20:00.178]  Generated 32 batches of size 32 in 1.745 sec
[2020-05-11 19:20:01.112]  Step 143345  [3.219 sec/step, loss=0.09215, avg_loss=0.09566, mel_loss=0.04094, linear_loss=0.05121]
[2020-05-11 19:20:02.748]  Step 143346  [3.161 sec/step, loss=0.09515, avg_loss=0.09557, mel_loss=0.04259, linear_loss=0.05256]
[2020-05-11 19:20:03.548]  Step 143347  [3.139 sec/step, loss=0.08006, avg_loss=0.09535, mel_loss=0.03527, linear_loss=0.04478]
[2020-05-11 19:20:04.108]  Step 143348  [3.121 sec/step, loss=0.07303, avg_loss=0.09509, mel_loss=0.03308, linear_loss=0.03995]
[2020-05-11 19:20:05.637]  Step 143349  [3.128 sec/step, loss=0.09278, avg_loss=0.09519, mel_loss=0.04179, linear_loss=0.05099]
[2020-05-11 19:20:06.763]  Step 143350  [3.094 sec/step, loss=0.09015, avg_loss=0.09507, mel_loss=0.04017, linear_loss=0.04998]
[2020-05-11 19:20:06.763]  Writing summary at step: 143350
[2020-05-11 19:20:12.181]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143350
[2020-05-11 19:20:13.506]  Saving audio and alignment...
[2020-05-11 19:20:29.486]  Input: 음 외고 그리고 영어과를 나왔기 때문이에요 좀 특기 이걸 활용해서 용돈을 좀 벌어 봐야겠다 이십대 초반에 그런 생각을 했어요~______________________________
[2020-05-11 19:20:30.932]  Step 143351  [3.088 sec/step, loss=0.09124, avg_loss=0.09503, mel_loss=0.04119, linear_loss=0.05005]
[2020-05-11 19:20:32.139]  Step 143352  [3.085 sec/step, loss=0.08993, avg_loss=0.09498, mel_loss=0.04069, linear_loss=0.04924]
[2020-05-11 19:20:36.955]  Step 143353  [3.098 sec/step, loss=0.10183, avg_loss=0.09502, mel_loss=0.04715, linear_loss=0.05468]
[2020-05-11 19:20:42.910]  Step 143354  [3.145 sec/step, loss=0.10409, avg_loss=0.09517, mel_loss=0.04914, linear_loss=0.05495]
[2020-05-11 19:20:43.822]  Step 143355  [3.149 sec/step, loss=0.08643, avg_loss=0.09527, mel_loss=0.03863, linear_loss=0.04780]
[2020-05-11 19:20:45.740]  Step 143356  [3.160 sec/step, loss=0.09464, avg_loss=0.09539, mel_loss=0.04233, linear_loss=0.05230]
[2020-05-11 19:20:46.392]  Step 143357  [3.113 sec/step, loss=0.08336, avg_loss=0.09518, mel_loss=0.03736, linear_loss=0.04600]
[2020-05-11 19:20:47.159]  Step 143358  [3.088 sec/step, loss=0.08688, avg_loss=0.09501, mel_loss=0.03860, linear_loss=0.04828]
[2020-05-11 19:21:01.570]  Step 143359  [3.188 sec/step, loss=0.08219, avg_loss=0.09482, mel_loss=0.03995, linear_loss=0.04223]
[2020-05-11 19:21:02.107]  Step 143360  [3.182 sec/step, loss=0.07610, avg_loss=0.09469, mel_loss=0.03454, linear_loss=0.04156]
[2020-05-11 19:21:11.048]  Step 143361  [3.252 sec/step, loss=0.10235, avg_loss=0.09477, mel_loss=0.04898, linear_loss=0.05337]
[2020-05-11 19:21:18.663]  Step 143362  [3.308 sec/step, loss=0.10315, avg_loss=0.09484, mel_loss=0.04881, linear_loss=0.05434]
[2020-05-11 19:21:21.019]  Step 143363  [3.314 sec/step, loss=0.10166, avg_loss=0.09489, mel_loss=0.04663, linear_loss=0.05503]
[2020-05-11 19:21:23.098]  Step 143364  [3.300 sec/step, loss=0.09688, avg_loss=0.09486, mel_loss=0.04397, linear_loss=0.05291]
[2020-05-11 19:21:29.639]  Step 143365  [3.357 sec/step, loss=0.10417, avg_loss=0.09512, mel_loss=0.04935, linear_loss=0.05482]
[2020-05-11 19:21:32.268]  Step 143366  [3.308 sec/step, loss=0.09793, avg_loss=0.09506, mel_loss=0.04453, linear_loss=0.05340]
[2020-05-11 19:21:36.922]  Step 143367  [3.344 sec/step, loss=0.10435, avg_loss=0.09522, mel_loss=0.04864, linear_loss=0.05571]
[2020-05-11 19:21:40.877]  Step 143368  [3.358 sec/step, loss=0.10320, avg_loss=0.09528, mel_loss=0.04779, linear_loss=0.05541]
[2020-05-11 19:21:42.391]  Step 143369  [3.357 sec/step, loss=0.09282, avg_loss=0.09530, mel_loss=0.04210, linear_loss=0.05073]
[2020-05-11 19:21:44.373]  Step 143370  [3.321 sec/step, loss=0.09500, avg_loss=0.09525, mel_loss=0.04243, linear_loss=0.05257]
[2020-05-11 19:21:47.182]  Step 143371  [3.320 sec/step, loss=0.09941, avg_loss=0.09524, mel_loss=0.04569, linear_loss=0.05372]
[2020-05-11 19:21:49.362]  Step 143372  [3.254 sec/step, loss=0.09692, avg_loss=0.09518, mel_loss=0.04422, linear_loss=0.05271]
[2020-05-11 19:21:51.089]  Step 143373  [3.225 sec/step, loss=0.09487, avg_loss=0.09510, mel_loss=0.04322, linear_loss=0.05165]
[2020-05-11 19:21:52.177]  Step 143374  [3.214 sec/step, loss=0.08809, avg_loss=0.09503, mel_loss=0.03945, linear_loss=0.04864]
[2020-05-11 19:21:52.818]  Generated 32 batches of size 32 in 1.724 sec
[2020-05-11 19:21:55.501]  Step 143375  [3.210 sec/step, loss=0.10098, avg_loss=0.09501, mel_loss=0.04667, linear_loss=0.05431]
[2020-05-11 19:21:59.672]  Step 143376  [3.202 sec/step, loss=0.10166, avg_loss=0.09500, mel_loss=0.04721, linear_loss=0.05445]
[2020-05-11 19:22:02.862]  Step 143377  [3.221 sec/step, loss=0.10055, avg_loss=0.09509, mel_loss=0.04654, linear_loss=0.05402]
[2020-05-11 19:22:04.513]  Step 143378  [3.226 sec/step, loss=0.09421, avg_loss=0.09513, mel_loss=0.04283, linear_loss=0.05138]
[2020-05-11 19:22:10.047]  Step 143379  [3.241 sec/step, loss=0.10321, avg_loss=0.09515, mel_loss=0.04845, linear_loss=0.05476]
[2020-05-11 19:22:11.169]  Step 143380  [3.221 sec/step, loss=0.08939, avg_loss=0.09504, mel_loss=0.03942, linear_loss=0.04997]
[2020-05-11 19:22:15.412]  Step 143381  [3.195 sec/step, loss=0.10028, avg_loss=0.09500, mel_loss=0.04585, linear_loss=0.05442]
[2020-05-11 19:22:19.962]  Step 143382  [3.216 sec/step, loss=0.10073, avg_loss=0.09503, mel_loss=0.04610, linear_loss=0.05463]
[2020-05-11 19:22:25.562]  Step 143383  [3.263 sec/step, loss=0.10398, avg_loss=0.09524, mel_loss=0.04792, linear_loss=0.05606]
[2020-05-11 19:22:29.157]  Step 143384  [3.162 sec/step, loss=0.09717, avg_loss=0.09537, mel_loss=0.04422, linear_loss=0.05295]
[2020-05-11 19:22:31.842]  Step 143385  [3.183 sec/step, loss=0.09482, avg_loss=0.09555, mel_loss=0.04318, linear_loss=0.05164]
[2020-05-11 19:22:32.766]  Step 143386  [3.176 sec/step, loss=0.08706, avg_loss=0.09547, mel_loss=0.03843, linear_loss=0.04863]
[2020-05-11 19:22:34.780]  Step 143387  [3.187 sec/step, loss=0.09413, avg_loss=0.09555, mel_loss=0.04247, linear_loss=0.05166]
[2020-05-11 19:22:36.000]  Step 143388  [3.173 sec/step, loss=0.08963, avg_loss=0.09546, mel_loss=0.03988, linear_loss=0.04975]
[2020-05-11 19:22:38.679]  Step 143389  [3.166 sec/step, loss=0.09728, avg_loss=0.09542, mel_loss=0.04426, linear_loss=0.05302]
[2020-05-11 19:22:42.940]  Step 143390  [3.194 sec/step, loss=0.10220, avg_loss=0.09552, mel_loss=0.04726, linear_loss=0.05494]
[2020-05-11 19:22:48.112]  Step 143391  [3.234 sec/step, loss=0.10169, avg_loss=0.09563, mel_loss=0.04770, linear_loss=0.05400]
[2020-05-11 19:22:57.013]  Step 143392  [3.318 sec/step, loss=0.10195, avg_loss=0.09589, mel_loss=0.04856, linear_loss=0.05339]
[2020-05-11 19:23:02.542]  Step 143393  [3.327 sec/step, loss=0.10232, avg_loss=0.09588, mel_loss=0.04807, linear_loss=0.05425]
[2020-05-11 19:23:03.301]  Step 143394  [3.324 sec/step, loss=0.07961, avg_loss=0.09579, mel_loss=0.03680, linear_loss=0.04281]
[2020-05-11 19:23:04.110]  Step 143395  [3.278 sec/step, loss=0.08492, avg_loss=0.09561, mel_loss=0.03754, linear_loss=0.04738]
[2020-05-11 19:23:07.127]  Step 143396  [3.278 sec/step, loss=0.10136, avg_loss=0.09562, mel_loss=0.04649, linear_loss=0.05487]
[2020-05-11 19:23:10.006]  Step 143397  [3.291 sec/step, loss=0.10029, avg_loss=0.09568, mel_loss=0.04636, linear_loss=0.05393]
[2020-05-11 19:23:12.022]  Step 143398  [3.303 sec/step, loss=0.09833, avg_loss=0.09580, mel_loss=0.04504, linear_loss=0.05329]
[2020-05-11 19:23:19.072]  Step 143399  [3.234 sec/step, loss=0.10369, avg_loss=0.09601, mel_loss=0.04923, linear_loss=0.05446]
[2020-05-11 19:23:23.693]  Step 143400  [3.258 sec/step, loss=0.10264, avg_loss=0.09607, mel_loss=0.04771, linear_loss=0.05493]
[2020-05-11 19:23:23.693]  Writing summary at step: 143400
[2020-05-11 19:23:25.423]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143400
[2020-05-11 19:23:26.731]  Saving audio and alignment...
[2020-05-11 19:23:28.886]  Input: 앞서 우리가~_________________
[2020-05-11 19:23:29.662]  Step 143401  [3.236 sec/step, loss=0.08038, avg_loss=0.09586, mel_loss=0.03632, linear_loss=0.04406]
[2020-05-11 19:23:31.427]  Step 143402  [3.216 sec/step, loss=0.09440, avg_loss=0.09579, mel_loss=0.04247, linear_loss=0.05193]
[2020-05-11 19:23:33.890]  Step 143403  [3.227 sec/step, loss=0.09598, avg_loss=0.09584, mel_loss=0.04362, linear_loss=0.05236]
[2020-05-11 19:23:35.542]  Generated 32 batches of size 32 in 1.646 sec
[2020-05-11 19:23:47.389]  Step 143404  [3.349 sec/step, loss=0.08668, avg_loss=0.09580, mel_loss=0.04194, linear_loss=0.04474]
[2020-05-11 19:23:48.848]  Step 143405  [3.335 sec/step, loss=0.09359, avg_loss=0.09576, mel_loss=0.04251, linear_loss=0.05108]
[2020-05-11 19:23:52.978]  Step 143406  [3.340 sec/step, loss=0.10188, avg_loss=0.09576, mel_loss=0.04747, linear_loss=0.05441]
[2020-05-11 19:23:54.319]  Step 143407  [3.310 sec/step, loss=0.09106, avg_loss=0.09567, mel_loss=0.04076, linear_loss=0.05030]
[2020-05-11 19:23:57.701]  Step 143408  [3.325 sec/step, loss=0.10163, avg_loss=0.09572, mel_loss=0.04668, linear_loss=0.05495]
[2020-05-11 19:23:58.724]  Step 143409  [3.310 sec/step, loss=0.08729, avg_loss=0.09562, mel_loss=0.03908, linear_loss=0.04822]
[2020-05-11 19:24:02.204]  Step 143410  [3.311 sec/step, loss=0.09993, avg_loss=0.09557, mel_loss=0.04648, linear_loss=0.05345]
[2020-05-11 19:24:03.818]  Step 143411  [3.318 sec/step, loss=0.09285, avg_loss=0.09569, mel_loss=0.04215, linear_loss=0.05070]
[2020-05-11 19:24:10.510]  Step 143412  [3.310 sec/step, loss=0.10328, avg_loss=0.09569, mel_loss=0.04878, linear_loss=0.05449]
[2020-05-11 19:24:11.069]  Step 143413  [3.298 sec/step, loss=0.07690, avg_loss=0.09552, mel_loss=0.03505, linear_loss=0.04185]
[2020-05-11 19:24:12.363]  Step 143414  [3.301 sec/step, loss=0.09147, avg_loss=0.09555, mel_loss=0.04091, linear_loss=0.05057]
[2020-05-11 19:24:26.693]  Step 143415  [3.420 sec/step, loss=0.07702, avg_loss=0.09534, mel_loss=0.03725, linear_loss=0.03977]
[2020-05-11 19:24:28.674]  Step 143416  [3.375 sec/step, loss=0.09411, avg_loss=0.09526, mel_loss=0.04266, linear_loss=0.05145]
[2020-05-11 19:24:30.756]  Step 143417  [3.306 sec/step, loss=0.09788, avg_loss=0.09522, mel_loss=0.04427, linear_loss=0.05361]
[2020-05-11 19:24:31.732]  Step 143418  [3.295 sec/step, loss=0.08879, avg_loss=0.09515, mel_loss=0.04000, linear_loss=0.04878]
[2020-05-11 19:24:33.126]  Step 143419  [3.293 sec/step, loss=0.09041, avg_loss=0.09512, mel_loss=0.04068, linear_loss=0.04972]
[2020-05-11 19:24:35.615]  Step 143420  [3.261 sec/step, loss=0.09671, avg_loss=0.09504, mel_loss=0.04401, linear_loss=0.05270]
[2020-05-11 19:24:43.817]  Step 143421  [3.297 sec/step, loss=0.10067, avg_loss=0.09503, mel_loss=0.04776, linear_loss=0.05291]
[2020-05-11 19:24:45.429]  Step 143422  [3.276 sec/step, loss=0.09387, avg_loss=0.09495, mel_loss=0.04222, linear_loss=0.05165]
[2020-05-11 19:24:46.492]  Step 143423  [3.279 sec/step, loss=0.09028, avg_loss=0.09504, mel_loss=0.04014, linear_loss=0.05014]
[2020-05-11 19:24:49.353]  Step 143424  [3.225 sec/step, loss=0.10127, avg_loss=0.09504, mel_loss=0.04655, linear_loss=0.05472]
[2020-05-11 19:24:51.676]  Step 143425  [3.239 sec/step, loss=0.09980, avg_loss=0.09520, mel_loss=0.04559, linear_loss=0.05421]
[2020-05-11 19:24:52.482]  Step 143426  [3.225 sec/step, loss=0.08446, avg_loss=0.09507, mel_loss=0.03738, linear_loss=0.04707]
[2020-05-11 19:24:56.926]  Step 143427  [3.229 sec/step, loss=0.10345, avg_loss=0.09508, mel_loss=0.04811, linear_loss=0.05534]
[2020-05-11 19:25:01.194]  Step 143428  [3.261 sec/step, loss=0.10163, avg_loss=0.09525, mel_loss=0.04720, linear_loss=0.05442]
[2020-05-11 19:25:04.330]  Step 143429  [3.269 sec/step, loss=0.10155, avg_loss=0.09531, mel_loss=0.04709, linear_loss=0.05445]
[2020-05-11 19:25:06.063]  Step 143430  [3.253 sec/step, loss=0.09570, avg_loss=0.09525, mel_loss=0.04326, linear_loss=0.05244]
[2020-05-11 19:25:13.161]  Step 143431  [3.307 sec/step, loss=0.10309, avg_loss=0.09532, mel_loss=0.04914, linear_loss=0.05395]
[2020-05-11 19:25:15.879]  Step 143432  [3.277 sec/step, loss=0.09986, avg_loss=0.09530, mel_loss=0.04586, linear_loss=0.05400]
[2020-05-11 19:25:19.014]  Step 143433  [3.289 sec/step, loss=0.10090, avg_loss=0.09534, mel_loss=0.04648, linear_loss=0.05443]
[2020-05-11 19:25:19.803]  Step 143434  [3.278 sec/step, loss=0.07993, avg_loss=0.09517, mel_loss=0.03568, linear_loss=0.04425]
[2020-05-11 19:25:23.581]  Step 143435  [3.280 sec/step, loss=0.10107, avg_loss=0.09520, mel_loss=0.04662, linear_loss=0.05445]
[2020-05-11 19:25:25.319]  Generated 32 batches of size 32 in 1.732 sec
[2020-05-11 19:25:25.501]  Step 143436  [3.275 sec/step, loss=0.09537, avg_loss=0.09518, mel_loss=0.04298, linear_loss=0.05239]
[2020-05-11 19:25:30.393]  Step 143437  [3.282 sec/step, loss=0.10168, avg_loss=0.09517, mel_loss=0.04712, linear_loss=0.05456]
[2020-05-11 19:25:31.602]  Step 143438  [3.267 sec/step, loss=0.09178, avg_loss=0.09511, mel_loss=0.04121, linear_loss=0.05056]
[2020-05-11 19:25:32.585]  Step 143439  [3.202 sec/step, loss=0.08793, avg_loss=0.09496, mel_loss=0.03889, linear_loss=0.04904]
[2020-05-11 19:25:36.004]  Step 143440  [3.206 sec/step, loss=0.09921, avg_loss=0.09493, mel_loss=0.04589, linear_loss=0.05332]
[2020-05-11 19:25:39.623]  Step 143441  [3.215 sec/step, loss=0.10243, avg_loss=0.09498, mel_loss=0.04752, linear_loss=0.05490]
[2020-05-11 19:25:45.114]  Step 143442  [3.255 sec/step, loss=0.10521, avg_loss=0.09511, mel_loss=0.04940, linear_loss=0.05581]
[2020-05-11 19:25:51.205]  Step 143443  [3.248 sec/step, loss=0.10287, avg_loss=0.09510, mel_loss=0.04873, linear_loss=0.05415]
[2020-05-11 19:25:53.388]  Step 143444  [3.257 sec/step, loss=0.09834, avg_loss=0.09519, mel_loss=0.04500, linear_loss=0.05335]
[2020-05-11 19:26:00.840]  Step 143445  [3.318 sec/step, loss=0.10292, avg_loss=0.09530, mel_loss=0.04867, linear_loss=0.05425]
[2020-05-11 19:26:04.351]  Step 143446  [3.337 sec/step, loss=0.09882, avg_loss=0.09534, mel_loss=0.04544, linear_loss=0.05337]
[2020-05-11 19:26:05.692]  Step 143447  [3.342 sec/step, loss=0.09174, avg_loss=0.09546, mel_loss=0.04124, linear_loss=0.05050]
[2020-05-11 19:26:07.337]  Step 143448  [3.353 sec/step, loss=0.09369, avg_loss=0.09566, mel_loss=0.04262, linear_loss=0.05107]
[2020-05-11 19:26:08.639]  Step 143449  [3.351 sec/step, loss=0.09170, avg_loss=0.09565, mel_loss=0.04129, linear_loss=0.05040]
[2020-05-11 19:26:13.840]  Step 143450  [3.391 sec/step, loss=0.10156, avg_loss=0.09577, mel_loss=0.04757, linear_loss=0.05399]
[2020-05-11 19:26:13.840]  Writing summary at step: 143450
[2020-05-11 19:26:16.964]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143450
[2020-05-11 19:26:18.243]  Saving audio and alignment...
[2020-05-11 19:26:24.192]  Input: 뉴스 리딩을 할 때 우리가 지켜야 할 정말 많은 것들이 있겠지만~_____
[2020-05-11 19:26:26.089]  Step 143451  [3.396 sec/step, loss=0.09530, avg_loss=0.09581, mel_loss=0.04295, linear_loss=0.05236]
[2020-05-11 19:26:40.332]  Step 143452  [3.526 sec/step, loss=0.08167, avg_loss=0.09572, mel_loss=0.03987, linear_loss=0.04179]
[2020-05-11 19:26:41.095]  Step 143453  [3.486 sec/step, loss=0.07668, avg_loss=0.09547, mel_loss=0.03510, linear_loss=0.04158]
[2020-05-11 19:26:42.563]  Step 143454  [3.441 sec/step, loss=0.09133, avg_loss=0.09534, mel_loss=0.04101, linear_loss=0.05032]
[2020-05-11 19:26:43.324]  Step 143455  [3.439 sec/step, loss=0.08626, avg_loss=0.09534, mel_loss=0.03859, linear_loss=0.04767]
[2020-05-11 19:26:44.203]  Step 143456  [3.429 sec/step, loss=0.08670, avg_loss=0.09526, mel_loss=0.03861, linear_loss=0.04808]
[2020-05-11 19:26:50.872]  Step 143457  [3.489 sec/step, loss=0.10263, avg_loss=0.09546, mel_loss=0.04835, linear_loss=0.05428]
[2020-05-11 19:26:54.680]  Step 143458  [3.520 sec/step, loss=0.10151, avg_loss=0.09560, mel_loss=0.04688, linear_loss=0.05463]
[2020-05-11 19:26:57.201]  Step 143459  [3.401 sec/step, loss=0.09449, avg_loss=0.09573, mel_loss=0.04308, linear_loss=0.05141]
[2020-05-11 19:26:57.846]  Step 143460  [3.402 sec/step, loss=0.08349, avg_loss=0.09580, mel_loss=0.03721, linear_loss=0.04628]
[2020-05-11 19:26:59.883]  Step 143461  [3.333 sec/step, loss=0.09604, avg_loss=0.09574, mel_loss=0.04364, linear_loss=0.05240]
[2020-05-11 19:27:08.748]  Step 143462  [3.345 sec/step, loss=0.10157, avg_loss=0.09572, mel_loss=0.04883, linear_loss=0.05273]
[2020-05-11 19:27:10.515]  Step 143463  [3.339 sec/step, loss=0.09343, avg_loss=0.09564, mel_loss=0.04208, linear_loss=0.05136]
[2020-05-11 19:27:15.227]  Step 143464  [3.366 sec/step, loss=0.10140, avg_loss=0.09568, mel_loss=0.04735, linear_loss=0.05405]
[2020-05-11 19:27:16.415]  Step 143465  [3.312 sec/step, loss=0.08938, avg_loss=0.09554, mel_loss=0.04010, linear_loss=0.04928]
[2020-05-11 19:27:17.568]  Step 143466  [3.297 sec/step, loss=0.09138, avg_loss=0.09547, mel_loss=0.04068, linear_loss=0.05069]
[2020-05-11 19:27:18.182]  Generated 32 batches of size 32 in 1.762 sec
[2020-05-11 19:27:19.180]  Step 143467  [3.267 sec/step, loss=0.09579, avg_loss=0.09538, mel_loss=0.04314, linear_loss=0.05265]
[2020-05-11 19:27:20.159]  Step 143468  [3.237 sec/step, loss=0.08803, avg_loss=0.09523, mel_loss=0.03934, linear_loss=0.04868]
[2020-05-11 19:27:24.547]  Step 143469  [3.266 sec/step, loss=0.10054, avg_loss=0.09531, mel_loss=0.04677, linear_loss=0.05378]
[2020-05-11 19:27:30.124]  Step 143470  [3.302 sec/step, loss=0.10449, avg_loss=0.09540, mel_loss=0.04919, linear_loss=0.05530]
[2020-05-11 19:27:33.506]  Step 143471  [3.308 sec/step, loss=0.10067, avg_loss=0.09542, mel_loss=0.04631, linear_loss=0.05435]
[2020-05-11 19:27:36.355]  Step 143472  [3.314 sec/step, loss=0.09607, avg_loss=0.09541, mel_loss=0.04389, linear_loss=0.05218]
[2020-05-11 19:27:38.935]  Step 143473  [3.323 sec/step, loss=0.09759, avg_loss=0.09544, mel_loss=0.04446, linear_loss=0.05313]
[2020-05-11 19:27:41.114]  Step 143474  [3.334 sec/step, loss=0.09652, avg_loss=0.09552, mel_loss=0.04410, linear_loss=0.05242]
[2020-05-11 19:27:43.530]  Step 143475  [3.325 sec/step, loss=0.09531, avg_loss=0.09546, mel_loss=0.04307, linear_loss=0.05224]
[2020-05-11 19:27:45.479]  Step 143476  [3.302 sec/step, loss=0.09554, avg_loss=0.09540, mel_loss=0.04311, linear_loss=0.05243]
[2020-05-11 19:27:46.601]  Step 143477  [3.282 sec/step, loss=0.08502, avg_loss=0.09525, mel_loss=0.03774, linear_loss=0.04728]
[2020-05-11 19:27:50.752]  Step 143478  [3.307 sec/step, loss=0.10271, avg_loss=0.09533, mel_loss=0.04744, linear_loss=0.05527]
[2020-05-11 19:27:53.956]  Step 143479  [3.283 sec/step, loss=0.10076, avg_loss=0.09531, mel_loss=0.04664, linear_loss=0.05412]
[2020-05-11 19:27:55.178]  Step 143480  [3.284 sec/step, loss=0.08929, avg_loss=0.09531, mel_loss=0.04010, linear_loss=0.04919]
[2020-05-11 19:27:59.359]  Step 143481  [3.284 sec/step, loss=0.10232, avg_loss=0.09533, mel_loss=0.04787, linear_loss=0.05446]
[2020-05-11 19:28:02.166]  Step 143482  [3.266 sec/step, loss=0.09839, avg_loss=0.09530, mel_loss=0.04527, linear_loss=0.05312]
[2020-05-11 19:28:05.619]  Step 143483  [3.245 sec/step, loss=0.10167, avg_loss=0.09528, mel_loss=0.04699, linear_loss=0.05468]
[2020-05-11 19:28:08.433]  Step 143484  [3.237 sec/step, loss=0.10223, avg_loss=0.09533, mel_loss=0.04702, linear_loss=0.05521]
[2020-05-11 19:28:10.667]  Step 143485  [3.233 sec/step, loss=0.09457, avg_loss=0.09533, mel_loss=0.04319, linear_loss=0.05138]
[2020-05-11 19:28:12.652]  Step 143486  [3.243 sec/step, loss=0.09724, avg_loss=0.09543, mel_loss=0.04394, linear_loss=0.05330]
[2020-05-11 19:28:16.076]  Step 143487  [3.257 sec/step, loss=0.09838, avg_loss=0.09547, mel_loss=0.04541, linear_loss=0.05297]
[2020-05-11 19:28:17.748]  Step 143488  [3.262 sec/step, loss=0.09231, avg_loss=0.09550, mel_loss=0.04185, linear_loss=0.05046]
[2020-05-11 19:28:21.469]  Step 143489  [3.272 sec/step, loss=0.10247, avg_loss=0.09555, mel_loss=0.04727, linear_loss=0.05520]
[2020-05-11 19:28:26.011]  Step 143490  [3.275 sec/step, loss=0.10373, avg_loss=0.09557, mel_loss=0.04810, linear_loss=0.05563]
[2020-05-11 19:28:27.023]  Step 143491  [3.233 sec/step, loss=0.08893, avg_loss=0.09544, mel_loss=0.03968, linear_loss=0.04925]
[2020-05-11 19:28:32.366]  Step 143492  [3.198 sec/step, loss=0.09893, avg_loss=0.09541, mel_loss=0.04632, linear_loss=0.05261]
[2020-05-11 19:28:39.888]  Step 143493  [3.218 sec/step, loss=0.10443, avg_loss=0.09543, mel_loss=0.04971, linear_loss=0.05472]
[2020-05-11 19:28:54.219]  Step 143494  [3.353 sec/step, loss=0.07971, avg_loss=0.09543, mel_loss=0.03880, linear_loss=0.04092]
[2020-05-11 19:28:55.025]  Step 143495  [3.353 sec/step, loss=0.08400, avg_loss=0.09542, mel_loss=0.03747, linear_loss=0.04653]
[2020-05-11 19:28:56.746]  Step 143496  [3.340 sec/step, loss=0.09589, avg_loss=0.09537, mel_loss=0.04293, linear_loss=0.05296]
[2020-05-11 19:28:58.174]  Step 143497  [3.326 sec/step, loss=0.09200, avg_loss=0.09528, mel_loss=0.04174, linear_loss=0.05026]
[2020-05-11 19:28:59.836]  Generated 32 batches of size 32 in 1.656 sec
[2020-05-11 19:29:04.596]  Step 143498  [3.370 sec/step, loss=0.10239, avg_loss=0.09533, mel_loss=0.04870, linear_loss=0.05369]
[2020-05-11 19:29:05.156]  Step 143499  [3.305 sec/step, loss=0.07560, avg_loss=0.09504, mel_loss=0.03417, linear_loss=0.04143]
[2020-05-11 19:29:10.782]  Step 143500  [3.315 sec/step, loss=0.10099, avg_loss=0.09503, mel_loss=0.04714, linear_loss=0.05385]
[2020-05-11 19:29:10.782]  Writing summary at step: 143500
[2020-05-11 19:29:11.574]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143500
[2020-05-11 19:29:12.844]  Saving audio and alignment...
[2020-05-11 19:29:17.140]  Input: 수많은  상처를 안고 살아가는 거리에 여자지만~______
[2020-05-11 19:29:25.886]  Step 143501  [3.395 sec/step, loss=0.10235, avg_loss=0.09525, mel_loss=0.04854, linear_loss=0.05382]
[2020-05-11 19:29:27.668]  Step 143502  [3.395 sec/step, loss=0.09528, avg_loss=0.09526, mel_loss=0.04291, linear_loss=0.05237]
[2020-05-11 19:29:28.658]  Step 143503  [3.380 sec/step, loss=0.08646, avg_loss=0.09516, mel_loss=0.03843, linear_loss=0.04802]
[2020-05-11 19:29:30.036]  Step 143504  [3.259 sec/step, loss=0.09174, avg_loss=0.09521, mel_loss=0.04107, linear_loss=0.05067]
[2020-05-11 19:29:32.726]  Step 143505  [3.271 sec/step, loss=0.09868, avg_loss=0.09526, mel_loss=0.04502, linear_loss=0.05365]
[2020-05-11 19:29:33.733]  Step 143506  [3.240 sec/step, loss=0.08618, avg_loss=0.09511, mel_loss=0.03856, linear_loss=0.04763]
[2020-05-11 19:29:37.137]  Step 143507  [3.261 sec/step, loss=0.10056, avg_loss=0.09520, mel_loss=0.04660, linear_loss=0.05396]
[2020-05-11 19:29:39.457]  Step 143508  [3.250 sec/step, loss=0.09748, avg_loss=0.09516, mel_loss=0.04443, linear_loss=0.05305]
[2020-05-11 19:29:40.801]  Step 143509  [3.253 sec/step, loss=0.09055, avg_loss=0.09519, mel_loss=0.04076, linear_loss=0.04979]
[2020-05-11 19:29:47.389]  Step 143510  [3.285 sec/step, loss=0.10183, avg_loss=0.09521, mel_loss=0.04802, linear_loss=0.05381]
[2020-05-11 19:29:48.223]  Step 143511  [3.277 sec/step, loss=0.08032, avg_loss=0.09509, mel_loss=0.03606, linear_loss=0.04426]
[2020-05-11 19:29:50.379]  Step 143512  [3.231 sec/step, loss=0.09789, avg_loss=0.09503, mel_loss=0.04474, linear_loss=0.05314]
[2020-05-11 19:29:51.841]  Step 143513  [3.240 sec/step, loss=0.09027, avg_loss=0.09517, mel_loss=0.04075, linear_loss=0.04951]
[2020-05-11 19:30:00.398]  Step 143514  [3.313 sec/step, loss=0.09877, avg_loss=0.09524, mel_loss=0.04719, linear_loss=0.05157]
[2020-05-11 19:30:02.199]  Step 143515  [3.188 sec/step, loss=0.09510, avg_loss=0.09542, mel_loss=0.04289, linear_loss=0.05221]
[2020-05-11 19:30:03.424]  Step 143516  [3.180 sec/step, loss=0.08896, avg_loss=0.09537, mel_loss=0.03964, linear_loss=0.04933]
[2020-05-11 19:30:04.981]  Step 143517  [3.175 sec/step, loss=0.09247, avg_loss=0.09531, mel_loss=0.04170, linear_loss=0.05077]
[2020-05-11 19:30:06.633]  Step 143518  [3.182 sec/step, loss=0.09490, avg_loss=0.09537, mel_loss=0.04286, linear_loss=0.05204]
[2020-05-11 19:30:10.828]  Step 143519  [3.210 sec/step, loss=0.10007, avg_loss=0.09547, mel_loss=0.04635, linear_loss=0.05372]
[2020-05-11 19:30:11.608]  Step 143520  [3.193 sec/step, loss=0.08602, avg_loss=0.09536, mel_loss=0.03817, linear_loss=0.04785]
[2020-05-11 19:30:12.513]  Step 143521  [3.120 sec/step, loss=0.08484, avg_loss=0.09521, mel_loss=0.03788, linear_loss=0.04696]
[2020-05-11 19:30:14.444]  Step 143522  [3.123 sec/step, loss=0.09555, avg_loss=0.09522, mel_loss=0.04321, linear_loss=0.05234]
[2020-05-11 19:30:17.969]  Step 143523  [3.147 sec/step, loss=0.10092, avg_loss=0.09533, mel_loss=0.04643, linear_loss=0.05449]
[2020-05-11 19:30:20.405]  Step 143524  [3.143 sec/step, loss=0.09994, avg_loss=0.09532, mel_loss=0.04577, linear_loss=0.05417]
[2020-05-11 19:30:23.763]  Step 143525  [3.154 sec/step, loss=0.10250, avg_loss=0.09534, mel_loss=0.04717, linear_loss=0.05533]
[2020-05-11 19:30:24.323]  Step 143526  [3.151 sec/step, loss=0.07505, avg_loss=0.09525, mel_loss=0.03397, linear_loss=0.04108]
[2020-05-11 19:30:29.433]  Step 143527  [3.158 sec/step, loss=0.10421, avg_loss=0.09526, mel_loss=0.04869, linear_loss=0.05552]
[2020-05-11 19:30:31.107]  Generated 32 batches of size 32 in 1.669 sec
[2020-05-11 19:30:35.039]  Step 143528  [3.171 sec/step, loss=0.10362, avg_loss=0.09528, mel_loss=0.04875, linear_loss=0.05487]
[2020-05-11 19:30:37.047]  Step 143529  [3.160 sec/step, loss=0.09672, avg_loss=0.09523, mel_loss=0.04405, linear_loss=0.05267]
[2020-05-11 19:30:49.340]  Step 143530  [3.265 sec/step, loss=0.09002, avg_loss=0.09517, mel_loss=0.04352, linear_loss=0.04650]
[2020-05-11 19:30:56.922]  Step 143531  [3.270 sec/step, loss=0.10421, avg_loss=0.09518, mel_loss=0.04943, linear_loss=0.05477]
[2020-05-11 19:31:00.637]  Step 143532  [3.280 sec/step, loss=0.10314, avg_loss=0.09521, mel_loss=0.04800, linear_loss=0.05514]
[2020-05-11 19:31:03.665]  Step 143533  [3.279 sec/step, loss=0.09945, avg_loss=0.09520, mel_loss=0.04550, linear_loss=0.05395]
[2020-05-11 19:31:08.186]  Step 143534  [3.316 sec/step, loss=0.10116, avg_loss=0.09541, mel_loss=0.04709, linear_loss=0.05407]
[2020-05-11 19:31:09.300]  Step 143535  [3.290 sec/step, loss=0.08998, avg_loss=0.09530, mel_loss=0.04015, linear_loss=0.04984]
[2020-05-11 19:31:12.160]  Step 143536  [3.299 sec/step, loss=0.10154, avg_loss=0.09536, mel_loss=0.04683, linear_loss=0.05471]
[2020-05-11 19:31:14.892]  Step 143537  [3.278 sec/step, loss=0.09938, avg_loss=0.09534, mel_loss=0.04542, linear_loss=0.05396]
[2020-05-11 19:31:17.237]  Step 143538  [3.289 sec/step, loss=0.09662, avg_loss=0.09539, mel_loss=0.04424, linear_loss=0.05237]
[2020-05-11 19:31:21.630]  Step 143539  [3.323 sec/step, loss=0.10333, avg_loss=0.09554, mel_loss=0.04806, linear_loss=0.05527]
[2020-05-11 19:31:24.535]  Step 143540  [3.318 sec/step, loss=0.10030, avg_loss=0.09555, mel_loss=0.04599, linear_loss=0.05431]
[2020-05-11 19:31:27.021]  Step 143541  [3.307 sec/step, loss=0.09503, avg_loss=0.09548, mel_loss=0.04305, linear_loss=0.05197]
[2020-05-11 19:31:30.151]  Step 143542  [3.283 sec/step, loss=0.10087, avg_loss=0.09544, mel_loss=0.04600, linear_loss=0.05486]
[2020-05-11 19:31:31.901]  Step 143543  [3.240 sec/step, loss=0.09460, avg_loss=0.09535, mel_loss=0.04273, linear_loss=0.05187]
[2020-05-11 19:31:40.546]  Step 143544  [3.304 sec/step, loss=0.10154, avg_loss=0.09539, mel_loss=0.04817, linear_loss=0.05337]
[2020-05-11 19:31:44.744]  Step 143545  [3.272 sec/step, loss=0.09951, avg_loss=0.09535, mel_loss=0.04599, linear_loss=0.05352]
[2020-05-11 19:31:46.329]  Step 143546  [3.252 sec/step, loss=0.09327, avg_loss=0.09530, mel_loss=0.04205, linear_loss=0.05121]
[2020-05-11 19:31:52.029]  Step 143547  [3.296 sec/step, loss=0.10423, avg_loss=0.09542, mel_loss=0.04912, linear_loss=0.05510]
[2020-05-11 19:31:53.034]  Step 143548  [3.290 sec/step, loss=0.08649, avg_loss=0.09535, mel_loss=0.03838, linear_loss=0.04811]
[2020-05-11 19:31:54.645]  Step 143549  [3.293 sec/step, loss=0.09512, avg_loss=0.09538, mel_loss=0.04271, linear_loss=0.05242]
[2020-05-11 19:32:00.012]  Step 143550  [3.294 sec/step, loss=0.10195, avg_loss=0.09539, mel_loss=0.04777, linear_loss=0.05418]
[2020-05-11 19:32:00.013]  Writing summary at step: 143550
[2020-05-11 19:32:03.662]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143550
[2020-05-11 19:32:04.998]  Saving audio and alignment...
[2020-05-11 19:32:06.448]  Input: 주황~_____________________________
[2020-05-11 19:32:08.780]  Step 143551  [3.299 sec/step, loss=0.09602, avg_loss=0.09539, mel_loss=0.04364, linear_loss=0.05238]
[2020-05-11 19:32:09.773]  Step 143552  [3.166 sec/step, loss=0.08964, avg_loss=0.09547, mel_loss=0.03971, linear_loss=0.04994]
[2020-05-11 19:32:10.601]  Step 143553  [3.167 sec/step, loss=0.08183, avg_loss=0.09553, mel_loss=0.03636, linear_loss=0.04548]
[2020-05-11 19:32:11.997]  Step 143554  [3.166 sec/step, loss=0.09027, avg_loss=0.09551, mel_loss=0.04062, linear_loss=0.04965]
[2020-05-11 19:32:12.804]  Step 143555  [3.167 sec/step, loss=0.07846, avg_loss=0.09544, mel_loss=0.03496, linear_loss=0.04350]
[2020-05-11 19:32:19.304]  Step 143556  [3.223 sec/step, loss=0.10425, avg_loss=0.09561, mel_loss=0.04936, linear_loss=0.05488]
[2020-05-11 19:32:21.230]  Step 143557  [3.175 sec/step, loss=0.09485, avg_loss=0.09553, mel_loss=0.04259, linear_loss=0.05226]
[2020-05-11 19:32:22.662]  Step 143558  [3.152 sec/step, loss=0.08771, avg_loss=0.09540, mel_loss=0.03930, linear_loss=0.04841]
[2020-05-11 19:32:22.979]  Generated 32 batches of size 32 in 1.744 sec
[2020-05-11 19:32:25.199]  Step 143559  [3.152 sec/step, loss=0.09760, avg_loss=0.09543, mel_loss=0.04434, linear_loss=0.05326]
[2020-05-11 19:32:28.704]  Step 143560  [3.180 sec/step, loss=0.09932, avg_loss=0.09559, mel_loss=0.04558, linear_loss=0.05374]
[2020-05-11 19:32:33.204]  Step 143561  [3.205 sec/step, loss=0.10268, avg_loss=0.09565, mel_loss=0.04724, linear_loss=0.05544]
[2020-05-11 19:32:44.943]  Step 143562  [3.234 sec/step, loss=0.10470, avg_loss=0.09568, mel_loss=0.04997, linear_loss=0.05473]
[2020-05-11 19:32:46.879]  Step 143563  [3.235 sec/step, loss=0.08993, avg_loss=0.09565, mel_loss=0.04037, linear_loss=0.04956]
[2020-05-11 19:32:48.653]  Step 143564  [3.206 sec/step, loss=0.08656, avg_loss=0.09550, mel_loss=0.03837, linear_loss=0.04820]
[2020-05-11 19:33:03.906]  Step 143565  [3.347 sec/step, loss=0.07934, avg_loss=0.09540, mel_loss=0.03850, linear_loss=0.04084]
[2020-05-11 19:33:08.806]  Step 143566  [3.384 sec/step, loss=0.10132, avg_loss=0.09550, mel_loss=0.04700, linear_loss=0.05432]
[2020-05-11 19:33:10.807]  Step 143567  [3.388 sec/step, loss=0.09861, avg_loss=0.09553, mel_loss=0.04436, linear_loss=0.05425]
[2020-05-11 19:33:11.562]  Step 143568  [3.386 sec/step, loss=0.07848, avg_loss=0.09543, mel_loss=0.03507, linear_loss=0.04342]
[2020-05-11 19:33:15.154]  Step 143569  [3.378 sec/step, loss=0.10157, avg_loss=0.09544, mel_loss=0.04672, linear_loss=0.05486]
[2020-05-11 19:33:26.948]  Step 143570  [3.440 sec/step, loss=0.09772, avg_loss=0.09537, mel_loss=0.04736, linear_loss=0.05036]
[2020-05-11 19:33:27.964]  Step 143571  [3.416 sec/step, loss=0.08573, avg_loss=0.09523, mel_loss=0.03818, linear_loss=0.04755]
[2020-05-11 19:33:29.690]  Step 143572  [3.405 sec/step, loss=0.09500, avg_loss=0.09521, mel_loss=0.04259, linear_loss=0.05241]
[2020-05-11 19:33:30.845]  Step 143573  [3.391 sec/step, loss=0.08895, avg_loss=0.09513, mel_loss=0.03946, linear_loss=0.04949]
[2020-05-11 19:33:35.089]  Step 143574  [3.412 sec/step, loss=0.10217, avg_loss=0.09518, mel_loss=0.04725, linear_loss=0.05492]
[2020-05-11 19:33:44.052]  Step 143575  [3.477 sec/step, loss=0.10254, avg_loss=0.09526, mel_loss=0.04890, linear_loss=0.05365]
[2020-05-11 19:33:47.171]  Step 143576  [3.489 sec/step, loss=0.10114, avg_loss=0.09531, mel_loss=0.04682, linear_loss=0.05432]
[2020-05-11 19:33:54.486]  Step 143577  [3.551 sec/step, loss=0.10211, avg_loss=0.09548, mel_loss=0.04799, linear_loss=0.05412]
[2020-05-11 19:33:56.925]  Step 143578  [3.534 sec/step, loss=0.09579, avg_loss=0.09541, mel_loss=0.04344, linear_loss=0.05235]
[2020-05-11 19:34:00.346]  Step 143579  [3.536 sec/step, loss=0.09891, avg_loss=0.09540, mel_loss=0.04593, linear_loss=0.05297]
[2020-05-11 19:34:03.191]  Step 143580  [3.552 sec/step, loss=0.09818, avg_loss=0.09548, mel_loss=0.04526, linear_loss=0.05292]
[2020-05-11 19:34:04.249]  Step 143581  [3.521 sec/step, loss=0.09356, avg_loss=0.09540, mel_loss=0.04146, linear_loss=0.05210]
[2020-05-11 19:34:05.718]  Step 143582  [3.507 sec/step, loss=0.09423, avg_loss=0.09536, mel_loss=0.04238, linear_loss=0.05186]
[2020-05-11 19:34:09.706]  Step 143583  [3.513 sec/step, loss=0.10289, avg_loss=0.09537, mel_loss=0.04764, linear_loss=0.05526]
[2020-05-11 19:34:10.665]  Step 143584  [3.494 sec/step, loss=0.08627, avg_loss=0.09521, mel_loss=0.03851, linear_loss=0.04776]
[2020-05-11 19:34:11.462]  Step 143585  [3.480 sec/step, loss=0.08213, avg_loss=0.09508, mel_loss=0.03672, linear_loss=0.04541]
[2020-05-11 19:34:13.704]  Step 143586  [3.482 sec/step, loss=0.09684, avg_loss=0.09508, mel_loss=0.04435, linear_loss=0.05249]
[2020-05-11 19:34:16.407]  Step 143587  [3.475 sec/step, loss=0.09720, avg_loss=0.09507, mel_loss=0.04441, linear_loss=0.05278]
[2020-05-11 19:34:18.026]  Step 143588  [3.475 sec/step, loss=0.09697, avg_loss=0.09511, mel_loss=0.04386, linear_loss=0.05311]
[2020-05-11 19:34:22.557]  Step 143589  [3.483 sec/step, loss=0.10222, avg_loss=0.09511, mel_loss=0.04788, linear_loss=0.05434]
[2020-05-11 19:34:23.148]  Step 143590  [3.443 sec/step, loss=0.07741, avg_loss=0.09485, mel_loss=0.03570, linear_loss=0.04171]
[2020-05-11 19:34:24.398]  Generated 32 batches of size 32 in 1.837 sec
[2020-05-11 19:34:25.351]  Step 143591  [3.455 sec/step, loss=0.09828, avg_loss=0.09494, mel_loss=0.04449, linear_loss=0.05379]
[2020-05-11 19:34:32.105]  Step 143592  [3.469 sec/step, loss=0.10089, avg_loss=0.09496, mel_loss=0.04744, linear_loss=0.05345]
[2020-05-11 19:34:37.082]  Step 143593  [3.444 sec/step, loss=0.10230, avg_loss=0.09494, mel_loss=0.04774, linear_loss=0.05456]
[2020-05-11 19:34:38.469]  Step 143594  [3.314 sec/step, loss=0.09479, avg_loss=0.09509, mel_loss=0.04294, linear_loss=0.05184]
[2020-05-11 19:34:40.362]  Step 143595  [3.325 sec/step, loss=0.09561, avg_loss=0.09521, mel_loss=0.04310, linear_loss=0.05251]
[2020-05-11 19:34:45.667]  Step 143596  [3.361 sec/step, loss=0.10189, avg_loss=0.09527, mel_loss=0.04768, linear_loss=0.05421]
[2020-05-11 19:34:48.827]  Step 143597  [3.378 sec/step, loss=0.10228, avg_loss=0.09537, mel_loss=0.04709, linear_loss=0.05518]
[2020-05-11 19:34:50.125]  Step 143598  [3.327 sec/step, loss=0.09363, avg_loss=0.09528, mel_loss=0.04208, linear_loss=0.05155]
[2020-05-11 19:34:58.909]  Step 143599  [3.409 sec/step, loss=0.10221, avg_loss=0.09555, mel_loss=0.04880, linear_loss=0.05341]
[2020-05-11 19:35:05.566]  Step 143600  [3.420 sec/step, loss=0.10342, avg_loss=0.09557, mel_loss=0.04891, linear_loss=0.05451]
[2020-05-11 19:35:05.566]  Writing summary at step: 143600
[2020-05-11 19:35:07.291]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143600
[2020-05-11 19:35:08.627]  Saving audio and alignment...
[2020-05-11 19:35:26.954]  Input: 케이비에스 인간극장 하면 뭐 내레이션 하면 여러분이 떠올리는 가장 대표적인 프로그램이죠 그래서 각 방마다 한 번씩 꼭 다를 것 같아요오~_____________________________
[2020-05-11 19:35:29.125]  Step 143601  [3.354 sec/step, loss=0.09455, avg_loss=0.09550, mel_loss=0.04321, linear_loss=0.05134]
[2020-05-11 19:35:32.577]  Step 143602  [3.371 sec/step, loss=0.10080, avg_loss=0.09555, mel_loss=0.04644, linear_loss=0.05436]
[2020-05-11 19:35:35.188]  Step 143603  [3.387 sec/step, loss=0.09950, avg_loss=0.09568, mel_loss=0.04580, linear_loss=0.05369]
[2020-05-11 19:35:39.169]  Step 143604  [3.413 sec/step, loss=0.10043, avg_loss=0.09577, mel_loss=0.04643, linear_loss=0.05400]
[2020-05-11 19:35:42.862]  Step 143605  [3.423 sec/step, loss=0.10279, avg_loss=0.09581, mel_loss=0.04760, linear_loss=0.05519]
[2020-05-11 19:35:50.430]  Step 143606  [3.488 sec/step, loss=0.10282, avg_loss=0.09598, mel_loss=0.04880, linear_loss=0.05403]
[2020-05-11 19:35:53.846]  Step 143607  [3.489 sec/step, loss=0.10050, avg_loss=0.09597, mel_loss=0.04632, linear_loss=0.05418]
[2020-05-11 19:35:56.847]  Step 143608  [3.495 sec/step, loss=0.10054, avg_loss=0.09601, mel_loss=0.04621, linear_loss=0.05433]
[2020-05-11 19:35:57.685]  Step 143609  [3.490 sec/step, loss=0.08321, avg_loss=0.09593, mel_loss=0.03717, linear_loss=0.04603]
[2020-05-11 19:36:00.150]  Step 143610  [3.449 sec/step, loss=0.09738, avg_loss=0.09589, mel_loss=0.04452, linear_loss=0.05285]
[2020-05-11 19:36:04.256]  Step 143611  [3.482 sec/step, loss=0.10318, avg_loss=0.09612, mel_loss=0.04790, linear_loss=0.05528]
[2020-05-11 19:36:06.155]  Step 143612  [3.479 sec/step, loss=0.09638, avg_loss=0.09610, mel_loss=0.04351, linear_loss=0.05287]
[2020-05-11 19:36:10.692]  Step 143613  [3.510 sec/step, loss=0.10378, avg_loss=0.09624, mel_loss=0.04841, linear_loss=0.05537]
[2020-05-11 19:36:12.307]  Step 143614  [3.441 sec/step, loss=0.09264, avg_loss=0.09617, mel_loss=0.04189, linear_loss=0.05075]
[2020-05-11 19:36:15.336]  Step 143615  [3.453 sec/step, loss=0.09986, avg_loss=0.09622, mel_loss=0.04579, linear_loss=0.05407]
[2020-05-11 19:36:17.795]  Step 143616  [3.465 sec/step, loss=0.09893, avg_loss=0.09632, mel_loss=0.04507, linear_loss=0.05386]
[2020-05-11 19:36:22.920]  Step 143617  [3.501 sec/step, loss=0.10314, avg_loss=0.09643, mel_loss=0.04819, linear_loss=0.05494]
[2020-05-11 19:36:23.763]  Step 143618  [3.493 sec/step, loss=0.08352, avg_loss=0.09631, mel_loss=0.03733, linear_loss=0.04619]
[2020-05-11 19:36:25.743]  Step 143619  [3.471 sec/step, loss=0.09596, avg_loss=0.09627, mel_loss=0.04370, linear_loss=0.05225]
[2020-05-11 19:36:26.710]  Step 143620  [3.473 sec/step, loss=0.08776, avg_loss=0.09629, mel_loss=0.03928, linear_loss=0.04848]
[2020-05-11 19:36:27.539]  Generated 32 batches of size 32 in 1.790 sec
[2020-05-11 19:36:28.561]  Step 143621  [3.482 sec/step, loss=0.09475, avg_loss=0.09639, mel_loss=0.04309, linear_loss=0.05166]
[2020-05-11 19:36:34.253]  Step 143622  [3.520 sec/step, loss=0.10944, avg_loss=0.09653, mel_loss=0.05294, linear_loss=0.05650]
[2020-05-11 19:36:34.789]  Step 143623  [3.490 sec/step, loss=0.07729, avg_loss=0.09629, mel_loss=0.03549, linear_loss=0.04180]
[2020-05-11 19:36:36.199]  Step 143624  [3.479 sec/step, loss=0.09317, avg_loss=0.09623, mel_loss=0.04217, linear_loss=0.05099]
[2020-05-11 19:36:37.561]  Step 143625  [3.459 sec/step, loss=0.09237, avg_loss=0.09612, mel_loss=0.04152, linear_loss=0.05085]
[2020-05-11 19:36:38.787]  Step 143626  [3.466 sec/step, loss=0.09111, avg_loss=0.09628, mel_loss=0.04095, linear_loss=0.05016]
[2020-05-11 19:36:39.804]  Step 143627  [3.425 sec/step, loss=0.08783, avg_loss=0.09612, mel_loss=0.03950, linear_loss=0.04833]
[2020-05-11 19:36:40.911]  Step 143628  [3.380 sec/step, loss=0.08894, avg_loss=0.09597, mel_loss=0.03981, linear_loss=0.04913]
[2020-05-11 19:36:46.494]  Step 143629  [3.416 sec/step, loss=0.10527, avg_loss=0.09606, mel_loss=0.04984, linear_loss=0.05543]
[2020-05-11 19:36:51.065]  Step 143630  [3.339 sec/step, loss=0.10694, avg_loss=0.09623, mel_loss=0.05066, linear_loss=0.05628]
[2020-05-11 19:36:54.746]  Step 143631  [3.300 sec/step, loss=0.10585, avg_loss=0.09624, mel_loss=0.04955, linear_loss=0.05631]
[2020-05-11 19:36:56.168]  Step 143632  [3.277 sec/step, loss=0.09244, avg_loss=0.09614, mel_loss=0.04219, linear_loss=0.05025]
[2020-05-11 19:36:58.856]  Step 143633  [3.273 sec/step, loss=0.09866, avg_loss=0.09613, mel_loss=0.04496, linear_loss=0.05371]
[2020-05-11 19:37:01.031]  Step 143634  [3.250 sec/step, loss=0.09668, avg_loss=0.09609, mel_loss=0.04348, linear_loss=0.05320]
[2020-05-11 19:37:02.252]  Step 143635  [3.251 sec/step, loss=0.09103, avg_loss=0.09610, mel_loss=0.04025, linear_loss=0.05079]
[2020-05-11 19:37:02.817]  Step 143636  [3.228 sec/step, loss=0.07606, avg_loss=0.09584, mel_loss=0.03466, linear_loss=0.04141]
[2020-05-11 19:37:03.835]  Step 143637  [3.211 sec/step, loss=0.08839, avg_loss=0.09573, mel_loss=0.04012, linear_loss=0.04826]
[2020-05-11 19:37:10.967]  Step 143638  [3.259 sec/step, loss=0.12480, avg_loss=0.09601, mel_loss=0.06332, linear_loss=0.06148]
[2020-05-11 19:37:12.331]  Step 143639  [3.229 sec/step, loss=0.09054, avg_loss=0.09589, mel_loss=0.04090, linear_loss=0.04965]
[2020-05-11 19:37:13.836]  Step 143640  [3.215 sec/step, loss=0.08925, avg_loss=0.09577, mel_loss=0.04043, linear_loss=0.04882]
[2020-05-11 19:37:18.412]  Step 143641  [3.235 sec/step, loss=0.10372, avg_loss=0.09586, mel_loss=0.04912, linear_loss=0.05460]
[2020-05-11 19:37:30.876]  Step 143642  [3.329 sec/step, loss=0.09095, avg_loss=0.09576, mel_loss=0.04479, linear_loss=0.04616]
[2020-05-11 19:37:33.868]  Step 143643  [3.341 sec/step, loss=0.10503, avg_loss=0.09587, mel_loss=0.04868, linear_loss=0.05635]
[2020-05-11 19:37:34.618]  Step 143644  [3.262 sec/step, loss=0.08483, avg_loss=0.09570, mel_loss=0.03828, linear_loss=0.04654]
[2020-05-11 19:37:36.994]  Step 143645  [3.244 sec/step, loss=0.09763, avg_loss=0.09568, mel_loss=0.04501, linear_loss=0.05262]
[2020-05-11 19:37:39.051]  Step 143646  [3.249 sec/step, loss=0.10128, avg_loss=0.09576, mel_loss=0.04708, linear_loss=0.05420]
[2020-05-11 19:37:40.676]  Step 143647  [3.208 sec/step, loss=0.09416, avg_loss=0.09566, mel_loss=0.04321, linear_loss=0.05095]
[2020-05-11 19:37:41.558]  Step 143648  [3.207 sec/step, loss=0.08897, avg_loss=0.09568, mel_loss=0.04015, linear_loss=0.04882]
[2020-05-11 19:37:44.696]  Step 143649  [3.222 sec/step, loss=0.10867, avg_loss=0.09582, mel_loss=0.05126, linear_loss=0.05741]
[2020-05-11 19:37:48.143]  Step 143650  [3.203 sec/step, loss=0.11195, avg_loss=0.09592, mel_loss=0.05344, linear_loss=0.05851]
[2020-05-11 19:37:48.143]  Writing summary at step: 143650
[2020-05-11 19:37:51.027]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143650
[2020-05-11 19:37:52.329]  Saving audio and alignment...
[2020-05-11 19:37:54.371]  Generated 32 batches of size 32 in 1.528 sec
[2020-05-11 19:37:57.926]  Input: 읽는 속도가 일정 해서는 안 되고요 변화가 있어야 되죠~__________
[2020-05-11 19:37:58.731]  Step 143651  [3.188 sec/step, loss=0.08260, avg_loss=0.09579, mel_loss=0.03684, linear_loss=0.04576]
[2020-05-11 19:38:04.019]  Step 143652  [3.231 sec/step, loss=0.10507, avg_loss=0.09594, mel_loss=0.05042, linear_loss=0.05465]
[2020-05-11 19:38:05.680]  Step 143653  [3.239 sec/step, loss=0.09807, avg_loss=0.09610, mel_loss=0.04464, linear_loss=0.05343]
[2020-05-11 19:38:07.665]  Step 143654  [3.245 sec/step, loss=0.09938, avg_loss=0.09619, mel_loss=0.04535, linear_loss=0.05403]
[2020-05-11 19:38:09.569]  Step 143655  [3.256 sec/step, loss=0.09752, avg_loss=0.09638, mel_loss=0.04425, linear_loss=0.05328]
[2020-05-11 19:38:12.188]  Step 143656  [3.217 sec/step, loss=0.10095, avg_loss=0.09635, mel_loss=0.04700, linear_loss=0.05395]
[2020-05-11 19:38:20.204]  Step 143657  [3.278 sec/step, loss=0.10515, avg_loss=0.09645, mel_loss=0.05074, linear_loss=0.05440]
[2020-05-11 19:38:26.837]  Step 143658  [3.330 sec/step, loss=0.10658, avg_loss=0.09664, mel_loss=0.05081, linear_loss=0.05577]
[2020-05-11 19:38:27.621]  Step 143659  [3.312 sec/step, loss=0.08349, avg_loss=0.09650, mel_loss=0.03765, linear_loss=0.04585]
[2020-05-11 19:38:35.173]  Step 143660  [3.353 sec/step, loss=0.10445, avg_loss=0.09655, mel_loss=0.05007, linear_loss=0.05438]
[2020-05-11 19:38:39.283]  Step 143661  [3.349 sec/step, loss=0.10506, avg_loss=0.09658, mel_loss=0.04915, linear_loss=0.05591]
[2020-05-11 19:38:41.146]  Step 143662  [3.250 sec/step, loss=0.09586, avg_loss=0.09649, mel_loss=0.04372, linear_loss=0.05214]
[2020-05-11 19:38:42.524]  Step 143663  [3.245 sec/step, loss=0.09384, avg_loss=0.09653, mel_loss=0.04262, linear_loss=0.05122]
[2020-05-11 19:38:44.670]  Step 143664  [3.248 sec/step, loss=0.09785, avg_loss=0.09664, mel_loss=0.04482, linear_loss=0.05303]
[2020-05-11 19:38:46.912]  Step 143665  [3.118 sec/step, loss=0.09927, avg_loss=0.09684, mel_loss=0.04547, linear_loss=0.05380]
[2020-05-11 19:38:48.909]  Step 143666  [3.089 sec/step, loss=0.09763, avg_loss=0.09680, mel_loss=0.04441, linear_loss=0.05322]
[2020-05-11 19:38:51.960]  Step 143667  [3.100 sec/step, loss=0.10327, avg_loss=0.09685, mel_loss=0.04812, linear_loss=0.05515]
[2020-05-11 19:38:58.260]  Step 143668  [3.155 sec/step, loss=0.10411, avg_loss=0.09711, mel_loss=0.04986, linear_loss=0.05425]
[2020-05-11 19:39:02.568]  Step 143669  [3.162 sec/step, loss=0.10487, avg_loss=0.09714, mel_loss=0.04912, linear_loss=0.05575]
[2020-05-11 19:39:04.163]  Step 143670  [3.060 sec/step, loss=0.09767, avg_loss=0.09714, mel_loss=0.04421, linear_loss=0.05346]
[2020-05-11 19:39:18.312]  Step 143671  [3.192 sec/step, loss=0.08295, avg_loss=0.09711, mel_loss=0.04087, linear_loss=0.04208]
[2020-05-11 19:39:22.939]  Step 143672  [3.221 sec/step, loss=0.10531, avg_loss=0.09721, mel_loss=0.04946, linear_loss=0.05585]
[2020-05-11 19:39:26.207]  Step 143673  [3.242 sec/step, loss=0.10392, avg_loss=0.09736, mel_loss=0.04829, linear_loss=0.05563]
[2020-05-11 19:39:27.116]  Step 143674  [3.208 sec/step, loss=0.08570, avg_loss=0.09720, mel_loss=0.03821, linear_loss=0.04749]
[2020-05-11 19:39:28.339]  Step 143675  [3.131 sec/step, loss=0.09108, avg_loss=0.09708, mel_loss=0.04096, linear_loss=0.05012]
[2020-05-11 19:39:31.203]  Step 143676  [3.128 sec/step, loss=0.10083, avg_loss=0.09708, mel_loss=0.04681, linear_loss=0.05402]
[2020-05-11 19:39:40.046]  Step 143677  [3.144 sec/step, loss=0.10457, avg_loss=0.09711, mel_loss=0.05028, linear_loss=0.05428]
[2020-05-11 19:39:45.605]  Step 143678  [3.175 sec/step, loss=0.10345, avg_loss=0.09718, mel_loss=0.04878, linear_loss=0.05467]
[2020-05-11 19:39:48.035]  Step 143679  [3.165 sec/step, loss=0.10043, avg_loss=0.09720, mel_loss=0.04596, linear_loss=0.05448]
[2020-05-11 19:39:49.790]  Step 143680  [3.154 sec/step, loss=0.09523, avg_loss=0.09717, mel_loss=0.04265, linear_loss=0.05259]
[2020-05-11 19:39:55.059]  Step 143681  [3.196 sec/step, loss=0.10405, avg_loss=0.09727, mel_loss=0.04897, linear_loss=0.05508]
[2020-05-11 19:39:56.844]  Generated 32 batches of size 32 in 1.780 sec
[2020-05-11 19:39:58.636]  Step 143682  [3.217 sec/step, loss=0.10055, avg_loss=0.09734, mel_loss=0.04632, linear_loss=0.05423]
[2020-05-11 19:39:59.664]  Step 143683  [3.188 sec/step, loss=0.08723, avg_loss=0.09718, mel_loss=0.03878, linear_loss=0.04845]
[2020-05-11 19:40:01.191]  Step 143684  [3.193 sec/step, loss=0.09448, avg_loss=0.09726, mel_loss=0.04285, linear_loss=0.05164]
[2020-05-11 19:40:02.305]  Step 143685  [3.196 sec/step, loss=0.08985, avg_loss=0.09734, mel_loss=0.04022, linear_loss=0.04963]
[2020-05-11 19:40:05.979]  Step 143686  [3.211 sec/step, loss=0.10236, avg_loss=0.09739, mel_loss=0.04741, linear_loss=0.05495]
[2020-05-11 19:40:07.303]  Step 143687  [3.197 sec/step, loss=0.09488, avg_loss=0.09737, mel_loss=0.04309, linear_loss=0.05179]
[2020-05-11 19:40:08.058]  Step 143688  [3.188 sec/step, loss=0.08192, avg_loss=0.09722, mel_loss=0.03688, linear_loss=0.04503]
[2020-05-11 19:40:10.758]  Step 143689  [3.170 sec/step, loss=0.09931, avg_loss=0.09719, mel_loss=0.04534, linear_loss=0.05397]
[2020-05-11 19:40:11.514]  Step 143690  [3.172 sec/step, loss=0.07733, avg_loss=0.09719, mel_loss=0.03526, linear_loss=0.04207]
[2020-05-11 19:40:15.813]  Step 143691  [3.193 sec/step, loss=0.10321, avg_loss=0.09724, mel_loss=0.04824, linear_loss=0.05497]
[2020-05-11 19:40:16.612]  Step 143692  [3.133 sec/step, loss=0.08398, avg_loss=0.09707, mel_loss=0.03720, linear_loss=0.04678]
[2020-05-11 19:40:17.140]  Step 143693  [3.089 sec/step, loss=0.07804, avg_loss=0.09683, mel_loss=0.03546, linear_loss=0.04258]
[2020-05-11 19:40:19.645]  Step 143694  [3.100 sec/step, loss=0.09906, avg_loss=0.09687, mel_loss=0.04521, linear_loss=0.05385]
[2020-05-11 19:40:22.748]  Step 143695  [3.112 sec/step, loss=0.10387, avg_loss=0.09695, mel_loss=0.04812, linear_loss=0.05575]
[2020-05-11 19:40:35.819]  Step 143696  [3.190 sec/step, loss=0.08632, avg_loss=0.09680, mel_loss=0.04174, linear_loss=0.04458]
[2020-05-11 19:40:37.462]  Step 143697  [3.174 sec/step, loss=0.09494, avg_loss=0.09672, mel_loss=0.04290, linear_loss=0.05205]
[2020-05-11 19:40:43.090]  Step 143698  [3.218 sec/step, loss=0.10346, avg_loss=0.09682, mel_loss=0.04847, linear_loss=0.05500]
[2020-05-11 19:40:50.649]  Step 143699  [3.205 sec/step, loss=0.10549, avg_loss=0.09686, mel_loss=0.05038, linear_loss=0.05511]
[2020-05-11 19:40:59.457]  Step 143700  [3.227 sec/step, loss=0.10131, avg_loss=0.09683, mel_loss=0.04835, linear_loss=0.05296]
[2020-05-11 19:40:59.457]  Writing summary at step: 143700
[2020-05-11 19:41:01.323]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143700
[2020-05-11 19:41:02.643]  Saving audio and alignment...
[2020-05-11 19:41:11.695]  Input: 포 티비 게임즈가 함께하는 스타크래프트이 이천십칠 어조를 다양화 하실때~_________________________________________________________
[2020-05-11 19:41:13.641]  Step 143701  [3.225 sec/step, loss=0.09561, avg_loss=0.09685, mel_loss=0.04344, linear_loss=0.05217]
[2020-05-11 19:41:14.820]  Step 143702  [3.202 sec/step, loss=0.08878, avg_loss=0.09673, mel_loss=0.03988, linear_loss=0.04891]
[2020-05-11 19:41:19.576]  Step 143703  [3.223 sec/step, loss=0.10191, avg_loss=0.09675, mel_loss=0.04765, linear_loss=0.05426]
[2020-05-11 19:41:20.577]  Step 143704  [3.194 sec/step, loss=0.08660, avg_loss=0.09661, mel_loss=0.03847, linear_loss=0.04813]
[2020-05-11 19:41:22.970]  Step 143705  [3.181 sec/step, loss=0.09870, avg_loss=0.09657, mel_loss=0.04493, linear_loss=0.05377]
[2020-05-11 19:41:25.659]  Step 143706  [3.132 sec/step, loss=0.09922, avg_loss=0.09653, mel_loss=0.04541, linear_loss=0.05381]
[2020-05-11 19:41:26.647]  Step 143707  [3.108 sec/step, loss=0.09008, avg_loss=0.09643, mel_loss=0.04029, linear_loss=0.04979]
[2020-05-11 19:41:28.083]  Step 143708  [3.092 sec/step, loss=0.09146, avg_loss=0.09634, mel_loss=0.04150, linear_loss=0.04996]
[2020-05-11 19:41:33.447]  Step 143709  [3.137 sec/step, loss=0.10093, avg_loss=0.09652, mel_loss=0.04725, linear_loss=0.05368]
[2020-05-11 19:41:35.650]  Step 143710  [3.135 sec/step, loss=0.09697, avg_loss=0.09651, mel_loss=0.04403, linear_loss=0.05293]
[2020-05-11 19:41:37.268]  Step 143711  [3.110 sec/step, loss=0.09323, avg_loss=0.09641, mel_loss=0.04216, linear_loss=0.05107]
[2020-05-11 19:41:38.440]  Step 143712  [3.102 sec/step, loss=0.08715, avg_loss=0.09632, mel_loss=0.03869, linear_loss=0.04847]
[2020-05-11 19:41:38.995]  Generated 32 batches of size 32 in 1.722 sec
[2020-05-11 19:41:41.363]  Step 143713  [3.086 sec/step, loss=0.10267, avg_loss=0.09631, mel_loss=0.04703, linear_loss=0.05564]
[2020-05-11 19:41:44.837]  Step 143714  [3.105 sec/step, loss=0.10141, avg_loss=0.09640, mel_loss=0.04684, linear_loss=0.05457]
[2020-05-11 19:41:48.483]  Step 143715  [3.111 sec/step, loss=0.10316, avg_loss=0.09643, mel_loss=0.04768, linear_loss=0.05548]
[2020-05-11 19:41:51.918]  Step 143716  [3.121 sec/step, loss=0.10098, avg_loss=0.09645, mel_loss=0.04652, linear_loss=0.05446]
[2020-05-11 19:41:53.981]  Step 143717  [3.090 sec/step, loss=0.09826, avg_loss=0.09640, mel_loss=0.04478, linear_loss=0.05348]
[2020-05-11 19:41:55.338]  Step 143718  [3.095 sec/step, loss=0.09315, avg_loss=0.09650, mel_loss=0.04176, linear_loss=0.05139]
[2020-05-11 19:41:56.136]  Step 143719  [3.083 sec/step, loss=0.07858, avg_loss=0.09632, mel_loss=0.03513, linear_loss=0.04345]
[2020-05-11 19:42:00.266]  Step 143720  [3.115 sec/step, loss=0.10099, avg_loss=0.09646, mel_loss=0.04695, linear_loss=0.05404]
[2020-05-11 19:42:02.262]  Step 143721  [3.117 sec/step, loss=0.09857, avg_loss=0.09649, mel_loss=0.04490, linear_loss=0.05368]
[2020-05-11 19:42:05.945]  Step 143722  [3.096 sec/step, loss=0.10387, avg_loss=0.09644, mel_loss=0.04816, linear_loss=0.05571]
[2020-05-11 19:42:09.433]  Step 143723  [3.126 sec/step, loss=0.10190, avg_loss=0.09669, mel_loss=0.04710, linear_loss=0.05480]
[2020-05-11 19:42:10.906]  Step 143724  [3.127 sec/step, loss=0.09425, avg_loss=0.09670, mel_loss=0.04232, linear_loss=0.05193]
[2020-05-11 19:42:16.237]  Step 143725  [3.166 sec/step, loss=0.10234, avg_loss=0.09680, mel_loss=0.04806, linear_loss=0.05428]
[2020-05-11 19:42:25.222]  Step 143726  [3.244 sec/step, loss=0.09944, avg_loss=0.09688, mel_loss=0.04746, linear_loss=0.05199]
[2020-05-11 19:42:26.669]  Step 143727  [3.248 sec/step, loss=0.09151, avg_loss=0.09692, mel_loss=0.04084, linear_loss=0.05067]
[2020-05-11 19:42:29.596]  Step 143728  [3.266 sec/step, loss=0.09840, avg_loss=0.09701, mel_loss=0.04488, linear_loss=0.05352]
[2020-05-11 19:42:30.209]  Step 143729  [3.217 sec/step, loss=0.07435, avg_loss=0.09670, mel_loss=0.03382, linear_loss=0.04052]
[2020-05-11 19:42:32.306]  Step 143730  [3.192 sec/step, loss=0.09626, avg_loss=0.09659, mel_loss=0.04339, linear_loss=0.05287]
[2020-05-11 19:42:39.249]  Step 143731  [3.225 sec/step, loss=0.10411, avg_loss=0.09658, mel_loss=0.04921, linear_loss=0.05490]
[2020-05-11 19:42:40.870]  Step 143732  [3.227 sec/step, loss=0.09454, avg_loss=0.09660, mel_loss=0.04267, linear_loss=0.05186]
[2020-05-11 19:42:41.883]  Step 143733  [3.210 sec/step, loss=0.08383, avg_loss=0.09645, mel_loss=0.03725, linear_loss=0.04657]
[2020-05-11 19:42:46.045]  Step 143734  [3.230 sec/step, loss=0.10136, avg_loss=0.09650, mel_loss=0.04700, linear_loss=0.05437]
[2020-05-11 19:42:49.259]  Step 143735  [3.250 sec/step, loss=0.10132, avg_loss=0.09660, mel_loss=0.04674, linear_loss=0.05459]
[2020-05-11 19:42:50.455]  Step 143736  [3.256 sec/step, loss=0.08211, avg_loss=0.09666, mel_loss=0.03676, linear_loss=0.04534]
[2020-05-11 19:42:53.231]  Step 143737  [3.274 sec/step, loss=0.09517, avg_loss=0.09673, mel_loss=0.04296, linear_loss=0.05221]
[2020-05-11 19:42:56.716]  Step 143738  [3.237 sec/step, loss=0.09584, avg_loss=0.09644, mel_loss=0.04375, linear_loss=0.05208]
[2020-05-11 19:43:02.199]  Step 143739  [3.278 sec/step, loss=0.09977, avg_loss=0.09653, mel_loss=0.04622, linear_loss=0.05355]
[2020-05-11 19:43:18.788]  Step 143740  [3.429 sec/step, loss=0.08096, avg_loss=0.09645, mel_loss=0.03959, linear_loss=0.04137]
[2020-05-11 19:43:20.192]  Step 143741  [3.397 sec/step, loss=0.09161, avg_loss=0.09633, mel_loss=0.04150, linear_loss=0.05011]
[2020-05-11 19:43:21.231]  Step 143742  [3.283 sec/step, loss=0.08614, avg_loss=0.09628, mel_loss=0.03833, linear_loss=0.04782]
[2020-05-11 19:43:25.907]  Step 143743  [3.300 sec/step, loss=0.10312, avg_loss=0.09626, mel_loss=0.04815, linear_loss=0.05497]
[2020-05-11 19:43:27.632]  Generated 32 batches of size 32 in 1.720 sec
[2020-05-11 19:43:28.398]  Step 143744  [3.317 sec/step, loss=0.09894, avg_loss=0.09640, mel_loss=0.04522, linear_loss=0.05372]
[2020-05-11 19:43:31.410]  Step 143745  [3.324 sec/step, loss=0.10125, avg_loss=0.09644, mel_loss=0.04629, linear_loss=0.05496]
[2020-05-11 19:43:32.504]  Step 143746  [3.314 sec/step, loss=0.09174, avg_loss=0.09634, mel_loss=0.04098, linear_loss=0.05076]
[2020-05-11 19:43:35.239]  Step 143747  [3.325 sec/step, loss=0.09824, avg_loss=0.09638, mel_loss=0.04538, linear_loss=0.05286]
[2020-05-11 19:43:37.074]  Step 143748  [3.335 sec/step, loss=0.09557, avg_loss=0.09645, mel_loss=0.04282, linear_loss=0.05274]
[2020-05-11 19:43:37.834]  Step 143749  [3.311 sec/step, loss=0.08689, avg_loss=0.09623, mel_loss=0.03870, linear_loss=0.04819]
[2020-05-11 19:43:44.170]  Step 143750  [3.340 sec/step, loss=0.10270, avg_loss=0.09614, mel_loss=0.04856, linear_loss=0.05414]
[2020-05-11 19:43:44.170]  Writing summary at step: 143750
[2020-05-11 19:43:49.376]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143750
[2020-05-11 19:43:50.688]  Saving audio and alignment...
[2020-05-11 19:43:53.008]  Input: 뉴스는 어떤가요~________________
[2020-05-11 19:43:58.462]  Step 143751  [3.386 sec/step, loss=0.10255, avg_loss=0.09634, mel_loss=0.04825, linear_loss=0.05430]
[2020-05-11 19:44:07.475]  Step 143752  [3.424 sec/step, loss=0.09910, avg_loss=0.09628, mel_loss=0.04725, linear_loss=0.05185]
[2020-05-11 19:44:08.492]  Step 143753  [3.417 sec/step, loss=0.08277, avg_loss=0.09612, mel_loss=0.03675, linear_loss=0.04602]
[2020-05-11 19:44:09.728]  Step 143754  [3.410 sec/step, loss=0.09141, avg_loss=0.09604, mel_loss=0.04101, linear_loss=0.05040]
[2020-05-11 19:44:10.296]  Step 143755  [3.396 sec/step, loss=0.07642, avg_loss=0.09583, mel_loss=0.03475, linear_loss=0.04168]
[2020-05-11 19:44:12.448]  Step 143756  [3.392 sec/step, loss=0.09537, avg_loss=0.09578, mel_loss=0.04327, linear_loss=0.05209]
[2020-05-11 19:44:25.769]  Step 143757  [3.445 sec/step, loss=0.09001, avg_loss=0.09563, mel_loss=0.04366, linear_loss=0.04636]
[2020-05-11 19:44:29.209]  Step 143758  [3.413 sec/step, loss=0.09997, avg_loss=0.09556, mel_loss=0.04597, linear_loss=0.05400]
[2020-05-11 19:44:30.607]  Step 143759  [3.419 sec/step, loss=0.09236, avg_loss=0.09565, mel_loss=0.04183, linear_loss=0.05054]
[2020-05-11 19:44:34.314]  Step 143760  [3.380 sec/step, loss=0.10270, avg_loss=0.09563, mel_loss=0.04733, linear_loss=0.05536]
[2020-05-11 19:44:37.308]  Step 143761  [3.369 sec/step, loss=0.09922, avg_loss=0.09557, mel_loss=0.04545, linear_loss=0.05377]
[2020-05-11 19:44:40.499]  Step 143762  [3.383 sec/step, loss=0.10219, avg_loss=0.09564, mel_loss=0.04711, linear_loss=0.05508]
[2020-05-11 19:44:44.071]  Step 143763  [3.404 sec/step, loss=0.10100, avg_loss=0.09571, mel_loss=0.04675, linear_loss=0.05425]
[2020-05-11 19:44:45.716]  Step 143764  [3.399 sec/step, loss=0.09438, avg_loss=0.09567, mel_loss=0.04301, linear_loss=0.05137]
[2020-05-11 19:44:48.376]  Step 143765  [3.404 sec/step, loss=0.09653, avg_loss=0.09565, mel_loss=0.04378, linear_loss=0.05275]
[2020-05-11 19:44:52.581]  Step 143766  [3.426 sec/step, loss=0.10139, avg_loss=0.09568, mel_loss=0.04677, linear_loss=0.05462]
[2020-05-11 19:44:57.550]  Step 143767  [3.445 sec/step, loss=0.10142, avg_loss=0.09566, mel_loss=0.04740, linear_loss=0.05401]
[2020-05-11 19:45:00.401]  Step 143768  [3.410 sec/step, loss=0.09757, avg_loss=0.09560, mel_loss=0.04461, linear_loss=0.05296]
[2020-05-11 19:45:01.157]  Step 143769  [3.375 sec/step, loss=0.08480, avg_loss=0.09540, mel_loss=0.03765, linear_loss=0.04715]
[2020-05-11 19:45:02.516]  Step 143770  [3.373 sec/step, loss=0.08956, avg_loss=0.09532, mel_loss=0.04026, linear_loss=0.04929]
[2020-05-11 19:45:04.512]  Step 143771  [3.251 sec/step, loss=0.09515, avg_loss=0.09544, mel_loss=0.04314, linear_loss=0.05201]
[2020-05-11 19:45:09.039]  Step 143772  [3.250 sec/step, loss=0.10400, avg_loss=0.09543, mel_loss=0.04839, linear_loss=0.05560]
[2020-05-11 19:45:09.806]  Step 143773  [3.225 sec/step, loss=0.08123, avg_loss=0.09520, mel_loss=0.03607, linear_loss=0.04516]
[2020-05-11 19:45:11.425]  Step 143774  [3.232 sec/step, loss=0.09314, avg_loss=0.09527, mel_loss=0.04173, linear_loss=0.05141]
[2020-05-11 19:45:11.599]  Generated 32 batches of size 32 in 1.788 sec
[2020-05-11 19:45:12.556]  Step 143775  [3.231 sec/step, loss=0.09031, avg_loss=0.09527, mel_loss=0.04007, linear_loss=0.05024]
[2020-05-11 19:45:14.448]  Step 143776  [3.221 sec/step, loss=0.09275, avg_loss=0.09519, mel_loss=0.04143, linear_loss=0.05131]
[2020-05-11 19:45:16.819]  Step 143777  [3.157 sec/step, loss=0.09859, avg_loss=0.09513, mel_loss=0.04498, linear_loss=0.05361]
[2020-05-11 19:45:24.395]  Step 143778  [3.177 sec/step, loss=0.10198, avg_loss=0.09511, mel_loss=0.04829, linear_loss=0.05369]
[2020-05-11 19:45:25.426]  Step 143779  [3.163 sec/step, loss=0.08700, avg_loss=0.09498, mel_loss=0.03894, linear_loss=0.04807]
[2020-05-11 19:45:27.677]  Step 143780  [3.168 sec/step, loss=0.09694, avg_loss=0.09499, mel_loss=0.04419, linear_loss=0.05274]
[2020-05-11 19:45:29.450]  Step 143781  [3.133 sec/step, loss=0.09455, avg_loss=0.09490, mel_loss=0.04214, linear_loss=0.05241]
[2020-05-11 19:45:35.571]  Step 143782  [3.158 sec/step, loss=0.10083, avg_loss=0.09490, mel_loss=0.04755, linear_loss=0.05328]
[2020-05-11 19:45:41.017]  Step 143783  [3.203 sec/step, loss=0.10175, avg_loss=0.09505, mel_loss=0.04743, linear_loss=0.05432]
[2020-05-11 19:45:45.461]  Step 143784  [3.232 sec/step, loss=0.10052, avg_loss=0.09511, mel_loss=0.04681, linear_loss=0.05371]
[2020-05-11 19:45:46.451]  Step 143785  [3.230 sec/step, loss=0.08706, avg_loss=0.09508, mel_loss=0.03863, linear_loss=0.04842]
[2020-05-11 19:45:51.339]  Step 143786  [3.243 sec/step, loss=0.10196, avg_loss=0.09508, mel_loss=0.04737, linear_loss=0.05459]
[2020-05-11 19:45:54.031]  Step 143787  [3.256 sec/step, loss=0.09980, avg_loss=0.09512, mel_loss=0.04592, linear_loss=0.05387]
[2020-05-11 19:45:57.513]  Step 143788  [3.284 sec/step, loss=0.09993, avg_loss=0.09530, mel_loss=0.04614, linear_loss=0.05379]
[2020-05-11 19:45:58.823]  Step 143789  [3.270 sec/step, loss=0.09031, avg_loss=0.09521, mel_loss=0.04034, linear_loss=0.04997]
[2020-05-11 19:46:02.763]  Step 143790  [3.301 sec/step, loss=0.10004, avg_loss=0.09544, mel_loss=0.04626, linear_loss=0.05377]
[2020-05-11 19:46:03.907]  Step 143791  [3.270 sec/step, loss=0.08892, avg_loss=0.09530, mel_loss=0.03940, linear_loss=0.04952]
[2020-05-11 19:46:07.695]  Step 143792  [3.300 sec/step, loss=0.10168, avg_loss=0.09548, mel_loss=0.04694, linear_loss=0.05473]
[2020-05-11 19:46:09.383]  Step 143793  [3.311 sec/step, loss=0.09105, avg_loss=0.09561, mel_loss=0.04109, linear_loss=0.04996]
[2020-05-11 19:46:17.887]  Step 143794  [3.371 sec/step, loss=0.10265, avg_loss=0.09564, mel_loss=0.04873, linear_loss=0.05392]
[2020-05-11 19:46:18.720]  Step 143795  [3.349 sec/step, loss=0.07955, avg_loss=0.09540, mel_loss=0.03506, linear_loss=0.04449]
[2020-05-11 19:46:21.240]  Step 143796  [3.243 sec/step, loss=0.09782, avg_loss=0.09551, mel_loss=0.04452, linear_loss=0.05330]
[2020-05-11 19:46:28.353]  Step 143797  [3.298 sec/step, loss=0.10493, avg_loss=0.09561, mel_loss=0.04992, linear_loss=0.05501]
[2020-05-11 19:46:31.276]  Step 143798  [3.271 sec/step, loss=0.10191, avg_loss=0.09560, mel_loss=0.04663, linear_loss=0.05528]
[2020-05-11 19:46:45.081]  Step 143799  [3.333 sec/step, loss=0.07657, avg_loss=0.09531, mel_loss=0.03719, linear_loss=0.03938]
[2020-05-11 19:46:46.850]  Step 143800  [3.263 sec/step, loss=0.09397, avg_loss=0.09524, mel_loss=0.04214, linear_loss=0.05183]
[2020-05-11 19:46:46.850]  Writing summary at step: 143800
[2020-05-11 19:46:52.708]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143800
[2020-05-11 19:46:54.075]  Saving audio and alignment...
[2020-05-11 19:46:57.953]  Input: 한번 붙어 봅시다 이렇게요~___________________________
[2020-05-11 19:47:04.811]  Step 143801  [3.312 sec/step, loss=0.10307, avg_loss=0.09531, mel_loss=0.04852, linear_loss=0.05456]
[2020-05-11 19:47:08.305]  Step 143802  [3.335 sec/step, loss=0.09930, avg_loss=0.09542, mel_loss=0.04560, linear_loss=0.05370]
[2020-05-11 19:47:10.245]  Step 143803  [3.307 sec/step, loss=0.09432, avg_loss=0.09534, mel_loss=0.04260, linear_loss=0.05173]
[2020-05-11 19:47:12.008]  Generated 32 batches of size 32 in 1.758 sec
[2020-05-11 19:47:12.509]  Step 143804  [3.320 sec/step, loss=0.09794, avg_loss=0.09545, mel_loss=0.04472, linear_loss=0.05322]
[2020-05-11 19:47:14.135]  Step 143805  [3.312 sec/step, loss=0.09333, avg_loss=0.09540, mel_loss=0.04184, linear_loss=0.05149]
[2020-05-11 19:47:14.719]  Step 143806  [3.291 sec/step, loss=0.07395, avg_loss=0.09515, mel_loss=0.03346, linear_loss=0.04049]
[2020-05-11 19:47:17.764]  Step 143807  [3.311 sec/step, loss=0.10002, avg_loss=0.09525, mel_loss=0.04589, linear_loss=0.05414]
[2020-05-11 19:47:18.592]  Step 143808  [3.305 sec/step, loss=0.08054, avg_loss=0.09514, mel_loss=0.03560, linear_loss=0.04493]
[2020-05-11 19:47:19.951]  Step 143809  [3.265 sec/step, loss=0.09276, avg_loss=0.09505, mel_loss=0.04170, linear_loss=0.05106]
[2020-05-11 19:47:21.021]  Step 143810  [3.254 sec/step, loss=0.08738, avg_loss=0.09496, mel_loss=0.03885, linear_loss=0.04853]
[2020-05-11 19:47:21.873]  Step 143811  [3.246 sec/step, loss=0.08821, avg_loss=0.09491, mel_loss=0.03882, linear_loss=0.04939]
[2020-05-11 19:47:23.864]  Step 143812  [3.255 sec/step, loss=0.09711, avg_loss=0.09501, mel_loss=0.04432, linear_loss=0.05279]
[2020-05-11 19:47:25.217]  Step 143813  [3.239 sec/step, loss=0.09187, avg_loss=0.09490, mel_loss=0.04114, linear_loss=0.05073]
[2020-05-11 19:47:26.729]  Step 143814  [3.219 sec/step, loss=0.09348, avg_loss=0.09482, mel_loss=0.04184, linear_loss=0.05165]
[2020-05-11 19:47:31.049]  Step 143815  [3.226 sec/step, loss=0.10111, avg_loss=0.09480, mel_loss=0.04705, linear_loss=0.05406]
[2020-05-11 19:47:34.641]  Step 143816  [3.228 sec/step, loss=0.10370, avg_loss=0.09483, mel_loss=0.04800, linear_loss=0.05570]
[2020-05-11 19:47:36.488]  Step 143817  [3.225 sec/step, loss=0.09547, avg_loss=0.09480, mel_loss=0.04286, linear_loss=0.05261]
[2020-05-11 19:47:37.534]  Step 143818  [3.222 sec/step, loss=0.08640, avg_loss=0.09473, mel_loss=0.03854, linear_loss=0.04787]
[2020-05-11 19:47:46.591]  Step 143819  [3.305 sec/step, loss=0.09950, avg_loss=0.09494, mel_loss=0.04737, linear_loss=0.05213]
[2020-05-11 19:47:48.950]  Step 143820  [3.287 sec/step, loss=0.09897, avg_loss=0.09492, mel_loss=0.04522, linear_loss=0.05374]
[2020-05-11 19:47:53.462]  Step 143821  [3.312 sec/step, loss=0.10237, avg_loss=0.09496, mel_loss=0.04777, linear_loss=0.05460]
[2020-05-11 19:47:55.884]  Step 143822  [3.300 sec/step, loss=0.09630, avg_loss=0.09488, mel_loss=0.04344, linear_loss=0.05285]
[2020-05-11 19:47:56.732]  Step 143823  [3.273 sec/step, loss=0.08190, avg_loss=0.09468, mel_loss=0.03649, linear_loss=0.04541]
[2020-05-11 19:48:00.257]  Step 143824  [3.294 sec/step, loss=0.09955, avg_loss=0.09474, mel_loss=0.04598, linear_loss=0.05357]
[2020-05-11 19:48:14.672]  Step 143825  [3.385 sec/step, loss=0.08151, avg_loss=0.09453, mel_loss=0.03957, linear_loss=0.04194]
[2020-05-11 19:48:16.664]  Step 143826  [3.315 sec/step, loss=0.09526, avg_loss=0.09449, mel_loss=0.04320, linear_loss=0.05206]
[2020-05-11 19:48:17.723]  Step 143827  [3.311 sec/step, loss=0.08993, avg_loss=0.09447, mel_loss=0.03999, linear_loss=0.04994]
[2020-05-11 19:48:23.003]  Step 143828  [3.334 sec/step, loss=0.10176, avg_loss=0.09450, mel_loss=0.04772, linear_loss=0.05404]
[2020-05-11 19:48:25.968]  Step 143829  [3.358 sec/step, loss=0.09842, avg_loss=0.09475, mel_loss=0.04514, linear_loss=0.05327]
[2020-05-11 19:48:28.280]  Step 143830  [3.360 sec/step, loss=0.09619, avg_loss=0.09474, mel_loss=0.04363, linear_loss=0.05256]
[2020-05-11 19:48:28.993]  Step 143831  [3.298 sec/step, loss=0.08154, avg_loss=0.09452, mel_loss=0.03614, linear_loss=0.04540]
[2020-05-11 19:48:35.723]  Step 143832  [3.349 sec/step, loss=0.10234, avg_loss=0.09460, mel_loss=0.04844, linear_loss=0.05390]
[2020-05-11 19:48:37.925]  Step 143833  [3.361 sec/step, loss=0.09551, avg_loss=0.09471, mel_loss=0.04332, linear_loss=0.05219]
[2020-05-11 19:48:39.155]  Step 143834  [3.331 sec/step, loss=0.09086, avg_loss=0.09461, mel_loss=0.04046, linear_loss=0.05041]
[2020-05-11 19:48:44.722]  Step 143835  [3.355 sec/step, loss=0.10238, avg_loss=0.09462, mel_loss=0.04771, linear_loss=0.05467]
[2020-05-11 19:48:46.813]  Generated 32 batches of size 32 in 2.083 sec
[2020-05-11 19:48:48.927]  Step 143836  [3.385 sec/step, loss=0.10183, avg_loss=0.09482, mel_loss=0.04726, linear_loss=0.05458]
[2020-05-11 19:48:51.784]  Step 143837  [3.386 sec/step, loss=0.09921, avg_loss=0.09486, mel_loss=0.04553, linear_loss=0.05367]
[2020-05-11 19:48:52.542]  Step 143838  [3.359 sec/step, loss=0.07949, avg_loss=0.09469, mel_loss=0.03640, linear_loss=0.04309]
[2020-05-11 19:48:56.171]  Step 143839  [3.340 sec/step, loss=0.10199, avg_loss=0.09472, mel_loss=0.04701, linear_loss=0.05498]
[2020-05-11 19:49:03.645]  Step 143840  [3.249 sec/step, loss=0.10478, avg_loss=0.09495, mel_loss=0.04972, linear_loss=0.05507]
[2020-05-11 19:49:06.727]  Step 143841  [3.266 sec/step, loss=0.09926, avg_loss=0.09503, mel_loss=0.04570, linear_loss=0.05356]
[2020-05-11 19:49:08.332]  Step 143842  [3.271 sec/step, loss=0.09401, avg_loss=0.09511, mel_loss=0.04265, linear_loss=0.05136]
[2020-05-11 19:49:10.135]  Step 143843  [3.243 sec/step, loss=0.09423, avg_loss=0.09502, mel_loss=0.04209, linear_loss=0.05214]
[2020-05-11 19:49:11.278]  Step 143844  [3.229 sec/step, loss=0.08766, avg_loss=0.09491, mel_loss=0.03896, linear_loss=0.04870]
[2020-05-11 19:49:12.500]  Step 143845  [3.211 sec/step, loss=0.08707, avg_loss=0.09477, mel_loss=0.03884, linear_loss=0.04823]
[2020-05-11 19:49:13.254]  Step 143846  [3.208 sec/step, loss=0.08451, avg_loss=0.09469, mel_loss=0.03739, linear_loss=0.04713]
[2020-05-11 19:49:15.845]  Step 143847  [3.206 sec/step, loss=0.09650, avg_loss=0.09468, mel_loss=0.04407, linear_loss=0.05242]
[2020-05-11 19:49:16.405]  Step 143848  [3.194 sec/step, loss=0.07395, avg_loss=0.09446, mel_loss=0.03330, linear_loss=0.04064]
[2020-05-11 19:49:25.446]  Step 143849  [3.276 sec/step, loss=0.10318, avg_loss=0.09462, mel_loss=0.04951, linear_loss=0.05368]
[2020-05-11 19:49:27.847]  Step 143850  [3.237 sec/step, loss=0.09746, avg_loss=0.09457, mel_loss=0.04454, linear_loss=0.05292]
[2020-05-11 19:49:27.847]  Writing summary at step: 143850
[2020-05-11 19:49:28.820]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143850
[2020-05-11 19:49:30.661]  Saving audio and alignment...
[2020-05-11 19:49:38.731]  Input: 승부를 예측할 수 없는 그래야 약간 극적이 느낌이 들어요 승부를 예측할 수 없는 깜찍한 대결에~
[2020-05-11 19:49:40.111]  Step 143851  [3.196 sec/step, loss=0.09160, avg_loss=0.09446, mel_loss=0.04124, linear_loss=0.05036]
[2020-05-11 19:49:41.144]  Step 143852  [3.117 sec/step, loss=0.08776, avg_loss=0.09435, mel_loss=0.03912, linear_loss=0.04863]
[2020-05-11 19:49:43.041]  Step 143853  [3.125 sec/step, loss=0.09535, avg_loss=0.09447, mel_loss=0.04291, linear_loss=0.05244]
[2020-05-11 19:49:44.393]  Step 143854  [3.127 sec/step, loss=0.09039, avg_loss=0.09446, mel_loss=0.04072, linear_loss=0.04966]
[2020-05-11 19:49:47.509]  Step 143855  [3.152 sec/step, loss=0.10148, avg_loss=0.09471, mel_loss=0.04668, linear_loss=0.05480]
[2020-05-11 19:50:00.624]  Step 143856  [3.262 sec/step, loss=0.09063, avg_loss=0.09467, mel_loss=0.04388, linear_loss=0.04675]
[2020-05-11 19:50:04.789]  Step 143857  [3.170 sec/step, loss=0.10329, avg_loss=0.09480, mel_loss=0.04796, linear_loss=0.05533]
[2020-05-11 19:50:06.421]  Step 143858  [3.152 sec/step, loss=0.09164, avg_loss=0.09472, mel_loss=0.04138, linear_loss=0.05027]
[2020-05-11 19:50:08.659]  Step 143859  [3.160 sec/step, loss=0.09711, avg_loss=0.09476, mel_loss=0.04434, linear_loss=0.05277]
[2020-05-11 19:50:09.733]  Step 143860  [3.134 sec/step, loss=0.08883, avg_loss=0.09462, mel_loss=0.03969, linear_loss=0.04914]
[2020-05-11 19:50:13.203]  Step 143861  [3.139 sec/step, loss=0.09784, avg_loss=0.09461, mel_loss=0.04481, linear_loss=0.05303]
[2020-05-11 19:50:14.982]  Step 143862  [3.125 sec/step, loss=0.09532, avg_loss=0.09454, mel_loss=0.04354, linear_loss=0.05178]
[2020-05-11 19:50:18.653]  Step 143863  [3.126 sec/step, loss=0.10305, avg_loss=0.09456, mel_loss=0.04768, linear_loss=0.05537]
[2020-05-11 19:50:23.340]  Step 143864  [3.156 sec/step, loss=0.10446, avg_loss=0.09466, mel_loss=0.04881, linear_loss=0.05565]
[2020-05-11 19:50:29.080]  Step 143865  [3.187 sec/step, loss=0.10454, avg_loss=0.09474, mel_loss=0.04930, linear_loss=0.05524]
[2020-05-11 19:50:30.850]  Generated 32 batches of size 32 in 1.764 sec
[2020-05-11 19:50:35.437]  Step 143866  [3.208 sec/step, loss=0.10316, avg_loss=0.09476, mel_loss=0.04860, linear_loss=0.05456]
[2020-05-11 19:50:36.265]  Step 143867  [3.167 sec/step, loss=0.08230, avg_loss=0.09457, mel_loss=0.03692, linear_loss=0.04539]
[2020-05-11 19:50:40.056]  Step 143868  [3.176 sec/step, loss=0.10096, avg_loss=0.09460, mel_loss=0.04661, linear_loss=0.05435]
[2020-05-11 19:50:41.763]  Step 143869  [3.186 sec/step, loss=0.09342, avg_loss=0.09469, mel_loss=0.04239, linear_loss=0.05104]
[2020-05-11 19:50:43.745]  Step 143870  [3.192 sec/step, loss=0.09738, avg_loss=0.09477, mel_loss=0.04375, linear_loss=0.05363]
[2020-05-11 19:50:46.879]  Step 143871  [3.204 sec/step, loss=0.10058, avg_loss=0.09482, mel_loss=0.04594, linear_loss=0.05464]
[2020-05-11 19:50:49.693]  Step 143872  [3.186 sec/step, loss=0.10117, avg_loss=0.09479, mel_loss=0.04645, linear_loss=0.05472]
[2020-05-11 19:50:54.884]  Step 143873  [3.231 sec/step, loss=0.10354, avg_loss=0.09502, mel_loss=0.04847, linear_loss=0.05508]
[2020-05-11 19:51:02.347]  Step 143874  [3.289 sec/step, loss=0.10330, avg_loss=0.09512, mel_loss=0.04887, linear_loss=0.05443]
[2020-05-11 19:51:03.487]  Step 143875  [3.289 sec/step, loss=0.08871, avg_loss=0.09510, mel_loss=0.03975, linear_loss=0.04896]
[2020-05-11 19:51:05.126]  Step 143876  [3.287 sec/step, loss=0.09609, avg_loss=0.09514, mel_loss=0.04306, linear_loss=0.05303]
[2020-05-11 19:51:07.965]  Step 143877  [3.291 sec/step, loss=0.09849, avg_loss=0.09514, mel_loss=0.04514, linear_loss=0.05335]
[2020-05-11 19:51:09.413]  Step 143878  [3.230 sec/step, loss=0.09306, avg_loss=0.09505, mel_loss=0.04185, linear_loss=0.05121]
[2020-05-11 19:51:11.394]  Step 143879  [3.240 sec/step, loss=0.09345, avg_loss=0.09511, mel_loss=0.04220, linear_loss=0.05125]
[2020-05-11 19:51:13.023]  Step 143880  [3.233 sec/step, loss=0.09340, avg_loss=0.09508, mel_loss=0.04214, linear_loss=0.05126]
[2020-05-11 19:51:14.375]  Step 143881  [3.229 sec/step, loss=0.09025, avg_loss=0.09503, mel_loss=0.04060, linear_loss=0.04966]
[2020-05-11 19:51:15.325]  Step 143882  [3.177 sec/step, loss=0.08478, avg_loss=0.09487, mel_loss=0.03761, linear_loss=0.04716]
[2020-05-11 19:51:19.558]  Step 143883  [3.165 sec/step, loss=0.10086, avg_loss=0.09486, mel_loss=0.04654, linear_loss=0.05433]
[2020-05-11 19:51:23.745]  Step 143884  [3.163 sec/step, loss=0.10245, avg_loss=0.09488, mel_loss=0.04793, linear_loss=0.05452]
[2020-05-11 19:51:29.821]  Step 143885  [3.214 sec/step, loss=0.10137, avg_loss=0.09503, mel_loss=0.04780, linear_loss=0.05356]
[2020-05-11 19:51:33.422]  Step 143886  [3.201 sec/step, loss=0.10181, avg_loss=0.09502, mel_loss=0.04691, linear_loss=0.05490]
[2020-05-11 19:51:35.424]  Step 143887  [3.194 sec/step, loss=0.09752, avg_loss=0.09500, mel_loss=0.04400, linear_loss=0.05352]
[2020-05-11 19:51:37.236]  Step 143888  [3.177 sec/step, loss=0.09226, avg_loss=0.09492, mel_loss=0.04142, linear_loss=0.05085]
[2020-05-11 19:51:38.565]  Step 143889  [3.177 sec/step, loss=0.09386, avg_loss=0.09496, mel_loss=0.04192, linear_loss=0.05193]
[2020-05-11 19:51:39.276]  Step 143890  [3.145 sec/step, loss=0.08054, avg_loss=0.09476, mel_loss=0.03593, linear_loss=0.04461]
[2020-05-11 19:51:40.034]  Step 143891  [3.141 sec/step, loss=0.08508, avg_loss=0.09473, mel_loss=0.03759, linear_loss=0.04749]
[2020-05-11 19:51:43.151]  Step 143892  [3.134 sec/step, loss=0.10090, avg_loss=0.09472, mel_loss=0.04620, linear_loss=0.05470]
[2020-05-11 19:51:45.662]  Step 143893  [3.143 sec/step, loss=0.09758, avg_loss=0.09478, mel_loss=0.04420, linear_loss=0.05338]
[2020-05-11 19:51:47.823]  Step 143894  [3.079 sec/step, loss=0.09605, avg_loss=0.09472, mel_loss=0.04328, linear_loss=0.05277]
[2020-05-11 19:51:52.537]  Step 143895  [3.118 sec/step, loss=0.10113, avg_loss=0.09493, mel_loss=0.04714, linear_loss=0.05399]
[2020-05-11 19:51:53.546]  Step 143896  [3.103 sec/step, loss=0.08525, avg_loss=0.09481, mel_loss=0.03773, linear_loss=0.04752]
[2020-05-11 19:51:56.941]  Step 143897  [3.066 sec/step, loss=0.09991, avg_loss=0.09476, mel_loss=0.04594, linear_loss=0.05396]
[2020-05-11 19:51:58.517]  Generated 32 batches of size 32 in 1.572 sec
[2020-05-11 19:52:04.328]  Step 143898  [3.110 sec/step, loss=0.10355, avg_loss=0.09477, mel_loss=0.04913, linear_loss=0.05442]
[2020-05-11 19:52:07.687]  Step 143899  [3.006 sec/step, loss=0.10162, avg_loss=0.09502, mel_loss=0.04702, linear_loss=0.05459]
[2020-05-11 19:52:15.884]  Step 143900  [3.070 sec/step, loss=0.10076, avg_loss=0.09509, mel_loss=0.04812, linear_loss=0.05264]
[2020-05-11 19:52:15.884]  Writing summary at step: 143900
[2020-05-11 19:52:21.175]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143900
[2020-05-11 19:52:23.001]  Saving audio and alignment...
[2020-05-11 19:52:24.749]  Input: 이렇게~______
[2020-05-11 19:52:39.633]  Step 143901  [3.150 sec/step, loss=0.07643, avg_loss=0.09483, mel_loss=0.03690, linear_loss=0.03954]
[2020-05-11 19:52:42.014]  Step 143902  [3.139 sec/step, loss=0.09876, avg_loss=0.09482, mel_loss=0.04501, linear_loss=0.05375]
[2020-05-11 19:52:44.922]  Step 143903  [3.149 sec/step, loss=0.09885, avg_loss=0.09487, mel_loss=0.04554, linear_loss=0.05331]
[2020-05-11 19:52:46.099]  Step 143904  [3.138 sec/step, loss=0.08755, avg_loss=0.09476, mel_loss=0.03876, linear_loss=0.04879]
[2020-05-11 19:52:48.627]  Step 143905  [3.147 sec/step, loss=0.09831, avg_loss=0.09481, mel_loss=0.04475, linear_loss=0.05356]
[2020-05-11 19:52:50.267]  Step 143906  [3.158 sec/step, loss=0.09530, avg_loss=0.09503, mel_loss=0.04252, linear_loss=0.05278]
[2020-05-11 19:53:04.474]  Step 143907  [3.269 sec/step, loss=0.07522, avg_loss=0.09478, mel_loss=0.03625, linear_loss=0.03897]
[2020-05-11 19:53:14.159]  Step 143908  [3.358 sec/step, loss=0.10241, avg_loss=0.09500, mel_loss=0.04830, linear_loss=0.05412]
[2020-05-11 19:53:18.184]  Step 143909  [3.385 sec/step, loss=0.09685, avg_loss=0.09504, mel_loss=0.04394, linear_loss=0.05291]
[2020-05-11 19:53:19.950]  Step 143910  [3.392 sec/step, loss=0.08945, avg_loss=0.09506, mel_loss=0.03978, linear_loss=0.04968]
[2020-05-11 19:53:21.157]  Step 143911  [3.395 sec/step, loss=0.08005, avg_loss=0.09498, mel_loss=0.03546, linear_loss=0.04459]
[2020-05-11 19:53:23.018]  Step 143912  [3.394 sec/step, loss=0.09200, avg_loss=0.09493, mel_loss=0.04092, linear_loss=0.05108]
[2020-05-11 19:53:24.195]  Step 143913  [3.392 sec/step, loss=0.08181, avg_loss=0.09482, mel_loss=0.03636, linear_loss=0.04544]
[2020-05-11 19:53:28.007]  Step 143914  [3.415 sec/step, loss=0.09899, avg_loss=0.09488, mel_loss=0.04524, linear_loss=0.05375]
[2020-05-11 19:53:29.363]  Step 143915  [3.385 sec/step, loss=0.08908, avg_loss=0.09476, mel_loss=0.03980, linear_loss=0.04928]
[2020-05-11 19:53:33.664]  Step 143916  [3.392 sec/step, loss=0.09981, avg_loss=0.09472, mel_loss=0.04582, linear_loss=0.05399]
[2020-05-11 19:53:34.635]  Step 143917  [3.384 sec/step, loss=0.08888, avg_loss=0.09465, mel_loss=0.03987, linear_loss=0.04901]
[2020-05-11 19:53:35.623]  Step 143918  [3.383 sec/step, loss=0.08383, avg_loss=0.09463, mel_loss=0.03690, linear_loss=0.04693]
[2020-05-11 19:53:41.091]  Step 143919  [3.347 sec/step, loss=0.10162, avg_loss=0.09465, mel_loss=0.04740, linear_loss=0.05422]
[2020-05-11 19:53:46.892]  Step 143920  [3.382 sec/step, loss=0.10298, avg_loss=0.09469, mel_loss=0.04837, linear_loss=0.05462]
[2020-05-11 19:53:51.562]  Step 143921  [3.383 sec/step, loss=0.10127, avg_loss=0.09468, mel_loss=0.04693, linear_loss=0.05434]
[2020-05-11 19:53:53.769]  Step 143922  [3.381 sec/step, loss=0.09541, avg_loss=0.09467, mel_loss=0.04319, linear_loss=0.05222]
[2020-05-11 19:53:54.301]  Step 143923  [3.378 sec/step, loss=0.08327, avg_loss=0.09468, mel_loss=0.03725, linear_loss=0.04602]
[2020-05-11 19:53:56.364]  Step 143924  [3.363 sec/step, loss=0.09694, avg_loss=0.09466, mel_loss=0.04403, linear_loss=0.05291]
[2020-05-11 19:53:57.746]  Step 143925  [3.233 sec/step, loss=0.09089, avg_loss=0.09475, mel_loss=0.04098, linear_loss=0.04991]
[2020-05-11 19:54:01.164]  Step 143926  [3.247 sec/step, loss=0.10012, avg_loss=0.09480, mel_loss=0.04614, linear_loss=0.05399]
[2020-05-11 19:54:02.875]  Step 143927  [3.254 sec/step, loss=0.09448, avg_loss=0.09485, mel_loss=0.04220, linear_loss=0.05228]
[2020-05-11 19:54:04.590]  Generated 32 batches of size 32 in 1.710 sec
[2020-05-11 19:54:06.070]  Step 143928  [3.233 sec/step, loss=0.10263, avg_loss=0.09485, mel_loss=0.04701, linear_loss=0.05563]
[2020-05-11 19:54:08.876]  Step 143929  [3.231 sec/step, loss=0.09868, avg_loss=0.09486, mel_loss=0.04509, linear_loss=0.05358]
[2020-05-11 19:54:12.457]  Step 143930  [3.244 sec/step, loss=0.10336, avg_loss=0.09493, mel_loss=0.04759, linear_loss=0.05576]
[2020-05-11 19:54:14.258]  Step 143931  [3.255 sec/step, loss=0.09503, avg_loss=0.09506, mel_loss=0.04248, linear_loss=0.05255]
[2020-05-11 19:54:22.402]  Step 143932  [3.269 sec/step, loss=0.10268, avg_loss=0.09507, mel_loss=0.04853, linear_loss=0.05415]
[2020-05-11 19:54:24.394]  Step 143933  [3.267 sec/step, loss=0.09481, avg_loss=0.09506, mel_loss=0.04299, linear_loss=0.05182]
[2020-05-11 19:54:25.870]  Step 143934  [3.269 sec/step, loss=0.09240, avg_loss=0.09508, mel_loss=0.04173, linear_loss=0.05067]
[2020-05-11 19:54:28.794]  Step 143935  [3.243 sec/step, loss=0.10179, avg_loss=0.09507, mel_loss=0.04645, linear_loss=0.05534]
[2020-05-11 19:54:33.167]  Step 143936  [3.245 sec/step, loss=0.10027, avg_loss=0.09505, mel_loss=0.04654, linear_loss=0.05373]
[2020-05-11 19:54:36.841]  Step 143937  [3.253 sec/step, loss=0.10257, avg_loss=0.09509, mel_loss=0.04762, linear_loss=0.05495]
[2020-05-11 19:54:38.942]  Step 143938  [3.266 sec/step, loss=0.09526, avg_loss=0.09525, mel_loss=0.04313, linear_loss=0.05213]
[2020-05-11 19:54:52.132]  Step 143939  [3.362 sec/step, loss=0.09015, avg_loss=0.09513, mel_loss=0.04360, linear_loss=0.04655]
[2020-05-11 19:54:53.180]  Step 143940  [3.298 sec/step, loss=0.08378, avg_loss=0.09492, mel_loss=0.03717, linear_loss=0.04661]
[2020-05-11 19:54:53.928]  Step 143941  [3.274 sec/step, loss=0.07880, avg_loss=0.09471, mel_loss=0.03632, linear_loss=0.04248]
[2020-05-11 19:54:58.207]  Step 143942  [3.301 sec/step, loss=0.10415, avg_loss=0.09481, mel_loss=0.04864, linear_loss=0.05551]
[2020-05-11 19:55:00.872]  Step 143943  [3.310 sec/step, loss=0.09610, avg_loss=0.09483, mel_loss=0.04413, linear_loss=0.05197]
[2020-05-11 19:55:02.775]  Step 143944  [3.317 sec/step, loss=0.09473, avg_loss=0.09490, mel_loss=0.04321, linear_loss=0.05152]
[2020-05-11 19:55:04.374]  Step 143945  [3.321 sec/step, loss=0.09512, avg_loss=0.09498, mel_loss=0.04309, linear_loss=0.05204]
[2020-05-11 19:55:06.789]  Step 143946  [3.338 sec/step, loss=0.09705, avg_loss=0.09511, mel_loss=0.04387, linear_loss=0.05318]
[2020-05-11 19:55:13.544]  Step 143947  [3.379 sec/step, loss=0.10471, avg_loss=0.09519, mel_loss=0.04935, linear_loss=0.05535]
[2020-05-11 19:55:18.373]  Step 143948  [3.422 sec/step, loss=0.10095, avg_loss=0.09546, mel_loss=0.04662, linear_loss=0.05433]
[2020-05-11 19:55:22.504]  Step 143949  [3.373 sec/step, loss=0.10064, avg_loss=0.09544, mel_loss=0.04648, linear_loss=0.05416]
[2020-05-11 19:55:23.835]  Step 143950  [3.362 sec/step, loss=0.09200, avg_loss=0.09538, mel_loss=0.04101, linear_loss=0.05100]
[2020-05-11 19:55:23.835]  Writing summary at step: 143950
[2020-05-11 19:55:26.845]  Saving checkpoint to: ./logs-tacotron/model.ckpt-143950
[2020-05-11 19:55:28.182]  Saving audio and alignment...
[2020-05-11 19:55:35.845]  Input: 힘 있게 직선에 느낌으로 갔다면 이번에도 똑같이 심정으로 겪었죠 하면 안 되시고요~______
[2020-05-11 19:55:41.657]  Step 143951  [3.406 sec/step, loss=0.10307, avg_loss=0.09550, mel_loss=0.04860, linear_loss=0.05447]
[2020-05-11 19:55:44.313]  Step 143952  [3.423 sec/step, loss=0.09906, avg_loss=0.09561, mel_loss=0.04544, linear_loss=0.05362]
[2020-05-11 19:55:47.701]  Step 143953  [3.438 sec/step, loss=0.09876, avg_loss=0.09564, mel_loss=0.04574, linear_loss=0.05303]
[2020-05-11 19:55:55.280]  Step 143954  [3.500 sec/step, loss=0.10248, avg_loss=0.09576, mel_loss=0.04845, linear_loss=0.05403]
[2020-05-11 19:55:57.455]  Step 143955  [3.490 sec/step, loss=0.09563, avg_loss=0.09570, mel_loss=0.04357, linear_loss=0.05205]
[2020-05-11 19:55:59.231]  Step 143956  [3.377 sec/step, loss=0.09539, avg_loss=0.09575, mel_loss=0.04303, linear_loss=0.05236]
[2020-05-11 19:55:59.976]  Step 143957  [3.343 sec/step, loss=0.07866, avg_loss=0.09551, mel_loss=0.03536, linear_loss=0.04330]
[2020-05-11 19:56:01.128]  Step 143958  [3.338 sec/step, loss=0.08921, avg_loss=0.09548, mel_loss=0.03930, linear_loss=0.04990]
[2020-05-11 19:56:01.992]  Generated 32 batches of size 32 in 2.010 sec
[2020-05-11 19:56:02.004]  Step 143959  [3.324 sec/step, loss=0.08354, avg_loss=0.09535, mel_loss=0.03706, linear_loss=0.04648]
[2020-05-11 19:56:05.177]  Step 143960  [3.345 sec/step, loss=0.10138, avg_loss=0.09547, mel_loss=0.04661, linear_loss=0.05477]
[2020-05-11 19:56:14.168]  Step 143961  [3.401 sec/step, loss=0.10401, avg_loss=0.09553, mel_loss=0.04986, linear_loss=0.05415]
[2020-05-11 19:56:15.047]  Step 143962  [3.392 sec/step, loss=0.08815, avg_loss=0.09546, mel_loss=0.03936, linear_loss=0.04878]
[2020-05-11 19:56:16.497]  Step 143963  [3.369 sec/step, loss=0.09003, avg_loss=0.09533, mel_loss=0.04043, linear_loss=0.04960]
[2020-05-11 19:56:20.153]  Step 143964  [3.359 sec/step, loss=0.10251, avg_loss=0.09531, mel_loss=0.04734, linear_loss=0.05517]
[2020-05-11 19:56:21.943]  Step 143965  [3.320 sec/step, loss=0.09493, avg_loss=0.09522, mel_loss=0.04269, linear_loss=0.05224]
[2020-05-11 19:56:23.233]  Step 143966  [3.269 sec/step, loss=0.08660, avg_loss=0.09505, mel_loss=0.03909, linear_loss=0.04751]
[2020-05-11 19:56:24.920]  Step 143967  [3.278 sec/step, loss=0.09221, avg_loss=0.09515, mel_loss=0.04166, linear_loss=0.05056]
[2020-05-11 19:56:26.122]  Step 143968  [3.252 sec/step, loss=0.08854, avg_loss=0.09503, mel_loss=0.03937, linear_loss=0.04918]
[2020-05-11 19:56:27.070]  Step 143969  [3.244 sec/step, loss=0.08883, avg_loss=0.09498, mel_loss=0.03929, linear_loss=0.04954]
[2020-05-11 19:56:29.198]  Step 143970  [3.246 sec/step, loss=0.09731, avg_loss=0.09498, mel_loss=0.04422, linear_loss=0.05309]
[2020-05-11 19:56:32.156]  Step 143971  [3.244 sec/step, loss=0.10165, avg_loss=0.09499, mel_loss=0.04665, linear_loss=0.05500]
[2020-05-11 19:56:36.499]  Step 143972  [3.259 sec/step, loss=0.10148, avg_loss=0.09499, mel_loss=0.04715, linear_loss=0.05432]
[2020-05-11 19:56:40.615]  Step 143973  [3.248 sec/step, loss=0.09929, avg_loss=0.09495, mel_loss=0.04558, linear_loss=0.05371]
[2020-05-11 19:56:45.302]  Step 143974  [3.221 sec/step, loss=0.10238, avg_loss=0.09494, mel_loss=0.04725, linear_loss=0.05513]
[2020-05-11 19:56:46.103]  Step 143975  [3.217 sec/step, loss=0.07956, avg_loss=0.09485, mel_loss=0.03507, linear_loss=0.04449]
[2020-05-11 19:56:59.056]  Step 143976  [3.330 sec/step, loss=0.08711, avg_loss=0.09476, mel_loss=0.04206, linear_loss=0.04504]
[2020-05-11 19:57:06.394]  Step 143977  [3.375 sec/step, loss=0.10362, avg_loss=0.09481, mel_loss=0.04889, linear_loss=0.05473]
[2020-05-11 19:57:07.865]  Step 143978  [3.376 sec/step, loss=0.09321, avg_loss=0.09481, mel_loss=0.04180, linear_loss=0.05141]
[2020-05-11 19:57:09.846]  Step 143979  [3.376 sec/step, loss=0.09677, avg_loss=0.09485, mel_loss=0.04362, linear_loss=0.05316]
[2020-05-11 19:57:15.143]  Step 143980  [3.412 sec/step, loss=0.10168, avg_loss=0.09493, mel_loss=0.04754, linear_loss=0.05414]
[2020-05-11 19:57:20.749]  Step 143981  [3.455 sec/step, loss=0.10252, avg_loss=0.09505, mel_loss=0.04792, linear_loss=0.05459]
[2020-05-11 19:57:23.025]  Step 143982  [3.468 sec/step, loss=0.09677, avg_loss=0.09517, mel_loss=0.04425, linear_loss=0.05253]
[2020-05-11 19:57:24.775]  Step 143983  [3.443 sec/step, loss=0.09218, avg_loss=0.09508, mel_loss=0.04135, linear_loss=0.05083]
[2020-05-11 19:57:26.143]  Step 143984  [3.415 sec/step, loss=0.09071, avg_loss=0.09497, mel_loss=0.04076, linear_loss=0.04995]
[2020-05-11 19:57:28.587]  Step 143985  [3.379 sec/step, loss=0.09657, avg_loss=0.09492, mel_loss=0.04355, linear_loss=0.05302]
[2020-05-11 19:57:29.900]  Step 143986  [3.356 sec/step, loss=0.09123, avg_loss=0.09481, mel_loss=0.04093, linear_loss=0.05029]
[2020-05-11 19:57:31.799]  Step 143987  [3.355 sec/step, loss=0.09447, avg_loss=0.09478, mel_loss=0.04265, linear_loss=0.05182]
[2020-05-11 19:57:35.189]  Step 143988  [3.371 sec/step, loss=0.10127, avg_loss=0.09487, mel_loss=0.04667, linear_loss=0.05460]
[2020-05-11 19:57:43.383]  Step 143989  [3.439 sec/step, loss=0.10083, avg_loss=0.09494, mel_loss=0.04788, linear_loss=0.05294]
[2020-05-11 19:57:44.288]  Step 143990  [3.441 sec/step, loss=0.07787, avg_loss=0.09492, mel_loss=0.03525, linear_loss=0.04262]
[2020-05-11 19:57:45.433]  Generated 32 batches of size 32 in 2.045 sec
[2020-05-11 19:57:51.075]  Step 143991  [3.501 sec/step, loss=0.10179, avg_loss=0.09508, mel_loss=0.04801, linear_loss=0.05378]
[2020-05-11 19:57:52.173]  Step 143992  [3.481 sec/step, loss=0.08659, avg_loss=0.09494, mel_loss=0.03841, linear_loss=0.04818]
[2020-05-11 19:57:55.724]  Step 143993  [3.492 sec/step, loss=0.09996, avg_loss=0.09496, mel_loss=0.04618, linear_loss=0.05378]
[2020-05-11 19:57:58.527]  Step 143994  [3.498 sec/step, loss=0.09752, avg_loss=0.09498, mel_loss=0.04452, linear_loss=0.05300]
[2020-05-11 19:57:59.134]  Step 143995  [3.457 sec/step, loss=0.07266, avg_loss=0.09469, mel_loss=0.03234, linear_loss=0.04032]
[2020-05-11 19:58:00.232]  Step 143996  [3.458 sec/step, loss=0.08432, avg_loss=0.09468, mel_loss=0.03736, linear_loss=0.04696]
[2020-05-11 19:58:03.378]  Step 143997  [3.455 sec/step, loss=0.09775, avg_loss=0.09466, mel_loss=0.04521, linear_loss=0.05253]
[2020-05-11 19:58:07.110]  Step 143998  [3.419 sec/step, loss=0.10215, avg_loss=0.09465, mel_loss=0.04735, linear_loss=0.05480]
[2020-05-11 19:58:07.646]  Step 143999  [3.391 sec/step, loss=0.07591, avg_loss=0.09439, mel_loss=0.03440, linear_loss=0.04152]
[2020-05-11 19:58:10.759]  Step 144000  [3.340 sec/step, loss=0.10029, avg_loss=0.09439, mel_loss=0.04640, linear_loss=0.05389]
[2020-05-11 19:58:10.759]  Writing summary at step: 144000
[2020-05-11 19:58:12.162]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144000
[2020-05-11 19:58:13.456]  Saving audio and alignment...
[2020-05-11 19:58:16.895]  Input: 문의 사항 문제점 있으면 전화 주세요~______
[2020-05-11 19:58:21.001]  Step 144001  [3.232 sec/step, loss=0.09986, avg_loss=0.09462, mel_loss=0.04608, linear_loss=0.05377]
[2020-05-11 19:58:21.846]  Step 144002  [3.217 sec/step, loss=0.08490, avg_loss=0.09448, mel_loss=0.03738, linear_loss=0.04752]
[2020-05-11 19:58:22.895]  Step 144003  [3.198 sec/step, loss=0.08750, avg_loss=0.09437, mel_loss=0.03906, linear_loss=0.04844]
[2020-05-11 19:58:24.468]  Step 144004  [3.202 sec/step, loss=0.09140, avg_loss=0.09441, mel_loss=0.04115, linear_loss=0.05025]
[2020-05-11 19:58:27.194]  Step 144005  [3.204 sec/step, loss=0.09934, avg_loss=0.09442, mel_loss=0.04543, linear_loss=0.05391]
[2020-05-11 19:58:33.495]  Step 144006  [3.251 sec/step, loss=0.10332, avg_loss=0.09450, mel_loss=0.04843, linear_loss=0.05490]
[2020-05-11 19:58:35.869]  Step 144007  [3.132 sec/step, loss=0.09488, avg_loss=0.09469, mel_loss=0.04290, linear_loss=0.05198]
[2020-05-11 19:58:38.775]  Step 144008  [3.064 sec/step, loss=0.10010, avg_loss=0.09467, mel_loss=0.04551, linear_loss=0.05458]
[2020-05-11 19:58:39.751]  Step 144009  [3.034 sec/step, loss=0.08684, avg_loss=0.09457, mel_loss=0.03869, linear_loss=0.04814]
[2020-05-11 19:58:40.924]  Step 144010  [3.028 sec/step, loss=0.08689, avg_loss=0.09455, mel_loss=0.03892, linear_loss=0.04797]
[2020-05-11 19:58:44.028]  Step 144011  [3.047 sec/step, loss=0.10244, avg_loss=0.09477, mel_loss=0.04717, linear_loss=0.05527]
[2020-05-11 19:58:46.171]  Step 144012  [3.050 sec/step, loss=0.09519, avg_loss=0.09480, mel_loss=0.04283, linear_loss=0.05237]
[2020-05-11 19:58:51.088]  Step 144013  [3.087 sec/step, loss=0.10014, avg_loss=0.09498, mel_loss=0.04658, linear_loss=0.05357]
[2020-05-11 19:58:52.446]  Step 144014  [3.063 sec/step, loss=0.08832, avg_loss=0.09488, mel_loss=0.03927, linear_loss=0.04905]
[2020-05-11 19:58:54.047]  Step 144015  [3.065 sec/step, loss=0.09667, avg_loss=0.09495, mel_loss=0.04366, linear_loss=0.05300]
[2020-05-11 19:58:58.601]  Step 144016  [3.068 sec/step, loss=0.10208, avg_loss=0.09498, mel_loss=0.04749, linear_loss=0.05459]
[2020-05-11 19:59:00.352]  Step 144017  [3.075 sec/step, loss=0.09505, avg_loss=0.09504, mel_loss=0.04243, linear_loss=0.05262]
[2020-05-11 19:59:03.897]  Step 144018  [3.101 sec/step, loss=0.10005, avg_loss=0.09520, mel_loss=0.04599, linear_loss=0.05406]
[2020-05-11 19:59:04.665]  Step 144019  [3.054 sec/step, loss=0.08630, avg_loss=0.09505, mel_loss=0.03827, linear_loss=0.04802]
[2020-05-11 19:59:06.423]  Generated 32 batches of size 32 in 1.752 sec
[2020-05-11 19:59:07.198]  Step 144020  [3.021 sec/step, loss=0.09595, avg_loss=0.09498, mel_loss=0.04356, linear_loss=0.05239]
[2020-05-11 19:59:10.626]  Step 144021  [3.009 sec/step, loss=0.09869, avg_loss=0.09495, mel_loss=0.04518, linear_loss=0.05351]
[2020-05-11 19:59:24.767]  Step 144022  [3.128 sec/step, loss=0.07902, avg_loss=0.09479, mel_loss=0.03834, linear_loss=0.04068]
[2020-05-11 19:59:33.622]  Step 144023  [3.212 sec/step, loss=0.10312, avg_loss=0.09499, mel_loss=0.04925, linear_loss=0.05387]
[2020-05-11 19:59:35.546]  Step 144024  [3.210 sec/step, loss=0.09440, avg_loss=0.09496, mel_loss=0.04232, linear_loss=0.05208]
[2020-05-11 19:59:43.058]  Step 144025  [3.271 sec/step, loss=0.10126, avg_loss=0.09506, mel_loss=0.04768, linear_loss=0.05359]
[2020-05-11 19:59:43.898]  Step 144026  [3.246 sec/step, loss=0.08260, avg_loss=0.09489, mel_loss=0.03647, linear_loss=0.04613]
[2020-05-11 19:59:49.395]  Step 144027  [3.283 sec/step, loss=0.10109, avg_loss=0.09495, mel_loss=0.04725, linear_loss=0.05383]
[2020-05-11 19:59:53.180]  Step 144028  [3.289 sec/step, loss=0.10376, avg_loss=0.09497, mel_loss=0.04795, linear_loss=0.05581]
[2020-05-11 19:59:55.154]  Step 144029  [3.281 sec/step, loss=0.09499, avg_loss=0.09493, mel_loss=0.04277, linear_loss=0.05221]
[2020-05-11 19:59:57.813]  Step 144030  [3.272 sec/step, loss=0.09680, avg_loss=0.09486, mel_loss=0.04462, linear_loss=0.05219]
[2020-05-11 20:00:01.169]  Step 144031  [3.287 sec/step, loss=0.09924, avg_loss=0.09491, mel_loss=0.04552, linear_loss=0.05372]
[2020-05-11 20:00:04.551]  Step 144032  [3.240 sec/step, loss=0.10010, avg_loss=0.09488, mel_loss=0.04610, linear_loss=0.05400]
[2020-05-11 20:00:05.352]  Step 144033  [3.228 sec/step, loss=0.08284, avg_loss=0.09476, mel_loss=0.03659, linear_loss=0.04625]
[2020-05-11 20:00:09.064]  Step 144034  [3.250 sec/step, loss=0.10113, avg_loss=0.09485, mel_loss=0.04668, linear_loss=0.05445]
[2020-05-11 20:00:13.937]  Step 144035  [3.270 sec/step, loss=0.10072, avg_loss=0.09484, mel_loss=0.04670, linear_loss=0.05402]
[2020-05-11 20:00:19.553]  Step 144036  [3.282 sec/step, loss=0.10193, avg_loss=0.09485, mel_loss=0.04785, linear_loss=0.05408]
[2020-05-11 20:00:20.357]  Step 144037  [3.253 sec/step, loss=0.07898, avg_loss=0.09462, mel_loss=0.03544, linear_loss=0.04354]
[2020-05-11 20:00:21.427]  Step 144038  [3.243 sec/step, loss=0.08637, avg_loss=0.09453, mel_loss=0.03839, linear_loss=0.04798]
[2020-05-11 20:00:25.709]  Step 144039  [3.154 sec/step, loss=0.10101, avg_loss=0.09464, mel_loss=0.04678, linear_loss=0.05423]
[2020-05-11 20:00:28.057]  Step 144040  [3.167 sec/step, loss=0.09622, avg_loss=0.09476, mel_loss=0.04388, linear_loss=0.05233]
[2020-05-11 20:00:35.555]  Step 144041  [3.235 sec/step, loss=0.10241, avg_loss=0.09500, mel_loss=0.04843, linear_loss=0.05398]
[2020-05-11 20:00:36.549]  Step 144042  [3.202 sec/step, loss=0.08662, avg_loss=0.09482, mel_loss=0.03845, linear_loss=0.04817]
[2020-05-11 20:00:38.724]  Step 144043  [3.197 sec/step, loss=0.09798, avg_loss=0.09484, mel_loss=0.04442, linear_loss=0.05355]
[2020-05-11 20:00:52.919]  Step 144044  [3.320 sec/step, loss=0.07830, avg_loss=0.09468, mel_loss=0.03787, linear_loss=0.04043]
[2020-05-11 20:00:55.370]  Step 144045  [3.328 sec/step, loss=0.09630, avg_loss=0.09469, mel_loss=0.04346, linear_loss=0.05284]
[2020-05-11 20:00:56.512]  Step 144046  [3.316 sec/step, loss=0.08747, avg_loss=0.09459, mel_loss=0.03873, linear_loss=0.04874]
[2020-05-11 20:01:01.468]  Step 144047  [3.298 sec/step, loss=0.10208, avg_loss=0.09457, mel_loss=0.04781, linear_loss=0.05427]
[2020-05-11 20:01:09.904]  Step 144048  [3.334 sec/step, loss=0.09856, avg_loss=0.09454, mel_loss=0.04686, linear_loss=0.05171]
[2020-05-11 20:01:16.082]  Step 144049  [3.354 sec/step, loss=0.10198, avg_loss=0.09456, mel_loss=0.04824, linear_loss=0.05374]
[2020-05-11 20:01:19.380]  Step 144050  [3.374 sec/step, loss=0.09995, avg_loss=0.09464, mel_loss=0.04570, linear_loss=0.05425]
[2020-05-11 20:01:19.380]  Writing summary at step: 144050
[2020-05-11 20:01:19.950]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144050
[2020-05-11 20:01:21.248]  Saving audio and alignment...
[2020-05-11 20:01:23.285]  Generated 32 batches of size 32 in 1.514 sec
[2020-05-11 20:01:24.686]  Input: 그래서 변화를 주셔야 합니다~_________
[2020-05-11 20:01:26.545]  Step 144051  [3.334 sec/step, loss=0.09492, avg_loss=0.09455, mel_loss=0.04272, linear_loss=0.05220]
[2020-05-11 20:01:28.055]  Step 144052  [3.323 sec/step, loss=0.09044, avg_loss=0.09447, mel_loss=0.04086, linear_loss=0.04958]
[2020-05-11 20:01:30.145]  Step 144053  [3.310 sec/step, loss=0.09544, avg_loss=0.09443, mel_loss=0.04288, linear_loss=0.05256]
[2020-05-11 20:01:31.525]  Step 144054  [3.248 sec/step, loss=0.08823, avg_loss=0.09429, mel_loss=0.03948, linear_loss=0.04875]
[2020-05-11 20:01:35.678]  Step 144055  [3.268 sec/step, loss=0.09968, avg_loss=0.09433, mel_loss=0.04584, linear_loss=0.05385]
[2020-05-11 20:01:37.299]  Step 144056  [3.266 sec/step, loss=0.09349, avg_loss=0.09431, mel_loss=0.04224, linear_loss=0.05125]
[2020-05-11 20:01:38.553]  Step 144057  [3.271 sec/step, loss=0.08849, avg_loss=0.09441, mel_loss=0.03945, linear_loss=0.04904]
[2020-05-11 20:01:41.452]  Step 144058  [3.289 sec/step, loss=0.09972, avg_loss=0.09452, mel_loss=0.04529, linear_loss=0.05444]
[2020-05-11 20:01:44.328]  Step 144059  [3.309 sec/step, loss=0.09865, avg_loss=0.09467, mel_loss=0.04537, linear_loss=0.05327]
[2020-05-11 20:01:45.767]  Step 144060  [3.291 sec/step, loss=0.09448, avg_loss=0.09460, mel_loss=0.04251, linear_loss=0.05196]
[2020-05-11 20:01:49.427]  Step 144061  [3.238 sec/step, loss=0.10283, avg_loss=0.09459, mel_loss=0.04739, linear_loss=0.05545]
[2020-05-11 20:01:51.827]  Step 144062  [3.253 sec/step, loss=0.09701, avg_loss=0.09468, mel_loss=0.04421, linear_loss=0.05280]
[2020-05-11 20:01:52.829]  Step 144063  [3.249 sec/step, loss=0.08603, avg_loss=0.09464, mel_loss=0.03817, linear_loss=0.04786]
[2020-05-11 20:01:54.790]  Step 144064  [3.232 sec/step, loss=0.09444, avg_loss=0.09456, mel_loss=0.04254, linear_loss=0.05189]
[2020-05-11 20:02:00.115]  Step 144065  [3.267 sec/step, loss=0.10207, avg_loss=0.09463, mel_loss=0.04752, linear_loss=0.05455]
[2020-05-11 20:02:03.286]  Step 144066  [3.286 sec/step, loss=0.10005, avg_loss=0.09476, mel_loss=0.04569, linear_loss=0.05437]
[2020-05-11 20:02:04.194]  Step 144067  [3.278 sec/step, loss=0.08428, avg_loss=0.09468, mel_loss=0.03747, linear_loss=0.04681]
[2020-05-11 20:02:05.424]  Step 144068  [3.278 sec/step, loss=0.08763, avg_loss=0.09467, mel_loss=0.03917, linear_loss=0.04846]
[2020-05-11 20:02:12.090]  Step 144069  [3.336 sec/step, loss=0.10321, avg_loss=0.09482, mel_loss=0.04859, linear_loss=0.05463]
[2020-05-11 20:02:17.812]  Step 144070  [3.371 sec/step, loss=0.10358, avg_loss=0.09488, mel_loss=0.04848, linear_loss=0.05510]
[2020-05-11 20:02:18.926]  Step 144071  [3.353 sec/step, loss=0.08682, avg_loss=0.09473, mel_loss=0.03830, linear_loss=0.04851]
[2020-05-11 20:02:20.712]  Step 144072  [3.327 sec/step, loss=0.09489, avg_loss=0.09466, mel_loss=0.04258, linear_loss=0.05231]
[2020-05-11 20:02:22.187]  Step 144073  [3.301 sec/step, loss=0.09342, avg_loss=0.09461, mel_loss=0.04148, linear_loss=0.05194]
[2020-05-11 20:02:29.121]  Step 144074  [3.324 sec/step, loss=0.10411, avg_loss=0.09462, mel_loss=0.04941, linear_loss=0.05470]
[2020-05-11 20:02:29.951]  Step 144075  [3.324 sec/step, loss=0.08000, avg_loss=0.09463, mel_loss=0.03579, linear_loss=0.04422]
[2020-05-11 20:02:30.677]  Step 144076  [3.202 sec/step, loss=0.08381, avg_loss=0.09459, mel_loss=0.03666, linear_loss=0.04715]
[2020-05-11 20:02:39.391]  Step 144077  [3.215 sec/step, loss=0.10196, avg_loss=0.09458, mel_loss=0.04865, linear_loss=0.05331]
[2020-05-11 20:02:44.079]  Step 144078  [3.247 sec/step, loss=0.10263, avg_loss=0.09467, mel_loss=0.04753, linear_loss=0.05510]
[2020-05-11 20:02:45.817]  Step 144079  [3.245 sec/step, loss=0.09182, avg_loss=0.09462, mel_loss=0.04144, linear_loss=0.05038]
[2020-05-11 20:02:49.384]  Step 144080  [3.228 sec/step, loss=0.09782, avg_loss=0.09458, mel_loss=0.04486, linear_loss=0.05296]
[2020-05-11 20:02:51.559]  Step 144081  [3.193 sec/step, loss=0.09696, avg_loss=0.09453, mel_loss=0.04430, linear_loss=0.05266]
[2020-05-11 20:02:53.239]  Generated 32 batches of size 32 in 1.675 sec
[2020-05-11 20:02:55.597]  Step 144082  [3.211 sec/step, loss=0.10057, avg_loss=0.09457, mel_loss=0.04656, linear_loss=0.05402]
[2020-05-11 20:02:58.225]  Step 144083  [3.220 sec/step, loss=0.09892, avg_loss=0.09463, mel_loss=0.04511, linear_loss=0.05382]
[2020-05-11 20:03:11.578]  Step 144084  [3.340 sec/step, loss=0.08589, avg_loss=0.09459, mel_loss=0.04170, linear_loss=0.04419]
[2020-05-11 20:03:12.180]  Step 144085  [3.321 sec/step, loss=0.07534, avg_loss=0.09437, mel_loss=0.03392, linear_loss=0.04142]
[2020-05-11 20:03:14.255]  Step 144086  [3.329 sec/step, loss=0.09416, avg_loss=0.09440, mel_loss=0.04250, linear_loss=0.05166]
[2020-05-11 20:03:18.718]  Step 144087  [3.354 sec/step, loss=0.10181, avg_loss=0.09448, mel_loss=0.04758, linear_loss=0.05423]
[2020-05-11 20:03:20.071]  Step 144088  [3.334 sec/step, loss=0.09387, avg_loss=0.09440, mel_loss=0.04214, linear_loss=0.05174]
[2020-05-11 20:03:22.602]  Step 144089  [3.277 sec/step, loss=0.09772, avg_loss=0.09437, mel_loss=0.04447, linear_loss=0.05325]
[2020-05-11 20:03:26.762]  Step 144090  [3.310 sec/step, loss=0.10174, avg_loss=0.09461, mel_loss=0.04695, linear_loss=0.05479]
[2020-05-11 20:03:30.162]  Step 144091  [3.276 sec/step, loss=0.09652, avg_loss=0.09456, mel_loss=0.04369, linear_loss=0.05284]
[2020-05-11 20:03:35.639]  Step 144092  [3.320 sec/step, loss=0.09865, avg_loss=0.09468, mel_loss=0.04522, linear_loss=0.05342]
[2020-05-11 20:03:42.272]  Step 144093  [3.351 sec/step, loss=0.10042, avg_loss=0.09468, mel_loss=0.04627, linear_loss=0.05415]
[2020-05-11 20:03:43.502]  Step 144094  [3.335 sec/step, loss=0.08940, avg_loss=0.09460, mel_loss=0.03960, linear_loss=0.04980]
[2020-05-11 20:03:48.280]  Step 144095  [3.377 sec/step, loss=0.10164, avg_loss=0.09489, mel_loss=0.04724, linear_loss=0.05440]
[2020-05-11 20:03:52.007]  Step 144096  [3.403 sec/step, loss=0.10141, avg_loss=0.09506, mel_loss=0.04653, linear_loss=0.05488]
[2020-05-11 20:03:53.137]  Step 144097  [3.383 sec/step, loss=0.08943, avg_loss=0.09498, mel_loss=0.03966, linear_loss=0.04977]
[2020-05-11 20:03:56.459]  Step 144098  [3.379 sec/step, loss=0.10060, avg_loss=0.09496, mel_loss=0.04645, linear_loss=0.05414]
[2020-05-11 20:03:59.539]  Step 144099  [3.404 sec/step, loss=0.09997, avg_loss=0.09520, mel_loss=0.04598, linear_loss=0.05400]
[2020-05-11 20:04:00.940]  Step 144100  [3.387 sec/step, loss=0.09248, avg_loss=0.09513, mel_loss=0.04144, linear_loss=0.05104]
[2020-05-11 20:04:00.940]  Writing summary at step: 144100
[2020-05-11 20:04:02.680]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144100
[2020-05-11 20:04:03.996]  Saving audio and alignment...
[2020-05-11 20:04:08.075]  Input: 이렇게 아이콘택트까지 쓸 줄 압니다~______________
[2020-05-11 20:04:12.997]  Step 144101  [3.395 sec/step, loss=0.09865, avg_loss=0.09511, mel_loss=0.04557, linear_loss=0.05308]
[2020-05-11 20:04:15.026]  Step 144102  [3.407 sec/step, loss=0.09722, avg_loss=0.09524, mel_loss=0.04391, linear_loss=0.05330]
[2020-05-11 20:04:23.521]  Step 144103  [3.482 sec/step, loss=0.09993, avg_loss=0.09536, mel_loss=0.04720, linear_loss=0.05272]
[2020-05-11 20:04:24.524]  Step 144104  [3.476 sec/step, loss=0.08259, avg_loss=0.09527, mel_loss=0.03651, linear_loss=0.04609]
[2020-05-11 20:04:26.933]  Step 144105  [3.473 sec/step, loss=0.09643, avg_loss=0.09524, mel_loss=0.04387, linear_loss=0.05256]
[2020-05-11 20:04:27.571]  Step 144106  [3.416 sec/step, loss=0.07809, avg_loss=0.09499, mel_loss=0.03519, linear_loss=0.04290]
[2020-05-11 20:04:28.101]  Step 144107  [3.398 sec/step, loss=0.08059, avg_loss=0.09485, mel_loss=0.03623, linear_loss=0.04436]
[2020-05-11 20:04:29.562]  Step 144108  [3.383 sec/step, loss=0.09127, avg_loss=0.09476, mel_loss=0.04094, linear_loss=0.05033]
[2020-05-11 20:04:36.866]  Step 144109  [3.446 sec/step, loss=0.10379, avg_loss=0.09493, mel_loss=0.04904, linear_loss=0.05475]
[2020-05-11 20:04:38.524]  Step 144110  [3.451 sec/step, loss=0.09422, avg_loss=0.09500, mel_loss=0.04271, linear_loss=0.05151]
[2020-05-11 20:04:40.501]  Step 144111  [3.440 sec/step, loss=0.09481, avg_loss=0.09493, mel_loss=0.04270, linear_loss=0.05211]
[2020-05-11 20:04:42.205]  Generated 32 batches of size 32 in 1.699 sec
[2020-05-11 20:04:47.187]  Step 144112  [3.485 sec/step, loss=0.09919, avg_loss=0.09497, mel_loss=0.04663, linear_loss=0.05256]
[2020-05-11 20:05:00.554]  Step 144113  [3.570 sec/step, loss=0.08434, avg_loss=0.09481, mel_loss=0.04050, linear_loss=0.04384]
[2020-05-11 20:05:01.859]  Step 144114  [3.569 sec/step, loss=0.08792, avg_loss=0.09480, mel_loss=0.03947, linear_loss=0.04845]
[2020-05-11 20:05:02.820]  Step 144115  [3.563 sec/step, loss=0.08801, avg_loss=0.09472, mel_loss=0.03919, linear_loss=0.04882]
[2020-05-11 20:05:03.700]  Step 144116  [3.526 sec/step, loss=0.08010, avg_loss=0.09450, mel_loss=0.03551, linear_loss=0.04460]
[2020-05-11 20:05:06.437]  Step 144117  [3.536 sec/step, loss=0.09706, avg_loss=0.09452, mel_loss=0.04431, linear_loss=0.05275]
[2020-05-11 20:05:11.835]  Step 144118  [3.555 sec/step, loss=0.10005, avg_loss=0.09452, mel_loss=0.04653, linear_loss=0.05352]
[2020-05-11 20:05:14.741]  Step 144119  [3.576 sec/step, loss=0.09982, avg_loss=0.09465, mel_loss=0.04540, linear_loss=0.05442]
[2020-05-11 20:05:16.501]  Step 144120  [3.568 sec/step, loss=0.09414, avg_loss=0.09464, mel_loss=0.04225, linear_loss=0.05189]
[2020-05-11 20:05:17.889]  Step 144121  [3.548 sec/step, loss=0.08819, avg_loss=0.09453, mel_loss=0.03919, linear_loss=0.04900]
[2020-05-11 20:05:21.297]  Step 144122  [3.441 sec/step, loss=0.09737, avg_loss=0.09471, mel_loss=0.04461, linear_loss=0.05276]
[2020-05-11 20:05:24.985]  Step 144123  [3.389 sec/step, loss=0.10219, avg_loss=0.09471, mel_loss=0.04727, linear_loss=0.05493]
[2020-05-11 20:05:25.775]  Step 144124  [3.378 sec/step, loss=0.07249, avg_loss=0.09449, mel_loss=0.03288, linear_loss=0.03962]
[2020-05-11 20:05:34.935]  Step 144125  [3.394 sec/step, loss=0.10238, avg_loss=0.09450, mel_loss=0.04901, linear_loss=0.05337]
[2020-05-11 20:05:36.158]  Step 144126  [3.398 sec/step, loss=0.08701, avg_loss=0.09454, mel_loss=0.03860, linear_loss=0.04841]
[2020-05-11 20:05:37.909]  Step 144127  [3.360 sec/step, loss=0.09433, avg_loss=0.09447, mel_loss=0.04235, linear_loss=0.05198]
[2020-05-11 20:05:40.038]  Step 144128  [3.344 sec/step, loss=0.09646, avg_loss=0.09440, mel_loss=0.04389, linear_loss=0.05257]
[2020-05-11 20:05:44.419]  Step 144129  [3.368 sec/step, loss=0.10233, avg_loss=0.09447, mel_loss=0.04766, linear_loss=0.05467]
[2020-05-11 20:05:58.609]  Step 144130  [3.483 sec/step, loss=0.08330, avg_loss=0.09434, mel_loss=0.04061, linear_loss=0.04269]
[2020-05-11 20:06:02.163]  Step 144131  [3.485 sec/step, loss=0.10233, avg_loss=0.09437, mel_loss=0.04721, linear_loss=0.05512]
[2020-05-11 20:06:03.796]  Step 144132  [3.468 sec/step, loss=0.09430, avg_loss=0.09431, mel_loss=0.04220, linear_loss=0.05209]
[2020-05-11 20:06:10.446]  Step 144133  [3.526 sec/step, loss=0.10377, avg_loss=0.09452, mel_loss=0.04892, linear_loss=0.05485]
[2020-05-11 20:06:11.290]  Step 144134  [3.498 sec/step, loss=0.08242, avg_loss=0.09433, mel_loss=0.03660, linear_loss=0.04582]
[2020-05-11 20:06:13.710]  Step 144135  [3.473 sec/step, loss=0.09799, avg_loss=0.09431, mel_loss=0.04450, linear_loss=0.05349]
[2020-05-11 20:06:14.944]  Step 144136  [3.429 sec/step, loss=0.09139, avg_loss=0.09420, mel_loss=0.04082, linear_loss=0.05058]
[2020-05-11 20:06:22.686]  Step 144137  [3.499 sec/step, loss=0.10300, avg_loss=0.09444, mel_loss=0.04865, linear_loss=0.05436]
[2020-05-11 20:06:23.509]  Step 144138  [3.496 sec/step, loss=0.07758, avg_loss=0.09435, mel_loss=0.03502, linear_loss=0.04257]
[2020-05-11 20:06:24.531]  Step 144139  [3.464 sec/step, loss=0.08854, avg_loss=0.09423, mel_loss=0.03919, linear_loss=0.04935]
[2020-05-11 20:06:27.616]  Step 144140  [3.471 sec/step, loss=0.10120, avg_loss=0.09428, mel_loss=0.04642, linear_loss=0.05478]
[2020-05-11 20:06:30.553]  Step 144141  [3.425 sec/step, loss=0.09757, avg_loss=0.09423, mel_loss=0.04487, linear_loss=0.05270]
[2020-05-11 20:06:32.668]  Step 144142  [3.437 sec/step, loss=0.09375, avg_loss=0.09430, mel_loss=0.04221, linear_loss=0.05154]
[2020-05-11 20:06:36.170]  Step 144143  [3.450 sec/step, loss=0.10105, avg_loss=0.09433, mel_loss=0.04598, linear_loss=0.05507]
[2020-05-11 20:06:37.856]  Generated 32 batches of size 32 in 1.680 sec
[2020-05-11 20:06:41.123]  Step 144144  [3.357 sec/step, loss=0.09918, avg_loss=0.09454, mel_loss=0.04604, linear_loss=0.05314]
[2020-05-11 20:06:43.859]  Step 144145  [3.360 sec/step, loss=0.09676, avg_loss=0.09455, mel_loss=0.04423, linear_loss=0.05253]
[2020-05-11 20:06:45.472]  Step 144146  [3.365 sec/step, loss=0.09170, avg_loss=0.09459, mel_loss=0.04147, linear_loss=0.05023]
[2020-05-11 20:06:46.516]  Step 144147  [3.326 sec/step, loss=0.08559, avg_loss=0.09442, mel_loss=0.03818, linear_loss=0.04741]
[2020-05-11 20:06:52.469]  Step 144148  [3.301 sec/step, loss=0.10121, avg_loss=0.09445, mel_loss=0.04760, linear_loss=0.05361]
[2020-05-11 20:06:54.305]  Step 144149  [3.258 sec/step, loss=0.09273, avg_loss=0.09436, mel_loss=0.04156, linear_loss=0.05117]
[2020-05-11 20:06:58.456]  Step 144150  [3.266 sec/step, loss=0.10141, avg_loss=0.09437, mel_loss=0.04672, linear_loss=0.05469]
[2020-05-11 20:06:58.456]  Writing summary at step: 144150
[2020-05-11 20:07:03.996]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144150
[2020-05-11 20:07:05.314]  Saving audio and alignment...
[2020-05-11 20:07:09.041]  Input: 이 실제 책과 인터넷 강의는요~________________
[2020-05-11 20:07:10.018]  Step 144151  [3.257 sec/step, loss=0.08701, avg_loss=0.09429, mel_loss=0.03858, linear_loss=0.04844]
[2020-05-11 20:07:14.096]  Step 144152  [3.283 sec/step, loss=0.10065, avg_loss=0.09440, mel_loss=0.04641, linear_loss=0.05423]
[2020-05-11 20:07:17.570]  Step 144153  [3.297 sec/step, loss=0.09932, avg_loss=0.09443, mel_loss=0.04574, linear_loss=0.05358]
[2020-05-11 20:07:19.312]  Step 144154  [3.300 sec/step, loss=0.09366, avg_loss=0.09449, mel_loss=0.04242, linear_loss=0.05124]
[2020-05-11 20:07:22.369]  Step 144155  [3.289 sec/step, loss=0.09992, avg_loss=0.09449, mel_loss=0.04565, linear_loss=0.05426]
[2020-05-11 20:07:23.272]  Step 144156  [3.282 sec/step, loss=0.08580, avg_loss=0.09441, mel_loss=0.03764, linear_loss=0.04816]
[2020-05-11 20:07:24.033]  Step 144157  [3.277 sec/step, loss=0.08345, avg_loss=0.09436, mel_loss=0.03685, linear_loss=0.04660]
[2020-05-11 20:07:25.173]  Step 144158  [3.260 sec/step, loss=0.08812, avg_loss=0.09425, mel_loss=0.03911, linear_loss=0.04902]
[2020-05-11 20:07:28.811]  Step 144159  [3.267 sec/step, loss=0.10165, avg_loss=0.09428, mel_loss=0.04663, linear_loss=0.05502]
[2020-05-11 20:07:31.270]  Step 144160  [3.278 sec/step, loss=0.09547, avg_loss=0.09429, mel_loss=0.04322, linear_loss=0.05226]
[2020-05-11 20:07:31.906]  Step 144161  [3.247 sec/step, loss=0.07986, avg_loss=0.09406, mel_loss=0.03588, linear_loss=0.04398]
[2020-05-11 20:07:39.071]  Step 144162  [3.295 sec/step, loss=0.10454, avg_loss=0.09413, mel_loss=0.04952, linear_loss=0.05502]
[2020-05-11 20:07:44.615]  Step 144163  [3.340 sec/step, loss=0.10306, avg_loss=0.09430, mel_loss=0.04794, linear_loss=0.05512]
[2020-05-11 20:07:46.940]  Step 144164  [3.344 sec/step, loss=0.09495, avg_loss=0.09431, mel_loss=0.04314, linear_loss=0.05181]
[2020-05-11 20:08:01.373]  Step 144165  [3.435 sec/step, loss=0.07772, avg_loss=0.09406, mel_loss=0.03749, linear_loss=0.04023]
[2020-05-11 20:08:02.978]  Step 144166  [3.419 sec/step, loss=0.09028, avg_loss=0.09397, mel_loss=0.04058, linear_loss=0.04970]
[2020-05-11 20:08:04.370]  Step 144167  [3.424 sec/step, loss=0.09228, avg_loss=0.09405, mel_loss=0.04134, linear_loss=0.05094]
[2020-05-11 20:08:05.431]  Step 144168  [3.423 sec/step, loss=0.08884, avg_loss=0.09406, mel_loss=0.03953, linear_loss=0.04931]
[2020-05-11 20:08:11.500]  Step 144169  [3.417 sec/step, loss=0.10164, avg_loss=0.09404, mel_loss=0.04778, linear_loss=0.05386]
[2020-05-11 20:08:13.616]  Step 144170  [3.381 sec/step, loss=0.09468, avg_loss=0.09395, mel_loss=0.04272, linear_loss=0.05196]
[2020-05-11 20:08:15.614]  Step 144171  [3.389 sec/step, loss=0.09506, avg_loss=0.09404, mel_loss=0.04315, linear_loss=0.05191]
[2020-05-11 20:08:17.190]  Step 144172  [3.387 sec/step, loss=0.09106, avg_loss=0.09400, mel_loss=0.04137, linear_loss=0.04970]
[2020-05-11 20:08:21.508]  Step 144173  [3.416 sec/step, loss=0.10133, avg_loss=0.09408, mel_loss=0.04687, linear_loss=0.05446]
[2020-05-11 20:08:23.275]  Generated 32 batches of size 32 in 1.762 sec
[2020-05-11 20:08:24.591]  Step 144174  [3.377 sec/step, loss=0.09839, avg_loss=0.09402, mel_loss=0.04508, linear_loss=0.05331]
[2020-05-11 20:08:28.291]  Step 144175  [3.406 sec/step, loss=0.10134, avg_loss=0.09423, mel_loss=0.04663, linear_loss=0.05471]
[2020-05-11 20:08:33.242]  Step 144176  [3.448 sec/step, loss=0.10274, avg_loss=0.09442, mel_loss=0.04794, linear_loss=0.05480]
[2020-05-11 20:08:42.091]  Step 144177  [3.450 sec/step, loss=0.09840, avg_loss=0.09439, mel_loss=0.04658, linear_loss=0.05182]
[2020-05-11 20:08:46.671]  Step 144178  [3.448 sec/step, loss=0.10204, avg_loss=0.09438, mel_loss=0.04744, linear_loss=0.05460]
[2020-05-11 20:08:47.242]  Step 144179  [3.437 sec/step, loss=0.07374, avg_loss=0.09420, mel_loss=0.03357, linear_loss=0.04017]
[2020-05-11 20:08:49.848]  Step 144180  [3.427 sec/step, loss=0.09874, avg_loss=0.09421, mel_loss=0.04502, linear_loss=0.05372]
[2020-05-11 20:08:51.086]  Step 144181  [3.418 sec/step, loss=0.09089, avg_loss=0.09415, mel_loss=0.04049, linear_loss=0.05039]
[2020-05-11 20:08:52.929]  Step 144182  [3.396 sec/step, loss=0.09416, avg_loss=0.09409, mel_loss=0.04246, linear_loss=0.05170]
[2020-05-11 20:08:55.626]  Step 144183  [3.397 sec/step, loss=0.09502, avg_loss=0.09405, mel_loss=0.04307, linear_loss=0.05195]
[2020-05-11 20:08:56.389]  Step 144184  [3.271 sec/step, loss=0.07930, avg_loss=0.09398, mel_loss=0.03557, linear_loss=0.04373]
[2020-05-11 20:08:59.929]  Step 144185  [3.300 sec/step, loss=0.10095, avg_loss=0.09424, mel_loss=0.04643, linear_loss=0.05452]
[2020-05-11 20:09:00.755]  Step 144186  [3.288 sec/step, loss=0.07919, avg_loss=0.09409, mel_loss=0.03506, linear_loss=0.04413]
[2020-05-11 20:09:04.247]  Step 144187  [3.278 sec/step, loss=0.09773, avg_loss=0.09405, mel_loss=0.04518, linear_loss=0.05254]
[2020-05-11 20:09:08.794]  Step 144188  [3.310 sec/step, loss=0.10148, avg_loss=0.09412, mel_loss=0.04699, linear_loss=0.05449]
[2020-05-11 20:09:14.395]  Step 144189  [3.340 sec/step, loss=0.10018, avg_loss=0.09415, mel_loss=0.04677, linear_loss=0.05341]
[2020-05-11 20:09:15.361]  Step 144190  [3.309 sec/step, loss=0.08929, avg_loss=0.09402, mel_loss=0.03969, linear_loss=0.04961]
[2020-05-11 20:09:16.421]  Step 144191  [3.285 sec/step, loss=0.09041, avg_loss=0.09396, mel_loss=0.04036, linear_loss=0.05006]
[2020-05-11 20:09:19.208]  Step 144192  [3.258 sec/step, loss=0.09756, avg_loss=0.09395, mel_loss=0.04447, linear_loss=0.05309]
[2020-05-11 20:09:19.733]  Step 144193  [3.197 sec/step, loss=0.07369, avg_loss=0.09368, mel_loss=0.03309, linear_loss=0.04060]
[2020-05-11 20:09:23.869]  Step 144194  [3.226 sec/step, loss=0.09993, avg_loss=0.09379, mel_loss=0.04606, linear_loss=0.05387]
[2020-05-11 20:09:26.906]  Step 144195  [3.209 sec/step, loss=0.10026, avg_loss=0.09377, mel_loss=0.04590, linear_loss=0.05436]
[2020-05-11 20:09:33.165]  Step 144196  [3.234 sec/step, loss=0.10081, avg_loss=0.09377, mel_loss=0.04737, linear_loss=0.05343]
[2020-05-11 20:09:36.525]  Step 144197  [3.256 sec/step, loss=0.10100, avg_loss=0.09388, mel_loss=0.04632, linear_loss=0.05468]
[2020-05-11 20:09:37.410]  Step 144198  [3.232 sec/step, loss=0.08346, avg_loss=0.09371, mel_loss=0.03698, linear_loss=0.04648]
[2020-05-11 20:09:41.164]  Step 144199  [3.239 sec/step, loss=0.10083, avg_loss=0.09372, mel_loss=0.04649, linear_loss=0.05434]
[2020-05-11 20:09:42.477]  Step 144200  [3.238 sec/step, loss=0.08959, avg_loss=0.09369, mel_loss=0.04037, linear_loss=0.04922]
[2020-05-11 20:09:42.477]  Writing summary at step: 144200
[2020-05-11 20:09:43.649]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144200
[2020-05-11 20:09:45.003]  Saving audio and alignment...
[2020-05-11 20:09:48.396]  Input: 다음 줄에 한국이 보입니다~__________________
[2020-05-11 20:09:55.540]  Step 144201  [3.260 sec/step, loss=0.10140, avg_loss=0.09372, mel_loss=0.04791, linear_loss=0.05349]
[2020-05-11 20:09:57.404]  Step 144202  [3.258 sec/step, loss=0.09195, avg_loss=0.09367, mel_loss=0.04159, linear_loss=0.05036]
[2020-05-11 20:09:59.125]  Step 144203  [3.191 sec/step, loss=0.09310, avg_loss=0.09360, mel_loss=0.04190, linear_loss=0.05120]
[2020-05-11 20:10:00.757]  Step 144204  [3.197 sec/step, loss=0.09399, avg_loss=0.09371, mel_loss=0.04209, linear_loss=0.05189]
[2020-05-11 20:10:00.907]  Generated 32 batches of size 32 in 1.776 sec
[2020-05-11 20:10:02.867]  Step 144205  [3.194 sec/step, loss=0.09466, avg_loss=0.09369, mel_loss=0.04274, linear_loss=0.05192]
[2020-05-11 20:10:04.181]  Step 144206  [3.201 sec/step, loss=0.09168, avg_loss=0.09383, mel_loss=0.04100, linear_loss=0.05068]
[2020-05-11 20:10:06.569]  Step 144207  [3.219 sec/step, loss=0.09414, avg_loss=0.09397, mel_loss=0.04291, linear_loss=0.05123]
[2020-05-11 20:10:20.749]  Step 144208  [3.347 sec/step, loss=0.07923, avg_loss=0.09385, mel_loss=0.03834, linear_loss=0.04089]
[2020-05-11 20:10:29.360]  Step 144209  [3.360 sec/step, loss=0.10216, avg_loss=0.09383, mel_loss=0.04859, linear_loss=0.05357]
[2020-05-11 20:10:34.712]  Step 144210  [3.397 sec/step, loss=0.10033, avg_loss=0.09389, mel_loss=0.04667, linear_loss=0.05366]
[2020-05-11 20:10:36.321]  Step 144211  [3.393 sec/step, loss=0.09440, avg_loss=0.09389, mel_loss=0.04231, linear_loss=0.05209]
[2020-05-11 20:10:38.509]  Step 144212  [3.348 sec/step, loss=0.09507, avg_loss=0.09385, mel_loss=0.04336, linear_loss=0.05171]
[2020-05-11 20:10:40.551]  Step 144213  [3.235 sec/step, loss=0.09437, avg_loss=0.09395, mel_loss=0.04299, linear_loss=0.05137]
[2020-05-11 20:10:41.763]  Step 144214  [3.234 sec/step, loss=0.09095, avg_loss=0.09398, mel_loss=0.04051, linear_loss=0.05044]
[2020-05-11 20:10:43.355]  Step 144215  [3.240 sec/step, loss=0.09206, avg_loss=0.09402, mel_loss=0.04158, linear_loss=0.05047]
[2020-05-11 20:10:45.153]  Step 144216  [3.249 sec/step, loss=0.09443, avg_loss=0.09416, mel_loss=0.04196, linear_loss=0.05247]
[2020-05-11 20:10:49.736]  Step 144217  [3.268 sec/step, loss=0.10349, avg_loss=0.09422, mel_loss=0.04825, linear_loss=0.05525]
[2020-05-11 20:10:55.273]  Step 144218  [3.269 sec/step, loss=0.10299, avg_loss=0.09425, mel_loss=0.04825, linear_loss=0.05475]
[2020-05-11 20:10:57.973]  Step 144219  [3.267 sec/step, loss=0.09793, avg_loss=0.09423, mel_loss=0.04473, linear_loss=0.05319]
[2020-05-11 20:10:58.778]  Step 144220  [3.257 sec/step, loss=0.08289, avg_loss=0.09412, mel_loss=0.03686, linear_loss=0.04603]
[2020-05-11 20:10:59.470]  Step 144221  [3.251 sec/step, loss=0.08039, avg_loss=0.09404, mel_loss=0.03554, linear_loss=0.04485]
[2020-05-11 20:11:02.036]  Step 144222  [3.242 sec/step, loss=0.09832, avg_loss=0.09405, mel_loss=0.04477, linear_loss=0.05355]
[2020-05-11 20:11:05.388]  Step 144223  [3.239 sec/step, loss=0.10039, avg_loss=0.09404, mel_loss=0.04602, linear_loss=0.05437]
[2020-05-11 20:11:07.833]  Step 144224  [3.255 sec/step, loss=0.09787, avg_loss=0.09429, mel_loss=0.04438, linear_loss=0.05350]
[2020-05-11 20:11:12.924]  Step 144225  [3.215 sec/step, loss=0.10105, avg_loss=0.09428, mel_loss=0.04689, linear_loss=0.05416]
[2020-05-11 20:11:13.931]  Step 144226  [3.212 sec/step, loss=0.08626, avg_loss=0.09427, mel_loss=0.03808, linear_loss=0.04818]
[2020-05-11 20:11:22.175]  Step 144227  [3.277 sec/step, loss=0.10004, avg_loss=0.09433, mel_loss=0.04753, linear_loss=0.05251]
[2020-05-11 20:11:26.490]  Step 144228  [3.299 sec/step, loss=0.10270, avg_loss=0.09439, mel_loss=0.04756, linear_loss=0.05514]
[2020-05-11 20:11:27.918]  Step 144229  [3.270 sec/step, loss=0.09212, avg_loss=0.09429, mel_loss=0.04150, linear_loss=0.05062]
[2020-05-11 20:11:29.265]  Step 144230  [3.141 sec/step, loss=0.09189, avg_loss=0.09437, mel_loss=0.04097, linear_loss=0.05092]
[2020-05-11 20:11:32.128]  Step 144231  [3.134 sec/step, loss=0.10024, avg_loss=0.09435, mel_loss=0.04599, linear_loss=0.05425]
[2020-05-11 20:11:34.383]  Step 144232  [3.141 sec/step, loss=0.09527, avg_loss=0.09436, mel_loss=0.04296, linear_loss=0.05231]
[2020-05-11 20:11:36.340]  Step 144233  [3.094 sec/step, loss=0.09623, avg_loss=0.09429, mel_loss=0.04351, linear_loss=0.05272]
[2020-05-11 20:11:37.411]  Step 144234  [3.096 sec/step, loss=0.08619, avg_loss=0.09432, mel_loss=0.03838, linear_loss=0.04781]
[2020-05-11 20:11:40.695]  Step 144235  [3.105 sec/step, loss=0.10080, avg_loss=0.09435, mel_loss=0.04640, linear_loss=0.05440]
[2020-05-11 20:11:42.309]  Generated 32 batches of size 32 in 1.610 sec
[2020-05-11 20:11:48.184]  Step 144236  [3.167 sec/step, loss=0.10416, avg_loss=0.09448, mel_loss=0.04938, linear_loss=0.05478]
[2020-05-11 20:11:54.888]  Step 144237  [3.157 sec/step, loss=0.10064, avg_loss=0.09446, mel_loss=0.04727, linear_loss=0.05337]
[2020-05-11 20:11:58.274]  Step 144238  [3.182 sec/step, loss=0.09966, avg_loss=0.09468, mel_loss=0.04554, linear_loss=0.05412]
[2020-05-11 20:11:59.931]  Step 144239  [3.189 sec/step, loss=0.09439, avg_loss=0.09473, mel_loss=0.04266, linear_loss=0.05173]
[2020-05-11 20:12:01.043]  Step 144240  [3.169 sec/step, loss=0.09019, avg_loss=0.09462, mel_loss=0.03981, linear_loss=0.05039]
[2020-05-11 20:12:04.661]  Step 144241  [3.176 sec/step, loss=0.10393, avg_loss=0.09469, mel_loss=0.04842, linear_loss=0.05551]
[2020-05-11 20:12:05.418]  Step 144242  [3.162 sec/step, loss=0.07709, avg_loss=0.09452, mel_loss=0.03529, linear_loss=0.04180]
[2020-05-11 20:12:17.390]  Step 144243  [3.247 sec/step, loss=0.09106, avg_loss=0.09442, mel_loss=0.04407, linear_loss=0.04699]
[2020-05-11 20:12:21.493]  Step 144244  [3.238 sec/step, loss=0.10268, avg_loss=0.09446, mel_loss=0.04744, linear_loss=0.05524]
[2020-05-11 20:12:23.260]  Step 144245  [3.229 sec/step, loss=0.09624, avg_loss=0.09445, mel_loss=0.04308, linear_loss=0.05316]
[2020-05-11 20:12:27.573]  Step 144246  [3.256 sec/step, loss=0.10276, avg_loss=0.09456, mel_loss=0.04765, linear_loss=0.05511]
[2020-05-11 20:12:30.989]  Step 144247  [3.279 sec/step, loss=0.09777, avg_loss=0.09468, mel_loss=0.04498, linear_loss=0.05279]
[2020-05-11 20:12:32.216]  Step 144248  [3.232 sec/step, loss=0.09102, avg_loss=0.09458, mel_loss=0.04071, linear_loss=0.05032]
[2020-05-11 20:12:36.279]  Step 144249  [3.254 sec/step, loss=0.10380, avg_loss=0.09469, mel_loss=0.04809, linear_loss=0.05571]
[2020-05-11 20:12:37.748]  Step 144250  [3.228 sec/step, loss=0.09221, avg_loss=0.09460, mel_loss=0.04152, linear_loss=0.05070]
[2020-05-11 20:12:37.748]  Writing summary at step: 144250
[2020-05-11 20:12:43.481]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144250
[2020-05-11 20:12:44.840]  Saving audio and alignment...
[2020-05-11 20:12:49.668]  Input: 시작됐습니다 이게 가장 정석인 발음입니다~______________________
[2020-05-11 20:13:04.111]  Step 144251  [3.362 sec/step, loss=0.08277, avg_loss=0.09456, mel_loss=0.04010, linear_loss=0.04267]
[2020-05-11 20:13:09.397]  Step 144252  [3.374 sec/step, loss=0.10160, avg_loss=0.09457, mel_loss=0.04753, linear_loss=0.05407]
[2020-05-11 20:13:10.394]  Step 144253  [3.350 sec/step, loss=0.08569, avg_loss=0.09443, mel_loss=0.03849, linear_loss=0.04721]
[2020-05-11 20:13:11.957]  Step 144254  [3.348 sec/step, loss=0.09342, avg_loss=0.09443, mel_loss=0.04223, linear_loss=0.05119]
[2020-05-11 20:13:12.525]  Step 144255  [3.323 sec/step, loss=0.07766, avg_loss=0.09421, mel_loss=0.03476, linear_loss=0.04291]
[2020-05-11 20:13:13.278]  Step 144256  [3.321 sec/step, loss=0.08313, avg_loss=0.09418, mel_loss=0.03656, linear_loss=0.04657]
[2020-05-11 20:13:14.678]  Step 144257  [3.328 sec/step, loss=0.09070, avg_loss=0.09425, mel_loss=0.04071, linear_loss=0.04998]
[2020-05-11 20:13:15.685]  Step 144258  [3.326 sec/step, loss=0.08494, avg_loss=0.09422, mel_loss=0.03782, linear_loss=0.04713]
[2020-05-11 20:13:17.726]  Step 144259  [3.311 sec/step, loss=0.09604, avg_loss=0.09416, mel_loss=0.04350, linear_loss=0.05255]
[2020-05-11 20:13:20.151]  Step 144260  [3.310 sec/step, loss=0.09813, avg_loss=0.09419, mel_loss=0.04451, linear_loss=0.05362]
[2020-05-11 20:13:22.998]  Step 144261  [3.332 sec/step, loss=0.09939, avg_loss=0.09439, mel_loss=0.04556, linear_loss=0.05383]
[2020-05-11 20:13:26.200]  Step 144262  [3.293 sec/step, loss=0.10128, avg_loss=0.09435, mel_loss=0.04659, linear_loss=0.05469]
[2020-05-11 20:13:27.043]  Step 144263  [3.246 sec/step, loss=0.08154, avg_loss=0.09414, mel_loss=0.03611, linear_loss=0.04542]
[2020-05-11 20:13:29.915]  Step 144264  [3.251 sec/step, loss=0.09726, avg_loss=0.09416, mel_loss=0.04446, linear_loss=0.05279]
[2020-05-11 20:13:33.846]  Step 144265  [3.146 sec/step, loss=0.10285, avg_loss=0.09441, mel_loss=0.04740, linear_loss=0.05546]
[2020-05-11 20:13:35.671]  Generated 32 batches of size 32 in 1.820 sec
[2020-05-11 20:13:36.277]  Step 144266  [3.154 sec/step, loss=0.09747, avg_loss=0.09448, mel_loss=0.04422, linear_loss=0.05325]
[2020-05-11 20:13:38.666]  Step 144267  [3.164 sec/step, loss=0.09650, avg_loss=0.09453, mel_loss=0.04427, linear_loss=0.05223]
[2020-05-11 20:13:46.510]  Step 144268  [3.232 sec/step, loss=0.10453, avg_loss=0.09468, mel_loss=0.04922, linear_loss=0.05531]
[2020-05-11 20:13:58.261]  Step 144269  [3.289 sec/step, loss=0.10135, avg_loss=0.09468, mel_loss=0.04811, linear_loss=0.05324]
[2020-05-11 20:14:03.960]  Step 144270  [3.325 sec/step, loss=0.10037, avg_loss=0.09474, mel_loss=0.04668, linear_loss=0.05369]
[2020-05-11 20:14:13.179]  Step 144271  [3.397 sec/step, loss=0.10090, avg_loss=0.09480, mel_loss=0.04804, linear_loss=0.05286]
[2020-05-11 20:14:14.293]  Step 144272  [3.392 sec/step, loss=0.08985, avg_loss=0.09478, mel_loss=0.03988, linear_loss=0.04998]
[2020-05-11 20:14:16.024]  Step 144273  [3.367 sec/step, loss=0.09451, avg_loss=0.09472, mel_loss=0.04272, linear_loss=0.05179]
[2020-05-11 20:14:17.969]  Step 144274  [3.355 sec/step, loss=0.09547, avg_loss=0.09469, mel_loss=0.04295, linear_loss=0.05252]
[2020-05-11 20:14:20.164]  Step 144275  [3.340 sec/step, loss=0.09677, avg_loss=0.09464, mel_loss=0.04406, linear_loss=0.05271]
[2020-05-11 20:14:22.835]  Step 144276  [3.317 sec/step, loss=0.09784, avg_loss=0.09459, mel_loss=0.04478, linear_loss=0.05306]
[2020-05-11 20:14:23.941]  Step 144277  [3.240 sec/step, loss=0.08848, avg_loss=0.09449, mel_loss=0.03927, linear_loss=0.04921]
[2020-05-11 20:14:25.919]  Step 144278  [3.214 sec/step, loss=0.09619, avg_loss=0.09443, mel_loss=0.04340, linear_loss=0.05280]
[2020-05-11 20:14:27.700]  Step 144279  [3.226 sec/step, loss=0.09419, avg_loss=0.09464, mel_loss=0.04224, linear_loss=0.05195]
[2020-05-11 20:14:28.266]  Step 144280  [3.206 sec/step, loss=0.07348, avg_loss=0.09439, mel_loss=0.03367, linear_loss=0.03982]
[2020-05-11 20:14:29.111]  Step 144281  [3.202 sec/step, loss=0.08025, avg_loss=0.09428, mel_loss=0.03578, linear_loss=0.04447]
[2020-05-11 20:14:33.219]  Step 144282  [3.224 sec/step, loss=0.10014, avg_loss=0.09434, mel_loss=0.04637, linear_loss=0.05377]
[2020-05-11 20:14:36.780]  Step 144283  [3.233 sec/step, loss=0.09947, avg_loss=0.09438, mel_loss=0.04570, linear_loss=0.05377]
[2020-05-11 20:14:38.362]  Step 144284  [3.241 sec/step, loss=0.09286, avg_loss=0.09452, mel_loss=0.04178, linear_loss=0.05108]
[2020-05-11 20:14:41.872]  Step 144285  [3.241 sec/step, loss=0.09991, avg_loss=0.09451, mel_loss=0.04618, linear_loss=0.05373]
[2020-05-11 20:14:48.303]  Step 144286  [3.297 sec/step, loss=0.10317, avg_loss=0.09475, mel_loss=0.04860, linear_loss=0.05458]
[2020-05-11 20:14:51.405]  Step 144287  [3.293 sec/step, loss=0.10194, avg_loss=0.09479, mel_loss=0.04684, linear_loss=0.05510]
[2020-05-11 20:14:57.029]  Step 144288  [3.304 sec/step, loss=0.10277, avg_loss=0.09480, mel_loss=0.04833, linear_loss=0.05444]
[2020-05-11 20:15:01.110]  Step 144289  [3.289 sec/step, loss=0.10047, avg_loss=0.09481, mel_loss=0.04633, linear_loss=0.05414]
[2020-05-11 20:15:09.943]  Step 144290  [3.367 sec/step, loss=0.09987, avg_loss=0.09491, mel_loss=0.04751, linear_loss=0.05236]
[2020-05-11 20:15:12.802]  Step 144291  [3.385 sec/step, loss=0.09836, avg_loss=0.09499, mel_loss=0.04525, linear_loss=0.05310]
[2020-05-11 20:15:13.612]  Step 144292  [3.365 sec/step, loss=0.08296, avg_loss=0.09485, mel_loss=0.03723, linear_loss=0.04572]
[2020-05-11 20:15:15.471]  Step 144293  [3.379 sec/step, loss=0.09396, avg_loss=0.09505, mel_loss=0.04220, linear_loss=0.05176]
[2020-05-11 20:15:16.864]  Step 144294  [3.351 sec/step, loss=0.09159, avg_loss=0.09497, mel_loss=0.04152, linear_loss=0.05007]
[2020-05-11 20:15:19.293]  Step 144295  [3.345 sec/step, loss=0.09570, avg_loss=0.09492, mel_loss=0.04311, linear_loss=0.05259]
[2020-05-11 20:15:20.461]  Step 144296  [3.294 sec/step, loss=0.08790, avg_loss=0.09479, mel_loss=0.03950, linear_loss=0.04840]
[2020-05-11 20:15:25.799]  Step 144297  [3.314 sec/step, loss=0.10096, avg_loss=0.09479, mel_loss=0.04697, linear_loss=0.05400]
[2020-05-11 20:15:27.553]  Generated 32 batches of size 32 in 1.748 sec
[2020-05-11 20:15:27.990]  Step 144298  [3.327 sec/step, loss=0.09743, avg_loss=0.09493, mel_loss=0.04429, linear_loss=0.05314]
[2020-05-11 20:15:29.302]  Step 144299  [3.303 sec/step, loss=0.09117, avg_loss=0.09483, mel_loss=0.04108, linear_loss=0.05009]
[2020-05-11 20:15:30.922]  Step 144300  [3.306 sec/step, loss=0.09564, avg_loss=0.09489, mel_loss=0.04299, linear_loss=0.05265]
[2020-05-11 20:15:30.922]  Writing summary at step: 144300
[2020-05-11 20:15:31.967]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144300
[2020-05-11 20:15:33.310]  Saving audio and alignment...
[2020-05-11 20:15:37.953]  Input: 고개를 활용해서 리딩 해보세요~__________________________________
[2020-05-11 20:15:52.390]  Step 144301  [3.379 sec/step, loss=0.07830, avg_loss=0.09466, mel_loss=0.03791, linear_loss=0.04039]
[2020-05-11 20:15:56.975]  Step 144302  [3.406 sec/step, loss=0.10247, avg_loss=0.09477, mel_loss=0.04767, linear_loss=0.05480]
[2020-05-11 20:16:04.427]  Step 144303  [3.463 sec/step, loss=0.10214, avg_loss=0.09486, mel_loss=0.04799, linear_loss=0.05414]
[2020-05-11 20:16:05.322]  Step 144304  [3.456 sec/step, loss=0.08282, avg_loss=0.09475, mel_loss=0.03650, linear_loss=0.04632]
[2020-05-11 20:16:09.696]  Step 144305  [3.479 sec/step, loss=0.10242, avg_loss=0.09482, mel_loss=0.04747, linear_loss=0.05494]
[2020-05-11 20:16:15.299]  Step 144306  [3.521 sec/step, loss=0.10241, avg_loss=0.09493, mel_loss=0.04762, linear_loss=0.05479]
[2020-05-11 20:16:16.298]  Step 144307  [3.508 sec/step, loss=0.08724, avg_loss=0.09486, mel_loss=0.03852, linear_loss=0.04872]
[2020-05-11 20:16:17.556]  Step 144308  [3.378 sec/step, loss=0.09100, avg_loss=0.09498, mel_loss=0.04052, linear_loss=0.05047]
[2020-05-11 20:16:20.368]  Step 144309  [3.320 sec/step, loss=0.09684, avg_loss=0.09493, mel_loss=0.04433, linear_loss=0.05250]
[2020-05-11 20:16:23.725]  Step 144310  [3.300 sec/step, loss=0.10020, avg_loss=0.09493, mel_loss=0.04614, linear_loss=0.05407]
[2020-05-11 20:16:28.931]  Step 144311  [3.336 sec/step, loss=0.10131, avg_loss=0.09500, mel_loss=0.04737, linear_loss=0.05394]
[2020-05-11 20:16:30.005]  Step 144312  [3.325 sec/step, loss=0.09150, avg_loss=0.09496, mel_loss=0.04023, linear_loss=0.05127]
[2020-05-11 20:16:38.659]  Step 144313  [3.391 sec/step, loss=0.10194, avg_loss=0.09504, mel_loss=0.04854, linear_loss=0.05340]
[2020-05-11 20:16:42.858]  Step 144314  [3.421 sec/step, loss=0.09975, avg_loss=0.09512, mel_loss=0.04595, linear_loss=0.05381]
[2020-05-11 20:16:44.594]  Step 144315  [3.423 sec/step, loss=0.09296, avg_loss=0.09513, mel_loss=0.04185, linear_loss=0.05110]
[2020-05-11 20:16:46.653]  Step 144316  [3.425 sec/step, loss=0.09451, avg_loss=0.09513, mel_loss=0.04247, linear_loss=0.05204]
[2020-05-11 20:16:48.206]  Step 144317  [3.395 sec/step, loss=0.09410, avg_loss=0.09504, mel_loss=0.04246, linear_loss=0.05165]
[2020-05-11 20:16:52.819]  Step 144318  [3.386 sec/step, loss=0.10222, avg_loss=0.09503, mel_loss=0.04711, linear_loss=0.05511]
[2020-05-11 20:16:55.807]  Step 144319  [3.389 sec/step, loss=0.09979, avg_loss=0.09505, mel_loss=0.04554, linear_loss=0.05425]
[2020-05-11 20:16:58.930]  Step 144320  [3.412 sec/step, loss=0.10077, avg_loss=0.09523, mel_loss=0.04639, linear_loss=0.05439]
[2020-05-11 20:16:59.494]  Step 144321  [3.410 sec/step, loss=0.07670, avg_loss=0.09519, mel_loss=0.03483, linear_loss=0.04187]
[2020-05-11 20:17:00.287]  Step 144322  [3.393 sec/step, loss=0.08168, avg_loss=0.09503, mel_loss=0.03638, linear_loss=0.04531]
[2020-05-11 20:17:02.072]  Step 144323  [3.377 sec/step, loss=0.09357, avg_loss=0.09496, mel_loss=0.04187, linear_loss=0.05169]
[2020-05-11 20:17:03.493]  Step 144324  [3.367 sec/step, loss=0.09081, avg_loss=0.09489, mel_loss=0.04104, linear_loss=0.04977]
[2020-05-11 20:17:10.951]  Step 144325  [3.391 sec/step, loss=0.10235, avg_loss=0.09490, mel_loss=0.04841, linear_loss=0.05394]
[2020-05-11 20:17:13.198]  Step 144326  [3.403 sec/step, loss=0.09443, avg_loss=0.09498, mel_loss=0.04281, linear_loss=0.05162]
[2020-05-11 20:17:14.602]  Step 144327  [3.335 sec/step, loss=0.09052, avg_loss=0.09489, mel_loss=0.04040, linear_loss=0.05013]
[2020-05-11 20:17:15.431]  Step 144328  [3.300 sec/step, loss=0.07489, avg_loss=0.09461, mel_loss=0.03397, linear_loss=0.04092]
[2020-05-11 20:17:16.317]  Generated 32 batches of size 32 in 1.711 sec
[2020-05-11 20:17:17.516]  Step 144329  [3.306 sec/step, loss=0.09540, avg_loss=0.09464, mel_loss=0.04312, linear_loss=0.05229]
[2020-05-11 20:17:23.627]  Step 144330  [3.354 sec/step, loss=0.10353, avg_loss=0.09476, mel_loss=0.04897, linear_loss=0.05456]
[2020-05-11 20:17:27.313]  Step 144331  [3.362 sec/step, loss=0.10259, avg_loss=0.09478, mel_loss=0.04742, linear_loss=0.05517]
[2020-05-11 20:17:28.337]  Step 144332  [3.350 sec/step, loss=0.08930, avg_loss=0.09472, mel_loss=0.03973, linear_loss=0.04957]
[2020-05-11 20:17:31.138]  Step 144333  [3.358 sec/step, loss=0.09575, avg_loss=0.09472, mel_loss=0.04354, linear_loss=0.05221]
[2020-05-11 20:17:33.605]  Step 144334  [3.372 sec/step, loss=0.09639, avg_loss=0.09482, mel_loss=0.04398, linear_loss=0.05241]
[2020-05-11 20:17:46.813]  Step 144335  [3.471 sec/step, loss=0.08681, avg_loss=0.09468, mel_loss=0.04202, linear_loss=0.04479]
[2020-05-11 20:17:50.333]  Step 144336  [3.432 sec/step, loss=0.10007, avg_loss=0.09464, mel_loss=0.04595, linear_loss=0.05413]
[2020-05-11 20:17:51.106]  Step 144337  [3.372 sec/step, loss=0.08540, avg_loss=0.09449, mel_loss=0.03766, linear_loss=0.04775]
[2020-05-11 20:17:52.864]  Step 144338  [3.356 sec/step, loss=0.09476, avg_loss=0.09444, mel_loss=0.04249, linear_loss=0.05227]
[2020-05-11 20:17:55.809]  Step 144339  [3.369 sec/step, loss=0.09990, avg_loss=0.09449, mel_loss=0.04572, linear_loss=0.05419]
[2020-05-11 20:17:59.842]  Step 144340  [3.398 sec/step, loss=0.10264, avg_loss=0.09462, mel_loss=0.04719, linear_loss=0.05545]
[2020-05-11 20:18:01.131]  Step 144341  [3.375 sec/step, loss=0.09095, avg_loss=0.09449, mel_loss=0.04057, linear_loss=0.05038]
[2020-05-11 20:18:03.520]  Step 144342  [3.391 sec/step, loss=0.09686, avg_loss=0.09468, mel_loss=0.04369, linear_loss=0.05317]
[2020-05-11 20:18:07.660]  Step 144343  [3.313 sec/step, loss=0.10220, avg_loss=0.09480, mel_loss=0.04783, linear_loss=0.05437]
[2020-05-11 20:18:08.998]  Step 144344  [3.285 sec/step, loss=0.09256, avg_loss=0.09469, mel_loss=0.04143, linear_loss=0.05113]
[2020-05-11 20:18:11.734]  Step 144345  [3.295 sec/step, loss=0.09906, avg_loss=0.09472, mel_loss=0.04517, linear_loss=0.05389]
[2020-05-11 20:18:20.669]  Step 144346  [3.341 sec/step, loss=0.10315, avg_loss=0.09473, mel_loss=0.04889, linear_loss=0.05426]
[2020-05-11 20:18:25.369]  Step 144347  [3.354 sec/step, loss=0.10255, avg_loss=0.09477, mel_loss=0.04763, linear_loss=0.05491]
[2020-05-11 20:18:26.449]  Step 144348  [3.353 sec/step, loss=0.08883, avg_loss=0.09475, mel_loss=0.03926, linear_loss=0.04957]
[2020-05-11 20:18:34.112]  Step 144349  [3.389 sec/step, loss=0.10176, avg_loss=0.09473, mel_loss=0.04794, linear_loss=0.05383]
[2020-05-11 20:18:34.668]  Step 144350  [3.379 sec/step, loss=0.07483, avg_loss=0.09456, mel_loss=0.03370, linear_loss=0.04114]
[2020-05-11 20:18:34.668]  Writing summary at step: 144350
[2020-05-11 20:18:36.901]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144350
[2020-05-11 20:18:38.258]  Saving audio and alignment...
[2020-05-11 20:18:40.178]  Input: 바로 오늘~_____________
[2020-05-11 20:18:41.128]  Step 144351  [3.245 sec/step, loss=0.08173, avg_loss=0.09455, mel_loss=0.03607, linear_loss=0.04566]
[2020-05-11 20:18:44.741]  Step 144352  [3.228 sec/step, loss=0.10097, avg_loss=0.09454, mel_loss=0.04643, linear_loss=0.05454]
[2020-05-11 20:18:46.432]  Step 144353  [3.235 sec/step, loss=0.09208, avg_loss=0.09460, mel_loss=0.04145, linear_loss=0.05063]
[2020-05-11 20:18:49.046]  Step 144354  [3.245 sec/step, loss=0.09731, avg_loss=0.09464, mel_loss=0.04401, linear_loss=0.05330]
[2020-05-11 20:18:50.639]  Step 144355  [3.255 sec/step, loss=0.09352, avg_loss=0.09480, mel_loss=0.04223, linear_loss=0.05129]
[2020-05-11 20:18:53.763]  Step 144356  [3.279 sec/step, loss=0.10070, avg_loss=0.09498, mel_loss=0.04620, linear_loss=0.05450]
[2020-05-11 20:18:55.782]  Step 144357  [3.285 sec/step, loss=0.09543, avg_loss=0.09503, mel_loss=0.04336, linear_loss=0.05207]
[2020-05-11 20:18:56.541]  Step 144358  [3.283 sec/step, loss=0.08186, avg_loss=0.09499, mel_loss=0.03633, linear_loss=0.04553]
[2020-05-11 20:18:57.477]  Generated 32 batches of size 32 in 1.690 sec
[2020-05-11 20:19:00.017]  Step 144359  [3.297 sec/step, loss=0.09919, avg_loss=0.09503, mel_loss=0.04547, linear_loss=0.05372]
[2020-05-11 20:19:01.187]  Step 144360  [3.285 sec/step, loss=0.08795, avg_loss=0.09492, mel_loss=0.03940, linear_loss=0.04856]
[2020-05-11 20:19:06.451]  Step 144361  [3.309 sec/step, loss=0.10178, avg_loss=0.09495, mel_loss=0.04744, linear_loss=0.05434]
[2020-05-11 20:19:12.917]  Step 144362  [3.342 sec/step, loss=0.10338, avg_loss=0.09497, mel_loss=0.04854, linear_loss=0.05484]
[2020-05-11 20:19:18.664]  Step 144363  [3.391 sec/step, loss=0.10093, avg_loss=0.09516, mel_loss=0.04720, linear_loss=0.05373]
[2020-05-11 20:19:22.293]  Step 144364  [3.398 sec/step, loss=0.10155, avg_loss=0.09521, mel_loss=0.04664, linear_loss=0.05491]
[2020-05-11 20:19:35.305]  Step 144365  [3.489 sec/step, loss=0.08820, avg_loss=0.09506, mel_loss=0.04265, linear_loss=0.04555]
[2020-05-11 20:19:37.223]  Step 144366  [3.484 sec/step, loss=0.09503, avg_loss=0.09503, mel_loss=0.04280, linear_loss=0.05223]
[2020-05-11 20:19:38.874]  Step 144367  [3.476 sec/step, loss=0.09595, avg_loss=0.09503, mel_loss=0.04280, linear_loss=0.05315]
[2020-05-11 20:19:39.702]  Step 144368  [3.406 sec/step, loss=0.08161, avg_loss=0.09480, mel_loss=0.03617, linear_loss=0.04544]
[2020-05-11 20:19:40.493]  Step 144369  [3.297 sec/step, loss=0.08145, avg_loss=0.09460, mel_loss=0.03626, linear_loss=0.04519]
[2020-05-11 20:19:43.017]  Step 144370  [3.265 sec/step, loss=0.09785, avg_loss=0.09458, mel_loss=0.04458, linear_loss=0.05327]
[2020-05-11 20:19:47.009]  Step 144371  [3.213 sec/step, loss=0.10169, avg_loss=0.09458, mel_loss=0.04696, linear_loss=0.05473]
[2020-05-11 20:19:51.280]  Step 144372  [3.244 sec/step, loss=0.10047, avg_loss=0.09469, mel_loss=0.04622, linear_loss=0.05425]
[2020-05-11 20:19:53.673]  Step 144373  [3.251 sec/step, loss=0.09550, avg_loss=0.09470, mel_loss=0.04330, linear_loss=0.05219]
[2020-05-11 20:19:54.782]  Step 144374  [3.242 sec/step, loss=0.08906, avg_loss=0.09464, mel_loss=0.03957, linear_loss=0.04949]
[2020-05-11 20:20:08.670]  Step 144375  [3.359 sec/step, loss=0.07648, avg_loss=0.09443, mel_loss=0.03696, linear_loss=0.03952]
[2020-05-11 20:20:10.411]  Step 144376  [3.350 sec/step, loss=0.09474, avg_loss=0.09440, mel_loss=0.04241, linear_loss=0.05233]
[2020-05-11 20:20:12.381]  Step 144377  [3.359 sec/step, loss=0.09602, avg_loss=0.09448, mel_loss=0.04363, linear_loss=0.05240]
[2020-05-11 20:20:17.922]  Step 144378  [3.394 sec/step, loss=0.10300, avg_loss=0.09455, mel_loss=0.04829, linear_loss=0.05471]
[2020-05-11 20:20:19.259]  Step 144379  [3.390 sec/step, loss=0.08893, avg_loss=0.09449, mel_loss=0.03988, linear_loss=0.04905]
[2020-05-11 20:20:26.516]  Step 144380  [3.457 sec/step, loss=0.10163, avg_loss=0.09477, mel_loss=0.04799, linear_loss=0.05364]
[2020-05-11 20:20:28.826]  Step 144381  [3.471 sec/step, loss=0.09551, avg_loss=0.09493, mel_loss=0.04314, linear_loss=0.05237]
[2020-05-11 20:20:32.037]  Step 144382  [3.463 sec/step, loss=0.10150, avg_loss=0.09494, mel_loss=0.04662, linear_loss=0.05488]
[2020-05-11 20:20:35.008]  Step 144383  [3.457 sec/step, loss=0.09911, avg_loss=0.09494, mel_loss=0.04541, linear_loss=0.05370]
[2020-05-11 20:20:37.782]  Step 144384  [3.469 sec/step, loss=0.09737, avg_loss=0.09498, mel_loss=0.04451, linear_loss=0.05286]
[2020-05-11 20:20:39.662]  Step 144385  [3.452 sec/step, loss=0.09272, avg_loss=0.09491, mel_loss=0.04154, linear_loss=0.05118]
[2020-05-11 20:20:40.670]  Step 144386  [3.398 sec/step, loss=0.08518, avg_loss=0.09473, mel_loss=0.03809, linear_loss=0.04709]
[2020-05-11 20:20:42.055]  Step 144387  [3.381 sec/step, loss=0.09101, avg_loss=0.09462, mel_loss=0.04081, linear_loss=0.05020]
[2020-05-11 20:20:43.261]  Step 144388  [3.337 sec/step, loss=0.08809, avg_loss=0.09447, mel_loss=0.03902, linear_loss=0.04906]
[2020-05-11 20:20:46.632]  Step 144389  [3.330 sec/step, loss=0.09761, avg_loss=0.09445, mel_loss=0.04520, linear_loss=0.05241]
[2020-05-11 20:20:48.554]  Generated 32 batches of size 32 in 1.915 sec
[2020-05-11 20:20:48.907]  Step 144390  [3.264 sec/step, loss=0.09706, avg_loss=0.09442, mel_loss=0.04398, linear_loss=0.05309]
[2020-05-11 20:20:49.487]  Step 144391  [3.241 sec/step, loss=0.07594, avg_loss=0.09419, mel_loss=0.03426, linear_loss=0.04168]
[2020-05-11 20:20:57.481]  Step 144392  [3.313 sec/step, loss=0.10348, avg_loss=0.09440, mel_loss=0.04920, linear_loss=0.05428]
[2020-05-11 20:21:02.688]  Step 144393  [3.347 sec/step, loss=0.10207, avg_loss=0.09448, mel_loss=0.04774, linear_loss=0.05432]
[2020-05-11 20:21:08.666]  Step 144394  [3.392 sec/step, loss=0.10218, avg_loss=0.09459, mel_loss=0.04812, linear_loss=0.05406]
[2020-05-11 20:21:10.183]  Step 144395  [3.383 sec/step, loss=0.09357, avg_loss=0.09456, mel_loss=0.04190, linear_loss=0.05167]
[2020-05-11 20:21:14.765]  Step 144396  [3.417 sec/step, loss=0.10004, avg_loss=0.09469, mel_loss=0.04626, linear_loss=0.05379]
[2020-05-11 20:21:15.757]  Step 144397  [3.374 sec/step, loss=0.08566, avg_loss=0.09453, mel_loss=0.03793, linear_loss=0.04773]
[2020-05-11 20:21:19.250]  Step 144398  [3.387 sec/step, loss=0.10159, avg_loss=0.09457, mel_loss=0.04681, linear_loss=0.05477]
[2020-05-11 20:21:21.849]  Step 144399  [3.400 sec/step, loss=0.09857, avg_loss=0.09465, mel_loss=0.04526, linear_loss=0.05332]
[2020-05-11 20:21:36.119]  Step 144400  [3.526 sec/step, loss=0.08148, avg_loss=0.09451, mel_loss=0.03929, linear_loss=0.04219]
[2020-05-11 20:21:36.119]  Writing summary at step: 144400
[2020-05-11 20:21:37.314]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144400
[2020-05-11 20:21:38.667]  Saving audio and alignment...
[2020-05-11 20:21:40.183]  Input: 모두~______________________________
[2020-05-11 20:21:41.799]  Step 144401  [3.398 sec/step, loss=0.09433, avg_loss=0.09467, mel_loss=0.04246, linear_loss=0.05187]
[2020-05-11 20:21:42.324]  Step 144402  [3.358 sec/step, loss=0.07693, avg_loss=0.09441, mel_loss=0.03536, linear_loss=0.04157]
[2020-05-11 20:21:43.158]  Step 144403  [3.291 sec/step, loss=0.08544, avg_loss=0.09424, mel_loss=0.03764, linear_loss=0.04780]
[2020-05-11 20:21:46.578]  Step 144404  [3.317 sec/step, loss=0.10021, avg_loss=0.09442, mel_loss=0.04598, linear_loss=0.05423]
[2020-05-11 20:21:49.185]  Step 144405  [3.299 sec/step, loss=0.09602, avg_loss=0.09435, mel_loss=0.04342, linear_loss=0.05260]
[2020-05-11 20:21:50.582]  Step 144406  [3.257 sec/step, loss=0.09259, avg_loss=0.09426, mel_loss=0.04150, linear_loss=0.05109]
[2020-05-11 20:21:56.879]  Step 144407  [3.310 sec/step, loss=0.10151, avg_loss=0.09440, mel_loss=0.04768, linear_loss=0.05383]
[2020-05-11 20:21:58.446]  Step 144408  [3.313 sec/step, loss=0.09044, avg_loss=0.09439, mel_loss=0.04073, linear_loss=0.04971]
[2020-05-11 20:22:01.894]  Step 144409  [3.319 sec/step, loss=0.09795, avg_loss=0.09440, mel_loss=0.04526, linear_loss=0.05269]
[2020-05-11 20:22:02.639]  Step 144410  [3.293 sec/step, loss=0.08704, avg_loss=0.09427, mel_loss=0.03852, linear_loss=0.04852]
[2020-05-11 20:22:04.571]  Step 144411  [3.260 sec/step, loss=0.09434, avg_loss=0.09420, mel_loss=0.04274, linear_loss=0.05161]
[2020-05-11 20:22:11.993]  Step 144412  [3.324 sec/step, loss=0.10399, avg_loss=0.09433, mel_loss=0.04927, linear_loss=0.05472]
[2020-05-11 20:22:16.373]  Step 144413  [3.281 sec/step, loss=0.10255, avg_loss=0.09433, mel_loss=0.04785, linear_loss=0.05470]
[2020-05-11 20:22:21.001]  Step 144414  [3.285 sec/step, loss=0.10162, avg_loss=0.09435, mel_loss=0.04706, linear_loss=0.05457]
[2020-05-11 20:22:23.778]  Step 144415  [3.296 sec/step, loss=0.09810, avg_loss=0.09440, mel_loss=0.04505, linear_loss=0.05305]
[2020-05-11 20:22:32.231]  Step 144416  [3.360 sec/step, loss=0.10034, avg_loss=0.09446, mel_loss=0.04733, linear_loss=0.05301]
[2020-05-11 20:22:36.209]  Step 144417  [3.384 sec/step, loss=0.10068, avg_loss=0.09453, mel_loss=0.04645, linear_loss=0.05423]
[2020-05-11 20:22:37.272]  Step 144418  [3.349 sec/step, loss=0.08979, avg_loss=0.09440, mel_loss=0.03973, linear_loss=0.05005]
[2020-05-11 20:22:42.855]  Step 144419  [3.374 sec/step, loss=0.10147, avg_loss=0.09442, mel_loss=0.04717, linear_loss=0.05430]
[2020-05-11 20:22:44.645]  Generated 32 batches of size 32 in 1.785 sec
[2020-05-11 20:22:48.241]  Step 144420  [3.397 sec/step, loss=0.10240, avg_loss=0.09444, mel_loss=0.04791, linear_loss=0.05449]
[2020-05-11 20:22:50.447]  Step 144421  [3.414 sec/step, loss=0.09534, avg_loss=0.09462, mel_loss=0.04330, linear_loss=0.05205]
[2020-05-11 20:22:52.845]  Step 144422  [3.430 sec/step, loss=0.09663, avg_loss=0.09477, mel_loss=0.04363, linear_loss=0.05300]
[2020-05-11 20:22:54.155]  Step 144423  [3.425 sec/step, loss=0.09008, avg_loss=0.09474, mel_loss=0.04038, linear_loss=0.04970]
[2020-05-11 20:22:57.250]  Step 144424  [3.442 sec/step, loss=0.09838, avg_loss=0.09481, mel_loss=0.04497, linear_loss=0.05341]
[2020-05-11 20:22:58.216]  Step 144425  [3.377 sec/step, loss=0.08717, avg_loss=0.09466, mel_loss=0.03884, linear_loss=0.04833]
[2020-05-11 20:23:01.908]  Step 144426  [3.391 sec/step, loss=0.10214, avg_loss=0.09474, mel_loss=0.04707, linear_loss=0.05507]
[2020-05-11 20:23:03.691]  Step 144427  [3.395 sec/step, loss=0.09405, avg_loss=0.09477, mel_loss=0.04202, linear_loss=0.05202]
[2020-05-11 20:23:05.816]  Step 144428  [3.408 sec/step, loss=0.09350, avg_loss=0.09496, mel_loss=0.04229, linear_loss=0.05121]
[2020-05-11 20:23:13.835]  Step 144429  [3.467 sec/step, loss=0.10208, avg_loss=0.09503, mel_loss=0.04820, linear_loss=0.05387]
[2020-05-11 20:23:15.645]  Step 144430  [3.424 sec/step, loss=0.09301, avg_loss=0.09492, mel_loss=0.04192, linear_loss=0.05109]
[2020-05-11 20:23:16.960]  Step 144431  [3.400 sec/step, loss=0.08587, avg_loss=0.09476, mel_loss=0.03841, linear_loss=0.04746]
[2020-05-11 20:23:20.349]  Step 144432  [3.424 sec/step, loss=0.10105, avg_loss=0.09487, mel_loss=0.04648, linear_loss=0.05457]
[2020-05-11 20:23:24.050]  Step 144433  [3.433 sec/step, loss=0.10222, avg_loss=0.09494, mel_loss=0.04712, linear_loss=0.05510]
[2020-05-11 20:23:31.099]  Step 144434  [3.479 sec/step, loss=0.10179, avg_loss=0.09499, mel_loss=0.04803, linear_loss=0.05375]
[2020-05-11 20:23:31.658]  Step 144435  [3.352 sec/step, loss=0.07516, avg_loss=0.09487, mel_loss=0.03397, linear_loss=0.04119]
[2020-05-11 20:23:43.855]  Step 144436  [3.439 sec/step, loss=0.08828, avg_loss=0.09476, mel_loss=0.04264, linear_loss=0.04564]
[2020-05-11 20:23:45.670]  Step 144437  [3.450 sec/step, loss=0.09355, avg_loss=0.09484, mel_loss=0.04191, linear_loss=0.05164]
[2020-05-11 20:23:47.685]  Step 144438  [3.452 sec/step, loss=0.09516, avg_loss=0.09484, mel_loss=0.04294, linear_loss=0.05222]
[2020-05-11 20:23:51.207]  Step 144439  [3.458 sec/step, loss=0.09958, avg_loss=0.09484, mel_loss=0.04562, linear_loss=0.05397]
[2020-05-11 20:23:52.642]  Step 144440  [3.432 sec/step, loss=0.09254, avg_loss=0.09474, mel_loss=0.04099, linear_loss=0.05156]
[2020-05-11 20:23:55.899]  Step 144441  [3.452 sec/step, loss=0.10333, avg_loss=0.09486, mel_loss=0.04765, linear_loss=0.05568]
[2020-05-11 20:23:57.544]  Step 144442  [3.444 sec/step, loss=0.09209, avg_loss=0.09481, mel_loss=0.04112, linear_loss=0.05097]
[2020-05-11 20:23:59.944]  Step 144443  [3.427 sec/step, loss=0.09800, avg_loss=0.09477, mel_loss=0.04468, linear_loss=0.05332]
[2020-05-11 20:24:04.564]  Step 144444  [3.460 sec/step, loss=0.10062, avg_loss=0.09485, mel_loss=0.04624, linear_loss=0.05438]
[2020-05-11 20:24:05.779]  Step 144445  [3.444 sec/step, loss=0.08280, avg_loss=0.09469, mel_loss=0.03670, linear_loss=0.04610]
[2020-05-11 20:24:07.391]  Step 144446  [3.371 sec/step, loss=0.09022, avg_loss=0.09456, mel_loss=0.03975, linear_loss=0.05046]
[2020-05-11 20:24:14.968]  Step 144447  [3.400 sec/step, loss=0.10123, avg_loss=0.09455, mel_loss=0.04682, linear_loss=0.05441]
[2020-05-11 20:24:25.593]  Step 144448  [3.495 sec/step, loss=0.10001, avg_loss=0.09466, mel_loss=0.04765, linear_loss=0.05236]
[2020-05-11 20:24:26.323]  Step 144449  [3.426 sec/step, loss=0.08240, avg_loss=0.09447, mel_loss=0.03684, linear_loss=0.04556]
[2020-05-11 20:24:27.330]  Step 144450  [3.431 sec/step, loss=0.08657, avg_loss=0.09458, mel_loss=0.03806, linear_loss=0.04851]
[2020-05-11 20:24:27.330]  Writing summary at step: 144450
[2020-05-11 20:24:28.949]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144450
[2020-05-11 20:24:30.287]  Saving audio and alignment...
[2020-05-11 20:24:32.513]  Generated 32 batches of size 32 in 1.693 sec
[2020-05-11 20:24:34.301]  Input: 래서 총장님을 딱 소개해드린 후에~_______
[2020-05-11 20:24:38.938]  Step 144451  [3.467 sec/step, loss=0.10242, avg_loss=0.09479, mel_loss=0.04752, linear_loss=0.05490]
[2020-05-11 20:24:41.153]  Step 144452  [3.454 sec/step, loss=0.09523, avg_loss=0.09473, mel_loss=0.04320, linear_loss=0.05203]
[2020-05-11 20:24:46.868]  Step 144453  [3.494 sec/step, loss=0.10198, avg_loss=0.09483, mel_loss=0.04795, linear_loss=0.05403]
[2020-05-11 20:24:49.572]  Step 144454  [3.495 sec/step, loss=0.09566, avg_loss=0.09482, mel_loss=0.04358, linear_loss=0.05209]
[2020-05-11 20:24:50.779]  Step 144455  [3.491 sec/step, loss=0.08790, avg_loss=0.09476, mel_loss=0.03959, linear_loss=0.04831]
[2020-05-11 20:24:52.478]  Step 144456  [3.477 sec/step, loss=0.09528, avg_loss=0.09471, mel_loss=0.04259, linear_loss=0.05268]
[2020-05-11 20:24:56.632]  Step 144457  [3.498 sec/step, loss=0.10128, avg_loss=0.09476, mel_loss=0.04660, linear_loss=0.05468]
[2020-05-11 20:24:59.482]  Step 144458  [3.519 sec/step, loss=0.09707, avg_loss=0.09492, mel_loss=0.04431, linear_loss=0.05277]
[2020-05-11 20:25:03.118]  Step 144459  [3.520 sec/step, loss=0.10103, avg_loss=0.09493, mel_loss=0.04641, linear_loss=0.05462]
[2020-05-11 20:25:04.336]  Step 144460  [3.521 sec/step, loss=0.08675, avg_loss=0.09492, mel_loss=0.03849, linear_loss=0.04826]
[2020-05-11 20:25:05.310]  Step 144461  [3.478 sec/step, loss=0.08387, avg_loss=0.09474, mel_loss=0.03699, linear_loss=0.04687]
[2020-05-11 20:25:10.552]  Step 144462  [3.466 sec/step, loss=0.10081, avg_loss=0.09472, mel_loss=0.04703, linear_loss=0.05378]
[2020-05-11 20:25:11.310]  Step 144463  [3.416 sec/step, loss=0.08284, avg_loss=0.09454, mel_loss=0.03654, linear_loss=0.04630]
[2020-05-11 20:25:12.399]  Step 144464  [3.390 sec/step, loss=0.08586, avg_loss=0.09438, mel_loss=0.03802, linear_loss=0.04784]
[2020-05-11 20:25:14.124]  Step 144465  [3.278 sec/step, loss=0.09319, avg_loss=0.09443, mel_loss=0.04168, linear_loss=0.05151]
[2020-05-11 20:25:15.648]  Step 144466  [3.274 sec/step, loss=0.09415, avg_loss=0.09442, mel_loss=0.04244, linear_loss=0.05171]
[2020-05-11 20:25:17.265]  Step 144467  [3.273 sec/step, loss=0.09407, avg_loss=0.09440, mel_loss=0.04221, linear_loss=0.05187]
[2020-05-11 20:25:21.558]  Step 144468  [3.308 sec/step, loss=0.10190, avg_loss=0.09460, mel_loss=0.04725, linear_loss=0.05465]
[2020-05-11 20:25:24.796]  Step 144469  [3.332 sec/step, loss=0.10064, avg_loss=0.09480, mel_loss=0.04615, linear_loss=0.05449]
[2020-05-11 20:25:28.795]  Step 144470  [3.347 sec/step, loss=0.09928, avg_loss=0.09481, mel_loss=0.04547, linear_loss=0.05381]
[2020-05-11 20:25:37.849]  Step 144471  [3.398 sec/step, loss=0.10138, avg_loss=0.09481, mel_loss=0.04829, linear_loss=0.05309]
[2020-05-11 20:25:40.534]  Step 144472  [3.382 sec/step, loss=0.09739, avg_loss=0.09478, mel_loss=0.04460, linear_loss=0.05279]
[2020-05-11 20:25:42.450]  Step 144473  [3.377 sec/step, loss=0.09632, avg_loss=0.09479, mel_loss=0.04357, linear_loss=0.05275]
[2020-05-11 20:25:45.824]  Step 144474  [3.400 sec/step, loss=0.09769, avg_loss=0.09487, mel_loss=0.04510, linear_loss=0.05259]
[2020-05-11 20:25:50.420]  Step 144475  [3.307 sec/step, loss=0.10170, avg_loss=0.09512, mel_loss=0.04705, linear_loss=0.05464]
[2020-05-11 20:26:04.918]  Step 144476  [3.434 sec/step, loss=0.08075, avg_loss=0.09498, mel_loss=0.03909, linear_loss=0.04166]
[2020-05-11 20:26:07.778]  Step 144477  [3.443 sec/step, loss=0.09786, avg_loss=0.09500, mel_loss=0.04457, linear_loss=0.05328]
[2020-05-11 20:26:08.740]  Step 144478  [3.398 sec/step, loss=0.08797, avg_loss=0.09485, mel_loss=0.03893, linear_loss=0.04904]
[2020-05-11 20:26:16.370]  Step 144479  [3.461 sec/step, loss=0.10199, avg_loss=0.09498, mel_loss=0.04821, linear_loss=0.05378]
[2020-05-11 20:26:18.731]  Step 144480  [3.412 sec/step, loss=0.09799, avg_loss=0.09495, mel_loss=0.04463, linear_loss=0.05335]
[2020-05-11 20:26:24.419]  Step 144481  [3.445 sec/step, loss=0.09894, avg_loss=0.09498, mel_loss=0.04604, linear_loss=0.05290]
[2020-05-11 20:26:26.251]  Generated 32 batches of size 32 in 1.826 sec
[2020-05-11 20:26:26.669]  Step 144482  [3.436 sec/step, loss=0.09458, avg_loss=0.09491, mel_loss=0.04286, linear_loss=0.05171]
[2020-05-11 20:26:29.598]  Step 144483  [3.435 sec/step, loss=0.09963, avg_loss=0.09492, mel_loss=0.04549, linear_loss=0.05414]
[2020-05-11 20:26:32.037]  Step 144484  [3.432 sec/step, loss=0.09639, avg_loss=0.09491, mel_loss=0.04367, linear_loss=0.05272]
[2020-05-11 20:26:32.869]  Step 144485  [3.421 sec/step, loss=0.08015, avg_loss=0.09478, mel_loss=0.03575, linear_loss=0.04441]
[2020-05-11 20:26:34.249]  Step 144486  [3.425 sec/step, loss=0.09207, avg_loss=0.09485, mel_loss=0.04136, linear_loss=0.05070]
[2020-05-11 20:26:35.564]  Step 144487  [3.424 sec/step, loss=0.08962, avg_loss=0.09484, mel_loss=0.03972, linear_loss=0.04990]
[2020-05-11 20:26:41.850]  Step 144488  [3.475 sec/step, loss=0.10162, avg_loss=0.09497, mel_loss=0.04777, linear_loss=0.05385]
[2020-05-11 20:26:43.726]  Step 144489  [3.460 sec/step, loss=0.09352, avg_loss=0.09493, mel_loss=0.04205, linear_loss=0.05147]
[2020-05-11 20:26:44.277]  Step 144490  [3.443 sec/step, loss=0.07320, avg_loss=0.09469, mel_loss=0.03322, linear_loss=0.03998]
[2020-05-11 20:26:49.883]  Step 144491  [3.493 sec/step, loss=0.10348, avg_loss=0.09497, mel_loss=0.04847, linear_loss=0.05501]
[2020-05-11 20:26:53.000]  Step 144492  [3.445 sec/step, loss=0.10206, avg_loss=0.09495, mel_loss=0.04701, linear_loss=0.05505]
[2020-05-11 20:26:59.839]  Step 144493  [3.461 sec/step, loss=0.10306, avg_loss=0.09496, mel_loss=0.04841, linear_loss=0.05466]
[2020-05-11 20:27:05.155]  Step 144494  [3.454 sec/step, loss=0.10136, avg_loss=0.09495, mel_loss=0.04739, linear_loss=0.05397]
[2020-05-11 20:27:08.807]  Step 144495  [3.476 sec/step, loss=0.10297, avg_loss=0.09505, mel_loss=0.04721, linear_loss=0.05576]
[2020-05-11 20:27:20.091]  Step 144496  [3.543 sec/step, loss=0.09588, avg_loss=0.09501, mel_loss=0.04610, linear_loss=0.04978]
[2020-05-11 20:27:22.194]  Step 144497  [3.554 sec/step, loss=0.09672, avg_loss=0.09512, mel_loss=0.04381, linear_loss=0.05291]
[2020-05-11 20:27:23.416]  Step 144498  [3.531 sec/step, loss=0.08945, avg_loss=0.09500, mel_loss=0.04022, linear_loss=0.04923]
[2020-05-11 20:27:24.349]  Step 144499  [3.514 sec/step, loss=0.08437, avg_loss=0.09485, mel_loss=0.03780, linear_loss=0.04657]
[2020-05-11 20:27:31.719]  Step 144500  [3.445 sec/step, loss=0.10095, avg_loss=0.09505, mel_loss=0.04746, linear_loss=0.05349]
[2020-05-11 20:27:31.719]  Writing summary at step: 144500
[2020-05-11 20:27:35.171]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144500
[2020-05-11 20:27:36.969]  Saving audio and alignment...
[2020-05-11 20:27:39.457]  Input: 그리고 방금 전까지~_____________
[2020-05-11 20:27:40.591]  Step 144501  [3.441 sec/step, loss=0.08687, avg_loss=0.09497, mel_loss=0.03858, linear_loss=0.04829]
[2020-05-11 20:27:42.310]  Step 144502  [3.453 sec/step, loss=0.09531, avg_loss=0.09516, mel_loss=0.04277, linear_loss=0.05255]
[2020-05-11 20:27:43.731]  Step 144503  [3.458 sec/step, loss=0.08899, avg_loss=0.09519, mel_loss=0.03964, linear_loss=0.04935]
[2020-05-11 20:27:45.504]  Step 144504  [3.442 sec/step, loss=0.09388, avg_loss=0.09513, mel_loss=0.04205, linear_loss=0.05183]
[2020-05-11 20:27:48.181]  Step 144505  [3.443 sec/step, loss=0.09470, avg_loss=0.09512, mel_loss=0.04287, linear_loss=0.05183]
[2020-05-11 20:27:51.599]  Step 144506  [3.463 sec/step, loss=0.09908, avg_loss=0.09518, mel_loss=0.04504, linear_loss=0.05404]
[2020-05-11 20:27:59.912]  Step 144507  [3.483 sec/step, loss=0.09954, avg_loss=0.09516, mel_loss=0.04710, linear_loss=0.05244]
[2020-05-11 20:28:04.076]  Step 144508  [3.509 sec/step, loss=0.10064, avg_loss=0.09526, mel_loss=0.04679, linear_loss=0.05385]
[2020-05-11 20:28:04.829]  Step 144509  [3.482 sec/step, loss=0.07796, avg_loss=0.09506, mel_loss=0.03479, linear_loss=0.04316]
[2020-05-11 20:28:08.968]  Step 144510  [3.516 sec/step, loss=0.09967, avg_loss=0.09519, mel_loss=0.04571, linear_loss=0.05397]
[2020-05-11 20:28:11.164]  Step 144511  [3.519 sec/step, loss=0.09506, avg_loss=0.09520, mel_loss=0.04308, linear_loss=0.05198]
[2020-05-11 20:28:12.902]  Generated 32 batches of size 32 in 1.732 sec
[2020-05-11 20:28:13.246]  Step 144512  [3.465 sec/step, loss=0.09433, avg_loss=0.09510, mel_loss=0.04229, linear_loss=0.05205]
[2020-05-11 20:28:14.077]  Step 144513  [3.430 sec/step, loss=0.08179, avg_loss=0.09489, mel_loss=0.03619, linear_loss=0.04559]
[2020-05-11 20:28:16.382]  Step 144514  [3.406 sec/step, loss=0.09658, avg_loss=0.09484, mel_loss=0.04382, linear_loss=0.05276]
[2020-05-11 20:28:17.165]  Step 144515  [3.387 sec/step, loss=0.07503, avg_loss=0.09461, mel_loss=0.03322, linear_loss=0.04181]
[2020-05-11 20:28:19.768]  Step 144516  [3.328 sec/step, loss=0.09804, avg_loss=0.09459, mel_loss=0.04482, linear_loss=0.05322]
[2020-05-11 20:28:24.512]  Step 144517  [3.336 sec/step, loss=0.10104, avg_loss=0.09459, mel_loss=0.04693, linear_loss=0.05410]
[2020-05-11 20:28:27.437]  Step 144518  [3.354 sec/step, loss=0.10114, avg_loss=0.09471, mel_loss=0.04625, linear_loss=0.05489]
[2020-05-11 20:28:29.037]  Step 144519  [3.314 sec/step, loss=0.09367, avg_loss=0.09463, mel_loss=0.04181, linear_loss=0.05186]
[2020-05-11 20:28:30.084]  Step 144520  [3.271 sec/step, loss=0.08710, avg_loss=0.09448, mel_loss=0.03903, linear_loss=0.04807]
[2020-05-11 20:28:31.677]  Step 144521  [3.265 sec/step, loss=0.09283, avg_loss=0.09445, mel_loss=0.04196, linear_loss=0.05087]
[2020-05-11 20:28:34.755]  Step 144522  [3.272 sec/step, loss=0.09979, avg_loss=0.09448, mel_loss=0.04559, linear_loss=0.05420]
[2020-05-11 20:28:36.904]  Step 144523  [3.280 sec/step, loss=0.09529, avg_loss=0.09453, mel_loss=0.04298, linear_loss=0.05231]
[2020-05-11 20:28:38.229]  Step 144524  [3.262 sec/step, loss=0.09064, avg_loss=0.09446, mel_loss=0.04052, linear_loss=0.05012]
[2020-05-11 20:28:41.993]  Step 144525  [3.290 sec/step, loss=0.10009, avg_loss=0.09459, mel_loss=0.04617, linear_loss=0.05393]
[2020-05-11 20:28:50.865]  Step 144526  [3.342 sec/step, loss=0.09943, avg_loss=0.09456, mel_loss=0.04717, linear_loss=0.05226]
[2020-05-11 20:28:52.025]  Step 144527  [3.336 sec/step, loss=0.08507, avg_loss=0.09447, mel_loss=0.03765, linear_loss=0.04742]
[2020-05-11 20:28:52.998]  Step 144528  [3.324 sec/step, loss=0.08808, avg_loss=0.09442, mel_loss=0.03908, linear_loss=0.04900]
[2020-05-11 20:28:55.393]  Step 144529  [3.268 sec/step, loss=0.09684, avg_loss=0.09436, mel_loss=0.04394, linear_loss=0.05289]
[2020-05-11 20:28:56.867]  Step 144530  [3.265 sec/step, loss=0.09185, avg_loss=0.09435, mel_loss=0.04110, linear_loss=0.05075]
[2020-05-11 20:29:01.177]  Step 144531  [3.295 sec/step, loss=0.10106, avg_loss=0.09450, mel_loss=0.04677, linear_loss=0.05429]
[2020-05-11 20:29:02.316]  Step 144532  [3.272 sec/step, loss=0.08934, avg_loss=0.09439, mel_loss=0.03944, linear_loss=0.04989]
[2020-05-11 20:29:05.329]  Step 144533  [3.265 sec/step, loss=0.09644, avg_loss=0.09433, mel_loss=0.04414, linear_loss=0.05229]
[2020-05-11 20:29:13.059]  Step 144534  [3.272 sec/step, loss=0.10267, avg_loss=0.09434, mel_loss=0.04859, linear_loss=0.05408]
[2020-05-11 20:29:19.639]  Step 144535  [3.332 sec/step, loss=0.10181, avg_loss=0.09460, mel_loss=0.04785, linear_loss=0.05396]
[2020-05-11 20:29:33.901]  Step 144536  [3.353 sec/step, loss=0.08075, avg_loss=0.09453, mel_loss=0.03914, linear_loss=0.04160]
[2020-05-11 20:29:37.226]  Step 144537  [3.368 sec/step, loss=0.10106, avg_loss=0.09460, mel_loss=0.04632, linear_loss=0.05474]
[2020-05-11 20:29:37.784]  Step 144538  [3.354 sec/step, loss=0.07477, avg_loss=0.09440, mel_loss=0.03358, linear_loss=0.04119]
[2020-05-11 20:29:39.819]  Step 144539  [3.339 sec/step, loss=0.09581, avg_loss=0.09436, mel_loss=0.04348, linear_loss=0.05233]
[2020-05-11 20:29:44.383]  Step 144540  [3.370 sec/step, loss=0.10037, avg_loss=0.09444, mel_loss=0.04660, linear_loss=0.05377]
[2020-05-11 20:29:49.278]  Step 144541  [3.386 sec/step, loss=0.10156, avg_loss=0.09442, mel_loss=0.04711, linear_loss=0.05445]
[2020-05-11 20:29:50.176]  Step 144542  [3.379 sec/step, loss=0.08201, avg_loss=0.09432, mel_loss=0.03605, linear_loss=0.04596]
[2020-05-11 20:29:50.800]  Step 144543  [3.361 sec/step, loss=0.08186, avg_loss=0.09416, mel_loss=0.03675, linear_loss=0.04512]
[2020-05-11 20:29:52.443]  Generated 32 batches of size 32 in 1.638 sec
[2020-05-11 20:29:52.886]  Step 144544  [3.336 sec/step, loss=0.09310, avg_loss=0.09408, mel_loss=0.04215, linear_loss=0.05095]
[2020-05-11 20:29:56.251]  Step 144545  [3.357 sec/step, loss=0.09782, avg_loss=0.09423, mel_loss=0.04477, linear_loss=0.05305]
[2020-05-11 20:29:58.777]  Step 144546  [3.367 sec/step, loss=0.09720, avg_loss=0.09430, mel_loss=0.04400, linear_loss=0.05320]
[2020-05-11 20:30:04.129]  Step 144547  [3.344 sec/step, loss=0.10175, avg_loss=0.09431, mel_loss=0.04761, linear_loss=0.05414]
[2020-05-11 20:30:05.966]  Step 144548  [3.256 sec/step, loss=0.09217, avg_loss=0.09423, mel_loss=0.04129, linear_loss=0.05088]
[2020-05-11 20:30:07.270]  Step 144549  [3.262 sec/step, loss=0.09141, avg_loss=0.09432, mel_loss=0.04071, linear_loss=0.05071]
[2020-05-11 20:30:10.838]  Step 144550  [3.288 sec/step, loss=0.10154, avg_loss=0.09447, mel_loss=0.04678, linear_loss=0.05476]
[2020-05-11 20:30:10.838]  Writing summary at step: 144550
[2020-05-11 20:30:11.601]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144550
[2020-05-11 20:30:12.889]  Saving audio and alignment...
[2020-05-11 20:30:15.840]  Input: 힘든 날 울고 싶은 날~_______________
[2020-05-11 20:30:21.191]  Step 144551  [3.295 sec/step, loss=0.10289, avg_loss=0.09448, mel_loss=0.04800, linear_loss=0.05490]
[2020-05-11 20:30:24.906]  Step 144552  [3.310 sec/step, loss=0.10016, avg_loss=0.09453, mel_loss=0.04617, linear_loss=0.05399]
[2020-05-11 20:30:26.826]  Step 144553  [3.272 sec/step, loss=0.09515, avg_loss=0.09446, mel_loss=0.04304, linear_loss=0.05211]
[2020-05-11 20:30:29.327]  Step 144554  [3.270 sec/step, loss=0.09388, avg_loss=0.09444, mel_loss=0.04248, linear_loss=0.05140]
[2020-05-11 20:30:36.738]  Step 144555  [3.332 sec/step, loss=0.10355, avg_loss=0.09460, mel_loss=0.04892, linear_loss=0.05464]
[2020-05-11 20:30:37.739]  Step 144556  [3.325 sec/step, loss=0.08520, avg_loss=0.09450, mel_loss=0.03782, linear_loss=0.04738]
[2020-05-11 20:30:46.308]  Step 144557  [3.369 sec/step, loss=0.10022, avg_loss=0.09448, mel_loss=0.04752, linear_loss=0.05270]
[2020-05-11 20:30:49.723]  Step 144558  [3.375 sec/step, loss=0.09672, avg_loss=0.09448, mel_loss=0.04437, linear_loss=0.05235]
[2020-05-11 20:30:50.286]  Step 144559  [3.344 sec/step, loss=0.07286, avg_loss=0.09420, mel_loss=0.03291, linear_loss=0.03996]
[2020-05-11 20:30:51.669]  Step 144560  [3.346 sec/step, loss=0.09237, avg_loss=0.09426, mel_loss=0.04139, linear_loss=0.05098]
[2020-05-11 20:30:52.879]  Step 144561  [3.348 sec/step, loss=0.09048, avg_loss=0.09432, mel_loss=0.04022, linear_loss=0.05025]
[2020-05-11 20:30:57.221]  Step 144562  [3.339 sec/step, loss=0.10088, avg_loss=0.09432, mel_loss=0.04646, linear_loss=0.05442]
[2020-05-11 20:31:01.992]  Step 144563  [3.379 sec/step, loss=0.09936, avg_loss=0.09449, mel_loss=0.04597, linear_loss=0.05340]
[2020-05-11 20:31:04.606]  Step 144564  [3.394 sec/step, loss=0.09763, avg_loss=0.09461, mel_loss=0.04464, linear_loss=0.05299]
[2020-05-11 20:31:06.388]  Step 144565  [3.395 sec/step, loss=0.09397, avg_loss=0.09461, mel_loss=0.04233, linear_loss=0.05165]
[2020-05-11 20:31:08.053]  Step 144566  [3.396 sec/step, loss=0.09313, avg_loss=0.09460, mel_loss=0.04194, linear_loss=0.05119]
[2020-05-11 20:31:20.294]  Step 144567  [3.503 sec/step, loss=0.08884, avg_loss=0.09455, mel_loss=0.04277, linear_loss=0.04607]
[2020-05-11 20:31:24.438]  Step 144568  [3.501 sec/step, loss=0.10013, avg_loss=0.09453, mel_loss=0.04602, linear_loss=0.05411]
[2020-05-11 20:31:25.252]  Step 144569  [3.477 sec/step, loss=0.08293, avg_loss=0.09436, mel_loss=0.03688, linear_loss=0.04604]
[2020-05-11 20:31:26.372]  Step 144570  [3.448 sec/step, loss=0.08942, avg_loss=0.09426, mel_loss=0.03967, linear_loss=0.04975]
[2020-05-11 20:31:27.383]  Step 144571  [3.368 sec/step, loss=0.08615, avg_loss=0.09410, mel_loss=0.03807, linear_loss=0.04808]
[2020-05-11 20:31:29.565]  Step 144572  [3.363 sec/step, loss=0.09657, avg_loss=0.09410, mel_loss=0.04400, linear_loss=0.05257]
[2020-05-11 20:31:31.199]  Step 144573  [3.360 sec/step, loss=0.09056, avg_loss=0.09404, mel_loss=0.04059, linear_loss=0.04997]
[2020-05-11 20:31:32.990]  Generated 32 batches of size 32 in 1.786 sec
[2020-05-11 20:31:33.556]  Step 144574  [3.350 sec/step, loss=0.09838, avg_loss=0.09405, mel_loss=0.04473, linear_loss=0.05365]
[2020-05-11 20:31:36.637]  Step 144575  [3.335 sec/step, loss=0.10104, avg_loss=0.09404, mel_loss=0.04624, linear_loss=0.05480]
[2020-05-11 20:31:40.155]  Step 144576  [3.225 sec/step, loss=0.10015, avg_loss=0.09423, mel_loss=0.04580, linear_loss=0.05435]
[2020-05-11 20:31:40.919]  Step 144577  [3.204 sec/step, loss=0.07999, avg_loss=0.09405, mel_loss=0.03516, linear_loss=0.04483]
[2020-05-11 20:31:42.949]  Step 144578  [3.214 sec/step, loss=0.09446, avg_loss=0.09412, mel_loss=0.04219, linear_loss=0.05227]
[2020-05-11 20:31:45.848]  Step 144579  [3.167 sec/step, loss=0.10081, avg_loss=0.09411, mel_loss=0.04580, linear_loss=0.05501]
[2020-05-11 20:31:47.184]  Step 144580  [3.157 sec/step, loss=0.09041, avg_loss=0.09403, mel_loss=0.04030, linear_loss=0.05011]
[2020-05-11 20:31:53.968]  Step 144581  [3.168 sec/step, loss=0.10070, avg_loss=0.09405, mel_loss=0.04730, linear_loss=0.05340]
[2020-05-11 20:31:59.635]  Step 144582  [3.202 sec/step, loss=0.10307, avg_loss=0.09413, mel_loss=0.04817, linear_loss=0.05490]
[2020-05-11 20:32:04.255]  Step 144583  [3.219 sec/step, loss=0.10415, avg_loss=0.09418, mel_loss=0.04837, linear_loss=0.05578]
[2020-05-11 20:32:05.058]  Step 144584  [3.203 sec/step, loss=0.08087, avg_loss=0.09402, mel_loss=0.03559, linear_loss=0.04528]
[2020-05-11 20:32:05.942]  Step 144585  [3.203 sec/step, loss=0.08106, avg_loss=0.09403, mel_loss=0.03567, linear_loss=0.04539]
[2020-05-11 20:32:07.016]  Step 144586  [3.200 sec/step, loss=0.08694, avg_loss=0.09398, mel_loss=0.03840, linear_loss=0.04854]
[2020-05-11 20:32:09.424]  Step 144587  [3.211 sec/step, loss=0.09671, avg_loss=0.09405, mel_loss=0.04367, linear_loss=0.05305]
[2020-05-11 20:32:11.139]  Step 144588  [3.165 sec/step, loss=0.09471, avg_loss=0.09398, mel_loss=0.04237, linear_loss=0.05233]
[2020-05-11 20:32:13.259]  Step 144589  [3.168 sec/step, loss=0.09733, avg_loss=0.09402, mel_loss=0.04417, linear_loss=0.05316]
[2020-05-11 20:32:20.551]  Step 144590  [3.235 sec/step, loss=0.10063, avg_loss=0.09430, mel_loss=0.04742, linear_loss=0.05322]
[2020-05-11 20:32:22.999]  Step 144591  [3.204 sec/step, loss=0.09608, avg_loss=0.09422, mel_loss=0.04353, linear_loss=0.05255]
[2020-05-11 20:32:24.881]  Step 144592  [3.191 sec/step, loss=0.09503, avg_loss=0.09415, mel_loss=0.04254, linear_loss=0.05249]
[2020-05-11 20:32:26.314]  Step 144593  [3.137 sec/step, loss=0.08999, avg_loss=0.09402, mel_loss=0.04054, linear_loss=0.04946]
[2020-05-11 20:32:34.894]  Step 144594  [3.170 sec/step, loss=0.10044, avg_loss=0.09401, mel_loss=0.04776, linear_loss=0.05268]
[2020-05-11 20:32:36.917]  Step 144595  [3.153 sec/step, loss=0.09440, avg_loss=0.09393, mel_loss=0.04272, linear_loss=0.05167]
[2020-05-11 20:32:39.645]  Step 144596  [3.068 sec/step, loss=0.09814, avg_loss=0.09395, mel_loss=0.04475, linear_loss=0.05339]
[2020-05-11 20:32:43.013]  Step 144597  [3.081 sec/step, loss=0.09916, avg_loss=0.09397, mel_loss=0.04570, linear_loss=0.05346]
[2020-05-11 20:32:49.064]  Step 144598  [3.129 sec/step, loss=0.10002, avg_loss=0.09408, mel_loss=0.04709, linear_loss=0.05293]
[2020-05-11 20:32:53.065]  Step 144599  [3.160 sec/step, loss=0.10210, avg_loss=0.09426, mel_loss=0.04712, linear_loss=0.05498]
[2020-05-11 20:32:57.343]  Step 144600  [3.129 sec/step, loss=0.09990, avg_loss=0.09425, mel_loss=0.04596, linear_loss=0.05394]
[2020-05-11 20:32:57.344]  Writing summary at step: 144600
[2020-05-11 20:32:58.945]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144600
[2020-05-11 20:33:00.247]  Saving audio and alignment...
[2020-05-11 20:33:18.345]  Input: 소개하실 필요 없어요 첫 곡 정도만 소개 하고 무대가 끝난 후에 방금 들으신 뭐 노래는 어땠다 이렇게 후에 소개 하는 방법도 있습니다~___________________________________
[2020-05-11 20:33:19.734]  Step 144601  [3.131 sec/step, loss=0.08946, avg_loss=0.09427, mel_loss=0.04007, linear_loss=0.04939]
[2020-05-11 20:33:20.750]  Step 144602  [3.124 sec/step, loss=0.08391, avg_loss=0.09416, mel_loss=0.03748, linear_loss=0.04643]
[2020-05-11 20:33:24.324]  Step 144603  [3.146 sec/step, loss=0.10097, avg_loss=0.09428, mel_loss=0.04640, linear_loss=0.05458]
[2020-05-11 20:33:26.050]  Generated 32 batches of size 32 in 1.721 sec
[2020-05-11 20:33:27.751]  Step 144604  [3.162 sec/step, loss=0.10200, avg_loss=0.09436, mel_loss=0.04682, linear_loss=0.05518]
[2020-05-11 20:33:29.493]  Step 144605  [3.153 sec/step, loss=0.09225, avg_loss=0.09433, mel_loss=0.04116, linear_loss=0.05108]
[2020-05-11 20:33:32.368]  Step 144606  [3.147 sec/step, loss=0.09811, avg_loss=0.09432, mel_loss=0.04492, linear_loss=0.05319]
[2020-05-11 20:33:33.555]  Step 144607  [3.076 sec/step, loss=0.08451, avg_loss=0.09417, mel_loss=0.03779, linear_loss=0.04673]
[2020-05-11 20:33:34.109]  Step 144608  [3.040 sec/step, loss=0.07537, avg_loss=0.09392, mel_loss=0.03402, linear_loss=0.04136]
[2020-05-11 20:33:38.919]  Step 144609  [3.081 sec/step, loss=0.10130, avg_loss=0.09416, mel_loss=0.04698, linear_loss=0.05433]
[2020-05-11 20:33:39.748]  Step 144610  [3.048 sec/step, loss=0.08064, avg_loss=0.09396, mel_loss=0.03579, linear_loss=0.04485]
[2020-05-11 20:33:42.886]  Step 144611  [3.057 sec/step, loss=0.09979, avg_loss=0.09401, mel_loss=0.04559, linear_loss=0.05420]
[2020-05-11 20:33:48.324]  Step 144612  [3.090 sec/step, loss=0.10093, avg_loss=0.09408, mel_loss=0.04693, linear_loss=0.05400]
[2020-05-11 20:33:49.163]  Step 144613  [3.091 sec/step, loss=0.08207, avg_loss=0.09408, mel_loss=0.03592, linear_loss=0.04615]
[2020-05-11 20:33:53.524]  Step 144614  [3.111 sec/step, loss=0.10302, avg_loss=0.09415, mel_loss=0.04773, linear_loss=0.05529]
[2020-05-11 20:33:54.313]  Step 144615  [3.111 sec/step, loss=0.08259, avg_loss=0.09422, mel_loss=0.03638, linear_loss=0.04622]
[2020-05-11 20:33:56.269]  Step 144616  [3.105 sec/step, loss=0.09414, avg_loss=0.09418, mel_loss=0.04238, linear_loss=0.05176]
[2020-05-11 20:33:59.623]  Step 144617  [3.091 sec/step, loss=0.09982, avg_loss=0.09417, mel_loss=0.04576, linear_loss=0.05406]
[2020-05-11 20:34:11.737]  Step 144618  [3.183 sec/step, loss=0.08690, avg_loss=0.09403, mel_loss=0.04180, linear_loss=0.04510]
[2020-05-11 20:34:14.130]  Step 144619  [3.191 sec/step, loss=0.09566, avg_loss=0.09405, mel_loss=0.04340, linear_loss=0.05226]
[2020-05-11 20:34:15.843]  Step 144620  [3.197 sec/step, loss=0.09448, avg_loss=0.09412, mel_loss=0.04258, linear_loss=0.05190]
[2020-05-11 20:34:17.056]  Step 144621  [3.194 sec/step, loss=0.08943, avg_loss=0.09409, mel_loss=0.03959, linear_loss=0.04984]
[2020-05-11 20:34:18.827]  Step 144622  [3.180 sec/step, loss=0.09467, avg_loss=0.09404, mel_loss=0.04233, linear_loss=0.05234]
[2020-05-11 20:34:21.313]  Step 144623  [3.184 sec/step, loss=0.09372, avg_loss=0.09402, mel_loss=0.04213, linear_loss=0.05159]
[2020-05-11 20:34:22.909]  Step 144624  [3.187 sec/step, loss=0.08619, avg_loss=0.09398, mel_loss=0.03817, linear_loss=0.04802]
[2020-05-11 20:34:25.160]  Step 144625  [3.171 sec/step, loss=0.09101, avg_loss=0.09388, mel_loss=0.04064, linear_loss=0.05037]
[2020-05-11 20:34:27.193]  Step 144626  [3.103 sec/step, loss=0.08920, avg_loss=0.09378, mel_loss=0.04020, linear_loss=0.04900]
[2020-05-11 20:34:33.034]  Step 144627  [3.150 sec/step, loss=0.10152, avg_loss=0.09395, mel_loss=0.04670, linear_loss=0.05482]
[2020-05-11 20:34:43.000]  Step 144628  [3.240 sec/step, loss=0.10041, avg_loss=0.09407, mel_loss=0.04755, linear_loss=0.05286]
[2020-05-11 20:34:43.568]  Step 144629  [3.221 sec/step, loss=0.07289, avg_loss=0.09383, mel_loss=0.03281, linear_loss=0.04008]
[2020-05-11 20:34:46.820]  Step 144630  [3.239 sec/step, loss=0.10093, avg_loss=0.09392, mel_loss=0.04619, linear_loss=0.05474]
[2020-05-11 20:34:49.307]  Step 144631  [3.221 sec/step, loss=0.09643, avg_loss=0.09388, mel_loss=0.04363, linear_loss=0.05280]
[2020-05-11 20:34:51.378]  Step 144632  [3.230 sec/step, loss=0.09515, avg_loss=0.09393, mel_loss=0.04282, linear_loss=0.05233]
[2020-05-11 20:34:54.936]  Step 144633  [3.236 sec/step, loss=0.09719, avg_loss=0.09394, mel_loss=0.04452, linear_loss=0.05267]
[2020-05-11 20:34:55.998]  Step 144634  [3.169 sec/step, loss=0.08761, avg_loss=0.09379, mel_loss=0.03866, linear_loss=0.04895]
[2020-05-11 20:35:02.841]  Step 144635  [3.172 sec/step, loss=0.10125, avg_loss=0.09378, mel_loss=0.04743, linear_loss=0.05382]
[2020-05-11 20:35:04.546]  Generated 32 batches of size 32 in 1.699 sec
[2020-05-11 20:35:10.449]  Step 144636  [3.105 sec/step, loss=0.10309, avg_loss=0.09401, mel_loss=0.04840, linear_loss=0.05469]
[2020-05-11 20:35:13.348]  Step 144637  [3.101 sec/step, loss=0.09853, avg_loss=0.09398, mel_loss=0.04502, linear_loss=0.05351]
[2020-05-11 20:35:18.370]  Step 144638  [3.146 sec/step, loss=0.09836, avg_loss=0.09422, mel_loss=0.04564, linear_loss=0.05272]
[2020-05-11 20:35:19.207]  Step 144639  [3.134 sec/step, loss=0.08002, avg_loss=0.09406, mel_loss=0.03567, linear_loss=0.04435]
[2020-05-11 20:35:23.340]  Step 144640  [3.129 sec/step, loss=0.10053, avg_loss=0.09406, mel_loss=0.04626, linear_loss=0.05428]
[2020-05-11 20:35:25.465]  Step 144641  [3.102 sec/step, loss=0.09747, avg_loss=0.09402, mel_loss=0.04435, linear_loss=0.05313]
[2020-05-11 20:35:31.072]  Step 144642  [3.149 sec/step, loss=0.10014, avg_loss=0.09420, mel_loss=0.04655, linear_loss=0.05359]
[2020-05-11 20:35:33.803]  Step 144643  [3.170 sec/step, loss=0.09561, avg_loss=0.09434, mel_loss=0.04362, linear_loss=0.05199]
[2020-05-11 20:35:35.115]  Step 144644  [3.162 sec/step, loss=0.09147, avg_loss=0.09432, mel_loss=0.04095, linear_loss=0.05052]
[2020-05-11 20:35:39.761]  Step 144645  [3.175 sec/step, loss=0.10249, avg_loss=0.09437, mel_loss=0.04753, linear_loss=0.05496]
[2020-05-11 20:35:40.877]  Step 144646  [3.161 sec/step, loss=0.08718, avg_loss=0.09427, mel_loss=0.03870, linear_loss=0.04847]
[2020-05-11 20:35:55.389]  Step 144647  [3.252 sec/step, loss=0.08132, avg_loss=0.09407, mel_loss=0.03937, linear_loss=0.04195]
[2020-05-11 20:35:57.843]  Step 144648  [3.258 sec/step, loss=0.09607, avg_loss=0.09411, mel_loss=0.04354, linear_loss=0.05253]
[2020-05-11 20:35:59.537]  Step 144649  [3.262 sec/step, loss=0.09528, avg_loss=0.09414, mel_loss=0.04295, linear_loss=0.05233]
[2020-05-11 20:36:02.407]  Step 144650  [3.255 sec/step, loss=0.09816, avg_loss=0.09411, mel_loss=0.04494, linear_loss=0.05323]
[2020-05-11 20:36:02.407]  Writing summary at step: 144650
[2020-05-11 20:36:03.962]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144650
[2020-05-11 20:36:05.300]  Saving audio and alignment...
[2020-05-11 20:36:13.074]  Input: 지금 제가 손에 들고 있는 이 양파 정말 특이한 효능이 숨어 있는 걸까요 멘트만 이렇게 하시구요~_____
[2020-05-11 20:36:18.732]  Step 144651  [3.258 sec/step, loss=0.10378, avg_loss=0.09412, mel_loss=0.04864, linear_loss=0.05514]
[2020-05-11 20:36:22.138]  Step 144652  [3.255 sec/step, loss=0.09915, avg_loss=0.09411, mel_loss=0.04573, linear_loss=0.05342]
[2020-05-11 20:36:22.664]  Step 144653  [3.241 sec/step, loss=0.07660, avg_loss=0.09392, mel_loss=0.03510, linear_loss=0.04151]
[2020-05-11 20:36:24.872]  Step 144654  [3.239 sec/step, loss=0.09580, avg_loss=0.09394, mel_loss=0.04367, linear_loss=0.05213]
[2020-05-11 20:36:32.208]  Step 144655  [3.238 sec/step, loss=0.10092, avg_loss=0.09392, mel_loss=0.04773, linear_loss=0.05319]
[2020-05-11 20:36:38.520]  Step 144656  [3.291 sec/step, loss=0.10185, avg_loss=0.09408, mel_loss=0.04768, linear_loss=0.05417]
[2020-05-11 20:36:42.044]  Step 144657  [3.240 sec/step, loss=0.10097, avg_loss=0.09409, mel_loss=0.04635, linear_loss=0.05462]
[2020-05-11 20:36:45.706]  Step 144658  [3.243 sec/step, loss=0.10109, avg_loss=0.09413, mel_loss=0.04638, linear_loss=0.05471]
[2020-05-11 20:36:46.760]  Step 144659  [3.248 sec/step, loss=0.08329, avg_loss=0.09424, mel_loss=0.03697, linear_loss=0.04632]
[2020-05-11 20:36:55.447]  Step 144660  [3.321 sec/step, loss=0.10005, avg_loss=0.09432, mel_loss=0.04743, linear_loss=0.05262]
[2020-05-11 20:36:58.602]  Step 144661  [3.340 sec/step, loss=0.10056, avg_loss=0.09442, mel_loss=0.04592, linear_loss=0.05464]
[2020-05-11 20:37:00.513]  Step 144662  [3.316 sec/step, loss=0.09563, avg_loss=0.09436, mel_loss=0.04298, linear_loss=0.05265]
[2020-05-11 20:37:01.882]  Step 144663  [3.282 sec/step, loss=0.08911, avg_loss=0.09426, mel_loss=0.03992, linear_loss=0.04919]
[2020-05-11 20:37:03.273]  Step 144664  [3.270 sec/step, loss=0.09070, avg_loss=0.09419, mel_loss=0.04069, linear_loss=0.05001]
[2020-05-11 20:37:04.448]  Step 144665  [3.264 sec/step, loss=0.08955, avg_loss=0.09415, mel_loss=0.03984, linear_loss=0.04971]
[2020-05-11 20:37:05.300]  Step 144666  [3.256 sec/step, loss=0.07734, avg_loss=0.09399, mel_loss=0.03401, linear_loss=0.04333]
[2020-05-11 20:37:06.237]  Generated 32 batches of size 32 in 1.784 sec
[2020-05-11 20:37:08.093]  Step 144667  [3.161 sec/step, loss=0.09653, avg_loss=0.09407, mel_loss=0.04385, linear_loss=0.05267]
[2020-05-11 20:37:10.244]  Step 144668  [3.141 sec/step, loss=0.09647, avg_loss=0.09403, mel_loss=0.04338, linear_loss=0.05309]
[2020-05-11 20:37:14.327]  Step 144669  [3.174 sec/step, loss=0.09985, avg_loss=0.09420, mel_loss=0.04585, linear_loss=0.05400]
[2020-05-11 20:37:17.351]  Step 144670  [3.193 sec/step, loss=0.09879, avg_loss=0.09429, mel_loss=0.04521, linear_loss=0.05358]
[2020-05-11 20:37:18.251]  Step 144671  [3.192 sec/step, loss=0.08602, avg_loss=0.09429, mel_loss=0.03803, linear_loss=0.04799]
[2020-05-11 20:37:19.045]  Step 144672  [3.178 sec/step, loss=0.08482, avg_loss=0.09417, mel_loss=0.03752, linear_loss=0.04730]
[2020-05-11 20:37:23.426]  Step 144673  [3.205 sec/step, loss=0.09957, avg_loss=0.09426, mel_loss=0.04610, linear_loss=0.05347]
[2020-05-11 20:37:25.244]  Step 144674  [3.200 sec/step, loss=0.09214, avg_loss=0.09420, mel_loss=0.04109, linear_loss=0.05105]
[2020-05-11 20:37:26.479]  Step 144675  [3.181 sec/step, loss=0.08691, avg_loss=0.09406, mel_loss=0.03869, linear_loss=0.04822]
[2020-05-11 20:37:28.859]  Step 144676  [3.170 sec/step, loss=0.09601, avg_loss=0.09402, mel_loss=0.04359, linear_loss=0.05242]
[2020-05-11 20:37:32.241]  Step 144677  [3.196 sec/step, loss=0.09816, avg_loss=0.09420, mel_loss=0.04479, linear_loss=0.05337]
[2020-05-11 20:37:33.284]  Step 144678  [3.186 sec/step, loss=0.08553, avg_loss=0.09411, mel_loss=0.03809, linear_loss=0.04744]
[2020-05-11 20:37:34.620]  Step 144679  [3.171 sec/step, loss=0.09233, avg_loss=0.09403, mel_loss=0.04104, linear_loss=0.05130]
[2020-05-11 20:37:41.942]  Step 144680  [3.231 sec/step, loss=0.10160, avg_loss=0.09414, mel_loss=0.04789, linear_loss=0.05370]
[2020-05-11 20:37:42.903]  Step 144681  [3.172 sec/step, loss=0.08263, avg_loss=0.09396, mel_loss=0.03631, linear_loss=0.04632]
[2020-05-11 20:37:45.351]  Step 144682  [3.140 sec/step, loss=0.09467, avg_loss=0.09387, mel_loss=0.04254, linear_loss=0.05213]
[2020-05-11 20:37:58.354]  Step 144683  [3.224 sec/step, loss=0.08598, avg_loss=0.09369, mel_loss=0.04132, linear_loss=0.04466]
[2020-05-11 20:38:00.146]  Step 144684  [3.234 sec/step, loss=0.09200, avg_loss=0.09380, mel_loss=0.04120, linear_loss=0.05080]
[2020-05-11 20:38:06.738]  Step 144685  [3.291 sec/step, loss=0.10207, avg_loss=0.09401, mel_loss=0.04793, linear_loss=0.05413]
[2020-05-11 20:38:15.457]  Step 144686  [3.367 sec/step, loss=0.10140, avg_loss=0.09416, mel_loss=0.04821, linear_loss=0.05318]
[2020-05-11 20:38:16.279]  Step 144687  [3.352 sec/step, loss=0.08429, avg_loss=0.09403, mel_loss=0.03721, linear_loss=0.04708]
[2020-05-11 20:38:18.241]  Step 144688  [3.354 sec/step, loss=0.09509, avg_loss=0.09404, mel_loss=0.04274, linear_loss=0.05235]
[2020-05-11 20:38:22.763]  Step 144689  [3.378 sec/step, loss=0.10150, avg_loss=0.09408, mel_loss=0.04664, linear_loss=0.05486]
[2020-05-11 20:38:23.855]  Step 144690  [3.316 sec/step, loss=0.08934, avg_loss=0.09397, mel_loss=0.03943, linear_loss=0.04991]
[2020-05-11 20:38:25.271]  Step 144691  [3.306 sec/step, loss=0.09090, avg_loss=0.09391, mel_loss=0.04040, linear_loss=0.05050]
[2020-05-11 20:38:28.364]  Step 144692  [3.318 sec/step, loss=0.09849, avg_loss=0.09395, mel_loss=0.04480, linear_loss=0.05369]
[2020-05-11 20:38:29.989]  Step 144693  [3.320 sec/step, loss=0.09144, avg_loss=0.09396, mel_loss=0.04091, linear_loss=0.05053]
[2020-05-11 20:38:33.557]  Step 144694  [3.270 sec/step, loss=0.10115, avg_loss=0.09397, mel_loss=0.04634, linear_loss=0.05482]
[2020-05-11 20:38:34.606]  Step 144695  [3.260 sec/step, loss=0.07890, avg_loss=0.09382, mel_loss=0.03503, linear_loss=0.04386]
[2020-05-11 20:38:36.810]  Step 144696  [3.255 sec/step, loss=0.09608, avg_loss=0.09380, mel_loss=0.04334, linear_loss=0.05274]
[2020-05-11 20:38:42.377]  Step 144697  [3.277 sec/step, loss=0.10075, avg_loss=0.09381, mel_loss=0.04689, linear_loss=0.05386]
[2020-05-11 20:38:44.129]  Generated 32 batches of size 32 in 1.745 sec
[2020-05-11 20:38:45.338]  Step 144698  [3.246 sec/step, loss=0.09866, avg_loss=0.09380, mel_loss=0.04528, linear_loss=0.05339]
[2020-05-11 20:38:49.703]  Step 144699  [3.249 sec/step, loss=0.10033, avg_loss=0.09378, mel_loss=0.04659, linear_loss=0.05375]
[2020-05-11 20:38:51.599]  Step 144700  [3.226 sec/step, loss=0.09550, avg_loss=0.09374, mel_loss=0.04279, linear_loss=0.05271]
[2020-05-11 20:38:51.599]  Writing summary at step: 144700
[2020-05-11 20:38:52.173]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144700
[2020-05-11 20:38:53.473]  Saving audio and alignment...
[2020-05-11 20:38:57.729]  Input: 텃세를 어떻게 극복할 생각인가~__________________________
[2020-05-11 20:39:01.309]  Step 144701  [3.248 sec/step, loss=0.10029, avg_loss=0.09384, mel_loss=0.04593, linear_loss=0.05436]
[2020-05-11 20:39:05.363]  Step 144702  [3.278 sec/step, loss=0.09911, avg_loss=0.09400, mel_loss=0.04561, linear_loss=0.05350]
[2020-05-11 20:39:06.951]  Step 144703  [3.258 sec/step, loss=0.09385, avg_loss=0.09392, mel_loss=0.04207, linear_loss=0.05178]
[2020-05-11 20:39:12.039]  Step 144704  [3.275 sec/step, loss=0.10168, avg_loss=0.09392, mel_loss=0.04734, linear_loss=0.05435]
[2020-05-11 20:39:12.864]  Step 144705  [3.265 sec/step, loss=0.08202, avg_loss=0.09382, mel_loss=0.03650, linear_loss=0.04553]
[2020-05-11 20:39:21.472]  Step 144706  [3.323 sec/step, loss=0.09937, avg_loss=0.09383, mel_loss=0.04719, linear_loss=0.05218]
[2020-05-11 20:39:22.591]  Step 144707  [3.322 sec/step, loss=0.08678, avg_loss=0.09385, mel_loss=0.03849, linear_loss=0.04829]
[2020-05-11 20:39:37.484]  Step 144708  [3.466 sec/step, loss=0.07992, avg_loss=0.09390, mel_loss=0.03868, linear_loss=0.04124]
[2020-05-11 20:39:42.573]  Step 144709  [3.468 sec/step, loss=0.10124, avg_loss=0.09390, mel_loss=0.04714, linear_loss=0.05410]
[2020-05-11 20:39:46.694]  Step 144710  [3.501 sec/step, loss=0.10367, avg_loss=0.09413, mel_loss=0.04782, linear_loss=0.05586]
[2020-05-11 20:39:49.301]  Step 144711  [3.496 sec/step, loss=0.09892, avg_loss=0.09412, mel_loss=0.04516, linear_loss=0.05377]
[2020-05-11 20:39:51.755]  Step 144712  [3.466 sec/step, loss=0.09655, avg_loss=0.09408, mel_loss=0.04365, linear_loss=0.05290]
[2020-05-11 20:39:53.785]  Step 144713  [3.478 sec/step, loss=0.09604, avg_loss=0.09422, mel_loss=0.04361, linear_loss=0.05243]
[2020-05-11 20:39:54.783]  Step 144714  [3.444 sec/step, loss=0.08511, avg_loss=0.09404, mel_loss=0.03757, linear_loss=0.04754]
[2020-05-11 20:39:58.439]  Step 144715  [3.473 sec/step, loss=0.10171, avg_loss=0.09423, mel_loss=0.04663, linear_loss=0.05508]
[2020-05-11 20:40:00.239]  Step 144716  [3.471 sec/step, loss=0.09261, avg_loss=0.09421, mel_loss=0.04131, linear_loss=0.05130]
[2020-05-11 20:40:03.776]  Step 144717  [3.473 sec/step, loss=0.10149, avg_loss=0.09423, mel_loss=0.04676, linear_loss=0.05474]
[2020-05-11 20:40:07.923]  Step 144718  [3.394 sec/step, loss=0.09901, avg_loss=0.09435, mel_loss=0.04539, linear_loss=0.05362]
[2020-05-11 20:40:13.532]  Step 144719  [3.426 sec/step, loss=0.10286, avg_loss=0.09442, mel_loss=0.04797, linear_loss=0.05489]
[2020-05-11 20:40:21.239]  Step 144720  [3.486 sec/step, loss=0.10228, avg_loss=0.09450, mel_loss=0.04809, linear_loss=0.05419]
[2020-05-11 20:40:23.456]  Step 144721  [3.496 sec/step, loss=0.09449, avg_loss=0.09455, mel_loss=0.04291, linear_loss=0.05157]
[2020-05-11 20:40:24.682]  Step 144722  [3.490 sec/step, loss=0.08743, avg_loss=0.09448, mel_loss=0.03907, linear_loss=0.04836]
[2020-05-11 20:40:31.181]  Step 144723  [3.530 sec/step, loss=0.10249, avg_loss=0.09457, mel_loss=0.04804, linear_loss=0.05445]
[2020-05-11 20:40:34.677]  Step 144724  [3.549 sec/step, loss=0.09853, avg_loss=0.09469, mel_loss=0.04512, linear_loss=0.05341]
[2020-05-11 20:40:37.612]  Step 144725  [3.556 sec/step, loss=0.09927, avg_loss=0.09477, mel_loss=0.04511, linear_loss=0.05416]
[2020-05-11 20:40:38.584]  Step 144726  [3.546 sec/step, loss=0.08868, avg_loss=0.09477, mel_loss=0.03940, linear_loss=0.04928]
[2020-05-11 20:40:39.350]  Step 144727  [3.495 sec/step, loss=0.08602, avg_loss=0.09461, mel_loss=0.03778, linear_loss=0.04823]
[2020-05-11 20:40:41.070]  Generated 32 batches of size 32 in 1.714 sec
[2020-05-11 20:40:42.532]  Step 144728  [3.427 sec/step, loss=0.10141, avg_loss=0.09462, mel_loss=0.04656, linear_loss=0.05485]
[2020-05-11 20:40:44.040]  Step 144729  [3.437 sec/step, loss=0.09288, avg_loss=0.09482, mel_loss=0.04179, linear_loss=0.05109]
[2020-05-11 20:40:46.306]  Step 144730  [3.427 sec/step, loss=0.09784, avg_loss=0.09479, mel_loss=0.04444, linear_loss=0.05340]
[2020-05-11 20:40:47.693]  Step 144731  [3.416 sec/step, loss=0.09217, avg_loss=0.09475, mel_loss=0.04162, linear_loss=0.05055]
[2020-05-11 20:40:49.608]  Step 144732  [3.414 sec/step, loss=0.09453, avg_loss=0.09474, mel_loss=0.04231, linear_loss=0.05222]
[2020-05-11 20:40:51.330]  Step 144733  [3.396 sec/step, loss=0.09390, avg_loss=0.09471, mel_loss=0.04198, linear_loss=0.05192]
[2020-05-11 20:40:56.053]  Step 144734  [3.432 sec/step, loss=0.10134, avg_loss=0.09485, mel_loss=0.04673, linear_loss=0.05462]
[2020-05-11 20:40:56.620]  Step 144735  [3.370 sec/step, loss=0.07350, avg_loss=0.09457, mel_loss=0.03365, linear_loss=0.03985]
[2020-05-11 20:40:57.929]  Step 144736  [3.307 sec/step, loss=0.09106, avg_loss=0.09445, mel_loss=0.04071, linear_loss=0.05034]
[2020-05-11 20:41:01.335]  Step 144737  [3.312 sec/step, loss=0.09693, avg_loss=0.09443, mel_loss=0.04453, linear_loss=0.05240]
[2020-05-11 20:41:02.750]  Step 144738  [3.276 sec/step, loss=0.09068, avg_loss=0.09436, mel_loss=0.04070, linear_loss=0.04998]
[2020-05-11 20:41:03.985]  Step 144739  [3.280 sec/step, loss=0.08537, avg_loss=0.09441, mel_loss=0.03791, linear_loss=0.04746]
[2020-05-11 20:41:04.963]  Step 144740  [3.248 sec/step, loss=0.08465, avg_loss=0.09425, mel_loss=0.03761, linear_loss=0.04705]
[2020-05-11 20:41:07.353]  Step 144741  [3.251 sec/step, loss=0.09629, avg_loss=0.09424, mel_loss=0.04377, linear_loss=0.05253]
[2020-05-11 20:41:08.471]  Step 144742  [3.206 sec/step, loss=0.08670, avg_loss=0.09411, mel_loss=0.03821, linear_loss=0.04849]
[2020-05-11 20:41:10.059]  Step 144743  [3.194 sec/step, loss=0.09416, avg_loss=0.09409, mel_loss=0.04226, linear_loss=0.05190]
[2020-05-11 20:41:13.411]  Step 144744  [3.215 sec/step, loss=0.10111, avg_loss=0.09419, mel_loss=0.04628, linear_loss=0.05483]
[2020-05-11 20:41:18.929]  Step 144745  [3.223 sec/step, loss=0.10351, avg_loss=0.09420, mel_loss=0.04830, linear_loss=0.05521]
[2020-05-11 20:41:22.961]  Step 144746  [3.253 sec/step, loss=0.10254, avg_loss=0.09435, mel_loss=0.04724, linear_loss=0.05529]
[2020-05-11 20:41:28.932]  Step 144747  [3.167 sec/step, loss=0.10183, avg_loss=0.09456, mel_loss=0.04781, linear_loss=0.05402]
[2020-05-11 20:41:32.565]  Step 144748  [3.179 sec/step, loss=0.10076, avg_loss=0.09460, mel_loss=0.04632, linear_loss=0.05444]
[2020-05-11 20:41:35.675]  Step 144749  [3.193 sec/step, loss=0.09877, avg_loss=0.09464, mel_loss=0.04502, linear_loss=0.05374]
[2020-05-11 20:41:43.796]  Step 144750  [3.246 sec/step, loss=0.09757, avg_loss=0.09463, mel_loss=0.04621, linear_loss=0.05136]
[2020-05-11 20:41:43.797]  Writing summary at step: 144750
[2020-05-11 20:41:45.628]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144750
[2020-05-11 20:41:46.934]  Saving audio and alignment...
[2020-05-11 20:41:48.593]  Input: 궁금해하세요~____________________
[2020-05-11 20:41:50.507]  Step 144751  [3.208 sec/step, loss=0.09348, avg_loss=0.09453, mel_loss=0.04188, linear_loss=0.05160]
[2020-05-11 20:41:51.394]  Step 144752  [3.183 sec/step, loss=0.08261, avg_loss=0.09436, mel_loss=0.03635, linear_loss=0.04626]
[2020-05-11 20:41:54.284]  Step 144753  [3.207 sec/step, loss=0.09911, avg_loss=0.09459, mel_loss=0.04534, linear_loss=0.05377]
[2020-05-11 20:41:54.844]  Step 144754  [3.190 sec/step, loss=0.07413, avg_loss=0.09437, mel_loss=0.03344, linear_loss=0.04068]
[2020-05-11 20:41:56.194]  Step 144755  [3.130 sec/step, loss=0.09168, avg_loss=0.09428, mel_loss=0.04073, linear_loss=0.05095]
[2020-05-11 20:41:57.833]  Step 144756  [3.084 sec/step, loss=0.09315, avg_loss=0.09419, mel_loss=0.04194, linear_loss=0.05121]
[2020-05-11 20:41:58.591]  Step 144757  [3.056 sec/step, loss=0.08452, avg_loss=0.09403, mel_loss=0.03726, linear_loss=0.04726]
[2020-05-11 20:42:00.257]  Generated 32 batches of size 32 in 1.662 sec
[2020-05-11 20:42:10.969]  Step 144758  [3.143 sec/step, loss=0.08915, avg_loss=0.09391, mel_loss=0.04307, linear_loss=0.04608]
[2020-05-11 20:42:13.604]  Step 144759  [3.159 sec/step, loss=0.09522, avg_loss=0.09403, mel_loss=0.04291, linear_loss=0.05232]
[2020-05-11 20:42:20.930]  Step 144760  [3.145 sec/step, loss=0.10388, avg_loss=0.09407, mel_loss=0.04879, linear_loss=0.05509]
[2020-05-11 20:42:23.680]  Step 144761  [3.141 sec/step, loss=0.09731, avg_loss=0.09403, mel_loss=0.04443, linear_loss=0.05288]
[2020-05-11 20:42:28.200]  Step 144762  [3.167 sec/step, loss=0.10185, avg_loss=0.09410, mel_loss=0.04736, linear_loss=0.05449]
[2020-05-11 20:42:33.356]  Step 144763  [3.205 sec/step, loss=0.10081, avg_loss=0.09421, mel_loss=0.04681, linear_loss=0.05400]
[2020-05-11 20:42:35.404]  Step 144764  [3.212 sec/step, loss=0.09777, avg_loss=0.09428, mel_loss=0.04427, linear_loss=0.05350]
[2020-05-11 20:42:37.429]  Step 144765  [3.220 sec/step, loss=0.09384, avg_loss=0.09433, mel_loss=0.04224, linear_loss=0.05159]
[2020-05-11 20:42:41.532]  Step 144766  [3.253 sec/step, loss=0.10087, avg_loss=0.09456, mel_loss=0.04661, linear_loss=0.05426]
[2020-05-11 20:42:42.651]  Step 144767  [3.236 sec/step, loss=0.08823, avg_loss=0.09448, mel_loss=0.03874, linear_loss=0.04950]
[2020-05-11 20:42:51.205]  Step 144768  [3.300 sec/step, loss=0.10051, avg_loss=0.09452, mel_loss=0.04750, linear_loss=0.05301]
[2020-05-11 20:42:58.489]  Step 144769  [3.332 sec/step, loss=0.10284, avg_loss=0.09455, mel_loss=0.04867, linear_loss=0.05417]
[2020-05-11 20:43:01.903]  Step 144770  [3.336 sec/step, loss=0.09743, avg_loss=0.09454, mel_loss=0.04425, linear_loss=0.05317]
[2020-05-11 20:43:08.624]  Step 144771  [3.394 sec/step, loss=0.09987, avg_loss=0.09467, mel_loss=0.04681, linear_loss=0.05306]
[2020-05-11 20:43:12.836]  Step 144772  [3.428 sec/step, loss=0.10048, avg_loss=0.09483, mel_loss=0.04642, linear_loss=0.05405]
[2020-05-11 20:43:14.368]  Step 144773  [3.400 sec/step, loss=0.09263, avg_loss=0.09476, mel_loss=0.04161, linear_loss=0.05102]
[2020-05-11 20:43:15.763]  Step 144774  [3.396 sec/step, loss=0.09175, avg_loss=0.09476, mel_loss=0.04119, linear_loss=0.05057]
[2020-05-11 20:43:20.939]  Step 144775  [3.435 sec/step, loss=0.10099, avg_loss=0.09490, mel_loss=0.04701, linear_loss=0.05398]
[2020-05-11 20:43:26.531]  Step 144776  [3.467 sec/step, loss=0.10045, avg_loss=0.09494, mel_loss=0.04681, linear_loss=0.05364]
[2020-05-11 20:43:27.883]  Step 144777  [3.447 sec/step, loss=0.08873, avg_loss=0.09485, mel_loss=0.03964, linear_loss=0.04909]
[2020-05-11 20:43:29.848]  Step 144778  [3.456 sec/step, loss=0.09754, avg_loss=0.09497, mel_loss=0.04409, linear_loss=0.05345]
[2020-05-11 20:43:32.692]  Step 144779  [3.471 sec/step, loss=0.09856, avg_loss=0.09503, mel_loss=0.04491, linear_loss=0.05365]
[2020-05-11 20:43:34.279]  Step 144780  [3.414 sec/step, loss=0.09340, avg_loss=0.09495, mel_loss=0.04167, linear_loss=0.05173]
[2020-05-11 20:43:35.084]  Step 144781  [3.412 sec/step, loss=0.08061, avg_loss=0.09493, mel_loss=0.03556, linear_loss=0.04504]
[2020-05-11 20:43:38.191]  Step 144782  [3.419 sec/step, loss=0.10074, avg_loss=0.09499, mel_loss=0.04616, linear_loss=0.05458]
[2020-05-11 20:43:40.810]  Step 144783  [3.315 sec/step, loss=0.09763, avg_loss=0.09511, mel_loss=0.04445, linear_loss=0.05318]
[2020-05-11 20:43:41.817]  Step 144784  [3.307 sec/step, loss=0.08400, avg_loss=0.09503, mel_loss=0.03706, linear_loss=0.04694]
[2020-05-11 20:43:43.966]  Step 144785  [3.263 sec/step, loss=0.09563, avg_loss=0.09496, mel_loss=0.04295, linear_loss=0.05268]
[2020-05-11 20:43:47.261]  Step 144786  [3.209 sec/step, loss=0.10125, avg_loss=0.09496, mel_loss=0.04694, linear_loss=0.05431]
[2020-05-11 20:43:49.023]  Step 144787  [3.218 sec/step, loss=0.09303, avg_loss=0.09505, mel_loss=0.04167, linear_loss=0.05136]
[2020-05-11 20:43:50.238]  Step 144788  [3.210 sec/step, loss=0.08824, avg_loss=0.09498, mel_loss=0.03916, linear_loss=0.04908]
[2020-05-11 20:43:50.883]  Step 144789  [3.172 sec/step, loss=0.08266, avg_loss=0.09479, mel_loss=0.03659, linear_loss=0.04607]
[2020-05-11 20:43:52.588]  Generated 32 batches of size 32 in 1.701 sec
[2020-05-11 20:43:52.856]  Step 144790  [3.181 sec/step, loss=0.09625, avg_loss=0.09486, mel_loss=0.04336, linear_loss=0.05289]
[2020-05-11 20:43:55.089]  Step 144791  [3.189 sec/step, loss=0.09551, avg_loss=0.09491, mel_loss=0.04324, linear_loss=0.05226]
[2020-05-11 20:44:09.212]  Step 144792  [3.299 sec/step, loss=0.07908, avg_loss=0.09471, mel_loss=0.03804, linear_loss=0.04104]
[2020-05-11 20:44:10.211]  Step 144793  [3.293 sec/step, loss=0.08571, avg_loss=0.09465, mel_loss=0.03785, linear_loss=0.04786]
[2020-05-11 20:44:12.680]  Step 144794  [3.282 sec/step, loss=0.09811, avg_loss=0.09462, mel_loss=0.04480, linear_loss=0.05331]
[2020-05-11 20:44:17.211]  Step 144795  [3.317 sec/step, loss=0.10027, avg_loss=0.09484, mel_loss=0.04627, linear_loss=0.05400]
[2020-05-11 20:44:20.902]  Step 144796  [3.331 sec/step, loss=0.10212, avg_loss=0.09490, mel_loss=0.04685, linear_loss=0.05528]
[2020-05-11 20:44:21.467]  Step 144797  [3.281 sec/step, loss=0.07511, avg_loss=0.09464, mel_loss=0.03404, linear_loss=0.04106]
[2020-05-11 20:44:25.055]  Step 144798  [3.288 sec/step, loss=0.10043, avg_loss=0.09466, mel_loss=0.04612, linear_loss=0.05431]
[2020-05-11 20:44:30.637]  Step 144799  [3.300 sec/step, loss=0.10164, avg_loss=0.09467, mel_loss=0.04715, linear_loss=0.05448]
[2020-05-11 20:44:40.881]  Step 144800  [3.383 sec/step, loss=0.09921, avg_loss=0.09471, mel_loss=0.04706, linear_loss=0.05215]
[2020-05-11 20:44:40.881]  Writing summary at step: 144800
[2020-05-11 20:44:46.384]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144800
[2020-05-11 20:44:50.952]  Saving audio and alignment...
[2020-05-11 20:44:53.492]  Input: 교재를 보겠습니다~______________
[2020-05-11 20:44:55.246]  Step 144801  [3.365 sec/step, loss=0.08939, avg_loss=0.09460, mel_loss=0.03984, linear_loss=0.04954]
[2020-05-11 20:44:56.324]  Step 144802  [3.335 sec/step, loss=0.08980, avg_loss=0.09451, mel_loss=0.03967, linear_loss=0.05012]
[2020-05-11 20:45:01.281]  Step 144803  [3.369 sec/step, loss=0.10107, avg_loss=0.09458, mel_loss=0.04656, linear_loss=0.05452]
[2020-05-11 20:45:03.054]  Step 144804  [3.336 sec/step, loss=0.09488, avg_loss=0.09451, mel_loss=0.04234, linear_loss=0.05254]
[2020-05-11 20:45:03.859]  Step 144805  [3.336 sec/step, loss=0.08484, avg_loss=0.09454, mel_loss=0.03740, linear_loss=0.04744]
[2020-05-11 20:45:05.911]  Step 144806  [3.270 sec/step, loss=0.09471, avg_loss=0.09449, mel_loss=0.04241, linear_loss=0.05230]
[2020-05-11 20:45:08.853]  Step 144807  [3.288 sec/step, loss=0.09519, avg_loss=0.09458, mel_loss=0.04357, linear_loss=0.05162]
[2020-05-11 20:45:13.149]  Step 144808  [3.182 sec/step, loss=0.10165, avg_loss=0.09479, mel_loss=0.04716, linear_loss=0.05450]
[2020-05-11 20:45:14.833]  Step 144809  [3.148 sec/step, loss=0.09408, avg_loss=0.09472, mel_loss=0.04228, linear_loss=0.05180]
[2020-05-11 20:45:15.402]  Step 144810  [3.113 sec/step, loss=0.07564, avg_loss=0.09444, mel_loss=0.03437, linear_loss=0.04128]
[2020-05-11 20:45:16.766]  Step 144811  [3.100 sec/step, loss=0.09109, avg_loss=0.09436, mel_loss=0.04052, linear_loss=0.05057]
[2020-05-11 20:45:17.642]  Step 144812  [3.085 sec/step, loss=0.08341, avg_loss=0.09423, mel_loss=0.03650, linear_loss=0.04691]
[2020-05-11 20:45:23.571]  Step 144813  [3.124 sec/step, loss=0.10305, avg_loss=0.09430, mel_loss=0.04815, linear_loss=0.05490]
[2020-05-11 20:45:25.975]  Step 144814  [3.138 sec/step, loss=0.09517, avg_loss=0.09440, mel_loss=0.04282, linear_loss=0.05235]
[2020-05-11 20:45:29.693]  Step 144815  [3.138 sec/step, loss=0.10095, avg_loss=0.09440, mel_loss=0.04653, linear_loss=0.05443]
[2020-05-11 20:45:33.886]  Step 144816  [3.162 sec/step, loss=0.09909, avg_loss=0.09446, mel_loss=0.04546, linear_loss=0.05363]
[2020-05-11 20:45:34.854]  Step 144817  [3.136 sec/step, loss=0.08771, avg_loss=0.09432, mel_loss=0.03916, linear_loss=0.04855]
[2020-05-11 20:45:36.086]  Step 144818  [3.107 sec/step, loss=0.08766, avg_loss=0.09421, mel_loss=0.03877, linear_loss=0.04889]
[2020-05-11 20:45:38.331]  Step 144819  [3.074 sec/step, loss=0.09420, avg_loss=0.09412, mel_loss=0.04283, linear_loss=0.05137]
[2020-05-11 20:45:40.271]  Generated 32 batches of size 32 in 1.935 sec
[2020-05-11 20:45:41.126]  Step 144820  [3.025 sec/step, loss=0.09714, avg_loss=0.09407, mel_loss=0.04426, linear_loss=0.05288]
[2020-05-11 20:45:43.302]  Step 144821  [3.024 sec/step, loss=0.09555, avg_loss=0.09408, mel_loss=0.04325, linear_loss=0.05229]
[2020-05-11 20:45:46.375]  Step 144822  [3.043 sec/step, loss=0.09810, avg_loss=0.09419, mel_loss=0.04503, linear_loss=0.05307]
[2020-05-11 20:45:47.137]  Step 144823  [2.985 sec/step, loss=0.08131, avg_loss=0.09398, mel_loss=0.03636, linear_loss=0.04495]
[2020-05-11 20:45:54.903]  Step 144824  [3.028 sec/step, loss=0.10291, avg_loss=0.09402, mel_loss=0.04847, linear_loss=0.05444]
[2020-05-11 20:46:09.735]  Step 144825  [3.147 sec/step, loss=0.07953, avg_loss=0.09382, mel_loss=0.03866, linear_loss=0.04087]
[2020-05-11 20:46:11.605]  Step 144826  [3.156 sec/step, loss=0.09317, avg_loss=0.09387, mel_loss=0.04152, linear_loss=0.05165]
[2020-05-11 20:46:15.126]  Step 144827  [3.183 sec/step, loss=0.09944, avg_loss=0.09400, mel_loss=0.04582, linear_loss=0.05361]
[2020-05-11 20:46:21.909]  Step 144828  [3.219 sec/step, loss=0.10281, avg_loss=0.09402, mel_loss=0.04828, linear_loss=0.05453]
[2020-05-11 20:46:22.675]  Step 144829  [3.212 sec/step, loss=0.07304, avg_loss=0.09382, mel_loss=0.03295, linear_loss=0.04009]
[2020-05-11 20:46:23.436]  Step 144830  [3.197 sec/step, loss=0.07950, avg_loss=0.09363, mel_loss=0.03496, linear_loss=0.04454]
[2020-05-11 20:46:24.568]  Step 144831  [3.194 sec/step, loss=0.08877, avg_loss=0.09360, mel_loss=0.03922, linear_loss=0.04955]
[2020-05-11 20:46:29.485]  Step 144832  [3.224 sec/step, loss=0.10113, avg_loss=0.09367, mel_loss=0.04694, linear_loss=0.05418]
[2020-05-11 20:46:30.544]  Step 144833  [3.218 sec/step, loss=0.08384, avg_loss=0.09357, mel_loss=0.03751, linear_loss=0.04633]
[2020-05-11 20:46:32.573]  Step 144834  [3.191 sec/step, loss=0.09554, avg_loss=0.09351, mel_loss=0.04353, linear_loss=0.05201]
[2020-05-11 20:46:37.189]  Step 144835  [3.231 sec/step, loss=0.10046, avg_loss=0.09378, mel_loss=0.04644, linear_loss=0.05403]
[2020-05-11 20:46:41.305]  Step 144836  [3.259 sec/step, loss=0.09972, avg_loss=0.09386, mel_loss=0.04567, linear_loss=0.05405]
[2020-05-11 20:46:43.473]  Step 144837  [3.247 sec/step, loss=0.09804, avg_loss=0.09388, mel_loss=0.04443, linear_loss=0.05361]
[2020-05-11 20:46:44.277]  Step 144838  [3.241 sec/step, loss=0.07946, avg_loss=0.09376, mel_loss=0.03518, linear_loss=0.04429]
[2020-05-11 20:46:47.036]  Step 144839  [3.256 sec/step, loss=0.09788, avg_loss=0.09389, mel_loss=0.04468, linear_loss=0.05320]
[2020-05-11 20:46:51.226]  Step 144840  [3.288 sec/step, loss=0.10146, avg_loss=0.09406, mel_loss=0.04676, linear_loss=0.05470]
[2020-05-11 20:46:53.023]  Step 144841  [3.282 sec/step, loss=0.09354, avg_loss=0.09403, mel_loss=0.04189, linear_loss=0.05165]
[2020-05-11 20:46:54.622]  Step 144842  [3.287 sec/step, loss=0.09378, avg_loss=0.09410, mel_loss=0.04206, linear_loss=0.05173]
[2020-05-11 20:46:56.347]  Step 144843  [3.289 sec/step, loss=0.09426, avg_loss=0.09410, mel_loss=0.04235, linear_loss=0.05190]
[2020-05-11 20:46:57.617]  Step 144844  [3.268 sec/step, loss=0.09008, avg_loss=0.09399, mel_loss=0.04011, linear_loss=0.04998]
[2020-05-11 20:46:59.180]  Step 144845  [3.228 sec/step, loss=0.09245, avg_loss=0.09388, mel_loss=0.04121, linear_loss=0.05124]
[2020-05-11 20:47:08.137]  Step 144846  [3.277 sec/step, loss=0.10304, avg_loss=0.09388, mel_loss=0.04903, linear_loss=0.05401]
[2020-05-11 20:47:09.148]  Step 144847  [3.228 sec/step, loss=0.08630, avg_loss=0.09373, mel_loss=0.03819, linear_loss=0.04812]
[2020-05-11 20:47:14.731]  Step 144848  [3.247 sec/step, loss=0.10012, avg_loss=0.09372, mel_loss=0.04652, linear_loss=0.05360]
[2020-05-11 20:47:18.100]  Step 144849  [3.250 sec/step, loss=0.10117, avg_loss=0.09375, mel_loss=0.04636, linear_loss=0.05482]
[2020-05-11 20:47:21.593]  Step 144850  [3.204 sec/step, loss=0.09909, avg_loss=0.09376, mel_loss=0.04515, linear_loss=0.05394]
[2020-05-11 20:47:21.593]  Writing summary at step: 144850
[2020-05-11 20:47:24.817]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144850
[2020-05-11 20:47:26.206]  Saving audio and alignment...
[2020-05-11 20:47:28.578]  Generated 32 batches of size 32 in 1.798 sec
[2020-05-11 20:47:44.612]  Input: 일단 이게 뉴스가 아니잖아요 장르대본을 소화하실 때는 언제나 미소를 기본적으로 장착해 놓고 첫 음을 내 주시기 바랍니다~________________________________________________
[2020-05-11 20:47:46.012]  Step 144851  [3.198 sec/step, loss=0.08902, avg_loss=0.09372, mel_loss=0.03970, linear_loss=0.04932]
[2020-05-11 20:47:49.672]  Step 144852  [3.226 sec/step, loss=0.10228, avg_loss=0.09391, mel_loss=0.04690, linear_loss=0.05538]
[2020-05-11 20:47:51.604]  Step 144853  [3.217 sec/step, loss=0.09495, avg_loss=0.09387, mel_loss=0.04288, linear_loss=0.05207]
[2020-05-11 20:47:58.314]  Step 144854  [3.278 sec/step, loss=0.10059, avg_loss=0.09414, mel_loss=0.04718, linear_loss=0.05341]
[2020-05-11 20:48:01.237]  Step 144855  [3.294 sec/step, loss=0.10020, avg_loss=0.09422, mel_loss=0.04573, linear_loss=0.05447]
[2020-05-11 20:48:03.788]  Step 144856  [3.303 sec/step, loss=0.09484, avg_loss=0.09424, mel_loss=0.04274, linear_loss=0.05210]
[2020-05-11 20:48:06.171]  Step 144857  [3.319 sec/step, loss=0.09648, avg_loss=0.09436, mel_loss=0.04390, linear_loss=0.05257]
[2020-05-11 20:48:13.942]  Step 144858  [3.273 sec/step, loss=0.10194, avg_loss=0.09449, mel_loss=0.04821, linear_loss=0.05373]
[2020-05-11 20:48:18.617]  Step 144859  [3.294 sec/step, loss=0.10047, avg_loss=0.09454, mel_loss=0.04663, linear_loss=0.05384]
[2020-05-11 20:48:22.949]  Step 144860  [3.264 sec/step, loss=0.10028, avg_loss=0.09450, mel_loss=0.04642, linear_loss=0.05386]
[2020-05-11 20:48:25.561]  Step 144861  [3.262 sec/step, loss=0.09603, avg_loss=0.09449, mel_loss=0.04375, linear_loss=0.05228]
[2020-05-11 20:48:28.048]  Step 144862  [3.242 sec/step, loss=0.09625, avg_loss=0.09443, mel_loss=0.04362, linear_loss=0.05263]
[2020-05-11 20:48:34.430]  Step 144863  [3.254 sec/step, loss=0.10126, avg_loss=0.09444, mel_loss=0.04742, linear_loss=0.05383]
[2020-05-11 20:48:35.684]  Step 144864  [3.246 sec/step, loss=0.08919, avg_loss=0.09435, mel_loss=0.03980, linear_loss=0.04939]
[2020-05-11 20:48:36.832]  Step 144865  [3.237 sec/step, loss=0.08640, avg_loss=0.09428, mel_loss=0.03842, linear_loss=0.04799]
[2020-05-11 20:48:39.679]  Step 144866  [3.225 sec/step, loss=0.09738, avg_loss=0.09424, mel_loss=0.04456, linear_loss=0.05281]
[2020-05-11 20:48:40.725]  Step 144867  [3.224 sec/step, loss=0.09017, avg_loss=0.09426, mel_loss=0.04004, linear_loss=0.05014]
[2020-05-11 20:48:42.595]  Step 144868  [3.157 sec/step, loss=0.09270, avg_loss=0.09419, mel_loss=0.04120, linear_loss=0.05150]
[2020-05-11 20:48:48.199]  Step 144869  [3.141 sec/step, loss=0.10258, avg_loss=0.09418, mel_loss=0.04783, linear_loss=0.05475]
[2020-05-11 20:48:49.664]  Step 144870  [3.121 sec/step, loss=0.09148, avg_loss=0.09412, mel_loss=0.04102, linear_loss=0.05046]
[2020-05-11 20:48:50.533]  Step 144871  [3.063 sec/step, loss=0.07748, avg_loss=0.09390, mel_loss=0.03461, linear_loss=0.04288]
[2020-05-11 20:48:51.330]  Step 144872  [3.028 sec/step, loss=0.08319, avg_loss=0.09373, mel_loss=0.03681, linear_loss=0.04638]
[2020-05-11 20:48:59.307]  Step 144873  [3.093 sec/step, loss=0.10153, avg_loss=0.09382, mel_loss=0.04799, linear_loss=0.05354]
[2020-05-11 20:49:02.313]  Step 144874  [3.109 sec/step, loss=0.10024, avg_loss=0.09390, mel_loss=0.04561, linear_loss=0.05463]
[2020-05-11 20:49:03.264]  Step 144875  [3.067 sec/step, loss=0.08784, avg_loss=0.09377, mel_loss=0.03860, linear_loss=0.04924]
[2020-05-11 20:49:06.719]  Step 144876  [3.045 sec/step, loss=0.09799, avg_loss=0.09374, mel_loss=0.04497, linear_loss=0.05302]
[2020-05-11 20:49:08.357]  Step 144877  [3.048 sec/step, loss=0.09158, avg_loss=0.09377, mel_loss=0.04107, linear_loss=0.05051]
[2020-05-11 20:49:10.362]  Step 144878  [3.049 sec/step, loss=0.09390, avg_loss=0.09374, mel_loss=0.04205, linear_loss=0.05186]
[2020-05-11 20:49:13.707]  Step 144879  [3.054 sec/step, loss=0.10093, avg_loss=0.09376, mel_loss=0.04636, linear_loss=0.05457]
[2020-05-11 20:49:15.853]  Step 144880  [3.059 sec/step, loss=0.09401, avg_loss=0.09377, mel_loss=0.04234, linear_loss=0.05167]
[2020-05-11 20:49:21.089]  Step 144881  [3.103 sec/step, loss=0.10220, avg_loss=0.09398, mel_loss=0.04761, linear_loss=0.05459]
[2020-05-11 20:49:22.793]  Generated 32 batches of size 32 in 1.698 sec
[2020-05-11 20:49:28.095]  Step 144882  [3.142 sec/step, loss=0.10329, avg_loss=0.09401, mel_loss=0.04855, linear_loss=0.05474]
[2020-05-11 20:49:31.874]  Step 144883  [3.154 sec/step, loss=0.10148, avg_loss=0.09405, mel_loss=0.04653, linear_loss=0.05496]
[2020-05-11 20:49:33.638]  Step 144884  [3.162 sec/step, loss=0.09354, avg_loss=0.09414, mel_loss=0.04211, linear_loss=0.05143]
[2020-05-11 20:49:37.107]  Step 144885  [3.175 sec/step, loss=0.09874, avg_loss=0.09417, mel_loss=0.04527, linear_loss=0.05348]
[2020-05-11 20:49:39.299]  Step 144886  [3.164 sec/step, loss=0.09604, avg_loss=0.09412, mel_loss=0.04356, linear_loss=0.05247]
[2020-05-11 20:49:40.679]  Step 144887  [3.160 sec/step, loss=0.08988, avg_loss=0.09409, mel_loss=0.04024, linear_loss=0.04963]
[2020-05-11 20:49:41.247]  Step 144888  [3.154 sec/step, loss=0.07577, avg_loss=0.09396, mel_loss=0.03414, linear_loss=0.04164]
[2020-05-11 20:49:53.816]  Step 144889  [3.273 sec/step, loss=0.08703, avg_loss=0.09401, mel_loss=0.04177, linear_loss=0.04526]
[2020-05-11 20:49:54.770]  Step 144890  [3.263 sec/step, loss=0.08410, avg_loss=0.09389, mel_loss=0.03702, linear_loss=0.04709]
[2020-05-11 20:49:56.458]  Step 144891  [3.257 sec/step, loss=0.09240, avg_loss=0.09386, mel_loss=0.04164, linear_loss=0.05075]
[2020-05-11 20:49:59.886]  Step 144892  [3.150 sec/step, loss=0.09904, avg_loss=0.09406, mel_loss=0.04522, linear_loss=0.05382]
[2020-05-11 20:50:08.753]  Step 144893  [3.229 sec/step, loss=0.10062, avg_loss=0.09420, mel_loss=0.04755, linear_loss=0.05308]
[2020-05-11 20:50:09.836]  Step 144894  [3.215 sec/step, loss=0.08742, avg_loss=0.09410, mel_loss=0.03880, linear_loss=0.04863]
[2020-05-11 20:50:10.624]  Step 144895  [3.178 sec/step, loss=0.08101, avg_loss=0.09390, mel_loss=0.03572, linear_loss=0.04529]
[2020-05-11 20:50:13.885]  Step 144896  [3.173 sec/step, loss=0.10127, avg_loss=0.09390, mel_loss=0.04673, linear_loss=0.05454]
[2020-05-11 20:50:26.915]  Step 144897  [3.298 sec/step, loss=0.08789, avg_loss=0.09402, mel_loss=0.04236, linear_loss=0.04553]
[2020-05-11 20:50:31.253]  Step 144898  [3.305 sec/step, loss=0.10184, avg_loss=0.09404, mel_loss=0.04716, linear_loss=0.05468]
[2020-05-11 20:50:33.146]  Step 144899  [3.269 sec/step, loss=0.09398, avg_loss=0.09396, mel_loss=0.04229, linear_loss=0.05169]
[2020-05-11 20:50:33.704]  Step 144900  [3.172 sec/step, loss=0.07649, avg_loss=0.09373, mel_loss=0.03491, linear_loss=0.04158]
[2020-05-11 20:50:33.704]  Writing summary at step: 144900
[2020-05-11 20:50:34.768]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144900
[2020-05-11 20:50:36.083]  Saving audio and alignment...
[2020-05-11 20:50:40.779]  Input: 목소리 외모 표정의 눈빛 자세 마저도~____________________________
[2020-05-11 20:50:42.844]  Step 144901  [3.175 sec/step, loss=0.09410, avg_loss=0.09378, mel_loss=0.04241, linear_loss=0.05169]
[2020-05-11 20:50:44.326]  Step 144902  [3.179 sec/step, loss=0.09073, avg_loss=0.09379, mel_loss=0.04057, linear_loss=0.05017]
[2020-05-11 20:50:46.144]  Step 144903  [3.147 sec/step, loss=0.09407, avg_loss=0.09372, mel_loss=0.04207, linear_loss=0.05200]
[2020-05-11 20:50:46.950]  Step 144904  [3.138 sec/step, loss=0.07642, avg_loss=0.09354, mel_loss=0.03368, linear_loss=0.04274]
[2020-05-11 20:50:48.210]  Step 144905  [3.142 sec/step, loss=0.08964, avg_loss=0.09358, mel_loss=0.04016, linear_loss=0.04948]
[2020-05-11 20:50:53.939]  Step 144906  [3.179 sec/step, loss=0.10237, avg_loss=0.09366, mel_loss=0.04787, linear_loss=0.05450]
[2020-05-11 20:50:58.698]  Step 144907  [3.197 sec/step, loss=0.10121, avg_loss=0.09372, mel_loss=0.04689, linear_loss=0.05432]
[2020-05-11 20:51:00.273]  Step 144908  [3.170 sec/step, loss=0.09484, avg_loss=0.09365, mel_loss=0.04275, linear_loss=0.05209]
[2020-05-11 20:51:01.638]  Step 144909  [3.167 sec/step, loss=0.09037, avg_loss=0.09362, mel_loss=0.04036, linear_loss=0.05001]
[2020-05-11 20:51:04.118]  Step 144910  [3.186 sec/step, loss=0.09508, avg_loss=0.09381, mel_loss=0.04300, linear_loss=0.05209]
[2020-05-11 20:51:09.409]  Step 144911  [3.225 sec/step, loss=0.10089, avg_loss=0.09391, mel_loss=0.04692, linear_loss=0.05396]
[2020-05-11 20:51:11.051]  Generated 32 batches of size 32 in 1.636 sec
[2020-05-11 20:51:16.237]  Step 144912  [3.285 sec/step, loss=0.10241, avg_loss=0.09410, mel_loss=0.04817, linear_loss=0.05424]
[2020-05-11 20:51:17.113]  Step 144913  [3.234 sec/step, loss=0.08448, avg_loss=0.09391, mel_loss=0.03730, linear_loss=0.04718]
[2020-05-11 20:51:19.986]  Step 144914  [3.239 sec/step, loss=0.09769, avg_loss=0.09394, mel_loss=0.04467, linear_loss=0.05301]
[2020-05-11 20:51:22.147]  Step 144915  [3.223 sec/step, loss=0.09611, avg_loss=0.09389, mel_loss=0.04373, linear_loss=0.05238]
[2020-05-11 20:51:24.767]  Step 144916  [3.208 sec/step, loss=0.09657, avg_loss=0.09386, mel_loss=0.04393, linear_loss=0.05263]
[2020-05-11 20:51:32.359]  Step 144917  [3.274 sec/step, loss=0.10335, avg_loss=0.09402, mel_loss=0.04883, linear_loss=0.05452]
[2020-05-11 20:51:36.473]  Step 144918  [3.303 sec/step, loss=0.10044, avg_loss=0.09415, mel_loss=0.04614, linear_loss=0.05430]
[2020-05-11 20:51:40.150]  Step 144919  [3.317 sec/step, loss=0.10193, avg_loss=0.09423, mel_loss=0.04696, linear_loss=0.05497]
[2020-05-11 20:51:42.440]  Step 144920  [3.312 sec/step, loss=0.09669, avg_loss=0.09422, mel_loss=0.04364, linear_loss=0.05305]
[2020-05-11 20:51:43.798]  Step 144921  [3.304 sec/step, loss=0.09093, avg_loss=0.09417, mel_loss=0.04038, linear_loss=0.05055]
[2020-05-11 20:51:44.789]  Step 144922  [3.283 sec/step, loss=0.08806, avg_loss=0.09407, mel_loss=0.03891, linear_loss=0.04915]
[2020-05-11 20:51:49.098]  Step 144923  [3.318 sec/step, loss=0.10088, avg_loss=0.09427, mel_loss=0.04670, linear_loss=0.05418]
[2020-05-11 20:51:50.543]  Step 144924  [3.255 sec/step, loss=0.09292, avg_loss=0.09417, mel_loss=0.04157, linear_loss=0.05134]
[2020-05-11 20:51:52.232]  Step 144925  [3.124 sec/step, loss=0.09471, avg_loss=0.09432, mel_loss=0.04232, linear_loss=0.05240]
[2020-05-11 20:51:55.537]  Step 144926  [3.138 sec/step, loss=0.10107, avg_loss=0.09440, mel_loss=0.04582, linear_loss=0.05525]
[2020-05-11 20:51:56.535]  Step 144927  [3.113 sec/step, loss=0.08288, avg_loss=0.09424, mel_loss=0.03662, linear_loss=0.04625]
[2020-05-11 20:51:57.680]  Step 144928  [3.057 sec/step, loss=0.08776, avg_loss=0.09408, mel_loss=0.03866, linear_loss=0.04910]
[2020-05-11 20:52:02.639]  Step 144929  [3.098 sec/step, loss=0.10053, avg_loss=0.09436, mel_loss=0.04660, linear_loss=0.05393]
[2020-05-11 20:52:03.513]  Step 144930  [3.100 sec/step, loss=0.07847, avg_loss=0.09435, mel_loss=0.03491, linear_loss=0.04356]
[2020-05-11 20:52:04.549]  Step 144931  [3.099 sec/step, loss=0.09078, avg_loss=0.09437, mel_loss=0.03978, linear_loss=0.05100]
[2020-05-11 20:52:07.242]  Step 144932  [3.076 sec/step, loss=0.09719, avg_loss=0.09433, mel_loss=0.04434, linear_loss=0.05285]
[2020-05-11 20:52:12.711]  Step 144933  [3.120 sec/step, loss=0.10152, avg_loss=0.09451, mel_loss=0.04728, linear_loss=0.05424]
[2020-05-11 20:52:15.829]  Step 144934  [3.131 sec/step, loss=0.09945, avg_loss=0.09455, mel_loss=0.04514, linear_loss=0.05431]
[2020-05-11 20:52:19.309]  Step 144935  [3.120 sec/step, loss=0.09863, avg_loss=0.09453, mel_loss=0.04525, linear_loss=0.05338]
[2020-05-11 20:52:25.195]  Step 144936  [3.138 sec/step, loss=0.10245, avg_loss=0.09456, mel_loss=0.04780, linear_loss=0.05465]
[2020-05-11 20:52:27.497]  Step 144937  [3.139 sec/step, loss=0.09390, avg_loss=0.09451, mel_loss=0.04240, linear_loss=0.05149]
[2020-05-11 20:52:28.840]  Step 144938  [3.144 sec/step, loss=0.08968, avg_loss=0.09462, mel_loss=0.04025, linear_loss=0.04943]
[2020-05-11 20:52:30.459]  Step 144939  [3.133 sec/step, loss=0.09473, avg_loss=0.09458, mel_loss=0.04244, linear_loss=0.05229]
[2020-05-11 20:52:44.533]  Step 144940  [3.232 sec/step, loss=0.07536, avg_loss=0.09432, mel_loss=0.03643, linear_loss=0.03893]
[2020-05-11 20:52:47.381]  Step 144941  [3.242 sec/step, loss=0.09800, avg_loss=0.09437, mel_loss=0.04477, linear_loss=0.05323]
[2020-05-11 20:52:50.809]  Step 144942  [3.261 sec/step, loss=0.09933, avg_loss=0.09442, mel_loss=0.04574, linear_loss=0.05358]
[2020-05-11 20:52:57.321]  Step 144943  [3.309 sec/step, loss=0.10441, avg_loss=0.09452, mel_loss=0.04908, linear_loss=0.05533]
[2020-05-11 20:52:58.190]  Step 144944  [3.305 sec/step, loss=0.07856, avg_loss=0.09441, mel_loss=0.03515, linear_loss=0.04341]
[2020-05-11 20:52:59.095]  Generated 32 batches of size 32 in 1.768 sec
[2020-05-11 20:53:01.819]  Step 144945  [3.325 sec/step, loss=0.10189, avg_loss=0.09450, mel_loss=0.04672, linear_loss=0.05516]
[2020-05-11 20:53:03.809]  Step 144946  [3.256 sec/step, loss=0.09355, avg_loss=0.09441, mel_loss=0.04209, linear_loss=0.05146]
[2020-05-11 20:53:11.905]  Step 144947  [3.326 sec/step, loss=0.09941, avg_loss=0.09454, mel_loss=0.04670, linear_loss=0.05271]
[2020-05-11 20:53:12.488]  Step 144948  [3.276 sec/step, loss=0.07588, avg_loss=0.09430, mel_loss=0.03370, linear_loss=0.04218]
[2020-05-11 20:53:14.324]  Step 144949  [3.261 sec/step, loss=0.09415, avg_loss=0.09423, mel_loss=0.04232, linear_loss=0.05183]
[2020-05-11 20:53:16.389]  Step 144950  [3.247 sec/step, loss=0.09565, avg_loss=0.09419, mel_loss=0.04304, linear_loss=0.05261]
[2020-05-11 20:53:16.390]  Writing summary at step: 144950
[2020-05-11 20:53:18.867]  Saving checkpoint to: ./logs-tacotron/model.ckpt-144950
[2020-05-11 20:53:20.172]  Saving audio and alignment...
[2020-05-11 20:53:26.267]  Input: 오늘도 눈부신 햇살과 함께 활기찬 하루가 시작됐습니다~___________________
[2020-05-11 20:53:30.974]  Step 144951  [3.280 sec/step, loss=0.10037, avg_loss=0.09431, mel_loss=0.04647, linear_loss=0.05389]
[2020-05-11 20:53:33.339]  Step 144952  [3.267 sec/step, loss=0.09849, avg_loss=0.09427, mel_loss=0.04491, linear_loss=0.05358]
[2020-05-11 20:53:34.441]  Step 144953  [3.259 sec/step, loss=0.08835, avg_loss=0.09420, mel_loss=0.03880, linear_loss=0.04955]
[2020-05-11 20:53:35.239]  Step 144954  [3.199 sec/step, loss=0.08051, avg_loss=0.09400, mel_loss=0.03546, linear_loss=0.04505]
[2020-05-11 20:53:49.007]  Step 144955  [3.308 sec/step, loss=0.07958, avg_loss=0.09380, mel_loss=0.03866, linear_loss=0.04092]
[2020-05-11 20:53:54.285]  Step 144956  [3.335 sec/step, loss=0.10103, avg_loss=0.09386, mel_loss=0.04691, linear_loss=0.05412]
[2020-05-11 20:53:55.592]  Step 144957  [3.324 sec/step, loss=0.09196, avg_loss=0.09381, mel_loss=0.04088, linear_loss=0.05108]
[2020-05-11 20:53:59.769]  Step 144958  [3.288 sec/step, loss=0.09867, avg_loss=0.09378, mel_loss=0.04537, linear_loss=0.05330]
[2020-05-11 20:54:05.397]  Step 144959  [3.298 sec/step, loss=0.10131, avg_loss=0.09379, mel_loss=0.04738, linear_loss=0.05393]
[2020-05-11 20:54:06.396]  Step 144960  [3.265 sec/step, loss=0.08331, avg_loss=0.09362, mel_loss=0.03668, linear_loss=0.04663]
[2020-05-11 20:54:09.298]  Step 144961  [3.268 sec/step, loss=0.09819, avg_loss=0.09364, mel_loss=0.04484, linear_loss=0.05335]
[2020-05-11 20:54:11.300]  Step 144962  [3.263 sec/step, loss=0.09590, avg_loss=0.09364, mel_loss=0.04333, linear_loss=0.05257]
[2020-05-11 20:54:13.798]  Step 144963  [3.224 sec/step, loss=0.09585, avg_loss=0.09358, mel_loss=0.04348, linear_loss=0.05237]
[2020-05-11 20:54:20.415]  Step 144964  [3.278 sec/step, loss=0.10236, avg_loss=0.09371, mel_loss=0.04810, linear_loss=0.05426]
[2020-05-11 20:54:23.881]  Step 144965  [3.301 sec/step, loss=0.09881, avg_loss=0.09384, mel_loss=0.04533, linear_loss=0.05348]
[2020-05-11 20:54:27.575]  Step 144966  [3.309 sec/step, loss=0.10007, avg_loss=0.09387, mel_loss=0.04599, linear_loss=0.05409]
[2020-05-11 20:54:29.175]  Step 144967  [3.315 sec/step, loss=0.09203, avg_loss=0.09388, mel_loss=0.04133, linear_loss=0.05070]
[2020-05-11 20:54:37.976]  Step 144968  [3.384 sec/step, loss=0.09883, avg_loss=0.09395, mel_loss=0.04689, linear_loss=0.05194]
[2020-05-11 20:54:40.188]  Step 144969  [3.350 sec/step, loss=0.09392, avg_loss=0.09386, mel_loss=0.04258, linear_loss=0.05133]
[2020-05-11 20:54:47.700]  Step 144970  [3.411 sec/step, loss=0.10235, avg_loss=0.09397, mel_loss=0.04821, linear_loss=0.05414]
[2020-05-11 20:54:48.266]  Step 144971  [3.408 sec/step, loss=0.07380, avg_loss=0.09393, mel_loss=0.03351, linear_loss=0.04029]
[2020-05-11 20:54:51.456]  Step 144972  [3.431 sec/step, loss=0.10024, avg_loss=0.09410, mel_loss=0.04592, linear_loss=0.05431]
[2020-05-11 20:54:58.452]  Step 144973  [3.422 sec/step, loss=0.10205, avg_loss=0.09411, mel_loss=0.04729, linear_loss=0.05476]
[2020-05-11 20:55:01.358]  Step 144974  [3.421 sec/step, loss=0.09345, avg_loss=0.09404, mel_loss=0.04157, linear_loss=0.05188]
[2020-05-11 20:55:01.619]  Generated 32 batches of size 32 in 3.158 sec
[2020-05-11 20:55:04.420]  Step 144975  [3.442 sec/step, loss=0.09236, avg_loss=0.09408, mel_loss=0.04137, linear_loss=0.05099]
[2020-05-11 20:55:06.615]  Step 144976  [3.429 sec/step, loss=0.08966, avg_loss=0.09400, mel_loss=0.04005, linear_loss=0.04961]
[2020-05-11 20:55:08.245]  Step 144977  [3.429 sec/step, loss=0.08622, avg_loss=0.09395, mel_loss=0.03840, linear_loss=0.04782]
[2020-05-11 20:55:11.613]  Step 144978  [3.443 sec/step, loss=0.09713, avg_loss=0.09398, mel_loss=0.04425, linear_loss=0.05287]
[2020-05-11 20:55:12.468]  Step 144979  [3.418 sec/step, loss=0.08205, avg_loss=0.09379, mel_loss=0.03648, linear_loss=0.04557]
[2020-05-11 20:55:13.751]  Step 144980  [3.409 sec/step, loss=0.08799, avg_loss=0.09373, mel_loss=0.03923, linear_loss=0.04875]
[2020-05-11 20:55:17.393]  Step 144981  [3.393 sec/step, loss=0.09892, avg_loss=0.09370, mel_loss=0.04544, linear_loss=0.05348]
[2020-05-11 20:55:18.995]  Step 144982  [3.339 sec/step, loss=0.09472, avg_loss=0.09361, mel_loss=0.04270, linear_loss=0.05202]
[2020-05-11 20:55:25.277]  Step 144983  [3.364 sec/step, loss=0.09993, avg_loss=0.09360, mel_loss=0.04676, linear_loss=0.05317]
[2020-05-11 20:55:26.180]  Step 144984  [3.356 sec/step, loss=0.08811, avg_loss=0.09354, mel_loss=0.03867, linear_loss=0.04944]
[2020-05-11 20:55:28.186]  Step 144985  [3.341 sec/step, loss=0.09484, avg_loss=0.09350, mel_loss=0.04246, linear_loss=0.05238]
[2020-05-11 20:55:30.169]  Step 144986  [3.339 sec/step, loss=0.09600, avg_loss=0.09350, mel_loss=0.04341, linear_loss=0.05258]
[2020-05-11 20:55:32.730]  Step 144987  [3.351 sec/step, loss=0.09594, avg_loss=0.09356, mel_loss=0.04334, linear_loss=0.05260]
[2020-05-11 20:55:34.945]  Step 144988  [3.367 sec/step, loss=0.09357, avg_loss=0.09374, mel_loss=0.04243, linear_loss=0.05114]
[2020-05-11 20:55:38.042]  Step 144989  [3.272 sec/step, loss=0.09982, avg_loss=0.09387, mel_loss=0.04571, linear_loss=0.05412]
[2020-05-11 20:55:42.288]  Step 144990  [3.305 sec/step, loss=0.10066, avg_loss=0.09403, mel_loss=0.04652, linear_loss=0.05413]
[2020-05-11 20:55:42.855]  Step 144991  [3.294 sec/step, loss=0.08045, avg_loss=0.09391, mel_loss=0.03617, linear_loss=0.04428]
[2020-05-11 20:55:45.937]  Step 144992  [3.291 sec/step, loss=0.09961, avg_loss=0.09392, mel_loss=0.04569, linear_loss=0.05392]
[2020-05-11 20:55:46.803]  Step 144993  [3.211 sec/step, loss=0.07994, avg_loss=0.09371, mel_loss=0.03520, linear_loss=0.04474]
[2020-05-11 20:55:48.522]  Step 144994  [3.217 sec/step, loss=0.09251, avg_loss=0.09376, mel_loss=0.04165, linear_loss=0.05086]
[2020-05-11 20:55:49.870]  Step 144995  [3.223 sec/step, loss=0.08987, avg_loss=0.09385, mel_loss=0.03994, linear_loss=0.04993]
[2020-05-11 20:55:51.716]  Step 144996  [3.209 sec/step, loss=0.09346, avg_loss=0.09377, mel_loss=0.04195, linear_loss=0.05151]
[2020-05-11 20:55:54.534]  Step 144997  [3.106 sec/step, loss=0.09821, avg_loss=0.09388, mel_loss=0.04464, linear_loss=0.05358]
[2020-05-11 20:55:55.546]  Step 144998  [3.073 sec/step, loss=0.08637, avg_loss=0.09372, mel_loss=0.03855, linear_loss=0.04782]
[2020-05-11 20:56:03.743]  Step 144999  [3.136 sec/step, loss=0.10278, avg_loss=0.09381, mel_loss=0.04825, linear_loss=0.05453]
[2020-05-11 20:56:07.494]  Step 145000  [3.168 sec/step, loss=0.10341, avg_loss=0.09408, mel_loss=0.04762, linear_loss=0.05579]
[2020-05-11 20:56:07.494]  Writing summary at step: 145000
[2020-05-11 20:56:08.701]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145000
[2020-05-11 20:56:10.046]  Saving audio and alignment...
[2020-05-11 20:56:17.828]  Input: 나라는 사람에게 주어진 소중한 기회이자 영광이고 사명이자 특명입니다~_______________________________
[2020-05-11 20:56:21.408]  Step 145001  [3.183 sec/step, loss=0.10056, avg_loss=0.09415, mel_loss=0.04581, linear_loss=0.05475]
[2020-05-11 20:56:22.549]  Step 145002  [3.180 sec/step, loss=0.08614, avg_loss=0.09410, mel_loss=0.03816, linear_loss=0.04798]
[2020-05-11 20:56:35.932]  Step 145003  [3.296 sec/step, loss=0.09155, avg_loss=0.09407, mel_loss=0.04414, linear_loss=0.04740]
[2020-05-11 20:56:37.657]  Generated 32 batches of size 32 in 1.718 sec
[2020-05-11 20:56:39.358]  Step 145004  [3.322 sec/step, loss=0.09978, avg_loss=0.09431, mel_loss=0.04602, linear_loss=0.05376]
[2020-05-11 20:56:48.527]  Step 145005  [3.401 sec/step, loss=0.10593, avg_loss=0.09447, mel_loss=0.05066, linear_loss=0.05527]
[2020-05-11 20:56:55.161]  Step 145006  [3.410 sec/step, loss=0.10576, avg_loss=0.09450, mel_loss=0.04980, linear_loss=0.05597]
[2020-05-11 20:56:56.755]  Step 145007  [3.378 sec/step, loss=0.09210, avg_loss=0.09441, mel_loss=0.04141, linear_loss=0.05069]
[2020-05-11 20:56:59.218]  Step 145008  [3.387 sec/step, loss=0.09475, avg_loss=0.09441, mel_loss=0.04234, linear_loss=0.05242]
[2020-05-11 20:57:03.720]  Step 145009  [3.418 sec/step, loss=0.10230, avg_loss=0.09453, mel_loss=0.04733, linear_loss=0.05497]
[2020-05-11 20:57:08.637]  Step 145010  [3.443 sec/step, loss=0.09997, avg_loss=0.09458, mel_loss=0.04618, linear_loss=0.05379]
[2020-05-11 20:57:09.477]  Step 145011  [3.398 sec/step, loss=0.07824, avg_loss=0.09435, mel_loss=0.03473, linear_loss=0.04351]
[2020-05-11 20:57:10.886]  Step 145012  [3.344 sec/step, loss=0.09099, avg_loss=0.09424, mel_loss=0.04101, linear_loss=0.04998]
[2020-05-11 20:57:18.936]  Step 145013  [3.416 sec/step, loss=0.09974, avg_loss=0.09439, mel_loss=0.04702, linear_loss=0.05272]
[2020-05-11 20:57:22.360]  Step 145014  [3.421 sec/step, loss=0.09895, avg_loss=0.09441, mel_loss=0.04525, linear_loss=0.05370]
[2020-05-11 20:57:23.575]  Step 145015  [3.412 sec/step, loss=0.08819, avg_loss=0.09433, mel_loss=0.03901, linear_loss=0.04918]
[2020-05-11 20:57:27.310]  Step 145016  [3.423 sec/step, loss=0.10106, avg_loss=0.09437, mel_loss=0.04643, linear_loss=0.05463]
[2020-05-11 20:57:34.791]  Step 145017  [3.422 sec/step, loss=0.10207, avg_loss=0.09436, mel_loss=0.04815, linear_loss=0.05392]
[2020-05-11 20:57:38.132]  Step 145018  [3.414 sec/step, loss=0.09895, avg_loss=0.09434, mel_loss=0.04517, linear_loss=0.05377]
[2020-05-11 20:57:39.121]  Step 145019  [3.387 sec/step, loss=0.08643, avg_loss=0.09419, mel_loss=0.03803, linear_loss=0.04840]
[2020-05-11 20:57:40.875]  Step 145020  [3.382 sec/step, loss=0.09278, avg_loss=0.09415, mel_loss=0.04137, linear_loss=0.05142]
[2020-05-11 20:57:43.806]  Step 145021  [3.398 sec/step, loss=0.09975, avg_loss=0.09424, mel_loss=0.04539, linear_loss=0.05436]
[2020-05-11 20:57:45.685]  Step 145022  [3.407 sec/step, loss=0.09157, avg_loss=0.09427, mel_loss=0.04107, linear_loss=0.05050]
[2020-05-11 20:57:48.149]  Step 145023  [3.388 sec/step, loss=0.09654, avg_loss=0.09423, mel_loss=0.04375, linear_loss=0.05279]
[2020-05-11 20:57:48.949]  Step 145024  [3.382 sec/step, loss=0.08159, avg_loss=0.09412, mel_loss=0.03612, linear_loss=0.04547]
[2020-05-11 20:57:53.369]  Step 145025  [3.409 sec/step, loss=0.10241, avg_loss=0.09419, mel_loss=0.04738, linear_loss=0.05502]
[2020-05-11 20:57:54.328]  Step 145026  [3.386 sec/step, loss=0.08384, avg_loss=0.09402, mel_loss=0.03688, linear_loss=0.04696]
[2020-05-11 20:57:56.536]  Step 145027  [3.398 sec/step, loss=0.09491, avg_loss=0.09414, mel_loss=0.04280, linear_loss=0.05210]
[2020-05-11 20:57:57.060]  Step 145028  [3.391 sec/step, loss=0.07851, avg_loss=0.09405, mel_loss=0.03493, linear_loss=0.04358]
[2020-05-11 20:57:57.697]  Step 145029  [3.348 sec/step, loss=0.07612, avg_loss=0.09380, mel_loss=0.03431, linear_loss=0.04181]
[2020-05-11 20:58:03.701]  Step 145030  [3.400 sec/step, loss=0.10205, avg_loss=0.09404, mel_loss=0.04778, linear_loss=0.05428]
[2020-05-11 20:58:04.816]  Step 145031  [3.400 sec/step, loss=0.08655, avg_loss=0.09400, mel_loss=0.03825, linear_loss=0.04830]
[2020-05-11 20:58:06.814]  Step 145032  [3.393 sec/step, loss=0.09549, avg_loss=0.09398, mel_loss=0.04311, linear_loss=0.05238]
[2020-05-11 20:58:10.376]  Step 145033  [3.374 sec/step, loss=0.09843, avg_loss=0.09395, mel_loss=0.04514, linear_loss=0.05328]
[2020-05-11 20:58:14.536]  Step 145034  [3.385 sec/step, loss=0.09864, avg_loss=0.09394, mel_loss=0.04519, linear_loss=0.05345]
[2020-05-11 20:58:19.289]  Step 145035  [3.397 sec/step, loss=0.09974, avg_loss=0.09395, mel_loss=0.04610, linear_loss=0.05363]
[2020-05-11 20:58:20.896]  Step 145036  [3.355 sec/step, loss=0.09317, avg_loss=0.09386, mel_loss=0.04145, linear_loss=0.05172]
[2020-05-11 20:58:21.018]  Generated 32 batches of size 32 in 1.724 sec
[2020-05-11 20:58:22.172]  Step 145037  [3.344 sec/step, loss=0.09102, avg_loss=0.09383, mel_loss=0.04043, linear_loss=0.05059]
[2020-05-11 20:58:24.810]  Step 145038  [3.357 sec/step, loss=0.09599, avg_loss=0.09389, mel_loss=0.04333, linear_loss=0.05266]
[2020-05-11 20:58:26.911]  Step 145039  [3.362 sec/step, loss=0.09618, avg_loss=0.09391, mel_loss=0.04355, linear_loss=0.05263]
[2020-05-11 20:58:32.436]  Step 145040  [3.277 sec/step, loss=0.10204, avg_loss=0.09418, mel_loss=0.04753, linear_loss=0.05451]
[2020-05-11 20:58:33.795]  Step 145041  [3.262 sec/step, loss=0.08987, avg_loss=0.09409, mel_loss=0.04036, linear_loss=0.04951]
[2020-05-11 20:58:36.600]  Step 145042  [3.256 sec/step, loss=0.09669, avg_loss=0.09407, mel_loss=0.04423, linear_loss=0.05246]
[2020-05-11 20:58:47.544]  Step 145043  [3.300 sec/step, loss=0.09362, avg_loss=0.09396, mel_loss=0.04481, linear_loss=0.04881]
[2020-05-11 20:58:49.156]  Step 145044  [3.307 sec/step, loss=0.09388, avg_loss=0.09411, mel_loss=0.04237, linear_loss=0.05150]
[2020-05-11 20:58:50.954]  Step 145045  [3.289 sec/step, loss=0.09461, avg_loss=0.09404, mel_loss=0.04222, linear_loss=0.05239]
[2020-05-11 20:58:59.811]  Step 145046  [3.358 sec/step, loss=0.10144, avg_loss=0.09412, mel_loss=0.04798, linear_loss=0.05347]
[2020-05-11 20:59:07.469]  Step 145047  [3.353 sec/step, loss=0.10134, avg_loss=0.09414, mel_loss=0.04755, linear_loss=0.05379]
[2020-05-11 20:59:09.418]  Step 145048  [3.367 sec/step, loss=0.09348, avg_loss=0.09431, mel_loss=0.04236, linear_loss=0.05111]
[2020-05-11 20:59:10.393]  Step 145049  [3.358 sec/step, loss=0.08665, avg_loss=0.09424, mel_loss=0.03850, linear_loss=0.04816]
[2020-05-11 20:59:13.095]  Step 145050  [3.365 sec/step, loss=0.09483, avg_loss=0.09423, mel_loss=0.04335, linear_loss=0.05148]
[2020-05-11 20:59:13.096]  Writing summary at step: 145050
[2020-05-11 20:59:16.359]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145050
[2020-05-11 20:59:17.661]  Saving audio and alignment...
[2020-05-11 20:59:19.652]  Input: 저음 중음~_______________
[2020-05-11 20:59:22.067]  Step 145051  [3.342 sec/step, loss=0.09645, avg_loss=0.09419, mel_loss=0.04363, linear_loss=0.05282]
[2020-05-11 20:59:22.945]  Step 145052  [3.327 sec/step, loss=0.08432, avg_loss=0.09405, mel_loss=0.03693, linear_loss=0.04739]
[2020-05-11 20:59:24.461]  Step 145053  [3.331 sec/step, loss=0.09069, avg_loss=0.09407, mel_loss=0.04081, linear_loss=0.04988]
[2020-05-11 20:59:29.073]  Step 145054  [3.369 sec/step, loss=0.10151, avg_loss=0.09428, mel_loss=0.04685, linear_loss=0.05466]
[2020-05-11 20:59:29.828]  Step 145055  [3.239 sec/step, loss=0.07500, avg_loss=0.09424, mel_loss=0.03389, linear_loss=0.04112]
[2020-05-11 20:59:44.120]  Step 145056  [3.329 sec/step, loss=0.08143, avg_loss=0.09404, mel_loss=0.03944, linear_loss=0.04199]
[2020-05-11 20:59:45.866]  Step 145057  [3.334 sec/step, loss=0.09466, avg_loss=0.09407, mel_loss=0.04252, linear_loss=0.05214]
[2020-05-11 20:59:48.034]  Step 145058  [3.313 sec/step, loss=0.09506, avg_loss=0.09403, mel_loss=0.04316, linear_loss=0.05191]
[2020-05-11 20:59:52.288]  Step 145059  [3.300 sec/step, loss=0.10172, avg_loss=0.09404, mel_loss=0.04700, linear_loss=0.05472]
[2020-05-11 20:59:53.870]  Step 145060  [3.306 sec/step, loss=0.09397, avg_loss=0.09414, mel_loss=0.04225, linear_loss=0.05172]
[2020-05-11 20:59:58.856]  Step 145061  [3.326 sec/step, loss=0.10140, avg_loss=0.09418, mel_loss=0.04722, linear_loss=0.05417]
[2020-05-11 20:59:59.996]  Step 145062  [3.318 sec/step, loss=0.08837, avg_loss=0.09410, mel_loss=0.03879, linear_loss=0.04957]
[2020-05-11 21:00:00.799]  Step 145063  [3.301 sec/step, loss=0.08367, avg_loss=0.09398, mel_loss=0.03711, linear_loss=0.04656]
[2020-05-11 21:00:03.660]  Step 145064  [3.263 sec/step, loss=0.09849, avg_loss=0.09394, mel_loss=0.04518, linear_loss=0.05331]
[2020-05-11 21:00:05.741]  Step 145065  [3.249 sec/step, loss=0.09634, avg_loss=0.09391, mel_loss=0.04337, linear_loss=0.05297]
[2020-05-11 21:00:07.482]  Generated 32 batches of size 32 in 1.735 sec
[2020-05-11 21:00:09.597]  Step 145066  [3.251 sec/step, loss=0.10131, avg_loss=0.09393, mel_loss=0.04651, linear_loss=0.05480]
[2020-05-11 21:00:10.436]  Step 145067  [3.243 sec/step, loss=0.07669, avg_loss=0.09377, mel_loss=0.03411, linear_loss=0.04259]
[2020-05-11 21:00:16.357]  Step 145068  [3.215 sec/step, loss=0.10019, avg_loss=0.09379, mel_loss=0.04662, linear_loss=0.05357]
[2020-05-11 21:00:22.764]  Step 145069  [3.257 sec/step, loss=0.10089, avg_loss=0.09386, mel_loss=0.04736, linear_loss=0.05353]
[2020-05-11 21:00:25.760]  Step 145070  [3.211 sec/step, loss=0.10002, avg_loss=0.09383, mel_loss=0.04610, linear_loss=0.05392]
[2020-05-11 21:00:27.061]  Step 145071  [3.219 sec/step, loss=0.08799, avg_loss=0.09398, mel_loss=0.03919, linear_loss=0.04880]
[2020-05-11 21:00:31.347]  Step 145072  [3.230 sec/step, loss=0.10242, avg_loss=0.09400, mel_loss=0.04696, linear_loss=0.05546]
[2020-05-11 21:00:34.884]  Step 145073  [3.195 sec/step, loss=0.09849, avg_loss=0.09396, mel_loss=0.04532, linear_loss=0.05316]
[2020-05-11 21:00:36.225]  Step 145074  [3.180 sec/step, loss=0.09196, avg_loss=0.09395, mel_loss=0.04088, linear_loss=0.05108]
[2020-05-11 21:00:39.827]  Step 145075  [3.185 sec/step, loss=0.10037, avg_loss=0.09403, mel_loss=0.04627, linear_loss=0.05411]
[2020-05-11 21:00:41.860]  Step 145076  [3.183 sec/step, loss=0.09465, avg_loss=0.09408, mel_loss=0.04267, linear_loss=0.05198]
[2020-05-11 21:00:50.139]  Step 145077  [3.250 sec/step, loss=0.09751, avg_loss=0.09419, mel_loss=0.04618, linear_loss=0.05133]
[2020-05-11 21:00:53.021]  Step 145078  [3.245 sec/step, loss=0.09644, avg_loss=0.09418, mel_loss=0.04393, linear_loss=0.05251]
[2020-05-11 21:00:57.508]  Step 145079  [3.281 sec/step, loss=0.10219, avg_loss=0.09438, mel_loss=0.04728, linear_loss=0.05491]
[2020-05-11 21:00:58.075]  Step 145080  [3.274 sec/step, loss=0.07600, avg_loss=0.09426, mel_loss=0.03456, linear_loss=0.04144]
[2020-05-11 21:01:00.696]  Step 145081  [3.264 sec/step, loss=0.09803, avg_loss=0.09426, mel_loss=0.04477, linear_loss=0.05326]
[2020-05-11 21:01:03.218]  Step 145082  [3.273 sec/step, loss=0.09546, avg_loss=0.09426, mel_loss=0.04303, linear_loss=0.05243]
[2020-05-11 21:01:04.162]  Step 145083  [3.220 sec/step, loss=0.08601, avg_loss=0.09412, mel_loss=0.03836, linear_loss=0.04765]
[2020-05-11 21:01:05.392]  Step 145084  [3.223 sec/step, loss=0.09029, avg_loss=0.09415, mel_loss=0.04009, linear_loss=0.05020]
[2020-05-11 21:01:11.303]  Step 145085  [3.262 sec/step, loss=0.10185, avg_loss=0.09422, mel_loss=0.04772, linear_loss=0.05413]
[2020-05-11 21:01:13.210]  Step 145086  [3.261 sec/step, loss=0.09444, avg_loss=0.09420, mel_loss=0.04229, linear_loss=0.05215]
[2020-05-11 21:01:14.202]  Step 145087  [3.246 sec/step, loss=0.08261, avg_loss=0.09407, mel_loss=0.03659, linear_loss=0.04601]
[2020-05-11 21:01:15.545]  Step 145088  [3.237 sec/step, loss=0.08934, avg_loss=0.09403, mel_loss=0.04001, linear_loss=0.04933]
[2020-05-11 21:01:18.950]  Step 145089  [3.240 sec/step, loss=0.09832, avg_loss=0.09401, mel_loss=0.04519, linear_loss=0.05312]
[2020-05-11 21:01:24.536]  Step 145090  [3.253 sec/step, loss=0.10254, avg_loss=0.09403, mel_loss=0.04792, linear_loss=0.05463]
[2020-05-11 21:01:26.696]  Step 145091  [3.269 sec/step, loss=0.09614, avg_loss=0.09419, mel_loss=0.04366, linear_loss=0.05248]
[2020-05-11 21:01:28.076]  Step 145092  [3.252 sec/step, loss=0.09100, avg_loss=0.09410, mel_loss=0.04094, linear_loss=0.05006]
[2020-05-11 21:01:35.202]  Step 145093  [3.315 sec/step, loss=0.10417, avg_loss=0.09434, mel_loss=0.04914, linear_loss=0.05503]
[2020-05-11 21:01:36.985]  Step 145094  [3.315 sec/step, loss=0.09089, avg_loss=0.09433, mel_loss=0.04042, linear_loss=0.05047]
[2020-05-11 21:01:40.369]  Step 145095  [3.336 sec/step, loss=0.09921, avg_loss=0.09442, mel_loss=0.04547, linear_loss=0.05374]
[2020-05-11 21:01:43.470]  Step 145096  [3.348 sec/step, loss=0.10009, avg_loss=0.09449, mel_loss=0.04554, linear_loss=0.05455]
[2020-05-11 21:01:55.824]  Step 145097  [3.444 sec/step, loss=0.08809, avg_loss=0.09438, mel_loss=0.04235, linear_loss=0.04574]
[2020-05-11 21:01:57.630]  Generated 32 batches of size 32 in 1.801 sec
[2020-05-11 21:01:58.203]  Step 145098  [3.457 sec/step, loss=0.09479, avg_loss=0.09447, mel_loss=0.04292, linear_loss=0.05187]
[2020-05-11 21:01:59.027]  Step 145099  [3.384 sec/step, loss=0.08142, avg_loss=0.09425, mel_loss=0.03587, linear_loss=0.04556]
[2020-05-11 21:02:00.127]  Step 145100  [3.357 sec/step, loss=0.08766, avg_loss=0.09410, mel_loss=0.03857, linear_loss=0.04909]
[2020-05-11 21:02:00.127]  Writing summary at step: 145100
[2020-05-11 21:02:00.891]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145100
[2020-05-11 21:02:02.714]  Saving audio and alignment...
[2020-05-11 21:02:08.710]  Input: 자 계속해서 다른 스킬들 그리고 풍부한 예시 보도록 할~________________________________
[2020-05-11 21:02:10.353]  Step 145101  [3.338 sec/step, loss=0.09222, avg_loss=0.09401, mel_loss=0.04142, linear_loss=0.05081]
[2020-05-11 21:02:15.503]  Step 145102  [3.378 sec/step, loss=0.09935, avg_loss=0.09415, mel_loss=0.04594, linear_loss=0.05341]
[2020-05-11 21:02:19.604]  Step 145103  [3.285 sec/step, loss=0.09970, avg_loss=0.09423, mel_loss=0.04601, linear_loss=0.05369]
[2020-05-11 21:02:21.187]  Step 145104  [3.267 sec/step, loss=0.09210, avg_loss=0.09415, mel_loss=0.04110, linear_loss=0.05100]
[2020-05-11 21:02:22.295]  Step 145105  [3.186 sec/step, loss=0.08613, avg_loss=0.09395, mel_loss=0.03814, linear_loss=0.04799]
[2020-05-11 21:02:23.680]  Step 145106  [3.134 sec/step, loss=0.08994, avg_loss=0.09379, mel_loss=0.04026, linear_loss=0.04968]
[2020-05-11 21:02:26.109]  Step 145107  [3.142 sec/step, loss=0.09580, avg_loss=0.09383, mel_loss=0.04329, linear_loss=0.05251]
[2020-05-11 21:02:28.708]  Step 145108  [3.143 sec/step, loss=0.09698, avg_loss=0.09385, mel_loss=0.04425, linear_loss=0.05274]
[2020-05-11 21:02:32.411]  Step 145109  [3.135 sec/step, loss=0.10104, avg_loss=0.09384, mel_loss=0.04676, linear_loss=0.05428]
[2020-05-11 21:02:34.622]  Step 145110  [3.108 sec/step, loss=0.09415, avg_loss=0.09378, mel_loss=0.04212, linear_loss=0.05204]
[2020-05-11 21:02:42.358]  Step 145111  [3.177 sec/step, loss=0.10104, avg_loss=0.09401, mel_loss=0.04761, linear_loss=0.05344]
[2020-05-11 21:02:44.738]  Step 145112  [3.187 sec/step, loss=0.09517, avg_loss=0.09405, mel_loss=0.04330, linear_loss=0.05187]
[2020-05-11 21:02:45.496]  Step 145113  [3.114 sec/step, loss=0.08130, avg_loss=0.09387, mel_loss=0.03592, linear_loss=0.04538]
[2020-05-11 21:02:48.886]  Step 145114  [3.114 sec/step, loss=0.09861, avg_loss=0.09387, mel_loss=0.04521, linear_loss=0.05340]
[2020-05-11 21:02:50.385]  Step 145115  [3.116 sec/step, loss=0.09139, avg_loss=0.09390, mel_loss=0.04076, linear_loss=0.05063]
[2020-05-11 21:02:58.976]  Step 145116  [3.165 sec/step, loss=0.10097, avg_loss=0.09390, mel_loss=0.04769, linear_loss=0.05329]
[2020-05-11 21:03:04.061]  Step 145117  [3.141 sec/step, loss=0.09872, avg_loss=0.09386, mel_loss=0.04569, linear_loss=0.05303]
[2020-05-11 21:03:10.721]  Step 145118  [3.174 sec/step, loss=0.10006, avg_loss=0.09387, mel_loss=0.04687, linear_loss=0.05319]
[2020-05-11 21:03:11.913]  Step 145119  [3.176 sec/step, loss=0.08944, avg_loss=0.09390, mel_loss=0.03986, linear_loss=0.04957]
[2020-05-11 21:03:13.531]  Step 145120  [3.175 sec/step, loss=0.09544, avg_loss=0.09393, mel_loss=0.04262, linear_loss=0.05282]
[2020-05-11 21:03:19.068]  Step 145121  [3.201 sec/step, loss=0.10002, avg_loss=0.09393, mel_loss=0.04663, linear_loss=0.05339]
[2020-05-11 21:03:21.891]  Step 145122  [3.210 sec/step, loss=0.09920, avg_loss=0.09401, mel_loss=0.04528, linear_loss=0.05392]
[2020-05-11 21:03:23.654]  Step 145123  [3.203 sec/step, loss=0.09187, avg_loss=0.09396, mel_loss=0.04111, linear_loss=0.05076]
[2020-05-11 21:03:27.915]  Step 145124  [3.238 sec/step, loss=0.09904, avg_loss=0.09414, mel_loss=0.04559, linear_loss=0.05345]
[2020-05-11 21:03:29.864]  Step 145125  [3.213 sec/step, loss=0.09646, avg_loss=0.09408, mel_loss=0.04358, linear_loss=0.05289]
[2020-05-11 21:03:31.758]  Step 145126  [3.223 sec/step, loss=0.09404, avg_loss=0.09418, mel_loss=0.04191, linear_loss=0.05213]
[2020-05-11 21:03:32.310]  Step 145127  [3.206 sec/step, loss=0.07451, avg_loss=0.09398, mel_loss=0.03391, linear_loss=0.04061]
[2020-05-11 21:03:33.317]  Step 145128  [3.211 sec/step, loss=0.08735, avg_loss=0.09406, mel_loss=0.03844, linear_loss=0.04890]
[2020-05-11 21:03:34.116]  Generated 32 batches of size 32 in 1.800 sec
[2020-05-11 21:03:34.158]  Step 145129  [3.213 sec/step, loss=0.07969, avg_loss=0.09410, mel_loss=0.03512, linear_loss=0.04458]
[2020-05-11 21:03:35.035]  Step 145130  [3.162 sec/step, loss=0.08309, avg_loss=0.09391, mel_loss=0.03654, linear_loss=0.04655]
[2020-05-11 21:03:39.588]  Step 145131  [3.196 sec/step, loss=0.10074, avg_loss=0.09405, mel_loss=0.04641, linear_loss=0.05433]
[2020-05-11 21:03:53.644]  Step 145132  [3.317 sec/step, loss=0.07664, avg_loss=0.09386, mel_loss=0.03691, linear_loss=0.03973]
[2020-05-11 21:03:57.265]  Step 145133  [3.317 sec/step, loss=0.10162, avg_loss=0.09390, mel_loss=0.04662, linear_loss=0.05500]
[2020-05-11 21:04:00.739]  Step 145134  [3.310 sec/step, loss=0.09713, avg_loss=0.09388, mel_loss=0.04448, linear_loss=0.05265]
[2020-05-11 21:04:02.090]  Step 145135  [3.276 sec/step, loss=0.08876, avg_loss=0.09377, mel_loss=0.03948, linear_loss=0.04928]
[2020-05-11 21:04:05.188]  Step 145136  [3.291 sec/step, loss=0.09796, avg_loss=0.09382, mel_loss=0.04457, linear_loss=0.05339]
[2020-05-11 21:04:06.576]  Step 145137  [3.292 sec/step, loss=0.09138, avg_loss=0.09382, mel_loss=0.04109, linear_loss=0.05029]
[2020-05-11 21:04:08.222]  Step 145138  [3.282 sec/step, loss=0.09258, avg_loss=0.09379, mel_loss=0.04153, linear_loss=0.05105]
[2020-05-11 21:04:10.947]  Step 145139  [3.289 sec/step, loss=0.09496, avg_loss=0.09378, mel_loss=0.04322, linear_loss=0.05174]
[2020-05-11 21:04:16.531]  Step 145140  [3.289 sec/step, loss=0.10287, avg_loss=0.09378, mel_loss=0.04819, linear_loss=0.05468]
[2020-05-11 21:04:20.182]  Step 145141  [3.312 sec/step, loss=0.10000, avg_loss=0.09389, mel_loss=0.04570, linear_loss=0.05430]
[2020-05-11 21:04:22.225]  Step 145142  [3.305 sec/step, loss=0.09389, avg_loss=0.09386, mel_loss=0.04210, linear_loss=0.05179]
[2020-05-11 21:04:23.268]  Step 145143  [3.206 sec/step, loss=0.08378, avg_loss=0.09376, mel_loss=0.03710, linear_loss=0.04668]
[2020-05-11 21:04:24.875]  Step 145144  [3.206 sec/step, loss=0.09160, avg_loss=0.09374, mel_loss=0.04125, linear_loss=0.05035]
[2020-05-11 21:04:26.783]  Step 145145  [3.207 sec/step, loss=0.09204, avg_loss=0.09371, mel_loss=0.04139, linear_loss=0.05065]
[2020-05-11 21:04:28.892]  Step 145146  [3.139 sec/step, loss=0.09415, avg_loss=0.09364, mel_loss=0.04274, linear_loss=0.05141]
[2020-05-11 21:04:32.278]  Step 145147  [3.096 sec/step, loss=0.10034, avg_loss=0.09363, mel_loss=0.04585, linear_loss=0.05449]
[2020-05-11 21:04:33.278]  Step 145148  [3.087 sec/step, loss=0.08533, avg_loss=0.09355, mel_loss=0.03747, linear_loss=0.04787]
[2020-05-11 21:04:34.519]  Step 145149  [3.090 sec/step, loss=0.08629, avg_loss=0.09354, mel_loss=0.03844, linear_loss=0.04785]
[2020-05-11 21:04:38.613]  Step 145150  [3.104 sec/step, loss=0.09986, avg_loss=0.09359, mel_loss=0.04553, linear_loss=0.05433]
[2020-05-11 21:04:38.613]  Writing summary at step: 145150
[2020-05-11 21:04:39.431]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145150
[2020-05-11 21:04:40.741]  Saving audio and alignment...
[2020-05-11 21:04:47.134]  Input: 자 대결을 위한 완벽한 세팅을 마쳤으니 한번 붙어 봅시다~_______________
[2020-05-11 21:04:49.573]  Step 145151  [3.104 sec/step, loss=0.09590, avg_loss=0.09359, mel_loss=0.04291, linear_loss=0.05300]
[2020-05-11 21:04:52.580]  Step 145152  [3.125 sec/step, loss=0.10015, avg_loss=0.09375, mel_loss=0.04604, linear_loss=0.05411]
[2020-05-11 21:04:57.225]  Step 145153  [3.156 sec/step, loss=0.10138, avg_loss=0.09385, mel_loss=0.04683, linear_loss=0.05455]
[2020-05-11 21:05:04.641]  Step 145154  [3.184 sec/step, loss=0.10155, avg_loss=0.09385, mel_loss=0.04780, linear_loss=0.05375]
[2020-05-11 21:05:11.817]  Step 145155  [3.249 sec/step, loss=0.10267, avg_loss=0.09413, mel_loss=0.04812, linear_loss=0.05455]
[2020-05-11 21:05:13.125]  Step 145156  [3.119 sec/step, loss=0.07505, avg_loss=0.09407, mel_loss=0.03338, linear_loss=0.04167]
[2020-05-11 21:05:15.888]  Step 145157  [3.129 sec/step, loss=0.09511, avg_loss=0.09407, mel_loss=0.04228, linear_loss=0.05283]
[2020-05-11 21:05:19.067]  Generated 32 batches of size 32 in 3.170 sec
[2020-05-11 21:05:29.190]  Step 145158  [3.240 sec/step, loss=0.09855, avg_loss=0.09411, mel_loss=0.04653, linear_loss=0.05201]
[2020-05-11 21:05:31.653]  Step 145159  [3.222 sec/step, loss=0.09517, avg_loss=0.09404, mel_loss=0.04312, linear_loss=0.05205]
[2020-05-11 21:05:44.972]  Step 145160  [3.340 sec/step, loss=0.08761, avg_loss=0.09398, mel_loss=0.04226, linear_loss=0.04534]
[2020-05-11 21:05:46.320]  Step 145161  [3.303 sec/step, loss=0.09052, avg_loss=0.09387, mel_loss=0.04023, linear_loss=0.05029]
[2020-05-11 21:05:51.674]  Step 145162  [3.345 sec/step, loss=0.10090, avg_loss=0.09399, mel_loss=0.04694, linear_loss=0.05396]
[2020-05-11 21:05:52.800]  Step 145163  [3.349 sec/step, loss=0.08815, avg_loss=0.09404, mel_loss=0.03865, linear_loss=0.04950]
[2020-05-11 21:05:53.371]  Step 145164  [3.326 sec/step, loss=0.07231, avg_loss=0.09378, mel_loss=0.03231, linear_loss=0.03999]
[2020-05-11 21:05:56.795]  Step 145165  [3.339 sec/step, loss=0.09819, avg_loss=0.09380, mel_loss=0.04483, linear_loss=0.05336]
[2020-05-11 21:05:59.662]  Step 145166  [3.329 sec/step, loss=0.09796, avg_loss=0.09376, mel_loss=0.04452, linear_loss=0.05344]
[2020-05-11 21:06:02.105]  Step 145167  [3.345 sec/step, loss=0.09474, avg_loss=0.09394, mel_loss=0.04270, linear_loss=0.05204]
[2020-05-11 21:06:04.989]  Step 145168  [3.315 sec/step, loss=0.09965, avg_loss=0.09394, mel_loss=0.04528, linear_loss=0.05437]
[2020-05-11 21:06:06.318]  Step 145169  [3.264 sec/step, loss=0.08792, avg_loss=0.09381, mel_loss=0.03886, linear_loss=0.04906]
[2020-05-11 21:06:07.177]  Step 145170  [3.243 sec/step, loss=0.08009, avg_loss=0.09361, mel_loss=0.03536, linear_loss=0.04474]
[2020-05-11 21:06:12.466]  Step 145171  [3.283 sec/step, loss=0.09957, avg_loss=0.09372, mel_loss=0.04628, linear_loss=0.05328]
[2020-05-11 21:06:18.063]  Step 145172  [3.296 sec/step, loss=0.10086, avg_loss=0.09371, mel_loss=0.04695, linear_loss=0.05390]
[2020-05-11 21:06:19.843]  Step 145173  [3.278 sec/step, loss=0.09421, avg_loss=0.09366, mel_loss=0.04226, linear_loss=0.05195]
[2020-05-11 21:06:20.639]  Step 145174  [3.273 sec/step, loss=0.07206, avg_loss=0.09347, mel_loss=0.03262, linear_loss=0.03945]
[2020-05-11 21:06:23.943]  Step 145175  [3.270 sec/step, loss=0.10033, avg_loss=0.09347, mel_loss=0.04609, linear_loss=0.05424]
[2020-05-11 21:06:25.490]  Step 145176  [3.265 sec/step, loss=0.09250, avg_loss=0.09344, mel_loss=0.04111, linear_loss=0.05139]
[2020-05-11 21:06:39.681]  Step 145177  [3.324 sec/step, loss=0.07607, avg_loss=0.09323, mel_loss=0.03674, linear_loss=0.03933]
[2020-05-11 21:06:40.987]  Step 145178  [3.308 sec/step, loss=0.09071, avg_loss=0.09317, mel_loss=0.04057, linear_loss=0.05013]
[2020-05-11 21:06:45.612]  Step 145179  [3.310 sec/step, loss=0.10132, avg_loss=0.09316, mel_loss=0.04678, linear_loss=0.05454]
[2020-05-11 21:06:48.783]  Step 145180  [3.336 sec/step, loss=0.09963, avg_loss=0.09340, mel_loss=0.04557, linear_loss=0.05406]
[2020-05-11 21:06:49.846]  Step 145181  [3.320 sec/step, loss=0.08828, avg_loss=0.09330, mel_loss=0.03929, linear_loss=0.04899]
[2020-05-11 21:06:51.987]  Step 145182  [3.316 sec/step, loss=0.09663, avg_loss=0.09331, mel_loss=0.04360, linear_loss=0.05303]
[2020-05-11 21:06:53.962]  Step 145183  [3.327 sec/step, loss=0.09450, avg_loss=0.09340, mel_loss=0.04229, linear_loss=0.05221]
[2020-05-11 21:06:56.679]  Step 145184  [3.342 sec/step, loss=0.09728, avg_loss=0.09347, mel_loss=0.04442, linear_loss=0.05286]
[2020-05-11 21:06:57.709]  Step 145185  [3.293 sec/step, loss=0.08605, avg_loss=0.09331, mel_loss=0.03820, linear_loss=0.04785]
[2020-05-11 21:06:59.292]  Step 145186  [3.290 sec/step, loss=0.09097, avg_loss=0.09328, mel_loss=0.04082, linear_loss=0.05015]
[2020-05-11 21:07:00.066]  Step 145187  [3.287 sec/step, loss=0.07850, avg_loss=0.09324, mel_loss=0.03436, linear_loss=0.04414]
[2020-05-11 21:07:08.238]  Step 145188  [3.356 sec/step, loss=0.10120, avg_loss=0.09335, mel_loss=0.04790, linear_loss=0.05330]
[2020-05-11 21:07:12.260]  Step 145189  [3.362 sec/step, loss=0.10126, avg_loss=0.09338, mel_loss=0.04660, linear_loss=0.05467]
[2020-05-11 21:07:13.994]  Generated 32 batches of size 32 in 1.728 sec
[2020-05-11 21:07:18.703]  Step 145190  [3.370 sec/step, loss=0.10165, avg_loss=0.09337, mel_loss=0.04768, linear_loss=0.05397]
[2020-05-11 21:07:19.849]  Step 145191  [3.360 sec/step, loss=0.08730, avg_loss=0.09329, mel_loss=0.03889, linear_loss=0.04842]
[2020-05-11 21:07:23.283]  Step 145192  [3.381 sec/step, loss=0.09781, avg_loss=0.09335, mel_loss=0.04489, linear_loss=0.05292]
[2020-05-11 21:07:27.453]  Step 145193  [3.351 sec/step, loss=0.09950, avg_loss=0.09331, mel_loss=0.04598, linear_loss=0.05352]
[2020-05-11 21:07:29.432]  Step 145194  [3.353 sec/step, loss=0.09495, avg_loss=0.09335, mel_loss=0.04275, linear_loss=0.05220]
[2020-05-11 21:07:36.775]  Step 145195  [3.393 sec/step, loss=0.10284, avg_loss=0.09338, mel_loss=0.04828, linear_loss=0.05457]
[2020-05-11 21:07:39.040]  Step 145196  [3.384 sec/step, loss=0.09496, avg_loss=0.09333, mel_loss=0.04311, linear_loss=0.05185]
[2020-05-11 21:07:40.803]  Step 145197  [3.278 sec/step, loss=0.09170, avg_loss=0.09337, mel_loss=0.04109, linear_loss=0.05061]
[2020-05-11 21:07:44.535]  Step 145198  [3.292 sec/step, loss=0.10168, avg_loss=0.09344, mel_loss=0.04667, linear_loss=0.05502]
[2020-05-11 21:07:46.539]  Step 145199  [3.304 sec/step, loss=0.09415, avg_loss=0.09357, mel_loss=0.04246, linear_loss=0.05169]
[2020-05-11 21:07:51.307]  Step 145200  [3.341 sec/step, loss=0.09998, avg_loss=0.09369, mel_loss=0.04611, linear_loss=0.05387]
[2020-05-11 21:07:51.307]  Writing summary at step: 145200
[2020-05-11 21:07:52.214]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145200
[2020-05-11 21:07:53.520]  Saving audio and alignment...
[2020-05-11 21:07:56.124]  Input: 패기가 넘치게 되죠~________________
[2020-05-11 21:08:00.242]  Step 145201  [3.365 sec/step, loss=0.09923, avg_loss=0.09376, mel_loss=0.04528, linear_loss=0.05394]
[2020-05-11 21:08:02.351]  Step 145202  [3.335 sec/step, loss=0.09617, avg_loss=0.09373, mel_loss=0.04375, linear_loss=0.05242]
[2020-05-11 21:08:08.014]  Step 145203  [3.350 sec/step, loss=0.10128, avg_loss=0.09374, mel_loss=0.04725, linear_loss=0.05404]
[2020-05-11 21:08:10.350]  Step 145204  [3.358 sec/step, loss=0.09585, avg_loss=0.09378, mel_loss=0.04355, linear_loss=0.05229]
[2020-05-11 21:08:12.092]  Step 145205  [3.364 sec/step, loss=0.09298, avg_loss=0.09385, mel_loss=0.04171, linear_loss=0.05127]
[2020-05-11 21:08:12.938]  Step 145206  [3.359 sec/step, loss=0.08332, avg_loss=0.09378, mel_loss=0.03636, linear_loss=0.04695]
[2020-05-11 21:08:13.684]  Step 145207  [3.342 sec/step, loss=0.08532, avg_loss=0.09368, mel_loss=0.03789, linear_loss=0.04743]
[2020-05-11 21:08:27.890]  Step 145208  [3.458 sec/step, loss=0.08323, avg_loss=0.09354, mel_loss=0.04041, linear_loss=0.04282]
[2020-05-11 21:08:37.032]  Step 145209  [3.513 sec/step, loss=0.10413, avg_loss=0.09357, mel_loss=0.04957, linear_loss=0.05456]
[2020-05-11 21:08:38.089]  Step 145210  [3.501 sec/step, loss=0.08952, avg_loss=0.09352, mel_loss=0.03914, linear_loss=0.05037]
[2020-05-11 21:08:41.736]  Step 145211  [3.460 sec/step, loss=0.10110, avg_loss=0.09353, mel_loss=0.04642, linear_loss=0.05467]
[2020-05-11 21:08:44.113]  Step 145212  [3.460 sec/step, loss=0.09658, avg_loss=0.09354, mel_loss=0.04367, linear_loss=0.05291]
[2020-05-11 21:08:47.514]  Step 145213  [3.487 sec/step, loss=0.09834, avg_loss=0.09371, mel_loss=0.04503, linear_loss=0.05331]
[2020-05-11 21:08:52.799]  Step 145214  [3.505 sec/step, loss=0.10132, avg_loss=0.09374, mel_loss=0.04711, linear_loss=0.05421]
[2020-05-11 21:08:55.659]  Step 145215  [3.519 sec/step, loss=0.09626, avg_loss=0.09379, mel_loss=0.04366, linear_loss=0.05259]
[2020-05-11 21:08:58.367]  Step 145216  [3.460 sec/step, loss=0.09689, avg_loss=0.09374, mel_loss=0.04405, linear_loss=0.05283]
[2020-05-11 21:09:00.162]  Step 145217  [3.427 sec/step, loss=0.09395, avg_loss=0.09370, mel_loss=0.04215, linear_loss=0.05180]
[2020-05-11 21:09:01.367]  Step 145218  [3.373 sec/step, loss=0.08918, avg_loss=0.09359, mel_loss=0.03968, linear_loss=0.04949]
[2020-05-11 21:09:05.684]  Step 145219  [3.404 sec/step, loss=0.10303, avg_loss=0.09372, mel_loss=0.04753, linear_loss=0.05550]
[2020-05-11 21:09:07.344]  Generated 32 batches of size 32 in 1.654 sec
[2020-05-11 21:09:13.375]  Step 145220  [3.465 sec/step, loss=0.09998, avg_loss=0.09377, mel_loss=0.04720, linear_loss=0.05278]
[2020-05-11 21:09:16.779]  Step 145221  [3.443 sec/step, loss=0.09794, avg_loss=0.09375, mel_loss=0.04463, linear_loss=0.05332]
[2020-05-11 21:09:17.302]  Step 145222  [3.420 sec/step, loss=0.08154, avg_loss=0.09357, mel_loss=0.03628, linear_loss=0.04526]
[2020-05-11 21:09:18.913]  Step 145223  [3.419 sec/step, loss=0.09341, avg_loss=0.09359, mel_loss=0.04150, linear_loss=0.05191]
[2020-05-11 21:09:19.518]  Step 145224  [3.382 sec/step, loss=0.07814, avg_loss=0.09338, mel_loss=0.03540, linear_loss=0.04273]
[2020-05-11 21:09:25.749]  Step 145225  [3.425 sec/step, loss=0.10202, avg_loss=0.09343, mel_loss=0.04783, linear_loss=0.05419]
[2020-05-11 21:09:28.885]  Step 145226  [3.438 sec/step, loss=0.09797, avg_loss=0.09347, mel_loss=0.04458, linear_loss=0.05339]
[2020-05-11 21:09:30.322]  Step 145227  [3.446 sec/step, loss=0.09038, avg_loss=0.09363, mel_loss=0.04031, linear_loss=0.05007]
[2020-05-11 21:09:31.438]  Step 145228  [3.448 sec/step, loss=0.08251, avg_loss=0.09358, mel_loss=0.03625, linear_loss=0.04626]
[2020-05-11 21:09:37.333]  Step 145229  [3.498 sec/step, loss=0.10239, avg_loss=0.09381, mel_loss=0.04762, linear_loss=0.05477]
[2020-05-11 21:09:39.765]  Step 145230  [3.514 sec/step, loss=0.09528, avg_loss=0.09393, mel_loss=0.04293, linear_loss=0.05235]
[2020-05-11 21:09:43.560]  Step 145231  [3.506 sec/step, loss=0.09996, avg_loss=0.09392, mel_loss=0.04586, linear_loss=0.05410]
[2020-05-11 21:09:45.897]  Step 145232  [3.389 sec/step, loss=0.09606, avg_loss=0.09412, mel_loss=0.04365, linear_loss=0.05241]
[2020-05-11 21:09:54.191]  Step 145233  [3.436 sec/step, loss=0.10012, avg_loss=0.09410, mel_loss=0.04733, linear_loss=0.05279]
[2020-05-11 21:09:58.377]  Step 145234  [3.443 sec/step, loss=0.09870, avg_loss=0.09412, mel_loss=0.04562, linear_loss=0.05308]
[2020-05-11 21:09:59.807]  Step 145235  [3.444 sec/step, loss=0.09099, avg_loss=0.09414, mel_loss=0.04072, linear_loss=0.05027]
[2020-05-11 21:10:12.811]  Step 145236  [3.543 sec/step, loss=0.08457, avg_loss=0.09401, mel_loss=0.04061, linear_loss=0.04395]
[2020-05-11 21:10:13.927]  Step 145237  [3.540 sec/step, loss=0.08765, avg_loss=0.09397, mel_loss=0.03882, linear_loss=0.04883]
[2020-05-11 21:10:15.492]  Step 145238  [3.539 sec/step, loss=0.09004, avg_loss=0.09394, mel_loss=0.04033, linear_loss=0.04971]
[2020-05-11 21:10:17.263]  Step 145239  [3.530 sec/step, loss=0.09360, avg_loss=0.09393, mel_loss=0.04198, linear_loss=0.05163]
[2020-05-11 21:10:19.422]  Step 145240  [3.495 sec/step, loss=0.09524, avg_loss=0.09386, mel_loss=0.04271, linear_loss=0.05252]
[2020-05-11 21:10:20.421]  Step 145241  [3.469 sec/step, loss=0.08368, avg_loss=0.09369, mel_loss=0.03684, linear_loss=0.04684]
[2020-05-11 21:10:21.730]  Step 145242  [3.461 sec/step, loss=0.09100, avg_loss=0.09366, mel_loss=0.04055, linear_loss=0.05044]
[2020-05-11 21:10:27.785]  Step 145243  [3.512 sec/step, loss=0.10012, avg_loss=0.09383, mel_loss=0.04686, linear_loss=0.05326]
[2020-05-11 21:10:35.318]  Step 145244  [3.571 sec/step, loss=0.10091, avg_loss=0.09392, mel_loss=0.04746, linear_loss=0.05345]
[2020-05-11 21:10:36.404]  Step 145245  [3.563 sec/step, loss=0.08422, avg_loss=0.09384, mel_loss=0.03751, linear_loss=0.04671]
[2020-05-11 21:10:40.070]  Step 145246  [3.578 sec/step, loss=0.09685, avg_loss=0.09387, mel_loss=0.04450, linear_loss=0.05235]
[2020-05-11 21:10:43.690]  Step 145247  [3.580 sec/step, loss=0.10055, avg_loss=0.09387, mel_loss=0.04595, linear_loss=0.05460]
[2020-05-11 21:10:44.951]  Step 145248  [3.583 sec/step, loss=0.08526, avg_loss=0.09387, mel_loss=0.03815, linear_loss=0.04711]
[2020-05-11 21:10:47.841]  Step 145249  [3.600 sec/step, loss=0.09682, avg_loss=0.09397, mel_loss=0.04389, linear_loss=0.05293]
[2020-05-11 21:10:52.963]  Step 145250  [3.610 sec/step, loss=0.09875, avg_loss=0.09396, mel_loss=0.04576, linear_loss=0.05299]
[2020-05-11 21:10:52.963]  Writing summary at step: 145250
[2020-05-11 21:10:54.745]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145250
[2020-05-11 21:10:56.075]  Saving audio and alignment...
[2020-05-11 21:10:58.262]  Generated 32 batches of size 32 in 1.632 sec
[2020-05-11 21:11:01.200]  Input: 그 대본 속에 숨은 포인트들을 잘 찾아서~_________________________
[2020-05-11 21:11:03.207]  Step 145251  [3.606 sec/step, loss=0.09411, avg_loss=0.09395, mel_loss=0.04238, linear_loss=0.05173]
[2020-05-11 21:11:06.598]  Step 145252  [3.609 sec/step, loss=0.10138, avg_loss=0.09396, mel_loss=0.04639, linear_loss=0.05498]
[2020-05-11 21:11:07.439]  Step 145253  [3.571 sec/step, loss=0.08147, avg_loss=0.09376, mel_loss=0.03605, linear_loss=0.04542]
[2020-05-11 21:11:08.276]  Step 145254  [3.506 sec/step, loss=0.07915, avg_loss=0.09354, mel_loss=0.03472, linear_loss=0.04443]
[2020-05-11 21:11:09.929]  Step 145255  [3.450 sec/step, loss=0.09143, avg_loss=0.09342, mel_loss=0.04098, linear_loss=0.05045]
[2020-05-11 21:11:14.420]  Step 145256  [3.482 sec/step, loss=0.10112, avg_loss=0.09368, mel_loss=0.04676, linear_loss=0.05437]
[2020-05-11 21:11:16.982]  Step 145257  [3.480 sec/step, loss=0.09863, avg_loss=0.09372, mel_loss=0.04482, linear_loss=0.05381]
[2020-05-11 21:11:17.539]  Step 145258  [3.353 sec/step, loss=0.07585, avg_loss=0.09349, mel_loss=0.03399, linear_loss=0.04185]
[2020-05-11 21:11:22.225]  Step 145259  [3.375 sec/step, loss=0.09975, avg_loss=0.09354, mel_loss=0.04592, linear_loss=0.05383]
[2020-05-11 21:11:26.058]  Step 145260  [3.280 sec/step, loss=0.09802, avg_loss=0.09364, mel_loss=0.04505, linear_loss=0.05297]
[2020-05-11 21:11:40.433]  Step 145261  [3.410 sec/step, loss=0.08056, avg_loss=0.09354, mel_loss=0.03907, linear_loss=0.04150]
[2020-05-11 21:11:41.457]  Step 145262  [3.367 sec/step, loss=0.08457, avg_loss=0.09338, mel_loss=0.03771, linear_loss=0.04685]
[2020-05-11 21:11:43.583]  Step 145263  [3.377 sec/step, loss=0.09646, avg_loss=0.09346, mel_loss=0.04362, linear_loss=0.05284]
[2020-05-11 21:11:44.409]  Step 145264  [3.380 sec/step, loss=0.07866, avg_loss=0.09353, mel_loss=0.03492, linear_loss=0.04373]
[2020-05-11 21:11:49.738]  Step 145265  [3.399 sec/step, loss=0.10243, avg_loss=0.09357, mel_loss=0.04778, linear_loss=0.05465]
[2020-05-11 21:11:57.270]  Step 145266  [3.445 sec/step, loss=0.10236, avg_loss=0.09361, mel_loss=0.04796, linear_loss=0.05440]
[2020-05-11 21:12:00.863]  Step 145267  [3.457 sec/step, loss=0.09657, avg_loss=0.09363, mel_loss=0.04411, linear_loss=0.05246]
[2020-05-11 21:12:02.499]  Step 145268  [3.444 sec/step, loss=0.08850, avg_loss=0.09352, mel_loss=0.03960, linear_loss=0.04889]
[2020-05-11 21:12:08.184]  Step 145269  [3.488 sec/step, loss=0.10201, avg_loss=0.09366, mel_loss=0.04767, linear_loss=0.05435]
[2020-05-11 21:12:10.214]  Step 145270  [3.500 sec/step, loss=0.09350, avg_loss=0.09379, mel_loss=0.04233, linear_loss=0.05117]
[2020-05-11 21:12:14.631]  Step 145271  [3.491 sec/step, loss=0.10114, avg_loss=0.09381, mel_loss=0.04717, linear_loss=0.05397]
[2020-05-11 21:12:15.744]  Step 145272  [3.446 sec/step, loss=0.08780, avg_loss=0.09368, mel_loss=0.03881, linear_loss=0.04898]
[2020-05-11 21:12:17.522]  Step 145273  [3.446 sec/step, loss=0.09230, avg_loss=0.09366, mel_loss=0.04100, linear_loss=0.05130]
[2020-05-11 21:12:20.045]  Step 145274  [3.463 sec/step, loss=0.09639, avg_loss=0.09390, mel_loss=0.04357, linear_loss=0.05282]
[2020-05-11 21:12:22.673]  Step 145275  [3.457 sec/step, loss=0.09528, avg_loss=0.09385, mel_loss=0.04327, linear_loss=0.05202]
[2020-05-11 21:12:23.239]  Step 145276  [3.447 sec/step, loss=0.07507, avg_loss=0.09368, mel_loss=0.03351, linear_loss=0.04156]
[2020-05-11 21:12:29.950]  Step 145277  [3.372 sec/step, loss=0.10280, avg_loss=0.09395, mel_loss=0.04839, linear_loss=0.05441]
[2020-05-11 21:12:31.323]  Step 145278  [3.373 sec/step, loss=0.08714, avg_loss=0.09391, mel_loss=0.03892, linear_loss=0.04823]
[2020-05-11 21:12:35.318]  Step 145279  [3.366 sec/step, loss=0.10250, avg_loss=0.09392, mel_loss=0.04695, linear_loss=0.05554]
[2020-05-11 21:12:36.230]  Step 145280  [3.344 sec/step, loss=0.08397, avg_loss=0.09376, mel_loss=0.03701, linear_loss=0.04696]
[2020-05-11 21:12:38.140]  Step 145281  [3.352 sec/step, loss=0.09401, avg_loss=0.09382, mel_loss=0.04176, linear_loss=0.05225]
[2020-05-11 21:12:40.119]  Generated 32 batches of size 32 in 1.972 sec
[2020-05-11 21:12:40.629]  Step 145282  [3.356 sec/step, loss=0.09554, avg_loss=0.09381, mel_loss=0.04299, linear_loss=0.05255]
[2020-05-11 21:12:41.785]  Step 145283  [3.347 sec/step, loss=0.09079, avg_loss=0.09377, mel_loss=0.04039, linear_loss=0.05040]
[2020-05-11 21:12:43.388]  Step 145284  [3.336 sec/step, loss=0.09625, avg_loss=0.09376, mel_loss=0.04309, linear_loss=0.05316]
[2020-05-11 21:12:44.797]  Step 145285  [3.340 sec/step, loss=0.08980, avg_loss=0.09380, mel_loss=0.04029, linear_loss=0.04951]
[2020-05-11 21:12:53.940]  Step 145286  [3.416 sec/step, loss=0.09922, avg_loss=0.09388, mel_loss=0.04693, linear_loss=0.05229]
[2020-05-11 21:12:57.336]  Step 145287  [3.442 sec/step, loss=0.10070, avg_loss=0.09411, mel_loss=0.04606, linear_loss=0.05464]
[2020-05-11 21:12:58.090]  Step 145288  [3.368 sec/step, loss=0.08469, avg_loss=0.09394, mel_loss=0.03699, linear_loss=0.04771]
[2020-05-11 21:13:01.094]  Step 145289  [3.358 sec/step, loss=0.10126, avg_loss=0.09394, mel_loss=0.04653, linear_loss=0.05473]
[2020-05-11 21:13:03.973]  Step 145290  [3.322 sec/step, loss=0.09822, avg_loss=0.09391, mel_loss=0.04472, linear_loss=0.05350]
[2020-05-11 21:13:05.913]  Step 145291  [3.330 sec/step, loss=0.09375, avg_loss=0.09397, mel_loss=0.04212, linear_loss=0.05164]
[2020-05-11 21:13:08.292]  Step 145292  [3.319 sec/step, loss=0.09432, avg_loss=0.09394, mel_loss=0.04239, linear_loss=0.05193]
[2020-05-11 21:13:10.477]  Step 145293  [3.299 sec/step, loss=0.09671, avg_loss=0.09391, mel_loss=0.04394, linear_loss=0.05277]
[2020-05-11 21:13:11.695]  Step 145294  [3.292 sec/step, loss=0.08741, avg_loss=0.09383, mel_loss=0.03881, linear_loss=0.04860]
[2020-05-11 21:13:18.038]  Step 145295  [3.282 sec/step, loss=0.10037, avg_loss=0.09381, mel_loss=0.04684, linear_loss=0.05353]
[2020-05-11 21:13:19.557]  Step 145296  [3.274 sec/step, loss=0.09280, avg_loss=0.09379, mel_loss=0.04155, linear_loss=0.05125]
[2020-05-11 21:13:23.637]  Step 145297  [3.298 sec/step, loss=0.09964, avg_loss=0.09387, mel_loss=0.04562, linear_loss=0.05402]
[2020-05-11 21:13:25.783]  Step 145298  [3.282 sec/step, loss=0.09463, avg_loss=0.09379, mel_loss=0.04273, linear_loss=0.05190]
[2020-05-11 21:13:26.890]  Step 145299  [3.273 sec/step, loss=0.08679, avg_loss=0.09372, mel_loss=0.03833, linear_loss=0.04847]
[2020-05-11 21:13:28.671]  Step 145300  [3.243 sec/step, loss=0.09228, avg_loss=0.09364, mel_loss=0.04120, linear_loss=0.05108]
[2020-05-11 21:13:28.671]  Writing summary at step: 145300
[2020-05-11 21:13:33.908]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145300
[2020-05-11 21:13:35.243]  Saving audio and alignment...
[2020-05-11 21:13:40.780]  Input: 인상 깊은 애드립 만드는 여섯가지 공식과 예시를~____________
[2020-05-11 21:13:43.893]  Step 145301  [3.233 sec/step, loss=0.09914, avg_loss=0.09364, mel_loss=0.04521, linear_loss=0.05393]
[2020-05-11 21:13:46.600]  Step 145302  [3.239 sec/step, loss=0.09621, avg_loss=0.09364, mel_loss=0.04373, linear_loss=0.05248]
[2020-05-11 21:13:50.050]  Step 145303  [3.217 sec/step, loss=0.09675, avg_loss=0.09360, mel_loss=0.04450, linear_loss=0.05225]
[2020-05-11 21:13:51.350]  Step 145304  [3.206 sec/step, loss=0.09128, avg_loss=0.09355, mel_loss=0.04070, linear_loss=0.05059]
[2020-05-11 21:13:52.722]  Step 145305  [3.203 sec/step, loss=0.08979, avg_loss=0.09352, mel_loss=0.03993, linear_loss=0.04986]
[2020-05-11 21:14:00.170]  Step 145306  [3.269 sec/step, loss=0.10224, avg_loss=0.09371, mel_loss=0.04824, linear_loss=0.05400]
[2020-05-11 21:14:04.192]  Step 145307  [3.301 sec/step, loss=0.10041, avg_loss=0.09386, mel_loss=0.04625, linear_loss=0.05417]
[2020-05-11 21:14:16.202]  Step 145308  [3.279 sec/step, loss=0.08769, avg_loss=0.09391, mel_loss=0.04197, linear_loss=0.04572]
[2020-05-11 21:14:17.860]  Step 145309  [3.205 sec/step, loss=0.09094, avg_loss=0.09377, mel_loss=0.04092, linear_loss=0.05002]
[2020-05-11 21:14:19.863]  Step 145310  [3.214 sec/step, loss=0.09531, avg_loss=0.09383, mel_loss=0.04278, linear_loss=0.05252]
[2020-05-11 21:14:24.389]  Step 145311  [3.223 sec/step, loss=0.10156, avg_loss=0.09384, mel_loss=0.04689, linear_loss=0.05467]
[2020-05-11 21:14:26.195]  Generated 32 batches of size 32 in 1.800 sec
[2020-05-11 21:14:27.641]  Step 145312  [3.232 sec/step, loss=0.10050, avg_loss=0.09388, mel_loss=0.04571, linear_loss=0.05479]
[2020-05-11 21:14:28.635]  Step 145313  [3.208 sec/step, loss=0.08185, avg_loss=0.09371, mel_loss=0.03602, linear_loss=0.04584]
[2020-05-11 21:14:29.394]  Step 145314  [3.162 sec/step, loss=0.07507, avg_loss=0.09345, mel_loss=0.03315, linear_loss=0.04192]
[2020-05-11 21:14:32.255]  Step 145315  [3.162 sec/step, loss=0.09756, avg_loss=0.09346, mel_loss=0.04436, linear_loss=0.05320]
[2020-05-11 21:14:33.058]  Step 145316  [3.143 sec/step, loss=0.07970, avg_loss=0.09329, mel_loss=0.03511, linear_loss=0.04459]
[2020-05-11 21:14:41.045]  Step 145317  [3.205 sec/step, loss=0.10077, avg_loss=0.09336, mel_loss=0.04770, linear_loss=0.05307]
[2020-05-11 21:14:41.605]  Step 145318  [3.199 sec/step, loss=0.07237, avg_loss=0.09319, mel_loss=0.03312, linear_loss=0.03925]
[2020-05-11 21:14:47.161]  Step 145319  [3.211 sec/step, loss=0.10081, avg_loss=0.09317, mel_loss=0.04667, linear_loss=0.05414]
[2020-05-11 21:14:48.183]  Step 145320  [3.144 sec/step, loss=0.08419, avg_loss=0.09301, mel_loss=0.03731, linear_loss=0.04688]
[2020-05-11 21:14:56.887]  Step 145321  [3.197 sec/step, loss=0.09881, avg_loss=0.09302, mel_loss=0.04663, linear_loss=0.05218]
[2020-05-11 21:15:00.934]  Step 145322  [3.233 sec/step, loss=0.09903, avg_loss=0.09319, mel_loss=0.04530, linear_loss=0.05373]
[2020-05-11 21:15:01.498]  Step 145323  [3.222 sec/step, loss=0.07176, avg_loss=0.09298, mel_loss=0.03195, linear_loss=0.03980]
[2020-05-11 21:15:04.938]  Step 145324  [3.250 sec/step, loss=0.09979, avg_loss=0.09319, mel_loss=0.04574, linear_loss=0.05405]
[2020-05-11 21:15:10.527]  Step 145325  [3.244 sec/step, loss=0.09919, avg_loss=0.09316, mel_loss=0.04587, linear_loss=0.05332]
[2020-05-11 21:15:11.363]  Step 145326  [3.221 sec/step, loss=0.07828, avg_loss=0.09297, mel_loss=0.03454, linear_loss=0.04374]
[2020-05-11 21:15:13.146]  Step 145327  [3.225 sec/step, loss=0.09329, avg_loss=0.09300, mel_loss=0.04150, linear_loss=0.05179]
[2020-05-11 21:15:27.387]  Step 145328  [3.356 sec/step, loss=0.07976, avg_loss=0.09297, mel_loss=0.03857, linear_loss=0.04119]
[2020-05-11 21:15:29.352]  Step 145329  [3.316 sec/step, loss=0.09294, avg_loss=0.09287, mel_loss=0.04161, linear_loss=0.05134]
[2020-05-11 21:15:31.436]  Step 145330  [3.313 sec/step, loss=0.08621, avg_loss=0.09278, mel_loss=0.03842, linear_loss=0.04779]
[2020-05-11 21:15:34.568]  Step 145331  [3.306 sec/step, loss=0.09579, avg_loss=0.09274, mel_loss=0.04315, linear_loss=0.05264]
[2020-05-11 21:15:41.865]  Step 145332  [3.356 sec/step, loss=0.10015, avg_loss=0.09278, mel_loss=0.04625, linear_loss=0.05390]
[2020-05-11 21:15:43.402]  Step 145333  [3.288 sec/step, loss=0.08578, avg_loss=0.09264, mel_loss=0.03809, linear_loss=0.04769]
[2020-05-11 21:15:46.770]  Step 145334  [3.280 sec/step, loss=0.09391, avg_loss=0.09259, mel_loss=0.04250, linear_loss=0.05141]
[2020-05-11 21:15:50.680]  Step 145335  [3.305 sec/step, loss=0.09715, avg_loss=0.09265, mel_loss=0.04416, linear_loss=0.05298]
[2020-05-11 21:15:51.777]  Step 145336  [3.186 sec/step, loss=0.08675, avg_loss=0.09268, mel_loss=0.03819, linear_loss=0.04856]
[2020-05-11 21:15:52.568]  Step 145337  [3.183 sec/step, loss=0.08008, avg_loss=0.09260, mel_loss=0.03537, linear_loss=0.04472]
[2020-05-11 21:15:57.989]  Step 145338  [3.221 sec/step, loss=0.09908, avg_loss=0.09269, mel_loss=0.04603, linear_loss=0.05304]
[2020-05-11 21:15:58.955]  Step 145339  [3.213 sec/step, loss=0.08032, avg_loss=0.09256, mel_loss=0.03531, linear_loss=0.04502]
[2020-05-11 21:16:02.125]  Step 145340  [3.223 sec/step, loss=0.09961, avg_loss=0.09260, mel_loss=0.04538, linear_loss=0.05423]
[2020-05-11 21:16:09.929]  Step 145341  [3.291 sec/step, loss=0.10101, avg_loss=0.09277, mel_loss=0.04755, linear_loss=0.05346]
[2020-05-11 21:16:13.544]  Step 145342  [3.314 sec/step, loss=0.10164, avg_loss=0.09288, mel_loss=0.04665, linear_loss=0.05499]
[2020-05-11 21:16:15.000]  Step 145343  [3.268 sec/step, loss=0.09091, avg_loss=0.09279, mel_loss=0.04047, linear_loss=0.05044]
[2020-05-11 21:16:16.675]  Generated 32 batches of size 32 in 1.670 sec
[2020-05-11 21:16:21.789]  Step 145344  [3.261 sec/step, loss=0.09938, avg_loss=0.09277, mel_loss=0.04655, linear_loss=0.05282]
[2020-05-11 21:16:24.568]  Step 145345  [3.278 sec/step, loss=0.09527, avg_loss=0.09288, mel_loss=0.04327, linear_loss=0.05200]
[2020-05-11 21:16:25.909]  Step 145346  [3.255 sec/step, loss=0.09025, avg_loss=0.09282, mel_loss=0.04005, linear_loss=0.05021]
[2020-05-11 21:16:27.849]  Step 145347  [3.238 sec/step, loss=0.09196, avg_loss=0.09273, mel_loss=0.04119, linear_loss=0.05077]
[2020-05-11 21:16:29.567]  Step 145348  [3.242 sec/step, loss=0.09450, avg_loss=0.09282, mel_loss=0.04214, linear_loss=0.05236]
[2020-05-11 21:16:31.869]  Step 145349  [3.237 sec/step, loss=0.09670, avg_loss=0.09282, mel_loss=0.04393, linear_loss=0.05277]
[2020-05-11 21:16:34.076]  Step 145350  [3.207 sec/step, loss=0.09506, avg_loss=0.09279, mel_loss=0.04317, linear_loss=0.05190]
[2020-05-11 21:16:34.076]  Writing summary at step: 145350
[2020-05-11 21:16:37.109]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145350
[2020-05-11 21:16:38.443]  Saving audio and alignment...
[2020-05-11 21:16:44.608]  Input: 들어가 볼까요 이렇게 끼를 좀 부려 보세요~_____________________________________
[2020-05-11 21:16:46.641]  Step 145351  [3.208 sec/step, loss=0.09603, avg_loss=0.09280, mel_loss=0.04291, linear_loss=0.05311]
[2020-05-11 21:16:50.750]  Step 145352  [3.215 sec/step, loss=0.10036, avg_loss=0.09279, mel_loss=0.04594, linear_loss=0.05442]
[2020-05-11 21:16:51.754]  Step 145353  [3.216 sec/step, loss=0.08830, avg_loss=0.09286, mel_loss=0.03881, linear_loss=0.04950]
[2020-05-11 21:16:57.879]  Step 145354  [3.269 sec/step, loss=0.10076, avg_loss=0.09308, mel_loss=0.04715, linear_loss=0.05360]
[2020-05-11 21:16:58.644]  Step 145355  [3.260 sec/step, loss=0.08317, avg_loss=0.09300, mel_loss=0.03647, linear_loss=0.04670]
[2020-05-11 21:17:05.598]  Step 145356  [3.285 sec/step, loss=0.10347, avg_loss=0.09302, mel_loss=0.04842, linear_loss=0.05505]
[2020-05-11 21:17:07.588]  Step 145357  [3.279 sec/step, loss=0.09602, avg_loss=0.09299, mel_loss=0.04306, linear_loss=0.05296]
[2020-05-11 21:17:12.127]  Step 145358  [3.319 sec/step, loss=0.10115, avg_loss=0.09325, mel_loss=0.04669, linear_loss=0.05445]
[2020-05-11 21:17:12.970]  Step 145359  [3.281 sec/step, loss=0.08315, avg_loss=0.09308, mel_loss=0.03649, linear_loss=0.04666]
[2020-05-11 21:17:13.497]  Step 145360  [3.248 sec/step, loss=0.07471, avg_loss=0.09285, mel_loss=0.03401, linear_loss=0.04071]
[2020-05-11 21:17:15.152]  Step 145361  [3.121 sec/step, loss=0.08926, avg_loss=0.09293, mel_loss=0.04018, linear_loss=0.04908]
[2020-05-11 21:17:17.631]  Step 145362  [3.135 sec/step, loss=0.09607, avg_loss=0.09305, mel_loss=0.04344, linear_loss=0.05263]
[2020-05-11 21:17:26.495]  Step 145363  [3.202 sec/step, loss=0.09952, avg_loss=0.09308, mel_loss=0.04699, linear_loss=0.05253]
[2020-05-11 21:17:27.723]  Step 145364  [3.206 sec/step, loss=0.08803, avg_loss=0.09317, mel_loss=0.03935, linear_loss=0.04868]
[2020-05-11 21:17:29.899]  Step 145365  [3.175 sec/step, loss=0.09443, avg_loss=0.09309, mel_loss=0.04238, linear_loss=0.05205]
[2020-05-11 21:17:31.320]  Step 145366  [3.114 sec/step, loss=0.08909, avg_loss=0.09296, mel_loss=0.03998, linear_loss=0.04912]
[2020-05-11 21:17:32.368]  Step 145367  [3.088 sec/step, loss=0.08685, avg_loss=0.09286, mel_loss=0.03853, linear_loss=0.04832]
[2020-05-11 21:17:37.623]  Step 145368  [3.125 sec/step, loss=0.10170, avg_loss=0.09300, mel_loss=0.04740, linear_loss=0.05430]
[2020-05-11 21:17:38.965]  Step 145369  [3.081 sec/step, loss=0.09108, avg_loss=0.09289, mel_loss=0.04065, linear_loss=0.05043]
[2020-05-11 21:17:40.776]  Step 145370  [3.079 sec/step, loss=0.09378, avg_loss=0.09289, mel_loss=0.04219, linear_loss=0.05159]
[2020-05-11 21:17:41.887]  Step 145371  [3.046 sec/step, loss=0.08970, avg_loss=0.09278, mel_loss=0.03931, linear_loss=0.05039]
[2020-05-11 21:17:54.574]  Step 145372  [3.162 sec/step, loss=0.08803, avg_loss=0.09278, mel_loss=0.04212, linear_loss=0.04590]
[2020-05-11 21:17:55.366]  Step 145373  [3.152 sec/step, loss=0.08046, avg_loss=0.09266, mel_loss=0.03541, linear_loss=0.04505]
[2020-05-11 21:17:57.064]  Generated 32 batches of size 32 in 1.693 sec
[2020-05-11 21:17:59.496]  Step 145374  [3.168 sec/step, loss=0.10184, avg_loss=0.09271, mel_loss=0.04672, linear_loss=0.05512]
[2020-05-11 21:18:03.114]  Step 145375  [3.178 sec/step, loss=0.10103, avg_loss=0.09277, mel_loss=0.04634, linear_loss=0.05469]
[2020-05-11 21:18:08.020]  Step 145376  [3.221 sec/step, loss=0.10226, avg_loss=0.09304, mel_loss=0.04742, linear_loss=0.05484]
[2020-05-11 21:18:11.160]  Step 145377  [3.185 sec/step, loss=0.09900, avg_loss=0.09300, mel_loss=0.04527, linear_loss=0.05372]
[2020-05-11 21:18:14.064]  Step 145378  [3.201 sec/step, loss=0.09970, avg_loss=0.09313, mel_loss=0.04551, linear_loss=0.05419]
[2020-05-11 21:18:16.450]  Step 145379  [3.185 sec/step, loss=0.09728, avg_loss=0.09308, mel_loss=0.04370, linear_loss=0.05358]
[2020-05-11 21:18:19.045]  Step 145380  [3.201 sec/step, loss=0.09745, avg_loss=0.09321, mel_loss=0.04434, linear_loss=0.05311]
[2020-05-11 21:18:20.798]  Step 145381  [3.200 sec/step, loss=0.09216, avg_loss=0.09319, mel_loss=0.04107, linear_loss=0.05109]
[2020-05-11 21:18:24.290]  Step 145382  [3.210 sec/step, loss=0.09804, avg_loss=0.09322, mel_loss=0.04513, linear_loss=0.05290]
[2020-05-11 21:18:28.622]  Step 145383  [3.242 sec/step, loss=0.09805, avg_loss=0.09329, mel_loss=0.04506, linear_loss=0.05300]
[2020-05-11 21:18:30.968]  Step 145384  [3.249 sec/step, loss=0.09569, avg_loss=0.09329, mel_loss=0.04327, linear_loss=0.05241]
[2020-05-11 21:18:32.509]  Step 145385  [3.250 sec/step, loss=0.09101, avg_loss=0.09330, mel_loss=0.04029, linear_loss=0.05071]
[2020-05-11 21:18:35.865]  Step 145386  [3.193 sec/step, loss=0.09924, avg_loss=0.09330, mel_loss=0.04521, linear_loss=0.05404]
[2020-05-11 21:18:40.992]  Step 145387  [3.210 sec/step, loss=0.10185, avg_loss=0.09331, mel_loss=0.04729, linear_loss=0.05456]
[2020-05-11 21:18:42.027]  Step 145388  [3.213 sec/step, loss=0.08368, avg_loss=0.09330, mel_loss=0.03690, linear_loss=0.04679]
[2020-05-11 21:18:44.829]  Step 145389  [3.211 sec/step, loss=0.09714, avg_loss=0.09326, mel_loss=0.04421, linear_loss=0.05293]
[2020-05-11 21:18:48.257]  Step 145390  [3.216 sec/step, loss=0.09778, avg_loss=0.09325, mel_loss=0.04475, linear_loss=0.05303]
[2020-05-11 21:18:49.566]  Step 145391  [3.210 sec/step, loss=0.08809, avg_loss=0.09320, mel_loss=0.03915, linear_loss=0.04894]
[2020-05-11 21:18:50.352]  Step 145392  [3.194 sec/step, loss=0.07628, avg_loss=0.09302, mel_loss=0.03329, linear_loss=0.04299]
[2020-05-11 21:18:57.027]  Step 145393  [3.239 sec/step, loss=0.09992, avg_loss=0.09305, mel_loss=0.04655, linear_loss=0.05337]
[2020-05-11 21:18:58.752]  Step 145394  [3.244 sec/step, loss=0.09298, avg_loss=0.09311, mel_loss=0.04177, linear_loss=0.05121]
[2020-05-11 21:19:03.365]  Step 145395  [3.227 sec/step, loss=0.10107, avg_loss=0.09311, mel_loss=0.04662, linear_loss=0.05445]
[2020-05-11 21:19:04.819]  Step 145396  [3.226 sec/step, loss=0.08914, avg_loss=0.09308, mel_loss=0.04004, linear_loss=0.04909]
[2020-05-11 21:19:07.234]  Step 145397  [3.209 sec/step, loss=0.09490, avg_loss=0.09303, mel_loss=0.04280, linear_loss=0.05210]
[2020-05-11 21:19:08.978]  Step 145398  [3.205 sec/step, loss=0.09294, avg_loss=0.09301, mel_loss=0.04144, linear_loss=0.05150]
[2020-05-11 21:19:17.748]  Step 145399  [3.282 sec/step, loss=0.09994, avg_loss=0.09314, mel_loss=0.04733, linear_loss=0.05261]
[2020-05-11 21:19:25.183]  Step 145400  [3.338 sec/step, loss=0.10288, avg_loss=0.09325, mel_loss=0.04840, linear_loss=0.05448]
[2020-05-11 21:19:25.183]  Writing summary at step: 145400
[2020-05-11 21:19:28.646]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145400
[2020-05-11 21:19:29.970]  Saving audio and alignment...
[2020-05-11 21:19:35.841]  Input: 제 아무리 동장군이 세다 해도 봄은 오고 꽃은 핀다~______________________________________
[2020-05-11 21:19:38.377]  Step 145401  [3.333 sec/step, loss=0.09702, avg_loss=0.09323, mel_loss=0.04394, linear_loss=0.05308]
[2020-05-11 21:19:39.427]  Step 145402  [3.316 sec/step, loss=0.08754, avg_loss=0.09314, mel_loss=0.03870, linear_loss=0.04884]
[2020-05-11 21:19:42.408]  Step 145403  [3.311 sec/step, loss=0.09985, avg_loss=0.09317, mel_loss=0.04566, linear_loss=0.05418]
[2020-05-11 21:19:44.187]  Generated 32 batches of size 32 in 1.774 sec
[2020-05-11 21:19:44.383]  Step 145404  [3.318 sec/step, loss=0.09219, avg_loss=0.09318, mel_loss=0.04111, linear_loss=0.05108]
[2020-05-11 21:19:45.227]  Step 145405  [3.313 sec/step, loss=0.08012, avg_loss=0.09308, mel_loss=0.03565, linear_loss=0.04446]
[2020-05-11 21:19:58.333]  Step 145406  [3.369 sec/step, loss=0.08400, avg_loss=0.09290, mel_loss=0.04025, linear_loss=0.04375]
[2020-05-11 21:20:03.953]  Step 145407  [3.385 sec/step, loss=0.10099, avg_loss=0.09291, mel_loss=0.04716, linear_loss=0.05382]
[2020-05-11 21:20:05.345]  Step 145408  [3.279 sec/step, loss=0.09057, avg_loss=0.09294, mel_loss=0.04053, linear_loss=0.05005]
[2020-05-11 21:20:07.357]  Step 145409  [3.283 sec/step, loss=0.09554, avg_loss=0.09298, mel_loss=0.04284, linear_loss=0.05269]
[2020-05-11 21:20:07.919]  Step 145410  [3.268 sec/step, loss=0.07589, avg_loss=0.09279, mel_loss=0.03414, linear_loss=0.04175]
[2020-05-11 21:20:09.062]  Step 145411  [3.235 sec/step, loss=0.08816, avg_loss=0.09265, mel_loss=0.03885, linear_loss=0.04932]
[2020-05-11 21:20:11.171]  Step 145412  [3.223 sec/step, loss=0.09674, avg_loss=0.09262, mel_loss=0.04371, linear_loss=0.05302]
[2020-05-11 21:20:12.975]  Step 145413  [3.231 sec/step, loss=0.09161, avg_loss=0.09271, mel_loss=0.04103, linear_loss=0.05059]
[2020-05-11 21:20:16.655]  Step 145414  [3.260 sec/step, loss=0.10017, avg_loss=0.09297, mel_loss=0.04600, linear_loss=0.05417]
[2020-05-11 21:20:19.854]  Step 145415  [3.264 sec/step, loss=0.10191, avg_loss=0.09301, mel_loss=0.04645, linear_loss=0.05546]
[2020-05-11 21:20:22.986]  Step 145416  [3.287 sec/step, loss=0.10051, avg_loss=0.09322, mel_loss=0.04591, linear_loss=0.05460]
[2020-05-11 21:20:23.869]  Step 145417  [3.216 sec/step, loss=0.08763, avg_loss=0.09309, mel_loss=0.03867, linear_loss=0.04895]
[2020-05-11 21:20:31.071]  Step 145418  [3.283 sec/step, loss=0.09923, avg_loss=0.09335, mel_loss=0.04655, linear_loss=0.05268]
[2020-05-11 21:20:36.754]  Step 145419  [3.284 sec/step, loss=0.10180, avg_loss=0.09336, mel_loss=0.04749, linear_loss=0.05431]
[2020-05-11 21:20:41.121]  Step 145420  [3.317 sec/step, loss=0.10194, avg_loss=0.09354, mel_loss=0.04732, linear_loss=0.05462]
[2020-05-11 21:20:42.201]  Step 145421  [3.241 sec/step, loss=0.08984, avg_loss=0.09345, mel_loss=0.03968, linear_loss=0.05017]
[2020-05-11 21:20:43.419]  Step 145422  [3.213 sec/step, loss=0.08993, avg_loss=0.09336, mel_loss=0.04037, linear_loss=0.04957]
[2020-05-11 21:20:44.171]  Step 145423  [3.215 sec/step, loss=0.07945, avg_loss=0.09344, mel_loss=0.03616, linear_loss=0.04328]
[2020-05-11 21:20:45.877]  Step 145424  [3.197 sec/step, loss=0.09400, avg_loss=0.09338, mel_loss=0.04220, linear_loss=0.05181]
[2020-05-11 21:20:49.820]  Step 145425  [3.181 sec/step, loss=0.09935, avg_loss=0.09338, mel_loss=0.04564, linear_loss=0.05371]
[2020-05-11 21:20:51.460]  Step 145426  [3.189 sec/step, loss=0.09445, avg_loss=0.09354, mel_loss=0.04252, linear_loss=0.05192]
[2020-05-11 21:20:52.892]  Step 145427  [3.185 sec/step, loss=0.08831, avg_loss=0.09349, mel_loss=0.03946, linear_loss=0.04885]
[2020-05-11 21:21:07.769]  Step 145428  [3.192 sec/step, loss=0.08072, avg_loss=0.09350, mel_loss=0.03904, linear_loss=0.04168]
[2020-05-11 21:21:08.786]  Step 145429  [3.182 sec/step, loss=0.08762, avg_loss=0.09345, mel_loss=0.03898, linear_loss=0.04863]
[2020-05-11 21:21:17.389]  Step 145430  [3.247 sec/step, loss=0.10013, avg_loss=0.09359, mel_loss=0.04748, linear_loss=0.05265]
[2020-05-11 21:21:18.189]  Step 145431  [3.224 sec/step, loss=0.08295, avg_loss=0.09346, mel_loss=0.03600, linear_loss=0.04695]
[2020-05-11 21:21:20.216]  Step 145432  [3.171 sec/step, loss=0.09332, avg_loss=0.09339, mel_loss=0.04221, linear_loss=0.05111]
[2020-05-11 21:21:22.715]  Step 145433  [3.181 sec/step, loss=0.09623, avg_loss=0.09350, mel_loss=0.04334, linear_loss=0.05289]
[2020-05-11 21:21:27.322]  Step 145434  [3.193 sec/step, loss=0.10065, avg_loss=0.09356, mel_loss=0.04614, linear_loss=0.05451]
[2020-05-11 21:21:28.752]  Step 145435  [3.169 sec/step, loss=0.09114, avg_loss=0.09350, mel_loss=0.04065, linear_loss=0.05049]
[2020-05-11 21:21:29.485]  Step 145436  [3.165 sec/step, loss=0.08282, avg_loss=0.09346, mel_loss=0.03713, linear_loss=0.04569]
[2020-05-11 21:21:30.441]  Generated 32 batches of size 32 in 1.685 sec
[2020-05-11 21:21:31.910]  Step 145437  [3.181 sec/step, loss=0.09601, avg_loss=0.09362, mel_loss=0.04341, linear_loss=0.05260]
[2020-05-11 21:21:33.864]  Step 145438  [3.147 sec/step, loss=0.09605, avg_loss=0.09359, mel_loss=0.04311, linear_loss=0.05294]
[2020-05-11 21:21:39.797]  Step 145439  [3.196 sec/step, loss=0.10242, avg_loss=0.09381, mel_loss=0.04807, linear_loss=0.05435]
[2020-05-11 21:21:43.172]  Step 145440  [3.198 sec/step, loss=0.09888, avg_loss=0.09381, mel_loss=0.04501, linear_loss=0.05388]
[2020-05-11 21:21:48.435]  Step 145441  [3.173 sec/step, loss=0.10038, avg_loss=0.09380, mel_loss=0.04633, linear_loss=0.05405]
[2020-05-11 21:21:50.550]  Step 145442  [3.158 sec/step, loss=0.09852, avg_loss=0.09377, mel_loss=0.04445, linear_loss=0.05407]
[2020-05-11 21:21:53.276]  Step 145443  [3.171 sec/step, loss=0.09757, avg_loss=0.09384, mel_loss=0.04463, linear_loss=0.05294]
[2020-05-11 21:21:56.192]  Step 145444  [3.132 sec/step, loss=0.10070, avg_loss=0.09385, mel_loss=0.04602, linear_loss=0.05469]
[2020-05-11 21:21:58.333]  Step 145445  [3.126 sec/step, loss=0.09461, avg_loss=0.09384, mel_loss=0.04278, linear_loss=0.05184]
[2020-05-11 21:22:00.269]  Step 145446  [3.131 sec/step, loss=0.09460, avg_loss=0.09389, mel_loss=0.04255, linear_loss=0.05206]
[2020-05-11 21:22:07.043]  Step 145447  [3.180 sec/step, loss=0.10166, avg_loss=0.09398, mel_loss=0.04788, linear_loss=0.05378]
[2020-05-11 21:22:12.155]  Step 145448  [3.214 sec/step, loss=0.10089, avg_loss=0.09405, mel_loss=0.04681, linear_loss=0.05409]
[2020-05-11 21:22:13.493]  Step 145449  [3.204 sec/step, loss=0.09313, avg_loss=0.09401, mel_loss=0.04147, linear_loss=0.05166]
[2020-05-11 21:22:16.937]  Step 145450  [3.216 sec/step, loss=0.09840, avg_loss=0.09405, mel_loss=0.04496, linear_loss=0.05344]
[2020-05-11 21:22:16.937]  Writing summary at step: 145450
[2020-05-11 21:22:17.699]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145450
[2020-05-11 21:22:18.995]  Saving audio and alignment...
[2020-05-11 21:22:23.667]  Input: 주어에 다른 처리를 하실 줄 알아야겠어요~___________________
[2020-05-11 21:22:25.485]  Step 145451  [3.214 sec/step, loss=0.09217, avg_loss=0.09401, mel_loss=0.04135, linear_loss=0.05082]
[2020-05-11 21:22:39.267]  Step 145452  [3.311 sec/step, loss=0.07922, avg_loss=0.09380, mel_loss=0.03846, linear_loss=0.04076]
[2020-05-11 21:22:39.830]  Step 145453  [3.307 sec/step, loss=0.07297, avg_loss=0.09364, mel_loss=0.03291, linear_loss=0.04006]
[2020-05-11 21:22:45.400]  Step 145454  [3.301 sec/step, loss=0.10324, avg_loss=0.09367, mel_loss=0.04826, linear_loss=0.05498]
[2020-05-11 21:22:48.251]  Step 145455  [3.322 sec/step, loss=0.09746, avg_loss=0.09381, mel_loss=0.04450, linear_loss=0.05296]
[2020-05-11 21:22:52.501]  Step 145456  [3.295 sec/step, loss=0.09981, avg_loss=0.09377, mel_loss=0.04584, linear_loss=0.05396]
[2020-05-11 21:22:57.042]  Step 145457  [3.320 sec/step, loss=0.10235, avg_loss=0.09384, mel_loss=0.04731, linear_loss=0.05504]
[2020-05-11 21:22:58.145]  Step 145458  [3.286 sec/step, loss=0.08816, avg_loss=0.09371, mel_loss=0.03910, linear_loss=0.04906]
[2020-05-11 21:22:59.341]  Step 145459  [3.290 sec/step, loss=0.08621, avg_loss=0.09374, mel_loss=0.03817, linear_loss=0.04804]
[2020-05-11 21:23:07.967]  Step 145460  [3.371 sec/step, loss=0.10068, avg_loss=0.09400, mel_loss=0.04770, linear_loss=0.05298]
[2020-05-11 21:23:09.242]  Step 145461  [3.367 sec/step, loss=0.08964, avg_loss=0.09400, mel_loss=0.03969, linear_loss=0.04995]
[2020-05-11 21:23:16.772]  Step 145462  [3.417 sec/step, loss=0.10383, avg_loss=0.09408, mel_loss=0.04910, linear_loss=0.05473]
[2020-05-11 21:23:18.513]  Step 145463  [3.346 sec/step, loss=0.09141, avg_loss=0.09400, mel_loss=0.04100, linear_loss=0.05041]
[2020-05-11 21:23:21.831]  Step 145464  [3.367 sec/step, loss=0.09903, avg_loss=0.09411, mel_loss=0.04537, linear_loss=0.05366]
[2020-05-11 21:23:24.094]  Step 145465  [3.368 sec/step, loss=0.09421, avg_loss=0.09411, mel_loss=0.04255, linear_loss=0.05165]
[2020-05-11 21:23:25.794]  Step 145466  [3.371 sec/step, loss=0.09107, avg_loss=0.09413, mel_loss=0.04084, linear_loss=0.05024]
[2020-05-11 21:23:25.878]  Generated 32 batches of size 32 in 1.779 sec
[2020-05-11 21:23:28.519]  Step 145467  [3.387 sec/step, loss=0.09694, avg_loss=0.09423, mel_loss=0.04406, linear_loss=0.05287]
[2020-05-11 21:23:32.172]  Step 145468  [3.371 sec/step, loss=0.10089, avg_loss=0.09422, mel_loss=0.04634, linear_loss=0.05455]
[2020-05-11 21:23:34.588]  Step 145469  [3.382 sec/step, loss=0.09606, avg_loss=0.09427, mel_loss=0.04329, linear_loss=0.05277]
[2020-05-11 21:23:35.415]  Step 145470  [3.372 sec/step, loss=0.07757, avg_loss=0.09411, mel_loss=0.03424, linear_loss=0.04333]
[2020-05-11 21:23:36.250]  Step 145471  [3.370 sec/step, loss=0.08349, avg_loss=0.09404, mel_loss=0.03682, linear_loss=0.04667]
[2020-05-11 21:23:37.708]  Step 145472  [3.257 sec/step, loss=0.08974, avg_loss=0.09406, mel_loss=0.04031, linear_loss=0.04943]
[2020-05-11 21:23:38.665]  Step 145473  [3.259 sec/step, loss=0.08345, avg_loss=0.09409, mel_loss=0.03679, linear_loss=0.04666]
[2020-05-11 21:23:42.651]  Step 145474  [3.257 sec/step, loss=0.10208, avg_loss=0.09409, mel_loss=0.04714, linear_loss=0.05494]
[2020-05-11 21:23:43.287]  Step 145475  [3.228 sec/step, loss=0.08422, avg_loss=0.09392, mel_loss=0.03793, linear_loss=0.04629]
[2020-05-11 21:23:46.720]  Step 145476  [3.213 sec/step, loss=0.10007, avg_loss=0.09390, mel_loss=0.04580, linear_loss=0.05427]
[2020-05-11 21:23:54.029]  Step 145477  [3.255 sec/step, loss=0.10366, avg_loss=0.09395, mel_loss=0.04867, linear_loss=0.05499]
[2020-05-11 21:23:55.784]  Step 145478  [3.243 sec/step, loss=0.09478, avg_loss=0.09390, mel_loss=0.04224, linear_loss=0.05254]
[2020-05-11 21:23:58.213]  Step 145479  [3.244 sec/step, loss=0.09532, avg_loss=0.09388, mel_loss=0.04314, linear_loss=0.05218]
[2020-05-11 21:23:59.512]  Step 145480  [3.231 sec/step, loss=0.09033, avg_loss=0.09381, mel_loss=0.04017, linear_loss=0.05016]
[2020-05-11 21:24:02.889]  Step 145481  [3.247 sec/step, loss=0.09986, avg_loss=0.09389, mel_loss=0.04584, linear_loss=0.05402]
[2020-05-11 21:24:03.889]  Step 145482  [3.222 sec/step, loss=0.08684, avg_loss=0.09377, mel_loss=0.03841, linear_loss=0.04843]
[2020-05-11 21:24:08.554]  Step 145483  [3.225 sec/step, loss=0.09964, avg_loss=0.09379, mel_loss=0.04647, linear_loss=0.05317]
[2020-05-11 21:24:13.753]  Step 145484  [3.254 sec/step, loss=0.10311, avg_loss=0.09386, mel_loss=0.04779, linear_loss=0.05532]
[2020-05-11 21:24:15.108]  Step 145485  [3.252 sec/step, loss=0.09180, avg_loss=0.09387, mel_loss=0.04070, linear_loss=0.05110]
[2020-05-11 21:24:23.395]  Step 145486  [3.301 sec/step, loss=0.09921, avg_loss=0.09387, mel_loss=0.04682, linear_loss=0.05239]
[2020-05-11 21:24:27.785]  Step 145487  [3.294 sec/step, loss=0.10309, avg_loss=0.09388, mel_loss=0.04779, linear_loss=0.05530]
[2020-05-11 21:24:29.791]  Step 145488  [3.304 sec/step, loss=0.09445, avg_loss=0.09399, mel_loss=0.04264, linear_loss=0.05181]
[2020-05-11 21:24:32.431]  Step 145489  [3.302 sec/step, loss=0.09494, avg_loss=0.09397, mel_loss=0.04283, linear_loss=0.05211]
[2020-05-11 21:24:35.237]  Step 145490  [3.296 sec/step, loss=0.09687, avg_loss=0.09396, mel_loss=0.04406, linear_loss=0.05281]
[2020-05-11 21:24:36.708]  Step 145491  [3.297 sec/step, loss=0.09170, avg_loss=0.09400, mel_loss=0.04091, linear_loss=0.05079]
[2020-05-11 21:24:39.986]  Step 145492  [3.322 sec/step, loss=0.09976, avg_loss=0.09423, mel_loss=0.04567, linear_loss=0.05410]
[2020-05-11 21:24:43.651]  Step 145493  [3.292 sec/step, loss=0.10180, avg_loss=0.09425, mel_loss=0.04665, linear_loss=0.05515]
[2020-05-11 21:24:47.822]  Step 145494  [3.317 sec/step, loss=0.10042, avg_loss=0.09433, mel_loss=0.04622, linear_loss=0.05420]
[2020-05-11 21:24:53.568]  Step 145495  [3.328 sec/step, loss=0.10219, avg_loss=0.09434, mel_loss=0.04759, linear_loss=0.05460]
[2020-05-11 21:24:55.358]  Step 145496  [3.331 sec/step, loss=0.09472, avg_loss=0.09439, mel_loss=0.04256, linear_loss=0.05216]
[2020-05-11 21:25:09.480]  Step 145497  [3.448 sec/step, loss=0.07721, avg_loss=0.09422, mel_loss=0.03709, linear_loss=0.04011]
[2020-05-11 21:25:10.067]  Step 145498  [3.437 sec/step, loss=0.07341, avg_loss=0.09402, mel_loss=0.03302, linear_loss=0.04038]
[2020-05-11 21:25:11.196]  Generated 32 batches of size 32 in 1.711 sec
[2020-05-11 21:25:16.287]  Step 145499  [3.411 sec/step, loss=0.10034, avg_loss=0.09402, mel_loss=0.04695, linear_loss=0.05339]
[2020-05-11 21:25:17.330]  Step 145500  [3.347 sec/step, loss=0.08614, avg_loss=0.09386, mel_loss=0.03837, linear_loss=0.04777]
[2020-05-11 21:25:17.330]  Writing summary at step: 145500
[2020-05-11 21:25:18.492]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145500
[2020-05-11 21:25:19.857]  Saving audio and alignment...
[2020-05-11 21:25:23.167]  Input: 문제 해결이 아주 쉬워진다는 것입니다~
[2020-05-11 21:25:25.347]  Step 145501  [3.344 sec/step, loss=0.09464, avg_loss=0.09383, mel_loss=0.04281, linear_loss=0.05184]
[2020-05-11 21:25:27.462]  Step 145502  [3.354 sec/step, loss=0.09513, avg_loss=0.09391, mel_loss=0.04282, linear_loss=0.05231]
[2020-05-11 21:25:28.260]  Step 145503  [3.333 sec/step, loss=0.08060, avg_loss=0.09372, mel_loss=0.03536, linear_loss=0.04523]
[2020-05-11 21:25:31.211]  Step 145504  [3.342 sec/step, loss=0.09954, avg_loss=0.09379, mel_loss=0.04520, linear_loss=0.05434]
[2020-05-11 21:25:40.063]  Step 145505  [3.422 sec/step, loss=0.10281, avg_loss=0.09402, mel_loss=0.04872, linear_loss=0.05409]
[2020-05-11 21:25:42.061]  Step 145506  [3.311 sec/step, loss=0.09197, avg_loss=0.09410, mel_loss=0.04120, linear_loss=0.05077]
[2020-05-11 21:25:48.875]  Step 145507  [3.323 sec/step, loss=0.10027, avg_loss=0.09409, mel_loss=0.04659, linear_loss=0.05368]
[2020-05-11 21:25:50.875]  Step 145508  [3.329 sec/step, loss=0.08544, avg_loss=0.09404, mel_loss=0.03801, linear_loss=0.04743]
[2020-05-11 21:25:58.861]  Step 145509  [3.389 sec/step, loss=0.09925, avg_loss=0.09408, mel_loss=0.04588, linear_loss=0.05337]
[2020-05-11 21:26:03.908]  Step 145510  [3.434 sec/step, loss=0.10115, avg_loss=0.09433, mel_loss=0.04644, linear_loss=0.05470]
[2020-05-11 21:26:06.538]  Step 145511  [3.449 sec/step, loss=0.09585, avg_loss=0.09440, mel_loss=0.04325, linear_loss=0.05260]
[2020-05-11 21:26:09.285]  Step 145512  [3.455 sec/step, loss=0.09632, avg_loss=0.09440, mel_loss=0.04386, linear_loss=0.05246]
[2020-05-11 21:26:11.698]  Step 145513  [3.461 sec/step, loss=0.09369, avg_loss=0.09442, mel_loss=0.04265, linear_loss=0.05104]
[2020-05-11 21:26:15.862]  Step 145514  [3.466 sec/step, loss=0.10042, avg_loss=0.09442, mel_loss=0.04600, linear_loss=0.05442]
[2020-05-11 21:26:16.700]  Step 145515  [3.443 sec/step, loss=0.07997, avg_loss=0.09420, mel_loss=0.03560, linear_loss=0.04438]
[2020-05-11 21:26:24.423]  Step 145516  [3.488 sec/step, loss=0.10162, avg_loss=0.09422, mel_loss=0.04760, linear_loss=0.05402]
[2020-05-11 21:26:25.313]  Step 145517  [3.489 sec/step, loss=0.08128, avg_loss=0.09415, mel_loss=0.03576, linear_loss=0.04551]
[2020-05-11 21:26:38.696]  Step 145518  [3.550 sec/step, loss=0.08674, avg_loss=0.09403, mel_loss=0.04167, linear_loss=0.04507]
[2020-05-11 21:26:40.803]  Step 145519  [3.515 sec/step, loss=0.09402, avg_loss=0.09395, mel_loss=0.04205, linear_loss=0.05197]
[2020-05-11 21:26:47.711]  Step 145520  [3.540 sec/step, loss=0.10055, avg_loss=0.09394, mel_loss=0.04720, linear_loss=0.05335]
[2020-05-11 21:26:51.143]  Step 145521  [3.563 sec/step, loss=0.09843, avg_loss=0.09402, mel_loss=0.04511, linear_loss=0.05332]
[2020-05-11 21:26:54.172]  Step 145522  [3.582 sec/step, loss=0.09893, avg_loss=0.09411, mel_loss=0.04507, linear_loss=0.05386]
[2020-05-11 21:26:58.772]  Step 145523  [3.620 sec/step, loss=0.10090, avg_loss=0.09433, mel_loss=0.04628, linear_loss=0.05461]
[2020-05-11 21:27:00.575]  Step 145524  [3.621 sec/step, loss=0.09341, avg_loss=0.09432, mel_loss=0.04174, linear_loss=0.05168]
[2020-05-11 21:27:02.043]  Step 145525  [3.596 sec/step, loss=0.08983, avg_loss=0.09422, mel_loss=0.04018, linear_loss=0.04965]
[2020-05-11 21:27:02.578]  Step 145526  [3.585 sec/step, loss=0.07594, avg_loss=0.09404, mel_loss=0.03419, linear_loss=0.04175]
[2020-05-11 21:27:03.906]  Step 145527  [3.584 sec/step, loss=0.09151, avg_loss=0.09407, mel_loss=0.04114, linear_loss=0.05037]
[2020-05-11 21:27:05.629]  Step 145528  [3.453 sec/step, loss=0.09251, avg_loss=0.09419, mel_loss=0.04119, linear_loss=0.05132]
[2020-05-11 21:27:05.657]  Generated 32 batches of size 32 in 1.746 sec
[2020-05-11 21:27:07.368]  Step 145529  [3.460 sec/step, loss=0.09283, avg_loss=0.09424, mel_loss=0.04149, linear_loss=0.05134]
[2020-05-11 21:27:08.418]  Step 145530  [3.384 sec/step, loss=0.08698, avg_loss=0.09411, mel_loss=0.03825, linear_loss=0.04873]
[2020-05-11 21:27:09.390]  Step 145531  [3.386 sec/step, loss=0.08566, avg_loss=0.09414, mel_loss=0.03776, linear_loss=0.04790]
[2020-05-11 21:27:12.752]  Step 145532  [3.399 sec/step, loss=0.10182, avg_loss=0.09422, mel_loss=0.04668, linear_loss=0.05514]
[2020-05-11 21:27:16.892]  Step 145533  [3.416 sec/step, loss=0.09993, avg_loss=0.09426, mel_loss=0.04591, linear_loss=0.05402]
[2020-05-11 21:27:19.774]  Step 145534  [3.399 sec/step, loss=0.09689, avg_loss=0.09422, mel_loss=0.04426, linear_loss=0.05263]
[2020-05-11 21:27:20.565]  Step 145535  [3.392 sec/step, loss=0.08450, avg_loss=0.09416, mel_loss=0.03710, linear_loss=0.04740]
[2020-05-11 21:27:21.705]  Step 145536  [3.396 sec/step, loss=0.08846, avg_loss=0.09421, mel_loss=0.03919, linear_loss=0.04927]
[2020-05-11 21:27:25.747]  Step 145537  [3.412 sec/step, loss=0.10094, avg_loss=0.09426, mel_loss=0.04640, linear_loss=0.05454]
[2020-05-11 21:27:26.857]  Step 145538  [3.404 sec/step, loss=0.08551, avg_loss=0.09416, mel_loss=0.03770, linear_loss=0.04781]
[2020-05-11 21:27:32.931]  Step 145539  [3.405 sec/step, loss=0.10015, avg_loss=0.09413, mel_loss=0.04667, linear_loss=0.05348]
[2020-05-11 21:27:38.194]  Step 145540  [3.424 sec/step, loss=0.10144, avg_loss=0.09416, mel_loss=0.04725, linear_loss=0.05419]
[2020-05-11 21:27:39.003]  Step 145541  [3.380 sec/step, loss=0.08400, avg_loss=0.09399, mel_loss=0.03750, linear_loss=0.04650]
[2020-05-11 21:27:44.354]  Step 145542  [3.412 sec/step, loss=0.10040, avg_loss=0.09401, mel_loss=0.04682, linear_loss=0.05358]
[2020-05-11 21:27:47.011]  Step 145543  [3.411 sec/step, loss=0.09475, avg_loss=0.09399, mel_loss=0.04270, linear_loss=0.05205]
[2020-05-11 21:27:48.021]  Step 145544  [3.392 sec/step, loss=0.08341, avg_loss=0.09381, mel_loss=0.03674, linear_loss=0.04667]
[2020-05-11 21:27:49.233]  Step 145545  [3.383 sec/step, loss=0.08792, avg_loss=0.09375, mel_loss=0.03860, linear_loss=0.04932]
[2020-05-11 21:27:49.983]  Step 145546  [3.371 sec/step, loss=0.07655, avg_loss=0.09356, mel_loss=0.03465, linear_loss=0.04191]
[2020-05-11 21:28:04.188]  Step 145547  [3.446 sec/step, loss=0.07802, avg_loss=0.09333, mel_loss=0.03794, linear_loss=0.04008]
[2020-05-11 21:28:06.114]  Step 145548  [3.414 sec/step, loss=0.09460, avg_loss=0.09327, mel_loss=0.04198, linear_loss=0.05262]
[2020-05-11 21:28:10.316]  Step 145549  [3.442 sec/step, loss=0.09900, avg_loss=0.09332, mel_loss=0.04546, linear_loss=0.05354]
[2020-05-11 21:28:12.511]  Step 145550  [3.430 sec/step, loss=0.09451, avg_loss=0.09329, mel_loss=0.04274, linear_loss=0.05177]
[2020-05-11 21:28:12.511]  Writing summary at step: 145550
[2020-05-11 21:28:14.500]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145550
[2020-05-11 21:28:15.855]  Saving audio and alignment...
[2020-05-11 21:28:25.581]  Input: 한국인들의 특징은요 첫음이 굉장히 낮고 좀 어두운 흉성을 자주 쓴다는 것입니다~_________________________________________________
[2020-05-11 21:28:27.630]  Step 145551  [3.432 sec/step, loss=0.09350, avg_loss=0.09330, mel_loss=0.04220, linear_loss=0.05130]
[2020-05-11 21:28:29.206]  Step 145552  [3.310 sec/step, loss=0.09163, avg_loss=0.09342, mel_loss=0.04086, linear_loss=0.05077]
[2020-05-11 21:28:31.611]  Step 145553  [3.328 sec/step, loss=0.09532, avg_loss=0.09365, mel_loss=0.04308, linear_loss=0.05224]
[2020-05-11 21:28:34.638]  Step 145554  [3.303 sec/step, loss=0.09964, avg_loss=0.09361, mel_loss=0.04537, linear_loss=0.05427]
[2020-05-11 21:28:36.355]  Step 145555  [3.292 sec/step, loss=0.09387, avg_loss=0.09357, mel_loss=0.04176, linear_loss=0.05210]
[2020-05-11 21:28:37.648]  Step 145556  [3.262 sec/step, loss=0.09062, avg_loss=0.09348, mel_loss=0.04017, linear_loss=0.05045]
[2020-05-11 21:28:42.163]  Step 145557  [3.262 sec/step, loss=0.10250, avg_loss=0.09348, mel_loss=0.04728, linear_loss=0.05522]
[2020-05-11 21:28:44.335]  Generated 32 batches of size 32 in 2.166 sec
[2020-05-11 21:28:44.982]  Step 145558  [3.279 sec/step, loss=0.09745, avg_loss=0.09358, mel_loss=0.04409, linear_loss=0.05336]
[2020-05-11 21:28:46.574]  Step 145559  [3.283 sec/step, loss=0.09420, avg_loss=0.09366, mel_loss=0.04248, linear_loss=0.05173]
[2020-05-11 21:28:50.016]  Step 145560  [3.231 sec/step, loss=0.09876, avg_loss=0.09364, mel_loss=0.04530, linear_loss=0.05346]
[2020-05-11 21:28:50.686]  Step 145561  [3.225 sec/step, loss=0.07859, avg_loss=0.09353, mel_loss=0.03514, linear_loss=0.04346]
[2020-05-11 21:28:53.847]  Step 145562  [3.181 sec/step, loss=0.09845, avg_loss=0.09347, mel_loss=0.04504, linear_loss=0.05340]
[2020-05-11 21:29:01.956]  Step 145563  [3.245 sec/step, loss=0.09819, avg_loss=0.09354, mel_loss=0.04626, linear_loss=0.05193]
[2020-05-11 21:29:05.523]  Step 145564  [3.248 sec/step, loss=0.09847, avg_loss=0.09354, mel_loss=0.04510, linear_loss=0.05337]
[2020-05-11 21:29:06.900]  Step 145565  [3.239 sec/step, loss=0.08976, avg_loss=0.09349, mel_loss=0.04028, linear_loss=0.04948]
[2020-05-11 21:29:07.883]  Step 145566  [3.232 sec/step, loss=0.08465, avg_loss=0.09343, mel_loss=0.03746, linear_loss=0.04719]
[2020-05-11 21:29:13.522]  Step 145567  [3.261 sec/step, loss=0.10112, avg_loss=0.09347, mel_loss=0.04686, linear_loss=0.05426]
[2020-05-11 21:29:14.044]  Step 145568  [3.229 sec/step, loss=0.07410, avg_loss=0.09320, mel_loss=0.03386, linear_loss=0.04024]
[2020-05-11 21:29:17.739]  Step 145569  [3.242 sec/step, loss=0.10021, avg_loss=0.09324, mel_loss=0.04596, linear_loss=0.05425]
[2020-05-11 21:29:20.009]  Step 145570  [3.257 sec/step, loss=0.09820, avg_loss=0.09345, mel_loss=0.04459, linear_loss=0.05360]
[2020-05-11 21:29:21.209]  Step 145571  [3.260 sec/step, loss=0.08685, avg_loss=0.09348, mel_loss=0.03871, linear_loss=0.04814]
[2020-05-11 21:29:24.178]  Step 145572  [3.275 sec/step, loss=0.09996, avg_loss=0.09358, mel_loss=0.04577, linear_loss=0.05419]
[2020-05-11 21:29:25.202]  Step 145573  [3.276 sec/step, loss=0.08661, avg_loss=0.09362, mel_loss=0.03840, linear_loss=0.04821]
[2020-05-11 21:29:26.688]  Step 145574  [3.251 sec/step, loss=0.09321, avg_loss=0.09353, mel_loss=0.04135, linear_loss=0.05185]
[2020-05-11 21:29:27.801]  Step 145575  [3.256 sec/step, loss=0.08977, avg_loss=0.09358, mel_loss=0.03940, linear_loss=0.05036]
[2020-05-11 21:29:29.614]  Step 145576  [3.240 sec/step, loss=0.09222, avg_loss=0.09350, mel_loss=0.04131, linear_loss=0.05091]
[2020-05-11 21:29:30.970]  Step 145577  [3.180 sec/step, loss=0.09110, avg_loss=0.09338, mel_loss=0.04041, linear_loss=0.05069]
[2020-05-11 21:29:36.148]  Step 145578  [3.214 sec/step, loss=0.10008, avg_loss=0.09343, mel_loss=0.04654, linear_loss=0.05354]
[2020-05-11 21:29:40.512]  Step 145579  [3.234 sec/step, loss=0.10153, avg_loss=0.09349, mel_loss=0.04698, linear_loss=0.05454]
[2020-05-11 21:29:41.311]  Step 145580  [3.229 sec/step, loss=0.07977, avg_loss=0.09339, mel_loss=0.03545, linear_loss=0.04432]
[2020-05-11 21:29:45.902]  Step 145581  [3.241 sec/step, loss=0.10065, avg_loss=0.09340, mel_loss=0.04640, linear_loss=0.05425]
[2020-05-11 21:29:49.869]  Step 145582  [3.270 sec/step, loss=0.09952, avg_loss=0.09352, mel_loss=0.04588, linear_loss=0.05364]
[2020-05-11 21:30:03.033]  Step 145583  [3.355 sec/step, loss=0.08573, avg_loss=0.09338, mel_loss=0.04112, linear_loss=0.04462]
[2020-05-11 21:30:06.506]  Step 145584  [3.338 sec/step, loss=0.09997, avg_loss=0.09335, mel_loss=0.04579, linear_loss=0.05417]
[2020-05-11 21:30:08.570]  Step 145585  [3.345 sec/step, loss=0.09658, avg_loss=0.09340, mel_loss=0.04363, linear_loss=0.05296]
[2020-05-11 21:30:11.116]  Step 145586  [3.288 sec/step, loss=0.09562, avg_loss=0.09336, mel_loss=0.04349, linear_loss=0.05214]
[2020-05-11 21:30:14.197]  Step 145587  [3.275 sec/step, loss=0.10201, avg_loss=0.09335, mel_loss=0.04666, linear_loss=0.05536]
[2020-05-11 21:30:17.026]  Step 145588  [3.283 sec/step, loss=0.09711, avg_loss=0.09338, mel_loss=0.04418, linear_loss=0.05294]
[2020-05-11 21:30:18.683]  Step 145589  [3.273 sec/step, loss=0.09345, avg_loss=0.09337, mel_loss=0.04191, linear_loss=0.05154]
[2020-05-11 21:30:20.178]  Step 145590  [3.260 sec/step, loss=0.09098, avg_loss=0.09331, mel_loss=0.04076, linear_loss=0.05022]
[2020-05-11 21:30:20.604]  Generated 32 batches of size 32 in 1.915 sec
[2020-05-11 21:30:22.409]  Step 145591  [3.268 sec/step, loss=0.09874, avg_loss=0.09338, mel_loss=0.04469, linear_loss=0.05405]
[2020-05-11 21:30:24.337]  Step 145592  [3.254 sec/step, loss=0.09413, avg_loss=0.09332, mel_loss=0.04233, linear_loss=0.05180]
[2020-05-11 21:30:25.080]  Step 145593  [3.225 sec/step, loss=0.07881, avg_loss=0.09309, mel_loss=0.03473, linear_loss=0.04408]
[2020-05-11 21:30:33.769]  Step 145594  [3.270 sec/step, loss=0.10249, avg_loss=0.09311, mel_loss=0.04868, linear_loss=0.05382]
[2020-05-11 21:30:40.462]  Step 145595  [3.280 sec/step, loss=0.10332, avg_loss=0.09312, mel_loss=0.04872, linear_loss=0.05460]
[2020-05-11 21:30:47.875]  Step 145596  [3.336 sec/step, loss=0.10270, avg_loss=0.09320, mel_loss=0.04832, linear_loss=0.05438]
[2020-05-11 21:30:48.872]  Step 145597  [3.205 sec/step, loss=0.08321, avg_loss=0.09326, mel_loss=0.03668, linear_loss=0.04652]
[2020-05-11 21:30:52.270]  Step 145598  [3.233 sec/step, loss=0.10005, avg_loss=0.09353, mel_loss=0.04596, linear_loss=0.05410]
[2020-05-11 21:30:53.392]  Step 145599  [3.182 sec/step, loss=0.08793, avg_loss=0.09340, mel_loss=0.03871, linear_loss=0.04922]
[2020-05-11 21:30:56.537]  Step 145600  [3.203 sec/step, loss=0.09966, avg_loss=0.09354, mel_loss=0.04541, linear_loss=0.05425]
[2020-05-11 21:30:56.537]  Writing summary at step: 145600
[2020-05-11 21:31:10.607]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145600
[2020-05-11 21:31:11.946]  Saving audio and alignment...
[2020-05-11 21:31:14.379]  Input: 서 저도 시험장에서~______________
[2020-05-11 21:31:17.993]  Step 145601  [3.217 sec/step, loss=0.09753, avg_loss=0.09357, mel_loss=0.04463, linear_loss=0.05290]
[2020-05-11 21:31:20.676]  Step 145602  [3.223 sec/step, loss=0.09482, avg_loss=0.09357, mel_loss=0.04286, linear_loss=0.05196]
[2020-05-11 21:31:25.040]  Step 145603  [3.258 sec/step, loss=0.10025, avg_loss=0.09376, mel_loss=0.04614, linear_loss=0.05411]
[2020-05-11 21:31:26.439]  Step 145604  [3.243 sec/step, loss=0.08991, avg_loss=0.09367, mel_loss=0.04006, linear_loss=0.04985]
[2020-05-11 21:31:27.614]  Step 145605  [3.166 sec/step, loss=0.08942, avg_loss=0.09353, mel_loss=0.03978, linear_loss=0.04964]
[2020-05-11 21:31:29.128]  Step 145606  [3.161 sec/step, loss=0.09194, avg_loss=0.09353, mel_loss=0.04144, linear_loss=0.05050]
[2020-05-11 21:31:35.205]  Step 145607  [3.154 sec/step, loss=0.10101, avg_loss=0.09354, mel_loss=0.04722, linear_loss=0.05378]
[2020-05-11 21:31:38.583]  Step 145608  [3.168 sec/step, loss=0.09889, avg_loss=0.09367, mel_loss=0.04531, linear_loss=0.05357]
[2020-05-11 21:31:40.470]  Step 145609  [3.107 sec/step, loss=0.09100, avg_loss=0.09359, mel_loss=0.04049, linear_loss=0.05052]
[2020-05-11 21:31:44.471]  Step 145610  [3.096 sec/step, loss=0.10129, avg_loss=0.09359, mel_loss=0.04654, linear_loss=0.05476]
[2020-05-11 21:31:45.492]  Step 145611  [3.080 sec/step, loss=0.08400, avg_loss=0.09347, mel_loss=0.03731, linear_loss=0.04669]
[2020-05-11 21:31:47.625]  Step 145612  [3.074 sec/step, loss=0.09427, avg_loss=0.09345, mel_loss=0.04243, linear_loss=0.05183]
[2020-05-11 21:31:50.468]  Step 145613  [3.078 sec/step, loss=0.09768, avg_loss=0.09349, mel_loss=0.04449, linear_loss=0.05318]
[2020-05-11 21:31:51.267]  Step 145614  [3.045 sec/step, loss=0.08299, avg_loss=0.09332, mel_loss=0.03667, linear_loss=0.04632]
[2020-05-11 21:32:00.002]  Step 145615  [3.124 sec/step, loss=0.09872, avg_loss=0.09351, mel_loss=0.04651, linear_loss=0.05221]
[2020-05-11 21:32:05.540]  Step 145616  [3.102 sec/step, loss=0.10043, avg_loss=0.09349, mel_loss=0.04683, linear_loss=0.05360]
[2020-05-11 21:32:07.286]  Step 145617  [3.110 sec/step, loss=0.09407, avg_loss=0.09362, mel_loss=0.04202, linear_loss=0.05205]
[2020-05-11 21:32:12.475]  Step 145618  [3.028 sec/step, loss=0.09997, avg_loss=0.09376, mel_loss=0.04635, linear_loss=0.05362]
[2020-05-11 21:32:14.079]  Step 145619  [3.023 sec/step, loss=0.09459, avg_loss=0.09376, mel_loss=0.04235, linear_loss=0.05224]
[2020-05-11 21:32:15.713]  Generated 32 batches of size 32 in 1.629 sec
[2020-05-11 21:32:21.484]  Step 145620  [3.028 sec/step, loss=0.10172, avg_loss=0.09377, mel_loss=0.04797, linear_loss=0.05375]
[2020-05-11 21:32:23.810]  Step 145621  [3.017 sec/step, loss=0.09668, avg_loss=0.09375, mel_loss=0.04392, linear_loss=0.05276]
[2020-05-11 21:32:28.427]  Step 145622  [3.033 sec/step, loss=0.09978, avg_loss=0.09376, mel_loss=0.04612, linear_loss=0.05366]
[2020-05-11 21:32:29.176]  Step 145623  [2.995 sec/step, loss=0.07742, avg_loss=0.09353, mel_loss=0.03450, linear_loss=0.04291]
[2020-05-11 21:32:32.751]  Step 145624  [3.012 sec/step, loss=0.10116, avg_loss=0.09361, mel_loss=0.04634, linear_loss=0.05482]
[2020-05-11 21:32:35.367]  Step 145625  [3.024 sec/step, loss=0.09595, avg_loss=0.09367, mel_loss=0.04374, linear_loss=0.05221]
[2020-05-11 21:32:36.351]  Step 145626  [3.028 sec/step, loss=0.08427, avg_loss=0.09375, mel_loss=0.03692, linear_loss=0.04735]
[2020-05-11 21:32:36.909]  Step 145627  [3.021 sec/step, loss=0.07340, avg_loss=0.09357, mel_loss=0.03327, linear_loss=0.04014]
[2020-05-11 21:32:38.884]  Step 145628  [3.023 sec/step, loss=0.09611, avg_loss=0.09361, mel_loss=0.04335, linear_loss=0.05276]
[2020-05-11 21:32:40.499]  Step 145629  [3.022 sec/step, loss=0.09074, avg_loss=0.09358, mel_loss=0.04075, linear_loss=0.04998]
[2020-05-11 21:32:44.529]  Step 145630  [3.052 sec/step, loss=0.09986, avg_loss=0.09371, mel_loss=0.04600, linear_loss=0.05386]
[2020-05-11 21:32:48.535]  Step 145631  [3.082 sec/step, loss=0.10058, avg_loss=0.09386, mel_loss=0.04623, linear_loss=0.05435]
[2020-05-11 21:32:50.472]  Step 145632  [3.068 sec/step, loss=0.09434, avg_loss=0.09379, mel_loss=0.04244, linear_loss=0.05191]
[2020-05-11 21:32:53.471]  Step 145633  [3.056 sec/step, loss=0.10047, avg_loss=0.09379, mel_loss=0.04593, linear_loss=0.05454]
[2020-05-11 21:32:54.226]  Step 145634  [3.035 sec/step, loss=0.08195, avg_loss=0.09364, mel_loss=0.03620, linear_loss=0.04575]
[2020-05-11 21:32:55.180]  Step 145635  [3.037 sec/step, loss=0.08668, avg_loss=0.09367, mel_loss=0.03828, linear_loss=0.04840]
[2020-05-11 21:32:55.667]  Step 145636  [3.030 sec/step, loss=0.08096, avg_loss=0.09359, mel_loss=0.03553, linear_loss=0.04543]
[2020-05-11 21:32:57.920]  Step 145637  [3.012 sec/step, loss=0.09444, avg_loss=0.09353, mel_loss=0.04287, linear_loss=0.05156]
[2020-05-11 21:33:06.239]  Step 145638  [3.084 sec/step, loss=0.10012, avg_loss=0.09367, mel_loss=0.04743, linear_loss=0.05269]
[2020-05-11 21:33:07.073]  Step 145639  [3.032 sec/step, loss=0.08006, avg_loss=0.09347, mel_loss=0.03583, linear_loss=0.04423]
[2020-05-11 21:33:13.753]  Step 145640  [3.046 sec/step, loss=0.10045, avg_loss=0.09346, mel_loss=0.04691, linear_loss=0.05355]
[2020-05-11 21:33:14.716]  Step 145641  [3.048 sec/step, loss=0.08375, avg_loss=0.09346, mel_loss=0.03658, linear_loss=0.04717]
[2020-05-11 21:33:20.072]  Step 145642  [3.048 sec/step, loss=0.10136, avg_loss=0.09347, mel_loss=0.04713, linear_loss=0.05423]
[2020-05-11 21:33:27.519]  Step 145643  [3.096 sec/step, loss=0.10173, avg_loss=0.09354, mel_loss=0.04765, linear_loss=0.05408]
[2020-05-11 21:33:40.418]  Step 145644  [3.215 sec/step, loss=0.08464, avg_loss=0.09355, mel_loss=0.04055, linear_loss=0.04410]
[2020-05-11 21:33:42.394]  Step 145645  [3.222 sec/step, loss=0.09478, avg_loss=0.09362, mel_loss=0.04275, linear_loss=0.05203]
[2020-05-11 21:33:43.620]  Step 145646  [3.227 sec/step, loss=0.08569, avg_loss=0.09371, mel_loss=0.03783, linear_loss=0.04786]
[2020-05-11 21:33:44.677]  Step 145647  [3.096 sec/step, loss=0.08879, avg_loss=0.09382, mel_loss=0.03909, linear_loss=0.04970]
[2020-05-11 21:33:47.589]  Step 145648  [3.105 sec/step, loss=0.09618, avg_loss=0.09383, mel_loss=0.04367, linear_loss=0.05251]
[2020-05-11 21:33:49.363]  Step 145649  [3.081 sec/step, loss=0.09443, avg_loss=0.09379, mel_loss=0.04218, linear_loss=0.05224]
[2020-05-11 21:33:52.832]  Step 145650  [3.094 sec/step, loss=0.09885, avg_loss=0.09383, mel_loss=0.04510, linear_loss=0.05375]
[2020-05-11 21:33:52.832]  Writing summary at step: 145650
[2020-05-11 21:33:57.446]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145650
[2020-05-11 21:33:58.802]  Saving audio and alignment...
[2020-05-11 21:34:00.794]  Generated 32 batches of size 32 in 1.478 sec
[2020-05-11 21:34:01.823]  Input: 중요하다는 느낌을 줄수있~
[2020-05-11 21:34:04.235]  Step 145651  [3.097 sec/step, loss=0.09715, avg_loss=0.09387, mel_loss=0.04392, linear_loss=0.05323]
[2020-05-11 21:34:06.391]  Step 145652  [3.103 sec/step, loss=0.09630, avg_loss=0.09391, mel_loss=0.04376, linear_loss=0.05254]
[2020-05-11 21:34:08.096]  Step 145653  [3.096 sec/step, loss=0.09171, avg_loss=0.09388, mel_loss=0.04120, linear_loss=0.05051]
[2020-05-11 21:34:10.802]  Step 145654  [3.093 sec/step, loss=0.09776, avg_loss=0.09386, mel_loss=0.04480, linear_loss=0.05295]
[2020-05-11 21:34:14.367]  Step 145655  [3.112 sec/step, loss=0.10157, avg_loss=0.09394, mel_loss=0.04647, linear_loss=0.05510]
[2020-05-11 21:34:19.264]  Step 145656  [3.148 sec/step, loss=0.10081, avg_loss=0.09404, mel_loss=0.04657, linear_loss=0.05424]
[2020-05-11 21:34:22.432]  Step 145657  [3.134 sec/step, loss=0.10318, avg_loss=0.09405, mel_loss=0.04716, linear_loss=0.05602]
[2020-05-11 21:34:23.808]  Step 145658  [3.120 sec/step, loss=0.09156, avg_loss=0.09399, mel_loss=0.04116, linear_loss=0.05040]
[2020-05-11 21:34:27.229]  Step 145659  [3.138 sec/step, loss=0.09711, avg_loss=0.09402, mel_loss=0.04434, linear_loss=0.05277]
[2020-05-11 21:34:36.194]  Step 145660  [3.193 sec/step, loss=0.10056, avg_loss=0.09403, mel_loss=0.04756, linear_loss=0.05300]
[2020-05-11 21:34:50.009]  Step 145661  [3.325 sec/step, loss=0.07934, avg_loss=0.09404, mel_loss=0.03825, linear_loss=0.04110]
[2020-05-11 21:34:51.916]  Step 145662  [3.312 sec/step, loss=0.09350, avg_loss=0.09399, mel_loss=0.04195, linear_loss=0.05155]
[2020-05-11 21:34:55.564]  Step 145663  [3.268 sec/step, loss=0.10081, avg_loss=0.09402, mel_loss=0.04622, linear_loss=0.05460]
[2020-05-11 21:34:56.900]  Step 145664  [3.245 sec/step, loss=0.08897, avg_loss=0.09392, mel_loss=0.03952, linear_loss=0.04946]
[2020-05-11 21:34:59.230]  Step 145665  [3.255 sec/step, loss=0.09512, avg_loss=0.09398, mel_loss=0.04308, linear_loss=0.05204]
[2020-05-11 21:35:00.129]  Step 145666  [3.254 sec/step, loss=0.08425, avg_loss=0.09397, mel_loss=0.03692, linear_loss=0.04732]
[2020-05-11 21:35:01.277]  Step 145667  [3.209 sec/step, loss=0.08867, avg_loss=0.09385, mel_loss=0.03917, linear_loss=0.04949]
[2020-05-11 21:35:06.558]  Step 145668  [3.257 sec/step, loss=0.10114, avg_loss=0.09412, mel_loss=0.04715, linear_loss=0.05400]
[2020-05-11 21:35:08.341]  Step 145669  [3.237 sec/step, loss=0.09290, avg_loss=0.09405, mel_loss=0.04159, linear_loss=0.05131]
[2020-05-11 21:35:09.438]  Step 145670  [3.226 sec/step, loss=0.08654, avg_loss=0.09393, mel_loss=0.03832, linear_loss=0.04823]
[2020-05-11 21:35:11.023]  Step 145671  [3.230 sec/step, loss=0.09058, avg_loss=0.09397, mel_loss=0.04071, linear_loss=0.04987]
[2020-05-11 21:35:14.123]  Step 145672  [3.231 sec/step, loss=0.09917, avg_loss=0.09396, mel_loss=0.04535, linear_loss=0.05381]
[2020-05-11 21:35:16.217]  Step 145673  [3.242 sec/step, loss=0.09574, avg_loss=0.09405, mel_loss=0.04299, linear_loss=0.05276]
[2020-05-11 21:35:20.553]  Step 145674  [3.270 sec/step, loss=0.10179, avg_loss=0.09414, mel_loss=0.04732, linear_loss=0.05447]
[2020-05-11 21:35:25.043]  Step 145675  [3.304 sec/step, loss=0.10193, avg_loss=0.09426, mel_loss=0.04671, linear_loss=0.05522]
[2020-05-11 21:35:30.608]  Step 145676  [3.341 sec/step, loss=0.10230, avg_loss=0.09436, mel_loss=0.04762, linear_loss=0.05469]
[2020-05-11 21:35:36.928]  Step 145677  [3.391 sec/step, loss=0.10150, avg_loss=0.09446, mel_loss=0.04746, linear_loss=0.05404]
[2020-05-11 21:35:37.939]  Step 145678  [3.349 sec/step, loss=0.08408, avg_loss=0.09430, mel_loss=0.03720, linear_loss=0.04687]
[2020-05-11 21:35:40.786]  Step 145679  [3.334 sec/step, loss=0.09874, avg_loss=0.09427, mel_loss=0.04509, linear_loss=0.05365]
[2020-05-11 21:35:41.578]  Step 145680  [3.334 sec/step, loss=0.08068, avg_loss=0.09428, mel_loss=0.03532, linear_loss=0.04536]
[2020-05-11 21:35:43.171]  Step 145681  [3.304 sec/step, loss=0.09447, avg_loss=0.09422, mel_loss=0.04233, linear_loss=0.05214]
[2020-05-11 21:35:44.923]  Generated 32 batches of size 32 in 1.747 sec
[2020-05-11 21:35:45.267]  Step 145682  [3.285 sec/step, loss=0.09519, avg_loss=0.09418, mel_loss=0.04297, linear_loss=0.05223]
[2020-05-11 21:35:46.095]  Step 145683  [3.162 sec/step, loss=0.07880, avg_loss=0.09411, mel_loss=0.03457, linear_loss=0.04423]
[2020-05-11 21:35:53.472]  Step 145684  [3.201 sec/step, loss=0.10134, avg_loss=0.09412, mel_loss=0.04772, linear_loss=0.05362]
[2020-05-11 21:35:56.073]  Step 145685  [3.206 sec/step, loss=0.09530, avg_loss=0.09411, mel_loss=0.04314, linear_loss=0.05215]
[2020-05-11 21:35:56.622]  Step 145686  [3.186 sec/step, loss=0.07323, avg_loss=0.09389, mel_loss=0.03283, linear_loss=0.04040]
[2020-05-11 21:36:00.014]  Step 145687  [3.190 sec/step, loss=0.09755, avg_loss=0.09384, mel_loss=0.04456, linear_loss=0.05299]
[2020-05-11 21:36:04.125]  Step 145688  [3.202 sec/step, loss=0.09947, avg_loss=0.09386, mel_loss=0.04580, linear_loss=0.05367]
[2020-05-11 21:36:06.226]  Step 145689  [3.207 sec/step, loss=0.08996, avg_loss=0.09383, mel_loss=0.04026, linear_loss=0.04970]
[2020-05-11 21:36:09.920]  Step 145690  [3.229 sec/step, loss=0.09593, avg_loss=0.09388, mel_loss=0.04326, linear_loss=0.05267]
[2020-05-11 21:36:17.357]  Step 145691  [3.281 sec/step, loss=0.09874, avg_loss=0.09388, mel_loss=0.04559, linear_loss=0.05315]
[2020-05-11 21:36:31.322]  Step 145692  [3.401 sec/step, loss=0.09024, avg_loss=0.09384, mel_loss=0.04358, linear_loss=0.04666]
[2020-05-11 21:36:35.012]  Step 145693  [3.431 sec/step, loss=0.09789, avg_loss=0.09403, mel_loss=0.04462, linear_loss=0.05327]
[2020-05-11 21:36:39.124]  Step 145694  [3.385 sec/step, loss=0.09773, avg_loss=0.09398, mel_loss=0.04473, linear_loss=0.05300]
[2020-05-11 21:36:40.461]  Step 145695  [3.331 sec/step, loss=0.09010, avg_loss=0.09385, mel_loss=0.04019, linear_loss=0.04991]
[2020-05-11 21:36:41.316]  Step 145696  [3.266 sec/step, loss=0.08745, avg_loss=0.09370, mel_loss=0.03865, linear_loss=0.04880]
[2020-05-11 21:36:43.072]  Step 145697  [3.273 sec/step, loss=0.09385, avg_loss=0.09380, mel_loss=0.04175, linear_loss=0.05210]
[2020-05-11 21:36:45.485]  Step 145698  [3.264 sec/step, loss=0.09550, avg_loss=0.09376, mel_loss=0.04334, linear_loss=0.05217]
[2020-05-11 21:36:47.225]  Step 145699  [3.270 sec/step, loss=0.09134, avg_loss=0.09379, mel_loss=0.04064, linear_loss=0.05070]
[2020-05-11 21:36:50.092]  Step 145700  [3.267 sec/step, loss=0.09940, avg_loss=0.09379, mel_loss=0.04513, linear_loss=0.05427]
[2020-05-11 21:36:50.092]  Writing summary at step: 145700
[2020-05-11 21:36:51.122]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145700
[2020-05-11 21:36:52.436]  Saving audio and alignment...
[2020-05-11 21:36:54.577]  Input: 빨리이 가 주시는데~________
[2020-05-11 21:36:57.530]  Step 145701  [3.260 sec/step, loss=0.09959, avg_loss=0.09381, mel_loss=0.04553, linear_loss=0.05406]
[2020-05-11 21:36:58.334]  Step 145702  [3.242 sec/step, loss=0.08370, avg_loss=0.09370, mel_loss=0.03696, linear_loss=0.04674]
[2020-05-11 21:37:01.999]  Step 145703  [3.235 sec/step, loss=0.10146, avg_loss=0.09371, mel_loss=0.04654, linear_loss=0.05492]
[2020-05-11 21:37:04.007]  Step 145704  [3.241 sec/step, loss=0.09414, avg_loss=0.09375, mel_loss=0.04214, linear_loss=0.05200]
[2020-05-11 21:37:09.807]  Step 145705  [3.287 sec/step, loss=0.10209, avg_loss=0.09388, mel_loss=0.04767, linear_loss=0.05443]
[2020-05-11 21:37:12.054]  Step 145706  [3.294 sec/step, loss=0.09161, avg_loss=0.09388, mel_loss=0.04143, linear_loss=0.05018]
[2020-05-11 21:37:12.816]  Step 145707  [3.241 sec/step, loss=0.07612, avg_loss=0.09363, mel_loss=0.03434, linear_loss=0.04178]
[2020-05-11 21:37:15.423]  Step 145708  [3.233 sec/step, loss=0.09708, avg_loss=0.09361, mel_loss=0.04425, linear_loss=0.05283]
[2020-05-11 21:37:22.239]  Step 145709  [3.283 sec/step, loss=0.10195, avg_loss=0.09372, mel_loss=0.04775, linear_loss=0.05420]
[2020-05-11 21:37:23.553]  Step 145710  [3.256 sec/step, loss=0.08770, avg_loss=0.09358, mel_loss=0.03913, linear_loss=0.04857]
[2020-05-11 21:37:31.200]  Step 145711  [3.322 sec/step, loss=0.10295, avg_loss=0.09377, mel_loss=0.04828, linear_loss=0.05467]
[2020-05-11 21:37:32.983]  Generated 32 batches of size 32 in 1.778 sec
[2020-05-11 21:37:33.755]  Step 145712  [3.326 sec/step, loss=0.09526, avg_loss=0.09378, mel_loss=0.04274, linear_loss=0.05251]
[2020-05-11 21:37:38.982]  Step 145713  [3.350 sec/step, loss=0.10205, avg_loss=0.09383, mel_loss=0.04750, linear_loss=0.05455]
[2020-05-11 21:37:40.578]  Step 145714  [3.358 sec/step, loss=0.09127, avg_loss=0.09391, mel_loss=0.04109, linear_loss=0.05018]
[2020-05-11 21:37:44.978]  Step 145715  [3.315 sec/step, loss=0.09962, avg_loss=0.09392, mel_loss=0.04609, linear_loss=0.05354]
[2020-05-11 21:37:48.178]  Step 145716  [3.291 sec/step, loss=0.10015, avg_loss=0.09392, mel_loss=0.04590, linear_loss=0.05426]
[2020-05-11 21:37:49.667]  Step 145717  [3.289 sec/step, loss=0.09140, avg_loss=0.09389, mel_loss=0.04084, linear_loss=0.05056]
[2020-05-11 21:37:50.328]  Step 145718  [3.244 sec/step, loss=0.07990, avg_loss=0.09369, mel_loss=0.03616, linear_loss=0.04373]
[2020-05-11 21:37:52.252]  Step 145719  [3.247 sec/step, loss=0.09357, avg_loss=0.09368, mel_loss=0.04160, linear_loss=0.05196]
[2020-05-11 21:38:00.704]  Step 145720  [3.257 sec/step, loss=0.10081, avg_loss=0.09367, mel_loss=0.04764, linear_loss=0.05317]
[2020-05-11 21:38:02.747]  Step 145721  [3.254 sec/step, loss=0.09396, avg_loss=0.09364, mel_loss=0.04219, linear_loss=0.05178]
[2020-05-11 21:38:03.639]  Step 145722  [3.217 sec/step, loss=0.08468, avg_loss=0.09349, mel_loss=0.03689, linear_loss=0.04778]
[2020-05-11 21:38:04.733]  Step 145723  [3.221 sec/step, loss=0.08699, avg_loss=0.09359, mel_loss=0.03836, linear_loss=0.04863]
[2020-05-11 21:38:10.194]  Step 145724  [3.239 sec/step, loss=0.10071, avg_loss=0.09358, mel_loss=0.04680, linear_loss=0.05392]
[2020-05-11 21:38:11.407]  Step 145725  [3.225 sec/step, loss=0.08590, avg_loss=0.09348, mel_loss=0.03842, linear_loss=0.04749]
[2020-05-11 21:38:12.857]  Step 145726  [3.230 sec/step, loss=0.08730, avg_loss=0.09351, mel_loss=0.03901, linear_loss=0.04828]
[2020-05-11 21:38:16.373]  Step 145727  [3.260 sec/step, loss=0.09792, avg_loss=0.09376, mel_loss=0.04473, linear_loss=0.05319]
[2020-05-11 21:38:20.763]  Step 145728  [3.284 sec/step, loss=0.10028, avg_loss=0.09380, mel_loss=0.04622, linear_loss=0.05406]
[2020-05-11 21:38:22.084]  Step 145729  [3.281 sec/step, loss=0.09050, avg_loss=0.09380, mel_loss=0.03979, linear_loss=0.05072]
[2020-05-11 21:38:23.812]  Step 145730  [3.258 sec/step, loss=0.09460, avg_loss=0.09374, mel_loss=0.04214, linear_loss=0.05246]
[2020-05-11 21:38:26.214]  Step 145731  [3.242 sec/step, loss=0.09469, avg_loss=0.09369, mel_loss=0.04240, linear_loss=0.05229]
[2020-05-11 21:38:27.008]  Step 145732  [3.230 sec/step, loss=0.08118, avg_loss=0.09355, mel_loss=0.03549, linear_loss=0.04568]
[2020-05-11 21:38:30.105]  Step 145733  [3.231 sec/step, loss=0.10080, avg_loss=0.09356, mel_loss=0.04603, linear_loss=0.05477]
[2020-05-11 21:38:31.781]  Step 145734  [3.241 sec/step, loss=0.09188, avg_loss=0.09366, mel_loss=0.04088, linear_loss=0.05100]
[2020-05-11 21:38:32.336]  Step 145735  [3.237 sec/step, loss=0.07495, avg_loss=0.09354, mel_loss=0.03371, linear_loss=0.04125]
[2020-05-11 21:38:33.078]  Step 145736  [3.239 sec/step, loss=0.07730, avg_loss=0.09350, mel_loss=0.03484, linear_loss=0.04246]
[2020-05-11 21:38:41.829]  Step 145737  [3.304 sec/step, loss=0.10000, avg_loss=0.09356, mel_loss=0.04722, linear_loss=0.05277]
[2020-05-11 21:38:44.671]  Step 145738  [3.249 sec/step, loss=0.09909, avg_loss=0.09355, mel_loss=0.04500, linear_loss=0.05409]
[2020-05-11 21:38:48.698]  Step 145739  [3.281 sec/step, loss=0.09930, avg_loss=0.09374, mel_loss=0.04534, linear_loss=0.05396]
[2020-05-11 21:38:51.431]  Step 145740  [3.242 sec/step, loss=0.09719, avg_loss=0.09371, mel_loss=0.04422, linear_loss=0.05297]
[2020-05-11 21:38:57.938]  Step 145741  [3.297 sec/step, loss=0.09935, avg_loss=0.09386, mel_loss=0.04607, linear_loss=0.05329]
[2020-05-11 21:39:01.401]  Step 145742  [3.278 sec/step, loss=0.09733, avg_loss=0.09382, mel_loss=0.04454, linear_loss=0.05279]
[2020-05-11 21:39:02.995]  Step 145743  [3.220 sec/step, loss=0.09239, avg_loss=0.09373, mel_loss=0.04134, linear_loss=0.05105]
[2020-05-11 21:39:04.736]  Generated 32 batches of size 32 in 1.736 sec
[2020-05-11 21:39:06.697]  Step 145744  [3.128 sec/step, loss=0.09899, avg_loss=0.09387, mel_loss=0.04529, linear_loss=0.05370]
[2020-05-11 21:39:08.637]  Step 145745  [3.127 sec/step, loss=0.09192, avg_loss=0.09385, mel_loss=0.04125, linear_loss=0.05067]
[2020-05-11 21:39:22.967]  Step 145746  [3.258 sec/step, loss=0.07731, avg_loss=0.09376, mel_loss=0.03718, linear_loss=0.04013]
[2020-05-11 21:39:28.085]  Step 145747  [3.299 sec/step, loss=0.09990, avg_loss=0.09387, mel_loss=0.04616, linear_loss=0.05374]
[2020-05-11 21:39:30.184]  Step 145748  [3.291 sec/step, loss=0.09576, avg_loss=0.09387, mel_loss=0.04314, linear_loss=0.05262]
[2020-05-11 21:39:32.401]  Step 145749  [3.295 sec/step, loss=0.09636, avg_loss=0.09389, mel_loss=0.04381, linear_loss=0.05255]
[2020-05-11 21:39:39.450]  Step 145750  [3.331 sec/step, loss=0.09945, avg_loss=0.09389, mel_loss=0.04650, linear_loss=0.05295]
[2020-05-11 21:39:39.450]  Writing summary at step: 145750
[2020-05-11 21:39:40.462]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145750
[2020-05-11 21:39:41.786]  Saving audio and alignment...
[2020-05-11 21:39:48.655]  Input: 경제학과 나왔는데 한두 명 뽑는 아나운서 자리에 오늘처럼 이천 명씩 몰리는거~_______
[2020-05-11 21:39:50.632]  Step 145751  [3.327 sec/step, loss=0.09390, avg_loss=0.09386, mel_loss=0.04221, linear_loss=0.05169]
[2020-05-11 21:39:54.261]  Step 145752  [3.342 sec/step, loss=0.10119, avg_loss=0.09391, mel_loss=0.04638, linear_loss=0.05480]
[2020-05-11 21:39:57.289]  Step 145753  [3.355 sec/step, loss=0.09851, avg_loss=0.09398, mel_loss=0.04498, linear_loss=0.05353]
[2020-05-11 21:40:01.426]  Step 145754  [3.369 sec/step, loss=0.10191, avg_loss=0.09402, mel_loss=0.04712, linear_loss=0.05479]
[2020-05-11 21:40:02.479]  Step 145755  [3.344 sec/step, loss=0.08812, avg_loss=0.09389, mel_loss=0.03917, linear_loss=0.04895]
[2020-05-11 21:40:07.132]  Step 145756  [3.342 sec/step, loss=0.10096, avg_loss=0.09389, mel_loss=0.04641, linear_loss=0.05455]
[2020-05-11 21:40:09.494]  Step 145757  [3.333 sec/step, loss=0.09721, avg_loss=0.09383, mel_loss=0.04375, linear_loss=0.05346]
[2020-05-11 21:40:11.120]  Step 145758  [3.336 sec/step, loss=0.08989, avg_loss=0.09381, mel_loss=0.04021, linear_loss=0.04968]
[2020-05-11 21:40:14.255]  Step 145759  [3.333 sec/step, loss=0.09526, avg_loss=0.09379, mel_loss=0.04306, linear_loss=0.05219]
[2020-05-11 21:40:20.997]  Step 145760  [3.311 sec/step, loss=0.10235, avg_loss=0.09381, mel_loss=0.04803, linear_loss=0.05432]
[2020-05-11 21:40:24.518]  Step 145761  [3.208 sec/step, loss=0.09865, avg_loss=0.09400, mel_loss=0.04504, linear_loss=0.05361]
[2020-05-11 21:40:25.263]  Step 145762  [3.196 sec/step, loss=0.08480, avg_loss=0.09392, mel_loss=0.03767, linear_loss=0.04713]
[2020-05-11 21:40:27.216]  Step 145763  [3.179 sec/step, loss=0.09459, avg_loss=0.09385, mel_loss=0.04236, linear_loss=0.05223]
[2020-05-11 21:40:27.785]  Step 145764  [3.172 sec/step, loss=0.07397, avg_loss=0.09370, mel_loss=0.03319, linear_loss=0.04079]
[2020-05-11 21:40:28.613]  Step 145765  [3.157 sec/step, loss=0.08046, avg_loss=0.09356, mel_loss=0.03557, linear_loss=0.04489]
[2020-05-11 21:40:29.732]  Step 145766  [3.159 sec/step, loss=0.08860, avg_loss=0.09360, mel_loss=0.03911, linear_loss=0.04949]
[2020-05-11 21:40:33.160]  Step 145767  [3.182 sec/step, loss=0.09913, avg_loss=0.09371, mel_loss=0.04531, linear_loss=0.05382]
[2020-05-11 21:40:36.295]  Step 145768  [3.160 sec/step, loss=0.09962, avg_loss=0.09369, mel_loss=0.04553, linear_loss=0.05409]
[2020-05-11 21:40:48.608]  Step 145769  [3.266 sec/step, loss=0.09013, avg_loss=0.09366, mel_loss=0.04331, linear_loss=0.04683]
[2020-05-11 21:40:50.815]  Step 145770  [3.277 sec/step, loss=0.09371, avg_loss=0.09373, mel_loss=0.04229, linear_loss=0.05142]
[2020-05-11 21:40:51.795]  Step 145771  [3.271 sec/step, loss=0.08419, avg_loss=0.09367, mel_loss=0.03679, linear_loss=0.04740]
[2020-05-11 21:40:57.493]  Step 145772  [3.297 sec/step, loss=0.10036, avg_loss=0.09368, mel_loss=0.04664, linear_loss=0.05372]
[2020-05-11 21:41:00.014]  Step 145773  [3.301 sec/step, loss=0.09522, avg_loss=0.09368, mel_loss=0.04278, linear_loss=0.05244]
[2020-05-11 21:41:01.630]  Step 145774  [3.274 sec/step, loss=0.09000, avg_loss=0.09356, mel_loss=0.04029, linear_loss=0.04971]
[2020-05-11 21:41:01.888]  Generated 32 batches of size 32 in 1.868 sec
[2020-05-11 21:41:03.418]  Step 145775  [3.247 sec/step, loss=0.09328, avg_loss=0.09347, mel_loss=0.04150, linear_loss=0.05178]
[2020-05-11 21:41:08.754]  Step 145776  [3.244 sec/step, loss=0.09982, avg_loss=0.09345, mel_loss=0.04624, linear_loss=0.05357]
[2020-05-11 21:41:09.721]  Step 145777  [3.191 sec/step, loss=0.08659, avg_loss=0.09330, mel_loss=0.03847, linear_loss=0.04812]
[2020-05-11 21:41:17.084]  Step 145778  [3.254 sec/step, loss=0.10322, avg_loss=0.09349, mel_loss=0.04849, linear_loss=0.05473]
[2020-05-11 21:41:18.793]  Step 145779  [3.243 sec/step, loss=0.09122, avg_loss=0.09341, mel_loss=0.04090, linear_loss=0.05031]
[2020-05-11 21:41:22.961]  Step 145780  [3.277 sec/step, loss=0.09799, avg_loss=0.09359, mel_loss=0.04490, linear_loss=0.05309]
[2020-05-11 21:41:31.909]  Step 145781  [3.350 sec/step, loss=0.10065, avg_loss=0.09365, mel_loss=0.04764, linear_loss=0.05301]
[2020-05-11 21:41:33.209]  Step 145782  [3.342 sec/step, loss=0.08816, avg_loss=0.09358, mel_loss=0.03897, linear_loss=0.04919]
[2020-05-11 21:41:36.232]  Step 145783  [3.364 sec/step, loss=0.09828, avg_loss=0.09377, mel_loss=0.04466, linear_loss=0.05361]
[2020-05-11 21:41:38.406]  Step 145784  [3.312 sec/step, loss=0.09279, avg_loss=0.09369, mel_loss=0.04159, linear_loss=0.05121]
[2020-05-11 21:41:42.388]  Step 145785  [3.326 sec/step, loss=0.10078, avg_loss=0.09374, mel_loss=0.04628, linear_loss=0.05450]
[2020-05-11 21:41:42.997]  Step 145786  [3.327 sec/step, loss=0.07269, avg_loss=0.09374, mel_loss=0.03305, linear_loss=0.03965]
[2020-05-11 21:41:44.641]  Step 145787  [3.309 sec/step, loss=0.09182, avg_loss=0.09368, mel_loss=0.04058, linear_loss=0.05123]
[2020-05-11 21:41:48.149]  Step 145788  [3.303 sec/step, loss=0.09828, avg_loss=0.09367, mel_loss=0.04509, linear_loss=0.05319]
[2020-05-11 21:41:49.499]  Step 145789  [3.296 sec/step, loss=0.08737, avg_loss=0.09364, mel_loss=0.03860, linear_loss=0.04878]
[2020-05-11 21:41:52.164]  Step 145790  [3.285 sec/step, loss=0.09476, avg_loss=0.09363, mel_loss=0.04298, linear_loss=0.05178]
[2020-05-11 21:41:53.577]  Step 145791  [3.225 sec/step, loss=0.09084, avg_loss=0.09355, mel_loss=0.04033, linear_loss=0.05050]
[2020-05-11 21:42:07.948]  Step 145792  [3.229 sec/step, loss=0.07605, avg_loss=0.09341, mel_loss=0.03664, linear_loss=0.03942]
[2020-05-11 21:42:13.192]  Step 145793  [3.245 sec/step, loss=0.10126, avg_loss=0.09344, mel_loss=0.04702, linear_loss=0.05424]
[2020-05-11 21:42:14.387]  Step 145794  [3.215 sec/step, loss=0.08482, avg_loss=0.09331, mel_loss=0.03764, linear_loss=0.04718]
[2020-05-11 21:42:16.186]  Step 145795  [3.220 sec/step, loss=0.09118, avg_loss=0.09333, mel_loss=0.04059, linear_loss=0.05059]
[2020-05-11 21:42:22.250]  Step 145796  [3.272 sec/step, loss=0.10031, avg_loss=0.09345, mel_loss=0.04683, linear_loss=0.05348]
[2020-05-11 21:42:23.871]  Step 145797  [3.271 sec/step, loss=0.09208, avg_loss=0.09344, mel_loss=0.04104, linear_loss=0.05104]
[2020-05-11 21:42:24.635]  Step 145798  [3.254 sec/step, loss=0.07906, avg_loss=0.09327, mel_loss=0.03471, linear_loss=0.04434]
[2020-05-11 21:42:28.017]  Step 145799  [3.271 sec/step, loss=0.09883, avg_loss=0.09335, mel_loss=0.04492, linear_loss=0.05390]
[2020-05-11 21:42:36.171]  Step 145800  [3.324 sec/step, loss=0.10009, avg_loss=0.09335, mel_loss=0.04717, linear_loss=0.05292]
[2020-05-11 21:42:36.171]  Writing summary at step: 145800
[2020-05-11 21:42:40.703]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145800
[2020-05-11 21:42:42.996]  Saving audio and alignment...
[2020-05-11 21:42:44.927]  Input: 그런데에~_______________________
[2020-05-11 21:42:52.374]  Step 145801  [3.369 sec/step, loss=0.09941, avg_loss=0.09335, mel_loss=0.04658, linear_loss=0.05283]
[2020-05-11 21:42:53.388]  Step 145802  [3.371 sec/step, loss=0.08325, avg_loss=0.09335, mel_loss=0.03675, linear_loss=0.04650]
[2020-05-11 21:42:54.205]  Step 145803  [3.342 sec/step, loss=0.07877, avg_loss=0.09312, mel_loss=0.03445, linear_loss=0.04432]
[2020-05-11 21:42:56.145]  Generated 32 batches of size 32 in 1.935 sec
[2020-05-11 21:42:56.735]  Step 145804  [3.347 sec/step, loss=0.09424, avg_loss=0.09312, mel_loss=0.04252, linear_loss=0.05172]
[2020-05-11 21:43:00.981]  Step 145805  [3.332 sec/step, loss=0.10028, avg_loss=0.09310, mel_loss=0.04602, linear_loss=0.05426]
[2020-05-11 21:43:03.176]  Step 145806  [3.331 sec/step, loss=0.09568, avg_loss=0.09314, mel_loss=0.04310, linear_loss=0.05257]
[2020-05-11 21:43:04.911]  Step 145807  [3.341 sec/step, loss=0.09508, avg_loss=0.09333, mel_loss=0.04242, linear_loss=0.05266]
[2020-05-11 21:43:10.023]  Step 145808  [3.366 sec/step, loss=0.09774, avg_loss=0.09334, mel_loss=0.04513, linear_loss=0.05261]
[2020-05-11 21:43:11.143]  Step 145809  [3.309 sec/step, loss=0.08585, avg_loss=0.09318, mel_loss=0.03760, linear_loss=0.04825]
[2020-05-11 21:43:14.512]  Step 145810  [3.330 sec/step, loss=0.09854, avg_loss=0.09329, mel_loss=0.04511, linear_loss=0.05343]
[2020-05-11 21:43:16.457]  Step 145811  [3.273 sec/step, loss=0.09277, avg_loss=0.09319, mel_loss=0.04160, linear_loss=0.05117]
[2020-05-11 21:43:19.104]  Step 145812  [3.274 sec/step, loss=0.09661, avg_loss=0.09320, mel_loss=0.04381, linear_loss=0.05280]
[2020-05-11 21:43:20.149]  Step 145813  [3.232 sec/step, loss=0.08676, avg_loss=0.09305, mel_loss=0.03811, linear_loss=0.04865]
[2020-05-11 21:43:21.340]  Step 145814  [3.228 sec/step, loss=0.08666, avg_loss=0.09300, mel_loss=0.03783, linear_loss=0.04883]
[2020-05-11 21:43:25.071]  Step 145815  [3.221 sec/step, loss=0.09954, avg_loss=0.09300, mel_loss=0.04556, linear_loss=0.05398]
[2020-05-11 21:43:30.367]  Step 145816  [3.242 sec/step, loss=0.09956, avg_loss=0.09299, mel_loss=0.04623, linear_loss=0.05332]
[2020-05-11 21:43:30.897]  Step 145817  [3.232 sec/step, loss=0.07938, avg_loss=0.09287, mel_loss=0.03574, linear_loss=0.04364]
[2020-05-11 21:43:34.574]  Step 145818  [3.263 sec/step, loss=0.09951, avg_loss=0.09307, mel_loss=0.04546, linear_loss=0.05404]
[2020-05-11 21:43:36.328]  Step 145819  [3.261 sec/step, loss=0.08988, avg_loss=0.09303, mel_loss=0.04008, linear_loss=0.04980]
[2020-05-11 21:43:39.364]  Step 145820  [3.207 sec/step, loss=0.09847, avg_loss=0.09301, mel_loss=0.04427, linear_loss=0.05420]
[2020-05-11 21:43:40.758]  Step 145821  [3.200 sec/step, loss=0.08982, avg_loss=0.09297, mel_loss=0.03989, linear_loss=0.04992]
[2020-05-11 21:43:46.482]  Step 145822  [3.249 sec/step, loss=0.10116, avg_loss=0.09313, mel_loss=0.04686, linear_loss=0.05430]
[2020-05-11 21:43:55.522]  Step 145823  [3.328 sec/step, loss=0.09809, avg_loss=0.09324, mel_loss=0.04634, linear_loss=0.05175]
[2020-05-11 21:43:56.868]  Step 145824  [3.287 sec/step, loss=0.08935, avg_loss=0.09313, mel_loss=0.03979, linear_loss=0.04956]
[2020-05-11 21:43:58.871]  Step 145825  [3.295 sec/step, loss=0.09253, avg_loss=0.09320, mel_loss=0.04152, linear_loss=0.05101]
[2020-05-11 21:44:01.328]  Step 145826  [3.305 sec/step, loss=0.09411, avg_loss=0.09326, mel_loss=0.04248, linear_loss=0.05163]
[2020-05-11 21:44:04.807]  Step 145827  [3.304 sec/step, loss=0.09757, avg_loss=0.09326, mel_loss=0.04460, linear_loss=0.05297]
[2020-05-11 21:44:05.572]  Step 145828  [3.268 sec/step, loss=0.08026, avg_loss=0.09306, mel_loss=0.03509, linear_loss=0.04517]
[2020-05-11 21:44:13.149]  Step 145829  [3.331 sec/step, loss=0.10249, avg_loss=0.09318, mel_loss=0.04802, linear_loss=0.05447]
[2020-05-11 21:44:14.759]  Step 145830  [3.330 sec/step, loss=0.09158, avg_loss=0.09315, mel_loss=0.04119, linear_loss=0.05039]
[2020-05-11 21:44:18.893]  Step 145831  [3.347 sec/step, loss=0.09858, avg_loss=0.09319, mel_loss=0.04503, linear_loss=0.05355]
[2020-05-11 21:44:21.025]  Step 145832  [3.360 sec/step, loss=0.09486, avg_loss=0.09333, mel_loss=0.04256, linear_loss=0.05230]
[2020-05-11 21:44:24.237]  Step 145833  [3.361 sec/step, loss=0.09953, avg_loss=0.09331, mel_loss=0.04556, linear_loss=0.05397]
[2020-05-11 21:44:31.045]  Step 145834  [3.413 sec/step, loss=0.09971, avg_loss=0.09339, mel_loss=0.04654, linear_loss=0.05317]
[2020-05-11 21:44:33.264]  Step 145835  [3.429 sec/step, loss=0.09573, avg_loss=0.09360, mel_loss=0.04320, linear_loss=0.05253]
[2020-05-11 21:44:35.018]  Generated 32 batches of size 32 in 1.748 sec
[2020-05-11 21:44:47.721]  Step 145836  [3.567 sec/step, loss=0.08125, avg_loss=0.09364, mel_loss=0.03927, linear_loss=0.04198]
[2020-05-11 21:44:52.488]  Step 145837  [3.527 sec/step, loss=0.10137, avg_loss=0.09365, mel_loss=0.04667, linear_loss=0.05470]
[2020-05-11 21:44:53.393]  Step 145838  [3.507 sec/step, loss=0.08719, avg_loss=0.09353, mel_loss=0.03829, linear_loss=0.04890]
[2020-05-11 21:44:54.652]  Step 145839  [3.480 sec/step, loss=0.08715, avg_loss=0.09341, mel_loss=0.03887, linear_loss=0.04828]
[2020-05-11 21:44:57.506]  Step 145840  [3.481 sec/step, loss=0.09542, avg_loss=0.09339, mel_loss=0.04342, linear_loss=0.05200]
[2020-05-11 21:44:58.313]  Step 145841  [3.424 sec/step, loss=0.08310, avg_loss=0.09323, mel_loss=0.03660, linear_loss=0.04650]
[2020-05-11 21:45:02.722]  Step 145842  [3.433 sec/step, loss=0.10119, avg_loss=0.09327, mel_loss=0.04697, linear_loss=0.05422]
[2020-05-11 21:45:05.325]  Step 145843  [3.443 sec/step, loss=0.09524, avg_loss=0.09330, mel_loss=0.04305, linear_loss=0.05219]
[2020-05-11 21:45:07.143]  Step 145844  [3.425 sec/step, loss=0.09148, avg_loss=0.09322, mel_loss=0.04092, linear_loss=0.05056]
[2020-05-11 21:45:08.433]  Step 145845  [3.418 sec/step, loss=0.09085, avg_loss=0.09321, mel_loss=0.04027, linear_loss=0.05057]
[2020-05-11 21:45:10.151]  Step 145846  [3.292 sec/step, loss=0.09365, avg_loss=0.09338, mel_loss=0.04173, linear_loss=0.05192]
[2020-05-11 21:45:11.719]  Step 145847  [3.256 sec/step, loss=0.08979, avg_loss=0.09327, mel_loss=0.03995, linear_loss=0.04985]
[2020-05-11 21:45:12.850]  Step 145848  [3.247 sec/step, loss=0.08681, avg_loss=0.09319, mel_loss=0.03835, linear_loss=0.04845]
[2020-05-11 21:45:14.956]  Step 145849  [3.246 sec/step, loss=0.09488, avg_loss=0.09317, mel_loss=0.04267, linear_loss=0.05220]
[2020-05-11 21:45:21.249]  Step 145850  [3.238 sec/step, loss=0.10153, avg_loss=0.09319, mel_loss=0.04763, linear_loss=0.05390]
[2020-05-11 21:45:21.249]  Writing summary at step: 145850
[2020-05-11 21:45:22.002]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145850
[2020-05-11 21:45:23.370]  Saving audio and alignment...
[2020-05-11 21:45:28.028]  Input: 펜싱 전 국가대표 선수인 김준석씹니다~___________________
[2020-05-11 21:45:29.189]  Step 145851  [3.230 sec/step, loss=0.08817, avg_loss=0.09313, mel_loss=0.03898, linear_loss=0.04919]
[2020-05-11 21:45:31.046]  Step 145852  [3.212 sec/step, loss=0.09105, avg_loss=0.09303, mel_loss=0.04042, linear_loss=0.05063]
[2020-05-11 21:45:35.664]  Step 145853  [3.228 sec/step, loss=0.10270, avg_loss=0.09307, mel_loss=0.04805, linear_loss=0.05465]
[2020-05-11 21:45:38.347]  Step 145854  [3.214 sec/step, loss=0.09754, avg_loss=0.09303, mel_loss=0.04451, linear_loss=0.05303]
[2020-05-11 21:45:41.935]  Step 145855  [3.239 sec/step, loss=0.10081, avg_loss=0.09316, mel_loss=0.04643, linear_loss=0.05439]
[2020-05-11 21:45:48.877]  Step 145856  [3.262 sec/step, loss=0.10408, avg_loss=0.09319, mel_loss=0.04914, linear_loss=0.05494]
[2020-05-11 21:45:49.641]  Step 145857  [3.246 sec/step, loss=0.07899, avg_loss=0.09301, mel_loss=0.03453, linear_loss=0.04446]
[2020-05-11 21:45:53.752]  Step 145858  [3.271 sec/step, loss=0.10187, avg_loss=0.09313, mel_loss=0.04705, linear_loss=0.05483]
[2020-05-11 21:45:54.595]  Step 145859  [3.248 sec/step, loss=0.08500, avg_loss=0.09302, mel_loss=0.03732, linear_loss=0.04768]
[2020-05-11 21:45:56.793]  Step 145860  [3.202 sec/step, loss=0.09452, avg_loss=0.09295, mel_loss=0.04297, linear_loss=0.05155]
[2020-05-11 21:45:59.225]  Step 145861  [3.191 sec/step, loss=0.09877, avg_loss=0.09295, mel_loss=0.04510, linear_loss=0.05367]
[2020-05-11 21:46:04.471]  Step 145862  [3.236 sec/step, loss=0.10544, avg_loss=0.09315, mel_loss=0.04990, linear_loss=0.05554]
[2020-05-11 21:46:16.848]  Step 145863  [3.341 sec/step, loss=0.08824, avg_loss=0.09309, mel_loss=0.04255, linear_loss=0.04570]
[2020-05-11 21:46:20.314]  Step 145864  [3.370 sec/step, loss=0.09857, avg_loss=0.09334, mel_loss=0.04524, linear_loss=0.05333]
[2020-05-11 21:46:23.238]  Step 145865  [3.391 sec/step, loss=0.09615, avg_loss=0.09349, mel_loss=0.04359, linear_loss=0.05256]
[2020-05-11 21:46:26.561]  Generated 32 batches of size 32 in 3.314 sec
[2020-05-11 21:46:29.702]  Step 145866  [3.444 sec/step, loss=0.10108, avg_loss=0.09362, mel_loss=0.04662, linear_loss=0.05446]
[2020-05-11 21:46:31.962]  Step 145867  [3.432 sec/step, loss=0.09193, avg_loss=0.09355, mel_loss=0.04126, linear_loss=0.05067]
[2020-05-11 21:46:33.532]  Step 145868  [3.417 sec/step, loss=0.08623, avg_loss=0.09341, mel_loss=0.03813, linear_loss=0.04810]
[2020-05-11 21:46:43.267]  Step 145869  [3.391 sec/step, loss=0.10684, avg_loss=0.09358, mel_loss=0.05245, linear_loss=0.05440]
[2020-05-11 21:46:46.729]  Step 145870  [3.404 sec/step, loss=0.10118, avg_loss=0.09365, mel_loss=0.04628, linear_loss=0.05490]
[2020-05-11 21:46:48.475]  Step 145871  [3.411 sec/step, loss=0.09533, avg_loss=0.09376, mel_loss=0.04251, linear_loss=0.05281]
[2020-05-11 21:46:54.597]  Step 145872  [3.415 sec/step, loss=0.10265, avg_loss=0.09379, mel_loss=0.04802, linear_loss=0.05463]
[2020-05-11 21:46:57.420]  Step 145873  [3.418 sec/step, loss=0.09837, avg_loss=0.09382, mel_loss=0.04462, linear_loss=0.05375]
[2020-05-11 21:46:58.210]  Step 145874  [3.410 sec/step, loss=0.08278, avg_loss=0.09375, mel_loss=0.03638, linear_loss=0.04641]
[2020-05-11 21:47:06.825]  Step 145875  [3.478 sec/step, loss=0.10144, avg_loss=0.09383, mel_loss=0.04816, linear_loss=0.05328]
[2020-05-11 21:47:12.121]  Step 145876  [3.478 sec/step, loss=0.10162, avg_loss=0.09385, mel_loss=0.04744, linear_loss=0.05418]
[2020-05-11 21:47:14.402]  Step 145877  [3.491 sec/step, loss=0.09673, avg_loss=0.09395, mel_loss=0.04395, linear_loss=0.05278]
[2020-05-11 21:47:17.581]  Step 145878  [3.449 sec/step, loss=0.09992, avg_loss=0.09392, mel_loss=0.04594, linear_loss=0.05397]
[2020-05-11 21:47:20.319]  Step 145879  [3.460 sec/step, loss=0.09622, avg_loss=0.09397, mel_loss=0.04393, linear_loss=0.05229]
[2020-05-11 21:47:21.712]  Step 145880  [3.432 sec/step, loss=0.09031, avg_loss=0.09389, mel_loss=0.04053, linear_loss=0.04978]
[2020-05-11 21:47:23.085]  Step 145881  [3.356 sec/step, loss=0.09117, avg_loss=0.09379, mel_loss=0.04084, linear_loss=0.05032]
[2020-05-11 21:47:24.144]  Step 145882  [3.354 sec/step, loss=0.09072, avg_loss=0.09382, mel_loss=0.04015, linear_loss=0.05057]
[2020-05-11 21:47:31.717]  Step 145883  [3.399 sec/step, loss=0.10333, avg_loss=0.09387, mel_loss=0.04898, linear_loss=0.05435]
[2020-05-11 21:47:34.981]  Step 145884  [3.410 sec/step, loss=0.09949, avg_loss=0.09394, mel_loss=0.04579, linear_loss=0.05370]
[2020-05-11 21:47:37.477]  Step 145885  [3.395 sec/step, loss=0.09594, avg_loss=0.09389, mel_loss=0.04328, linear_loss=0.05265]
[2020-05-11 21:47:38.304]  Step 145886  [3.397 sec/step, loss=0.08406, avg_loss=0.09400, mel_loss=0.03731, linear_loss=0.04675]
[2020-05-11 21:47:39.185]  Step 145887  [3.390 sec/step, loss=0.07697, avg_loss=0.09385, mel_loss=0.03409, linear_loss=0.04288]
[2020-05-11 21:47:42.167]  Step 145888  [3.385 sec/step, loss=0.09931, avg_loss=0.09386, mel_loss=0.04531, linear_loss=0.05400]
[2020-05-11 21:47:44.201]  Step 145889  [3.391 sec/step, loss=0.09364, avg_loss=0.09393, mel_loss=0.04222, linear_loss=0.05142]
[2020-05-11 21:47:58.825]  Step 145890  [3.511 sec/step, loss=0.07709, avg_loss=0.09375, mel_loss=0.03712, linear_loss=0.03997]
[2020-05-11 21:48:04.452]  Step 145891  [3.553 sec/step, loss=0.10188, avg_loss=0.09386, mel_loss=0.04731, linear_loss=0.05456]
[2020-05-11 21:48:05.413]  Step 145892  [3.419 sec/step, loss=0.08467, avg_loss=0.09395, mel_loss=0.03731, linear_loss=0.04736]
[2020-05-11 21:48:07.089]  Step 145893  [3.383 sec/step, loss=0.09260, avg_loss=0.09386, mel_loss=0.04147, linear_loss=0.05113]
[2020-05-11 21:48:11.765]  Step 145894  [3.418 sec/step, loss=0.10250, avg_loss=0.09404, mel_loss=0.04734, linear_loss=0.05516]
[2020-05-11 21:48:17.914]  Step 145895  [3.462 sec/step, loss=0.09991, avg_loss=0.09412, mel_loss=0.04686, linear_loss=0.05305]
[2020-05-11 21:48:21.446]  Step 145896  [3.436 sec/step, loss=0.09702, avg_loss=0.09409, mel_loss=0.04445, linear_loss=0.05257]
[2020-05-11 21:48:23.405]  Step 145897  [3.440 sec/step, loss=0.09544, avg_loss=0.09412, mel_loss=0.04275, linear_loss=0.05269]
[2020-05-11 21:48:24.722]  Step 145898  [3.445 sec/step, loss=0.08835, avg_loss=0.09422, mel_loss=0.03942, linear_loss=0.04893]
[2020-05-11 21:48:25.147]  Generated 32 batches of size 32 in 1.736 sec
[2020-05-11 21:48:29.012]  Step 145899  [3.454 sec/step, loss=0.09932, avg_loss=0.09422, mel_loss=0.04551, linear_loss=0.05381]
[2020-05-11 21:48:30.669]  Step 145900  [3.389 sec/step, loss=0.09406, avg_loss=0.09416, mel_loss=0.04230, linear_loss=0.05176]
[2020-05-11 21:48:30.669]  Writing summary at step: 145900
[2020-05-11 21:48:32.506]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145900
[2020-05-11 21:48:33.886]  Saving audio and alignment...
[2020-05-11 21:48:35.264]  Input: 안녕~_______
[2020-05-11 21:48:36.309]  Step 145901  [3.325 sec/step, loss=0.08566, avg_loss=0.09402, mel_loss=0.03797, linear_loss=0.04769]
[2020-05-11 21:48:40.629]  Step 145902  [3.358 sec/step, loss=0.10326, avg_loss=0.09422, mel_loss=0.04773, linear_loss=0.05553]
[2020-05-11 21:48:44.278]  Step 145903  [3.387 sec/step, loss=0.10283, avg_loss=0.09447, mel_loss=0.04756, linear_loss=0.05528]
[2020-05-11 21:48:46.474]  Step 145904  [3.383 sec/step, loss=0.09551, avg_loss=0.09448, mel_loss=0.04324, linear_loss=0.05227]
[2020-05-11 21:48:48.171]  Step 145905  [3.358 sec/step, loss=0.09449, avg_loss=0.09442, mel_loss=0.04214, linear_loss=0.05235]
[2020-05-11 21:48:51.616]  Step 145906  [3.370 sec/step, loss=0.09859, avg_loss=0.09445, mel_loss=0.04470, linear_loss=0.05389]
[2020-05-11 21:48:52.921]  Step 145907  [3.366 sec/step, loss=0.09001, avg_loss=0.09440, mel_loss=0.03979, linear_loss=0.05022]
[2020-05-11 21:48:56.675]  Step 145908  [3.353 sec/step, loss=0.10102, avg_loss=0.09443, mel_loss=0.04643, linear_loss=0.05459]
[2020-05-11 21:49:02.309]  Step 145909  [3.398 sec/step, loss=0.10031, avg_loss=0.09458, mel_loss=0.04662, linear_loss=0.05369]
[2020-05-11 21:49:03.364]  Step 145910  [3.375 sec/step, loss=0.08695, avg_loss=0.09446, mel_loss=0.03863, linear_loss=0.04832]
[2020-05-11 21:49:04.218]  Step 145911  [3.364 sec/step, loss=0.08215, avg_loss=0.09435, mel_loss=0.03568, linear_loss=0.04647]
[2020-05-11 21:49:06.252]  Step 145912  [3.357 sec/step, loss=0.09485, avg_loss=0.09434, mel_loss=0.04235, linear_loss=0.05250]
[2020-05-11 21:49:07.078]  Step 145913  [3.355 sec/step, loss=0.08322, avg_loss=0.09430, mel_loss=0.03660, linear_loss=0.04662]
[2020-05-11 21:49:08.627]  Step 145914  [3.359 sec/step, loss=0.09059, avg_loss=0.09434, mel_loss=0.04019, linear_loss=0.05040]
[2020-05-11 21:49:10.042]  Step 145915  [3.336 sec/step, loss=0.08862, avg_loss=0.09423, mel_loss=0.03963, linear_loss=0.04899]
[2020-05-11 21:49:11.820]  Step 145916  [3.301 sec/step, loss=0.09314, avg_loss=0.09417, mel_loss=0.04175, linear_loss=0.05139]
[2020-05-11 21:49:13.707]  Step 145917  [3.314 sec/step, loss=0.09474, avg_loss=0.09432, mel_loss=0.04206, linear_loss=0.05269]
[2020-05-11 21:49:16.092]  Step 145918  [3.301 sec/step, loss=0.09358, avg_loss=0.09426, mel_loss=0.04233, linear_loss=0.05125]
[2020-05-11 21:49:16.598]  Step 145919  [3.289 sec/step, loss=0.07654, avg_loss=0.09413, mel_loss=0.03464, linear_loss=0.04190]
[2020-05-11 21:49:17.638]  Step 145920  [3.269 sec/step, loss=0.08343, avg_loss=0.09398, mel_loss=0.03680, linear_loss=0.04663]
[2020-05-11 21:49:26.544]  Step 145921  [3.344 sec/step, loss=0.10346, avg_loss=0.09411, mel_loss=0.04920, linear_loss=0.05426]
[2020-05-11 21:49:31.244]  Step 145922  [3.334 sec/step, loss=0.10044, avg_loss=0.09411, mel_loss=0.04642, linear_loss=0.05401]
[2020-05-11 21:49:34.122]  Step 145923  [3.272 sec/step, loss=0.09698, avg_loss=0.09410, mel_loss=0.04411, linear_loss=0.05287]
[2020-05-11 21:49:37.750]  Step 145924  [3.295 sec/step, loss=0.09938, avg_loss=0.09420, mel_loss=0.04535, linear_loss=0.05403]
[2020-05-11 21:49:40.259]  Step 145925  [3.300 sec/step, loss=0.09370, avg_loss=0.09421, mel_loss=0.04226, linear_loss=0.05144]
[2020-05-11 21:49:41.103]  Step 145926  [3.284 sec/step, loss=0.07738, avg_loss=0.09404, mel_loss=0.03476, linear_loss=0.04261]
[2020-05-11 21:49:46.187]  Step 145927  [3.300 sec/step, loss=0.10103, avg_loss=0.09407, mel_loss=0.04696, linear_loss=0.05407]
[2020-05-11 21:49:47.806]  Generated 32 batches of size 32 in 1.614 sec
[2020-05-11 21:49:49.759]  Step 145928  [3.328 sec/step, loss=0.09767, avg_loss=0.09425, mel_loss=0.04445, linear_loss=0.05322]
[2020-05-11 21:49:56.456]  Step 145929  [3.319 sec/step, loss=0.10094, avg_loss=0.09423, mel_loss=0.04707, linear_loss=0.05387]
[2020-05-11 21:49:59.182]  Step 145930  [3.330 sec/step, loss=0.09832, avg_loss=0.09430, mel_loss=0.04457, linear_loss=0.05374]
[2020-05-11 21:50:03.503]  Step 145931  [3.332 sec/step, loss=0.09877, avg_loss=0.09430, mel_loss=0.04549, linear_loss=0.05327]
[2020-05-11 21:50:04.630]  Step 145932  [3.322 sec/step, loss=0.09046, avg_loss=0.09426, mel_loss=0.04008, linear_loss=0.05038]
[2020-05-11 21:50:06.754]  Step 145933  [3.311 sec/step, loss=0.09612, avg_loss=0.09422, mel_loss=0.04319, linear_loss=0.05293]
[2020-05-11 21:50:20.871]  Step 145934  [3.384 sec/step, loss=0.08158, avg_loss=0.09404, mel_loss=0.03996, linear_loss=0.04162]
[2020-05-11 21:50:28.426]  Step 145935  [3.438 sec/step, loss=0.10139, avg_loss=0.09410, mel_loss=0.04767, linear_loss=0.05372]
[2020-05-11 21:50:31.578]  Step 145936  [3.325 sec/step, loss=0.09873, avg_loss=0.09427, mel_loss=0.04483, linear_loss=0.05390]
[2020-05-11 21:50:32.887]  Step 145937  [3.290 sec/step, loss=0.09205, avg_loss=0.09418, mel_loss=0.04132, linear_loss=0.05073]
[2020-05-11 21:50:37.092]  Step 145938  [3.323 sec/step, loss=0.10064, avg_loss=0.09432, mel_loss=0.04646, linear_loss=0.05418]
[2020-05-11 21:50:50.133]  Step 145939  [3.441 sec/step, loss=0.08679, avg_loss=0.09431, mel_loss=0.04198, linear_loss=0.04481]
[2020-05-11 21:50:52.140]  Step 145940  [3.432 sec/step, loss=0.09366, avg_loss=0.09429, mel_loss=0.04208, linear_loss=0.05158]
[2020-05-11 21:50:55.505]  Step 145941  [3.458 sec/step, loss=0.09916, avg_loss=0.09446, mel_loss=0.04557, linear_loss=0.05359]
[2020-05-11 21:50:56.068]  Step 145942  [3.419 sec/step, loss=0.07596, avg_loss=0.09420, mel_loss=0.03399, linear_loss=0.04198]
[2020-05-11 21:50:58.917]  Step 145943  [3.422 sec/step, loss=0.09697, avg_loss=0.09422, mel_loss=0.04407, linear_loss=0.05291]
[2020-05-11 21:51:05.348]  Step 145944  [3.468 sec/step, loss=0.10116, avg_loss=0.09432, mel_loss=0.04745, linear_loss=0.05371]
[2020-05-11 21:51:08.938]  Step 145945  [3.491 sec/step, loss=0.10091, avg_loss=0.09442, mel_loss=0.04648, linear_loss=0.05443]
[2020-05-11 21:51:10.156]  Step 145946  [3.486 sec/step, loss=0.08975, avg_loss=0.09438, mel_loss=0.03992, linear_loss=0.04983]
[2020-05-11 21:51:15.086]  Step 145947  [3.520 sec/step, loss=0.09928, avg_loss=0.09447, mel_loss=0.04605, linear_loss=0.05323]
[2020-05-11 21:51:20.687]  Step 145948  [3.564 sec/step, loss=0.10161, avg_loss=0.09462, mel_loss=0.04741, linear_loss=0.05421]
[2020-05-11 21:51:24.424]  Step 145949  [3.581 sec/step, loss=0.10145, avg_loss=0.09469, mel_loss=0.04672, linear_loss=0.05473]
[2020-05-11 21:51:25.129]  Step 145950  [3.525 sec/step, loss=0.08042, avg_loss=0.09448, mel_loss=0.03533, linear_loss=0.04509]
[2020-05-11 21:51:25.129]  Writing summary at step: 145950
[2020-05-11 21:51:27.265]  Saving checkpoint to: ./logs-tacotron/model.ckpt-145950
[2020-05-11 21:51:28.602]  Saving audio and alignment...
[2020-05-11 21:51:31.614]  Input: 폭죽처럼 터지는 날도 있어요~__________
[2020-05-11 21:51:36.136]  Step 145951  [3.558 sec/step, loss=0.10267, avg_loss=0.09462, mel_loss=0.04782, linear_loss=0.05485]
[2020-05-11 21:51:36.917]  Step 145952  [3.548 sec/step, loss=0.08140, avg_loss=0.09452, mel_loss=0.03604, linear_loss=0.04537]
[2020-05-11 21:51:40.206]  Step 145953  [3.534 sec/step, loss=0.10065, avg_loss=0.09450, mel_loss=0.04607, linear_loss=0.05458]
[2020-05-11 21:51:41.298]  Step 145954  [3.518 sec/step, loss=0.08764, avg_loss=0.09441, mel_loss=0.03866, linear_loss=0.04899]
[2020-05-11 21:51:43.669]  Step 145955  [3.506 sec/step, loss=0.09694, avg_loss=0.09437, mel_loss=0.04392, linear_loss=0.05302]
[2020-05-11 21:51:45.471]  Step 145956  [3.455 sec/step, loss=0.09341, avg_loss=0.09426, mel_loss=0.04194, linear_loss=0.05147]
[2020-05-11 21:51:46.477]  Step 145957  [3.457 sec/step, loss=0.08650, avg_loss=0.09434, mel_loss=0.03825, linear_loss=0.04826]
[2020-05-11 21:51:48.231]  Generated 32 batches of size 32 in 1.748 sec
[2020-05-11 21:51:49.119]  Step 145958  [3.443 sec/step, loss=0.09700, avg_loss=0.09429, mel_loss=0.04410, linear_loss=0.05290]
[2020-05-11 21:51:56.292]  Step 145959  [3.506 sec/step, loss=0.10306, avg_loss=0.09447, mel_loss=0.04869, linear_loss=0.05436]
[2020-05-11 21:52:05.101]  Step 145960  [3.572 sec/step, loss=0.09858, avg_loss=0.09451, mel_loss=0.04651, linear_loss=0.05207]
[2020-05-11 21:52:06.728]  Step 145961  [3.564 sec/step, loss=0.09222, avg_loss=0.09444, mel_loss=0.04109, linear_loss=0.05113]
[2020-05-11 21:52:09.783]  Step 145962  [3.542 sec/step, loss=0.10005, avg_loss=0.09439, mel_loss=0.04587, linear_loss=0.05418]
[2020-05-11 21:52:10.765]  Step 145963  [3.428 sec/step, loss=0.08563, avg_loss=0.09436, mel_loss=0.03767, linear_loss=0.04796]
[2020-05-11 21:52:12.353]  Step 145964  [3.409 sec/step, loss=0.09276, avg_loss=0.09430, mel_loss=0.04158, linear_loss=0.05118]
[2020-05-11 21:52:13.688]  Step 145965  [3.393 sec/step, loss=0.09258, avg_loss=0.09427, mel_loss=0.04133, linear_loss=0.05126]
[2020-05-11 21:52:16.004]  Step 145966  [3.352 sec/step, loss=0.09463, avg_loss=0.09420, mel_loss=0.04256, linear_loss=0.05207]
[2020-05-11 21:52:19.408]  Step 145967  [3.363 sec/step, loss=0.09833, avg_loss=0.09427, mel_loss=0.04475, linear_loss=0.05359]
[2020-05-11 21:52:21.721]  Step 145968  [3.371 sec/step, loss=0.09643, avg_loss=0.09437, mel_loss=0.04369, linear_loss=0.05274]
[2020-05-11 21:52:28.211]  Step 145969  [3.338 sec/step, loss=0.10324, avg_loss=0.09433, mel_loss=0.04828, linear_loss=0.05496]
[2020-05-11 21:52:29.373]  Step 145970  [3.315 sec/step, loss=0.08562, avg_loss=0.09418, mel_loss=0.03762, linear_loss=0.04800]
[2020-05-11 21:52:32.995]  Step 145971  [3.334 sec/step, loss=0.10094, avg_loss=0.09423, mel_loss=0.04622, linear_loss=0.05472]
[2020-05-11 21:52:34.341]  Step 145972  [3.286 sec/step, loss=0.08741, avg_loss=0.09408, mel_loss=0.03903, linear_loss=0.04839]
[2020-05-11 21:52:37.676]  Step 145973  [3.292 sec/step, loss=0.09802, avg_loss=0.09408, mel_loss=0.04488, linear_loss=0.05314]
[2020-05-11 21:52:38.746]  Step 145974  [3.294 sec/step, loss=0.08998, avg_loss=0.09415, mel_loss=0.03960, linear_loss=0.05038]
[2020-05-11 21:52:39.635]  Step 145975  [3.217 sec/step, loss=0.07578, avg_loss=0.09389, mel_loss=0.03336, linear_loss=0.04242]
[2020-05-11 21:52:48.670]  Step 145976  [3.254 sec/step, loss=0.10248, avg_loss=0.09390, mel_loss=0.04859, linear_loss=0.05389]
[2020-05-11 21:52:50.162]  Step 145977  [3.247 sec/step, loss=0.09197, avg_loss=0.09385, mel_loss=0.04109, linear_loss=0.05088]
[2020-05-11 21:52:55.900]  Step 145978  [3.272 sec/step, loss=0.10247, avg_loss=0.09388, mel_loss=0.04787, linear_loss=0.05459]
[2020-05-11 21:52:57.545]  Step 145979  [3.261 sec/step, loss=0.09407, avg_loss=0.09386, mel_loss=0.04217, linear_loss=0.05190]
[2020-05-11 21:52:59.245]  Step 145980  [3.264 sec/step, loss=0.09327, avg_loss=0.09389, mel_loss=0.04143, linear_loss=0.05184]
[2020-05-11 21:53:00.199]  Step 145981  [3.260 sec/step, loss=0.08572, avg_loss=0.09383, mel_loss=0.03808, linear_loss=0.04764]
[2020-05-11 21:53:04.333]  Step 145982  [3.291 sec/step, loss=0.09919, avg_loss=0.09392, mel_loss=0.04557, linear_loss=0.05362]
[2020-05-11 21:53:05.724]  Step 145983  [3.229 sec/step, loss=0.08947, avg_loss=0.09378, mel_loss=0.03976, linear_loss=0.04970]
[2020-05-11 21:53:19.672]  Step 145984  [3.336 sec/step, loss=0.08053, avg_loss=0.09359, mel_loss=0.03891, linear_loss=0.04162]
[2020-05-11 21:53:22.545]  Step 145985  [3.340 sec/step, loss=0.09864, avg_loss=0.09362, mel_loss=0.04461, linear_loss=0.05404]
[2020-05-11 21:53:27.903]  Step 145986  [3.385 sec/step, loss=0.10019, avg_loss=0.09378, mel_loss=0.04665, linear_loss=0.05354]
[2020-05-11 21:53:28.795]  Step 145987  [3.385 sec/step, loss=0.08044, avg_loss=0.09381, mel_loss=0.03545, linear_loss=0.04498]
[2020-05-11 21:53:30.668]  Step 145988  [3.374 sec/step, loss=0.09204, avg_loss=0.09374, mel_loss=0.04116, linear_loss=0.05088]
[2020-05-11 21:53:31.222]  Step 145989  [3.359 sec/step, loss=0.07643, avg_loss=0.09357, mel_loss=0.03457, linear_loss=0.04187]
[2020-05-11 21:53:32.851]  Generated 32 batches of size 32 in 1.624 sec
[2020-05-11 21:53:39.080]  Step 145990  [3.292 sec/step, loss=0.10378, avg_loss=0.09384, mel_loss=0.04895, linear_loss=0.05483]
[2020-05-11 21:53:39.836]  Step 145991  [3.243 sec/step, loss=0.08509, avg_loss=0.09367, mel_loss=0.03752, linear_loss=0.04757]
[2020-05-11 21:53:44.189]  Step 145992  [3.277 sec/step, loss=0.10147, avg_loss=0.09384, mel_loss=0.04682, linear_loss=0.05465]
[2020-05-11 21:53:46.205]  Step 145993  [3.280 sec/step, loss=0.09383, avg_loss=0.09385, mel_loss=0.04237, linear_loss=0.05147]
[2020-05-11 21:53:48.632]  Step 145994  [3.258 sec/step, loss=0.09613, avg_loss=0.09378, mel_loss=0.04343, linear_loss=0.05270]
[2020-05-11 21:53:53.366]  Step 145995  [3.243 sec/step, loss=0.09934, avg_loss=0.09378, mel_loss=0.04589, linear_loss=0.05345]
[2020-05-11 21:53:55.514]  Step 145996  [3.230 sec/step, loss=0.09434, avg_loss=0.09375, mel_loss=0.04256, linear_loss=0.05177]
[2020-05-11 21:53:58.611]  Step 145997  [3.241 sec/step, loss=0.10051, avg_loss=0.09380, mel_loss=0.04605, linear_loss=0.05446]
[2020-05-11 21:54:01.212]  Step 145998  [3.254 sec/step, loss=0.09874, avg_loss=0.09391, mel_loss=0.04529, linear_loss=0.05345]
[2020-05-11 21:54:03.985]  Step 145999  [3.239 sec/step, loss=0.09588, avg_loss=0.09387, mel_loss=0.04343, linear_loss=0.05244]
[2020-05-11 21:54:05.856]  Step 146000  [3.241 sec/step, loss=0.09185, avg_loss=0.09385, mel_loss=0.04081, linear_loss=0.05105]
[2020-05-11 21:54:05.856]  Writing summary at step: 146000
[2020-05-11 21:54:06.658]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146000
[2020-05-11 21:54:08.028]  Saving audio and alignment...
[2020-05-11 21:54:10.424]  Input: 한국석유공사는~_______________
[2020-05-11 21:54:13.764]  Step 146001  [3.264 sec/step, loss=0.09842, avg_loss=0.09398, mel_loss=0.04507, linear_loss=0.05334]
[2020-05-11 21:54:15.349]  Step 146002  [3.236 sec/step, loss=0.09277, avg_loss=0.09387, mel_loss=0.04162, linear_loss=0.05116]
[2020-05-11 21:54:19.458]  Step 146003  [3.241 sec/step, loss=0.09895, avg_loss=0.09383, mel_loss=0.04536, linear_loss=0.05359]
[2020-05-11 21:54:23.002]  Step 146004  [3.255 sec/step, loss=0.09939, avg_loss=0.09387, mel_loss=0.04555, linear_loss=0.05384]
[2020-05-11 21:54:23.556]  Step 146005  [3.243 sec/step, loss=0.07146, avg_loss=0.09364, mel_loss=0.03181, linear_loss=0.03965]
[2020-05-11 21:54:28.908]  Step 146006  [3.262 sec/step, loss=0.10150, avg_loss=0.09367, mel_loss=0.04725, linear_loss=0.05425]
[2020-05-11 21:54:29.896]  Step 146007  [3.259 sec/step, loss=0.08472, avg_loss=0.09362, mel_loss=0.03721, linear_loss=0.04752]
[2020-05-11 21:54:30.988]  Step 146008  [3.232 sec/step, loss=0.08621, avg_loss=0.09347, mel_loss=0.03792, linear_loss=0.04829]
[2020-05-11 21:54:34.292]  Step 146009  [3.209 sec/step, loss=0.10035, avg_loss=0.09347, mel_loss=0.04569, linear_loss=0.05466]
[2020-05-11 21:54:39.949]  Step 146010  [3.255 sec/step, loss=0.10212, avg_loss=0.09362, mel_loss=0.04749, linear_loss=0.05463]
[2020-05-11 21:54:40.956]  Step 146011  [3.257 sec/step, loss=0.08541, avg_loss=0.09366, mel_loss=0.03761, linear_loss=0.04780]
[2020-05-11 21:54:45.773]  Step 146012  [3.284 sec/step, loss=0.10025, avg_loss=0.09371, mel_loss=0.04627, linear_loss=0.05398]
[2020-05-11 21:54:49.985]  Step 146013  [3.318 sec/step, loss=0.10097, avg_loss=0.09389, mel_loss=0.04660, linear_loss=0.05437]
[2020-05-11 21:54:56.741]  Step 146014  [3.370 sec/step, loss=0.10347, avg_loss=0.09402, mel_loss=0.04856, linear_loss=0.05491]
[2020-05-11 21:54:58.876]  Step 146015  [3.378 sec/step, loss=0.09515, avg_loss=0.09408, mel_loss=0.04283, linear_loss=0.05232]
[2020-05-11 21:55:06.785]  Step 146016  [3.439 sec/step, loss=0.10082, avg_loss=0.09416, mel_loss=0.04738, linear_loss=0.05344]
[2020-05-11 21:55:08.176]  Step 146017  [3.434 sec/step, loss=0.08889, avg_loss=0.09410, mel_loss=0.03973, linear_loss=0.04916]
[2020-05-11 21:55:11.921]  Step 146018  [3.448 sec/step, loss=0.10072, avg_loss=0.09417, mel_loss=0.04602, linear_loss=0.05470]
[2020-05-11 21:55:13.707]  Step 146019  [3.460 sec/step, loss=0.09317, avg_loss=0.09434, mel_loss=0.04147, linear_loss=0.05170]
[2020-05-11 21:55:15.506]  Generated 32 batches of size 32 in 1.794 sec
[2020-05-11 21:55:16.453]  Step 146020  [3.477 sec/step, loss=0.09535, avg_loss=0.09446, mel_loss=0.04299, linear_loss=0.05235]
[2020-05-11 21:55:17.094]  Step 146021  [3.395 sec/step, loss=0.07912, avg_loss=0.09421, mel_loss=0.03507, linear_loss=0.04406]
[2020-05-11 21:55:19.086]  Step 146022  [3.368 sec/step, loss=0.09462, avg_loss=0.09415, mel_loss=0.04250, linear_loss=0.05212]
[2020-05-11 21:55:20.302]  Step 146023  [3.351 sec/step, loss=0.08822, avg_loss=0.09407, mel_loss=0.03900, linear_loss=0.04922]
[2020-05-11 21:55:23.247]  Step 146024  [3.344 sec/step, loss=0.09924, avg_loss=0.09407, mel_loss=0.04524, linear_loss=0.05401]
[2020-05-11 21:55:24.809]  Step 146025  [3.335 sec/step, loss=0.09115, avg_loss=0.09404, mel_loss=0.04085, linear_loss=0.05030]
[2020-05-11 21:55:27.499]  Step 146026  [3.353 sec/step, loss=0.09335, avg_loss=0.09420, mel_loss=0.04187, linear_loss=0.05148]
[2020-05-11 21:55:29.717]  Step 146027  [3.325 sec/step, loss=0.09455, avg_loss=0.09413, mel_loss=0.04283, linear_loss=0.05172]
[2020-05-11 21:55:42.762]  Step 146028  [3.419 sec/step, loss=0.08074, avg_loss=0.09397, mel_loss=0.03884, linear_loss=0.04191]
[2020-05-11 21:55:43.879]  Step 146029  [3.363 sec/step, loss=0.08521, avg_loss=0.09381, mel_loss=0.03753, linear_loss=0.04769]
[2020-05-11 21:55:44.675]  Step 146030  [3.344 sec/step, loss=0.08164, avg_loss=0.09364, mel_loss=0.03617, linear_loss=0.04547]
[2020-05-11 21:55:46.728]  Step 146031  [3.321 sec/step, loss=0.09274, avg_loss=0.09358, mel_loss=0.04178, linear_loss=0.05096]
[2020-05-11 21:55:49.370]  Step 146032  [3.337 sec/step, loss=0.09571, avg_loss=0.09363, mel_loss=0.04323, linear_loss=0.05248]
[2020-05-11 21:55:49.922]  Step 146033  [3.321 sec/step, loss=0.07558, avg_loss=0.09343, mel_loss=0.03389, linear_loss=0.04170]
[2020-05-11 21:55:52.011]  Step 146034  [3.201 sec/step, loss=0.09387, avg_loss=0.09355, mel_loss=0.04221, linear_loss=0.05165]
[2020-05-11 21:55:57.189]  Step 146035  [3.177 sec/step, loss=0.09987, avg_loss=0.09354, mel_loss=0.04633, linear_loss=0.05355]
[2020-05-11 21:55:58.242]  Step 146036  [3.156 sec/step, loss=0.08394, avg_loss=0.09339, mel_loss=0.03727, linear_loss=0.04667]
[2020-05-11 21:56:04.951]  Step 146037  [3.210 sec/step, loss=0.10046, avg_loss=0.09347, mel_loss=0.04704, linear_loss=0.05342]
[2020-05-11 21:56:06.676]  Step 146038  [3.185 sec/step, loss=0.09311, avg_loss=0.09340, mel_loss=0.04157, linear_loss=0.05154]
[2020-05-11 21:56:08.475]  Step 146039  [3.073 sec/step, loss=0.09275, avg_loss=0.09346, mel_loss=0.04110, linear_loss=0.05165]
[2020-05-11 21:56:22.478]  Step 146040  [3.193 sec/step, loss=0.08013, avg_loss=0.09332, mel_loss=0.03880, linear_loss=0.04133]
[2020-05-11 21:56:27.937]  Step 146041  [3.214 sec/step, loss=0.10070, avg_loss=0.09334, mel_loss=0.04695, linear_loss=0.05375]
[2020-05-11 21:56:30.346]  Step 146042  [3.232 sec/step, loss=0.09599, avg_loss=0.09354, mel_loss=0.04316, linear_loss=0.05283]
[2020-05-11 21:56:33.998]  Step 146043  [3.240 sec/step, loss=0.10038, avg_loss=0.09357, mel_loss=0.04611, linear_loss=0.05427]
[2020-05-11 21:56:35.097]  Step 146044  [3.187 sec/step, loss=0.07499, avg_loss=0.09331, mel_loss=0.03311, linear_loss=0.04188]
[2020-05-11 21:56:37.425]  Step 146045  [3.174 sec/step, loss=0.09123, avg_loss=0.09321, mel_loss=0.04058, linear_loss=0.05065]
[2020-05-11 21:56:42.490]  Step 146046  [3.213 sec/step, loss=0.09791, avg_loss=0.09329, mel_loss=0.04439, linear_loss=0.05351]
[2020-05-11 21:56:49.385]  Step 146047  [3.232 sec/step, loss=0.09945, avg_loss=0.09330, mel_loss=0.04565, linear_loss=0.05380]
[2020-05-11 21:56:55.258]  Step 146048  [3.235 sec/step, loss=0.10029, avg_loss=0.09328, mel_loss=0.04581, linear_loss=0.05448]
[2020-05-11 21:56:58.890]  Step 146049  [3.234 sec/step, loss=0.09791, avg_loss=0.09325, mel_loss=0.04469, linear_loss=0.05322]
[2020-05-11 21:57:02.336]  Step 146050  [3.261 sec/step, loss=0.09687, avg_loss=0.09341, mel_loss=0.04426, linear_loss=0.05261]
[2020-05-11 21:57:02.336]  Writing summary at step: 146050
[2020-05-11 21:57:03.657]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146050
[2020-05-11 21:57:05.056]  Saving audio and alignment...
[2020-05-11 21:57:07.932]  Generated 32 batches of size 32 in 2.342 sec
[2020-05-11 21:57:12.112]  Input: 사회 자에게만 허락된 일입니다 신랑신부를 낳고 길은 부모님조차도~_________________
[2020-05-11 21:57:13.784]  Step 146051  [3.233 sec/step, loss=0.09133, avg_loss=0.09330, mel_loss=0.04073, linear_loss=0.05060]
[2020-05-11 21:57:21.917]  Step 146052  [3.306 sec/step, loss=0.10083, avg_loss=0.09349, mel_loss=0.04743, linear_loss=0.05340]
[2020-05-11 21:57:23.278]  Step 146053  [3.287 sec/step, loss=0.08951, avg_loss=0.09338, mel_loss=0.03959, linear_loss=0.04992]
[2020-05-11 21:57:25.443]  Step 146054  [3.298 sec/step, loss=0.09388, avg_loss=0.09344, mel_loss=0.04217, linear_loss=0.05171]
[2020-05-11 21:57:28.221]  Step 146055  [3.302 sec/step, loss=0.09650, avg_loss=0.09344, mel_loss=0.04370, linear_loss=0.05280]
[2020-05-11 21:57:29.211]  Step 146056  [3.294 sec/step, loss=0.08394, avg_loss=0.09334, mel_loss=0.03675, linear_loss=0.04719]
[2020-05-11 21:57:32.307]  Step 146057  [3.315 sec/step, loss=0.10155, avg_loss=0.09349, mel_loss=0.04627, linear_loss=0.05528]
[2020-05-11 21:57:41.346]  Step 146058  [3.379 sec/step, loss=0.10141, avg_loss=0.09354, mel_loss=0.04817, linear_loss=0.05324]
[2020-05-11 21:57:45.028]  Step 146059  [3.344 sec/step, loss=0.09891, avg_loss=0.09350, mel_loss=0.04548, linear_loss=0.05344]
[2020-05-11 21:57:46.583]  Step 146060  [3.271 sec/step, loss=0.09159, avg_loss=0.09343, mel_loss=0.04074, linear_loss=0.05085]
[2020-05-11 21:57:47.622]  Step 146061  [3.265 sec/step, loss=0.08743, avg_loss=0.09338, mel_loss=0.03881, linear_loss=0.04862]
[2020-05-11 21:57:51.031]  Step 146062  [3.269 sec/step, loss=0.09706, avg_loss=0.09335, mel_loss=0.04427, linear_loss=0.05279]
[2020-05-11 21:57:52.150]  Step 146063  [3.270 sec/step, loss=0.08648, avg_loss=0.09336, mel_loss=0.03777, linear_loss=0.04871]
[2020-05-11 21:57:58.974]  Step 146064  [3.323 sec/step, loss=0.10301, avg_loss=0.09346, mel_loss=0.04814, linear_loss=0.05487]
[2020-05-11 21:58:06.986]  Step 146065  [3.389 sec/step, loss=0.10055, avg_loss=0.09354, mel_loss=0.04706, linear_loss=0.05349]
[2020-05-11 21:58:10.229]  Step 146066  [3.399 sec/step, loss=0.09838, avg_loss=0.09358, mel_loss=0.04480, linear_loss=0.05357]
[2020-05-11 21:58:16.312]  Step 146067  [3.425 sec/step, loss=0.09959, avg_loss=0.09359, mel_loss=0.04652, linear_loss=0.05306]
[2020-05-11 21:58:21.785]  Step 146068  [3.457 sec/step, loss=0.10177, avg_loss=0.09364, mel_loss=0.04703, linear_loss=0.05474]
[2020-05-11 21:58:25.915]  Step 146069  [3.433 sec/step, loss=0.10007, avg_loss=0.09361, mel_loss=0.04629, linear_loss=0.05378]
[2020-05-11 21:58:27.641]  Step 146070  [3.439 sec/step, loss=0.09242, avg_loss=0.09368, mel_loss=0.04108, linear_loss=0.05135]
[2020-05-11 21:58:28.546]  Step 146071  [3.412 sec/step, loss=0.08114, avg_loss=0.09348, mel_loss=0.03548, linear_loss=0.04566]
[2020-05-11 21:58:30.619]  Step 146072  [3.419 sec/step, loss=0.09258, avg_loss=0.09353, mel_loss=0.04120, linear_loss=0.05139]
[2020-05-11 21:58:32.571]  Step 146073  [3.405 sec/step, loss=0.09331, avg_loss=0.09349, mel_loss=0.04179, linear_loss=0.05152]
[2020-05-11 21:58:33.129]  Step 146074  [3.400 sec/step, loss=0.07316, avg_loss=0.09332, mel_loss=0.03282, linear_loss=0.04035]
[2020-05-11 21:58:34.466]  Step 146075  [3.405 sec/step, loss=0.09034, avg_loss=0.09346, mel_loss=0.04032, linear_loss=0.05002]
[2020-05-11 21:58:36.802]  Step 146076  [3.338 sec/step, loss=0.09696, avg_loss=0.09341, mel_loss=0.04364, linear_loss=0.05332]
[2020-05-11 21:58:38.104]  Step 146077  [3.336 sec/step, loss=0.08593, avg_loss=0.09335, mel_loss=0.03833, linear_loss=0.04760]
[2020-05-11 21:58:38.891]  Step 146078  [3.286 sec/step, loss=0.07987, avg_loss=0.09312, mel_loss=0.03473, linear_loss=0.04514]
[2020-05-11 21:58:41.562]  Step 146079  [3.296 sec/step, loss=0.09468, avg_loss=0.09313, mel_loss=0.04261, linear_loss=0.05207]
[2020-05-11 21:58:42.407]  Step 146080  [3.288 sec/step, loss=0.07935, avg_loss=0.09299, mel_loss=0.03473, linear_loss=0.04462]
[2020-05-11 21:58:57.003]  Step 146081  [3.424 sec/step, loss=0.07687, avg_loss=0.09290, mel_loss=0.03686, linear_loss=0.04001]
[2020-05-11 21:58:59.328]  Generated 32 batches of size 32 in 2.319 sec
[2020-05-11 21:58:59.983]  Step 146082  [3.413 sec/step, loss=0.09567, avg_loss=0.09287, mel_loss=0.04357, linear_loss=0.05210]
[2020-05-11 21:59:00.945]  Step 146083  [3.409 sec/step, loss=0.08612, avg_loss=0.09283, mel_loss=0.03764, linear_loss=0.04848]
[2020-05-11 21:59:03.158]  Step 146084  [3.291 sec/step, loss=0.09462, avg_loss=0.09297, mel_loss=0.04275, linear_loss=0.05187]
[2020-05-11 21:59:08.345]  Step 146085  [3.314 sec/step, loss=0.09974, avg_loss=0.09298, mel_loss=0.04607, linear_loss=0.05366]
[2020-05-11 21:59:11.276]  Step 146086  [3.290 sec/step, loss=0.09848, avg_loss=0.09297, mel_loss=0.04481, linear_loss=0.05367]
[2020-05-11 21:59:14.851]  Step 146087  [3.317 sec/step, loss=0.09964, avg_loss=0.09316, mel_loss=0.04559, linear_loss=0.05405]
[2020-05-11 21:59:16.220]  Step 146088  [3.312 sec/step, loss=0.09358, avg_loss=0.09317, mel_loss=0.04183, linear_loss=0.05175]
[2020-05-11 21:59:20.816]  Step 146089  [3.352 sec/step, loss=0.10043, avg_loss=0.09341, mel_loss=0.04633, linear_loss=0.05410]
[2020-05-11 21:59:22.582]  Step 146090  [3.291 sec/step, loss=0.09206, avg_loss=0.09330, mel_loss=0.04116, linear_loss=0.05091]
[2020-05-11 21:59:25.426]  Step 146091  [3.312 sec/step, loss=0.09533, avg_loss=0.09340, mel_loss=0.04327, linear_loss=0.05206]
[2020-05-11 21:59:28.418]  Step 146092  [3.299 sec/step, loss=0.09976, avg_loss=0.09338, mel_loss=0.04560, linear_loss=0.05416]
[2020-05-11 21:59:32.009]  Step 146093  [3.314 sec/step, loss=0.09991, avg_loss=0.09344, mel_loss=0.04563, linear_loss=0.05428]
[2020-05-11 21:59:33.614]  Step 146094  [3.306 sec/step, loss=0.08997, avg_loss=0.09338, mel_loss=0.03977, linear_loss=0.05020]
[2020-05-11 21:59:36.283]  Step 146095  [3.285 sec/step, loss=0.09654, avg_loss=0.09335, mel_loss=0.04417, linear_loss=0.05237]
[2020-05-11 21:59:37.412]  Step 146096  [3.275 sec/step, loss=0.08391, avg_loss=0.09325, mel_loss=0.03700, linear_loss=0.04690]
[2020-05-11 21:59:38.458]  Step 146097  [3.255 sec/step, loss=0.08165, avg_loss=0.09306, mel_loss=0.03581, linear_loss=0.04584]
[2020-05-11 21:59:45.257]  Step 146098  [3.297 sec/step, loss=0.10087, avg_loss=0.09308, mel_loss=0.04698, linear_loss=0.05390]
[2020-05-11 21:59:47.046]  Step 146099  [3.287 sec/step, loss=0.09032, avg_loss=0.09303, mel_loss=0.04005, linear_loss=0.05027]
[2020-05-11 21:59:50.318]  Step 146100  [3.301 sec/step, loss=0.09835, avg_loss=0.09309, mel_loss=0.04492, linear_loss=0.05343]
[2020-05-11 21:59:50.318]  Writing summary at step: 146100
[2020-05-11 21:59:51.571]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146100
[2020-05-11 21:59:52.929]  Saving audio and alignment...
[2020-05-11 21:59:55.862]  Input: 함께 부분 처리를 제가~______________
[2020-05-11 22:00:00.443]  Step 146101  [3.313 sec/step, loss=0.09966, avg_loss=0.09310, mel_loss=0.04580, linear_loss=0.05386]
[2020-05-11 22:00:02.412]  Step 146102  [3.317 sec/step, loss=0.09474, avg_loss=0.09312, mel_loss=0.04238, linear_loss=0.05237]
[2020-05-11 22:00:08.096]  Step 146103  [3.333 sec/step, loss=0.10078, avg_loss=0.09314, mel_loss=0.04666, linear_loss=0.05412]
[2020-05-11 22:00:16.982]  Step 146104  [3.386 sec/step, loss=0.10059, avg_loss=0.09315, mel_loss=0.04738, linear_loss=0.05321]
[2020-05-11 22:00:18.405]  Step 146105  [3.395 sec/step, loss=0.08994, avg_loss=0.09334, mel_loss=0.04016, linear_loss=0.04978]
[2020-05-11 22:00:21.741]  Step 146106  [3.375 sec/step, loss=0.09749, avg_loss=0.09330, mel_loss=0.04443, linear_loss=0.05306]
[2020-05-11 22:00:22.604]  Step 146107  [3.374 sec/step, loss=0.07593, avg_loss=0.09321, mel_loss=0.03362, linear_loss=0.04231]
[2020-05-11 22:00:24.762]  Step 146108  [3.384 sec/step, loss=0.09507, avg_loss=0.09330, mel_loss=0.04280, linear_loss=0.05227]
[2020-05-11 22:00:37.750]  Step 146109  [3.481 sec/step, loss=0.08695, avg_loss=0.09317, mel_loss=0.04185, linear_loss=0.04510]
[2020-05-11 22:00:43.026]  Step 146110  [3.477 sec/step, loss=0.09980, avg_loss=0.09314, mel_loss=0.04619, linear_loss=0.05361]
[2020-05-11 22:00:45.263]  Step 146111  [3.490 sec/step, loss=0.09576, avg_loss=0.09325, mel_loss=0.04324, linear_loss=0.05253]
[2020-05-11 22:00:47.174]  Generated 32 batches of size 32 in 1.905 sec
[2020-05-11 22:00:53.028]  Step 146112  [3.519 sec/step, loss=0.10283, avg_loss=0.09327, mel_loss=0.04838, linear_loss=0.05445]
[2020-05-11 22:00:53.827]  Step 146113  [3.485 sec/step, loss=0.08051, avg_loss=0.09307, mel_loss=0.03521, linear_loss=0.04530]
[2020-05-11 22:00:56.220]  Step 146114  [3.441 sec/step, loss=0.09552, avg_loss=0.09299, mel_loss=0.04299, linear_loss=0.05253]
[2020-05-11 22:00:57.223]  Step 146115  [3.430 sec/step, loss=0.08387, avg_loss=0.09287, mel_loss=0.03675, linear_loss=0.04711]
[2020-05-11 22:00:59.189]  Step 146116  [3.371 sec/step, loss=0.09418, avg_loss=0.09281, mel_loss=0.04237, linear_loss=0.05181]
[2020-05-11 22:01:03.177]  Step 146117  [3.397 sec/step, loss=0.10170, avg_loss=0.09294, mel_loss=0.04636, linear_loss=0.05534]
[2020-05-11 22:01:07.413]  Step 146118  [3.401 sec/step, loss=0.09917, avg_loss=0.09292, mel_loss=0.04550, linear_loss=0.05367]
[2020-05-11 22:01:08.749]  Step 146119  [3.397 sec/step, loss=0.09010, avg_loss=0.09289, mel_loss=0.03993, linear_loss=0.05017]
[2020-05-11 22:01:09.312]  Step 146120  [3.375 sec/step, loss=0.07444, avg_loss=0.09268, mel_loss=0.03348, linear_loss=0.04096]
[2020-05-11 22:01:12.406]  Step 146121  [3.400 sec/step, loss=0.09836, avg_loss=0.09287, mel_loss=0.04490, linear_loss=0.05345]
[2020-05-11 22:01:18.084]  Step 146122  [3.437 sec/step, loss=0.10174, avg_loss=0.09294, mel_loss=0.04764, linear_loss=0.05410]
[2020-05-11 22:01:30.003]  Step 146123  [3.544 sec/step, loss=0.08611, avg_loss=0.09292, mel_loss=0.04124, linear_loss=0.04486]
[2020-05-11 22:01:31.577]  Step 146124  [3.530 sec/step, loss=0.09326, avg_loss=0.09286, mel_loss=0.04180, linear_loss=0.05145]
[2020-05-11 22:01:32.910]  Step 146125  [3.528 sec/step, loss=0.09234, avg_loss=0.09288, mel_loss=0.04080, linear_loss=0.05154]
[2020-05-11 22:01:40.928]  Step 146126  [3.581 sec/step, loss=0.09686, avg_loss=0.09291, mel_loss=0.04550, linear_loss=0.05135]
[2020-05-11 22:01:41.765]  Step 146127  [3.567 sec/step, loss=0.07885, avg_loss=0.09275, mel_loss=0.03463, linear_loss=0.04422]
[2020-05-11 22:01:42.812]  Step 146128  [3.447 sec/step, loss=0.08849, avg_loss=0.09283, mel_loss=0.03931, linear_loss=0.04918]
[2020-05-11 22:01:46.604]  Step 146129  [3.474 sec/step, loss=0.09829, avg_loss=0.09296, mel_loss=0.04501, linear_loss=0.05328]
[2020-05-11 22:01:49.223]  Step 146130  [3.492 sec/step, loss=0.09730, avg_loss=0.09312, mel_loss=0.04393, linear_loss=0.05336]
[2020-05-11 22:01:50.053]  Step 146131  [3.480 sec/step, loss=0.07690, avg_loss=0.09296, mel_loss=0.03436, linear_loss=0.04254]
[2020-05-11 22:01:52.002]  Step 146132  [3.473 sec/step, loss=0.09419, avg_loss=0.09294, mel_loss=0.04238, linear_loss=0.05181]
[2020-05-11 22:01:54.502]  Step 146133  [3.492 sec/step, loss=0.09393, avg_loss=0.09313, mel_loss=0.04225, linear_loss=0.05168]
[2020-05-11 22:01:57.879]  Step 146134  [3.505 sec/step, loss=0.09985, avg_loss=0.09319, mel_loss=0.04541, linear_loss=0.05444]
[2020-05-11 22:01:59.709]  Step 146135  [3.472 sec/step, loss=0.09196, avg_loss=0.09311, mel_loss=0.04073, linear_loss=0.05123]
[2020-05-11 22:02:00.693]  Step 146136  [3.471 sec/step, loss=0.08525, avg_loss=0.09312, mel_loss=0.03777, linear_loss=0.04748]
[2020-05-11 22:02:03.591]  Step 146137  [3.433 sec/step, loss=0.09883, avg_loss=0.09311, mel_loss=0.04465, linear_loss=0.05418]
[2020-05-11 22:02:08.775]  Step 146138  [3.468 sec/step, loss=0.10190, avg_loss=0.09319, mel_loss=0.04728, linear_loss=0.05462]
[2020-05-11 22:02:10.075]  Step 146139  [3.463 sec/step, loss=0.08772, avg_loss=0.09314, mel_loss=0.03924, linear_loss=0.04848]
[2020-05-11 22:02:10.602]  Step 146140  [3.328 sec/step, loss=0.07154, avg_loss=0.09306, mel_loss=0.03197, linear_loss=0.03958]
[2020-05-11 22:02:15.170]  Step 146141  [3.319 sec/step, loss=0.10134, avg_loss=0.09306, mel_loss=0.04641, linear_loss=0.05493]
[2020-05-11 22:02:17.515]  Step 146142  [3.318 sec/step, loss=0.09599, avg_loss=0.09306, mel_loss=0.04316, linear_loss=0.05282]
[2020-05-11 22:02:19.091]  Step 146143  [3.297 sec/step, loss=0.08944, avg_loss=0.09295, mel_loss=0.04006, linear_loss=0.04938]
[2020-05-11 22:02:20.305]  Step 146144  [3.299 sec/step, loss=0.08676, avg_loss=0.09307, mel_loss=0.03782, linear_loss=0.04893]
[2020-05-11 22:02:20.819]  Generated 32 batches of size 32 in 1.722 sec
[2020-05-11 22:02:22.185]  Step 146145  [3.294 sec/step, loss=0.09278, avg_loss=0.09309, mel_loss=0.04092, linear_loss=0.05186]
[2020-05-11 22:02:24.481]  Step 146146  [3.266 sec/step, loss=0.09444, avg_loss=0.09305, mel_loss=0.04233, linear_loss=0.05211]
[2020-05-11 22:02:28.046]  Step 146147  [3.233 sec/step, loss=0.09824, avg_loss=0.09304, mel_loss=0.04478, linear_loss=0.05346]
[2020-05-11 22:02:29.067]  Step 146148  [3.185 sec/step, loss=0.08308, avg_loss=0.09287, mel_loss=0.03661, linear_loss=0.04647]
[2020-05-11 22:02:33.439]  Step 146149  [3.192 sec/step, loss=0.10167, avg_loss=0.09291, mel_loss=0.04670, linear_loss=0.05496]
[2020-05-11 22:02:37.064]  Step 146150  [3.194 sec/step, loss=0.10053, avg_loss=0.09294, mel_loss=0.04576, linear_loss=0.05477]
[2020-05-11 22:02:37.064]  Writing summary at step: 146150
[2020-05-11 22:02:41.932]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146150
[2020-05-11 22:02:43.276]  Saving audio and alignment...
[2020-05-11 22:02:52.545]  Input: 하나는 평생 살 것처럼 사는 거 두 번째는 당장 내일이 마지막 일 수도 있다고 생각하며 사는 것이다~__________
[2020-05-11 22:02:54.919]  Step 146151  [3.201 sec/step, loss=0.09616, avg_loss=0.09299, mel_loss=0.04303, linear_loss=0.05313]
[2020-05-11 22:02:56.022]  Step 146152  [3.131 sec/step, loss=0.08620, avg_loss=0.09284, mel_loss=0.03763, linear_loss=0.04857]
[2020-05-11 22:02:56.936]  Step 146153  [3.126 sec/step, loss=0.08343, avg_loss=0.09278, mel_loss=0.03643, linear_loss=0.04700]
[2020-05-11 22:03:01.028]  Step 146154  [3.145 sec/step, loss=0.09875, avg_loss=0.09283, mel_loss=0.04545, linear_loss=0.05329]
[2020-05-11 22:03:02.287]  Step 146155  [3.130 sec/step, loss=0.08659, avg_loss=0.09273, mel_loss=0.03861, linear_loss=0.04798]
[2020-05-11 22:03:03.987]  Step 146156  [3.137 sec/step, loss=0.09216, avg_loss=0.09282, mel_loss=0.04128, linear_loss=0.05088]
[2020-05-11 22:03:11.556]  Step 146157  [3.182 sec/step, loss=0.10224, avg_loss=0.09282, mel_loss=0.04789, linear_loss=0.05435]
[2020-05-11 22:03:12.896]  Step 146158  [3.105 sec/step, loss=0.09003, avg_loss=0.09271, mel_loss=0.04013, linear_loss=0.04990]
[2020-05-11 22:03:15.742]  Step 146159  [3.097 sec/step, loss=0.09506, avg_loss=0.09267, mel_loss=0.04341, linear_loss=0.05166]
[2020-05-11 22:03:17.107]  Step 146160  [3.095 sec/step, loss=0.09041, avg_loss=0.09266, mel_loss=0.04048, linear_loss=0.04994]
[2020-05-11 22:03:21.121]  Step 146161  [3.124 sec/step, loss=0.09906, avg_loss=0.09278, mel_loss=0.04530, linear_loss=0.05377]
[2020-05-11 22:03:34.123]  Step 146162  [3.220 sec/step, loss=0.08526, avg_loss=0.09266, mel_loss=0.04073, linear_loss=0.04453]
[2020-05-11 22:03:38.656]  Step 146163  [3.255 sec/step, loss=0.10069, avg_loss=0.09280, mel_loss=0.04643, linear_loss=0.05426]
[2020-05-11 22:03:45.495]  Step 146164  [3.255 sec/step, loss=0.10076, avg_loss=0.09278, mel_loss=0.04704, linear_loss=0.05372]
[2020-05-11 22:03:54.274]  Step 146165  [3.262 sec/step, loss=0.09951, avg_loss=0.09277, mel_loss=0.04683, linear_loss=0.05269]
[2020-05-11 22:03:54.830]  Step 146166  [3.236 sec/step, loss=0.07296, avg_loss=0.09251, mel_loss=0.03269, linear_loss=0.04028]
[2020-05-11 22:03:58.444]  Step 146167  [3.211 sec/step, loss=0.10007, avg_loss=0.09252, mel_loss=0.04573, linear_loss=0.05435]
[2020-05-11 22:04:00.379]  Step 146168  [3.175 sec/step, loss=0.09290, avg_loss=0.09243, mel_loss=0.04133, linear_loss=0.05157]
[2020-05-11 22:04:02.577]  Step 146169  [3.156 sec/step, loss=0.09357, avg_loss=0.09236, mel_loss=0.04233, linear_loss=0.05124]
[2020-05-11 22:04:04.136]  Step 146170  [3.154 sec/step, loss=0.09014, avg_loss=0.09234, mel_loss=0.03999, linear_loss=0.05014]
[2020-05-11 22:04:06.215]  Step 146171  [3.166 sec/step, loss=0.09546, avg_loss=0.09248, mel_loss=0.04293, linear_loss=0.05253]
[2020-05-11 22:04:08.872]  Step 146172  [3.172 sec/step, loss=0.09674, avg_loss=0.09253, mel_loss=0.04364, linear_loss=0.05310]
[2020-05-11 22:04:14.157]  Step 146173  [3.205 sec/step, loss=0.09906, avg_loss=0.09258, mel_loss=0.04603, linear_loss=0.05302]
[2020-05-11 22:04:14.855]  Step 146174  [3.207 sec/step, loss=0.07652, avg_loss=0.09262, mel_loss=0.03417, linear_loss=0.04236]
[2020-05-11 22:04:15.925]  Generated 32 batches of size 32 in 1.762 sec
[2020-05-11 22:04:15.927]  Step 146175  [3.204 sec/step, loss=0.08497, avg_loss=0.09256, mel_loss=0.03742, linear_loss=0.04755]
[2020-05-11 22:04:19.275]  Step 146176  [3.214 sec/step, loss=0.10068, avg_loss=0.09260, mel_loss=0.04589, linear_loss=0.05479]
[2020-05-11 22:04:21.262]  Step 146177  [3.221 sec/step, loss=0.09604, avg_loss=0.09270, mel_loss=0.04301, linear_loss=0.05302]
[2020-05-11 22:04:23.043]  Step 146178  [3.231 sec/step, loss=0.09189, avg_loss=0.09282, mel_loss=0.04060, linear_loss=0.05129]
[2020-05-11 22:04:26.505]  Step 146179  [3.239 sec/step, loss=0.09558, avg_loss=0.09283, mel_loss=0.04375, linear_loss=0.05183]
[2020-05-11 22:04:29.610]  Step 146180  [3.262 sec/step, loss=0.09785, avg_loss=0.09301, mel_loss=0.04425, linear_loss=0.05359]
[2020-05-11 22:04:35.295]  Step 146181  [3.172 sec/step, loss=0.10086, avg_loss=0.09325, mel_loss=0.04690, linear_loss=0.05396]
[2020-05-11 22:04:36.094]  Step 146182  [3.151 sec/step, loss=0.08025, avg_loss=0.09310, mel_loss=0.03539, linear_loss=0.04486]
[2020-05-11 22:04:39.479]  Step 146183  [3.175 sec/step, loss=0.09723, avg_loss=0.09321, mel_loss=0.04410, linear_loss=0.05313]
[2020-05-11 22:04:41.879]  Step 146184  [3.177 sec/step, loss=0.09436, avg_loss=0.09321, mel_loss=0.04270, linear_loss=0.05166]
[2020-05-11 22:04:42.663]  Step 146185  [3.133 sec/step, loss=0.07569, avg_loss=0.09297, mel_loss=0.03341, linear_loss=0.04227]
[2020-05-11 22:04:45.386]  Step 146186  [3.131 sec/step, loss=0.09502, avg_loss=0.09293, mel_loss=0.04293, linear_loss=0.05208]
[2020-05-11 22:04:51.002]  Step 146187  [3.151 sec/step, loss=0.09976, avg_loss=0.09294, mel_loss=0.04627, linear_loss=0.05349]
[2020-05-11 22:04:58.508]  Step 146188  [3.212 sec/step, loss=0.10133, avg_loss=0.09301, mel_loss=0.04770, linear_loss=0.05362]
[2020-05-11 22:05:02.797]  Step 146189  [3.209 sec/step, loss=0.09948, avg_loss=0.09300, mel_loss=0.04575, linear_loss=0.05373]
[2020-05-11 22:05:05.296]  Step 146190  [3.217 sec/step, loss=0.09413, avg_loss=0.09302, mel_loss=0.04206, linear_loss=0.05207]
[2020-05-11 22:05:06.904]  Step 146191  [3.204 sec/step, loss=0.09306, avg_loss=0.09300, mel_loss=0.04172, linear_loss=0.05134]
[2020-05-11 22:05:09.988]  Step 146192  [3.205 sec/step, loss=0.09904, avg_loss=0.09299, mel_loss=0.04495, linear_loss=0.05409]
[2020-05-11 22:05:23.806]  Step 146193  [3.307 sec/step, loss=0.08115, avg_loss=0.09281, mel_loss=0.03950, linear_loss=0.04165]
[2020-05-11 22:05:24.935]  Step 146194  [3.303 sec/step, loss=0.08983, avg_loss=0.09280, mel_loss=0.03934, linear_loss=0.05048]
[2020-05-11 22:05:25.746]  Step 146195  [3.284 sec/step, loss=0.08306, avg_loss=0.09267, mel_loss=0.03632, linear_loss=0.04674]
[2020-05-11 22:05:28.627]  Step 146196  [3.302 sec/step, loss=0.09959, avg_loss=0.09283, mel_loss=0.04532, linear_loss=0.05428]
[2020-05-11 22:05:29.973]  Step 146197  [3.305 sec/step, loss=0.09059, avg_loss=0.09292, mel_loss=0.03983, linear_loss=0.05076]
[2020-05-11 22:05:31.413]  Step 146198  [3.251 sec/step, loss=0.08879, avg_loss=0.09280, mel_loss=0.03941, linear_loss=0.04938]
[2020-05-11 22:05:32.608]  Step 146199  [3.245 sec/step, loss=0.08846, avg_loss=0.09278, mel_loss=0.03954, linear_loss=0.04892]
[2020-05-11 22:05:39.089]  Step 146200  [3.277 sec/step, loss=0.10058, avg_loss=0.09280, mel_loss=0.04692, linear_loss=0.05366]
[2020-05-11 22:05:39.089]  Writing summary at step: 146200
[2020-05-11 22:05:41.249]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146200
[2020-05-11 22:05:42.630]  Saving audio and alignment...
[2020-05-11 22:05:45.767]  Input: 이 멘트를 쓰고자~________________________
[2020-05-11 22:05:49.418]  Step 146201  [3.268 sec/step, loss=0.10013, avg_loss=0.09280, mel_loss=0.04582, linear_loss=0.05431]
[2020-05-11 22:05:54.143]  Step 146202  [3.295 sec/step, loss=0.10060, avg_loss=0.09286, mel_loss=0.04632, linear_loss=0.05429]
[2020-05-11 22:05:55.161]  Step 146203  [3.249 sec/step, loss=0.08481, avg_loss=0.09270, mel_loss=0.03704, linear_loss=0.04777]
[2020-05-11 22:05:56.821]  Generated 32 batches of size 32 in 1.656 sec
[2020-05-11 22:05:59.384]  Step 146204  [3.202 sec/step, loss=0.09949, avg_loss=0.09269, mel_loss=0.04543, linear_loss=0.05407]
[2020-05-11 22:06:01.164]  Step 146205  [3.206 sec/step, loss=0.09026, avg_loss=0.09270, mel_loss=0.04001, linear_loss=0.05025]
[2020-05-11 22:06:03.243]  Step 146206  [3.193 sec/step, loss=0.09485, avg_loss=0.09267, mel_loss=0.04240, linear_loss=0.05245]
[2020-05-11 22:06:06.696]  Step 146207  [3.219 sec/step, loss=0.09688, avg_loss=0.09288, mel_loss=0.04407, linear_loss=0.05281]
[2020-05-11 22:06:07.500]  Step 146208  [3.206 sec/step, loss=0.07308, avg_loss=0.09266, mel_loss=0.03315, linear_loss=0.03994]
[2020-05-11 22:06:12.822]  Step 146209  [3.129 sec/step, loss=0.09986, avg_loss=0.09279, mel_loss=0.04605, linear_loss=0.05381]
[2020-05-11 22:06:13.851]  Step 146210  [3.086 sec/step, loss=0.08334, avg_loss=0.09262, mel_loss=0.03693, linear_loss=0.04641]
[2020-05-11 22:06:15.794]  Step 146211  [3.083 sec/step, loss=0.09347, avg_loss=0.09260, mel_loss=0.04191, linear_loss=0.05156]
[2020-05-11 22:06:24.343]  Step 146212  [3.091 sec/step, loss=0.09839, avg_loss=0.09256, mel_loss=0.04643, linear_loss=0.05197]
[2020-05-11 22:06:31.600]  Step 146213  [3.156 sec/step, loss=0.10113, avg_loss=0.09276, mel_loss=0.04731, linear_loss=0.05382]
[2020-05-11 22:06:34.535]  Step 146214  [3.161 sec/step, loss=0.09647, avg_loss=0.09277, mel_loss=0.04376, linear_loss=0.05271]
[2020-05-11 22:06:35.851]  Step 146215  [3.164 sec/step, loss=0.08948, avg_loss=0.09283, mel_loss=0.03988, linear_loss=0.04960]
[2020-05-11 22:06:39.978]  Step 146216  [3.186 sec/step, loss=0.09916, avg_loss=0.09288, mel_loss=0.04529, linear_loss=0.05387]
[2020-05-11 22:06:41.495]  Step 146217  [3.161 sec/step, loss=0.09157, avg_loss=0.09278, mel_loss=0.04072, linear_loss=0.05086]
[2020-05-11 22:06:43.214]  Step 146218  [3.136 sec/step, loss=0.09268, avg_loss=0.09271, mel_loss=0.04132, linear_loss=0.05136]
[2020-05-11 22:06:44.317]  Step 146219  [3.134 sec/step, loss=0.08575, avg_loss=0.09267, mel_loss=0.03787, linear_loss=0.04788]
[2020-05-11 22:06:46.770]  Step 146220  [3.153 sec/step, loss=0.09561, avg_loss=0.09288, mel_loss=0.04299, linear_loss=0.05263]
[2020-05-11 22:06:50.478]  Step 146221  [3.159 sec/step, loss=0.09940, avg_loss=0.09289, mel_loss=0.04547, linear_loss=0.05393]
[2020-05-11 22:06:54.716]  Step 146222  [3.144 sec/step, loss=0.09877, avg_loss=0.09286, mel_loss=0.04549, linear_loss=0.05328]
[2020-05-11 22:07:05.462]  Step 146223  [3.133 sec/step, loss=0.09913, avg_loss=0.09299, mel_loss=0.04633, linear_loss=0.05280]
[2020-05-11 22:07:10.186]  Step 146224  [3.164 sec/step, loss=0.09727, avg_loss=0.09303, mel_loss=0.04446, linear_loss=0.05281]
[2020-05-11 22:07:16.202]  Step 146225  [3.211 sec/step, loss=0.10039, avg_loss=0.09311, mel_loss=0.04646, linear_loss=0.05392]
[2020-05-11 22:07:17.864]  Step 146226  [3.148 sec/step, loss=0.09014, avg_loss=0.09304, mel_loss=0.04038, linear_loss=0.04977]
[2020-05-11 22:07:20.250]  Step 146227  [3.163 sec/step, loss=0.09456, avg_loss=0.09320, mel_loss=0.04277, linear_loss=0.05179]
[2020-05-11 22:07:29.302]  Step 146228  [3.243 sec/step, loss=0.10057, avg_loss=0.09332, mel_loss=0.04753, linear_loss=0.05304]
[2020-05-11 22:07:31.995]  Step 146229  [3.232 sec/step, loss=0.09662, avg_loss=0.09330, mel_loss=0.04372, linear_loss=0.05290]
[2020-05-11 22:07:32.923]  Step 146230  [3.215 sec/step, loss=0.08210, avg_loss=0.09315, mel_loss=0.03604, linear_loss=0.04607]
[2020-05-11 22:07:36.683]  Step 146231  [3.244 sec/step, loss=0.09735, avg_loss=0.09336, mel_loss=0.04452, linear_loss=0.05283]
[2020-05-11 22:07:37.541]  Step 146232  [3.234 sec/step, loss=0.07710, avg_loss=0.09319, mel_loss=0.03385, linear_loss=0.04326]
[2020-05-11 22:07:41.060]  Step 146233  [3.244 sec/step, loss=0.09942, avg_loss=0.09324, mel_loss=0.04554, linear_loss=0.05388]
[2020-05-11 22:07:42.455]  Step 146234  [3.224 sec/step, loss=0.09117, avg_loss=0.09315, mel_loss=0.04028, linear_loss=0.05088]
[2020-05-11 22:07:55.780]  Step 146235  [3.339 sec/step, loss=0.08556, avg_loss=0.09309, mel_loss=0.04091, linear_loss=0.04465]
[2020-05-11 22:07:56.578]  Step 146236  [3.337 sec/step, loss=0.07724, avg_loss=0.09301, mel_loss=0.03451, linear_loss=0.04273]
[2020-05-11 22:07:57.540]  Generated 32 batches of size 32 in 1.754 sec
[2020-05-11 22:07:57.866]  Step 146237  [3.321 sec/step, loss=0.08761, avg_loss=0.09290, mel_loss=0.03876, linear_loss=0.04884]
[2020-05-11 22:08:00.028]  Step 146238  [3.291 sec/step, loss=0.09329, avg_loss=0.09281, mel_loss=0.04206, linear_loss=0.05124]
[2020-05-11 22:08:00.552]  Step 146239  [3.283 sec/step, loss=0.07749, avg_loss=0.09271, mel_loss=0.03434, linear_loss=0.04316]
[2020-05-11 22:08:02.531]  Step 146240  [3.297 sec/step, loss=0.09481, avg_loss=0.09294, mel_loss=0.04247, linear_loss=0.05233]
[2020-05-11 22:08:07.641]  Step 146241  [3.303 sec/step, loss=0.09948, avg_loss=0.09292, mel_loss=0.04624, linear_loss=0.05324]
[2020-05-11 22:08:09.558]  Step 146242  [3.299 sec/step, loss=0.09013, avg_loss=0.09287, mel_loss=0.04045, linear_loss=0.04968]
[2020-05-11 22:08:14.119]  Step 146243  [3.328 sec/step, loss=0.10159, avg_loss=0.09299, mel_loss=0.04677, linear_loss=0.05482]
[2020-05-11 22:08:15.166]  Step 146244  [3.327 sec/step, loss=0.08404, avg_loss=0.09296, mel_loss=0.03712, linear_loss=0.04691]
[2020-05-11 22:08:21.584]  Step 146245  [3.372 sec/step, loss=0.10099, avg_loss=0.09304, mel_loss=0.04724, linear_loss=0.05375]
[2020-05-11 22:08:26.973]  Step 146246  [3.403 sec/step, loss=0.10081, avg_loss=0.09311, mel_loss=0.04656, linear_loss=0.05425]
[2020-05-11 22:08:28.641]  Step 146247  [3.384 sec/step, loss=0.09238, avg_loss=0.09305, mel_loss=0.04129, linear_loss=0.05109]
[2020-05-11 22:08:30.012]  Step 146248  [3.388 sec/step, loss=0.08823, avg_loss=0.09310, mel_loss=0.03925, linear_loss=0.04898]
[2020-05-11 22:08:32.564]  Step 146249  [3.369 sec/step, loss=0.09337, avg_loss=0.09302, mel_loss=0.04199, linear_loss=0.05138]
[2020-05-11 22:08:46.776]  Step 146250  [3.475 sec/step, loss=0.07980, avg_loss=0.09281, mel_loss=0.03875, linear_loss=0.04105]
[2020-05-11 22:08:46.776]  Writing summary at step: 146250
[2020-05-11 22:08:52.670]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146250
[2020-05-11 22:08:54.080]  Saving audio and alignment...
[2020-05-11 22:09:01.009]  Input: 이메일 좋아요 이랬다면 예 이메일로 전송되도록 처리해드렸습니다~___________________________
[2020-05-11 22:09:03.865]  Step 146251  [3.480 sec/step, loss=0.09575, avg_loss=0.09280, mel_loss=0.04320, linear_loss=0.05256]
[2020-05-11 22:09:08.023]  Step 146252  [3.511 sec/step, loss=0.10020, avg_loss=0.09294, mel_loss=0.04578, linear_loss=0.05443]
[2020-05-11 22:09:11.218]  Step 146253  [3.533 sec/step, loss=0.09936, avg_loss=0.09310, mel_loss=0.04512, linear_loss=0.05423]
[2020-05-11 22:09:13.636]  Step 146254  [3.517 sec/step, loss=0.09451, avg_loss=0.09306, mel_loss=0.04267, linear_loss=0.05184]
[2020-05-11 22:09:21.268]  Step 146255  [3.580 sec/step, loss=0.10045, avg_loss=0.09320, mel_loss=0.04723, linear_loss=0.05322]
[2020-05-11 22:09:22.397]  Step 146256  [3.575 sec/step, loss=0.08478, avg_loss=0.09313, mel_loss=0.03730, linear_loss=0.04748]
[2020-05-11 22:09:26.781]  Step 146257  [3.543 sec/step, loss=0.10047, avg_loss=0.09311, mel_loss=0.04619, linear_loss=0.05428]
[2020-05-11 22:09:27.597]  Step 146258  [3.538 sec/step, loss=0.07870, avg_loss=0.09299, mel_loss=0.03444, linear_loss=0.04426]
[2020-05-11 22:09:29.351]  Step 146259  [3.527 sec/step, loss=0.09322, avg_loss=0.09298, mel_loss=0.04160, linear_loss=0.05163]
[2020-05-11 22:09:38.214]  Step 146260  [3.602 sec/step, loss=0.10015, avg_loss=0.09307, mel_loss=0.04715, linear_loss=0.05300]
[2020-05-11 22:09:40.153]  Step 146261  [3.581 sec/step, loss=0.09241, avg_loss=0.09301, mel_loss=0.04112, linear_loss=0.05129]
[2020-05-11 22:09:42.149]  Step 146262  [3.471 sec/step, loss=0.09424, avg_loss=0.09310, mel_loss=0.04228, linear_loss=0.05196]
[2020-05-11 22:09:45.804]  Step 146263  [3.462 sec/step, loss=0.10058, avg_loss=0.09310, mel_loss=0.04608, linear_loss=0.05450]
[2020-05-11 22:09:47.277]  Step 146264  [3.408 sec/step, loss=0.08987, avg_loss=0.09299, mel_loss=0.04005, linear_loss=0.04982]
[2020-05-11 22:09:48.033]  Step 146265  [3.328 sec/step, loss=0.08061, avg_loss=0.09280, mel_loss=0.03516, linear_loss=0.04546]
[2020-05-11 22:09:49.403]  Step 146266  [3.336 sec/step, loss=0.08959, avg_loss=0.09296, mel_loss=0.03934, linear_loss=0.05025]
[2020-05-11 22:09:49.802]  Generated 32 batches of size 32 in 1.764 sec
[2020-05-11 22:09:50.405]  Step 146267  [3.310 sec/step, loss=0.08592, avg_loss=0.09282, mel_loss=0.03781, linear_loss=0.04811]
[2020-05-11 22:09:53.321]  Step 146268  [3.320 sec/step, loss=0.09886, avg_loss=0.09288, mel_loss=0.04494, linear_loss=0.05392]
[2020-05-11 22:09:55.476]  Step 146269  [3.320 sec/step, loss=0.09530, avg_loss=0.09290, mel_loss=0.04281, linear_loss=0.05249]
[2020-05-11 22:09:58.916]  Step 146270  [3.338 sec/step, loss=0.09646, avg_loss=0.09296, mel_loss=0.04386, linear_loss=0.05260]
[2020-05-11 22:09:59.684]  Step 146271  [3.325 sec/step, loss=0.07383, avg_loss=0.09275, mel_loss=0.03327, linear_loss=0.04056]
[2020-05-11 22:10:03.123]  Step 146272  [3.333 sec/step, loss=0.09959, avg_loss=0.09278, mel_loss=0.04548, linear_loss=0.05411]
[2020-05-11 22:10:04.346]  Step 146273  [3.293 sec/step, loss=0.08632, avg_loss=0.09265, mel_loss=0.03808, linear_loss=0.04824]
[2020-05-11 22:10:05.253]  Step 146274  [3.295 sec/step, loss=0.08220, avg_loss=0.09270, mel_loss=0.03608, linear_loss=0.04612]
[2020-05-11 22:10:07.753]  Step 146275  [3.309 sec/step, loss=0.09467, avg_loss=0.09280, mel_loss=0.04257, linear_loss=0.05210]
[2020-05-11 22:10:11.847]  Step 146276  [3.316 sec/step, loss=0.09728, avg_loss=0.09277, mel_loss=0.04461, linear_loss=0.05267]
[2020-05-11 22:10:12.839]  Step 146277  [3.306 sec/step, loss=0.08539, avg_loss=0.09266, mel_loss=0.03744, linear_loss=0.04795]
[2020-05-11 22:10:16.397]  Step 146278  [3.324 sec/step, loss=0.09712, avg_loss=0.09271, mel_loss=0.04442, linear_loss=0.05270]
[2020-05-11 22:10:18.676]  Step 146279  [3.312 sec/step, loss=0.09539, avg_loss=0.09271, mel_loss=0.04276, linear_loss=0.05263]
[2020-05-11 22:10:20.853]  Step 146280  [3.303 sec/step, loss=0.09319, avg_loss=0.09267, mel_loss=0.04197, linear_loss=0.05122]
[2020-05-11 22:10:29.512]  Step 146281  [3.333 sec/step, loss=0.10013, avg_loss=0.09266, mel_loss=0.04703, linear_loss=0.05310]
[2020-05-11 22:10:37.187]  Step 146282  [3.402 sec/step, loss=0.10007, avg_loss=0.09286, mel_loss=0.04665, linear_loss=0.05341]
[2020-05-11 22:10:41.118]  Step 146283  [3.407 sec/step, loss=0.10115, avg_loss=0.09290, mel_loss=0.04616, linear_loss=0.05500]
[2020-05-11 22:10:42.277]  Step 146284  [3.395 sec/step, loss=0.08551, avg_loss=0.09281, mel_loss=0.03771, linear_loss=0.04779]
[2020-05-11 22:10:45.488]  Step 146285  [3.419 sec/step, loss=0.09860, avg_loss=0.09304, mel_loss=0.04514, linear_loss=0.05346]
[2020-05-11 22:10:46.048]  Step 146286  [3.397 sec/step, loss=0.07408, avg_loss=0.09283, mel_loss=0.03336, linear_loss=0.04072]
[2020-05-11 22:10:50.812]  Step 146287  [3.389 sec/step, loss=0.10033, avg_loss=0.09283, mel_loss=0.04619, linear_loss=0.05414]
[2020-05-11 22:10:52.430]  Step 146288  [3.330 sec/step, loss=0.09323, avg_loss=0.09275, mel_loss=0.04173, linear_loss=0.05150]
[2020-05-11 22:10:58.113]  Step 146289  [3.344 sec/step, loss=0.10111, avg_loss=0.09277, mel_loss=0.04702, linear_loss=0.05409]
[2020-05-11 22:10:59.311]  Step 146290  [3.331 sec/step, loss=0.08746, avg_loss=0.09270, mel_loss=0.03902, linear_loss=0.04844]
[2020-05-11 22:11:06.134]  Step 146291  [3.383 sec/step, loss=0.10335, avg_loss=0.09280, mel_loss=0.04849, linear_loss=0.05486]
[2020-05-11 22:11:06.946]  Step 146292  [3.360 sec/step, loss=0.08222, avg_loss=0.09264, mel_loss=0.03608, linear_loss=0.04614]
[2020-05-11 22:11:08.994]  Step 146293  [3.243 sec/step, loss=0.09304, avg_loss=0.09275, mel_loss=0.04173, linear_loss=0.05131]
[2020-05-11 22:11:10.122]  Step 146294  [3.243 sec/step, loss=0.08941, avg_loss=0.09275, mel_loss=0.03902, linear_loss=0.05038]
[2020-05-11 22:11:12.063]  Step 146295  [3.254 sec/step, loss=0.09365, avg_loss=0.09286, mel_loss=0.04177, linear_loss=0.05188]
[2020-05-11 22:11:13.444]  Step 146296  [3.239 sec/step, loss=0.08938, avg_loss=0.09275, mel_loss=0.03980, linear_loss=0.04958]
[2020-05-11 22:11:14.097]  Step 146297  [3.232 sec/step, loss=0.07506, avg_loss=0.09260, mel_loss=0.03360, linear_loss=0.04146]
[2020-05-11 22:11:15.639]  Step 146298  [3.233 sec/step, loss=0.08929, avg_loss=0.09260, mel_loss=0.03954, linear_loss=0.04974]
[2020-05-11 22:11:15.899]  Generated 32 batches of size 32 in 1.796 sec
[2020-05-11 22:11:18.266]  Step 146299  [3.247 sec/step, loss=0.09632, avg_loss=0.09268, mel_loss=0.04409, linear_loss=0.05223]
[2020-05-11 22:11:31.330]  Step 146300  [3.313 sec/step, loss=0.08549, avg_loss=0.09253, mel_loss=0.04106, linear_loss=0.04443]
[2020-05-11 22:11:31.330]  Writing summary at step: 146300
[2020-05-11 22:11:36.458]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146300
[2020-05-11 22:11:37.872]  Saving audio and alignment...
[2020-05-11 22:11:40.908]  Input: 어 궁금증을 좀 불러 이르키게~_____
[2020-05-11 22:11:45.332]  Step 146301  [3.321 sec/step, loss=0.10079, avg_loss=0.09254, mel_loss=0.04639, linear_loss=0.05440]
[2020-05-11 22:11:47.152]  Step 146302  [3.292 sec/step, loss=0.09186, avg_loss=0.09245, mel_loss=0.04089, linear_loss=0.05097]
[2020-05-11 22:11:50.556]  Step 146303  [3.316 sec/step, loss=0.09595, avg_loss=0.09256, mel_loss=0.04377, linear_loss=0.05218]
[2020-05-11 22:11:53.425]  Step 146304  [3.302 sec/step, loss=0.09790, avg_loss=0.09255, mel_loss=0.04456, linear_loss=0.05334]
[2020-05-11 22:11:55.421]  Step 146305  [3.304 sec/step, loss=0.09394, avg_loss=0.09258, mel_loss=0.04211, linear_loss=0.05184]
[2020-05-11 22:12:02.928]  Step 146306  [3.358 sec/step, loss=0.10141, avg_loss=0.09265, mel_loss=0.04762, linear_loss=0.05379]
[2020-05-11 22:12:05.176]  Step 146307  [3.346 sec/step, loss=0.09634, avg_loss=0.09264, mel_loss=0.04374, linear_loss=0.05260]
[2020-05-11 22:12:06.681]  Step 146308  [3.353 sec/step, loss=0.08881, avg_loss=0.09280, mel_loss=0.03926, linear_loss=0.04956]
[2020-05-11 22:12:10.258]  Step 146309  [3.336 sec/step, loss=0.10003, avg_loss=0.09280, mel_loss=0.04561, linear_loss=0.05441]
[2020-05-11 22:12:11.484]  Step 146310  [3.338 sec/step, loss=0.08834, avg_loss=0.09285, mel_loss=0.03906, linear_loss=0.04927]
[2020-05-11 22:12:18.155]  Step 146311  [3.385 sec/step, loss=0.10046, avg_loss=0.09292, mel_loss=0.04667, linear_loss=0.05380]
[2020-05-11 22:12:19.259]  Step 146312  [3.311 sec/step, loss=0.08689, avg_loss=0.09281, mel_loss=0.03819, linear_loss=0.04870]
[2020-05-11 22:12:20.279]  Step 146313  [3.248 sec/step, loss=0.08419, avg_loss=0.09264, mel_loss=0.03703, linear_loss=0.04716]
[2020-05-11 22:12:24.064]  Step 146314  [3.257 sec/step, loss=0.10030, avg_loss=0.09268, mel_loss=0.04597, linear_loss=0.05432]
[2020-05-11 22:12:32.872]  Step 146315  [3.332 sec/step, loss=0.09967, avg_loss=0.09278, mel_loss=0.04719, linear_loss=0.05248]
[2020-05-11 22:12:34.639]  Step 146316  [3.308 sec/step, loss=0.09322, avg_loss=0.09272, mel_loss=0.04151, linear_loss=0.05171]
[2020-05-11 22:12:35.648]  Step 146317  [3.303 sec/step, loss=0.08175, avg_loss=0.09262, mel_loss=0.03565, linear_loss=0.04610]
[2020-05-11 22:12:37.801]  Step 146318  [3.307 sec/step, loss=0.09400, avg_loss=0.09263, mel_loss=0.04265, linear_loss=0.05136]
[2020-05-11 22:12:39.143]  Step 146319  [3.310 sec/step, loss=0.08690, avg_loss=0.09264, mel_loss=0.03879, linear_loss=0.04812]
[2020-05-11 22:12:39.703]  Step 146320  [3.291 sec/step, loss=0.07144, avg_loss=0.09240, mel_loss=0.03221, linear_loss=0.03922]
[2020-05-11 22:12:45.009]  Step 146321  [3.307 sec/step, loss=0.10020, avg_loss=0.09241, mel_loss=0.04636, linear_loss=0.05383]
[2020-05-11 22:12:45.902]  Step 146322  [3.273 sec/step, loss=0.07903, avg_loss=0.09221, mel_loss=0.03468, linear_loss=0.04435]
[2020-05-11 22:12:48.508]  Step 146323  [3.192 sec/step, loss=0.09538, avg_loss=0.09218, mel_loss=0.04272, linear_loss=0.05266]
[2020-05-11 22:12:52.028]  Step 146324  [3.180 sec/step, loss=0.09608, avg_loss=0.09216, mel_loss=0.04378, linear_loss=0.05230]
[2020-05-11 22:12:53.470]  Step 146325  [3.134 sec/step, loss=0.09047, avg_loss=0.09206, mel_loss=0.04035, linear_loss=0.05011]
[2020-05-11 22:12:57.717]  Step 146326  [3.160 sec/step, loss=0.09870, avg_loss=0.09215, mel_loss=0.04547, linear_loss=0.05323]
[2020-05-11 22:13:00.572]  Step 146327  [3.165 sec/step, loss=0.09694, avg_loss=0.09217, mel_loss=0.04393, linear_loss=0.05301]
[2020-05-11 22:13:02.275]  Step 146328  [3.091 sec/step, loss=0.09317, avg_loss=0.09210, mel_loss=0.04155, linear_loss=0.05162]
[2020-05-11 22:13:02.334]  Generated 32 batches of size 32 in 1.756 sec
[2020-05-11 22:13:05.333]  Step 146329  [3.095 sec/step, loss=0.09849, avg_loss=0.09212, mel_loss=0.04457, linear_loss=0.05392]
[2020-05-11 22:13:09.882]  Step 146330  [3.131 sec/step, loss=0.10010, avg_loss=0.09230, mel_loss=0.04599, linear_loss=0.05411]
[2020-05-11 22:13:13.257]  Step 146331  [3.127 sec/step, loss=0.10117, avg_loss=0.09234, mel_loss=0.04605, linear_loss=0.05513]
[2020-05-11 22:13:15.853]  Step 146332  [3.145 sec/step, loss=0.09816, avg_loss=0.09255, mel_loss=0.04466, linear_loss=0.05349]
[2020-05-11 22:13:17.700]  Step 146333  [3.128 sec/step, loss=0.09293, avg_loss=0.09248, mel_loss=0.04126, linear_loss=0.05167]
[2020-05-11 22:13:23.288]  Step 146334  [3.170 sec/step, loss=0.10028, avg_loss=0.09257, mel_loss=0.04640, linear_loss=0.05388]
[2020-05-11 22:13:36.370]  Step 146335  [3.168 sec/step, loss=0.08505, avg_loss=0.09257, mel_loss=0.04067, linear_loss=0.04437]
[2020-05-11 22:13:37.185]  Step 146336  [3.168 sec/step, loss=0.07924, avg_loss=0.09259, mel_loss=0.03479, linear_loss=0.04445]
[2020-05-11 22:13:39.669]  Step 146337  [3.180 sec/step, loss=0.09394, avg_loss=0.09265, mel_loss=0.04220, linear_loss=0.05174]
[2020-05-11 22:13:42.391]  Step 146338  [3.185 sec/step, loss=0.09332, avg_loss=0.09265, mel_loss=0.04207, linear_loss=0.05125]
[2020-05-11 22:13:46.416]  Step 146339  [3.220 sec/step, loss=0.09886, avg_loss=0.09287, mel_loss=0.04510, linear_loss=0.05377]
[2020-05-11 22:13:51.286]  Step 146340  [3.249 sec/step, loss=0.09907, avg_loss=0.09291, mel_loss=0.04586, linear_loss=0.05321]
[2020-05-11 22:13:58.023]  Step 146341  [3.265 sec/step, loss=0.09848, avg_loss=0.09290, mel_loss=0.04575, linear_loss=0.05273]
[2020-05-11 22:13:59.476]  Step 146342  [3.261 sec/step, loss=0.08698, avg_loss=0.09287, mel_loss=0.03842, linear_loss=0.04857]
[2020-05-11 22:14:00.546]  Step 146343  [3.226 sec/step, loss=0.08156, avg_loss=0.09267, mel_loss=0.03612, linear_loss=0.04544]
[2020-05-11 22:14:01.774]  Step 146344  [3.228 sec/step, loss=0.08875, avg_loss=0.09271, mel_loss=0.03942, linear_loss=0.04933]
[2020-05-11 22:14:04.725]  Step 146345  [3.193 sec/step, loss=0.10159, avg_loss=0.09272, mel_loss=0.04626, linear_loss=0.05533]
[2020-05-11 22:14:06.843]  Step 146346  [3.160 sec/step, loss=0.09551, avg_loss=0.09267, mel_loss=0.04277, linear_loss=0.05274]
[2020-05-11 22:14:13.735]  Step 146347  [3.213 sec/step, loss=0.10135, avg_loss=0.09276, mel_loss=0.04729, linear_loss=0.05406]
[2020-05-11 22:14:21.792]  Step 146348  [3.279 sec/step, loss=0.09893, avg_loss=0.09286, mel_loss=0.04663, linear_loss=0.05230]
[2020-05-11 22:14:22.824]  Step 146349  [3.264 sec/step, loss=0.08154, avg_loss=0.09275, mel_loss=0.03562, linear_loss=0.04592]
[2020-05-11 22:14:27.402]  Step 146350  [3.168 sec/step, loss=0.10034, avg_loss=0.09295, mel_loss=0.04618, linear_loss=0.05415]
[2020-05-11 22:14:27.402]  Writing summary at step: 146350
[2020-05-11 22:14:28.847]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146350
[2020-05-11 22:14:30.227]  Saving audio and alignment...
[2020-05-11 22:14:38.061]  Input: 땡땡 기업이 클래식 음악을 대중화라는 기치를 내걸고 시작한 엘지 콘서트 역시~_______________________
[2020-05-11 22:14:38.905]  Step 146351  [3.148 sec/step, loss=0.07832, avg_loss=0.09278, mel_loss=0.03456, linear_loss=0.04376]
[2020-05-11 22:14:40.559]  Step 146352  [3.123 sec/step, loss=0.08960, avg_loss=0.09267, mel_loss=0.04033, linear_loss=0.04927]
[2020-05-11 22:14:41.618]  Step 146353  [3.101 sec/step, loss=0.08922, avg_loss=0.09257, mel_loss=0.03899, linear_loss=0.05024]
[2020-05-11 22:14:55.575]  Step 146354  [3.217 sec/step, loss=0.07522, avg_loss=0.09238, mel_loss=0.03602, linear_loss=0.03920]
[2020-05-11 22:14:59.046]  Step 146355  [3.175 sec/step, loss=0.09664, avg_loss=0.09234, mel_loss=0.04415, linear_loss=0.05249]
[2020-05-11 22:15:00.828]  Step 146356  [3.182 sec/step, loss=0.09224, avg_loss=0.09241, mel_loss=0.04132, linear_loss=0.05092]
[2020-05-11 22:15:01.382]  Step 146357  [3.143 sec/step, loss=0.07274, avg_loss=0.09214, mel_loss=0.03244, linear_loss=0.04030]
[2020-05-11 22:15:03.111]  Step 146358  [3.153 sec/step, loss=0.09358, avg_loss=0.09228, mel_loss=0.04127, linear_loss=0.05231]
[2020-05-11 22:15:03.143]  Generated 32 batches of size 32 in 1.754 sec
[2020-05-11 22:15:06.102]  Step 146359  [3.165 sec/step, loss=0.09787, avg_loss=0.09233, mel_loss=0.04431, linear_loss=0.05356]
[2020-05-11 22:15:08.040]  Step 146360  [3.096 sec/step, loss=0.09325, avg_loss=0.09226, mel_loss=0.04175, linear_loss=0.05150]
[2020-05-11 22:15:11.619]  Step 146361  [3.112 sec/step, loss=0.09993, avg_loss=0.09234, mel_loss=0.04559, linear_loss=0.05434]
[2020-05-11 22:15:13.578]  Step 146362  [3.112 sec/step, loss=0.09432, avg_loss=0.09234, mel_loss=0.04205, linear_loss=0.05226]
[2020-05-11 22:15:17.680]  Step 146363  [3.116 sec/step, loss=0.10041, avg_loss=0.09234, mel_loss=0.04623, linear_loss=0.05419]
[2020-05-11 22:15:20.567]  Step 146364  [3.130 sec/step, loss=0.09524, avg_loss=0.09239, mel_loss=0.04318, linear_loss=0.05206]
[2020-05-11 22:15:21.355]  Step 146365  [3.131 sec/step, loss=0.07627, avg_loss=0.09235, mel_loss=0.03339, linear_loss=0.04289]
[2020-05-11 22:15:23.609]  Step 146366  [3.139 sec/step, loss=0.09321, avg_loss=0.09238, mel_loss=0.04212, linear_loss=0.05109]
[2020-05-11 22:15:25.096]  Step 146367  [3.144 sec/step, loss=0.09179, avg_loss=0.09244, mel_loss=0.04093, linear_loss=0.05086]
[2020-05-11 22:15:25.936]  Step 146368  [3.124 sec/step, loss=0.07682, avg_loss=0.09222, mel_loss=0.03424, linear_loss=0.04258]
[2020-05-11 22:15:26.489]  Step 146369  [3.108 sec/step, loss=0.07196, avg_loss=0.09199, mel_loss=0.03189, linear_loss=0.04007]
[2020-05-11 22:15:27.278]  Step 146370  [3.081 sec/step, loss=0.08015, avg_loss=0.09182, mel_loss=0.03519, linear_loss=0.04495]
[2020-05-11 22:15:28.108]  Step 146371  [3.082 sec/step, loss=0.08055, avg_loss=0.09189, mel_loss=0.03503, linear_loss=0.04552]
[2020-05-11 22:15:30.148]  Step 146372  [3.068 sec/step, loss=0.09148, avg_loss=0.09181, mel_loss=0.04115, linear_loss=0.05032]
[2020-05-11 22:15:36.335]  Step 146373  [3.117 sec/step, loss=0.09736, avg_loss=0.09192, mel_loss=0.04557, linear_loss=0.05179]
[2020-05-11 22:15:38.210]  Step 146374  [3.127 sec/step, loss=0.08912, avg_loss=0.09199, mel_loss=0.03959, linear_loss=0.04953]
[2020-05-11 22:15:41.586]  Step 146375  [3.136 sec/step, loss=0.09830, avg_loss=0.09203, mel_loss=0.04470, linear_loss=0.05360]
[2020-05-11 22:15:43.922]  Step 146376  [3.118 sec/step, loss=0.09581, avg_loss=0.09201, mel_loss=0.04315, linear_loss=0.05266]
[2020-05-11 22:15:52.676]  Step 146377  [3.196 sec/step, loss=0.09886, avg_loss=0.09215, mel_loss=0.04671, linear_loss=0.05215]
[2020-05-11 22:15:53.986]  Step 146378  [3.173 sec/step, loss=0.08678, avg_loss=0.09204, mel_loss=0.03840, linear_loss=0.04838]
[2020-05-11 22:15:57.432]  Step 146379  [3.185 sec/step, loss=0.10018, avg_loss=0.09209, mel_loss=0.04570, linear_loss=0.05448]
[2020-05-11 22:16:03.076]  Step 146380  [3.220 sec/step, loss=0.09951, avg_loss=0.09215, mel_loss=0.04605, linear_loss=0.05346]
[2020-05-11 22:16:17.338]  Step 146381  [3.276 sec/step, loss=0.07843, avg_loss=0.09194, mel_loss=0.03771, linear_loss=0.04072]
[2020-05-11 22:16:20.935]  Step 146382  [3.235 sec/step, loss=0.09953, avg_loss=0.09193, mel_loss=0.04522, linear_loss=0.05431]
[2020-05-11 22:16:25.198]  Step 146383  [3.238 sec/step, loss=0.09920, avg_loss=0.09191, mel_loss=0.04550, linear_loss=0.05369]
[2020-05-11 22:16:26.250]  Step 146384  [3.237 sec/step, loss=0.08549, avg_loss=0.09191, mel_loss=0.03743, linear_loss=0.04806]
[2020-05-11 22:16:28.956]  Step 146385  [3.232 sec/step, loss=0.09721, avg_loss=0.09190, mel_loss=0.04405, linear_loss=0.05316]
[2020-05-11 22:16:30.098]  Step 146386  [3.238 sec/step, loss=0.08666, avg_loss=0.09202, mel_loss=0.03784, linear_loss=0.04881]
[2020-05-11 22:16:34.147]  Step 146387  [3.231 sec/step, loss=0.10027, avg_loss=0.09202, mel_loss=0.04574, linear_loss=0.05454]
[2020-05-11 22:16:37.296]  Step 146388  [3.246 sec/step, loss=0.09800, avg_loss=0.09207, mel_loss=0.04450, linear_loss=0.05350]
[2020-05-11 22:16:38.651]  Step 146389  [3.203 sec/step, loss=0.08962, avg_loss=0.09196, mel_loss=0.03972, linear_loss=0.04990]
[2020-05-11 22:16:40.376]  Generated 32 batches of size 32 in 1.719 sec
[2020-05-11 22:16:41.622]  Step 146390  [3.220 sec/step, loss=0.09930, avg_loss=0.09207, mel_loss=0.04501, linear_loss=0.05430]
[2020-05-11 22:16:42.566]  Step 146391  [3.162 sec/step, loss=0.08500, avg_loss=0.09189, mel_loss=0.03750, linear_loss=0.04750]
[2020-05-11 22:16:44.982]  Step 146392  [3.178 sec/step, loss=0.09378, avg_loss=0.09201, mel_loss=0.04220, linear_loss=0.05159]
[2020-05-11 22:16:50.178]  Step 146393  [3.209 sec/step, loss=0.09837, avg_loss=0.09206, mel_loss=0.04529, linear_loss=0.05308]
[2020-05-11 22:16:57.806]  Step 146394  [3.274 sec/step, loss=0.09984, avg_loss=0.09216, mel_loss=0.04672, linear_loss=0.05312]
[2020-05-11 22:16:59.925]  Step 146395  [3.276 sec/step, loss=0.09453, avg_loss=0.09217, mel_loss=0.04243, linear_loss=0.05210]
[2020-05-11 22:17:01.705]  Step 146396  [3.280 sec/step, loss=0.09173, avg_loss=0.09220, mel_loss=0.04095, linear_loss=0.05078]
[2020-05-11 22:17:03.400]  Step 146397  [3.290 sec/step, loss=0.09079, avg_loss=0.09235, mel_loss=0.04052, linear_loss=0.05028]
[2020-05-11 22:17:07.913]  Step 146398  [3.320 sec/step, loss=0.10090, avg_loss=0.09247, mel_loss=0.04656, linear_loss=0.05434]
[2020-05-11 22:17:15.228]  Step 146399  [3.367 sec/step, loss=0.10102, avg_loss=0.09252, mel_loss=0.04684, linear_loss=0.05418]
[2020-05-11 22:17:19.134]  Step 146400  [3.275 sec/step, loss=0.09586, avg_loss=0.09262, mel_loss=0.04276, linear_loss=0.05310]
[2020-05-11 22:17:19.134]  Writing summary at step: 146400
[2020-05-11 22:17:22.218]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146400
[2020-05-11 22:17:25.255]  Saving audio and alignment...
[2020-05-11 22:17:34.415]  Input: 음악은요 듣는 사람의 귀를 즐겁게 하고 마음에 감동을 주는 예술장르죠 그런 면에서~_________________________
[2020-05-11 22:17:36.461]  Step 146401  [3.252 sec/step, loss=0.09478, avg_loss=0.09256, mel_loss=0.04240, linear_loss=0.05239]
[2020-05-11 22:17:37.450]  Step 146402  [3.243 sec/step, loss=0.08082, avg_loss=0.09245, mel_loss=0.03556, linear_loss=0.04526]
[2020-05-11 22:17:39.703]  Step 146403  [3.232 sec/step, loss=0.09533, avg_loss=0.09244, mel_loss=0.04301, linear_loss=0.05232]
[2020-05-11 22:17:54.124]  Step 146404  [3.347 sec/step, loss=0.07812, avg_loss=0.09225, mel_loss=0.03774, linear_loss=0.04038]
[2020-05-11 22:17:56.958]  Step 146405  [3.356 sec/step, loss=0.09475, avg_loss=0.09225, mel_loss=0.04246, linear_loss=0.05229]
[2020-05-11 22:17:58.433]  Step 146406  [3.295 sec/step, loss=0.09025, avg_loss=0.09214, mel_loss=0.04025, linear_loss=0.05000]
[2020-05-11 22:18:00.163]  Step 146407  [3.290 sec/step, loss=0.08995, avg_loss=0.09208, mel_loss=0.03992, linear_loss=0.05003]
[2020-05-11 22:18:01.473]  Step 146408  [3.288 sec/step, loss=0.08696, avg_loss=0.09206, mel_loss=0.03839, linear_loss=0.04857]
[2020-05-11 22:18:02.324]  Step 146409  [3.261 sec/step, loss=0.08090, avg_loss=0.09187, mel_loss=0.03541, linear_loss=0.04549]
[2020-05-11 22:18:06.135]  Step 146410  [3.287 sec/step, loss=0.09978, avg_loss=0.09198, mel_loss=0.04557, linear_loss=0.05421]
[2020-05-11 22:18:07.774]  Step 146411  [3.237 sec/step, loss=0.09184, avg_loss=0.09190, mel_loss=0.04096, linear_loss=0.05087]
[2020-05-11 22:18:09.122]  Step 146412  [3.239 sec/step, loss=0.08842, avg_loss=0.09191, mel_loss=0.03934, linear_loss=0.04908]
[2020-05-11 22:18:13.302]  Step 146413  [3.271 sec/step, loss=0.09858, avg_loss=0.09206, mel_loss=0.04510, linear_loss=0.05348]
[2020-05-11 22:18:16.484]  Step 146414  [3.265 sec/step, loss=0.09720, avg_loss=0.09203, mel_loss=0.04406, linear_loss=0.05314]
[2020-05-11 22:18:19.380]  Step 146415  [3.205 sec/step, loss=0.09762, avg_loss=0.09200, mel_loss=0.04404, linear_loss=0.05358]
[2020-05-11 22:18:23.756]  Step 146416  [3.232 sec/step, loss=0.10067, avg_loss=0.09208, mel_loss=0.04630, linear_loss=0.05438]
[2020-05-11 22:18:32.543]  Step 146417  [3.309 sec/step, loss=0.10042, avg_loss=0.09227, mel_loss=0.04731, linear_loss=0.05310]
[2020-05-11 22:18:33.649]  Step 146418  [3.299 sec/step, loss=0.08712, avg_loss=0.09220, mel_loss=0.03825, linear_loss=0.04887]
[2020-05-11 22:18:38.770]  Step 146419  [3.337 sec/step, loss=0.10102, avg_loss=0.09234, mel_loss=0.04667, linear_loss=0.05435]
[2020-05-11 22:18:40.563]  Generated 32 batches of size 32 in 1.787 sec
[2020-05-11 22:18:40.690]  Step 146420  [3.350 sec/step, loss=0.08978, avg_loss=0.09252, mel_loss=0.03984, linear_loss=0.04994]
[2020-05-11 22:18:44.121]  Step 146421  [3.331 sec/step, loss=0.09774, avg_loss=0.09250, mel_loss=0.04456, linear_loss=0.05318]
[2020-05-11 22:18:44.913]  Step 146422  [3.330 sec/step, loss=0.07594, avg_loss=0.09247, mel_loss=0.03306, linear_loss=0.04289]
[2020-05-11 22:18:45.470]  Step 146423  [3.310 sec/step, loss=0.07718, avg_loss=0.09228, mel_loss=0.03498, linear_loss=0.04220]
[2020-05-11 22:18:50.040]  Step 146424  [3.320 sec/step, loss=0.10074, avg_loss=0.09233, mel_loss=0.04606, linear_loss=0.05468]
[2020-05-11 22:18:57.383]  Step 146425  [3.379 sec/step, loss=0.09940, avg_loss=0.09242, mel_loss=0.04645, linear_loss=0.05296]
[2020-05-11 22:18:59.581]  Step 146426  [3.359 sec/step, loss=0.09353, avg_loss=0.09237, mel_loss=0.04194, linear_loss=0.05158]
[2020-05-11 22:19:00.631]  Step 146427  [3.341 sec/step, loss=0.08408, avg_loss=0.09224, mel_loss=0.03714, linear_loss=0.04694]
[2020-05-11 22:19:04.316]  Step 146428  [3.361 sec/step, loss=0.09679, avg_loss=0.09228, mel_loss=0.04388, linear_loss=0.05290]
[2020-05-11 22:19:07.856]  Step 146429  [3.366 sec/step, loss=0.09822, avg_loss=0.09227, mel_loss=0.04483, linear_loss=0.05339]
[2020-05-11 22:19:12.214]  Step 146430  [3.364 sec/step, loss=0.09642, avg_loss=0.09224, mel_loss=0.04424, linear_loss=0.05218]
[2020-05-11 22:19:14.485]  Step 146431  [3.353 sec/step, loss=0.09364, avg_loss=0.09216, mel_loss=0.04231, linear_loss=0.05133]
[2020-05-11 22:19:16.967]  Step 146432  [3.351 sec/step, loss=0.09346, avg_loss=0.09211, mel_loss=0.04192, linear_loss=0.05155]
[2020-05-11 22:19:18.364]  Step 146433  [3.347 sec/step, loss=0.08890, avg_loss=0.09207, mel_loss=0.03942, linear_loss=0.04948]
[2020-05-11 22:19:19.685]  Step 146434  [3.304 sec/step, loss=0.08981, avg_loss=0.09197, mel_loss=0.03966, linear_loss=0.05015]
[2020-05-11 22:19:28.239]  Step 146435  [3.259 sec/step, loss=0.09814, avg_loss=0.09210, mel_loss=0.04609, linear_loss=0.05205]
[2020-05-11 22:19:28.779]  Step 146436  [3.256 sec/step, loss=0.07816, avg_loss=0.09209, mel_loss=0.03446, linear_loss=0.04370]
[2020-05-11 22:19:29.914]  Step 146437  [3.243 sec/step, loss=0.08582, avg_loss=0.09201, mel_loss=0.03774, linear_loss=0.04808]
[2020-05-11 22:19:36.616]  Step 146438  [3.283 sec/step, loss=0.09993, avg_loss=0.09207, mel_loss=0.04662, linear_loss=0.05331]
[2020-05-11 22:19:38.554]  Step 146439  [3.262 sec/step, loss=0.09284, avg_loss=0.09201, mel_loss=0.04132, linear_loss=0.05152]
[2020-05-11 22:19:40.299]  Step 146440  [3.230 sec/step, loss=0.08987, avg_loss=0.09192, mel_loss=0.04029, linear_loss=0.04957]
[2020-05-11 22:19:43.156]  Step 146441  [3.192 sec/step, loss=0.09638, avg_loss=0.09190, mel_loss=0.04386, linear_loss=0.05253]
[2020-05-11 22:19:46.508]  Step 146442  [3.211 sec/step, loss=0.09936, avg_loss=0.09203, mel_loss=0.04505, linear_loss=0.05431]
[2020-05-11 22:19:52.173]  Step 146443  [3.257 sec/step, loss=0.09998, avg_loss=0.09221, mel_loss=0.04645, linear_loss=0.05353]
[2020-05-11 22:19:53.925]  Step 146444  [3.262 sec/step, loss=0.09362, avg_loss=0.09226, mel_loss=0.04155, linear_loss=0.05207]
[2020-05-11 22:20:01.506]  Step 146445  [3.308 sec/step, loss=0.10122, avg_loss=0.09225, mel_loss=0.04755, linear_loss=0.05367]
[2020-05-11 22:20:14.545]  Step 146446  [3.417 sec/step, loss=0.08566, avg_loss=0.09216, mel_loss=0.04098, linear_loss=0.04468]
[2020-05-11 22:20:19.668]  Step 146447  [3.400 sec/step, loss=0.10097, avg_loss=0.09215, mel_loss=0.04668, linear_loss=0.05429]
[2020-05-11 22:20:20.552]  Step 146448  [3.328 sec/step, loss=0.08412, avg_loss=0.09200, mel_loss=0.03681, linear_loss=0.04731]
[2020-05-11 22:20:22.052]  Step 146449  [3.333 sec/step, loss=0.09096, avg_loss=0.09210, mel_loss=0.04037, linear_loss=0.05059]
[2020-05-11 22:20:25.831]  Step 146450  [3.325 sec/step, loss=0.09870, avg_loss=0.09208, mel_loss=0.04498, linear_loss=0.05372]
[2020-05-11 22:20:25.831]  Writing summary at step: 146450
[2020-05-11 22:20:26.866]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146450
[2020-05-11 22:20:28.246]  Saving audio and alignment...
[2020-05-11 22:20:30.304]  Generated 32 batches of size 32 in 1.503 sec
[2020-05-11 22:20:30.471]  Input: 되셨습니까~______________________
[2020-05-11 22:20:32.674]  Step 146451  [3.338 sec/step, loss=0.09459, avg_loss=0.09224, mel_loss=0.04255, linear_loss=0.05203]
[2020-05-11 22:20:33.853]  Step 146452  [3.333 sec/step, loss=0.08898, avg_loss=0.09224, mel_loss=0.03934, linear_loss=0.04964]
[2020-05-11 22:20:36.522]  Step 146453  [3.350 sec/step, loss=0.09625, avg_loss=0.09231, mel_loss=0.04342, linear_loss=0.05283]
[2020-05-11 22:20:37.349]  Step 146454  [3.218 sec/step, loss=0.07766, avg_loss=0.09233, mel_loss=0.03400, linear_loss=0.04366]
[2020-05-11 22:20:40.939]  Step 146455  [3.219 sec/step, loss=0.09926, avg_loss=0.09236, mel_loss=0.04538, linear_loss=0.05388]
[2020-05-11 22:20:43.268]  Step 146456  [3.225 sec/step, loss=0.09451, avg_loss=0.09238, mel_loss=0.04223, linear_loss=0.05228]
[2020-05-11 22:20:47.863]  Step 146457  [3.265 sec/step, loss=0.10138, avg_loss=0.09267, mel_loss=0.04665, linear_loss=0.05473]
[2020-05-11 22:20:50.844]  Step 146458  [3.278 sec/step, loss=0.09927, avg_loss=0.09273, mel_loss=0.04531, linear_loss=0.05396]
[2020-05-11 22:20:53.255]  Step 146459  [3.272 sec/step, loss=0.09295, avg_loss=0.09268, mel_loss=0.04155, linear_loss=0.05140]
[2020-05-11 22:20:56.845]  Step 146460  [3.289 sec/step, loss=0.10136, avg_loss=0.09276, mel_loss=0.04626, linear_loss=0.05510]
[2020-05-11 22:20:58.197]  Step 146461  [3.266 sec/step, loss=0.08664, avg_loss=0.09262, mel_loss=0.03849, linear_loss=0.04815]
[2020-05-11 22:21:00.192]  Step 146462  [3.267 sec/step, loss=0.09322, avg_loss=0.09261, mel_loss=0.04181, linear_loss=0.05142]
[2020-05-11 22:21:00.943]  Step 146463  [3.233 sec/step, loss=0.07358, avg_loss=0.09234, mel_loss=0.03305, linear_loss=0.04053]
[2020-05-11 22:21:04.996]  Step 146464  [3.245 sec/step, loss=0.09832, avg_loss=0.09238, mel_loss=0.04485, linear_loss=0.05347]
[2020-05-11 22:21:09.107]  Step 146465  [3.278 sec/step, loss=0.09898, avg_loss=0.09260, mel_loss=0.04542, linear_loss=0.05356]
[2020-05-11 22:21:09.992]  Step 146466  [3.264 sec/step, loss=0.08191, avg_loss=0.09249, mel_loss=0.03606, linear_loss=0.04586]
[2020-05-11 22:21:14.588]  Step 146467  [3.295 sec/step, loss=0.10129, avg_loss=0.09258, mel_loss=0.04663, linear_loss=0.05466]
[2020-05-11 22:21:17.986]  Step 146468  [3.321 sec/step, loss=0.09626, avg_loss=0.09278, mel_loss=0.04379, linear_loss=0.05247]
[2020-05-11 22:21:20.082]  Step 146469  [3.336 sec/step, loss=0.09404, avg_loss=0.09300, mel_loss=0.04219, linear_loss=0.05185]
[2020-05-11 22:21:21.464]  Step 146470  [3.342 sec/step, loss=0.08943, avg_loss=0.09309, mel_loss=0.03999, linear_loss=0.04944]
[2020-05-11 22:21:22.685]  Step 146471  [3.346 sec/step, loss=0.08954, avg_loss=0.09318, mel_loss=0.03965, linear_loss=0.04988]
[2020-05-11 22:21:23.457]  Step 146472  [3.334 sec/step, loss=0.08106, avg_loss=0.09308, mel_loss=0.03548, linear_loss=0.04557]
[2020-05-11 22:21:30.149]  Step 146473  [3.339 sec/step, loss=0.10059, avg_loss=0.09311, mel_loss=0.04696, linear_loss=0.05362]
[2020-05-11 22:21:31.857]  Step 146474  [3.337 sec/step, loss=0.09404, avg_loss=0.09316, mel_loss=0.04167, linear_loss=0.05237]
[2020-05-11 22:21:34.059]  Step 146475  [3.325 sec/step, loss=0.09221, avg_loss=0.09310, mel_loss=0.04155, linear_loss=0.05066]
[2020-05-11 22:21:39.682]  Step 146476  [3.358 sec/step, loss=0.09941, avg_loss=0.09314, mel_loss=0.04610, linear_loss=0.05332]
[2020-05-11 22:21:40.498]  Step 146477  [3.279 sec/step, loss=0.07689, avg_loss=0.09292, mel_loss=0.03347, linear_loss=0.04342]
[2020-05-11 22:21:43.533]  Step 146478  [3.296 sec/step, loss=0.09730, avg_loss=0.09302, mel_loss=0.04414, linear_loss=0.05317]
[2020-05-11 22:21:45.218]  Step 146479  [3.278 sec/step, loss=0.09250, avg_loss=0.09294, mel_loss=0.04107, linear_loss=0.05143]
[2020-05-11 22:21:48.067]  Step 146480  [3.250 sec/step, loss=0.09697, avg_loss=0.09292, mel_loss=0.04394, linear_loss=0.05302]
[2020-05-11 22:22:01.128]  Step 146481  [3.238 sec/step, loss=0.08426, avg_loss=0.09298, mel_loss=0.04025, linear_loss=0.04401]
[2020-05-11 22:22:02.824]  Step 146482  [3.219 sec/step, loss=0.09210, avg_loss=0.09290, mel_loss=0.04104, linear_loss=0.05106]
[2020-05-11 22:22:03.025]  Generated 32 batches of size 32 in 1.891 sec
[2020-05-11 22:22:04.768]  Step 146483  [3.196 sec/step, loss=0.09166, avg_loss=0.09283, mel_loss=0.04075, linear_loss=0.05092]
[2020-05-11 22:22:05.867]  Step 146484  [3.197 sec/step, loss=0.08779, avg_loss=0.09285, mel_loss=0.03838, linear_loss=0.04941]
[2020-05-11 22:22:13.318]  Step 146485  [3.244 sec/step, loss=0.09926, avg_loss=0.09287, mel_loss=0.04636, linear_loss=0.05290]
[2020-05-11 22:22:14.343]  Step 146486  [3.243 sec/step, loss=0.08563, avg_loss=0.09286, mel_loss=0.03786, linear_loss=0.04777]
[2020-05-11 22:22:23.145]  Step 146487  [3.291 sec/step, loss=0.09955, avg_loss=0.09285, mel_loss=0.04677, linear_loss=0.05278]
[2020-05-11 22:22:28.123]  Step 146488  [3.309 sec/step, loss=0.09761, avg_loss=0.09285, mel_loss=0.04503, linear_loss=0.05258]
[2020-05-11 22:22:30.826]  Step 146489  [3.322 sec/step, loss=0.09572, avg_loss=0.09291, mel_loss=0.04312, linear_loss=0.05260]
[2020-05-11 22:22:34.067]  Step 146490  [3.325 sec/step, loss=0.09917, avg_loss=0.09291, mel_loss=0.04514, linear_loss=0.05403]
[2020-05-11 22:22:38.775]  Step 146491  [3.363 sec/step, loss=0.09995, avg_loss=0.09306, mel_loss=0.04590, linear_loss=0.05404]
[2020-05-11 22:22:40.169]  Step 146492  [3.352 sec/step, loss=0.08833, avg_loss=0.09300, mel_loss=0.03912, linear_loss=0.04921]
[2020-05-11 22:22:42.629]  Step 146493  [3.325 sec/step, loss=0.09451, avg_loss=0.09297, mel_loss=0.04235, linear_loss=0.05216]
[2020-05-11 22:22:48.005]  Step 146494  [3.303 sec/step, loss=0.09928, avg_loss=0.09296, mel_loss=0.04582, linear_loss=0.05347]
[2020-05-11 22:22:49.163]  Step 146495  [3.293 sec/step, loss=0.08606, avg_loss=0.09287, mel_loss=0.03784, linear_loss=0.04822]
[2020-05-11 22:22:52.544]  Step 146496  [3.309 sec/step, loss=0.10084, avg_loss=0.09297, mel_loss=0.04578, linear_loss=0.05506]
[2020-05-11 22:22:54.793]  Step 146497  [3.314 sec/step, loss=0.09513, avg_loss=0.09301, mel_loss=0.04284, linear_loss=0.05229]
[2020-05-11 22:23:00.036]  Step 146498  [3.322 sec/step, loss=0.09910, avg_loss=0.09299, mel_loss=0.04618, linear_loss=0.05292]
[2020-05-11 22:23:00.565]  Step 146499  [3.254 sec/step, loss=0.07348, avg_loss=0.09272, mel_loss=0.03287, linear_loss=0.04061]
[2020-05-11 22:23:04.855]  Step 146500  [3.258 sec/step, loss=0.09872, avg_loss=0.09274, mel_loss=0.04511, linear_loss=0.05362]
[2020-05-11 22:23:04.856]  Writing summary at step: 146500
[2020-05-11 22:23:11.588]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146500
[2020-05-11 22:23:13.591]  Saving audio and alignment...
[2020-05-11 22:23:19.043]  Input: 면접용 답변들을 집중적으로 훈련 하겠습니다~_____________________
[2020-05-11 22:23:21.645]  Step 146501  [3.263 sec/step, loss=0.09546, avg_loss=0.09275, mel_loss=0.04329, linear_loss=0.05217]
[2020-05-11 22:23:24.482]  Step 146502  [3.282 sec/step, loss=0.09728, avg_loss=0.09292, mel_loss=0.04408, linear_loss=0.05320]
[2020-05-11 22:23:26.477]  Step 146503  [3.279 sec/step, loss=0.09272, avg_loss=0.09289, mel_loss=0.04153, linear_loss=0.05119]
[2020-05-11 22:23:30.131]  Step 146504  [3.172 sec/step, loss=0.09838, avg_loss=0.09309, mel_loss=0.04474, linear_loss=0.05365]
[2020-05-11 22:23:30.921]  Step 146505  [3.151 sec/step, loss=0.08277, avg_loss=0.09297, mel_loss=0.03626, linear_loss=0.04651]
[2020-05-11 22:23:32.226]  Step 146506  [3.149 sec/step, loss=0.09127, avg_loss=0.09298, mel_loss=0.04001, linear_loss=0.05126]
[2020-05-11 22:23:46.069]  Step 146507  [3.271 sec/step, loss=0.07762, avg_loss=0.09286, mel_loss=0.03747, linear_loss=0.04016]
[2020-05-11 22:23:47.081]  Step 146508  [3.268 sec/step, loss=0.08328, avg_loss=0.09282, mel_loss=0.03686, linear_loss=0.04642]
[2020-05-11 22:23:48.860]  Step 146509  [3.277 sec/step, loss=0.09183, avg_loss=0.09293, mel_loss=0.04088, linear_loss=0.05095]
[2020-05-11 22:23:50.377]  Step 146510  [3.254 sec/step, loss=0.09001, avg_loss=0.09283, mel_loss=0.03987, linear_loss=0.05014]
[2020-05-11 22:23:54.415]  Step 146511  [3.278 sec/step, loss=0.10079, avg_loss=0.09292, mel_loss=0.04599, linear_loss=0.05480]
[2020-05-11 22:23:56.038]  Generated 32 batches of size 32 in 1.617 sec
[2020-05-11 22:24:01.911]  Step 146512  [3.339 sec/step, loss=0.10222, avg_loss=0.09306, mel_loss=0.04774, linear_loss=0.05449]
[2020-05-11 22:24:04.064]  Step 146513  [3.319 sec/step, loss=0.09470, avg_loss=0.09302, mel_loss=0.04271, linear_loss=0.05199]
[2020-05-11 22:24:05.773]  Step 146514  [3.304 sec/step, loss=0.09098, avg_loss=0.09296, mel_loss=0.04079, linear_loss=0.05019]
[2020-05-11 22:24:07.756]  Step 146515  [3.295 sec/step, loss=0.09264, avg_loss=0.09291, mel_loss=0.04116, linear_loss=0.05148]
[2020-05-11 22:24:10.995]  Step 146516  [3.284 sec/step, loss=0.09871, avg_loss=0.09289, mel_loss=0.04481, linear_loss=0.05391]
[2020-05-11 22:24:11.681]  Step 146517  [3.203 sec/step, loss=0.07615, avg_loss=0.09265, mel_loss=0.03387, linear_loss=0.04229]
[2020-05-11 22:24:20.096]  Step 146518  [3.276 sec/step, loss=0.09770, avg_loss=0.09275, mel_loss=0.04611, linear_loss=0.05159]
[2020-05-11 22:24:21.093]  Step 146519  [3.235 sec/step, loss=0.08379, avg_loss=0.09258, mel_loss=0.03667, linear_loss=0.04712]
[2020-05-11 22:24:22.198]  Step 146520  [3.227 sec/step, loss=0.08521, avg_loss=0.09254, mel_loss=0.03716, linear_loss=0.04805]
[2020-05-11 22:24:24.202]  Step 146521  [3.212 sec/step, loss=0.09374, avg_loss=0.09250, mel_loss=0.04197, linear_loss=0.05177]
[2020-05-11 22:24:27.447]  Step 146522  [3.237 sec/step, loss=0.09885, avg_loss=0.09273, mel_loss=0.04488, linear_loss=0.05397]
[2020-05-11 22:24:36.269]  Step 146523  [3.319 sec/step, loss=0.10047, avg_loss=0.09296, mel_loss=0.04735, linear_loss=0.05312]
[2020-05-11 22:24:39.946]  Step 146524  [3.311 sec/step, loss=0.09857, avg_loss=0.09294, mel_loss=0.04509, linear_loss=0.05348]
[2020-05-11 22:24:41.840]  Step 146525  [3.256 sec/step, loss=0.09058, avg_loss=0.09285, mel_loss=0.04032, linear_loss=0.05026]
[2020-05-11 22:24:45.318]  Step 146526  [3.269 sec/step, loss=0.09749, avg_loss=0.09289, mel_loss=0.04426, linear_loss=0.05323]
[2020-05-11 22:24:46.948]  Step 146527  [3.275 sec/step, loss=0.09179, avg_loss=0.09297, mel_loss=0.04122, linear_loss=0.05057]
[2020-05-11 22:24:51.287]  Step 146528  [3.281 sec/step, loss=0.09938, avg_loss=0.09299, mel_loss=0.04580, linear_loss=0.05358]
[2020-05-11 22:24:52.047]  Step 146529  [3.253 sec/step, loss=0.08333, avg_loss=0.09284, mel_loss=0.03641, linear_loss=0.04692]
[2020-05-11 22:24:56.696]  Step 146530  [3.256 sec/step, loss=0.10008, avg_loss=0.09288, mel_loss=0.04596, linear_loss=0.05411]
[2020-05-11 22:24:57.753]  Step 146531  [3.244 sec/step, loss=0.08714, avg_loss=0.09281, mel_loss=0.03809, linear_loss=0.04904]
[2020-05-11 22:25:00.474]  Step 146532  [3.247 sec/step, loss=0.09707, avg_loss=0.09285, mel_loss=0.04389, linear_loss=0.05317]
[2020-05-11 22:25:01.224]  Step 146533  [3.240 sec/step, loss=0.07896, avg_loss=0.09275, mel_loss=0.03472, linear_loss=0.04424]
[2020-05-11 22:25:02.558]  Step 146534  [3.240 sec/step, loss=0.08863, avg_loss=0.09274, mel_loss=0.03931, linear_loss=0.04932]
[2020-05-11 22:25:05.633]  Step 146535  [3.185 sec/step, loss=0.10000, avg_loss=0.09276, mel_loss=0.04517, linear_loss=0.05483]
[2020-05-11 22:25:07.387]  Step 146536  [3.198 sec/step, loss=0.09226, avg_loss=0.09290, mel_loss=0.04093, linear_loss=0.05133]
[2020-05-11 22:25:11.239]  Step 146537  [3.225 sec/step, loss=0.09819, avg_loss=0.09302, mel_loss=0.04493, linear_loss=0.05326]
[2020-05-11 22:25:12.824]  Step 146538  [3.174 sec/step, loss=0.08953, avg_loss=0.09292, mel_loss=0.03978, linear_loss=0.04974]
[2020-05-11 22:25:13.788]  Step 146539  [3.164 sec/step, loss=0.08285, avg_loss=0.09282, mel_loss=0.03589, linear_loss=0.04697]
[2020-05-11 22:25:15.182]  Step 146540  [3.160 sec/step, loss=0.09034, avg_loss=0.09282, mel_loss=0.04005, linear_loss=0.05029]
[2020-05-11 22:25:20.807]  Step 146541  [3.188 sec/step, loss=0.10096, avg_loss=0.09287, mel_loss=0.04685, linear_loss=0.05411]
[2020-05-11 22:25:23.671]  Step 146542  [3.183 sec/step, loss=0.09782, avg_loss=0.09285, mel_loss=0.04442, linear_loss=0.05341]
[2020-05-11 22:25:31.067]  Step 146543  [3.200 sec/step, loss=0.10047, avg_loss=0.09286, mel_loss=0.04735, linear_loss=0.05312]
[2020-05-11 22:25:31.628]  Step 146544  [3.189 sec/step, loss=0.07745, avg_loss=0.09270, mel_loss=0.03442, linear_loss=0.04303]
[2020-05-11 22:25:32.792]  Generated 32 batches of size 32 in 1.719 sec
[2020-05-11 22:25:38.293]  Step 146545  [3.179 sec/step, loss=0.10061, avg_loss=0.09269, mel_loss=0.04700, linear_loss=0.05361]
[2020-05-11 22:25:39.275]  Step 146546  [3.059 sec/step, loss=0.08458, avg_loss=0.09268, mel_loss=0.03710, linear_loss=0.04748]
[2020-05-11 22:25:41.529]  Step 146547  [3.030 sec/step, loss=0.09408, avg_loss=0.09261, mel_loss=0.04248, linear_loss=0.05160]
[2020-05-11 22:25:46.933]  Step 146548  [3.075 sec/step, loss=0.10077, avg_loss=0.09278, mel_loss=0.04657, linear_loss=0.05419]
[2020-05-11 22:25:49.405]  Step 146549  [3.085 sec/step, loss=0.09419, avg_loss=0.09281, mel_loss=0.04235, linear_loss=0.05184]
[2020-05-11 22:25:51.493]  Step 146550  [3.068 sec/step, loss=0.09441, avg_loss=0.09277, mel_loss=0.04250, linear_loss=0.05192]
[2020-05-11 22:25:51.493]  Writing summary at step: 146550
[2020-05-11 22:25:52.673]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146550
[2020-05-11 22:25:54.036]  Saving audio and alignment...
[2020-05-11 22:26:10.992]  Input: 칠년 동안 아나운서 시험을 보다 보니까 각 방송사 기초의 대본을 모으고 연구하는 일은 어느덧 제 일상으로 자리를 잡았습니다~_________________________________________
[2020-05-11 22:26:11.831]  Step 146551  [3.054 sec/step, loss=0.07775, avg_loss=0.09260, mel_loss=0.03412, linear_loss=0.04363]
[2020-05-11 22:26:13.438]  Step 146552  [3.059 sec/step, loss=0.09338, avg_loss=0.09264, mel_loss=0.04134, linear_loss=0.05205]
[2020-05-11 22:26:15.206]  Step 146553  [3.050 sec/step, loss=0.09309, avg_loss=0.09261, mel_loss=0.04147, linear_loss=0.05162]
[2020-05-11 22:26:18.152]  Step 146554  [3.071 sec/step, loss=0.09766, avg_loss=0.09281, mel_loss=0.04418, linear_loss=0.05348]
[2020-05-11 22:26:20.489]  Step 146555  [3.058 sec/step, loss=0.09625, avg_loss=0.09278, mel_loss=0.04353, linear_loss=0.05273]
[2020-05-11 22:26:25.063]  Step 146556  [3.081 sec/step, loss=0.10174, avg_loss=0.09285, mel_loss=0.04678, linear_loss=0.05496]
[2020-05-11 22:26:27.865]  Step 146557  [3.063 sec/step, loss=0.09472, avg_loss=0.09279, mel_loss=0.04272, linear_loss=0.05199]
[2020-05-11 22:26:35.332]  Step 146558  [3.108 sec/step, loss=0.10101, avg_loss=0.09280, mel_loss=0.04710, linear_loss=0.05391]
[2020-05-11 22:26:38.730]  Step 146559  [3.118 sec/step, loss=0.09811, avg_loss=0.09286, mel_loss=0.04447, linear_loss=0.05364]
[2020-05-11 22:26:40.920]  Step 146560  [3.104 sec/step, loss=0.09376, avg_loss=0.09278, mel_loss=0.04203, linear_loss=0.05173]
[2020-05-11 22:26:41.667]  Step 146561  [3.098 sec/step, loss=0.07611, avg_loss=0.09267, mel_loss=0.03354, linear_loss=0.04257]
[2020-05-11 22:26:45.888]  Step 146562  [3.120 sec/step, loss=0.09993, avg_loss=0.09274, mel_loss=0.04573, linear_loss=0.05420]
[2020-05-11 22:26:47.857]  Step 146563  [3.132 sec/step, loss=0.09336, avg_loss=0.09294, mel_loss=0.04143, linear_loss=0.05193]
[2020-05-11 22:26:49.883]  Step 146564  [3.112 sec/step, loss=0.09320, avg_loss=0.09289, mel_loss=0.04160, linear_loss=0.05161]
[2020-05-11 22:26:53.282]  Step 146565  [3.105 sec/step, loss=0.09922, avg_loss=0.09289, mel_loss=0.04561, linear_loss=0.05361]
[2020-05-11 22:26:58.079]  Step 146566  [3.144 sec/step, loss=0.10032, avg_loss=0.09307, mel_loss=0.04645, linear_loss=0.05387]
[2020-05-11 22:27:01.690]  Step 146567  [3.134 sec/step, loss=0.10005, avg_loss=0.09306, mel_loss=0.04575, linear_loss=0.05431]
[2020-05-11 22:27:05.751]  Step 146568  [3.141 sec/step, loss=0.09994, avg_loss=0.09310, mel_loss=0.04581, linear_loss=0.05413]
[2020-05-11 22:27:12.443]  Step 146569  [3.187 sec/step, loss=0.09971, avg_loss=0.09316, mel_loss=0.04651, linear_loss=0.05321]
[2020-05-11 22:27:13.604]  Step 146570  [3.184 sec/step, loss=0.08430, avg_loss=0.09310, mel_loss=0.03712, linear_loss=0.04718]
[2020-05-11 22:27:14.370]  Step 146571  [3.180 sec/step, loss=0.07798, avg_loss=0.09299, mel_loss=0.03500, linear_loss=0.04298]
[2020-05-11 22:27:30.565]  Step 146572  [3.334 sec/step, loss=0.08098, avg_loss=0.09299, mel_loss=0.03898, linear_loss=0.04200]
[2020-05-11 22:27:35.406]  Step 146573  [3.315 sec/step, loss=0.10060, avg_loss=0.09299, mel_loss=0.04569, linear_loss=0.05491]
[2020-05-11 22:27:37.159]  Step 146574  [3.316 sec/step, loss=0.08512, avg_loss=0.09290, mel_loss=0.03774, linear_loss=0.04738]
[2020-05-11 22:27:38.797]  Generated 32 batches of size 32 in 3.381 sec
[2020-05-11 22:27:47.697]  Step 146575  [3.399 sec/step, loss=0.09615, avg_loss=0.09294, mel_loss=0.04535, linear_loss=0.05079]
[2020-05-11 22:27:49.424]  Step 146576  [3.360 sec/step, loss=0.09324, avg_loss=0.09288, mel_loss=0.04158, linear_loss=0.05165]
[2020-05-11 22:27:50.915]  Step 146577  [3.367 sec/step, loss=0.09205, avg_loss=0.09303, mel_loss=0.04140, linear_loss=0.05065]
[2020-05-11 22:27:53.394]  Step 146578  [3.361 sec/step, loss=0.09427, avg_loss=0.09300, mel_loss=0.04222, linear_loss=0.05205]
[2020-05-11 22:27:54.765]  Step 146579  [3.358 sec/step, loss=0.08692, avg_loss=0.09294, mel_loss=0.03823, linear_loss=0.04869]
[2020-05-11 22:27:56.029]  Step 146580  [3.343 sec/step, loss=0.08990, avg_loss=0.09287, mel_loss=0.04003, linear_loss=0.04987]
[2020-05-11 22:28:01.770]  Step 146581  [3.269 sec/step, loss=0.10008, avg_loss=0.09303, mel_loss=0.04639, linear_loss=0.05369]
[2020-05-11 22:28:02.731]  Step 146582  [3.262 sec/step, loss=0.08320, avg_loss=0.09294, mel_loss=0.03671, linear_loss=0.04649]
[2020-05-11 22:28:05.171]  Step 146583  [3.267 sec/step, loss=0.09485, avg_loss=0.09297, mel_loss=0.04278, linear_loss=0.05207]
[2020-05-11 22:28:07.542]  Step 146584  [3.280 sec/step, loss=0.09511, avg_loss=0.09305, mel_loss=0.04279, linear_loss=0.05232]
[2020-05-11 22:28:10.141]  Step 146585  [3.231 sec/step, loss=0.09691, avg_loss=0.09302, mel_loss=0.04393, linear_loss=0.05298]
[2020-05-11 22:28:11.152]  Step 146586  [3.231 sec/step, loss=0.08388, avg_loss=0.09300, mel_loss=0.03699, linear_loss=0.04688]
[2020-05-11 22:28:12.830]  Step 146587  [3.160 sec/step, loss=0.09235, avg_loss=0.09293, mel_loss=0.04115, linear_loss=0.05120]
[2020-05-11 22:28:14.830]  Step 146588  [3.130 sec/step, loss=0.09238, avg_loss=0.09288, mel_loss=0.04140, linear_loss=0.05098]
[2020-05-11 22:28:29.883]  Step 146589  [3.253 sec/step, loss=0.07594, avg_loss=0.09268, mel_loss=0.03659, linear_loss=0.03934]
[2020-05-11 22:28:38.631]  Step 146590  [3.309 sec/step, loss=0.09992, avg_loss=0.09269, mel_loss=0.04707, linear_loss=0.05285]
[2020-05-11 22:28:40.515]  Step 146591  [3.280 sec/step, loss=0.09323, avg_loss=0.09262, mel_loss=0.04149, linear_loss=0.05174]
[2020-05-11 22:28:44.539]  Step 146592  [3.307 sec/step, loss=0.09869, avg_loss=0.09273, mel_loss=0.04498, linear_loss=0.05371]
[2020-05-11 22:28:49.377]  Step 146593  [3.330 sec/step, loss=0.09851, avg_loss=0.09277, mel_loss=0.04509, linear_loss=0.05342]
[2020-05-11 22:28:50.204]  Step 146594  [3.285 sec/step, loss=0.07912, avg_loss=0.09256, mel_loss=0.03465, linear_loss=0.04446]
[2020-05-11 22:28:53.804]  Step 146595  [3.309 sec/step, loss=0.09736, avg_loss=0.09268, mel_loss=0.04440, linear_loss=0.05295]
[2020-05-11 22:28:58.249]  Step 146596  [3.320 sec/step, loss=0.10055, avg_loss=0.09267, mel_loss=0.04648, linear_loss=0.05407]
[2020-05-11 22:29:05.865]  Step 146597  [3.374 sec/step, loss=0.10152, avg_loss=0.09274, mel_loss=0.04770, linear_loss=0.05382]
[2020-05-11 22:29:07.196]  Step 146598  [3.334 sec/step, loss=0.08970, avg_loss=0.09264, mel_loss=0.03978, linear_loss=0.04992]
[2020-05-11 22:29:10.480]  Step 146599  [3.362 sec/step, loss=0.09697, avg_loss=0.09288, mel_loss=0.04409, linear_loss=0.05289]
[2020-05-11 22:29:12.291]  Step 146600  [3.337 sec/step, loss=0.09179, avg_loss=0.09281, mel_loss=0.04093, linear_loss=0.05086]
[2020-05-11 22:29:12.291]  Writing summary at step: 146600
[2020-05-11 22:29:19.041]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146600
[2020-05-11 22:29:20.419]  Saving audio and alignment...
[2020-05-11 22:29:22.308]  Input: 어머님 나는~___________________
[2020-05-11 22:29:23.686]  Step 146601  [3.325 sec/step, loss=0.08833, avg_loss=0.09274, mel_loss=0.03933, linear_loss=0.04901]
[2020-05-11 22:29:25.787]  Step 146602  [3.318 sec/step, loss=0.09724, avg_loss=0.09274, mel_loss=0.04382, linear_loss=0.05342]
[2020-05-11 22:29:28.857]  Step 146603  [3.328 sec/step, loss=0.09896, avg_loss=0.09280, mel_loss=0.04514, linear_loss=0.05382]
[2020-05-11 22:29:29.552]  Step 146604  [3.299 sec/step, loss=0.07805, avg_loss=0.09260, mel_loss=0.03485, linear_loss=0.04320]
[2020-05-11 22:29:30.350]  Step 146605  [3.299 sec/step, loss=0.07467, avg_loss=0.09252, mel_loss=0.03399, linear_loss=0.04068]
[2020-05-11 22:29:30.576]  Generated 32 batches of size 32 in 1.714 sec
[2020-05-11 22:29:31.877]  Step 146606  [3.301 sec/step, loss=0.09125, avg_loss=0.09252, mel_loss=0.04064, linear_loss=0.05061]
[2020-05-11 22:29:32.976]  Step 146607  [3.174 sec/step, loss=0.08796, avg_loss=0.09262, mel_loss=0.03830, linear_loss=0.04966]
[2020-05-11 22:29:36.636]  Step 146608  [3.200 sec/step, loss=0.10078, avg_loss=0.09279, mel_loss=0.04606, linear_loss=0.05471]
[2020-05-11 22:29:37.863]  Step 146609  [3.195 sec/step, loss=0.08833, avg_loss=0.09276, mel_loss=0.03913, linear_loss=0.04919]
[2020-05-11 22:29:43.615]  Step 146610  [3.237 sec/step, loss=0.10279, avg_loss=0.09289, mel_loss=0.04788, linear_loss=0.05491]
[2020-05-11 22:29:46.522]  Step 146611  [3.226 sec/step, loss=0.09716, avg_loss=0.09285, mel_loss=0.04406, linear_loss=0.05311]
[2020-05-11 22:29:51.865]  Step 146612  [3.204 sec/step, loss=0.10037, avg_loss=0.09283, mel_loss=0.04666, linear_loss=0.05371]
[2020-05-11 22:29:52.430]  Step 146613  [3.188 sec/step, loss=0.07171, avg_loss=0.09260, mel_loss=0.03191, linear_loss=0.03980]
[2020-05-11 22:29:54.643]  Step 146614  [3.193 sec/step, loss=0.09419, avg_loss=0.09263, mel_loss=0.04247, linear_loss=0.05172]
[2020-05-11 22:29:57.949]  Step 146615  [3.207 sec/step, loss=0.09950, avg_loss=0.09270, mel_loss=0.04497, linear_loss=0.05453]
[2020-05-11 22:30:00.977]  Step 146616  [3.204 sec/step, loss=0.09848, avg_loss=0.09270, mel_loss=0.04494, linear_loss=0.05354]
[2020-05-11 22:30:01.839]  Step 146617  [3.206 sec/step, loss=0.08323, avg_loss=0.09277, mel_loss=0.03608, linear_loss=0.04715]
[2020-05-11 22:30:08.657]  Step 146618  [3.190 sec/step, loss=0.10146, avg_loss=0.09281, mel_loss=0.04759, linear_loss=0.05388]
[2020-05-11 22:30:11.309]  Step 146619  [3.207 sec/step, loss=0.09685, avg_loss=0.09294, mel_loss=0.04367, linear_loss=0.05318]
[2020-05-11 22:30:15.324]  Step 146620  [3.236 sec/step, loss=0.09823, avg_loss=0.09307, mel_loss=0.04470, linear_loss=0.05352]
[2020-05-11 22:30:17.078]  Step 146621  [3.233 sec/step, loss=0.09243, avg_loss=0.09306, mel_loss=0.04100, linear_loss=0.05143]
[2020-05-11 22:30:19.900]  Step 146622  [3.229 sec/step, loss=0.09546, avg_loss=0.09302, mel_loss=0.04331, linear_loss=0.05215]
[2020-05-11 22:30:21.033]  Step 146623  [3.152 sec/step, loss=0.08628, avg_loss=0.09288, mel_loss=0.03830, linear_loss=0.04798]
[2020-05-11 22:30:22.071]  Step 146624  [3.126 sec/step, loss=0.08465, avg_loss=0.09274, mel_loss=0.03724, linear_loss=0.04741]
[2020-05-11 22:30:26.484]  Step 146625  [3.151 sec/step, loss=0.10041, avg_loss=0.09284, mel_loss=0.04608, linear_loss=0.05433]
[2020-05-11 22:30:28.500]  Step 146626  [3.136 sec/step, loss=0.09219, avg_loss=0.09279, mel_loss=0.04142, linear_loss=0.05078]
[2020-05-11 22:30:30.387]  Step 146627  [3.139 sec/step, loss=0.08987, avg_loss=0.09277, mel_loss=0.04015, linear_loss=0.04972]
[2020-05-11 22:30:31.413]  Step 146628  [3.106 sec/step, loss=0.08674, avg_loss=0.09264, mel_loss=0.03809, linear_loss=0.04865]
[2020-05-11 22:30:33.778]  Step 146629  [3.122 sec/step, loss=0.09554, avg_loss=0.09276, mel_loss=0.04292, linear_loss=0.05262]
[2020-05-11 22:30:48.196]  Step 146630  [3.220 sec/step, loss=0.07823, avg_loss=0.09255, mel_loss=0.03754, linear_loss=0.04069]
[2020-05-11 22:30:49.402]  Step 146631  [3.221 sec/step, loss=0.09003, avg_loss=0.09257, mel_loss=0.03996, linear_loss=0.05007]
[2020-05-11 22:30:52.921]  Step 146632  [3.229 sec/step, loss=0.09810, avg_loss=0.09258, mel_loss=0.04482, linear_loss=0.05329]
[2020-05-11 22:30:53.751]  Step 146633  [3.230 sec/step, loss=0.07753, avg_loss=0.09257, mel_loss=0.03444, linear_loss=0.04310]
[2020-05-11 22:30:55.812]  Step 146634  [3.237 sec/step, loss=0.09309, avg_loss=0.09262, mel_loss=0.04201, linear_loss=0.05108]
[2020-05-11 22:30:59.218]  Step 146635  [3.240 sec/step, loss=0.09743, avg_loss=0.09259, mel_loss=0.04439, linear_loss=0.05304]
[2020-05-11 22:31:00.898]  Generated 32 batches of size 32 in 1.674 sec
[2020-05-11 22:31:04.798]  Step 146636  [3.279 sec/step, loss=0.10072, avg_loss=0.09267, mel_loss=0.04671, linear_loss=0.05401]
[2020-05-11 22:31:13.205]  Step 146637  [3.324 sec/step, loss=0.09709, avg_loss=0.09266, mel_loss=0.04565, linear_loss=0.05143]
[2020-05-11 22:31:17.194]  Step 146638  [3.348 sec/step, loss=0.09955, avg_loss=0.09276, mel_loss=0.04553, linear_loss=0.05402]
[2020-05-11 22:31:21.994]  Step 146639  [3.387 sec/step, loss=0.09844, avg_loss=0.09292, mel_loss=0.04530, linear_loss=0.05314]
[2020-05-11 22:31:27.984]  Step 146640  [3.433 sec/step, loss=0.10176, avg_loss=0.09303, mel_loss=0.04731, linear_loss=0.05445]
[2020-05-11 22:31:29.470]  Step 146641  [3.391 sec/step, loss=0.09066, avg_loss=0.09293, mel_loss=0.03993, linear_loss=0.05074]
[2020-05-11 22:31:30.311]  Step 146642  [3.371 sec/step, loss=0.08111, avg_loss=0.09276, mel_loss=0.03593, linear_loss=0.04517]
[2020-05-11 22:31:31.669]  Step 146643  [3.311 sec/step, loss=0.09026, avg_loss=0.09266, mel_loss=0.04009, linear_loss=0.05017]
[2020-05-11 22:31:33.309]  Step 146644  [3.321 sec/step, loss=0.09173, avg_loss=0.09280, mel_loss=0.04098, linear_loss=0.05075]
[2020-05-11 22:31:36.717]  Step 146645  [3.289 sec/step, loss=0.09791, avg_loss=0.09278, mel_loss=0.04445, linear_loss=0.05346]
[2020-05-11 22:31:38.123]  Step 146646  [3.293 sec/step, loss=0.08797, avg_loss=0.09281, mel_loss=0.03942, linear_loss=0.04855]
[2020-05-11 22:31:39.906]  Step 146647  [3.288 sec/step, loss=0.09278, avg_loss=0.09280, mel_loss=0.04140, linear_loss=0.05138]
[2020-05-11 22:31:41.553]  Step 146648  [3.251 sec/step, loss=0.09268, avg_loss=0.09272, mel_loss=0.04132, linear_loss=0.05136]
[2020-05-11 22:31:50.266]  Step 146649  [3.313 sec/step, loss=0.10101, avg_loss=0.09278, mel_loss=0.04744, linear_loss=0.05357]
[2020-05-11 22:31:54.407]  Step 146650  [3.334 sec/step, loss=0.09810, avg_loss=0.09282, mel_loss=0.04479, linear_loss=0.05331]
[2020-05-11 22:31:54.407]  Writing summary at step: 146650
[2020-05-11 22:31:56.434]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146650
[2020-05-11 22:31:57.817]  Saving audio and alignment...
[2020-05-11 22:32:04.186]  Input: 가끔 강의 전에 제가 그 사전 콜 청취를 하다 보면요~____________________________________
[2020-05-11 22:32:04.940]  Step 146651  [3.333 sec/step, loss=0.07660, avg_loss=0.09281, mel_loss=0.03389, linear_loss=0.04272]
[2020-05-11 22:32:07.830]  Step 146652  [3.346 sec/step, loss=0.09718, avg_loss=0.09285, mel_loss=0.04398, linear_loss=0.05320]
[2020-05-11 22:32:10.322]  Step 146653  [3.353 sec/step, loss=0.09373, avg_loss=0.09285, mel_loss=0.04212, linear_loss=0.05161]
[2020-05-11 22:32:12.251]  Step 146654  [3.343 sec/step, loss=0.09423, avg_loss=0.09282, mel_loss=0.04187, linear_loss=0.05236]
[2020-05-11 22:32:24.278]  Step 146655  [3.440 sec/step, loss=0.09103, avg_loss=0.09277, mel_loss=0.04384, linear_loss=0.04719]
[2020-05-11 22:32:29.016]  Step 146656  [3.441 sec/step, loss=0.10039, avg_loss=0.09275, mel_loss=0.04620, linear_loss=0.05419]
[2020-05-11 22:32:29.838]  Step 146657  [3.422 sec/step, loss=0.08110, avg_loss=0.09262, mel_loss=0.03553, linear_loss=0.04557]
[2020-05-11 22:32:34.997]  Step 146658  [3.398 sec/step, loss=0.09900, avg_loss=0.09260, mel_loss=0.04588, linear_loss=0.05312]
[2020-05-11 22:32:35.955]  Step 146659  [3.374 sec/step, loss=0.08200, avg_loss=0.09244, mel_loss=0.03642, linear_loss=0.04559]
[2020-05-11 22:32:42.946]  Step 146660  [3.422 sec/step, loss=0.09927, avg_loss=0.09249, mel_loss=0.04638, linear_loss=0.05289]
[2020-05-11 22:32:44.007]  Step 146661  [3.425 sec/step, loss=0.08331, avg_loss=0.09256, mel_loss=0.03674, linear_loss=0.04658]
[2020-05-11 22:32:47.680]  Step 146662  [3.420 sec/step, loss=0.09979, avg_loss=0.09256, mel_loss=0.04558, linear_loss=0.05421]
[2020-05-11 22:32:55.337]  Step 146663  [3.477 sec/step, loss=0.10089, avg_loss=0.09264, mel_loss=0.04722, linear_loss=0.05367]
[2020-05-11 22:32:57.583]  Step 146664  [3.479 sec/step, loss=0.09185, avg_loss=0.09262, mel_loss=0.04137, linear_loss=0.05048]
[2020-05-11 22:32:58.729]  Step 146665  [3.456 sec/step, loss=0.08502, avg_loss=0.09248, mel_loss=0.03711, linear_loss=0.04792]
[2020-05-11 22:32:59.314]  Step 146666  [3.414 sec/step, loss=0.07547, avg_loss=0.09223, mel_loss=0.03385, linear_loss=0.04162]
[2020-05-11 22:33:00.512]  Generated 32 batches of size 32 in 1.777 sec
[2020-05-11 22:33:01.752]  Step 146667  [3.402 sec/step, loss=0.09666, avg_loss=0.09220, mel_loss=0.04351, linear_loss=0.05315]
[2020-05-11 22:33:04.379]  Step 146668  [3.388 sec/step, loss=0.09629, avg_loss=0.09216, mel_loss=0.04365, linear_loss=0.05265]
[2020-05-11 22:33:07.804]  Step 146669  [3.355 sec/step, loss=0.09883, avg_loss=0.09216, mel_loss=0.04504, linear_loss=0.05380]
[2020-05-11 22:33:10.959]  Step 146670  [3.375 sec/step, loss=0.09810, avg_loss=0.09229, mel_loss=0.04467, linear_loss=0.05343]
[2020-05-11 22:33:12.300]  Step 146671  [3.381 sec/step, loss=0.09060, avg_loss=0.09242, mel_loss=0.04020, linear_loss=0.05040]
[2020-05-11 22:33:13.851]  Step 146672  [3.235 sec/step, loss=0.09012, avg_loss=0.09251, mel_loss=0.04004, linear_loss=0.05008]
[2020-05-11 22:33:19.506]  Step 146673  [3.243 sec/step, loss=0.10016, avg_loss=0.09251, mel_loss=0.04639, linear_loss=0.05377]
[2020-05-11 22:33:20.752]  Step 146674  [3.238 sec/step, loss=0.08735, avg_loss=0.09253, mel_loss=0.03881, linear_loss=0.04855]
[2020-05-11 22:33:22.108]  Step 146675  [3.146 sec/step, loss=0.08819, avg_loss=0.09245, mel_loss=0.03892, linear_loss=0.04926]
[2020-05-11 22:33:25.735]  Step 146676  [3.165 sec/step, loss=0.09844, avg_loss=0.09250, mel_loss=0.04463, linear_loss=0.05381]
[2020-05-11 22:33:29.038]  Step 146677  [3.183 sec/step, loss=0.09882, avg_loss=0.09257, mel_loss=0.04471, linear_loss=0.05411]
[2020-05-11 22:33:32.306]  Step 146678  [3.191 sec/step, loss=0.10019, avg_loss=0.09263, mel_loss=0.04550, linear_loss=0.05469]
[2020-05-11 22:33:41.391]  Step 146679  [3.268 sec/step, loss=0.09755, avg_loss=0.09273, mel_loss=0.04566, linear_loss=0.05190]
[2020-05-11 22:33:41.945]  Step 146680  [3.261 sec/step, loss=0.07406, avg_loss=0.09258, mel_loss=0.03286, linear_loss=0.04120]
[2020-05-11 22:33:43.552]  Step 146681  [3.220 sec/step, loss=0.08838, avg_loss=0.09246, mel_loss=0.03920, linear_loss=0.04918]
[2020-05-11 22:33:49.870]  Step 146682  [3.273 sec/step, loss=0.10027, avg_loss=0.09263, mel_loss=0.04681, linear_loss=0.05346]
[2020-05-11 22:33:52.365]  Step 146683  [3.274 sec/step, loss=0.09332, avg_loss=0.09261, mel_loss=0.04196, linear_loss=0.05136]
[2020-05-11 22:33:56.702]  Step 146684  [3.293 sec/step, loss=0.09934, avg_loss=0.09266, mel_loss=0.04551, linear_loss=0.05383]
[2020-05-11 22:33:58.466]  Step 146685  [3.285 sec/step, loss=0.09141, avg_loss=0.09260, mel_loss=0.04022, linear_loss=0.05119]
[2020-05-11 22:34:03.786]  Step 146686  [3.328 sec/step, loss=0.09785, avg_loss=0.09274, mel_loss=0.04514, linear_loss=0.05271]
[2020-05-11 22:34:04.805]  Step 146687  [3.322 sec/step, loss=0.08516, avg_loss=0.09267, mel_loss=0.03767, linear_loss=0.04750]
[2020-05-11 22:34:06.825]  Step 146688  [3.322 sec/step, loss=0.09288, avg_loss=0.09267, mel_loss=0.04153, linear_loss=0.05135]
[2020-05-11 22:34:07.595]  Step 146689  [3.179 sec/step, loss=0.08241, avg_loss=0.09274, mel_loss=0.03572, linear_loss=0.04670]
[2020-05-11 22:34:10.523]  Step 146690  [3.121 sec/step, loss=0.09544, avg_loss=0.09269, mel_loss=0.04325, linear_loss=0.05219]
[2020-05-11 22:34:11.611]  Step 146691  [3.113 sec/step, loss=0.08676, avg_loss=0.09263, mel_loss=0.03785, linear_loss=0.04891]
[2020-05-11 22:34:13.823]  Step 146692  [3.095 sec/step, loss=0.09338, avg_loss=0.09258, mel_loss=0.04192, linear_loss=0.05146]
[2020-05-11 22:34:14.817]  Step 146693  [3.056 sec/step, loss=0.08304, avg_loss=0.09242, mel_loss=0.03671, linear_loss=0.04633]
[2020-05-11 22:34:17.390]  Step 146694  [3.074 sec/step, loss=0.09545, avg_loss=0.09259, mel_loss=0.04333, linear_loss=0.05212]
[2020-05-11 22:34:23.231]  Step 146695  [3.096 sec/step, loss=0.10013, avg_loss=0.09261, mel_loss=0.04624, linear_loss=0.05389]
[2020-05-11 22:34:27.903]  Step 146696  [3.098 sec/step, loss=0.09928, avg_loss=0.09260, mel_loss=0.04562, linear_loss=0.05366]
[2020-05-11 22:34:35.283]  Step 146697  [3.096 sec/step, loss=0.10220, avg_loss=0.09261, mel_loss=0.04792, linear_loss=0.05428]
[2020-05-11 22:34:37.119]  Generated 32 batches of size 32 in 1.830 sec
[2020-05-11 22:34:37.541]  Step 146698  [3.105 sec/step, loss=0.09452, avg_loss=0.09266, mel_loss=0.04227, linear_loss=0.05225]
[2020-05-11 22:34:39.457]  Step 146699  [3.092 sec/step, loss=0.09116, avg_loss=0.09260, mel_loss=0.04043, linear_loss=0.05072]
[2020-05-11 22:34:53.820]  Step 146700  [3.217 sec/step, loss=0.08127, avg_loss=0.09249, mel_loss=0.03905, linear_loss=0.04222]
[2020-05-11 22:34:53.820]  Writing summary at step: 146700
[2020-05-11 22:34:55.522]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146700
[2020-05-11 22:34:56.958]  Saving audio and alignment...
[2020-05-11 22:34:59.302]  Input: 자 내용에 맞춰서~_______________
[2020-05-11 22:35:02.796]  Step 146701  [3.238 sec/step, loss=0.09685, avg_loss=0.09258, mel_loss=0.04419, linear_loss=0.05266]
[2020-05-11 22:35:04.202]  Step 146702  [3.231 sec/step, loss=0.08943, avg_loss=0.09250, mel_loss=0.03991, linear_loss=0.04952]
[2020-05-11 22:35:05.040]  Step 146703  [3.209 sec/step, loss=0.07905, avg_loss=0.09230, mel_loss=0.03527, linear_loss=0.04377]
[2020-05-11 22:35:09.146]  Step 146704  [3.243 sec/step, loss=0.09838, avg_loss=0.09250, mel_loss=0.04491, linear_loss=0.05348]
[2020-05-11 22:35:12.615]  Step 146705  [3.270 sec/step, loss=0.09615, avg_loss=0.09272, mel_loss=0.04379, linear_loss=0.05236]
[2020-05-11 22:35:16.728]  Step 146706  [3.296 sec/step, loss=0.09909, avg_loss=0.09280, mel_loss=0.04502, linear_loss=0.05407]
[2020-05-11 22:35:25.111]  Step 146707  [3.368 sec/step, loss=0.09921, avg_loss=0.09291, mel_loss=0.04656, linear_loss=0.05265]
[2020-05-11 22:35:27.333]  Step 146708  [3.354 sec/step, loss=0.09352, avg_loss=0.09284, mel_loss=0.04217, linear_loss=0.05135]
[2020-05-11 22:35:28.237]  Step 146709  [3.351 sec/step, loss=0.08159, avg_loss=0.09277, mel_loss=0.03565, linear_loss=0.04594]
[2020-05-11 22:35:32.478]  Step 146710  [3.336 sec/step, loss=0.09927, avg_loss=0.09273, mel_loss=0.04565, linear_loss=0.05362]
[2020-05-11 22:35:35.218]  Step 146711  [3.334 sec/step, loss=0.09502, avg_loss=0.09271, mel_loss=0.04289, linear_loss=0.05214]
[2020-05-11 22:35:36.892]  Step 146712  [3.297 sec/step, loss=0.09010, avg_loss=0.09261, mel_loss=0.04038, linear_loss=0.04972]
[2020-05-11 22:35:42.154]  Step 146713  [3.344 sec/step, loss=0.10021, avg_loss=0.09289, mel_loss=0.04632, linear_loss=0.05389]
[2020-05-11 22:35:45.574]  Step 146714  [3.356 sec/step, loss=0.09949, avg_loss=0.09295, mel_loss=0.04538, linear_loss=0.05411]
[2020-05-11 22:35:50.368]  Step 146715  [3.371 sec/step, loss=0.09886, avg_loss=0.09294, mel_loss=0.04544, linear_loss=0.05341]
[2020-05-11 22:35:54.064]  Step 146716  [3.378 sec/step, loss=0.09966, avg_loss=0.09295, mel_loss=0.04554, linear_loss=0.05413]
[2020-05-11 22:35:55.838]  Step 146717  [3.387 sec/step, loss=0.09176, avg_loss=0.09304, mel_loss=0.04089, linear_loss=0.05087]
[2020-05-11 22:36:06.579]  Step 146718  [3.426 sec/step, loss=0.09730, avg_loss=0.09300, mel_loss=0.04635, linear_loss=0.05095]
[2020-05-11 22:36:09.120]  Step 146719  [3.425 sec/step, loss=0.09582, avg_loss=0.09299, mel_loss=0.04286, linear_loss=0.05296]
[2020-05-11 22:36:10.342]  Step 146720  [3.397 sec/step, loss=0.08810, avg_loss=0.09289, mel_loss=0.03909, linear_loss=0.04901]
[2020-05-11 22:36:13.433]  Step 146721  [3.411 sec/step, loss=0.09647, avg_loss=0.09293, mel_loss=0.04351, linear_loss=0.05296]
[2020-05-11 22:36:15.874]  Step 146722  [3.407 sec/step, loss=0.09507, avg_loss=0.09292, mel_loss=0.04277, linear_loss=0.05230]
[2020-05-11 22:36:17.324]  Step 146723  [3.410 sec/step, loss=0.08824, avg_loss=0.09294, mel_loss=0.03914, linear_loss=0.04910]
[2020-05-11 22:36:20.191]  Step 146724  [3.428 sec/step, loss=0.10009, avg_loss=0.09310, mel_loss=0.04511, linear_loss=0.05498]
[2020-05-11 22:36:22.164]  Step 146725  [3.404 sec/step, loss=0.09573, avg_loss=0.09305, mel_loss=0.04305, linear_loss=0.05268]
[2020-05-11 22:36:22.911]  Step 146726  [3.391 sec/step, loss=0.07620, avg_loss=0.09289, mel_loss=0.03346, linear_loss=0.04274]
[2020-05-11 22:36:24.023]  Step 146727  [3.383 sec/step, loss=0.08565, avg_loss=0.09285, mel_loss=0.03751, linear_loss=0.04814]
[2020-05-11 22:36:25.646]  Step 146728  [3.389 sec/step, loss=0.09089, avg_loss=0.09289, mel_loss=0.04038, linear_loss=0.05051]
[2020-05-11 22:36:25.775]  Generated 32 batches of size 32 in 1.747 sec
[2020-05-11 22:36:26.670]  Step 146729  [3.376 sec/step, loss=0.08312, avg_loss=0.09276, mel_loss=0.03661, linear_loss=0.04651]
[2020-05-11 22:36:32.528]  Step 146730  [3.290 sec/step, loss=0.10043, avg_loss=0.09299, mel_loss=0.04685, linear_loss=0.05358]
[2020-05-11 22:36:39.307]  Step 146731  [3.346 sec/step, loss=0.10035, avg_loss=0.09309, mel_loss=0.04651, linear_loss=0.05383]
[2020-05-11 22:36:41.280]  Step 146732  [3.331 sec/step, loss=0.09245, avg_loss=0.09303, mel_loss=0.04130, linear_loss=0.05115]
[2020-05-11 22:36:42.633]  Step 146733  [3.336 sec/step, loss=0.08702, avg_loss=0.09313, mel_loss=0.03855, linear_loss=0.04847]
[2020-05-11 22:36:43.440]  Step 146734  [3.323 sec/step, loss=0.08028, avg_loss=0.09300, mel_loss=0.03513, linear_loss=0.04516]
[2020-05-11 22:36:44.004]  Step 146735  [3.295 sec/step, loss=0.07148, avg_loss=0.09274, mel_loss=0.03231, linear_loss=0.03917]
[2020-05-11 22:36:51.405]  Step 146736  [3.313 sec/step, loss=0.10308, avg_loss=0.09276, mel_loss=0.04836, linear_loss=0.05472]
[2020-05-11 22:36:53.456]  Step 146737  [3.250 sec/step, loss=0.09087, avg_loss=0.09270, mel_loss=0.04070, linear_loss=0.05016]
[2020-05-11 22:36:54.268]  Step 146738  [3.218 sec/step, loss=0.07965, avg_loss=0.09250, mel_loss=0.03491, linear_loss=0.04474]
[2020-05-11 22:36:55.582]  Step 146739  [3.183 sec/step, loss=0.08963, avg_loss=0.09241, mel_loss=0.03968, linear_loss=0.04996]
[2020-05-11 22:36:56.487]  Step 146740  [3.132 sec/step, loss=0.08214, avg_loss=0.09222, mel_loss=0.03589, linear_loss=0.04625]
[2020-05-11 22:36:59.915]  Step 146741  [3.152 sec/step, loss=0.09794, avg_loss=0.09229, mel_loss=0.04451, linear_loss=0.05343]
[2020-05-11 22:37:07.417]  Step 146742  [3.218 sec/step, loss=0.09877, avg_loss=0.09247, mel_loss=0.04612, linear_loss=0.05265]
[2020-05-11 22:37:08.439]  Step 146743  [3.215 sec/step, loss=0.08172, avg_loss=0.09238, mel_loss=0.03567, linear_loss=0.04604]
[2020-05-11 22:37:11.374]  Step 146744  [3.228 sec/step, loss=0.09856, avg_loss=0.09245, mel_loss=0.04468, linear_loss=0.05388]
[2020-05-11 22:37:15.085]  Step 146745  [3.231 sec/step, loss=0.09922, avg_loss=0.09246, mel_loss=0.04516, linear_loss=0.05405]
[2020-05-11 22:37:16.850]  Step 146746  [3.234 sec/step, loss=0.09382, avg_loss=0.09252, mel_loss=0.04186, linear_loss=0.05196]
[2020-05-11 22:37:22.353]  Step 146747  [3.272 sec/step, loss=0.10145, avg_loss=0.09261, mel_loss=0.04684, linear_loss=0.05461]
[2020-05-11 22:37:30.966]  Step 146748  [3.341 sec/step, loss=0.09873, avg_loss=0.09267, mel_loss=0.04662, linear_loss=0.05211]
[2020-05-11 22:37:33.358]  Step 146749  [3.278 sec/step, loss=0.09732, avg_loss=0.09263, mel_loss=0.04391, linear_loss=0.05341]
[2020-05-11 22:37:34.956]  Step 146750  [3.253 sec/step, loss=0.09274, avg_loss=0.09258, mel_loss=0.04153, linear_loss=0.05122]
[2020-05-11 22:37:34.956]  Writing summary at step: 146750
[2020-05-11 22:37:35.526]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146750
[2020-05-11 22:37:36.945]  Saving audio and alignment...
[2020-05-11 22:37:49.048]  Input: 이제 찾게 되는데요 그 무한한 정보 중에서 취사선택을 잘하셔야 된다는 거죠~_________________
[2020-05-11 22:37:53.499]  Step 146751  [3.290 sec/step, loss=0.09913, avg_loss=0.09280, mel_loss=0.04534, linear_loss=0.05379]
[2020-05-11 22:37:54.588]  Step 146752  [3.272 sec/step, loss=0.08468, avg_loss=0.09268, mel_loss=0.03727, linear_loss=0.04741]
[2020-05-11 22:37:56.785]  Step 146753  [3.269 sec/step, loss=0.09479, avg_loss=0.09269, mel_loss=0.04282, linear_loss=0.05197]
[2020-05-11 22:38:02.953]  Step 146754  [3.311 sec/step, loss=0.09865, avg_loss=0.09273, mel_loss=0.04577, linear_loss=0.05288]
[2020-05-11 22:38:06.437]  Step 146755  [3.226 sec/step, loss=0.09740, avg_loss=0.09280, mel_loss=0.04445, linear_loss=0.05295]
[2020-05-11 22:38:19.151]  Step 146756  [3.305 sec/step, loss=0.08867, avg_loss=0.09268, mel_loss=0.04242, linear_loss=0.04625]
[2020-05-11 22:38:20.697]  Step 146757  [3.313 sec/step, loss=0.09236, avg_loss=0.09279, mel_loss=0.04106, linear_loss=0.05130]
[2020-05-11 22:38:22.456]  Generated 32 batches of size 32 in 1.753 sec
[2020-05-11 22:38:22.506]  Step 146758  [3.279 sec/step, loss=0.09422, avg_loss=0.09274, mel_loss=0.04174, linear_loss=0.05248]
[2020-05-11 22:38:25.056]  Step 146759  [3.295 sec/step, loss=0.09328, avg_loss=0.09286, mel_loss=0.04184, linear_loss=0.05144]
[2020-05-11 22:38:26.434]  Step 146760  [3.239 sec/step, loss=0.09019, avg_loss=0.09277, mel_loss=0.04011, linear_loss=0.05008]
[2020-05-11 22:38:29.549]  Step 146761  [3.259 sec/step, loss=0.09854, avg_loss=0.09292, mel_loss=0.04451, linear_loss=0.05403]
[2020-05-11 22:38:30.774]  Step 146762  [3.235 sec/step, loss=0.08618, avg_loss=0.09278, mel_loss=0.03795, linear_loss=0.04823]
[2020-05-11 22:38:33.586]  Step 146763  [3.186 sec/step, loss=0.09514, avg_loss=0.09273, mel_loss=0.04303, linear_loss=0.05211]
[2020-05-11 22:38:38.072]  Step 146764  [3.209 sec/step, loss=0.10017, avg_loss=0.09281, mel_loss=0.04615, linear_loss=0.05402]
[2020-05-11 22:38:40.160]  Step 146765  [3.218 sec/step, loss=0.09385, avg_loss=0.09290, mel_loss=0.04208, linear_loss=0.05177]
[2020-05-11 22:38:41.093]  Step 146766  [3.222 sec/step, loss=0.07449, avg_loss=0.09289, mel_loss=0.03278, linear_loss=0.04171]
[2020-05-11 22:38:42.280]  Step 146767  [3.209 sec/step, loss=0.08819, avg_loss=0.09280, mel_loss=0.03822, linear_loss=0.04998]
[2020-05-11 22:38:45.082]  Step 146768  [3.211 sec/step, loss=0.09601, avg_loss=0.09280, mel_loss=0.04323, linear_loss=0.05278]
[2020-05-11 22:38:53.856]  Step 146769  [3.265 sec/step, loss=0.09898, avg_loss=0.09280, mel_loss=0.04652, linear_loss=0.05245]
[2020-05-11 22:39:08.319]  Step 146770  [3.378 sec/step, loss=0.08041, avg_loss=0.09262, mel_loss=0.03870, linear_loss=0.04172]
[2020-05-11 22:39:13.986]  Step 146771  [3.421 sec/step, loss=0.10074, avg_loss=0.09273, mel_loss=0.04686, linear_loss=0.05388]
[2020-05-11 22:39:14.529]  Step 146772  [3.411 sec/step, loss=0.07505, avg_loss=0.09258, mel_loss=0.03348, linear_loss=0.04157]
[2020-05-11 22:39:16.013]  Step 146773  [3.369 sec/step, loss=0.08647, avg_loss=0.09244, mel_loss=0.03836, linear_loss=0.04811]
[2020-05-11 22:39:19.708]  Step 146774  [3.394 sec/step, loss=0.10022, avg_loss=0.09257, mel_loss=0.04595, linear_loss=0.05427]
[2020-05-11 22:39:23.148]  Step 146775  [3.414 sec/step, loss=0.10043, avg_loss=0.09269, mel_loss=0.04559, linear_loss=0.05484]
[2020-05-11 22:39:27.318]  Step 146776  [3.420 sec/step, loss=0.09887, avg_loss=0.09269, mel_loss=0.04496, linear_loss=0.05391]
[2020-05-11 22:39:28.097]  Step 146777  [3.395 sec/step, loss=0.07980, avg_loss=0.09250, mel_loss=0.03474, linear_loss=0.04506]
[2020-05-11 22:39:29.153]  Step 146778  [3.372 sec/step, loss=0.08445, avg_loss=0.09235, mel_loss=0.03708, linear_loss=0.04738]
[2020-05-11 22:39:32.294]  Step 146779  [3.313 sec/step, loss=0.09886, avg_loss=0.09236, mel_loss=0.04503, linear_loss=0.05383]
[2020-05-11 22:39:35.105]  Step 146780  [3.336 sec/step, loss=0.09649, avg_loss=0.09258, mel_loss=0.04372, linear_loss=0.05277]
[2020-05-11 22:39:39.784]  Step 146781  [3.366 sec/step, loss=0.09963, avg_loss=0.09270, mel_loss=0.04560, linear_loss=0.05403]
[2020-05-11 22:39:47.096]  Step 146782  [3.376 sec/step, loss=0.10132, avg_loss=0.09271, mel_loss=0.04738, linear_loss=0.05394]
[2020-05-11 22:39:48.366]  Step 146783  [3.364 sec/step, loss=0.08776, avg_loss=0.09265, mel_loss=0.03886, linear_loss=0.04890]
[2020-05-11 22:39:49.726]  Step 146784  [3.334 sec/step, loss=0.08964, avg_loss=0.09255, mel_loss=0.03958, linear_loss=0.05005]
[2020-05-11 22:39:50.545]  Step 146785  [3.325 sec/step, loss=0.07932, avg_loss=0.09243, mel_loss=0.03454, linear_loss=0.04478]
[2020-05-11 22:39:52.397]  Step 146786  [3.290 sec/step, loss=0.09325, avg_loss=0.09239, mel_loss=0.04150, linear_loss=0.05175]
[2020-05-11 22:39:55.915]  Step 146787  [3.315 sec/step, loss=0.09876, avg_loss=0.09252, mel_loss=0.04538, linear_loss=0.05338]
[2020-05-11 22:39:58.053]  Step 146788  [3.316 sec/step, loss=0.09504, avg_loss=0.09254, mel_loss=0.04260, linear_loss=0.05244]
[2020-05-11 22:40:00.088]  Step 146789  [3.329 sec/step, loss=0.09407, avg_loss=0.09266, mel_loss=0.04189, linear_loss=0.05218]
[2020-05-11 22:40:01.755]  Generated 32 batches of size 32 in 1.661 sec
[2020-05-11 22:40:05.303]  Step 146790  [3.352 sec/step, loss=0.10149, avg_loss=0.09272, mel_loss=0.04670, linear_loss=0.05479]
[2020-05-11 22:40:06.370]  Step 146791  [3.352 sec/step, loss=0.08368, avg_loss=0.09269, mel_loss=0.03696, linear_loss=0.04672]
[2020-05-11 22:40:13.080]  Step 146792  [3.397 sec/step, loss=0.10218, avg_loss=0.09278, mel_loss=0.04773, linear_loss=0.05444]
[2020-05-11 22:40:16.266]  Step 146793  [3.419 sec/step, loss=0.09842, avg_loss=0.09293, mel_loss=0.04482, linear_loss=0.05361]
[2020-05-11 22:40:18.036]  Step 146794  [3.410 sec/step, loss=0.09105, avg_loss=0.09289, mel_loss=0.04042, linear_loss=0.05063]
[2020-05-11 22:40:20.265]  Step 146795  [3.374 sec/step, loss=0.09246, avg_loss=0.09281, mel_loss=0.04169, linear_loss=0.05077]
[2020-05-11 22:40:22.674]  Step 146796  [3.352 sec/step, loss=0.09317, avg_loss=0.09275, mel_loss=0.04193, linear_loss=0.05124]
[2020-05-11 22:40:24.287]  Step 146797  [3.294 sec/step, loss=0.09044, avg_loss=0.09263, mel_loss=0.04012, linear_loss=0.05031]
[2020-05-11 22:40:28.742]  Step 146798  [3.316 sec/step, loss=0.10139, avg_loss=0.09270, mel_loss=0.04694, linear_loss=0.05445]
[2020-05-11 22:40:30.192]  Step 146799  [3.311 sec/step, loss=0.09164, avg_loss=0.09271, mel_loss=0.04086, linear_loss=0.05078]
[2020-05-11 22:40:39.010]  Step 146800  [3.256 sec/step, loss=0.09915, avg_loss=0.09289, mel_loss=0.04676, linear_loss=0.05239]
[2020-05-11 22:40:39.010]  Writing summary at step: 146800
[2020-05-11 22:40:40.165]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146800
[2020-05-11 22:40:41.547]  Saving audio and alignment...
[2020-05-11 22:40:43.281]  Input: 쉬어라~_____________
[2020-05-11 22:40:46.969]  Step 146801  [3.258 sec/step, loss=0.10044, avg_loss=0.09292, mel_loss=0.04576, linear_loss=0.05468]
[2020-05-11 22:40:49.154]  Step 146802  [3.266 sec/step, loss=0.09430, avg_loss=0.09297, mel_loss=0.04220, linear_loss=0.05210]
[2020-05-11 22:40:51.540]  Step 146803  [3.281 sec/step, loss=0.09429, avg_loss=0.09312, mel_loss=0.04258, linear_loss=0.05172]
[2020-05-11 22:40:54.117]  Step 146804  [3.266 sec/step, loss=0.09520, avg_loss=0.09309, mel_loss=0.04310, linear_loss=0.05210]
[2020-05-11 22:41:00.774]  Step 146805  [3.298 sec/step, loss=0.09862, avg_loss=0.09312, mel_loss=0.04593, linear_loss=0.05269]
[2020-05-11 22:41:02.383]  Step 146806  [3.273 sec/step, loss=0.09176, avg_loss=0.09304, mel_loss=0.04098, linear_loss=0.05079]
[2020-05-11 22:41:06.943]  Step 146807  [3.234 sec/step, loss=0.10039, avg_loss=0.09305, mel_loss=0.04633, linear_loss=0.05406]
[2020-05-11 22:41:12.108]  Step 146808  [3.264 sec/step, loss=0.09888, avg_loss=0.09311, mel_loss=0.04558, linear_loss=0.05331]
[2020-05-11 22:41:13.033]  Step 146809  [3.264 sec/step, loss=0.07737, avg_loss=0.09307, mel_loss=0.03424, linear_loss=0.04313]
[2020-05-11 22:41:16.811]  Step 146810  [3.259 sec/step, loss=0.09771, avg_loss=0.09305, mel_loss=0.04435, linear_loss=0.05336]
[2020-05-11 22:41:22.483]  Step 146811  [3.289 sec/step, loss=0.10176, avg_loss=0.09312, mel_loss=0.04702, linear_loss=0.05474]
[2020-05-11 22:41:33.737]  Step 146812  [3.385 sec/step, loss=0.09481, avg_loss=0.09316, mel_loss=0.04540, linear_loss=0.04941]
[2020-05-11 22:41:35.073]  Step 146813  [3.345 sec/step, loss=0.08720, avg_loss=0.09303, mel_loss=0.03863, linear_loss=0.04857]
[2020-05-11 22:41:39.203]  Step 146814  [3.352 sec/step, loss=0.09950, avg_loss=0.09303, mel_loss=0.04515, linear_loss=0.05435]
[2020-05-11 22:41:46.682]  Step 146815  [3.379 sec/step, loss=0.10193, avg_loss=0.09307, mel_loss=0.04777, linear_loss=0.05416]
[2020-05-11 22:41:48.589]  Step 146816  [3.361 sec/step, loss=0.09174, avg_loss=0.09299, mel_loss=0.04087, linear_loss=0.05087]
[2020-05-11 22:41:50.997]  Step 146817  [3.368 sec/step, loss=0.09540, avg_loss=0.09302, mel_loss=0.04280, linear_loss=0.05259]
[2020-05-11 22:41:52.755]  Step 146818  [3.278 sec/step, loss=0.09340, avg_loss=0.09298, mel_loss=0.04130, linear_loss=0.05210]
[2020-05-11 22:41:55.677]  Step 146819  [3.282 sec/step, loss=0.09539, avg_loss=0.09298, mel_loss=0.04304, linear_loss=0.05235]
[2020-05-11 22:41:56.280]  Step 146820  [3.276 sec/step, loss=0.07145, avg_loss=0.09281, mel_loss=0.03190, linear_loss=0.03955]
[2020-05-11 22:41:57.456]  Generated 32 batches of size 32 in 1.774 sec
[2020-05-11 22:42:00.648]  Step 146821  [3.288 sec/step, loss=0.09981, avg_loss=0.09285, mel_loss=0.04582, linear_loss=0.05400]
[2020-05-11 22:42:04.039]  Step 146822  [3.298 sec/step, loss=0.09878, avg_loss=0.09288, mel_loss=0.04485, linear_loss=0.05393]
[2020-05-11 22:42:04.887]  Step 146823  [3.292 sec/step, loss=0.08519, avg_loss=0.09285, mel_loss=0.03709, linear_loss=0.04810]
[2020-05-11 22:42:05.828]  Step 146824  [3.273 sec/step, loss=0.08710, avg_loss=0.09272, mel_loss=0.03839, linear_loss=0.04871]
[2020-05-11 22:42:06.892]  Step 146825  [3.263 sec/step, loss=0.08743, avg_loss=0.09264, mel_loss=0.03844, linear_loss=0.04899]
[2020-05-11 22:42:08.219]  Step 146826  [3.269 sec/step, loss=0.09082, avg_loss=0.09279, mel_loss=0.04025, linear_loss=0.05057]
[2020-05-11 22:42:10.213]  Step 146827  [3.278 sec/step, loss=0.09436, avg_loss=0.09287, mel_loss=0.04227, linear_loss=0.05210]
[2020-05-11 22:42:13.336]  Step 146828  [3.293 sec/step, loss=0.09848, avg_loss=0.09295, mel_loss=0.04482, linear_loss=0.05367]
[2020-05-11 22:42:14.827]  Step 146829  [3.298 sec/step, loss=0.08675, avg_loss=0.09299, mel_loss=0.03876, linear_loss=0.04799]
[2020-05-11 22:42:20.174]  Step 146830  [3.293 sec/step, loss=0.10037, avg_loss=0.09298, mel_loss=0.04636, linear_loss=0.05401]
[2020-05-11 22:42:22.620]  Step 146831  [3.249 sec/step, loss=0.09423, avg_loss=0.09292, mel_loss=0.04216, linear_loss=0.05207]
[2020-05-11 22:42:28.061]  Step 146832  [3.284 sec/step, loss=0.10009, avg_loss=0.09300, mel_loss=0.04624, linear_loss=0.05386]
[2020-05-11 22:42:29.328]  Step 146833  [3.283 sec/step, loss=0.08680, avg_loss=0.09300, mel_loss=0.03839, linear_loss=0.04840]
[2020-05-11 22:42:32.224]  Step 146834  [3.304 sec/step, loss=0.09652, avg_loss=0.09316, mel_loss=0.04397, linear_loss=0.05255]
[2020-05-11 22:42:34.383]  Step 146835  [3.320 sec/step, loss=0.09499, avg_loss=0.09340, mel_loss=0.04246, linear_loss=0.05254]
[2020-05-11 22:42:36.140]  Step 146836  [3.263 sec/step, loss=0.09237, avg_loss=0.09329, mel_loss=0.04107, linear_loss=0.05130]
[2020-05-11 22:42:44.394]  Step 146837  [3.326 sec/step, loss=0.09943, avg_loss=0.09337, mel_loss=0.04663, linear_loss=0.05280]
[2020-05-11 22:42:51.799]  Step 146838  [3.391 sec/step, loss=0.10009, avg_loss=0.09358, mel_loss=0.04676, linear_loss=0.05332]
[2020-05-11 22:42:55.211]  Step 146839  [3.412 sec/step, loss=0.09799, avg_loss=0.09366, mel_loss=0.04458, linear_loss=0.05341]
[2020-05-11 22:42:59.455]  Step 146840  [3.446 sec/step, loss=0.09990, avg_loss=0.09384, mel_loss=0.04592, linear_loss=0.05398]
[2020-05-11 22:43:00.553]  Step 146841  [3.423 sec/step, loss=0.08761, avg_loss=0.09374, mel_loss=0.03829, linear_loss=0.04933]
[2020-05-11 22:43:02.468]  Step 146842  [3.367 sec/step, loss=0.09300, avg_loss=0.09368, mel_loss=0.04136, linear_loss=0.05163]
[2020-05-11 22:43:04.108]  Step 146843  [3.373 sec/step, loss=0.08988, avg_loss=0.09376, mel_loss=0.04004, linear_loss=0.04984]
[2020-05-11 22:43:08.884]  Step 146844  [3.391 sec/step, loss=0.09886, avg_loss=0.09376, mel_loss=0.04530, linear_loss=0.05356]
[2020-05-11 22:43:10.498]  Step 146845  [3.370 sec/step, loss=0.09264, avg_loss=0.09370, mel_loss=0.04110, linear_loss=0.05153]
[2020-05-11 22:43:13.241]  Step 146846  [3.380 sec/step, loss=0.09476, avg_loss=0.09371, mel_loss=0.04273, linear_loss=0.05203]
[2020-05-11 22:43:16.589]  Step 146847  [3.358 sec/step, loss=0.09756, avg_loss=0.09367, mel_loss=0.04405, linear_loss=0.05352]
[2020-05-11 22:43:17.400]  Step 146848  [3.280 sec/step, loss=0.08190, avg_loss=0.09350, mel_loss=0.03568, linear_loss=0.04623]
[2020-05-11 22:43:20.523]  Step 146849  [3.288 sec/step, loss=0.09738, avg_loss=0.09350, mel_loss=0.04400, linear_loss=0.05338]
[2020-05-11 22:43:24.206]  Step 146850  [3.309 sec/step, loss=0.10077, avg_loss=0.09358, mel_loss=0.04629, linear_loss=0.05448]
[2020-05-11 22:43:24.206]  Writing summary at step: 146850
[2020-05-11 22:43:26.619]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146850
[2020-05-11 22:43:28.008]  Saving audio and alignment...
[2020-05-11 22:43:30.093]  Generated 32 batches of size 32 in 1.520 sec
[2020-05-11 22:43:30.561]  Input: 목소리가~__________________
[2020-05-11 22:43:31.127]  Step 146851  [3.270 sec/step, loss=0.07382, avg_loss=0.09333, mel_loss=0.03294, linear_loss=0.04087]
[2020-05-11 22:43:31.921]  Step 146852  [3.267 sec/step, loss=0.07858, avg_loss=0.09327, mel_loss=0.03428, linear_loss=0.04429]
[2020-05-11 22:43:35.904]  Step 146853  [3.285 sec/step, loss=0.09817, avg_loss=0.09330, mel_loss=0.04464, linear_loss=0.05352]
[2020-05-11 22:43:37.280]  Step 146854  [3.237 sec/step, loss=0.08805, avg_loss=0.09319, mel_loss=0.03939, linear_loss=0.04866]
[2020-05-11 22:43:43.915]  Step 146855  [3.268 sec/step, loss=0.10001, avg_loss=0.09322, mel_loss=0.04641, linear_loss=0.05360]
[2020-05-11 22:43:58.122]  Step 146856  [3.283 sec/step, loss=0.07620, avg_loss=0.09310, mel_loss=0.03646, linear_loss=0.03974]
[2020-05-11 22:43:59.213]  Step 146857  [3.279 sec/step, loss=0.08584, avg_loss=0.09303, mel_loss=0.03787, linear_loss=0.04797]
[2020-05-11 22:44:01.270]  Step 146858  [3.281 sec/step, loss=0.09304, avg_loss=0.09302, mel_loss=0.04199, linear_loss=0.05105]
[2020-05-11 22:44:02.784]  Step 146859  [3.271 sec/step, loss=0.08926, avg_loss=0.09298, mel_loss=0.03994, linear_loss=0.04931]
[2020-05-11 22:44:05.331]  Step 146860  [3.282 sec/step, loss=0.09528, avg_loss=0.09303, mel_loss=0.04311, linear_loss=0.05217]
[2020-05-11 22:44:07.068]  Step 146861  [3.269 sec/step, loss=0.09197, avg_loss=0.09296, mel_loss=0.04061, linear_loss=0.05136]
[2020-05-11 22:44:08.923]  Step 146862  [3.275 sec/step, loss=0.09244, avg_loss=0.09303, mel_loss=0.04084, linear_loss=0.05160]
[2020-05-11 22:44:17.681]  Step 146863  [3.334 sec/step, loss=0.09866, avg_loss=0.09306, mel_loss=0.04659, linear_loss=0.05207]
[2020-05-11 22:44:18.666]  Step 146864  [3.299 sec/step, loss=0.08221, avg_loss=0.09288, mel_loss=0.03607, linear_loss=0.04614]
[2020-05-11 22:44:22.313]  Step 146865  [3.315 sec/step, loss=0.09906, avg_loss=0.09293, mel_loss=0.04518, linear_loss=0.05388]
[2020-05-11 22:44:36.577]  Step 146866  [3.448 sec/step, loss=0.08008, avg_loss=0.09299, mel_loss=0.03859, linear_loss=0.04148]
[2020-05-11 22:44:41.647]  Step 146867  [3.487 sec/step, loss=0.09869, avg_loss=0.09309, mel_loss=0.04563, linear_loss=0.05307]
[2020-05-11 22:44:42.748]  Step 146868  [3.470 sec/step, loss=0.08638, avg_loss=0.09300, mel_loss=0.03787, linear_loss=0.04851]
[2020-05-11 22:44:43.546]  Step 146869  [3.390 sec/step, loss=0.07900, avg_loss=0.09280, mel_loss=0.03492, linear_loss=0.04407]
[2020-05-11 22:44:49.025]  Step 146870  [3.301 sec/step, loss=0.10026, avg_loss=0.09300, mel_loss=0.04635, linear_loss=0.05391]
[2020-05-11 22:44:51.854]  Step 146871  [3.272 sec/step, loss=0.09761, avg_loss=0.09297, mel_loss=0.04430, linear_loss=0.05331]
[2020-05-11 22:44:59.273]  Step 146872  [3.341 sec/step, loss=0.10000, avg_loss=0.09322, mel_loss=0.04684, linear_loss=0.05317]
[2020-05-11 22:45:00.975]  Step 146873  [3.343 sec/step, loss=0.09162, avg_loss=0.09327, mel_loss=0.04101, linear_loss=0.05061]
[2020-05-11 22:45:02.355]  Step 146874  [3.320 sec/step, loss=0.09022, avg_loss=0.09317, mel_loss=0.04011, linear_loss=0.05012]
[2020-05-11 22:45:08.394]  Step 146875  [3.346 sec/step, loss=0.09915, avg_loss=0.09315, mel_loss=0.04614, linear_loss=0.05302]
[2020-05-11 22:45:09.526]  Step 146876  [3.316 sec/step, loss=0.08832, avg_loss=0.09305, mel_loss=0.03931, linear_loss=0.04900]
[2020-05-11 22:45:10.867]  Step 146877  [3.321 sec/step, loss=0.08736, avg_loss=0.09312, mel_loss=0.03862, linear_loss=0.04874]
[2020-05-11 22:45:14.316]  Step 146878  [3.345 sec/step, loss=0.09785, avg_loss=0.09326, mel_loss=0.04451, linear_loss=0.05334]
[2020-05-11 22:45:14.876]  Step 146879  [3.319 sec/step, loss=0.07425, avg_loss=0.09301, mel_loss=0.03327, linear_loss=0.04098]
[2020-05-11 22:45:16.830]  Step 146880  [3.311 sec/step, loss=0.09392, avg_loss=0.09299, mel_loss=0.04192, linear_loss=0.05199]
[2020-05-11 22:45:21.221]  Step 146881  [3.308 sec/step, loss=0.09961, avg_loss=0.09299, mel_loss=0.04573, linear_loss=0.05387]
[2020-05-11 22:45:22.947]  Generated 32 batches of size 32 in 1.720 sec
[2020-05-11 22:45:23.725]  Step 146882  [3.260 sec/step, loss=0.09340, avg_loss=0.09291, mel_loss=0.04192, linear_loss=0.05149]
[2020-05-11 22:45:27.018]  Step 146883  [3.280 sec/step, loss=0.09990, avg_loss=0.09303, mel_loss=0.04544, linear_loss=0.05446]
[2020-05-11 22:45:29.109]  Step 146884  [3.287 sec/step, loss=0.09314, avg_loss=0.09306, mel_loss=0.04185, linear_loss=0.05129]
[2020-05-11 22:45:29.822]  Step 146885  [3.286 sec/step, loss=0.07971, avg_loss=0.09307, mel_loss=0.03532, linear_loss=0.04439]
[2020-05-11 22:45:32.051]  Step 146886  [3.290 sec/step, loss=0.09501, avg_loss=0.09308, mel_loss=0.04290, linear_loss=0.05211]
[2020-05-11 22:45:35.114]  Step 146887  [3.285 sec/step, loss=0.09816, avg_loss=0.09308, mel_loss=0.04445, linear_loss=0.05371]
[2020-05-11 22:45:38.459]  Step 146888  [3.298 sec/step, loss=0.09867, avg_loss=0.09312, mel_loss=0.04514, linear_loss=0.05353]
[2020-05-11 22:45:42.624]  Step 146889  [3.319 sec/step, loss=0.09825, avg_loss=0.09316, mel_loss=0.04502, linear_loss=0.05322]
[2020-05-11 22:45:43.649]  Step 146890  [3.277 sec/step, loss=0.08407, avg_loss=0.09298, mel_loss=0.03704, linear_loss=0.04703]
[2020-05-11 22:45:44.958]  Step 146891  [3.279 sec/step, loss=0.08748, avg_loss=0.09302, mel_loss=0.03870, linear_loss=0.04878]
[2020-05-11 22:45:50.161]  Step 146892  [3.264 sec/step, loss=0.09949, avg_loss=0.09299, mel_loss=0.04634, linear_loss=0.05316]
[2020-05-11 22:45:51.023]  Step 146893  [3.241 sec/step, loss=0.08094, avg_loss=0.09282, mel_loss=0.03523, linear_loss=0.04571]
[2020-05-11 22:45:52.395]  Step 146894  [3.237 sec/step, loss=0.08740, avg_loss=0.09278, mel_loss=0.03870, linear_loss=0.04870]
[2020-05-11 22:45:53.938]  Step 146895  [3.230 sec/step, loss=0.09149, avg_loss=0.09277, mel_loss=0.04054, linear_loss=0.05095]
[2020-05-11 22:45:55.520]  Step 146896  [3.222 sec/step, loss=0.09234, avg_loss=0.09276, mel_loss=0.04149, linear_loss=0.05085]
[2020-05-11 22:45:56.491]  Step 146897  [3.216 sec/step, loss=0.08641, avg_loss=0.09272, mel_loss=0.03802, linear_loss=0.04839]
[2020-05-11 22:46:04.060]  Step 146898  [3.247 sec/step, loss=0.10044, avg_loss=0.09271, mel_loss=0.04705, linear_loss=0.05339]
[2020-05-11 22:46:04.832]  Step 146899  [3.240 sec/step, loss=0.08418, avg_loss=0.09264, mel_loss=0.03693, linear_loss=0.04725]
[2020-05-11 22:46:09.157]  Step 146900  [3.195 sec/step, loss=0.10072, avg_loss=0.09266, mel_loss=0.04628, linear_loss=0.05444]
[2020-05-11 22:46:09.157]  Writing summary at step: 146900
[2020-05-11 22:46:11.614]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146900
[2020-05-11 22:46:12.998]  Saving audio and alignment...
[2020-05-11 22:46:16.427]  Input: 병원 치료 대신 자연을 벗 삼아~___________
[2020-05-11 22:46:18.119]  Step 146901  [3.175 sec/step, loss=0.09343, avg_loss=0.09259, mel_loss=0.04131, linear_loss=0.05212]
[2020-05-11 22:46:23.746]  Step 146902  [3.209 sec/step, loss=0.10084, avg_loss=0.09265, mel_loss=0.04672, linear_loss=0.05412]
[2020-05-11 22:46:24.882]  Step 146903  [3.197 sec/step, loss=0.08789, avg_loss=0.09259, mel_loss=0.03852, linear_loss=0.04936]
[2020-05-11 22:46:27.939]  Step 146904  [3.202 sec/step, loss=0.09771, avg_loss=0.09261, mel_loss=0.04408, linear_loss=0.05362]
[2020-05-11 22:46:30.163]  Step 146905  [3.157 sec/step, loss=0.09283, avg_loss=0.09255, mel_loss=0.04165, linear_loss=0.05117]
[2020-05-11 22:46:43.328]  Step 146906  [3.273 sec/step, loss=0.08440, avg_loss=0.09248, mel_loss=0.04032, linear_loss=0.04408]
[2020-05-11 22:46:45.844]  Step 146907  [3.253 sec/step, loss=0.09374, avg_loss=0.09241, mel_loss=0.04201, linear_loss=0.05172]
[2020-05-11 22:46:50.501]  Step 146908  [3.247 sec/step, loss=0.10076, avg_loss=0.09243, mel_loss=0.04624, linear_loss=0.05452]
[2020-05-11 22:46:54.452]  Step 146909  [3.278 sec/step, loss=0.09906, avg_loss=0.09265, mel_loss=0.04535, linear_loss=0.05371]
[2020-05-11 22:46:56.363]  Step 146910  [3.259 sec/step, loss=0.09051, avg_loss=0.09258, mel_loss=0.04045, linear_loss=0.05006]
[2020-05-11 22:46:57.204]  Step 146911  [3.211 sec/step, loss=0.07754, avg_loss=0.09234, mel_loss=0.03425, linear_loss=0.04330]
[2020-05-11 22:46:58.968]  Generated 32 batches of size 32 in 1.758 sec
[2020-05-11 22:47:03.469]  Step 146912  [3.161 sec/step, loss=0.09997, avg_loss=0.09239, mel_loss=0.04667, linear_loss=0.05330]
[2020-05-11 22:47:12.273]  Step 146913  [3.236 sec/step, loss=0.09976, avg_loss=0.09251, mel_loss=0.04689, linear_loss=0.05286]
[2020-05-11 22:47:15.207]  Step 146914  [3.224 sec/step, loss=0.09856, avg_loss=0.09250, mel_loss=0.04451, linear_loss=0.05405]
[2020-05-11 22:47:18.052]  Step 146915  [3.177 sec/step, loss=0.09548, avg_loss=0.09244, mel_loss=0.04325, linear_loss=0.05223]
[2020-05-11 22:47:18.608]  Step 146916  [3.164 sec/step, loss=0.07365, avg_loss=0.09226, mel_loss=0.03308, linear_loss=0.04057]
[2020-05-11 22:47:19.652]  Step 146917  [3.150 sec/step, loss=0.08807, avg_loss=0.09218, mel_loss=0.03876, linear_loss=0.04931]
[2020-05-11 22:47:21.665]  Step 146918  [3.153 sec/step, loss=0.09386, avg_loss=0.09219, mel_loss=0.04207, linear_loss=0.05179]
[2020-05-11 22:47:25.316]  Step 146919  [3.160 sec/step, loss=0.09771, avg_loss=0.09221, mel_loss=0.04477, linear_loss=0.05294]
[2020-05-11 22:47:28.712]  Step 146920  [3.188 sec/step, loss=0.09536, avg_loss=0.09245, mel_loss=0.04346, linear_loss=0.05189]
[2020-05-11 22:47:34.409]  Step 146921  [3.201 sec/step, loss=0.10073, avg_loss=0.09246, mel_loss=0.04673, linear_loss=0.05400]
[2020-05-11 22:47:35.050]  Step 146922  [3.174 sec/step, loss=0.08167, avg_loss=0.09229, mel_loss=0.03617, linear_loss=0.04550]
[2020-05-11 22:47:37.703]  Step 146923  [3.192 sec/step, loss=0.09600, avg_loss=0.09240, mel_loss=0.04355, linear_loss=0.05245]
[2020-05-11 22:47:38.506]  Step 146924  [3.190 sec/step, loss=0.07925, avg_loss=0.09232, mel_loss=0.03456, linear_loss=0.04469]
[2020-05-11 22:47:39.518]  Step 146925  [3.190 sec/step, loss=0.08428, avg_loss=0.09229, mel_loss=0.03713, linear_loss=0.04716]
[2020-05-11 22:47:40.767]  Step 146926  [3.189 sec/step, loss=0.08846, avg_loss=0.09226, mel_loss=0.03936, linear_loss=0.04910]
[2020-05-11 22:47:45.568]  Step 146927  [3.217 sec/step, loss=0.09928, avg_loss=0.09231, mel_loss=0.04533, linear_loss=0.05395]
[2020-05-11 22:47:49.693]  Step 146928  [3.227 sec/step, loss=0.09816, avg_loss=0.09231, mel_loss=0.04470, linear_loss=0.05346]
[2020-05-11 22:47:53.939]  Step 146929  [3.255 sec/step, loss=0.09681, avg_loss=0.09241, mel_loss=0.04416, linear_loss=0.05265]
[2020-05-11 22:48:05.204]  Step 146930  [3.314 sec/step, loss=0.10110, avg_loss=0.09242, mel_loss=0.04715, linear_loss=0.05395]
[2020-05-11 22:48:11.596]  Step 146931  [3.353 sec/step, loss=0.09937, avg_loss=0.09247, mel_loss=0.04579, linear_loss=0.05358]
[2020-05-11 22:48:13.020]  Step 146932  [3.313 sec/step, loss=0.08859, avg_loss=0.09235, mel_loss=0.03975, linear_loss=0.04884]
[2020-05-11 22:48:17.590]  Step 146933  [3.346 sec/step, loss=0.10123, avg_loss=0.09250, mel_loss=0.04674, linear_loss=0.05449]
[2020-05-11 22:48:19.734]  Step 146934  [3.339 sec/step, loss=0.09357, avg_loss=0.09247, mel_loss=0.04217, linear_loss=0.05140]
[2020-05-11 22:48:29.141]  Step 146935  [3.411 sec/step, loss=0.10017, avg_loss=0.09252, mel_loss=0.04744, linear_loss=0.05273]
[2020-05-11 22:48:30.872]  Step 146936  [3.411 sec/step, loss=0.09036, avg_loss=0.09250, mel_loss=0.04023, linear_loss=0.05013]
[2020-05-11 22:48:31.460]  Step 146937  [3.334 sec/step, loss=0.07364, avg_loss=0.09224, mel_loss=0.03284, linear_loss=0.04079]
[2020-05-11 22:48:33.034]  Step 146938  [3.276 sec/step, loss=0.09137, avg_loss=0.09216, mel_loss=0.04062, linear_loss=0.05074]
[2020-05-11 22:48:35.725]  Step 146939  [3.269 sec/step, loss=0.09502, avg_loss=0.09213, mel_loss=0.04271, linear_loss=0.05231]
[2020-05-11 22:48:39.163]  Step 146940  [3.261 sec/step, loss=0.09981, avg_loss=0.09212, mel_loss=0.04531, linear_loss=0.05450]
[2020-05-11 22:48:40.289]  Step 146941  [3.261 sec/step, loss=0.08470, avg_loss=0.09210, mel_loss=0.03715, linear_loss=0.04755]
[2020-05-11 22:48:42.191]  Step 146942  [3.261 sec/step, loss=0.09338, avg_loss=0.09210, mel_loss=0.04181, linear_loss=0.05158]
[2020-05-11 22:48:43.513]  Step 146943  [3.258 sec/step, loss=0.08962, avg_loss=0.09210, mel_loss=0.03955, linear_loss=0.05008]
[2020-05-11 22:48:45.266]  Generated 32 batches of size 32 in 1.747 sec
[2020-05-11 22:48:45.992]  Step 146944  [3.235 sec/step, loss=0.09349, avg_loss=0.09204, mel_loss=0.04229, linear_loss=0.05120]
[2020-05-11 22:48:49.498]  Step 146945  [3.253 sec/step, loss=0.09557, avg_loss=0.09207, mel_loss=0.04329, linear_loss=0.05229]
[2020-05-11 22:49:03.854]  Step 146946  [3.370 sec/step, loss=0.07952, avg_loss=0.09192, mel_loss=0.03820, linear_loss=0.04132]
[2020-05-11 22:49:05.752]  Step 146947  [3.355 sec/step, loss=0.09192, avg_loss=0.09186, mel_loss=0.04076, linear_loss=0.05116]
[2020-05-11 22:49:06.805]  Step 146948  [3.358 sec/step, loss=0.08287, avg_loss=0.09187, mel_loss=0.03626, linear_loss=0.04661]
[2020-05-11 22:49:13.871]  Step 146949  [3.397 sec/step, loss=0.10338, avg_loss=0.09193, mel_loss=0.04826, linear_loss=0.05512]
[2020-05-11 22:49:17.578]  Step 146950  [3.397 sec/step, loss=0.09991, avg_loss=0.09192, mel_loss=0.04545, linear_loss=0.05446]
[2020-05-11 22:49:17.578]  Writing summary at step: 146950
[2020-05-11 22:49:20.961]  Saving checkpoint to: ./logs-tacotron/model.ckpt-146950
[2020-05-11 22:49:22.307]  Saving audio and alignment...
[2020-05-11 22:49:25.976]  Input: 그냥 마이크 온 만 시켜서~____________________
[2020-05-11 22:49:26.563]  Step 146951  [3.397 sec/step, loss=0.07233, avg_loss=0.09191, mel_loss=0.03246, linear_loss=0.03987]
[2020-05-11 22:49:27.938]  Step 146952  [3.403 sec/step, loss=0.08740, avg_loss=0.09200, mel_loss=0.03847, linear_loss=0.04893]
[2020-05-11 22:49:29.080]  Step 146953  [3.375 sec/step, loss=0.08487, avg_loss=0.09187, mel_loss=0.03712, linear_loss=0.04775]
[2020-05-11 22:49:32.083]  Step 146954  [3.391 sec/step, loss=0.09703, avg_loss=0.09196, mel_loss=0.04374, linear_loss=0.05329]
[2020-05-11 22:49:33.855]  Step 146955  [3.342 sec/step, loss=0.09240, avg_loss=0.09188, mel_loss=0.04086, linear_loss=0.05153]
[2020-05-11 22:49:36.318]  Step 146956  [3.225 sec/step, loss=0.09558, avg_loss=0.09207, mel_loss=0.04271, linear_loss=0.05287]
[2020-05-11 22:49:41.169]  Step 146957  [3.263 sec/step, loss=0.09852, avg_loss=0.09220, mel_loss=0.04521, linear_loss=0.05331]
[2020-05-11 22:49:42.217]  Step 146958  [3.253 sec/step, loss=0.08499, avg_loss=0.09212, mel_loss=0.03737, linear_loss=0.04762]
[2020-05-11 22:49:45.641]  Step 146959  [3.272 sec/step, loss=0.09634, avg_loss=0.09219, mel_loss=0.04387, linear_loss=0.05247]
[2020-05-11 22:49:59.933]  Step 146960  [3.389 sec/step, loss=0.07636, avg_loss=0.09200, mel_loss=0.03666, linear_loss=0.03970]
[2020-05-11 22:50:01.201]  Step 146961  [3.384 sec/step, loss=0.08713, avg_loss=0.09195, mel_loss=0.03858, linear_loss=0.04856]
[2020-05-11 22:50:07.628]  Step 146962  [3.430 sec/step, loss=0.09921, avg_loss=0.09202, mel_loss=0.04599, linear_loss=0.05322]
[2020-05-11 22:50:09.604]  Step 146963  [3.362 sec/step, loss=0.09322, avg_loss=0.09197, mel_loss=0.04160, linear_loss=0.05162]
[2020-05-11 22:50:10.419]  Step 146964  [3.361 sec/step, loss=0.07961, avg_loss=0.09194, mel_loss=0.03482, linear_loss=0.04480]
[2020-05-11 22:50:15.797]  Step 146965  [3.378 sec/step, loss=0.10138, avg_loss=0.09196, mel_loss=0.04700, linear_loss=0.05438]
[2020-05-11 22:50:19.952]  Step 146966  [3.277 sec/step, loss=0.09905, avg_loss=0.09215, mel_loss=0.04521, linear_loss=0.05384]
[2020-05-11 22:50:22.892]  Step 146967  [3.256 sec/step, loss=0.09560, avg_loss=0.09212, mel_loss=0.04315, linear_loss=0.05245]
[2020-05-11 22:50:25.658]  Step 146968  [3.272 sec/step, loss=0.09519, avg_loss=0.09221, mel_loss=0.04317, linear_loss=0.05203]
[2020-05-11 22:50:31.344]  Step 146969  [3.321 sec/step, loss=0.10031, avg_loss=0.09242, mel_loss=0.04646, linear_loss=0.05384]
[2020-05-11 22:50:32.157]  Step 146970  [3.274 sec/step, loss=0.07360, avg_loss=0.09216, mel_loss=0.03205, linear_loss=0.04156]
[2020-05-11 22:50:34.374]  Step 146971  [3.268 sec/step, loss=0.09400, avg_loss=0.09212, mel_loss=0.04229, linear_loss=0.05172]
[2020-05-11 22:50:35.325]  Step 146972  [3.204 sec/step, loss=0.08024, avg_loss=0.09192, mel_loss=0.03510, linear_loss=0.04514]
[2020-05-11 22:50:36.933]  Step 146973  [3.203 sec/step, loss=0.08981, avg_loss=0.09190, mel_loss=0.04013, linear_loss=0.04968]
[2020-05-11 22:50:38.473]  Step 146974  [3.204 sec/step, loss=0.08875, avg_loss=0.09189, mel_loss=0.03938, linear_loss=0.04937]
[2020-05-11 22:50:38.717]  Generated 32 batches of size 32 in 1.778 sec
[2020-05-11 22:50:40.215]  Step 146975  [3.161 sec/step, loss=0.09289, avg_loss=0.09183, mel_loss=0.04110, linear_loss=0.05179]
[2020-05-11 22:50:44.389]  Step 146976  [3.192 sec/step, loss=0.10018, avg_loss=0.09195, mel_loss=0.04622, linear_loss=0.05396]
[2020-05-11 22:50:47.688]  Step 146977  [3.211 sec/step, loss=0.09870, avg_loss=0.09206, mel_loss=0.04487, linear_loss=0.05383]
[2020-05-11 22:50:50.094]  Step 146978  [3.201 sec/step, loss=0.09505, avg_loss=0.09203, mel_loss=0.04275, linear_loss=0.05229]
[2020-05-11 22:50:58.639]  Step 146979  [3.281 sec/step, loss=0.09698, avg_loss=0.09226, mel_loss=0.04538, linear_loss=0.05161]
[2020-05-11 22:51:06.255]  Step 146980  [3.337 sec/step, loss=0.10042, avg_loss=0.09232, mel_loss=0.04696, linear_loss=0.05345]
[2020-05-11 22:51:09.909]  Step 146981  [3.330 sec/step, loss=0.10003, avg_loss=0.09233, mel_loss=0.04557, linear_loss=0.05445]
[2020-05-11 22:51:11.918]  Step 146982  [3.325 sec/step, loss=0.09497, avg_loss=0.09234, mel_loss=0.04241, linear_loss=0.05256]
[2020-05-11 22:51:17.450]  Step 146983  [3.347 sec/step, loss=0.09649, avg_loss=0.09231, mel_loss=0.04443, linear_loss=0.05206]
[2020-05-11 22:51:20.316]  Step 146984  [3.355 sec/step, loss=0.09581, avg_loss=0.09234, mel_loss=0.04330, linear_loss=0.05251]
[2020-05-11 22:51:21.079]  Step 146985  [3.356 sec/step, loss=0.07475, avg_loss=0.09229, mel_loss=0.03337, linear_loss=0.04137]
[2020-05-11 22:51:22.063]  Step 146986  [3.343 sec/step, loss=0.08455, avg_loss=0.09218, mel_loss=0.03699, linear_loss=0.04756]
[2020-05-11 22:51:23.038]  Step 146987  [3.322 sec/step, loss=0.08528, avg_loss=0.09205, mel_loss=0.03683, linear_loss=0.04845]
[2020-05-11 22:51:24.787]  Step 146988  [3.306 sec/step, loss=0.08977, avg_loss=0.09196, mel_loss=0.04006, linear_loss=0.04971]
[2020-05-11 22:51:28.804]  Step 146989  [3.305 sec/step, loss=0.09780, avg_loss=0.09196, mel_loss=0.04480, linear_loss=0.05301]
[2020-05-11 22:51:41.291]  Step 146990  [3.419 sec/step, loss=0.08967, avg_loss=0.09202, mel_loss=0.04316, linear_loss=0.04651]
[2020-05-11 22:51:43.873]  Step 146991  [3.432 sec/step, loss=0.09683, avg_loss=0.09211, mel_loss=0.04361, linear_loss=0.05322]
[2020-05-11 22:51:47.008]  Step 146992  [3.412 sec/step, loss=0.09914, avg_loss=0.09211, mel_loss=0.04496, linear_loss=0.05418]
[2020-05-11 22:51:48.315]  Step 146993  [3.416 sec/step, loss=0.09184, avg_loss=0.09221, mel_loss=0.04051, linear_loss=0.05133]
[2020-05-11 22:51:51.793]  Step 146994  [3.437 sec/step, loss=0.09659, avg_loss=0.09231, mel_loss=0.04416, linear_loss=0.05243]
[2020-05-11 22:51:53.024]  Step 146995  [3.434 sec/step, loss=0.08507, avg_loss=0.09224, mel_loss=0.03765, linear_loss=0.04742]
[2020-05-11 22:51:55.050]  Step 146996  [3.438 sec/step, loss=0.09267, avg_loss=0.09225, mel_loss=0.04148, linear_loss=0.05118]
[2020-05-11 22:52:02.262]  Step 146997  [3.501 sec/step, loss=0.09861, avg_loss=0.09237, mel_loss=0.04613, linear_loss=0.05248]
[2020-05-11 22:52:04.205]  Step 146998  [3.445 sec/step, loss=0.09267, avg_loss=0.09229, mel_loss=0.04154, linear_loss=0.05113]
[2020-05-11 22:52:07.816]  Step 146999  [3.473 sec/step, loss=0.09771, avg_loss=0.09242, mel_loss=0.04443, linear_loss=0.05329]
[2020-05-11 22:52:13.784]  Step 147000  [3.489 sec/step, loss=0.10285, avg_loss=0.09245, mel_loss=0.04806, linear_loss=0.05479]
[2020-05-11 22:52:13.784]  Writing summary at step: 147000
[2020-05-11 22:52:17.521]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147000
[2020-05-11 22:52:18.895]  Saving audio and alignment...
[2020-05-11 22:52:22.091]  Input: 자 아까는 저축을 강조했죠~_____________
[2020-05-11 22:52:30.715]  Step 147001  [3.559 sec/step, loss=0.09741, avg_loss=0.09249, mel_loss=0.04612, linear_loss=0.05129]
[2020-05-11 22:52:31.480]  Step 147002  [3.510 sec/step, loss=0.08632, avg_loss=0.09234, mel_loss=0.03774, linear_loss=0.04859]
[2020-05-11 22:52:34.661]  Step 147003  [3.530 sec/step, loss=0.09864, avg_loss=0.09245, mel_loss=0.04494, linear_loss=0.05370]
[2020-05-11 22:52:36.427]  Generated 32 batches of size 32 in 1.760 sec
[2020-05-11 22:52:36.973]  Step 147004  [3.523 sec/step, loss=0.09466, avg_loss=0.09242, mel_loss=0.04265, linear_loss=0.05201]
[2020-05-11 22:52:38.528]  Step 147005  [3.516 sec/step, loss=0.09160, avg_loss=0.09241, mel_loss=0.04072, linear_loss=0.05087]
[2020-05-11 22:52:39.565]  Step 147006  [3.395 sec/step, loss=0.08625, avg_loss=0.09242, mel_loss=0.03773, linear_loss=0.04852]
[2020-05-11 22:52:44.487]  Step 147007  [3.419 sec/step, loss=0.10135, avg_loss=0.09250, mel_loss=0.04641, linear_loss=0.05494]
[2020-05-11 22:52:45.945]  Step 147008  [3.387 sec/step, loss=0.09061, avg_loss=0.09240, mel_loss=0.04017, linear_loss=0.05043]
[2020-05-11 22:52:47.524]  Step 147009  [3.363 sec/step, loss=0.09378, avg_loss=0.09235, mel_loss=0.04157, linear_loss=0.05220]
[2020-05-11 22:52:52.333]  Step 147010  [3.392 sec/step, loss=0.10033, avg_loss=0.09244, mel_loss=0.04622, linear_loss=0.05410]
[2020-05-11 22:52:54.768]  Step 147011  [3.408 sec/step, loss=0.09390, avg_loss=0.09261, mel_loss=0.04216, linear_loss=0.05175]
[2020-05-11 22:52:55.421]  Step 147012  [3.352 sec/step, loss=0.08025, avg_loss=0.09241, mel_loss=0.03517, linear_loss=0.04508]
[2020-05-11 22:52:56.385]  Step 147013  [3.274 sec/step, loss=0.08388, avg_loss=0.09225, mel_loss=0.03669, linear_loss=0.04719]
[2020-05-11 22:53:00.951]  Step 147014  [3.290 sec/step, loss=0.10026, avg_loss=0.09227, mel_loss=0.04602, linear_loss=0.05424]
[2020-05-11 22:53:04.091]  Step 147015  [3.293 sec/step, loss=0.09805, avg_loss=0.09229, mel_loss=0.04444, linear_loss=0.05362]
[2020-05-11 22:53:05.442]  Step 147016  [3.301 sec/step, loss=0.08945, avg_loss=0.09245, mel_loss=0.03961, linear_loss=0.04984]
[2020-05-11 22:53:06.935]  Step 147017  [3.306 sec/step, loss=0.09059, avg_loss=0.09248, mel_loss=0.03992, linear_loss=0.05067]
[2020-05-11 22:53:08.254]  Step 147018  [3.299 sec/step, loss=0.08768, avg_loss=0.09242, mel_loss=0.03895, linear_loss=0.04874]
[2020-05-11 22:53:10.383]  Step 147019  [3.283 sec/step, loss=0.09246, avg_loss=0.09236, mel_loss=0.04139, linear_loss=0.05107]
[2020-05-11 22:53:14.042]  Step 147020  [3.286 sec/step, loss=0.09875, avg_loss=0.09240, mel_loss=0.04511, linear_loss=0.05364]
[2020-05-11 22:53:15.086]  Step 147021  [3.239 sec/step, loss=0.08712, avg_loss=0.09226, mel_loss=0.03834, linear_loss=0.04878]
[2020-05-11 22:53:28.918]  Step 147022  [3.371 sec/step, loss=0.07544, avg_loss=0.09220, mel_loss=0.03598, linear_loss=0.03946]
[2020-05-11 22:53:36.143]  Step 147023  [3.417 sec/step, loss=0.10267, avg_loss=0.09227, mel_loss=0.04802, linear_loss=0.05464]
[2020-05-11 22:53:37.870]  Step 147024  [3.426 sec/step, loss=0.09237, avg_loss=0.09240, mel_loss=0.04097, linear_loss=0.05140]
[2020-05-11 22:53:41.879]  Step 147025  [3.456 sec/step, loss=0.09902, avg_loss=0.09254, mel_loss=0.04509, linear_loss=0.05393]
[2020-05-11 22:53:44.087]  Step 147026  [3.466 sec/step, loss=0.09268, avg_loss=0.09259, mel_loss=0.04156, linear_loss=0.05111]
[2020-05-11 22:53:45.062]  Step 147027  [3.428 sec/step, loss=0.08285, avg_loss=0.09242, mel_loss=0.03613, linear_loss=0.04672]
[2020-05-11 22:53:50.558]  Step 147028  [3.441 sec/step, loss=0.10032, avg_loss=0.09244, mel_loss=0.04633, linear_loss=0.05398]
[2020-05-11 22:53:52.534]  Step 147029  [3.419 sec/step, loss=0.09363, avg_loss=0.09241, mel_loss=0.04191, linear_loss=0.05172]
[2020-05-11 22:53:55.092]  Step 147030  [3.332 sec/step, loss=0.09344, avg_loss=0.09234, mel_loss=0.04200, linear_loss=0.05144]
[2020-05-11 22:54:01.111]  Step 147031  [3.328 sec/step, loss=0.09837, avg_loss=0.09233, mel_loss=0.04571, linear_loss=0.05266]
[2020-05-11 22:54:02.291]  Step 147032  [3.325 sec/step, loss=0.08519, avg_loss=0.09229, mel_loss=0.03746, linear_loss=0.04773]
[2020-05-11 22:54:05.684]  Step 147033  [3.314 sec/step, loss=0.09724, avg_loss=0.09225, mel_loss=0.04416, linear_loss=0.05308]
[2020-05-11 22:54:06.513]  Step 147034  [3.300 sec/step, loss=0.07892, avg_loss=0.09210, mel_loss=0.03430, linear_loss=0.04462]
[2020-05-11 22:54:08.907]  Step 147035  [3.230 sec/step, loss=0.09431, avg_loss=0.09205, mel_loss=0.04235, linear_loss=0.05196]
[2020-05-11 22:54:10.626]  Generated 32 batches of size 32 in 1.714 sec
[2020-05-11 22:54:17.557]  Step 147036  [3.300 sec/step, loss=0.09777, avg_loss=0.09212, mel_loss=0.04593, linear_loss=0.05185]
[2020-05-11 22:54:20.761]  Step 147037  [3.326 sec/step, loss=0.09824, avg_loss=0.09237, mel_loss=0.04480, linear_loss=0.05344]
[2020-05-11 22:54:21.363]  Step 147038  [3.316 sec/step, loss=0.07131, avg_loss=0.09217, mel_loss=0.03182, linear_loss=0.03949]
[2020-05-11 22:54:25.469]  Step 147039  [3.330 sec/step, loss=0.09826, avg_loss=0.09220, mel_loss=0.04503, linear_loss=0.05323]
[2020-05-11 22:54:26.297]  Step 147040  [3.304 sec/step, loss=0.07674, avg_loss=0.09197, mel_loss=0.03400, linear_loss=0.04274]
[2020-05-11 22:54:31.366]  Step 147041  [3.343 sec/step, loss=0.09966, avg_loss=0.09212, mel_loss=0.04590, linear_loss=0.05376]
[2020-05-11 22:54:34.192]  Step 147042  [3.353 sec/step, loss=0.09644, avg_loss=0.09215, mel_loss=0.04379, linear_loss=0.05265]
[2020-05-11 22:54:36.079]  Step 147043  [3.358 sec/step, loss=0.09061, avg_loss=0.09216, mel_loss=0.04025, linear_loss=0.05036]
[2020-05-11 22:54:37.669]  Step 147044  [3.349 sec/step, loss=0.08995, avg_loss=0.09212, mel_loss=0.03999, linear_loss=0.04996]
[2020-05-11 22:54:43.292]  Step 147045  [3.371 sec/step, loss=0.09973, avg_loss=0.09216, mel_loss=0.04618, linear_loss=0.05355]
[2020-05-11 22:54:45.910]  Step 147046  [3.253 sec/step, loss=0.09570, avg_loss=0.09233, mel_loss=0.04307, linear_loss=0.05263]
[2020-05-11 22:54:48.808]  Step 147047  [3.263 sec/step, loss=0.10002, avg_loss=0.09241, mel_loss=0.04527, linear_loss=0.05475]
[2020-05-11 22:54:53.827]  Step 147048  [3.303 sec/step, loss=0.09768, avg_loss=0.09255, mel_loss=0.04507, linear_loss=0.05260]
[2020-05-11 22:54:58.114]  Step 147049  [3.275 sec/step, loss=0.09944, avg_loss=0.09252, mel_loss=0.04562, linear_loss=0.05382]
[2020-05-11 22:54:59.687]  Step 147050  [3.254 sec/step, loss=0.08991, avg_loss=0.09242, mel_loss=0.04005, linear_loss=0.04987]
[2020-05-11 22:54:59.688]  Writing summary at step: 147050
[2020-05-11 22:55:03.347]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147050
[2020-05-11 22:55:04.771]  Saving audio and alignment...
[2020-05-11 22:55:09.787]  Input: 희망을 이야기하기 참 좋은 이 일월의 어느 멋진 날에~____________
[2020-05-11 22:55:13.202]  Step 147051  [3.282 sec/step, loss=0.09826, avg_loss=0.09267, mel_loss=0.04483, linear_loss=0.05343]
[2020-05-11 22:55:19.392]  Step 147052  [3.330 sec/step, loss=0.09907, avg_loss=0.09279, mel_loss=0.04604, linear_loss=0.05304]
[2020-05-11 22:55:23.855]  Step 147053  [3.363 sec/step, loss=0.10068, avg_loss=0.09295, mel_loss=0.04620, linear_loss=0.05448]
[2020-05-11 22:55:25.865]  Step 147054  [3.354 sec/step, loss=0.09349, avg_loss=0.09291, mel_loss=0.04161, linear_loss=0.05188]
[2020-05-11 22:55:26.927]  Step 147055  [3.346 sec/step, loss=0.08754, avg_loss=0.09287, mel_loss=0.03865, linear_loss=0.04890]
[2020-05-11 22:55:30.398]  Step 147056  [3.356 sec/step, loss=0.09740, avg_loss=0.09288, mel_loss=0.04430, linear_loss=0.05309]
[2020-05-11 22:55:31.709]  Step 147057  [3.321 sec/step, loss=0.08616, avg_loss=0.09276, mel_loss=0.03788, linear_loss=0.04828]
[2020-05-11 22:55:46.059]  Step 147058  [3.454 sec/step, loss=0.07831, avg_loss=0.09269, mel_loss=0.03762, linear_loss=0.04069]
[2020-05-11 22:55:46.872]  Step 147059  [3.428 sec/step, loss=0.07993, avg_loss=0.09253, mel_loss=0.03509, linear_loss=0.04484]
[2020-05-11 22:55:50.957]  Step 147060  [3.326 sec/step, loss=0.09967, avg_loss=0.09276, mel_loss=0.04525, linear_loss=0.05442]
[2020-05-11 22:55:52.335]  Step 147061  [3.327 sec/step, loss=0.08871, avg_loss=0.09278, mel_loss=0.03949, linear_loss=0.04922]
[2020-05-11 22:55:55.115]  Step 147062  [3.291 sec/step, loss=0.09388, avg_loss=0.09272, mel_loss=0.04246, linear_loss=0.05142]
[2020-05-11 22:55:56.238]  Step 147063  [3.282 sec/step, loss=0.08636, avg_loss=0.09266, mel_loss=0.03756, linear_loss=0.04880]
[2020-05-11 22:55:58.355]  Step 147064  [3.295 sec/step, loss=0.09377, avg_loss=0.09280, mel_loss=0.04196, linear_loss=0.05182]
[2020-05-11 22:56:00.725]  Step 147065  [3.265 sec/step, loss=0.09501, avg_loss=0.09273, mel_loss=0.04286, linear_loss=0.05215]
[2020-05-11 22:56:02.495]  Generated 32 batches of size 32 in 1.765 sec
[2020-05-11 22:56:02.747]  Step 147066  [3.244 sec/step, loss=0.09135, avg_loss=0.09266, mel_loss=0.04042, linear_loss=0.05093]
[2020-05-11 22:56:04.483]  Step 147067  [3.232 sec/step, loss=0.09121, avg_loss=0.09261, mel_loss=0.04008, linear_loss=0.05113]
[2020-05-11 22:56:13.285]  Step 147068  [3.292 sec/step, loss=0.09984, avg_loss=0.09266, mel_loss=0.04695, linear_loss=0.05289]
[2020-05-11 22:56:14.243]  Step 147069  [3.245 sec/step, loss=0.08470, avg_loss=0.09250, mel_loss=0.03719, linear_loss=0.04751]
[2020-05-11 22:56:15.856]  Step 147070  [3.253 sec/step, loss=0.09354, avg_loss=0.09270, mel_loss=0.04162, linear_loss=0.05192]
[2020-05-11 22:56:16.408]  Step 147071  [3.236 sec/step, loss=0.07247, avg_loss=0.09249, mel_loss=0.03321, linear_loss=0.03926]
[2020-05-11 22:56:23.916]  Step 147072  [3.302 sec/step, loss=0.09955, avg_loss=0.09268, mel_loss=0.04635, linear_loss=0.05320]
[2020-05-11 22:56:24.788]  Step 147073  [3.294 sec/step, loss=0.07304, avg_loss=0.09251, mel_loss=0.03219, linear_loss=0.04086]
[2020-05-11 22:56:25.783]  Step 147074  [3.289 sec/step, loss=0.08158, avg_loss=0.09244, mel_loss=0.03564, linear_loss=0.04593]
[2020-05-11 22:56:28.635]  Step 147075  [3.300 sec/step, loss=0.09652, avg_loss=0.09248, mel_loss=0.04374, linear_loss=0.05278]
[2020-05-11 22:56:32.025]  Step 147076  [3.292 sec/step, loss=0.09818, avg_loss=0.09246, mel_loss=0.04451, linear_loss=0.05367]
[2020-05-11 22:56:33.068]  Step 147077  [3.269 sec/step, loss=0.08468, avg_loss=0.09232, mel_loss=0.03716, linear_loss=0.04752]
[2020-05-11 22:56:37.214]  Step 147078  [3.287 sec/step, loss=0.09950, avg_loss=0.09236, mel_loss=0.04593, linear_loss=0.05358]
[2020-05-11 22:56:37.773]  Step 147079  [3.207 sec/step, loss=0.07677, avg_loss=0.09216, mel_loss=0.03426, linear_loss=0.04252]
[2020-05-11 22:56:38.568]  Step 147080  [3.139 sec/step, loss=0.08157, avg_loss=0.09197, mel_loss=0.03569, linear_loss=0.04587]
[2020-05-11 22:56:41.963]  Step 147081  [3.136 sec/step, loss=0.09722, avg_loss=0.09194, mel_loss=0.04418, linear_loss=0.05305]
[2020-05-11 22:56:43.331]  Step 147082  [3.130 sec/step, loss=0.08811, avg_loss=0.09187, mel_loss=0.03899, linear_loss=0.04912]
[2020-05-11 22:56:48.085]  Step 147083  [3.122 sec/step, loss=0.09998, avg_loss=0.09191, mel_loss=0.04591, linear_loss=0.05407]
[2020-05-11 22:56:50.508]  Step 147084  [3.118 sec/step, loss=0.09606, avg_loss=0.09191, mel_loss=0.04312, linear_loss=0.05294]
[2020-05-11 22:56:54.361]  Step 147085  [3.148 sec/step, loss=0.09973, avg_loss=0.09216, mel_loss=0.04535, linear_loss=0.05438]
[2020-05-11 22:56:55.406]  Step 147086  [3.149 sec/step, loss=0.08099, avg_loss=0.09213, mel_loss=0.03538, linear_loss=0.04561]
[2020-05-11 22:56:57.865]  Step 147087  [3.164 sec/step, loss=0.09449, avg_loss=0.09222, mel_loss=0.04224, linear_loss=0.05225]
[2020-05-11 22:57:00.622]  Step 147088  [3.174 sec/step, loss=0.09394, avg_loss=0.09226, mel_loss=0.04231, linear_loss=0.05163]
[2020-05-11 22:57:07.953]  Step 147089  [3.207 sec/step, loss=0.10065, avg_loss=0.09229, mel_loss=0.04706, linear_loss=0.05360]
[2020-05-11 22:57:16.426]  Step 147090  [3.167 sec/step, loss=0.09803, avg_loss=0.09237, mel_loss=0.04601, linear_loss=0.05202]
[2020-05-11 22:57:19.426]  Step 147091  [3.171 sec/step, loss=0.09763, avg_loss=0.09238, mel_loss=0.04447, linear_loss=0.05316]
[2020-05-11 22:57:24.476]  Step 147092  [3.190 sec/step, loss=0.10032, avg_loss=0.09239, mel_loss=0.04636, linear_loss=0.05396]
[2020-05-11 22:57:26.429]  Step 147093  [3.197 sec/step, loss=0.09241, avg_loss=0.09240, mel_loss=0.04167, linear_loss=0.05074]
[2020-05-11 22:57:28.125]  Step 147094  [3.179 sec/step, loss=0.09465, avg_loss=0.09238, mel_loss=0.04190, linear_loss=0.05275]
[2020-05-11 22:57:28.919]  Step 147095  [3.175 sec/step, loss=0.07768, avg_loss=0.09230, mel_loss=0.03435, linear_loss=0.04333]
[2020-05-11 22:57:32.725]  Step 147096  [3.192 sec/step, loss=0.09734, avg_loss=0.09235, mel_loss=0.04424, linear_loss=0.05310]
[2020-05-11 22:57:38.328]  Step 147097  [3.176 sec/step, loss=0.10004, avg_loss=0.09237, mel_loss=0.04640, linear_loss=0.05365]
[2020-05-11 22:57:40.001]  Step 147098  [3.174 sec/step, loss=0.08864, avg_loss=0.09232, mel_loss=0.03945, linear_loss=0.04919]
[2020-05-11 22:57:40.184]  Generated 32 batches of size 32 in 1.850 sec
[2020-05-11 22:57:41.264]  Step 147099  [3.150 sec/step, loss=0.08723, avg_loss=0.09222, mel_loss=0.03858, linear_loss=0.04865]
[2020-05-11 22:57:43.731]  Step 147100  [3.115 sec/step, loss=0.09365, avg_loss=0.09213, mel_loss=0.04177, linear_loss=0.05188]
[2020-05-11 22:57:43.731]  Writing summary at step: 147100
[2020-05-11 22:57:50.246]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147100
[2020-05-11 22:57:51.618]  Saving audio and alignment...
[2020-05-11 22:57:53.865]  Input: 입고 가실 건가요~__________
[2020-05-11 22:57:56.613]  Step 147101  [3.056 sec/step, loss=0.09569, avg_loss=0.09211, mel_loss=0.04339, linear_loss=0.05229]
[2020-05-11 22:57:58.423]  Step 147102  [3.067 sec/step, loss=0.09075, avg_loss=0.09215, mel_loss=0.04062, linear_loss=0.05013]
[2020-05-11 22:58:13.403]  Step 147103  [3.185 sec/step, loss=0.08618, avg_loss=0.09203, mel_loss=0.04139, linear_loss=0.04479]
[2020-05-11 22:58:15.662]  Step 147104  [3.184 sec/step, loss=0.08769, avg_loss=0.09196, mel_loss=0.03891, linear_loss=0.04878]
[2020-05-11 22:58:23.125]  Step 147105  [3.243 sec/step, loss=0.09687, avg_loss=0.09201, mel_loss=0.04420, linear_loss=0.05267]
[2020-05-11 22:58:26.063]  Step 147106  [3.262 sec/step, loss=0.09385, avg_loss=0.09209, mel_loss=0.04210, linear_loss=0.05174]
[2020-05-11 22:58:29.678]  Step 147107  [3.249 sec/step, loss=0.09723, avg_loss=0.09205, mel_loss=0.04424, linear_loss=0.05299]
[2020-05-11 22:58:31.385]  Step 147108  [3.252 sec/step, loss=0.09079, avg_loss=0.09205, mel_loss=0.04036, linear_loss=0.05043]
[2020-05-11 22:58:32.183]  Step 147109  [3.244 sec/step, loss=0.08118, avg_loss=0.09192, mel_loss=0.03527, linear_loss=0.04591]
[2020-05-11 22:58:38.024]  Step 147110  [3.254 sec/step, loss=0.09994, avg_loss=0.09192, mel_loss=0.04618, linear_loss=0.05376]
[2020-05-11 22:58:39.399]  Step 147111  [3.244 sec/step, loss=0.08724, avg_loss=0.09185, mel_loss=0.03847, linear_loss=0.04876]
[2020-05-11 22:58:47.139]  Step 147112  [3.315 sec/step, loss=0.10069, avg_loss=0.09206, mel_loss=0.04701, linear_loss=0.05369]
[2020-05-11 22:58:50.119]  Step 147113  [3.335 sec/step, loss=0.09778, avg_loss=0.09220, mel_loss=0.04428, linear_loss=0.05350]
[2020-05-11 22:58:51.738]  Step 147114  [3.305 sec/step, loss=0.09091, avg_loss=0.09210, mel_loss=0.04022, linear_loss=0.05069]
[2020-05-11 22:58:53.711]  Step 147115  [3.294 sec/step, loss=0.09393, avg_loss=0.09206, mel_loss=0.04207, linear_loss=0.05186]
[2020-05-11 22:58:55.612]  Step 147116  [3.299 sec/step, loss=0.09012, avg_loss=0.09207, mel_loss=0.03956, linear_loss=0.05056]
[2020-05-11 22:58:58.488]  Step 147117  [3.313 sec/step, loss=0.09439, avg_loss=0.09211, mel_loss=0.04263, linear_loss=0.05177]
[2020-05-11 22:59:03.799]  Step 147118  [3.353 sec/step, loss=0.10170, avg_loss=0.09225, mel_loss=0.04694, linear_loss=0.05475]
[2020-05-11 22:59:07.894]  Step 147119  [3.373 sec/step, loss=0.09885, avg_loss=0.09231, mel_loss=0.04500, linear_loss=0.05385]
[2020-05-11 22:59:09.067]  Step 147120  [3.348 sec/step, loss=0.08716, avg_loss=0.09219, mel_loss=0.03865, linear_loss=0.04851]
[2020-05-11 22:59:23.743]  Step 147121  [3.484 sec/step, loss=0.08029, avg_loss=0.09213, mel_loss=0.03875, linear_loss=0.04154]
[2020-05-11 22:59:24.577]  Step 147122  [3.354 sec/step, loss=0.07449, avg_loss=0.09212, mel_loss=0.03279, linear_loss=0.04170]
[2020-05-11 22:59:26.867]  Step 147123  [3.305 sec/step, loss=0.09325, avg_loss=0.09202, mel_loss=0.04165, linear_loss=0.05160]
[2020-05-11 22:59:29.231]  Step 147124  [3.311 sec/step, loss=0.09452, avg_loss=0.09204, mel_loss=0.04266, linear_loss=0.05187]
[2020-05-11 22:59:31.957]  Step 147125  [3.298 sec/step, loss=0.09605, avg_loss=0.09201, mel_loss=0.04329, linear_loss=0.05276]
[2020-05-11 22:59:32.933]  Step 147126  [3.286 sec/step, loss=0.08364, avg_loss=0.09192, mel_loss=0.03642, linear_loss=0.04722]
[2020-05-11 22:59:39.641]  Step 147127  [3.343 sec/step, loss=0.10119, avg_loss=0.09211, mel_loss=0.04712, linear_loss=0.05407]
[2020-05-11 22:59:40.816]  Step 147128  [3.300 sec/step, loss=0.08642, avg_loss=0.09197, mel_loss=0.03788, linear_loss=0.04854]
[2020-05-11 22:59:41.347]  Step 147129  [3.286 sec/step, loss=0.07782, avg_loss=0.09181, mel_loss=0.03431, linear_loss=0.04351]
[2020-05-11 22:59:41.434]  Generated 32 batches of size 32 in 1.788 sec
[2020-05-11 22:59:42.378]  Step 147130  [3.270 sec/step, loss=0.08470, avg_loss=0.09172, mel_loss=0.03724, linear_loss=0.04745]
[2020-05-11 22:59:44.121]  Step 147131  [3.228 sec/step, loss=0.09209, avg_loss=0.09166, mel_loss=0.04063, linear_loss=0.05146]
[2020-05-11 22:59:53.300]  Step 147132  [3.307 sec/step, loss=0.09685, avg_loss=0.09178, mel_loss=0.04580, linear_loss=0.05104]
[2020-05-11 22:59:56.714]  Step 147133  [3.308 sec/step, loss=0.09836, avg_loss=0.09179, mel_loss=0.04470, linear_loss=0.05366]
[2020-05-11 23:00:01.163]  Step 147134  [3.344 sec/step, loss=0.09792, avg_loss=0.09198, mel_loss=0.04476, linear_loss=0.05315]
[2020-05-11 23:00:02.558]  Step 147135  [3.334 sec/step, loss=0.08855, avg_loss=0.09192, mel_loss=0.03953, linear_loss=0.04902]
[2020-05-11 23:00:06.251]  Step 147136  [3.284 sec/step, loss=0.09935, avg_loss=0.09194, mel_loss=0.04529, linear_loss=0.05406]
[2020-05-11 23:00:09.995]  Step 147137  [3.290 sec/step, loss=0.10093, avg_loss=0.09196, mel_loss=0.04603, linear_loss=0.05489]
[2020-05-11 23:00:11.817]  Step 147138  [3.302 sec/step, loss=0.09297, avg_loss=0.09218, mel_loss=0.04135, linear_loss=0.05162]
[2020-05-11 23:00:12.599]  Step 147139  [3.269 sec/step, loss=0.08263, avg_loss=0.09202, mel_loss=0.03598, linear_loss=0.04665]
[2020-05-11 23:00:15.696]  Step 147140  [3.291 sec/step, loss=0.09939, avg_loss=0.09225, mel_loss=0.04512, linear_loss=0.05427]
[2020-05-11 23:00:18.336]  Step 147141  [3.267 sec/step, loss=0.09622, avg_loss=0.09222, mel_loss=0.04320, linear_loss=0.05302]
[2020-05-11 23:00:19.158]  Step 147142  [3.247 sec/step, loss=0.07745, avg_loss=0.09203, mel_loss=0.03373, linear_loss=0.04372]
[2020-05-11 23:00:22.196]  Step 147143  [3.259 sec/step, loss=0.09802, avg_loss=0.09210, mel_loss=0.04457, linear_loss=0.05345]
[2020-05-11 23:00:26.212]  Step 147144  [3.283 sec/step, loss=0.09871, avg_loss=0.09219, mel_loss=0.04518, linear_loss=0.05353]
[2020-05-11 23:00:27.664]  Step 147145  [3.241 sec/step, loss=0.09031, avg_loss=0.09209, mel_loss=0.04003, linear_loss=0.05028]
[2020-05-11 23:00:29.639]  Step 147146  [3.235 sec/step, loss=0.09339, avg_loss=0.09207, mel_loss=0.04193, linear_loss=0.05146]
[2020-05-11 23:00:30.738]  Step 147147  [3.217 sec/step, loss=0.08539, avg_loss=0.09192, mel_loss=0.03759, linear_loss=0.04780]
[2020-05-11 23:00:43.164]  Step 147148  [3.291 sec/step, loss=0.08787, avg_loss=0.09183, mel_loss=0.04220, linear_loss=0.04567]
[2020-05-11 23:00:45.625]  Step 147149  [3.273 sec/step, loss=0.09520, avg_loss=0.09178, mel_loss=0.04270, linear_loss=0.05250]
[2020-05-11 23:00:49.101]  Step 147150  [3.292 sec/step, loss=0.09749, avg_loss=0.09186, mel_loss=0.04440, linear_loss=0.05309]
[2020-05-11 23:00:49.101]  Writing summary at step: 147150
[2020-05-11 23:00:50.746]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147150
[2020-05-11 23:00:52.143]  Saving audio and alignment...
[2020-05-11 23:00:55.243]  Input: 방금 이런 부서가 들어가면~_____________
[2020-05-11 23:00:56.576]  Step 147151  [3.271 sec/step, loss=0.08812, avg_loss=0.09176, mel_loss=0.03896, linear_loss=0.04917]
[2020-05-11 23:01:02.109]  Step 147152  [3.264 sec/step, loss=0.09863, avg_loss=0.09175, mel_loss=0.04569, linear_loss=0.05294]
[2020-05-11 23:01:03.036]  Step 147153  [3.229 sec/step, loss=0.08766, avg_loss=0.09162, mel_loss=0.03870, linear_loss=0.04896]
[2020-05-11 23:01:11.371]  Step 147154  [3.292 sec/step, loss=0.09779, avg_loss=0.09167, mel_loss=0.04586, linear_loss=0.05193]
[2020-05-11 23:01:11.934]  Step 147155  [3.287 sec/step, loss=0.07481, avg_loss=0.09154, mel_loss=0.03396, linear_loss=0.04085]
[2020-05-11 23:01:13.110]  Step 147156  [3.264 sec/step, loss=0.08692, avg_loss=0.09143, mel_loss=0.03842, linear_loss=0.04850]
[2020-05-11 23:01:20.509]  Step 147157  [3.325 sec/step, loss=0.10146, avg_loss=0.09159, mel_loss=0.04748, linear_loss=0.05398]
[2020-05-11 23:01:22.322]  Generated 32 batches of size 32 in 1.807 sec
[2020-05-11 23:01:26.656]  Step 147158  [3.243 sec/step, loss=0.09916, avg_loss=0.09180, mel_loss=0.04615, linear_loss=0.05301]
[2020-05-11 23:01:31.491]  Step 147159  [3.283 sec/step, loss=0.09921, avg_loss=0.09199, mel_loss=0.04565, linear_loss=0.05355]
[2020-05-11 23:01:35.725]  Step 147160  [3.285 sec/step, loss=0.10239, avg_loss=0.09202, mel_loss=0.04734, linear_loss=0.05505]
[2020-05-11 23:01:37.846]  Step 147161  [3.292 sec/step, loss=0.09571, avg_loss=0.09209, mel_loss=0.04299, linear_loss=0.05273]
[2020-05-11 23:01:41.298]  Step 147162  [3.299 sec/step, loss=0.09739, avg_loss=0.09212, mel_loss=0.04437, linear_loss=0.05302]
[2020-05-11 23:01:43.460]  Step 147163  [3.309 sec/step, loss=0.09347, avg_loss=0.09219, mel_loss=0.04189, linear_loss=0.05158]
[2020-05-11 23:01:44.801]  Step 147164  [3.301 sec/step, loss=0.08922, avg_loss=0.09215, mel_loss=0.03958, linear_loss=0.04964]
[2020-05-11 23:01:45.802]  Step 147165  [3.288 sec/step, loss=0.07908, avg_loss=0.09199, mel_loss=0.03461, linear_loss=0.04447]
[2020-05-11 23:01:48.599]  Step 147166  [3.296 sec/step, loss=0.09512, avg_loss=0.09202, mel_loss=0.04313, linear_loss=0.05200]
[2020-05-11 23:01:53.904]  Step 147167  [3.331 sec/step, loss=0.10061, avg_loss=0.09212, mel_loss=0.04661, linear_loss=0.05400]
[2020-05-11 23:02:00.708]  Step 147168  [3.311 sec/step, loss=0.10050, avg_loss=0.09213, mel_loss=0.04690, linear_loss=0.05360]
[2020-05-11 23:02:02.494]  Step 147169  [3.319 sec/step, loss=0.09179, avg_loss=0.09220, mel_loss=0.04061, linear_loss=0.05119]
[2020-05-11 23:02:10.068]  Step 147170  [3.379 sec/step, loss=0.10019, avg_loss=0.09226, mel_loss=0.04679, linear_loss=0.05340]
[2020-05-11 23:02:12.094]  Step 147171  [3.394 sec/step, loss=0.09339, avg_loss=0.09247, mel_loss=0.04178, linear_loss=0.05160]
[2020-05-11 23:02:14.621]  Step 147172  [3.344 sec/step, loss=0.09476, avg_loss=0.09242, mel_loss=0.04231, linear_loss=0.05244]
[2020-05-11 23:02:16.989]  Step 147173  [3.359 sec/step, loss=0.09464, avg_loss=0.09264, mel_loss=0.04251, linear_loss=0.05213]
[2020-05-11 23:02:25.659]  Step 147174  [3.436 sec/step, loss=0.09878, avg_loss=0.09281, mel_loss=0.04642, linear_loss=0.05236]
[2020-05-11 23:02:28.376]  Step 147175  [3.434 sec/step, loss=0.09543, avg_loss=0.09280, mel_loss=0.04312, linear_loss=0.05231]
[2020-05-11 23:02:29.218]  Step 147176  [3.409 sec/step, loss=0.07678, avg_loss=0.09259, mel_loss=0.03395, linear_loss=0.04283]
[2020-05-11 23:02:34.667]  Step 147177  [3.453 sec/step, loss=0.09983, avg_loss=0.09274, mel_loss=0.04616, linear_loss=0.05366]
[2020-05-11 23:02:37.547]  Step 147178  [3.440 sec/step, loss=0.09756, avg_loss=0.09272, mel_loss=0.04387, linear_loss=0.05369]
[2020-05-11 23:02:38.612]  Step 147179  [3.445 sec/step, loss=0.08806, avg_loss=0.09283, mel_loss=0.03862, linear_loss=0.04943]
[2020-05-11 23:02:42.707]  Step 147180  [3.478 sec/step, loss=0.09892, avg_loss=0.09301, mel_loss=0.04507, linear_loss=0.05385]
[2020-05-11 23:02:56.851]  Step 147181  [3.586 sec/step, loss=0.07862, avg_loss=0.09282, mel_loss=0.03773, linear_loss=0.04089]
[2020-05-11 23:02:57.859]  Step 147182  [3.582 sec/step, loss=0.08361, avg_loss=0.09277, mel_loss=0.03677, linear_loss=0.04684]
[2020-05-11 23:02:59.053]  Step 147183  [3.547 sec/step, loss=0.08814, avg_loss=0.09266, mel_loss=0.03896, linear_loss=0.04918]
[2020-05-11 23:02:59.889]  Step 147184  [3.531 sec/step, loss=0.07967, avg_loss=0.09249, mel_loss=0.03489, linear_loss=0.04478]
[2020-05-11 23:03:01.225]  Step 147185  [3.506 sec/step, loss=0.08800, avg_loss=0.09238, mel_loss=0.03861, linear_loss=0.04939]
[2020-05-11 23:03:02.654]  Step 147186  [3.509 sec/step, loss=0.08981, avg_loss=0.09246, mel_loss=0.03990, linear_loss=0.04991]
[2020-05-11 23:03:03.208]  Step 147187  [3.490 sec/step, loss=0.06982, avg_loss=0.09222, mel_loss=0.03104, linear_loss=0.03878]
[2020-05-11 23:03:04.841]  Step 147188  [3.479 sec/step, loss=0.09227, avg_loss=0.09220, mel_loss=0.04133, linear_loss=0.05094]
[2020-05-11 23:03:08.245]  Step 147189  [3.440 sec/step, loss=0.09732, avg_loss=0.09217, mel_loss=0.04403, linear_loss=0.05328]
[2020-05-11 23:03:09.946]  Generated 32 batches of size 32 in 1.696 sec
[2020-05-11 23:03:13.026]  Step 147190  [3.403 sec/step, loss=0.09992, avg_loss=0.09219, mel_loss=0.04568, linear_loss=0.05423]
[2020-05-11 23:03:16.156]  Step 147191  [3.404 sec/step, loss=0.09979, avg_loss=0.09221, mel_loss=0.04541, linear_loss=0.05438]
[2020-05-11 23:03:19.851]  Step 147192  [3.391 sec/step, loss=0.09948, avg_loss=0.09220, mel_loss=0.04552, linear_loss=0.05396]
[2020-05-11 23:03:24.061]  Step 147193  [3.413 sec/step, loss=0.09888, avg_loss=0.09226, mel_loss=0.04547, linear_loss=0.05341]
[2020-05-11 23:03:25.646]  Step 147194  [3.412 sec/step, loss=0.09243, avg_loss=0.09224, mel_loss=0.04107, linear_loss=0.05137]
[2020-05-11 23:03:27.542]  Step 147195  [3.423 sec/step, loss=0.09111, avg_loss=0.09238, mel_loss=0.04049, linear_loss=0.05062]
[2020-05-11 23:03:30.969]  Step 147196  [3.419 sec/step, loss=0.09697, avg_loss=0.09237, mel_loss=0.04409, linear_loss=0.05288]
[2020-05-11 23:03:31.861]  Step 147197  [3.372 sec/step, loss=0.07963, avg_loss=0.09217, mel_loss=0.03476, linear_loss=0.04487]
[2020-05-11 23:03:34.077]  Step 147198  [3.378 sec/step, loss=0.09334, avg_loss=0.09221, mel_loss=0.04191, linear_loss=0.05143]
[2020-05-11 23:03:34.832]  Step 147199  [3.373 sec/step, loss=0.07632, avg_loss=0.09211, mel_loss=0.03362, linear_loss=0.04270]
[2020-05-11 23:03:37.123]  Step 147200  [3.371 sec/step, loss=0.09404, avg_loss=0.09211, mel_loss=0.04209, linear_loss=0.05195]
[2020-05-11 23:03:37.123]  Writing summary at step: 147200
[2020-05-11 23:03:38.543]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147200
[2020-05-11 23:03:39.935]  Saving audio and alignment...
[2020-05-11 23:03:43.485]  Input: 처음부터 포인트들 좀 볼게요~_________
[2020-05-11 23:03:44.435]  Step 147201  [3.353 sec/step, loss=0.08228, avg_loss=0.09198, mel_loss=0.03619, linear_loss=0.04609]
[2020-05-11 23:03:56.646]  Step 147202  [3.457 sec/step, loss=0.08903, avg_loss=0.09196, mel_loss=0.04281, linear_loss=0.04622]
[2020-05-11 23:03:59.628]  Step 147203  [3.337 sec/step, loss=0.09826, avg_loss=0.09208, mel_loss=0.04428, linear_loss=0.05398]
[2020-05-11 23:04:03.453]  Step 147204  [3.353 sec/step, loss=0.09739, avg_loss=0.09218, mel_loss=0.04431, linear_loss=0.05308]
[2020-05-11 23:04:08.585]  Step 147205  [3.329 sec/step, loss=0.09740, avg_loss=0.09218, mel_loss=0.04463, linear_loss=0.05277]
[2020-05-11 23:04:09.721]  Step 147206  [3.311 sec/step, loss=0.08648, avg_loss=0.09211, mel_loss=0.03777, linear_loss=0.04871]
[2020-05-11 23:04:12.335]  Step 147207  [3.301 sec/step, loss=0.09357, avg_loss=0.09207, mel_loss=0.04206, linear_loss=0.05152]
[2020-05-11 23:04:13.195]  Step 147208  [3.293 sec/step, loss=0.08148, avg_loss=0.09198, mel_loss=0.03577, linear_loss=0.04572]
[2020-05-11 23:04:14.967]  Step 147209  [3.303 sec/step, loss=0.09104, avg_loss=0.09208, mel_loss=0.04036, linear_loss=0.05068]
[2020-05-11 23:04:21.905]  Step 147210  [3.314 sec/step, loss=0.10262, avg_loss=0.09210, mel_loss=0.04808, linear_loss=0.05454]
[2020-05-11 23:04:23.806]  Step 147211  [3.319 sec/step, loss=0.09188, avg_loss=0.09215, mel_loss=0.04110, linear_loss=0.05078]
[2020-05-11 23:04:25.314]  Step 147212  [3.256 sec/step, loss=0.08899, avg_loss=0.09203, mel_loss=0.03953, linear_loss=0.04946]
[2020-05-11 23:04:29.668]  Step 147213  [3.270 sec/step, loss=0.09830, avg_loss=0.09204, mel_loss=0.04519, linear_loss=0.05311]
[2020-05-11 23:04:32.511]  Step 147214  [3.282 sec/step, loss=0.09636, avg_loss=0.09209, mel_loss=0.04365, linear_loss=0.05271]
[2020-05-11 23:04:36.248]  Step 147215  [3.300 sec/step, loss=0.09874, avg_loss=0.09214, mel_loss=0.04510, linear_loss=0.05364]
[2020-05-11 23:04:45.358]  Step 147216  [3.372 sec/step, loss=0.09721, avg_loss=0.09221, mel_loss=0.04571, linear_loss=0.05150]
[2020-05-11 23:04:46.370]  Step 147217  [3.354 sec/step, loss=0.08513, avg_loss=0.09212, mel_loss=0.03746, linear_loss=0.04766]
[2020-05-11 23:04:52.502]  Step 147218  [3.362 sec/step, loss=0.09856, avg_loss=0.09209, mel_loss=0.04573, linear_loss=0.05282]
[2020-05-11 23:04:57.185]  Step 147219  [3.368 sec/step, loss=0.10096, avg_loss=0.09211, mel_loss=0.04637, linear_loss=0.05458]
[2020-05-11 23:04:58.986]  Generated 32 batches of size 32 in 1.795 sec
[2020-05-11 23:04:59.730]  Step 147220  [3.381 sec/step, loss=0.09543, avg_loss=0.09219, mel_loss=0.04275, linear_loss=0.05267]
[2020-05-11 23:05:00.329]  Step 147221  [3.241 sec/step, loss=0.07130, avg_loss=0.09210, mel_loss=0.03187, linear_loss=0.03943]
[2020-05-11 23:05:03.464]  Step 147222  [3.264 sec/step, loss=0.09876, avg_loss=0.09234, mel_loss=0.04484, linear_loss=0.05392]
[2020-05-11 23:05:06.839]  Step 147223  [3.274 sec/step, loss=0.09758, avg_loss=0.09239, mel_loss=0.04428, linear_loss=0.05331]
[2020-05-11 23:05:12.456]  Step 147224  [3.307 sec/step, loss=0.09828, avg_loss=0.09243, mel_loss=0.04524, linear_loss=0.05304]
[2020-05-11 23:05:14.068]  Step 147225  [3.296 sec/step, loss=0.09143, avg_loss=0.09238, mel_loss=0.04068, linear_loss=0.05076]
[2020-05-11 23:05:16.076]  Step 147226  [3.306 sec/step, loss=0.09320, avg_loss=0.09247, mel_loss=0.04163, linear_loss=0.05157]
[2020-05-11 23:05:17.338]  Step 147227  [3.252 sec/step, loss=0.08630, avg_loss=0.09233, mel_loss=0.03784, linear_loss=0.04846]
[2020-05-11 23:05:18.679]  Step 147228  [3.253 sec/step, loss=0.08711, avg_loss=0.09233, mel_loss=0.03854, linear_loss=0.04857]
[2020-05-11 23:05:22.305]  Step 147229  [3.284 sec/step, loss=0.09986, avg_loss=0.09255, mel_loss=0.04559, linear_loss=0.05428]
[2020-05-11 23:05:23.325]  Step 147230  [3.284 sec/step, loss=0.08365, avg_loss=0.09254, mel_loss=0.03672, linear_loss=0.04693]
[2020-05-11 23:05:25.936]  Step 147231  [3.293 sec/step, loss=0.09614, avg_loss=0.09258, mel_loss=0.04343, linear_loss=0.05271]
[2020-05-11 23:05:26.935]  Step 147232  [3.211 sec/step, loss=0.08066, avg_loss=0.09242, mel_loss=0.03495, linear_loss=0.04571]
[2020-05-11 23:05:30.976]  Step 147233  [3.217 sec/step, loss=0.09871, avg_loss=0.09242, mel_loss=0.04498, linear_loss=0.05373]
[2020-05-11 23:05:32.711]  Step 147234  [3.190 sec/step, loss=0.09170, avg_loss=0.09236, mel_loss=0.04076, linear_loss=0.05093]
[2020-05-11 23:05:33.434]  Step 147235  [3.183 sec/step, loss=0.08012, avg_loss=0.09228, mel_loss=0.03514, linear_loss=0.04497]
[2020-05-11 23:05:36.586]  Step 147236  [3.178 sec/step, loss=0.09835, avg_loss=0.09227, mel_loss=0.04455, linear_loss=0.05380]
[2020-05-11 23:05:37.940]  Step 147237  [3.154 sec/step, loss=0.08857, avg_loss=0.09214, mel_loss=0.03917, linear_loss=0.04940]
[2020-05-11 23:05:46.894]  Step 147238  [3.225 sec/step, loss=0.09940, avg_loss=0.09221, mel_loss=0.04680, linear_loss=0.05260]
[2020-05-11 23:05:49.279]  Step 147239  [3.242 sec/step, loss=0.09526, avg_loss=0.09234, mel_loss=0.04294, linear_loss=0.05232]
[2020-05-11 23:05:49.842]  Step 147240  [3.216 sec/step, loss=0.07405, avg_loss=0.09208, mel_loss=0.03290, linear_loss=0.04115]
[2020-05-11 23:05:53.268]  Step 147241  [3.224 sec/step, loss=0.09870, avg_loss=0.09211, mel_loss=0.04480, linear_loss=0.05390]
[2020-05-11 23:06:00.115]  Step 147242  [3.284 sec/step, loss=0.09995, avg_loss=0.09233, mel_loss=0.04645, linear_loss=0.05349]
[2020-05-11 23:06:01.558]  Step 147243  [3.268 sec/step, loss=0.09045, avg_loss=0.09226, mel_loss=0.04013, linear_loss=0.05032]
[2020-05-11 23:06:03.567]  Step 147244  [3.248 sec/step, loss=0.09060, avg_loss=0.09217, mel_loss=0.04047, linear_loss=0.05012]
[2020-05-11 23:06:05.622]  Step 147245  [3.254 sec/step, loss=0.09321, avg_loss=0.09220, mel_loss=0.04184, linear_loss=0.05137]
[2020-05-11 23:06:08.552]  Step 147246  [3.264 sec/step, loss=0.09833, avg_loss=0.09225, mel_loss=0.04438, linear_loss=0.05395]
[2020-05-11 23:06:22.942]  Step 147247  [3.397 sec/step, loss=0.07972, avg_loss=0.09220, mel_loss=0.03828, linear_loss=0.04145]
[2020-05-11 23:06:28.401]  Step 147248  [3.327 sec/step, loss=0.10132, avg_loss=0.09233, mel_loss=0.04695, linear_loss=0.05437]
[2020-05-11 23:06:30.169]  Step 147249  [3.320 sec/step, loss=0.09453, avg_loss=0.09232, mel_loss=0.04177, linear_loss=0.05275]
[2020-05-11 23:06:31.427]  Step 147250  [3.298 sec/step, loss=0.08680, avg_loss=0.09222, mel_loss=0.03855, linear_loss=0.04825]
[2020-05-11 23:06:31.427]  Writing summary at step: 147250
[2020-05-11 23:06:34.108]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147250
[2020-05-11 23:06:36.243]  Saving audio and alignment...
[2020-05-11 23:06:38.329]  Generated 32 batches of size 32 in 1.534 sec
[2020-05-11 23:06:39.654]  Input: 골든벨 이렇게 확실하게~_____________
[2020-05-11 23:06:41.818]  Step 147251  [3.306 sec/step, loss=0.09398, avg_loss=0.09228, mel_loss=0.04201, linear_loss=0.05197]
[2020-05-11 23:06:45.359]  Step 147252  [3.286 sec/step, loss=0.09676, avg_loss=0.09226, mel_loss=0.04393, linear_loss=0.05283]
[2020-05-11 23:06:52.997]  Step 147253  [3.353 sec/step, loss=0.10013, avg_loss=0.09238, mel_loss=0.04664, linear_loss=0.05348]
[2020-05-11 23:06:53.818]  Step 147254  [3.278 sec/step, loss=0.07850, avg_loss=0.09219, mel_loss=0.03415, linear_loss=0.04435]
[2020-05-11 23:06:59.577]  Step 147255  [3.330 sec/step, loss=0.10153, avg_loss=0.09246, mel_loss=0.04714, linear_loss=0.05439]
[2020-05-11 23:07:03.983]  Step 147256  [3.363 sec/step, loss=0.09763, avg_loss=0.09256, mel_loss=0.04487, linear_loss=0.05277]
[2020-05-11 23:07:05.117]  Step 147257  [3.300 sec/step, loss=0.08559, avg_loss=0.09240, mel_loss=0.03750, linear_loss=0.04809]
[2020-05-11 23:07:09.944]  Step 147258  [3.287 sec/step, loss=0.09843, avg_loss=0.09240, mel_loss=0.04517, linear_loss=0.05326]
[2020-05-11 23:07:10.815]  Step 147259  [3.247 sec/step, loss=0.08276, avg_loss=0.09223, mel_loss=0.03626, linear_loss=0.04650]
[2020-05-11 23:07:15.489]  Step 147260  [3.252 sec/step, loss=0.09878, avg_loss=0.09220, mel_loss=0.04518, linear_loss=0.05360]
[2020-05-11 23:07:18.469]  Step 147261  [3.260 sec/step, loss=0.09654, avg_loss=0.09220, mel_loss=0.04384, linear_loss=0.05269]
[2020-05-11 23:07:22.795]  Step 147262  [3.269 sec/step, loss=0.09978, avg_loss=0.09223, mel_loss=0.04597, linear_loss=0.05381]
[2020-05-11 23:07:31.596]  Step 147263  [3.335 sec/step, loss=0.09871, avg_loss=0.09228, mel_loss=0.04644, linear_loss=0.05226]
[2020-05-11 23:07:32.665]  Step 147264  [3.332 sec/step, loss=0.08494, avg_loss=0.09224, mel_loss=0.03735, linear_loss=0.04759]
[2020-05-11 23:07:35.228]  Step 147265  [3.348 sec/step, loss=0.09365, avg_loss=0.09238, mel_loss=0.04203, linear_loss=0.05163]
[2020-05-11 23:07:38.676]  Step 147266  [3.355 sec/step, loss=0.09532, avg_loss=0.09239, mel_loss=0.04324, linear_loss=0.05207]
[2020-05-11 23:07:40.542]  Step 147267  [3.320 sec/step, loss=0.09093, avg_loss=0.09229, mel_loss=0.04058, linear_loss=0.05035]
[2020-05-11 23:07:42.148]  Step 147268  [3.268 sec/step, loss=0.09162, avg_loss=0.09220, mel_loss=0.04060, linear_loss=0.05101]
[2020-05-11 23:07:43.205]  Step 147269  [3.261 sec/step, loss=0.08644, avg_loss=0.09215, mel_loss=0.03774, linear_loss=0.04870]
[2020-05-11 23:07:50.834]  Step 147270  [3.262 sec/step, loss=0.10215, avg_loss=0.09217, mel_loss=0.04777, linear_loss=0.05438]
[2020-05-11 23:07:53.624]  Step 147271  [3.269 sec/step, loss=0.09459, avg_loss=0.09218, mel_loss=0.04287, linear_loss=0.05172]
[2020-05-11 23:07:54.972]  Step 147272  [3.257 sec/step, loss=0.08945, avg_loss=0.09213, mel_loss=0.03961, linear_loss=0.04984]
[2020-05-11 23:08:01.348]  Step 147273  [3.297 sec/step, loss=0.09917, avg_loss=0.09217, mel_loss=0.04622, linear_loss=0.05295]
[2020-05-11 23:08:06.431]  Step 147274  [3.262 sec/step, loss=0.09743, avg_loss=0.09216, mel_loss=0.04484, linear_loss=0.05259]
[2020-05-11 23:08:12.082]  Step 147275  [3.291 sec/step, loss=0.09843, avg_loss=0.09219, mel_loss=0.04546, linear_loss=0.05297]
[2020-05-11 23:08:15.576]  Step 147276  [3.317 sec/step, loss=0.09626, avg_loss=0.09238, mel_loss=0.04366, linear_loss=0.05259]
[2020-05-11 23:08:18.664]  Step 147277  [3.294 sec/step, loss=0.09708, avg_loss=0.09235, mel_loss=0.04390, linear_loss=0.05317]
[2020-05-11 23:08:22.825]  Step 147278  [3.307 sec/step, loss=0.09861, avg_loss=0.09236, mel_loss=0.04471, linear_loss=0.05390]
[2020-05-11 23:08:23.627]  Step 147279  [3.304 sec/step, loss=0.07961, avg_loss=0.09228, mel_loss=0.03492, linear_loss=0.04469]
[2020-05-11 23:08:28.701]  Step 147280  [3.314 sec/step, loss=0.10110, avg_loss=0.09230, mel_loss=0.04609, linear_loss=0.05501]
[2020-05-11 23:08:32.205]  Step 147281  [3.207 sec/step, loss=0.09256, avg_loss=0.09244, mel_loss=0.04169, linear_loss=0.05088]
[2020-05-11 23:08:34.619]  Step 147282  [3.221 sec/step, loss=0.08887, avg_loss=0.09249, mel_loss=0.03936, linear_loss=0.04951]
[2020-05-11 23:08:35.611]  Generated 32 batches of size 32 in 3.396 sec
[2020-05-11 23:08:37.967]  Step 147283  [3.243 sec/step, loss=0.09084, avg_loss=0.09252, mel_loss=0.04063, linear_loss=0.05021]
[2020-05-11 23:08:40.629]  Step 147284  [3.261 sec/step, loss=0.09151, avg_loss=0.09264, mel_loss=0.04053, linear_loss=0.05098]
[2020-05-11 23:08:41.976]  Step 147285  [3.261 sec/step, loss=0.08544, avg_loss=0.09261, mel_loss=0.03744, linear_loss=0.04801]
[2020-05-11 23:08:42.843]  Step 147286  [3.256 sec/step, loss=0.07836, avg_loss=0.09250, mel_loss=0.03433, linear_loss=0.04403]
[2020-05-11 23:08:43.611]  Step 147287  [3.258 sec/step, loss=0.07728, avg_loss=0.09257, mel_loss=0.03520, linear_loss=0.04208]
[2020-05-11 23:08:46.389]  Step 147288  [3.269 sec/step, loss=0.09243, avg_loss=0.09258, mel_loss=0.04133, linear_loss=0.05110]
[2020-05-11 23:08:59.337]  Step 147289  [3.365 sec/step, loss=0.08849, avg_loss=0.09249, mel_loss=0.04236, linear_loss=0.04613]
[2020-05-11 23:09:00.861]  Step 147290  [3.332 sec/step, loss=0.09161, avg_loss=0.09240, mel_loss=0.04064, linear_loss=0.05097]
[2020-05-11 23:09:04.035]  Step 147291  [3.333 sec/step, loss=0.09963, avg_loss=0.09240, mel_loss=0.04504, linear_loss=0.05459]
[2020-05-11 23:09:09.538]  Step 147292  [3.351 sec/step, loss=0.09947, avg_loss=0.09240, mel_loss=0.04607, linear_loss=0.05340]
[2020-05-11 23:09:11.197]  Step 147293  [3.325 sec/step, loss=0.08919, avg_loss=0.09231, mel_loss=0.03998, linear_loss=0.04921]
[2020-05-11 23:09:14.120]  Step 147294  [3.339 sec/step, loss=0.09722, avg_loss=0.09235, mel_loss=0.04376, linear_loss=0.05345]
[2020-05-11 23:09:21.003]  Step 147295  [3.388 sec/step, loss=0.10197, avg_loss=0.09246, mel_loss=0.04755, linear_loss=0.05442]
[2020-05-11 23:09:22.761]  Step 147296  [3.372 sec/step, loss=0.09070, avg_loss=0.09240, mel_loss=0.04034, linear_loss=0.05036]
[2020-05-11 23:09:24.931]  Step 147297  [3.385 sec/step, loss=0.09450, avg_loss=0.09255, mel_loss=0.04229, linear_loss=0.05221]
[2020-05-11 23:09:26.195]  Step 147298  [3.375 sec/step, loss=0.08683, avg_loss=0.09248, mel_loss=0.03864, linear_loss=0.04820]
[2020-05-11 23:09:27.054]  Step 147299  [3.376 sec/step, loss=0.08190, avg_loss=0.09254, mel_loss=0.03546, linear_loss=0.04644]
[2020-05-11 23:09:30.611]  Step 147300  [3.389 sec/step, loss=0.09815, avg_loss=0.09258, mel_loss=0.04458, linear_loss=0.05357]
[2020-05-11 23:09:30.611]  Writing summary at step: 147300
[2020-05-11 23:09:36.502]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147300
[2020-05-11 23:09:37.951]  Saving audio and alignment...
[2020-05-11 23:09:43.899]  Input: 뉴스 리딩을 할 때 우리가 지켜야 할 정말 많은 것들이 있겠지만~____
[2020-05-11 23:09:45.018]  Step 147301  [3.390 sec/step, loss=0.08724, avg_loss=0.09263, mel_loss=0.03789, linear_loss=0.04935]
[2020-05-11 23:09:49.697]  Step 147302  [3.315 sec/step, loss=0.10094, avg_loss=0.09275, mel_loss=0.04645, linear_loss=0.05449]
[2020-05-11 23:09:50.795]  Step 147303  [3.296 sec/step, loss=0.08177, avg_loss=0.09258, mel_loss=0.03571, linear_loss=0.04606]
[2020-05-11 23:09:54.366]  Step 147304  [3.294 sec/step, loss=0.09823, avg_loss=0.09259, mel_loss=0.04477, linear_loss=0.05346]
[2020-05-11 23:09:58.569]  Step 147305  [3.284 sec/step, loss=0.09753, avg_loss=0.09259, mel_loss=0.04441, linear_loss=0.05312]
[2020-05-11 23:10:07.057]  Step 147306  [3.358 sec/step, loss=0.09534, avg_loss=0.09268, mel_loss=0.04473, linear_loss=0.05061]
[2020-05-11 23:10:20.262]  Step 147307  [3.464 sec/step, loss=0.08084, avg_loss=0.09255, mel_loss=0.03851, linear_loss=0.04233]
[2020-05-11 23:10:22.667]  Step 147308  [3.479 sec/step, loss=0.09554, avg_loss=0.09270, mel_loss=0.04287, linear_loss=0.05267]
[2020-05-11 23:10:25.310]  Step 147309  [3.488 sec/step, loss=0.09593, avg_loss=0.09274, mel_loss=0.04332, linear_loss=0.05262]
[2020-05-11 23:10:27.369]  Step 147310  [3.439 sec/step, loss=0.09447, avg_loss=0.09266, mel_loss=0.04224, linear_loss=0.05223]
[2020-05-11 23:10:29.865]  Step 147311  [3.445 sec/step, loss=0.09425, avg_loss=0.09269, mel_loss=0.04234, linear_loss=0.05191]
[2020-05-11 23:10:30.678]  Step 147312  [3.438 sec/step, loss=0.08068, avg_loss=0.09260, mel_loss=0.03526, linear_loss=0.04542]
[2020-05-11 23:10:31.762]  Generated 32 batches of size 32 in 1.891 sec
[2020-05-11 23:10:32.111]  Step 147313  [3.409 sec/step, loss=0.08756, avg_loss=0.09250, mel_loss=0.03882, linear_loss=0.04874]
[2020-05-11 23:10:37.061]  Step 147314  [3.430 sec/step, loss=0.09725, avg_loss=0.09250, mel_loss=0.04455, linear_loss=0.05270]
[2020-05-11 23:10:38.878]  Step 147315  [3.411 sec/step, loss=0.09317, avg_loss=0.09245, mel_loss=0.04125, linear_loss=0.05192]
[2020-05-11 23:10:39.952]  Step 147316  [3.331 sec/step, loss=0.08218, avg_loss=0.09230, mel_loss=0.03627, linear_loss=0.04591]
[2020-05-11 23:10:41.383]  Step 147317  [3.335 sec/step, loss=0.08880, avg_loss=0.09234, mel_loss=0.03922, linear_loss=0.04958]
[2020-05-11 23:10:41.905]  Step 147318  [3.279 sec/step, loss=0.07661, avg_loss=0.09212, mel_loss=0.03419, linear_loss=0.04242]
[2020-05-11 23:10:43.831]  Step 147319  [3.251 sec/step, loss=0.09203, avg_loss=0.09203, mel_loss=0.04092, linear_loss=0.05112]
[2020-05-11 23:10:44.583]  Step 147320  [3.233 sec/step, loss=0.07893, avg_loss=0.09186, mel_loss=0.03472, linear_loss=0.04421]
[2020-05-11 23:10:46.407]  Step 147321  [3.245 sec/step, loss=0.09215, avg_loss=0.09207, mel_loss=0.04090, linear_loss=0.05125]
[2020-05-11 23:10:49.401]  Step 147322  [3.244 sec/step, loss=0.09479, avg_loss=0.09203, mel_loss=0.04281, linear_loss=0.05198]
[2020-05-11 23:10:52.841]  Step 147323  [3.245 sec/step, loss=0.09693, avg_loss=0.09202, mel_loss=0.04403, linear_loss=0.05290]
[2020-05-11 23:10:56.581]  Step 147324  [3.226 sec/step, loss=0.09824, avg_loss=0.09202, mel_loss=0.04472, linear_loss=0.05352]
[2020-05-11 23:11:04.137]  Step 147325  [3.285 sec/step, loss=0.09803, avg_loss=0.09209, mel_loss=0.04552, linear_loss=0.05251]
[2020-05-11 23:11:06.925]  Step 147326  [3.293 sec/step, loss=0.09520, avg_loss=0.09211, mel_loss=0.04295, linear_loss=0.05225]
[2020-05-11 23:11:08.952]  Step 147327  [3.301 sec/step, loss=0.09030, avg_loss=0.09215, mel_loss=0.04048, linear_loss=0.04982]
[2020-05-11 23:11:10.594]  Step 147328  [3.304 sec/step, loss=0.09148, avg_loss=0.09219, mel_loss=0.04061, linear_loss=0.05087]
[2020-05-11 23:11:12.829]  Step 147329  [3.290 sec/step, loss=0.09282, avg_loss=0.09212, mel_loss=0.04118, linear_loss=0.05163]
[2020-05-11 23:11:16.056]  Step 147330  [3.312 sec/step, loss=0.09937, avg_loss=0.09228, mel_loss=0.04511, linear_loss=0.05426]
[2020-05-11 23:11:29.936]  Step 147331  [3.425 sec/step, loss=0.07981, avg_loss=0.09212, mel_loss=0.03844, linear_loss=0.04137]
[2020-05-11 23:11:30.520]  Step 147332  [3.420 sec/step, loss=0.07504, avg_loss=0.09206, mel_loss=0.03368, linear_loss=0.04137]
[2020-05-11 23:11:34.010]  Step 147333  [3.415 sec/step, loss=0.09918, avg_loss=0.09207, mel_loss=0.04501, linear_loss=0.05417]
[2020-05-11 23:11:43.044]  Step 147334  [3.488 sec/step, loss=0.09926, avg_loss=0.09214, mel_loss=0.04669, linear_loss=0.05257]
[2020-05-11 23:11:44.326]  Step 147335  [3.493 sec/step, loss=0.08679, avg_loss=0.09221, mel_loss=0.03840, linear_loss=0.04839]
[2020-05-11 23:11:45.358]  Step 147336  [3.472 sec/step, loss=0.08395, avg_loss=0.09206, mel_loss=0.03678, linear_loss=0.04717]
[2020-05-11 23:11:47.110]  Step 147337  [3.476 sec/step, loss=0.09374, avg_loss=0.09212, mel_loss=0.04131, linear_loss=0.05244]
[2020-05-11 23:11:51.283]  Step 147338  [3.428 sec/step, loss=0.09841, avg_loss=0.09211, mel_loss=0.04489, linear_loss=0.05352]
[2020-05-11 23:11:52.288]  Step 147339  [3.415 sec/step, loss=0.08180, avg_loss=0.09197, mel_loss=0.03550, linear_loss=0.04630]
[2020-05-11 23:11:54.738]  Step 147340  [3.434 sec/step, loss=0.09599, avg_loss=0.09219, mel_loss=0.04303, linear_loss=0.05296]
[2020-05-11 23:11:56.175]  Step 147341  [3.414 sec/step, loss=0.08817, avg_loss=0.09208, mel_loss=0.03886, linear_loss=0.04930]
[2020-05-11 23:11:58.764]  Step 147342  [3.371 sec/step, loss=0.09293, avg_loss=0.09201, mel_loss=0.04168, linear_loss=0.05125]
[2020-05-11 23:12:03.496]  Step 147343  [3.404 sec/step, loss=0.10026, avg_loss=0.09211, mel_loss=0.04604, linear_loss=0.05422]
[2020-05-11 23:12:04.976]  Step 147344  [3.399 sec/step, loss=0.08804, avg_loss=0.09209, mel_loss=0.03890, linear_loss=0.04914]
[2020-05-11 23:12:05.329]  Generated 32 batches of size 32 in 1.828 sec
[2020-05-11 23:12:10.295]  Step 147345  [3.431 sec/step, loss=0.09845, avg_loss=0.09214, mel_loss=0.04536, linear_loss=0.05310]
[2020-05-11 23:12:14.749]  Step 147346  [3.447 sec/step, loss=0.09903, avg_loss=0.09215, mel_loss=0.04529, linear_loss=0.05374]
[2020-05-11 23:12:15.546]  Step 147347  [3.311 sec/step, loss=0.07599, avg_loss=0.09211, mel_loss=0.03325, linear_loss=0.04274]
[2020-05-11 23:12:22.349]  Step 147348  [3.324 sec/step, loss=0.09861, avg_loss=0.09208, mel_loss=0.04578, linear_loss=0.05283]
[2020-05-11 23:12:24.422]  Step 147349  [3.327 sec/step, loss=0.09269, avg_loss=0.09206, mel_loss=0.04142, linear_loss=0.05126]
[2020-05-11 23:12:25.237]  Step 147350  [3.323 sec/step, loss=0.07963, avg_loss=0.09199, mel_loss=0.03479, linear_loss=0.04484]
[2020-05-11 23:12:25.237]  Writing summary at step: 147350
[2020-05-11 23:12:26.368]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147350
[2020-05-11 23:12:27.760]  Saving audio and alignment...
[2020-05-11 23:12:35.578]  Input: 빨랐다 느렸다 속도에 차이를 보여주셔야만 실력자 가 될수있습니다~______________________________________
[2020-05-11 23:12:38.611]  Step 147351  [3.331 sec/step, loss=0.09680, avg_loss=0.09202, mel_loss=0.04369, linear_loss=0.05311]
[2020-05-11 23:12:40.384]  Step 147352  [3.314 sec/step, loss=0.09140, avg_loss=0.09197, mel_loss=0.04051, linear_loss=0.05089]
[2020-05-11 23:12:44.051]  Step 147353  [3.274 sec/step, loss=0.09802, avg_loss=0.09195, mel_loss=0.04462, linear_loss=0.05340]
[2020-05-11 23:12:47.423]  Step 147354  [3.299 sec/step, loss=0.09758, avg_loss=0.09214, mel_loss=0.04418, linear_loss=0.05340]
[2020-05-11 23:12:50.831]  Step 147355  [3.276 sec/step, loss=0.09661, avg_loss=0.09209, mel_loss=0.04429, linear_loss=0.05232]
[2020-05-11 23:12:52.358]  Step 147356  [3.247 sec/step, loss=0.08891, avg_loss=0.09200, mel_loss=0.03947, linear_loss=0.04943]
[2020-05-11 23:12:53.525]  Step 147357  [3.248 sec/step, loss=0.08653, avg_loss=0.09201, mel_loss=0.03821, linear_loss=0.04832]
[2020-05-11 23:13:02.095]  Step 147358  [3.285 sec/step, loss=0.09837, avg_loss=0.09201, mel_loss=0.04617, linear_loss=0.05220]
[2020-05-11 23:13:02.915]  Step 147359  [3.284 sec/step, loss=0.07839, avg_loss=0.09197, mel_loss=0.03428, linear_loss=0.04410]
[2020-05-11 23:13:04.293]  Step 147360  [3.251 sec/step, loss=0.08780, avg_loss=0.09186, mel_loss=0.03887, linear_loss=0.04894]
[2020-05-11 23:13:18.709]  Step 147361  [3.366 sec/step, loss=0.07708, avg_loss=0.09166, mel_loss=0.03699, linear_loss=0.04009]
[2020-05-11 23:13:22.900]  Step 147362  [3.364 sec/step, loss=0.09817, avg_loss=0.09164, mel_loss=0.04502, linear_loss=0.05316]
[2020-05-11 23:13:24.789]  Step 147363  [3.295 sec/step, loss=0.08941, avg_loss=0.09155, mel_loss=0.03954, linear_loss=0.04988]
[2020-05-11 23:13:25.707]  Step 147364  [3.294 sec/step, loss=0.08364, avg_loss=0.09154, mel_loss=0.03632, linear_loss=0.04732]
[2020-05-11 23:13:32.278]  Step 147365  [3.334 sec/step, loss=0.09929, avg_loss=0.09160, mel_loss=0.04626, linear_loss=0.05303]
[2020-05-11 23:13:36.891]  Step 147366  [3.346 sec/step, loss=0.09928, avg_loss=0.09163, mel_loss=0.04537, linear_loss=0.05391]
[2020-05-11 23:13:39.827]  Step 147367  [3.356 sec/step, loss=0.09663, avg_loss=0.09169, mel_loss=0.04378, linear_loss=0.05285]
[2020-05-11 23:13:47.178]  Step 147368  [3.414 sec/step, loss=0.10175, avg_loss=0.09179, mel_loss=0.04767, linear_loss=0.05409]
[2020-05-11 23:13:48.274]  Step 147369  [3.414 sec/step, loss=0.08666, avg_loss=0.09180, mel_loss=0.03791, linear_loss=0.04876]
[2020-05-11 23:13:52.068]  Step 147370  [3.376 sec/step, loss=0.09896, avg_loss=0.09176, mel_loss=0.04504, linear_loss=0.05392]
[2020-05-11 23:13:53.680]  Step 147371  [3.364 sec/step, loss=0.09295, avg_loss=0.09175, mel_loss=0.04159, linear_loss=0.05137]
[2020-05-11 23:13:55.648]  Step 147372  [3.370 sec/step, loss=0.09363, avg_loss=0.09179, mel_loss=0.04172, linear_loss=0.05192]
[2020-05-11 23:13:56.176]  Step 147373  [3.312 sec/step, loss=0.07207, avg_loss=0.09152, mel_loss=0.03231, linear_loss=0.03975]
[2020-05-11 23:13:57.046]  Step 147374  [3.270 sec/step, loss=0.07829, avg_loss=0.09133, mel_loss=0.03426, linear_loss=0.04404]
[2020-05-11 23:13:57.851]  Generated 32 batches of size 32 in 1.670 sec
[2020-05-11 23:14:02.470]  Step 147375  [3.267 sec/step, loss=0.09937, avg_loss=0.09134, mel_loss=0.04597, linear_loss=0.05339]
[2020-05-11 23:14:08.256]  Step 147376  [3.290 sec/step, loss=0.10088, avg_loss=0.09138, mel_loss=0.04683, linear_loss=0.05405]
[2020-05-11 23:14:10.900]  Step 147377  [3.286 sec/step, loss=0.09575, avg_loss=0.09137, mel_loss=0.04334, linear_loss=0.05241]
[2020-05-11 23:14:13.056]  Step 147378  [3.266 sec/step, loss=0.09365, avg_loss=0.09132, mel_loss=0.04212, linear_loss=0.05154]
[2020-05-11 23:14:15.316]  Step 147379  [3.280 sec/step, loss=0.09330, avg_loss=0.09146, mel_loss=0.04220, linear_loss=0.05109]
[2020-05-11 23:14:16.609]  Step 147380  [3.243 sec/step, loss=0.09009, avg_loss=0.09135, mel_loss=0.03995, linear_loss=0.05014]
[2020-05-11 23:14:19.104]  Step 147381  [3.232 sec/step, loss=0.09458, avg_loss=0.09137, mel_loss=0.04224, linear_loss=0.05234]
[2020-05-11 23:14:20.133]  Step 147382  [3.219 sec/step, loss=0.08408, avg_loss=0.09132, mel_loss=0.03702, linear_loss=0.04706]
[2020-05-11 23:14:22.534]  Step 147383  [3.209 sec/step, loss=0.09505, avg_loss=0.09136, mel_loss=0.04264, linear_loss=0.05240]
[2020-05-11 23:14:25.877]  Step 147384  [3.216 sec/step, loss=0.09962, avg_loss=0.09144, mel_loss=0.04509, linear_loss=0.05454]
[2020-05-11 23:14:26.683]  Step 147385  [3.211 sec/step, loss=0.07964, avg_loss=0.09138, mel_loss=0.03450, linear_loss=0.04514]
[2020-05-11 23:14:29.762]  Step 147386  [3.233 sec/step, loss=0.09923, avg_loss=0.09159, mel_loss=0.04498, linear_loss=0.05426]
[2020-05-11 23:14:31.799]  Step 147387  [3.245 sec/step, loss=0.09329, avg_loss=0.09175, mel_loss=0.04164, linear_loss=0.05165]
[2020-05-11 23:14:33.583]  Step 147388  [3.235 sec/step, loss=0.09139, avg_loss=0.09174, mel_loss=0.04049, linear_loss=0.05090]
[2020-05-11 23:14:36.233]  Step 147389  [3.132 sec/step, loss=0.09387, avg_loss=0.09180, mel_loss=0.04236, linear_loss=0.05151]
[2020-05-11 23:14:42.435]  Step 147390  [3.179 sec/step, loss=0.09859, avg_loss=0.09187, mel_loss=0.04599, linear_loss=0.05260]
[2020-05-11 23:14:47.029]  Step 147391  [3.193 sec/step, loss=0.09848, avg_loss=0.09185, mel_loss=0.04521, linear_loss=0.05327]
[2020-05-11 23:14:50.611]  Step 147392  [3.174 sec/step, loss=0.09908, avg_loss=0.09185, mel_loss=0.04502, linear_loss=0.05406]
[2020-05-11 23:14:51.133]  Step 147393  [3.163 sec/step, loss=0.07200, avg_loss=0.09168, mel_loss=0.03249, linear_loss=0.03951]
[2020-05-11 23:14:56.626]  Step 147394  [3.189 sec/step, loss=0.10035, avg_loss=0.09171, mel_loss=0.04652, linear_loss=0.05383]
[2020-05-11 23:14:58.133]  Step 147395  [3.135 sec/step, loss=0.08703, avg_loss=0.09156, mel_loss=0.03872, linear_loss=0.04831]
[2020-05-11 23:15:02.425]  Step 147396  [3.160 sec/step, loss=0.09931, avg_loss=0.09165, mel_loss=0.04525, linear_loss=0.05406]
[2020-05-11 23:15:07.853]  Step 147397  [3.193 sec/step, loss=0.09824, avg_loss=0.09168, mel_loss=0.04517, linear_loss=0.05307]
[2020-05-11 23:15:09.629]  Step 147398  [3.198 sec/step, loss=0.09095, avg_loss=0.09172, mel_loss=0.04044, linear_loss=0.05051]
[2020-05-11 23:15:10.684]  Step 147399  [3.200 sec/step, loss=0.08054, avg_loss=0.09171, mel_loss=0.03559, linear_loss=0.04496]
[2020-05-11 23:15:12.668]  Step 147400  [3.184 sec/step, loss=0.09297, avg_loss=0.09166, mel_loss=0.04117, linear_loss=0.05180]
[2020-05-11 23:15:12.668]  Writing summary at step: 147400
[2020-05-11 23:15:17.018]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147400
[2020-05-11 23:15:18.425]  Saving audio and alignment...
[2020-05-11 23:15:21.271]  Input: 그러면 키워드가 정말로 살아나~________
[2020-05-11 23:15:22.544]  Step 147401  [3.186 sec/step, loss=0.08691, avg_loss=0.09166, mel_loss=0.03825, linear_loss=0.04866]
[2020-05-11 23:15:24.659]  Step 147402  [3.160 sec/step, loss=0.09523, avg_loss=0.09160, mel_loss=0.04251, linear_loss=0.05272]
[2020-05-11 23:15:25.780]  Step 147403  [3.160 sec/step, loss=0.08397, avg_loss=0.09162, mel_loss=0.03664, linear_loss=0.04733]
[2020-05-11 23:15:27.494]  Generated 32 batches of size 32 in 1.709 sec
[2020-05-11 23:15:29.331]  Step 147404  [3.160 sec/step, loss=0.09682, avg_loss=0.09161, mel_loss=0.04392, linear_loss=0.05290]
[2020-05-11 23:15:32.206]  Step 147405  [3.147 sec/step, loss=0.09704, avg_loss=0.09160, mel_loss=0.04378, linear_loss=0.05326]
[2020-05-11 23:15:33.075]  Step 147406  [3.070 sec/step, loss=0.07338, avg_loss=0.09138, mel_loss=0.03234, linear_loss=0.04104]
[2020-05-11 23:15:47.099]  Step 147407  [3.079 sec/step, loss=0.07814, avg_loss=0.09136, mel_loss=0.03756, linear_loss=0.04058]
[2020-05-11 23:15:54.508]  Step 147408  [3.129 sec/step, loss=0.10194, avg_loss=0.09142, mel_loss=0.04752, linear_loss=0.05442]
[2020-05-11 23:15:55.498]  Step 147409  [3.112 sec/step, loss=0.08279, avg_loss=0.09129, mel_loss=0.03605, linear_loss=0.04674]
[2020-05-11 23:15:58.132]  Step 147410  [3.118 sec/step, loss=0.09550, avg_loss=0.09130, mel_loss=0.04337, linear_loss=0.05212]
[2020-05-11 23:15:59.484]  Step 147411  [3.106 sec/step, loss=0.09070, avg_loss=0.09126, mel_loss=0.04004, linear_loss=0.05066]
[2020-05-11 23:16:07.822]  Step 147412  [3.182 sec/step, loss=0.09807, avg_loss=0.09144, mel_loss=0.04580, linear_loss=0.05227]
[2020-05-11 23:16:09.337]  Step 147413  [3.183 sec/step, loss=0.09067, avg_loss=0.09147, mel_loss=0.04052, linear_loss=0.05015]
[2020-05-11 23:16:11.094]  Step 147414  [3.151 sec/step, loss=0.09113, avg_loss=0.09141, mel_loss=0.04045, linear_loss=0.05067]
[2020-05-11 23:16:12.807]  Step 147415  [3.150 sec/step, loss=0.09204, avg_loss=0.09140, mel_loss=0.04095, linear_loss=0.05109]
[2020-05-11 23:16:18.077]  Step 147416  [3.192 sec/step, loss=0.10087, avg_loss=0.09158, mel_loss=0.04661, linear_loss=0.05426]
[2020-05-11 23:16:22.332]  Step 147417  [3.220 sec/step, loss=0.10060, avg_loss=0.09170, mel_loss=0.04625, linear_loss=0.05435]
[2020-05-11 23:16:25.289]  Step 147418  [3.244 sec/step, loss=0.09689, avg_loss=0.09190, mel_loss=0.04380, linear_loss=0.05309]
[2020-05-11 23:16:29.414]  Step 147419  [3.266 sec/step, loss=0.09767, avg_loss=0.09196, mel_loss=0.04429, linear_loss=0.05339]
[2020-05-11 23:16:31.326]  Step 147420  [3.278 sec/step, loss=0.09207, avg_loss=0.09209, mel_loss=0.04112, linear_loss=0.05095]
[2020-05-11 23:16:34.993]  Step 147421  [3.296 sec/step, loss=0.09975, avg_loss=0.09217, mel_loss=0.04568, linear_loss=0.05407]
[2020-05-11 23:16:36.364]  Step 147422  [3.280 sec/step, loss=0.08963, avg_loss=0.09212, mel_loss=0.03980, linear_loss=0.04983]
[2020-05-11 23:16:37.106]  Step 147423  [3.253 sec/step, loss=0.08378, avg_loss=0.09198, mel_loss=0.03707, linear_loss=0.04671]
[2020-05-11 23:16:50.047]  Step 147424  [3.345 sec/step, loss=0.08715, avg_loss=0.09187, mel_loss=0.04195, linear_loss=0.04520]
[2020-05-11 23:16:52.534]  Step 147425  [3.294 sec/step, loss=0.09466, avg_loss=0.09184, mel_loss=0.04230, linear_loss=0.05237]
[2020-05-11 23:16:55.856]  Step 147426  [3.300 sec/step, loss=0.09762, avg_loss=0.09186, mel_loss=0.04453, linear_loss=0.05309]
[2020-05-11 23:17:00.636]  Step 147427  [3.327 sec/step, loss=0.09939, avg_loss=0.09195, mel_loss=0.04544, linear_loss=0.05395]
[2020-05-11 23:17:01.468]  Step 147428  [3.319 sec/step, loss=0.07984, avg_loss=0.09184, mel_loss=0.03543, linear_loss=0.04442]
[2020-05-11 23:17:02.563]  Step 147429  [3.308 sec/step, loss=0.08550, avg_loss=0.09176, mel_loss=0.03764, linear_loss=0.04786]
[2020-05-11 23:17:04.905]  Step 147430  [3.299 sec/step, loss=0.09547, avg_loss=0.09173, mel_loss=0.04290, linear_loss=0.05257]
[2020-05-11 23:17:10.703]  Step 147431  [3.218 sec/step, loss=0.10106, avg_loss=0.09194, mel_loss=0.04677, linear_loss=0.05429]
[2020-05-11 23:17:12.053]  Step 147432  [3.226 sec/step, loss=0.08467, avg_loss=0.09203, mel_loss=0.03740, linear_loss=0.04727]
[2020-05-11 23:17:13.203]  Step 147433  [3.202 sec/step, loss=0.08831, avg_loss=0.09193, mel_loss=0.03893, linear_loss=0.04938]
[2020-05-11 23:17:14.173]  Step 147434  [3.122 sec/step, loss=0.08348, avg_loss=0.09177, mel_loss=0.03669, linear_loss=0.04679]
[2020-05-11 23:17:15.043]  Step 147435  [3.117 sec/step, loss=0.08157, avg_loss=0.09172, mel_loss=0.03591, linear_loss=0.04566]
[2020-05-11 23:17:15.635]  Step 147436  [3.113 sec/step, loss=0.07309, avg_loss=0.09161, mel_loss=0.03263, linear_loss=0.04047]
[2020-05-11 23:17:16.812]  Generated 32 batches of size 32 in 1.763 sec
[2020-05-11 23:17:23.256]  Step 147437  [3.172 sec/step, loss=0.10091, avg_loss=0.09168, mel_loss=0.04717, linear_loss=0.05374]
[2020-05-11 23:17:26.420]  Step 147438  [3.162 sec/step, loss=0.09628, avg_loss=0.09166, mel_loss=0.04371, linear_loss=0.05257]
[2020-05-11 23:17:29.202]  Step 147439  [3.179 sec/step, loss=0.09421, avg_loss=0.09178, mel_loss=0.04242, linear_loss=0.05179]
[2020-05-11 23:17:31.367]  Step 147440  [3.177 sec/step, loss=0.09387, avg_loss=0.09176, mel_loss=0.04218, linear_loss=0.05169]
[2020-05-11 23:17:33.319]  Step 147441  [3.182 sec/step, loss=0.09496, avg_loss=0.09183, mel_loss=0.04274, linear_loss=0.05222]
[2020-05-11 23:17:40.172]  Step 147442  [3.224 sec/step, loss=0.10055, avg_loss=0.09190, mel_loss=0.04681, linear_loss=0.05374]
[2020-05-11 23:17:49.142]  Step 147443  [3.267 sec/step, loss=0.09971, avg_loss=0.09190, mel_loss=0.04698, linear_loss=0.05272]
[2020-05-11 23:17:52.759]  Step 147444  [3.288 sec/step, loss=0.09814, avg_loss=0.09200, mel_loss=0.04489, linear_loss=0.05324]
[2020-05-11 23:17:54.143]  Step 147445  [3.249 sec/step, loss=0.08607, avg_loss=0.09188, mel_loss=0.03801, linear_loss=0.04807]
[2020-05-11 23:18:02.851]  Step 147446  [3.291 sec/step, loss=0.09741, avg_loss=0.09186, mel_loss=0.04560, linear_loss=0.05182]
[2020-05-11 23:18:03.910]  Step 147447  [3.294 sec/step, loss=0.08767, avg_loss=0.09198, mel_loss=0.03826, linear_loss=0.04942]
[2020-05-11 23:18:07.077]  Step 147448  [3.258 sec/step, loss=0.09760, avg_loss=0.09197, mel_loss=0.04431, linear_loss=0.05329]
[2020-05-11 23:18:08.062]  Step 147449  [3.247 sec/step, loss=0.08189, avg_loss=0.09186, mel_loss=0.03552, linear_loss=0.04637]
[2020-05-11 23:18:09.662]  Step 147450  [3.255 sec/step, loss=0.09157, avg_loss=0.09198, mel_loss=0.04070, linear_loss=0.05087]
[2020-05-11 23:18:09.662]  Writing summary at step: 147450
[2020-05-11 23:18:10.234]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147450
[2020-05-11 23:18:11.642]  Saving audio and alignment...
[2020-05-11 23:18:13.430]  Input: 이런 식으로 처리~__
[2020-05-11 23:18:16.843]  Step 147451  [3.258 sec/step, loss=0.09739, avg_loss=0.09198, mel_loss=0.04400, linear_loss=0.05339]
[2020-05-11 23:18:22.153]  Step 147452  [3.294 sec/step, loss=0.09793, avg_loss=0.09205, mel_loss=0.04531, linear_loss=0.05262]
[2020-05-11 23:18:22.914]  Step 147453  [3.265 sec/step, loss=0.07243, avg_loss=0.09179, mel_loss=0.03168, linear_loss=0.04076]
[2020-05-11 23:18:27.270]  Step 147454  [3.275 sec/step, loss=0.09827, avg_loss=0.09180, mel_loss=0.04496, linear_loss=0.05331]
[2020-05-11 23:18:29.275]  Step 147455  [3.260 sec/step, loss=0.09220, avg_loss=0.09176, mel_loss=0.04107, linear_loss=0.05113]
[2020-05-11 23:18:32.822]  Step 147456  [3.281 sec/step, loss=0.09939, avg_loss=0.09186, mel_loss=0.04517, linear_loss=0.05421]
[2020-05-11 23:18:35.210]  Step 147457  [3.293 sec/step, loss=0.09663, avg_loss=0.09196, mel_loss=0.04340, linear_loss=0.05323]
[2020-05-11 23:18:39.859]  Step 147458  [3.254 sec/step, loss=0.09878, avg_loss=0.09197, mel_loss=0.04522, linear_loss=0.05356]
[2020-05-11 23:18:43.512]  Step 147459  [3.282 sec/step, loss=0.09359, avg_loss=0.09212, mel_loss=0.04192, linear_loss=0.05166]
[2020-05-11 23:18:45.319]  Step 147460  [3.286 sec/step, loss=0.08478, avg_loss=0.09209, mel_loss=0.03709, linear_loss=0.04770]
[2020-05-11 23:18:56.852]  Step 147461  [3.257 sec/step, loss=0.10017, avg_loss=0.09232, mel_loss=0.04676, linear_loss=0.05341]
[2020-05-11 23:19:01.058]  Step 147462  [3.258 sec/step, loss=0.09887, avg_loss=0.09233, mel_loss=0.04523, linear_loss=0.05364]
[2020-05-11 23:19:06.740]  Step 147463  [3.296 sec/step, loss=0.10046, avg_loss=0.09244, mel_loss=0.04642, linear_loss=0.05404]
[2020-05-11 23:19:08.038]  Step 147464  [3.299 sec/step, loss=0.08604, avg_loss=0.09246, mel_loss=0.03816, linear_loss=0.04788]
[2020-05-11 23:19:22.465]  Step 147465  [3.378 sec/step, loss=0.07663, avg_loss=0.09223, mel_loss=0.03653, linear_loss=0.04010]
[2020-05-11 23:19:24.122]  Step 147466  [3.348 sec/step, loss=0.08897, avg_loss=0.09213, mel_loss=0.03959, linear_loss=0.04938]
[2020-05-11 23:19:24.205]  Generated 32 batches of size 32 in 1.734 sec
[2020-05-11 23:19:26.951]  Step 147467  [3.347 sec/step, loss=0.09638, avg_loss=0.09213, mel_loss=0.04362, linear_loss=0.05276]
[2020-05-11 23:19:28.684]  Step 147468  [3.291 sec/step, loss=0.09139, avg_loss=0.09202, mel_loss=0.04027, linear_loss=0.05112]
[2020-05-11 23:19:29.644]  Step 147469  [3.290 sec/step, loss=0.08705, avg_loss=0.09203, mel_loss=0.03835, linear_loss=0.04871]
[2020-05-11 23:19:31.459]  Step 147470  [3.270 sec/step, loss=0.09156, avg_loss=0.09195, mel_loss=0.04048, linear_loss=0.05108]
[2020-05-11 23:19:33.637]  Step 147471  [3.276 sec/step, loss=0.09520, avg_loss=0.09198, mel_loss=0.04259, linear_loss=0.05261]
[2020-05-11 23:19:35.665]  Step 147472  [3.276 sec/step, loss=0.09248, avg_loss=0.09197, mel_loss=0.04115, linear_loss=0.05133]
[2020-05-11 23:19:39.091]  Step 147473  [3.305 sec/step, loss=0.09737, avg_loss=0.09222, mel_loss=0.04413, linear_loss=0.05325]
[2020-05-11 23:19:45.226]  Step 147474  [3.358 sec/step, loss=0.10012, avg_loss=0.09244, mel_loss=0.04649, linear_loss=0.05362]
[2020-05-11 23:19:50.664]  Step 147475  [3.358 sec/step, loss=0.10149, avg_loss=0.09246, mel_loss=0.04688, linear_loss=0.05461]
[2020-05-11 23:19:52.820]  Step 147476  [3.322 sec/step, loss=0.09202, avg_loss=0.09237, mel_loss=0.04131, linear_loss=0.05071]
[2020-05-11 23:19:53.373]  Step 147477  [3.301 sec/step, loss=0.07538, avg_loss=0.09217, mel_loss=0.03341, linear_loss=0.04196]
[2020-05-11 23:19:55.813]  Step 147478  [3.304 sec/step, loss=0.09207, avg_loss=0.09215, mel_loss=0.04107, linear_loss=0.05101]
[2020-05-11 23:19:57.057]  Step 147479  [3.293 sec/step, loss=0.08711, avg_loss=0.09209, mel_loss=0.03848, linear_loss=0.04864]
[2020-05-11 23:19:58.882]  Step 147480  [3.299 sec/step, loss=0.08971, avg_loss=0.09208, mel_loss=0.03997, linear_loss=0.04974]
[2020-05-11 23:20:03.740]  Step 147481  [3.322 sec/step, loss=0.09937, avg_loss=0.09213, mel_loss=0.04574, linear_loss=0.05363]
[2020-05-11 23:20:04.874]  Step 147482  [3.323 sec/step, loss=0.08272, avg_loss=0.09212, mel_loss=0.03634, linear_loss=0.04639]
[2020-05-11 23:20:06.785]  Step 147483  [3.319 sec/step, loss=0.09173, avg_loss=0.09209, mel_loss=0.04122, linear_loss=0.05050]
[2020-05-11 23:20:10.511]  Step 147484  [3.322 sec/step, loss=0.09839, avg_loss=0.09207, mel_loss=0.04459, linear_loss=0.05380]
[2020-05-11 23:20:14.004]  Step 147485  [3.349 sec/step, loss=0.09854, avg_loss=0.09226, mel_loss=0.04494, linear_loss=0.05360]
[2020-05-11 23:20:16.894]  Step 147486  [3.347 sec/step, loss=0.09588, avg_loss=0.09223, mel_loss=0.04348, linear_loss=0.05240]
[2020-05-11 23:20:23.512]  Step 147487  [3.393 sec/step, loss=0.09708, avg_loss=0.09227, mel_loss=0.04494, linear_loss=0.05213]
[2020-05-11 23:20:24.504]  Step 147488  [3.385 sec/step, loss=0.08087, avg_loss=0.09216, mel_loss=0.03513, linear_loss=0.04574]
[2020-05-11 23:20:33.016]  Step 147489  [3.444 sec/step, loss=0.09858, avg_loss=0.09221, mel_loss=0.04619, linear_loss=0.05239]
[2020-05-11 23:20:36.688]  Step 147490  [3.419 sec/step, loss=0.10036, avg_loss=0.09223, mel_loss=0.04589, linear_loss=0.05447]
[2020-05-11 23:20:41.251]  Step 147491  [3.418 sec/step, loss=0.09933, avg_loss=0.09223, mel_loss=0.04549, linear_loss=0.05384]
[2020-05-11 23:20:42.843]  Step 147492  [3.398 sec/step, loss=0.09251, avg_loss=0.09217, mel_loss=0.04104, linear_loss=0.05148]
[2020-05-11 23:20:44.278]  Step 147493  [3.408 sec/step, loss=0.08804, avg_loss=0.09233, mel_loss=0.03928, linear_loss=0.04876]
[2020-05-11 23:20:45.025]  Step 147494  [3.360 sec/step, loss=0.07982, avg_loss=0.09212, mel_loss=0.03469, linear_loss=0.04513]
[2020-05-11 23:20:45.825]  Step 147495  [3.353 sec/step, loss=0.07891, avg_loss=0.09204, mel_loss=0.03466, linear_loss=0.04424]
[2020-05-11 23:20:48.006]  Step 147496  [3.332 sec/step, loss=0.09178, avg_loss=0.09197, mel_loss=0.04109, linear_loss=0.05069]
[2020-05-11 23:20:51.339]  Step 147497  [3.311 sec/step, loss=0.09631, avg_loss=0.09195, mel_loss=0.04370, linear_loss=0.05261]
[2020-05-11 23:20:53.062]  Generated 32 batches of size 32 in 1.718 sec
[2020-05-11 23:20:58.777]  Step 147498  [3.368 sec/step, loss=0.10098, avg_loss=0.09205, mel_loss=0.04709, linear_loss=0.05389]
[2020-05-11 23:21:02.926]  Step 147499  [3.398 sec/step, loss=0.09872, avg_loss=0.09223, mel_loss=0.04510, linear_loss=0.05362]
[2020-05-11 23:21:05.618]  Step 147500  [3.406 sec/step, loss=0.09450, avg_loss=0.09225, mel_loss=0.04264, linear_loss=0.05186]
[2020-05-11 23:21:05.618]  Writing summary at step: 147500
[2020-05-11 23:21:06.623]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147500
[2020-05-11 23:21:08.023]  Saving audio and alignment...
[2020-05-11 23:21:10.626]  Input: 들어가 볼까요~__________________
[2020-05-11 23:21:11.971]  Step 147501  [3.406 sec/step, loss=0.09058, avg_loss=0.09228, mel_loss=0.03966, linear_loss=0.05092]
[2020-05-11 23:21:13.712]  Step 147502  [3.403 sec/step, loss=0.09103, avg_loss=0.09224, mel_loss=0.04033, linear_loss=0.05070]
[2020-05-11 23:21:16.583]  Step 147503  [3.420 sec/step, loss=0.09681, avg_loss=0.09237, mel_loss=0.04367, linear_loss=0.05314]
[2020-05-11 23:21:28.687]  Step 147504  [3.506 sec/step, loss=0.08902, avg_loss=0.09229, mel_loss=0.04267, linear_loss=0.04635]
[2020-05-11 23:21:42.854]  Step 147505  [3.618 sec/step, loss=0.07566, avg_loss=0.09208, mel_loss=0.03607, linear_loss=0.03959]
[2020-05-11 23:21:46.233]  Step 147506  [3.644 sec/step, loss=0.09691, avg_loss=0.09231, mel_loss=0.04415, linear_loss=0.05276]
[2020-05-11 23:21:49.257]  Step 147507  [3.534 sec/step, loss=0.09871, avg_loss=0.09252, mel_loss=0.04470, linear_loss=0.05401]
[2020-05-11 23:21:50.671]  Step 147508  [3.474 sec/step, loss=0.08846, avg_loss=0.09238, mel_loss=0.03906, linear_loss=0.04941]
[2020-05-11 23:21:52.634]  Step 147509  [3.483 sec/step, loss=0.09538, avg_loss=0.09251, mel_loss=0.04270, linear_loss=0.05268]
[2020-05-11 23:21:54.328]  Step 147510  [3.474 sec/step, loss=0.09373, avg_loss=0.09249, mel_loss=0.04133, linear_loss=0.05240]
[2020-05-11 23:21:59.908]  Step 147511  [3.516 sec/step, loss=0.10053, avg_loss=0.09259, mel_loss=0.04655, linear_loss=0.05398]
[2020-05-11 23:22:05.209]  Step 147512  [3.486 sec/step, loss=0.09792, avg_loss=0.09259, mel_loss=0.04514, linear_loss=0.05278]
[2020-05-11 23:22:06.594]  Step 147513  [3.485 sec/step, loss=0.08696, avg_loss=0.09255, mel_loss=0.03864, linear_loss=0.04833]
[2020-05-11 23:22:08.248]  Step 147514  [3.484 sec/step, loss=0.09029, avg_loss=0.09254, mel_loss=0.04034, linear_loss=0.04995]
[2020-05-11 23:22:09.259]  Step 147515  [3.477 sec/step, loss=0.08384, avg_loss=0.09246, mel_loss=0.03695, linear_loss=0.04689]
[2020-05-11 23:22:17.618]  Step 147516  [3.507 sec/step, loss=0.09892, avg_loss=0.09244, mel_loss=0.04655, linear_loss=0.05236]
[2020-05-11 23:22:18.432]  Step 147517  [3.473 sec/step, loss=0.07972, avg_loss=0.09223, mel_loss=0.03478, linear_loss=0.04494]
[2020-05-11 23:22:19.542]  Step 147518  [3.455 sec/step, loss=0.08963, avg_loss=0.09216, mel_loss=0.03881, linear_loss=0.05082]
[2020-05-11 23:22:21.555]  Step 147519  [3.433 sec/step, loss=0.09187, avg_loss=0.09210, mel_loss=0.04068, linear_loss=0.05119]
[2020-05-11 23:22:24.990]  Step 147520  [3.449 sec/step, loss=0.09697, avg_loss=0.09215, mel_loss=0.04396, linear_loss=0.05301]
[2020-05-11 23:22:26.781]  Step 147521  [3.430 sec/step, loss=0.09302, avg_loss=0.09208, mel_loss=0.04106, linear_loss=0.05196]
[2020-05-11 23:22:34.132]  Step 147522  [3.490 sec/step, loss=0.10086, avg_loss=0.09220, mel_loss=0.04696, linear_loss=0.05390]
[2020-05-11 23:22:36.761]  Step 147523  [3.509 sec/step, loss=0.09552, avg_loss=0.09231, mel_loss=0.04308, linear_loss=0.05244]
[2020-05-11 23:22:37.932]  Step 147524  [3.391 sec/step, loss=0.08798, avg_loss=0.09232, mel_loss=0.03874, linear_loss=0.04924]
[2020-05-11 23:22:42.694]  Step 147525  [3.414 sec/step, loss=0.10052, avg_loss=0.09238, mel_loss=0.04608, linear_loss=0.05444]
[2020-05-11 23:22:46.813]  Step 147526  [3.422 sec/step, loss=0.09820, avg_loss=0.09239, mel_loss=0.04459, linear_loss=0.05360]
[2020-05-11 23:22:48.981]  Step 147527  [3.395 sec/step, loss=0.09320, avg_loss=0.09232, mel_loss=0.04164, linear_loss=0.05156]
[2020-05-11 23:22:50.735]  Generated 32 batches of size 32 in 1.749 sec
[2020-05-11 23:22:51.437]  Step 147528  [3.412 sec/step, loss=0.09611, avg_loss=0.09249, mel_loss=0.04330, linear_loss=0.05281]
[2020-05-11 23:22:55.704]  Step 147529  [3.443 sec/step, loss=0.10088, avg_loss=0.09264, mel_loss=0.04617, linear_loss=0.05471]
[2020-05-11 23:22:56.599]  Step 147530  [3.429 sec/step, loss=0.08307, avg_loss=0.09252, mel_loss=0.03623, linear_loss=0.04684]
[2020-05-11 23:22:57.160]  Step 147531  [3.377 sec/step, loss=0.07547, avg_loss=0.09226, mel_loss=0.03410, linear_loss=0.04138]
[2020-05-11 23:23:00.051]  Step 147532  [3.392 sec/step, loss=0.09684, avg_loss=0.09238, mel_loss=0.04391, linear_loss=0.05293]
[2020-05-11 23:23:02.492]  Step 147533  [3.405 sec/step, loss=0.09539, avg_loss=0.09245, mel_loss=0.04302, linear_loss=0.05237]
[2020-05-11 23:23:06.159]  Step 147534  [3.432 sec/step, loss=0.09925, avg_loss=0.09261, mel_loss=0.04511, linear_loss=0.05414]
[2020-05-11 23:23:07.035]  Step 147535  [3.432 sec/step, loss=0.07429, avg_loss=0.09254, mel_loss=0.03228, linear_loss=0.04201]
[2020-05-11 23:23:13.622]  Step 147536  [3.492 sec/step, loss=0.10043, avg_loss=0.09281, mel_loss=0.04672, linear_loss=0.05371]
[2020-05-11 23:23:18.069]  Step 147537  [3.460 sec/step, loss=0.10119, avg_loss=0.09281, mel_loss=0.04637, linear_loss=0.05481]
[2020-05-11 23:23:22.093]  Step 147538  [3.469 sec/step, loss=0.09899, avg_loss=0.09284, mel_loss=0.04530, linear_loss=0.05369]
[2020-05-11 23:23:23.469]  Step 147539  [3.455 sec/step, loss=0.08834, avg_loss=0.09278, mel_loss=0.03901, linear_loss=0.04933]
[2020-05-11 23:23:24.644]  Step 147540  [3.445 sec/step, loss=0.08998, avg_loss=0.09274, mel_loss=0.03996, linear_loss=0.05002]
[2020-05-11 23:23:36.656]  Step 147541  [3.545 sec/step, loss=0.08984, avg_loss=0.09269, mel_loss=0.04304, linear_loss=0.04681]
[2020-05-11 23:23:37.517]  Step 147542  [3.485 sec/step, loss=0.07613, avg_loss=0.09245, mel_loss=0.03317, linear_loss=0.04296]
[2020-05-11 23:23:38.386]  Step 147543  [3.404 sec/step, loss=0.08240, avg_loss=0.09227, mel_loss=0.03572, linear_loss=0.04667]
[2020-05-11 23:23:41.292]  Step 147544  [3.397 sec/step, loss=0.09903, avg_loss=0.09228, mel_loss=0.04479, linear_loss=0.05424]
[2020-05-11 23:23:44.291]  Step 147545  [3.413 sec/step, loss=0.09846, avg_loss=0.09241, mel_loss=0.04472, linear_loss=0.05373]
[2020-05-11 23:23:45.129]  Step 147546  [3.335 sec/step, loss=0.07773, avg_loss=0.09221, mel_loss=0.03458, linear_loss=0.04316]
[2020-05-11 23:23:47.729]  Step 147547  [3.350 sec/step, loss=0.09482, avg_loss=0.09228, mel_loss=0.04298, linear_loss=0.05184]
[2020-05-11 23:23:50.098]  Step 147548  [3.342 sec/step, loss=0.09471, avg_loss=0.09225, mel_loss=0.04231, linear_loss=0.05241]
[2020-05-11 23:23:51.611]  Step 147549  [3.347 sec/step, loss=0.09022, avg_loss=0.09234, mel_loss=0.03998, linear_loss=0.05024]
[2020-05-11 23:23:56.440]  Step 147550  [3.380 sec/step, loss=0.09965, avg_loss=0.09242, mel_loss=0.04590, linear_loss=0.05375]
[2020-05-11 23:23:56.440]  Writing summary at step: 147550
[2020-05-11 23:23:58.948]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147550
[2020-05-11 23:24:00.320]  Saving audio and alignment...
[2020-05-11 23:24:03.578]  Input: 이렇게 내려버리면 상당히 어색하게 들릴~__
[2020-05-11 23:24:05.682]  Step 147551  [3.367 sec/step, loss=0.09310, avg_loss=0.09237, mel_loss=0.04180, linear_loss=0.05130]
[2020-05-11 23:24:13.539]  Step 147552  [3.392 sec/step, loss=0.09582, avg_loss=0.09235, mel_loss=0.04469, linear_loss=0.05113]
[2020-05-11 23:24:17.585]  Step 147553  [3.425 sec/step, loss=0.09860, avg_loss=0.09262, mel_loss=0.04494, linear_loss=0.05367]
[2020-05-11 23:24:20.920]  Step 147554  [3.415 sec/step, loss=0.09986, avg_loss=0.09263, mel_loss=0.04527, linear_loss=0.05459]
[2020-05-11 23:24:21.480]  Step 147555  [3.400 sec/step, loss=0.07123, avg_loss=0.09242, mel_loss=0.03177, linear_loss=0.03946]
[2020-05-11 23:24:27.389]  Step 147556  [3.424 sec/step, loss=0.09770, avg_loss=0.09240, mel_loss=0.04519, linear_loss=0.05250]
[2020-05-11 23:24:28.680]  Step 147557  [3.413 sec/step, loss=0.08701, avg_loss=0.09231, mel_loss=0.03829, linear_loss=0.04871]
[2020-05-11 23:24:29.786]  Step 147558  [3.378 sec/step, loss=0.08716, avg_loss=0.09219, mel_loss=0.03837, linear_loss=0.04879]
[2020-05-11 23:24:30.427]  Generated 32 batches of size 32 in 1.742 sec
[2020-05-11 23:24:30.824]  Step 147559  [3.351 sec/step, loss=0.08310, avg_loss=0.09209, mel_loss=0.03651, linear_loss=0.04659]
[2020-05-11 23:24:34.398]  Step 147560  [3.369 sec/step, loss=0.09763, avg_loss=0.09222, mel_loss=0.04420, linear_loss=0.05343]
[2020-05-11 23:24:36.010]  Step 147561  [3.270 sec/step, loss=0.09045, avg_loss=0.09212, mel_loss=0.04031, linear_loss=0.05014]
[2020-05-11 23:24:38.024]  Step 147562  [3.248 sec/step, loss=0.09259, avg_loss=0.09206, mel_loss=0.04134, linear_loss=0.05125]
[2020-05-11 23:24:41.381]  Step 147563  [3.225 sec/step, loss=0.09651, avg_loss=0.09202, mel_loss=0.04384, linear_loss=0.05268]
[2020-05-11 23:24:46.706]  Step 147564  [3.265 sec/step, loss=0.10052, avg_loss=0.09216, mel_loss=0.04627, linear_loss=0.05425]
[2020-05-11 23:24:53.653]  Step 147565  [3.190 sec/step, loss=0.10162, avg_loss=0.09241, mel_loss=0.04728, linear_loss=0.05435]
[2020-05-11 23:24:55.396]  Step 147566  [3.191 sec/step, loss=0.09275, avg_loss=0.09245, mel_loss=0.04103, linear_loss=0.05172]
[2020-05-11 23:24:59.113]  Step 147567  [3.200 sec/step, loss=0.09903, avg_loss=0.09248, mel_loss=0.04482, linear_loss=0.05421]
[2020-05-11 23:25:03.679]  Step 147568  [3.228 sec/step, loss=0.09903, avg_loss=0.09255, mel_loss=0.04545, linear_loss=0.05358]
[2020-05-11 23:25:06.603]  Step 147569  [3.248 sec/step, loss=0.09692, avg_loss=0.09265, mel_loss=0.04359, linear_loss=0.05332]
[2020-05-11 23:25:09.955]  Step 147570  [3.263 sec/step, loss=0.09575, avg_loss=0.09269, mel_loss=0.04343, linear_loss=0.05232]
[2020-05-11 23:25:11.249]  Step 147571  [3.254 sec/step, loss=0.08880, avg_loss=0.09263, mel_loss=0.03912, linear_loss=0.04968]
[2020-05-11 23:25:13.902]  Step 147572  [3.261 sec/step, loss=0.09472, avg_loss=0.09265, mel_loss=0.04249, linear_loss=0.05223]
[2020-05-11 23:25:16.037]  Step 147573  [3.248 sec/step, loss=0.09433, avg_loss=0.09262, mel_loss=0.04238, linear_loss=0.05195]
[2020-05-11 23:25:16.719]  Step 147574  [3.193 sec/step, loss=0.07592, avg_loss=0.09238, mel_loss=0.03342, linear_loss=0.04249]
[2020-05-11 23:25:31.518]  Step 147575  [3.287 sec/step, loss=0.07854, avg_loss=0.09215, mel_loss=0.03756, linear_loss=0.04098]
[2020-05-11 23:25:35.123]  Step 147576  [3.301 sec/step, loss=0.09947, avg_loss=0.09222, mel_loss=0.04526, linear_loss=0.05421]
[2020-05-11 23:25:42.687]  Step 147577  [3.371 sec/step, loss=0.10109, avg_loss=0.09248, mel_loss=0.04733, linear_loss=0.05377]
[2020-05-11 23:25:43.671]  Step 147578  [3.357 sec/step, loss=0.08084, avg_loss=0.09237, mel_loss=0.03543, linear_loss=0.04541]
[2020-05-11 23:25:47.941]  Step 147579  [3.387 sec/step, loss=0.09721, avg_loss=0.09247, mel_loss=0.04441, linear_loss=0.05280]
[2020-05-11 23:25:49.528]  Step 147580  [3.385 sec/step, loss=0.09161, avg_loss=0.09249, mel_loss=0.04061, linear_loss=0.05100]
[2020-05-11 23:25:51.096]  Step 147581  [3.352 sec/step, loss=0.08893, avg_loss=0.09238, mel_loss=0.03948, linear_loss=0.04946]
[2020-05-11 23:25:53.745]  Step 147582  [3.367 sec/step, loss=0.09516, avg_loss=0.09251, mel_loss=0.04273, linear_loss=0.05243]
[2020-05-11 23:25:55.889]  Step 147583  [3.369 sec/step, loss=0.09338, avg_loss=0.09252, mel_loss=0.04200, linear_loss=0.05138]
[2020-05-11 23:25:57.854]  Step 147584  [3.352 sec/step, loss=0.09258, avg_loss=0.09247, mel_loss=0.04108, linear_loss=0.05150]
[2020-05-11 23:25:59.655]  Step 147585  [3.335 sec/step, loss=0.09245, avg_loss=0.09241, mel_loss=0.04096, linear_loss=0.05149]
[2020-05-11 23:26:08.637]  Step 147586  [3.396 sec/step, loss=0.10006, avg_loss=0.09245, mel_loss=0.04701, linear_loss=0.05305]
[2020-05-11 23:26:09.746]  Step 147587  [3.341 sec/step, loss=0.08380, avg_loss=0.09231, mel_loss=0.03663, linear_loss=0.04716]
[2020-05-11 23:26:10.899]  Step 147588  [3.342 sec/step, loss=0.08418, avg_loss=0.09235, mel_loss=0.03690, linear_loss=0.04727]
[2020-05-11 23:26:11.905]  Step 147589  [3.267 sec/step, loss=0.08234, avg_loss=0.09218, mel_loss=0.03634, linear_loss=0.04600]
[2020-05-11 23:26:13.596]  Generated 32 batches of size 32 in 1.685 sec
[2020-05-11 23:26:14.280]  Step 147590  [3.254 sec/step, loss=0.09607, avg_loss=0.09214, mel_loss=0.04309, linear_loss=0.05298]
[2020-05-11 23:26:19.528]  Step 147591  [3.261 sec/step, loss=0.09864, avg_loss=0.09214, mel_loss=0.04550, linear_loss=0.05313]
[2020-05-11 23:26:20.079]  Step 147592  [3.251 sec/step, loss=0.07197, avg_loss=0.09193, mel_loss=0.03240, linear_loss=0.03957]
[2020-05-11 23:26:21.828]  Step 147593  [3.254 sec/step, loss=0.09074, avg_loss=0.09196, mel_loss=0.04031, linear_loss=0.05043]
[2020-05-11 23:26:22.630]  Step 147594  [3.254 sec/step, loss=0.08014, avg_loss=0.09196, mel_loss=0.03504, linear_loss=0.04510]
[2020-05-11 23:26:23.943]  Step 147595  [3.259 sec/step, loss=0.09076, avg_loss=0.09208, mel_loss=0.04020, linear_loss=0.05056]
[2020-05-11 23:26:27.359]  Step 147596  [3.272 sec/step, loss=0.09599, avg_loss=0.09212, mel_loss=0.04359, linear_loss=0.05241]
[2020-05-11 23:26:33.816]  Step 147597  [3.303 sec/step, loss=0.09874, avg_loss=0.09214, mel_loss=0.04596, linear_loss=0.05278]
[2020-05-11 23:26:39.482]  Step 147598  [3.285 sec/step, loss=0.10075, avg_loss=0.09214, mel_loss=0.04667, linear_loss=0.05408]
[2020-05-11 23:26:40.684]  Step 147599  [3.256 sec/step, loss=0.08688, avg_loss=0.09202, mel_loss=0.03829, linear_loss=0.04859]
[2020-05-11 23:26:42.251]  Step 147600  [3.245 sec/step, loss=0.09175, avg_loss=0.09200, mel_loss=0.04070, linear_loss=0.05105]
[2020-05-11 23:26:42.251]  Writing summary at step: 147600
[2020-05-11 23:26:42.810]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147600
[2020-05-11 23:26:44.183]  Saving audio and alignment...
[2020-05-11 23:26:46.122]  Input: 자 이번에는~______________
[2020-05-11 23:26:48.310]  Step 147601  [3.253 sec/step, loss=0.09347, avg_loss=0.09203, mel_loss=0.04187, linear_loss=0.05160]
[2020-05-11 23:26:51.112]  Step 147602  [3.264 sec/step, loss=0.09676, avg_loss=0.09208, mel_loss=0.04388, linear_loss=0.05288]
[2020-05-11 23:26:52.786]  Step 147603  [3.252 sec/step, loss=0.09231, avg_loss=0.09204, mel_loss=0.04092, linear_loss=0.05139]
[2020-05-11 23:26:59.367]  Step 147604  [3.196 sec/step, loss=0.10040, avg_loss=0.09215, mel_loss=0.04665, linear_loss=0.05375]
[2020-05-11 23:27:08.128]  Step 147605  [3.142 sec/step, loss=0.09801, avg_loss=0.09238, mel_loss=0.04602, linear_loss=0.05199]
[2020-05-11 23:27:22.094]  Step 147606  [3.248 sec/step, loss=0.07789, avg_loss=0.09218, mel_loss=0.03743, linear_loss=0.04047]
[2020-05-11 23:27:26.173]  Step 147607  [3.259 sec/step, loss=0.09860, avg_loss=0.09218, mel_loss=0.04512, linear_loss=0.05348]
[2020-05-11 23:27:27.593]  Step 147608  [3.259 sec/step, loss=0.08934, avg_loss=0.09219, mel_loss=0.03978, linear_loss=0.04956]
[2020-05-11 23:27:28.577]  Step 147609  [3.249 sec/step, loss=0.08116, avg_loss=0.09205, mel_loss=0.03518, linear_loss=0.04599]
[2020-05-11 23:27:29.373]  Step 147610  [3.240 sec/step, loss=0.07768, avg_loss=0.09189, mel_loss=0.03390, linear_loss=0.04378]
[2020-05-11 23:27:33.728]  Step 147611  [3.228 sec/step, loss=0.09518, avg_loss=0.09184, mel_loss=0.04313, linear_loss=0.05206]
[2020-05-11 23:27:38.728]  Step 147612  [3.225 sec/step, loss=0.09944, avg_loss=0.09185, mel_loss=0.04522, linear_loss=0.05422]
[2020-05-11 23:27:43.371]  Step 147613  [3.257 sec/step, loss=0.09857, avg_loss=0.09197, mel_loss=0.04467, linear_loss=0.05390]
[2020-05-11 23:27:50.709]  Step 147614  [3.314 sec/step, loss=0.09854, avg_loss=0.09205, mel_loss=0.04560, linear_loss=0.05294]
[2020-05-11 23:27:51.572]  Step 147615  [3.313 sec/step, loss=0.07599, avg_loss=0.09197, mel_loss=0.03329, linear_loss=0.04270]
[2020-05-11 23:27:54.573]  Step 147616  [3.259 sec/step, loss=0.09688, avg_loss=0.09195, mel_loss=0.04384, linear_loss=0.05304]
[2020-05-11 23:27:56.467]  Step 147617  [3.270 sec/step, loss=0.09190, avg_loss=0.09207, mel_loss=0.04030, linear_loss=0.05159]
[2020-05-11 23:27:57.743]  Step 147618  [3.272 sec/step, loss=0.08855, avg_loss=0.09206, mel_loss=0.03888, linear_loss=0.04967]
[2020-05-11 23:28:02.723]  Step 147619  [3.301 sec/step, loss=0.09877, avg_loss=0.09213, mel_loss=0.04554, linear_loss=0.05323]
[2020-05-11 23:28:05.129]  Generated 32 batches of size 32 in 2.396 sec
[2020-05-11 23:28:05.287]  Step 147620  [3.293 sec/step, loss=0.09358, avg_loss=0.09210, mel_loss=0.04183, linear_loss=0.05175]
[2020-05-11 23:28:12.772]  Step 147621  [3.350 sec/step, loss=0.10074, avg_loss=0.09217, mel_loss=0.04711, linear_loss=0.05362]
[2020-05-11 23:28:17.280]  Step 147622  [3.321 sec/step, loss=0.09954, avg_loss=0.09216, mel_loss=0.04551, linear_loss=0.05404]
[2020-05-11 23:28:19.949]  Step 147623  [3.322 sec/step, loss=0.09432, avg_loss=0.09215, mel_loss=0.04249, linear_loss=0.05183]
[2020-05-11 23:28:20.995]  Step 147624  [3.320 sec/step, loss=0.08620, avg_loss=0.09213, mel_loss=0.03778, linear_loss=0.04842]
[2020-05-11 23:28:22.566]  Step 147625  [3.288 sec/step, loss=0.09209, avg_loss=0.09205, mel_loss=0.04106, linear_loss=0.05103]
[2020-05-11 23:28:24.538]  Step 147626  [3.267 sec/step, loss=0.09404, avg_loss=0.09201, mel_loss=0.04214, linear_loss=0.05191]
[2020-05-11 23:28:26.600]  Step 147627  [3.266 sec/step, loss=0.09418, avg_loss=0.09202, mel_loss=0.04216, linear_loss=0.05202]
[2020-05-11 23:28:30.570]  Step 147628  [3.281 sec/step, loss=0.09917, avg_loss=0.09205, mel_loss=0.04525, linear_loss=0.05392]
[2020-05-11 23:28:32.321]  Step 147629  [3.256 sec/step, loss=0.09078, avg_loss=0.09195, mel_loss=0.04008, linear_loss=0.05071]
[2020-05-11 23:28:38.624]  Step 147630  [3.310 sec/step, loss=0.09798, avg_loss=0.09209, mel_loss=0.04552, linear_loss=0.05246]
[2020-05-11 23:28:41.481]  Step 147631  [3.333 sec/step, loss=0.09535, avg_loss=0.09229, mel_loss=0.04263, linear_loss=0.05272]
[2020-05-11 23:28:42.608]  Step 147632  [3.315 sec/step, loss=0.08702, avg_loss=0.09220, mel_loss=0.03800, linear_loss=0.04902]
[2020-05-11 23:28:48.219]  Step 147633  [3.347 sec/step, loss=0.09965, avg_loss=0.09224, mel_loss=0.04596, linear_loss=0.05369]
[2020-05-11 23:28:49.187]  Step 147634  [3.320 sec/step, loss=0.08567, avg_loss=0.09210, mel_loss=0.03758, linear_loss=0.04809]
[2020-05-11 23:28:52.787]  Step 147635  [3.347 sec/step, loss=0.09827, avg_loss=0.09234, mel_loss=0.04474, linear_loss=0.05353]
[2020-05-11 23:28:55.963]  Step 147636  [3.313 sec/step, loss=0.09800, avg_loss=0.09232, mel_loss=0.04430, linear_loss=0.05370]
[2020-05-11 23:29:02.560]  Step 147637  [3.335 sec/step, loss=0.09861, avg_loss=0.09229, mel_loss=0.04501, linear_loss=0.05360]
[2020-05-11 23:29:19.019]  Step 147638  [3.459 sec/step, loss=0.08327, avg_loss=0.09213, mel_loss=0.03968, linear_loss=0.04359]
[2020-05-11 23:29:24.527]  Step 147639  [3.500 sec/step, loss=0.09741, avg_loss=0.09223, mel_loss=0.04475, linear_loss=0.05267]
[2020-05-11 23:29:27.021]  Step 147640  [3.513 sec/step, loss=0.09508, avg_loss=0.09228, mel_loss=0.04250, linear_loss=0.05258]
[2020-05-11 23:29:29.442]  Step 147641  [3.418 sec/step, loss=0.09253, avg_loss=0.09230, mel_loss=0.04159, linear_loss=0.05094]
[2020-05-11 23:29:30.774]  Step 147642  [3.422 sec/step, loss=0.08956, avg_loss=0.09244, mel_loss=0.03949, linear_loss=0.05007]
[2020-05-11 23:29:32.094]  Step 147643  [3.427 sec/step, loss=0.08683, avg_loss=0.09248, mel_loss=0.03842, linear_loss=0.04841]
[2020-05-11 23:29:32.821]  Step 147644  [3.405 sec/step, loss=0.07736, avg_loss=0.09226, mel_loss=0.03384, linear_loss=0.04352]
[2020-05-11 23:29:37.472]  Step 147645  [3.421 sec/step, loss=0.09988, avg_loss=0.09228, mel_loss=0.04594, linear_loss=0.05393]
[2020-05-11 23:29:39.635]  Step 147646  [3.435 sec/step, loss=0.09572, avg_loss=0.09246, mel_loss=0.04301, linear_loss=0.05271]
[2020-05-11 23:29:43.746]  Step 147647  [3.450 sec/step, loss=0.09934, avg_loss=0.09250, mel_loss=0.04508, linear_loss=0.05426]
[2020-05-11 23:29:46.388]  Step 147648  [3.453 sec/step, loss=0.09655, avg_loss=0.09252, mel_loss=0.04355, linear_loss=0.05300]
[2020-05-11 23:29:47.475]  Step 147649  [3.448 sec/step, loss=0.08639, avg_loss=0.09248, mel_loss=0.03803, linear_loss=0.04836]
[2020-05-11 23:29:50.921]  Step 147650  [3.434 sec/step, loss=0.09607, avg_loss=0.09245, mel_loss=0.04361, linear_loss=0.05246]
[2020-05-11 23:29:50.921]  Writing summary at step: 147650
[2020-05-11 23:29:52.419]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147650
[2020-05-11 23:29:53.838]  Saving audio and alignment...
[2020-05-11 23:29:56.721]  Input: 들어가 볼까요~___________________________
[2020-05-11 23:29:57.531]  Step 147651  [3.422 sec/step, loss=0.07934, avg_loss=0.09231, mel_loss=0.03482, linear_loss=0.04452]
[2020-05-11 23:29:59.432]  Step 147652  [3.362 sec/step, loss=0.09134, avg_loss=0.09227, mel_loss=0.04058, linear_loss=0.05076]
[2020-05-11 23:30:01.426]  Step 147653  [3.341 sec/step, loss=0.09317, avg_loss=0.09221, mel_loss=0.04149, linear_loss=0.05168]
[2020-05-11 23:30:10.097]  Step 147654  [3.395 sec/step, loss=0.09751, avg_loss=0.09219, mel_loss=0.04551, linear_loss=0.05200]
[2020-05-11 23:30:17.161]  Step 147655  [3.460 sec/step, loss=0.09985, avg_loss=0.09247, mel_loss=0.04633, linear_loss=0.05353]
[2020-05-11 23:30:20.280]  Step 147656  [3.432 sec/step, loss=0.09937, avg_loss=0.09249, mel_loss=0.04522, linear_loss=0.05415]
[2020-05-11 23:30:21.130]  Step 147657  [3.428 sec/step, loss=0.08417, avg_loss=0.09246, mel_loss=0.03649, linear_loss=0.04769]
[2020-05-11 23:30:21.718]  Step 147658  [3.422 sec/step, loss=0.07315, avg_loss=0.09232, mel_loss=0.03321, linear_loss=0.03994]
[2020-05-11 23:31:45.386]  Generated 32 batches of size 32 in 110.995 sec
[2020-05-11 23:31:47.172]  Step 147659  [4.267 sec/step, loss=0.09286, avg_loss=0.09242, mel_loss=0.04102, linear_loss=0.05184]
[2020-05-11 23:31:49.169]  Step 147660  [4.251 sec/step, loss=0.09044, avg_loss=0.09235, mel_loss=0.04049, linear_loss=0.04995]
[2020-05-11 23:31:50.415]  Step 147661  [4.247 sec/step, loss=0.08585, avg_loss=0.09230, mel_loss=0.03787, linear_loss=0.04798]
[2020-05-11 23:31:55.349]  Step 147662  [4.276 sec/step, loss=0.09900, avg_loss=0.09237, mel_loss=0.04533, linear_loss=0.05366]
[2020-05-11 23:31:58.442]  Step 147663  [4.274 sec/step, loss=0.09727, avg_loss=0.09237, mel_loss=0.04395, linear_loss=0.05333]
[2020-05-11 23:32:01.259]  Step 147664  [4.249 sec/step, loss=0.09601, avg_loss=0.09233, mel_loss=0.04342, linear_loss=0.05259]
[2020-05-11 23:32:04.812]  Step 147665  [4.215 sec/step, loss=0.09885, avg_loss=0.09230, mel_loss=0.04473, linear_loss=0.05413]
[2020-05-11 23:32:05.929]  Step 147666  [4.208 sec/step, loss=0.08437, avg_loss=0.09222, mel_loss=0.03690, linear_loss=0.04747]
[2020-05-11 23:32:10.470]  Step 147667  [4.217 sec/step, loss=0.09962, avg_loss=0.09222, mel_loss=0.04570, linear_loss=0.05391]
[2020-05-11 23:32:16.394]  Step 147668  [4.230 sec/step, loss=0.10013, avg_loss=0.09223, mel_loss=0.04645, linear_loss=0.05367]
[2020-05-11 23:32:21.850]  Step 147669  [4.255 sec/step, loss=0.10034, avg_loss=0.09227, mel_loss=0.04622, linear_loss=0.05413]
[2020-05-11 23:32:24.291]  Step 147670  [4.246 sec/step, loss=0.09341, avg_loss=0.09225, mel_loss=0.04172, linear_loss=0.05169]
[2020-05-11 23:32:25.623]  Step 147671  [4.247 sec/step, loss=0.08880, avg_loss=0.09225, mel_loss=0.03920, linear_loss=0.04960]
[2020-05-11 23:32:26.611]  Step 147672  [4.230 sec/step, loss=0.08466, avg_loss=0.09214, mel_loss=0.03666, linear_loss=0.04800]
[2020-05-11 23:32:30.003]  Step 147673  [4.243 sec/step, loss=0.09530, avg_loss=0.09215, mel_loss=0.04325, linear_loss=0.05206]
[2020-05-11 23:32:31.576]  Step 147674  [4.252 sec/step, loss=0.09074, avg_loss=0.09230, mel_loss=0.04044, linear_loss=0.05031]
[2020-05-11 23:32:35.831]  Step 147675  [4.146 sec/step, loss=0.09860, avg_loss=0.09250, mel_loss=0.04508, linear_loss=0.05353]
[2020-05-11 23:32:36.402]  Step 147676  [4.116 sec/step, loss=0.07567, avg_loss=0.09227, mel_loss=0.03383, linear_loss=0.04183]
[2020-05-11 23:32:37.208]  Step 147677  [4.048 sec/step, loss=0.08003, avg_loss=0.09205, mel_loss=0.03468, linear_loss=0.04534]
[2020-05-11 23:32:39.446]  Step 147678  [4.061 sec/step, loss=0.09305, avg_loss=0.09218, mel_loss=0.04195, linear_loss=0.05111]
[2020-05-11 23:32:40.876]  Step 147679  [4.032 sec/step, loss=0.08740, avg_loss=0.09208, mel_loss=0.03872, linear_loss=0.04868]
[2020-05-11 23:32:41.678]  Step 147680  [4.025 sec/step, loss=0.07605, avg_loss=0.09192, mel_loss=0.03304, linear_loss=0.04300]
[2020-05-11 23:32:43.378]  Step 147681  [4.026 sec/step, loss=0.09117, avg_loss=0.09195, mel_loss=0.04041, linear_loss=0.05076]
[2020-05-11 23:32:45.272]  Step 147682  [4.018 sec/step, loss=0.09153, avg_loss=0.09191, mel_loss=0.04054, linear_loss=0.05099]
[2020-05-11 23:32:47.752]  Step 147683  [4.022 sec/step, loss=0.09367, avg_loss=0.09191, mel_loss=0.04192, linear_loss=0.05175]
[2020-05-11 23:33:01.367]  Step 147684  [4.138 sec/step, loss=0.08232, avg_loss=0.09181, mel_loss=0.03911, linear_loss=0.04320]
[2020-05-11 23:33:08.703]  Step 147685  [4.194 sec/step, loss=0.10180, avg_loss=0.09190, mel_loss=0.04752, linear_loss=0.05428]
[2020-05-11 23:33:12.448]  Step 147686  [4.141 sec/step, loss=0.09941, avg_loss=0.09190, mel_loss=0.04521, linear_loss=0.05420]
[2020-05-11 23:33:15.153]  Step 147687  [4.157 sec/step, loss=0.09452, avg_loss=0.09200, mel_loss=0.04272, linear_loss=0.05180]
[2020-05-11 23:33:16.135]  Step 147688  [4.155 sec/step, loss=0.08534, avg_loss=0.09202, mel_loss=0.03726, linear_loss=0.04808]
[2020-05-11 23:33:24.057]  Step 147689  [4.225 sec/step, loss=0.09853, avg_loss=0.09218, mel_loss=0.04609, linear_loss=0.05244]
[2020-05-11 23:33:27.423]  Step 147690  [4.234 sec/step, loss=0.09883, avg_loss=0.09220, mel_loss=0.04497, linear_loss=0.05386]
[2020-05-11 23:33:49.855]  Generated 32 batches of size 32 in 66.472 sec
[2020-05-11 23:33:50.958]  Step 147691  [4.417 sec/step, loss=0.08755, avg_loss=0.09209, mel_loss=0.03869, linear_loss=0.04886]
[2020-05-11 23:33:53.385]  Step 147692  [4.436 sec/step, loss=0.09305, avg_loss=0.09230, mel_loss=0.04151, linear_loss=0.05153]
[2020-05-11 23:33:54.232]  Step 147693  [4.427 sec/step, loss=0.07930, avg_loss=0.09219, mel_loss=0.03427, linear_loss=0.04503]
[2020-05-11 23:33:57.589]  Step 147694  [4.453 sec/step, loss=0.09696, avg_loss=0.09236, mel_loss=0.04403, linear_loss=0.05293]
[2020-05-11 23:33:59.740]  Step 147695  [4.461 sec/step, loss=0.09479, avg_loss=0.09240, mel_loss=0.04226, linear_loss=0.05253]
[2020-05-11 23:34:04.257]  Step 147696  [4.472 sec/step, loss=0.10009, avg_loss=0.09244, mel_loss=0.04583, linear_loss=0.05427]
[2020-05-11 23:34:07.681]  Step 147697  [4.442 sec/step, loss=0.10151, avg_loss=0.09247, mel_loss=0.04657, linear_loss=0.05494]
[2020-05-11 23:34:09.625]  Step 147698  [4.404 sec/step, loss=0.09317, avg_loss=0.09239, mel_loss=0.04157, linear_loss=0.05160]
[2020-05-11 23:34:13.863]  Step 147699  [4.435 sec/step, loss=0.09882, avg_loss=0.09251, mel_loss=0.04513, linear_loss=0.05368]
[2020-05-11 23:34:28.256]  Step 147700  [4.563 sec/step, loss=0.08283, avg_loss=0.09242, mel_loss=0.03992, linear_loss=0.04290]
[2020-05-11 23:34:28.256]  Writing summary at step: 147700
[2020-05-11 23:34:29.611]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147700
[2020-05-11 23:34:31.076]  Saving audio and alignment...
[2020-05-11 23:34:41.523]  Input: 활기차게 읽어야 되는데 이 부분을 잘 처리를 못 하겠어요 하신다면 이번에는 고개를 꽁 찍어 보세요 활기찬 하루가~___________________
[2020-05-11 23:34:44.723]  Step 147701  [4.573 sec/step, loss=0.09802, avg_loss=0.09247, mel_loss=0.04422, linear_loss=0.05380]
[2020-05-11 23:34:48.443]  Step 147702  [4.582 sec/step, loss=0.10051, avg_loss=0.09250, mel_loss=0.04548, linear_loss=0.05504]
[2020-05-11 23:34:51.313]  Step 147703  [4.594 sec/step, loss=0.09484, avg_loss=0.09253, mel_loss=0.04280, linear_loss=0.05205]
[2020-05-11 23:34:54.289]  Step 147704  [4.558 sec/step, loss=0.09903, avg_loss=0.09252, mel_loss=0.04486, linear_loss=0.05418]
[2020-05-11 23:34:55.255]  Step 147705  [4.480 sec/step, loss=0.08260, avg_loss=0.09236, mel_loss=0.03603, linear_loss=0.04657]
[2020-05-11 23:34:56.648]  Step 147706  [4.355 sec/step, loss=0.08697, avg_loss=0.09245, mel_loss=0.03835, linear_loss=0.04862]
[2020-05-11 23:34:57.391]  Step 147707  [4.321 sec/step, loss=0.07500, avg_loss=0.09222, mel_loss=0.03361, linear_loss=0.04140]
[2020-05-11 23:34:59.651]  Step 147708  [4.330 sec/step, loss=0.09468, avg_loss=0.09227, mel_loss=0.04243, linear_loss=0.05225]
[2020-05-11 23:35:00.400]  Step 147709  [4.327 sec/step, loss=0.07921, avg_loss=0.09225, mel_loss=0.03468, linear_loss=0.04453]
[2020-05-11 23:35:05.563]  Step 147710  [4.371 sec/step, loss=0.09894, avg_loss=0.09246, mel_loss=0.04572, linear_loss=0.05322]
[2020-05-11 23:35:07.339]  Step 147711  [4.345 sec/step, loss=0.09082, avg_loss=0.09242, mel_loss=0.04009, linear_loss=0.05073]
[2020-05-11 23:35:14.053]  Step 147712  [4.362 sec/step, loss=0.10019, avg_loss=0.09243, mel_loss=0.04651, linear_loss=0.05368]
[2020-05-11 23:35:15.198]  Step 147713  [4.327 sec/step, loss=0.08555, avg_loss=0.09230, mel_loss=0.03770, linear_loss=0.04786]
[2020-05-11 23:35:20.821]  Step 147714  [4.310 sec/step, loss=0.09931, avg_loss=0.09231, mel_loss=0.04559, linear_loss=0.05372]
[2020-05-11 23:35:22.110]  Step 147715  [4.314 sec/step, loss=0.08764, avg_loss=0.09242, mel_loss=0.03862, linear_loss=0.04902]
[2020-05-11 23:35:22.761]  Generated 32 batches of size 32 in 15.415 sec
[2020-05-11 23:35:23.768]  Step 147716  [4.301 sec/step, loss=0.09195, avg_loss=0.09237, mel_loss=0.04086, linear_loss=0.05109]
[2020-05-11 23:35:26.350]  Step 147717  [4.308 sec/step, loss=0.09577, avg_loss=0.09241, mel_loss=0.04292, linear_loss=0.05286]
[2020-05-11 23:35:28.425]  Step 147718  [4.316 sec/step, loss=0.09401, avg_loss=0.09247, mel_loss=0.04194, linear_loss=0.05208]
[2020-05-11 23:35:30.131]  Step 147719  [4.283 sec/step, loss=0.09260, avg_loss=0.09240, mel_loss=0.04084, linear_loss=0.05176]
[2020-05-11 23:35:39.301]  Step 147720  [4.349 sec/step, loss=0.10037, avg_loss=0.09247, mel_loss=0.04726, linear_loss=0.05311]
[2020-05-11 23:35:40.099]  Step 147721  [4.282 sec/step, loss=0.07929, avg_loss=0.09226, mel_loss=0.03470, linear_loss=0.04459]
[2020-05-11 23:35:42.097]  Step 147722  [4.257 sec/step, loss=0.09256, avg_loss=0.09219, mel_loss=0.04102, linear_loss=0.05154]
[2020-05-11 23:35:45.425]  Step 147723  [4.264 sec/step, loss=0.09763, avg_loss=0.09222, mel_loss=0.04427, linear_loss=0.05336]
[2020-05-11 23:35:49.742]  Step 147724  [4.297 sec/step, loss=0.09772, avg_loss=0.09234, mel_loss=0.04444, linear_loss=0.05328]
[2020-05-11 23:35:55.395]  Step 147725  [4.337 sec/step, loss=0.09991, avg_loss=0.09241, mel_loss=0.04615, linear_loss=0.05376]
[2020-05-11 23:35:59.058]  Step 147726  [4.354 sec/step, loss=0.09912, avg_loss=0.09246, mel_loss=0.04510, linear_loss=0.05403]
[2020-05-11 23:36:00.568]  Step 147727  [4.349 sec/step, loss=0.09043, avg_loss=0.09243, mel_loss=0.04001, linear_loss=0.05043]
[2020-05-11 23:36:07.920]  Step 147728  [4.383 sec/step, loss=0.10075, avg_loss=0.09244, mel_loss=0.04699, linear_loss=0.05376]
[2020-05-11 23:36:11.277]  Step 147729  [4.399 sec/step, loss=0.09759, avg_loss=0.09251, mel_loss=0.04424, linear_loss=0.05334]
[2020-05-11 23:36:12.178]  Step 147730  [4.345 sec/step, loss=0.08001, avg_loss=0.09233, mel_loss=0.03507, linear_loss=0.04494]
[2020-05-11 23:36:15.642]  Step 147731  [4.351 sec/step, loss=0.09665, avg_loss=0.09234, mel_loss=0.04385, linear_loss=0.05279]
[2020-05-11 23:36:17.234]  Step 147732  [4.355 sec/step, loss=0.09323, avg_loss=0.09241, mel_loss=0.04144, linear_loss=0.05179]
[2020-05-11 23:36:18.981]  Step 147733  [4.317 sec/step, loss=0.09084, avg_loss=0.09232, mel_loss=0.04034, linear_loss=0.05049]
[2020-05-11 23:36:23.072]  Step 147734  [4.348 sec/step, loss=0.09989, avg_loss=0.09246, mel_loss=0.04594, linear_loss=0.05395]
[2020-05-11 23:36:29.797]  Step 147735  [4.379 sec/step, loss=0.09770, avg_loss=0.09245, mel_loss=0.04539, linear_loss=0.05231]
[2020-05-11 23:36:30.970]  Step 147736  [4.359 sec/step, loss=0.08544, avg_loss=0.09233, mel_loss=0.03746, linear_loss=0.04798]
[2020-05-11 23:36:43.067]  Step 147737  [4.414 sec/step, loss=0.08678, avg_loss=0.09221, mel_loss=0.04146, linear_loss=0.04532]
[2020-05-11 23:36:44.366]  Step 147738  [4.263 sec/step, loss=0.08753, avg_loss=0.09225, mel_loss=0.03849, linear_loss=0.04904]
[2020-05-11 23:36:45.200]  Step 147739  [4.216 sec/step, loss=0.07891, avg_loss=0.09207, mel_loss=0.03461, linear_loss=0.04430]
[2020-05-11 23:36:46.268]  Step 147740  [4.202 sec/step, loss=0.08411, avg_loss=0.09196, mel_loss=0.03673, linear_loss=0.04738]
[2020-05-11 23:36:48.551]  Step 147741  [4.200 sec/step, loss=0.09276, avg_loss=0.09196, mel_loss=0.04164, linear_loss=0.05112]
[2020-05-11 23:36:50.569]  Step 147742  [4.207 sec/step, loss=0.09165, avg_loss=0.09198, mel_loss=0.04091, linear_loss=0.05074]
[2020-05-11 23:36:51.945]  Step 147743  [4.208 sec/step, loss=0.08753, avg_loss=0.09199, mel_loss=0.03880, linear_loss=0.04873]
[2020-05-11 23:36:52.921]  Step 147744  [4.210 sec/step, loss=0.08756, avg_loss=0.09209, mel_loss=0.03844, linear_loss=0.04912]
[2020-05-11 23:36:58.231]  Step 147745  [4.217 sec/step, loss=0.09909, avg_loss=0.09208, mel_loss=0.04566, linear_loss=0.05344]
[2020-05-11 23:36:58.471]  Generated 32 batches of size 32 in 6.520 sec
[2020-05-11 23:36:58.799]  Step 147746  [4.201 sec/step, loss=0.07361, avg_loss=0.09186, mel_loss=0.03327, linear_loss=0.04035]
[2020-05-11 23:37:00.866]  Step 147747  [4.180 sec/step, loss=0.09354, avg_loss=0.09180, mel_loss=0.04183, linear_loss=0.05171]
[2020-05-11 23:37:03.457]  Step 147748  [4.180 sec/step, loss=0.09541, avg_loss=0.09179, mel_loss=0.04316, linear_loss=0.05225]
[2020-05-11 23:37:05.952]  Step 147749  [4.194 sec/step, loss=0.09589, avg_loss=0.09189, mel_loss=0.04279, linear_loss=0.05310]
[2020-05-11 23:37:10.458]  Step 147750  [4.204 sec/step, loss=0.09971, avg_loss=0.09192, mel_loss=0.04574, linear_loss=0.05397]
[2020-05-11 23:37:10.458]  Writing summary at step: 147750
[2020-05-11 23:37:13.413]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147750
[2020-05-11 23:37:14.801]  Saving audio and alignment...
[2020-05-11 23:37:26.392]  Input: 언제나 우리 마음에 남아있는거 같아요 천구백 육십이년 아카데미 시상식에서 무려 열개 부문을 수상한 부분이 아니에요 여러분~_____________
[2020-05-11 23:37:28.737]  Step 147751  [4.220 sec/step, loss=0.09425, avg_loss=0.09207, mel_loss=0.04238, linear_loss=0.05187]
[2020-05-11 23:37:29.303]  Step 147752  [4.206 sec/step, loss=0.08209, avg_loss=0.09198, mel_loss=0.03619, linear_loss=0.04591]
[2020-05-11 23:37:31.298]  Step 147753  [4.206 sec/step, loss=0.09301, avg_loss=0.09198, mel_loss=0.04124, linear_loss=0.05177]
[2020-05-11 23:37:33.964]  Step 147754  [4.146 sec/step, loss=0.09572, avg_loss=0.09196, mel_loss=0.04319, linear_loss=0.05253]
[2020-05-11 23:37:38.543]  Step 147755  [4.122 sec/step, loss=0.09804, avg_loss=0.09194, mel_loss=0.04451, linear_loss=0.05353]
[2020-05-11 23:37:42.561]  Step 147756  [4.131 sec/step, loss=0.09759, avg_loss=0.09193, mel_loss=0.04441, linear_loss=0.05318]
[2020-05-11 23:37:51.114]  Step 147757  [4.208 sec/step, loss=0.09887, avg_loss=0.09207, mel_loss=0.04646, linear_loss=0.05241]
[2020-05-11 23:37:52.212]  Step 147758  [4.213 sec/step, loss=0.08521, avg_loss=0.09219, mel_loss=0.03702, linear_loss=0.04820]
[2020-05-11 23:37:53.539]  Step 147759  [3.371 sec/step, loss=0.08967, avg_loss=0.09216, mel_loss=0.03953, linear_loss=0.05014]
[2020-05-11 23:37:54.388]  Step 147760  [3.360 sec/step, loss=0.08249, avg_loss=0.09208, mel_loss=0.03580, linear_loss=0.04669]
[2020-05-11 23:37:56.512]  Step 147761  [3.369 sec/step, loss=0.09271, avg_loss=0.09215, mel_loss=0.04147, linear_loss=0.05124]
[2020-05-11 23:37:59.715]  Step 147762  [3.351 sec/step, loss=0.09722, avg_loss=0.09213, mel_loss=0.04412, linear_loss=0.05310]
[2020-05-11 23:38:02.121]  Step 147763  [3.345 sec/step, loss=0.09362, avg_loss=0.09210, mel_loss=0.04180, linear_loss=0.05182]
[2020-05-11 23:38:09.314]  Step 147764  [3.388 sec/step, loss=0.10181, avg_loss=0.09215, mel_loss=0.04742, linear_loss=0.05439]
[2020-05-11 23:38:14.184]  Step 147765  [3.401 sec/step, loss=0.10097, avg_loss=0.09217, mel_loss=0.04652, linear_loss=0.05445]
[2020-05-11 23:38:16.037]  Step 147766  [3.409 sec/step, loss=0.09135, avg_loss=0.09224, mel_loss=0.04027, linear_loss=0.05109]
[2020-05-11 23:38:16.605]  Step 147767  [3.369 sec/step, loss=0.07375, avg_loss=0.09199, mel_loss=0.03279, linear_loss=0.04097]
[2020-05-11 23:38:19.677]  Step 147768  [3.341 sec/step, loss=0.09575, avg_loss=0.09194, mel_loss=0.04351, linear_loss=0.05224]
[2020-05-11 23:38:25.096]  Step 147769  [3.340 sec/step, loss=0.10004, avg_loss=0.09194, mel_loss=0.04611, linear_loss=0.05393]
[2020-05-11 23:38:30.944]  Step 147770  [3.374 sec/step, loss=0.09954, avg_loss=0.09200, mel_loss=0.04608, linear_loss=0.05346]
[2020-05-11 23:38:31.786]  Step 147771  [3.369 sec/step, loss=0.07824, avg_loss=0.09189, mel_loss=0.03439, linear_loss=0.04385]
[2020-05-11 23:38:33.084]  Step 147772  [3.372 sec/step, loss=0.08606, avg_loss=0.09191, mel_loss=0.03796, linear_loss=0.04810]
[2020-05-11 23:38:34.816]  Step 147773  [3.356 sec/step, loss=0.09378, avg_loss=0.09189, mel_loss=0.04157, linear_loss=0.05221]
[2020-05-11 23:38:36.476]  Step 147774  [3.357 sec/step, loss=0.08989, avg_loss=0.09189, mel_loss=0.03989, linear_loss=0.05000]
[2020-05-11 23:38:36.570]  Generated 32 batches of size 32 in 1.744 sec
[2020-05-11 23:38:40.762]  Step 147775  [3.357 sec/step, loss=0.09841, avg_loss=0.09188, mel_loss=0.04482, linear_loss=0.05359]
[2020-05-11 23:38:44.371]  Step 147776  [3.387 sec/step, loss=0.09858, avg_loss=0.09211, mel_loss=0.04485, linear_loss=0.05372]
[2020-05-11 23:38:47.175]  Step 147777  [3.407 sec/step, loss=0.09880, avg_loss=0.09230, mel_loss=0.04470, linear_loss=0.05409]
[2020-05-11 23:38:50.598]  Step 147778  [3.419 sec/step, loss=0.09439, avg_loss=0.09231, mel_loss=0.04260, linear_loss=0.05179]
[2020-05-11 23:38:51.644]  Step 147779  [3.415 sec/step, loss=0.08498, avg_loss=0.09229, mel_loss=0.03733, linear_loss=0.04766]
[2020-05-11 23:39:05.564]  Step 147780  [3.547 sec/step, loss=0.07751, avg_loss=0.09230, mel_loss=0.03719, linear_loss=0.04031]
[2020-05-11 23:39:07.220]  Step 147781  [3.546 sec/step, loss=0.09292, avg_loss=0.09232, mel_loss=0.04166, linear_loss=0.05126]
[2020-05-11 23:39:08.244]  Step 147782  [3.537 sec/step, loss=0.08354, avg_loss=0.09224, mel_loss=0.03666, linear_loss=0.04689]
[2020-05-11 23:39:10.699]  Step 147783  [3.537 sec/step, loss=0.09263, avg_loss=0.09223, mel_loss=0.04110, linear_loss=0.05153]
[2020-05-11 23:39:15.543]  Step 147784  [3.450 sec/step, loss=0.09670, avg_loss=0.09237, mel_loss=0.04410, linear_loss=0.05260]
[2020-05-11 23:39:18.726]  Step 147785  [3.408 sec/step, loss=0.09281, avg_loss=0.09229, mel_loss=0.04159, linear_loss=0.05123]
[2020-05-11 23:39:19.614]  Step 147786  [3.379 sec/step, loss=0.06998, avg_loss=0.09199, mel_loss=0.03111, linear_loss=0.03887]
[2020-05-11 23:39:22.521]  Step 147787  [3.381 sec/step, loss=0.09108, avg_loss=0.09196, mel_loss=0.04042, linear_loss=0.05066]
[2020-05-11 23:39:29.409]  Step 147788  [3.440 sec/step, loss=0.09852, avg_loss=0.09209, mel_loss=0.04528, linear_loss=0.05324]
[2020-05-11 23:39:30.567]  Step 147789  [3.373 sec/step, loss=0.08707, avg_loss=0.09197, mel_loss=0.03846, linear_loss=0.04861]
[2020-05-11 23:39:31.663]  Step 147790  [3.350 sec/step, loss=0.08615, avg_loss=0.09185, mel_loss=0.03762, linear_loss=0.04853]
[2020-05-11 23:39:37.601]  Step 147791  [3.174 sec/step, loss=0.10058, avg_loss=0.09198, mel_loss=0.04647, linear_loss=0.05410]
[2020-05-11 23:39:38.981]  Step 147792  [3.164 sec/step, loss=0.08913, avg_loss=0.09194, mel_loss=0.03954, linear_loss=0.04959]
[2020-05-11 23:39:39.758]  Step 147793  [3.163 sec/step, loss=0.07675, avg_loss=0.09191, mel_loss=0.03343, linear_loss=0.04332]
[2020-05-11 23:39:42.705]  Step 147794  [3.159 sec/step, loss=0.09709, avg_loss=0.09191, mel_loss=0.04370, linear_loss=0.05339]
[2020-05-11 23:39:50.322]  Step 147795  [3.214 sec/step, loss=0.10140, avg_loss=0.09198, mel_loss=0.04729, linear_loss=0.05411]
[2020-05-11 23:39:51.327]  Step 147796  [3.178 sec/step, loss=0.08187, avg_loss=0.09180, mel_loss=0.03601, linear_loss=0.04586]
[2020-05-11 23:39:52.666]  Step 147797  [3.158 sec/step, loss=0.08664, avg_loss=0.09165, mel_loss=0.03838, linear_loss=0.04826]
[2020-05-11 23:39:54.402]  Step 147798  [3.156 sec/step, loss=0.09067, avg_loss=0.09162, mel_loss=0.03988, linear_loss=0.05079]
[2020-05-11 23:39:55.927]  Step 147799  [3.128 sec/step, loss=0.08930, avg_loss=0.09153, mel_loss=0.03960, linear_loss=0.04970]
[2020-05-11 23:40:09.049]  Step 147800  [3.116 sec/step, loss=0.08372, avg_loss=0.09154, mel_loss=0.04000, linear_loss=0.04371]
[2020-05-11 23:40:09.049]  Writing summary at step: 147800
[2020-05-11 23:40:15.407]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147800
[2020-05-11 23:40:16.766]  Saving audio and alignment...
[2020-05-11 23:40:18.278]  Input: 가장~_____________________________
[2020-05-11 23:40:19.158]  Step 147801  [3.092 sec/step, loss=0.07966, avg_loss=0.09135, mel_loss=0.03475, linear_loss=0.04491]
[2020-05-11 23:40:21.830]  Step 147802  [3.082 sec/step, loss=0.09447, avg_loss=0.09129, mel_loss=0.04248, linear_loss=0.05199]
[2020-05-11 23:40:23.958]  Step 147803  [3.075 sec/step, loss=0.09222, avg_loss=0.09127, mel_loss=0.04133, linear_loss=0.05089]
[2020-05-11 23:40:25.673]  Generated 32 batches of size 32 in 1.711 sec
[2020-05-11 23:40:27.214]  Step 147804  [3.077 sec/step, loss=0.09813, avg_loss=0.09126, mel_loss=0.04436, linear_loss=0.05376]
[2020-05-11 23:40:30.798]  Step 147805  [3.104 sec/step, loss=0.09851, avg_loss=0.09142, mel_loss=0.04461, linear_loss=0.05389]
[2020-05-11 23:40:32.382]  Step 147806  [3.105 sec/step, loss=0.09257, avg_loss=0.09147, mel_loss=0.04101, linear_loss=0.05156]
[2020-05-11 23:40:35.287]  Step 147807  [3.127 sec/step, loss=0.09484, avg_loss=0.09167, mel_loss=0.04280, linear_loss=0.05205]
[2020-05-11 23:40:39.122]  Step 147808  [3.143 sec/step, loss=0.09903, avg_loss=0.09172, mel_loss=0.04514, linear_loss=0.05389]
[2020-05-11 23:40:43.254]  Step 147809  [3.177 sec/step, loss=0.09983, avg_loss=0.09192, mel_loss=0.04578, linear_loss=0.05406]
[2020-05-11 23:40:51.617]  Step 147810  [3.209 sec/step, loss=0.09936, avg_loss=0.09193, mel_loss=0.04663, linear_loss=0.05274]
[2020-05-11 23:40:53.891]  Step 147811  [3.214 sec/step, loss=0.09380, avg_loss=0.09196, mel_loss=0.04223, linear_loss=0.05158]
[2020-05-11 23:40:58.664]  Step 147812  [3.194 sec/step, loss=0.09999, avg_loss=0.09195, mel_loss=0.04562, linear_loss=0.05437]
[2020-05-11 23:41:06.333]  Step 147813  [3.259 sec/step, loss=0.09928, avg_loss=0.09209, mel_loss=0.04624, linear_loss=0.05304]
[2020-05-11 23:41:07.427]  Step 147814  [3.214 sec/step, loss=0.08573, avg_loss=0.09196, mel_loss=0.03718, linear_loss=0.04854]
[2020-05-11 23:41:09.345]  Step 147815  [3.220 sec/step, loss=0.09273, avg_loss=0.09201, mel_loss=0.04149, linear_loss=0.05124]
[2020-05-11 23:41:12.155]  Step 147816  [3.232 sec/step, loss=0.09356, avg_loss=0.09202, mel_loss=0.04216, linear_loss=0.05140]
[2020-05-11 23:41:12.972]  Step 147817  [3.214 sec/step, loss=0.07701, avg_loss=0.09183, mel_loss=0.03399, linear_loss=0.04302]
[2020-05-11 23:41:14.360]  Step 147818  [3.207 sec/step, loss=0.09015, avg_loss=0.09180, mel_loss=0.03999, linear_loss=0.05017]
[2020-05-11 23:41:17.985]  Step 147819  [3.227 sec/step, loss=0.09941, avg_loss=0.09186, mel_loss=0.04525, linear_loss=0.05416]
[2020-05-11 23:41:19.675]  Step 147820  [3.152 sec/step, loss=0.09014, avg_loss=0.09176, mel_loss=0.04020, linear_loss=0.04995]
[2020-05-11 23:41:25.831]  Step 147821  [3.205 sec/step, loss=0.09882, avg_loss=0.09196, mel_loss=0.04584, linear_loss=0.05298]
[2020-05-11 23:41:28.806]  Step 147822  [3.215 sec/step, loss=0.09778, avg_loss=0.09201, mel_loss=0.04434, linear_loss=0.05344]
[2020-05-11 23:41:33.469]  Step 147823  [3.229 sec/step, loss=0.09871, avg_loss=0.09202, mel_loss=0.04521, linear_loss=0.05349]
[2020-05-11 23:41:35.250]  Step 147824  [3.203 sec/step, loss=0.09121, avg_loss=0.09195, mel_loss=0.04030, linear_loss=0.05091]
[2020-05-11 23:41:39.359]  Step 147825  [3.188 sec/step, loss=0.09777, avg_loss=0.09193, mel_loss=0.04442, linear_loss=0.05334]
[2020-05-11 23:41:41.431]  Step 147826  [3.172 sec/step, loss=0.09586, avg_loss=0.09190, mel_loss=0.04279, linear_loss=0.05307]
[2020-05-11 23:41:45.555]  Step 147827  [3.198 sec/step, loss=0.09913, avg_loss=0.09199, mel_loss=0.04544, linear_loss=0.05370]
[2020-05-11 23:41:47.126]  Step 147828  [3.140 sec/step, loss=0.09100, avg_loss=0.09189, mel_loss=0.04027, linear_loss=0.05073]
[2020-05-11 23:41:49.484]  Step 147829  [3.130 sec/step, loss=0.09395, avg_loss=0.09185, mel_loss=0.04215, linear_loss=0.05180]
[2020-05-11 23:41:50.486]  Step 147830  [3.131 sec/step, loss=0.08257, avg_loss=0.09188, mel_loss=0.03582, linear_loss=0.04675]
[2020-05-11 23:41:56.026]  Step 147831  [3.152 sec/step, loss=0.09987, avg_loss=0.09191, mel_loss=0.04621, linear_loss=0.05366]
[2020-05-11 23:41:59.299]  Step 147832  [3.169 sec/step, loss=0.09959, avg_loss=0.09198, mel_loss=0.04523, linear_loss=0.05436]
[2020-05-11 23:42:02.737]  Step 147833  [3.186 sec/step, loss=0.09659, avg_loss=0.09203, mel_loss=0.04359, linear_loss=0.05301]
[2020-05-11 23:42:15.706]  Step 147834  [3.274 sec/step, loss=0.08394, avg_loss=0.09187, mel_loss=0.04004, linear_loss=0.04390]
[2020-05-11 23:42:16.989]  Step 147835  [3.220 sec/step, loss=0.08963, avg_loss=0.09179, mel_loss=0.03932, linear_loss=0.05031]
[2020-05-11 23:42:18.676]  Generated 32 batches of size 32 in 1.683 sec
[2020-05-11 23:42:20.421]  Step 147836  [3.243 sec/step, loss=0.09790, avg_loss=0.09192, mel_loss=0.04470, linear_loss=0.05320]
[2020-05-11 23:42:21.604]  Step 147837  [3.133 sec/step, loss=0.08650, avg_loss=0.09191, mel_loss=0.03813, linear_loss=0.04836]
[2020-05-11 23:42:30.279]  Step 147838  [3.207 sec/step, loss=0.09903, avg_loss=0.09203, mel_loss=0.04649, linear_loss=0.05254]
[2020-05-11 23:42:31.171]  Step 147839  [3.208 sec/step, loss=0.08033, avg_loss=0.09204, mel_loss=0.03494, linear_loss=0.04539]
[2020-05-11 23:42:33.200]  Step 147840  [3.217 sec/step, loss=0.09293, avg_loss=0.09213, mel_loss=0.04135, linear_loss=0.05158]
[2020-05-11 23:42:33.765]  Step 147841  [3.200 sec/step, loss=0.07225, avg_loss=0.09193, mel_loss=0.03159, linear_loss=0.04066]
[2020-05-11 23:42:34.580]  Step 147842  [3.188 sec/step, loss=0.07692, avg_loss=0.09178, mel_loss=0.03362, linear_loss=0.04330]
[2020-05-11 23:42:39.964]  Step 147843  [3.228 sec/step, loss=0.09792, avg_loss=0.09188, mel_loss=0.04494, linear_loss=0.05298]
[2020-05-11 23:42:42.508]  Step 147844  [3.244 sec/step, loss=0.09389, avg_loss=0.09195, mel_loss=0.04201, linear_loss=0.05188]
[2020-05-11 23:42:48.120]  Step 147845  [3.247 sec/step, loss=0.09879, avg_loss=0.09194, mel_loss=0.04563, linear_loss=0.05316]
[2020-05-11 23:42:51.006]  Step 147846  [3.270 sec/step, loss=0.09447, avg_loss=0.09215, mel_loss=0.04251, linear_loss=0.05195]
[2020-05-11 23:42:55.914]  Step 147847  [3.299 sec/step, loss=0.09924, avg_loss=0.09221, mel_loss=0.04526, linear_loss=0.05397]
[2020-05-11 23:42:57.052]  Step 147848  [3.284 sec/step, loss=0.08415, avg_loss=0.09210, mel_loss=0.03687, linear_loss=0.04729]
[2020-05-11 23:42:58.992]  Step 147849  [3.279 sec/step, loss=0.08999, avg_loss=0.09204, mel_loss=0.03968, linear_loss=0.05031]
[2020-05-11 23:43:00.303]  Step 147850  [3.247 sec/step, loss=0.08857, avg_loss=0.09193, mel_loss=0.03943, linear_loss=0.04914]
[2020-05-11 23:43:00.303]  Writing summary at step: 147850
[2020-05-11 23:43:01.316]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147850
[2020-05-11 23:43:02.721]  Saving audio and alignment...
[2020-05-11 23:43:05.526]  Input: 보이스퀸 강사인 아나운서~_______
[2020-05-11 23:43:09.082]  Step 147851  [3.259 sec/step, loss=0.10068, avg_loss=0.09199, mel_loss=0.04571, linear_loss=0.05497]
[2020-05-11 23:43:11.831]  Step 147852  [3.280 sec/step, loss=0.09457, avg_loss=0.09212, mel_loss=0.04267, linear_loss=0.05190]
[2020-05-11 23:43:13.224]  Step 147853  [3.274 sec/step, loss=0.08751, avg_loss=0.09206, mel_loss=0.03892, linear_loss=0.04860]
[2020-05-11 23:43:21.986]  Step 147854  [3.335 sec/step, loss=0.09736, avg_loss=0.09208, mel_loss=0.04563, linear_loss=0.05172]
[2020-05-11 23:43:36.833]  Step 147855  [3.438 sec/step, loss=0.07732, avg_loss=0.09187, mel_loss=0.03722, linear_loss=0.04010]
[2020-05-11 23:43:40.840]  Step 147856  [3.438 sec/step, loss=0.09765, avg_loss=0.09187, mel_loss=0.04428, linear_loss=0.05337]
[2020-05-11 23:43:42.624]  Step 147857  [3.370 sec/step, loss=0.09037, avg_loss=0.09179, mel_loss=0.04003, linear_loss=0.05034]
[2020-05-11 23:43:49.272]  Step 147858  [3.426 sec/step, loss=0.09991, avg_loss=0.09193, mel_loss=0.04630, linear_loss=0.05361]
[2020-05-11 23:43:50.034]  Step 147859  [3.420 sec/step, loss=0.07959, avg_loss=0.09183, mel_loss=0.03454, linear_loss=0.04505]
[2020-05-11 23:43:50.853]  Step 147860  [3.420 sec/step, loss=0.07904, avg_loss=0.09180, mel_loss=0.03417, linear_loss=0.04487]
[2020-05-11 23:43:53.043]  Step 147861  [3.421 sec/step, loss=0.09222, avg_loss=0.09179, mel_loss=0.04164, linear_loss=0.05058]
[2020-05-11 23:43:55.488]  Step 147862  [3.413 sec/step, loss=0.09444, avg_loss=0.09176, mel_loss=0.04232, linear_loss=0.05212]
[2020-05-11 23:43:58.829]  Step 147863  [3.422 sec/step, loss=0.09715, avg_loss=0.09180, mel_loss=0.04406, linear_loss=0.05309]
[2020-05-11 23:43:59.394]  Step 147864  [3.356 sec/step, loss=0.07340, avg_loss=0.09152, mel_loss=0.03350, linear_loss=0.03990]
[2020-05-11 23:44:03.871]  Step 147865  [3.352 sec/step, loss=0.10028, avg_loss=0.09151, mel_loss=0.04606, linear_loss=0.05422]
[2020-05-11 23:44:05.568]  Generated 32 batches of size 32 in 1.692 sec
[2020-05-11 23:44:07.078]  Step 147866  [3.366 sec/step, loss=0.09704, avg_loss=0.09157, mel_loss=0.04353, linear_loss=0.05352]
[2020-05-11 23:44:08.146]  Step 147867  [3.371 sec/step, loss=0.08888, avg_loss=0.09172, mel_loss=0.03906, linear_loss=0.04981]
[2020-05-11 23:44:10.454]  Step 147868  [3.363 sec/step, loss=0.09283, avg_loss=0.09169, mel_loss=0.04181, linear_loss=0.05102]
[2020-05-11 23:44:13.851]  Step 147869  [3.343 sec/step, loss=0.09523, avg_loss=0.09164, mel_loss=0.04311, linear_loss=0.05212]
[2020-05-11 23:44:20.930]  Step 147870  [3.355 sec/step, loss=0.10044, avg_loss=0.09165, mel_loss=0.04682, linear_loss=0.05362]
[2020-05-11 23:44:22.578]  Step 147871  [3.363 sec/step, loss=0.09100, avg_loss=0.09178, mel_loss=0.04045, linear_loss=0.05056]
[2020-05-11 23:44:24.624]  Step 147872  [3.371 sec/step, loss=0.09228, avg_loss=0.09184, mel_loss=0.04116, linear_loss=0.05113]
[2020-05-11 23:44:28.342]  Step 147873  [3.390 sec/step, loss=0.09886, avg_loss=0.09189, mel_loss=0.04477, linear_loss=0.05409]
[2020-05-11 23:44:29.354]  Step 147874  [3.384 sec/step, loss=0.08312, avg_loss=0.09182, mel_loss=0.03682, linear_loss=0.04630]
[2020-05-11 23:44:43.441]  Step 147875  [3.482 sec/step, loss=0.07547, avg_loss=0.09159, mel_loss=0.03629, linear_loss=0.03919]
[2020-05-11 23:44:44.103]  Step 147876  [3.453 sec/step, loss=0.07775, avg_loss=0.09138, mel_loss=0.03414, linear_loss=0.04361]
[2020-05-11 23:44:47.056]  Step 147877  [3.454 sec/step, loss=0.09796, avg_loss=0.09138, mel_loss=0.04368, linear_loss=0.05429]
[2020-05-11 23:44:51.595]  Step 147878  [3.465 sec/step, loss=0.09931, avg_loss=0.09142, mel_loss=0.04539, linear_loss=0.05392]
[2020-05-11 23:44:53.348]  Step 147879  [3.472 sec/step, loss=0.09014, avg_loss=0.09148, mel_loss=0.03964, linear_loss=0.05050]
[2020-05-11 23:45:00.720]  Step 147880  [3.407 sec/step, loss=0.10067, avg_loss=0.09171, mel_loss=0.04682, linear_loss=0.05386]
[2020-05-11 23:45:01.769]  Step 147881  [3.401 sec/step, loss=0.08125, avg_loss=0.09159, mel_loss=0.03572, linear_loss=0.04553]
[2020-05-11 23:45:04.124]  Step 147882  [3.414 sec/step, loss=0.09338, avg_loss=0.09169, mel_loss=0.04202, linear_loss=0.05135]
[2020-05-11 23:45:08.141]  Step 147883  [3.430 sec/step, loss=0.09970, avg_loss=0.09176, mel_loss=0.04542, linear_loss=0.05429]
[2020-05-11 23:45:10.272]  Step 147884  [3.403 sec/step, loss=0.09407, avg_loss=0.09173, mel_loss=0.04193, linear_loss=0.05214]
[2020-05-11 23:45:11.470]  Step 147885  [3.383 sec/step, loss=0.08579, avg_loss=0.09166, mel_loss=0.03787, linear_loss=0.04792]
[2020-05-11 23:45:12.889]  Step 147886  [3.388 sec/step, loss=0.09002, avg_loss=0.09186, mel_loss=0.04008, linear_loss=0.04994]
[2020-05-11 23:45:14.785]  Step 147887  [3.378 sec/step, loss=0.09169, avg_loss=0.09187, mel_loss=0.04070, linear_loss=0.05099]
[2020-05-11 23:45:18.427]  Step 147888  [3.345 sec/step, loss=0.09750, avg_loss=0.09186, mel_loss=0.04411, linear_loss=0.05339]
[2020-05-11 23:45:20.048]  Step 147889  [3.350 sec/step, loss=0.09263, avg_loss=0.09192, mel_loss=0.04129, linear_loss=0.05134]
[2020-05-11 23:45:22.036]  Step 147890  [3.359 sec/step, loss=0.09393, avg_loss=0.09199, mel_loss=0.04191, linear_loss=0.05202]
[2020-05-11 23:45:25.516]  Step 147891  [3.334 sec/step, loss=0.09639, avg_loss=0.09195, mel_loss=0.04351, linear_loss=0.05288]
[2020-05-11 23:45:28.249]  Step 147892  [3.348 sec/step, loss=0.09447, avg_loss=0.09200, mel_loss=0.04259, linear_loss=0.05189]
[2020-05-11 23:45:36.667]  Step 147893  [3.424 sec/step, loss=0.09592, avg_loss=0.09220, mel_loss=0.04484, linear_loss=0.05108]
[2020-05-11 23:45:40.080]  Step 147894  [3.429 sec/step, loss=0.09836, avg_loss=0.09221, mel_loss=0.04458, linear_loss=0.05378]
[2020-05-11 23:45:41.484]  Step 147895  [3.367 sec/step, loss=0.08757, avg_loss=0.09207, mel_loss=0.03844, linear_loss=0.04913]
[2020-05-11 23:45:42.361]  Step 147896  [3.366 sec/step, loss=0.07851, avg_loss=0.09204, mel_loss=0.03415, linear_loss=0.04436]
[2020-05-11 23:45:43.510]  Step 147897  [3.364 sec/step, loss=0.08739, avg_loss=0.09204, mel_loss=0.03817, linear_loss=0.04921]
[2020-05-11 23:45:45.185]  Generated 32 batches of size 32 in 1.669 sec
[2020-05-11 23:45:49.191]  Step 147898  [3.403 sec/step, loss=0.09924, avg_loss=0.09213, mel_loss=0.04558, linear_loss=0.05366]
[2020-05-11 23:45:50.103]  Step 147899  [3.397 sec/step, loss=0.08090, avg_loss=0.09205, mel_loss=0.03522, linear_loss=0.04567]
[2020-05-11 23:45:51.677]  Step 147900  [3.282 sec/step, loss=0.09013, avg_loss=0.09211, mel_loss=0.03982, linear_loss=0.05031]
[2020-05-11 23:45:51.677]  Writing summary at step: 147900
[2020-05-11 23:45:52.440]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147900
[2020-05-11 23:45:53.799]  Saving audio and alignment...
[2020-05-11 23:45:57.948]  Input: 네 지방에서도 많이 들으십니다 이러면 이분이~_______
[2020-05-11 23:46:01.002]  Step 147901  [3.303 sec/step, loss=0.09923, avg_loss=0.09231, mel_loss=0.04471, linear_loss=0.05452]
[2020-05-11 23:46:07.447]  Step 147902  [3.341 sec/step, loss=0.09795, avg_loss=0.09234, mel_loss=0.04540, linear_loss=0.05254]
[2020-05-11 23:46:11.818]  Step 147903  [3.363 sec/step, loss=0.09777, avg_loss=0.09240, mel_loss=0.04472, linear_loss=0.05305]
[2020-05-11 23:46:17.062]  Step 147904  [3.383 sec/step, loss=0.09835, avg_loss=0.09240, mel_loss=0.04536, linear_loss=0.05299]
[2020-05-11 23:46:19.974]  Step 147905  [3.377 sec/step, loss=0.09575, avg_loss=0.09237, mel_loss=0.04297, linear_loss=0.05278]
[2020-05-11 23:46:21.432]  Step 147906  [3.375 sec/step, loss=0.08937, avg_loss=0.09234, mel_loss=0.03932, linear_loss=0.05005]
[2020-05-11 23:46:22.471]  Step 147907  [3.357 sec/step, loss=0.08277, avg_loss=0.09222, mel_loss=0.03620, linear_loss=0.04657]
[2020-05-11 23:46:27.991]  Step 147908  [3.373 sec/step, loss=0.10057, avg_loss=0.09223, mel_loss=0.04640, linear_loss=0.05417]
[2020-05-11 23:46:31.602]  Step 147909  [3.368 sec/step, loss=0.09869, avg_loss=0.09222, mel_loss=0.04488, linear_loss=0.05381]
[2020-05-11 23:46:33.217]  Step 147910  [3.301 sec/step, loss=0.09082, avg_loss=0.09214, mel_loss=0.04048, linear_loss=0.05033]
[2020-05-11 23:46:34.009]  Step 147911  [3.286 sec/step, loss=0.08025, avg_loss=0.09200, mel_loss=0.03543, linear_loss=0.04482]
[2020-05-11 23:46:38.109]  Step 147912  [3.279 sec/step, loss=0.09730, avg_loss=0.09197, mel_loss=0.04416, linear_loss=0.05314]
[2020-05-11 23:46:44.709]  Step 147913  [3.269 sec/step, loss=0.09851, avg_loss=0.09197, mel_loss=0.04580, linear_loss=0.05271]
[2020-05-11 23:46:46.975]  Step 147914  [3.280 sec/step, loss=0.09191, avg_loss=0.09203, mel_loss=0.04120, linear_loss=0.05070]
[2020-05-11 23:46:54.025]  Step 147915  [3.332 sec/step, loss=0.09762, avg_loss=0.09208, mel_loss=0.04545, linear_loss=0.05217]
[2020-05-11 23:46:55.987]  Step 147916  [3.323 sec/step, loss=0.09288, avg_loss=0.09207, mel_loss=0.04153, linear_loss=0.05135]
[2020-05-11 23:47:04.894]  Step 147917  [3.404 sec/step, loss=0.09720, avg_loss=0.09227, mel_loss=0.04557, linear_loss=0.05162]
[2020-05-11 23:47:07.758]  Step 147918  [3.419 sec/step, loss=0.09466, avg_loss=0.09232, mel_loss=0.04279, linear_loss=0.05188]
[2020-05-11 23:47:08.920]  Step 147919  [3.394 sec/step, loss=0.08545, avg_loss=0.09218, mel_loss=0.03707, linear_loss=0.04837]
[2020-05-11 23:47:10.780]  Step 147920  [3.396 sec/step, loss=0.09083, avg_loss=0.09218, mel_loss=0.04028, linear_loss=0.05055]
[2020-05-11 23:47:15.374]  Step 147921  [3.380 sec/step, loss=0.10136, avg_loss=0.09221, mel_loss=0.04645, linear_loss=0.05491]
[2020-05-11 23:47:16.668]  Step 147922  [3.363 sec/step, loss=0.08551, avg_loss=0.09209, mel_loss=0.03745, linear_loss=0.04806]
[2020-05-11 23:47:17.473]  Step 147923  [3.325 sec/step, loss=0.08187, avg_loss=0.09192, mel_loss=0.03553, linear_loss=0.04634]
[2020-05-11 23:47:20.054]  Step 147924  [3.333 sec/step, loss=0.09397, avg_loss=0.09195, mel_loss=0.04214, linear_loss=0.05183]
[2020-05-11 23:47:20.580]  Step 147925  [3.297 sec/step, loss=0.07709, avg_loss=0.09174, mel_loss=0.03380, linear_loss=0.04329]
[2020-05-11 23:47:33.668]  Step 147926  [3.407 sec/step, loss=0.08563, avg_loss=0.09164, mel_loss=0.04088, linear_loss=0.04475]
[2020-05-11 23:47:36.922]  Step 147927  [3.398 sec/step, loss=0.09582, avg_loss=0.09160, mel_loss=0.04351, linear_loss=0.05231]
[2020-05-11 23:47:38.645]  Generated 32 batches of size 32 in 1.718 sec
[2020-05-11 23:47:41.352]  Step 147928  [3.427 sec/step, loss=0.09825, avg_loss=0.09168, mel_loss=0.04471, linear_loss=0.05354]
[2020-05-11 23:47:43.107]  Step 147929  [3.421 sec/step, loss=0.09234, avg_loss=0.09166, mel_loss=0.04066, linear_loss=0.05168]
[2020-05-11 23:47:46.571]  Step 147930  [3.446 sec/step, loss=0.09552, avg_loss=0.09179, mel_loss=0.04341, linear_loss=0.05211]
[2020-05-11 23:47:47.409]  Step 147931  [3.399 sec/step, loss=0.07695, avg_loss=0.09156, mel_loss=0.03399, linear_loss=0.04296]
[2020-05-11 23:47:49.819]  Step 147932  [3.390 sec/step, loss=0.09592, avg_loss=0.09152, mel_loss=0.04292, linear_loss=0.05300]
[2020-05-11 23:47:51.925]  Step 147933  [3.377 sec/step, loss=0.09360, avg_loss=0.09149, mel_loss=0.04175, linear_loss=0.05185]
[2020-05-11 23:47:56.914]  Step 147934  [3.297 sec/step, loss=0.09939, avg_loss=0.09165, mel_loss=0.04586, linear_loss=0.05353]
[2020-05-11 23:47:57.902]  Step 147935  [3.294 sec/step, loss=0.08504, avg_loss=0.09160, mel_loss=0.03699, linear_loss=0.04805]
[2020-05-11 23:47:59.239]  Step 147936  [3.273 sec/step, loss=0.09037, avg_loss=0.09153, mel_loss=0.04011, linear_loss=0.05026]
[2020-05-11 23:48:04.602]  Step 147937  [3.315 sec/step, loss=0.10037, avg_loss=0.09167, mel_loss=0.04623, linear_loss=0.05413]
[2020-05-11 23:48:12.042]  Step 147938  [3.302 sec/step, loss=0.10014, avg_loss=0.09168, mel_loss=0.04664, linear_loss=0.05350]
[2020-05-11 23:48:12.744]  Step 147939  [3.301 sec/step, loss=0.07810, avg_loss=0.09166, mel_loss=0.03429, linear_loss=0.04381]
[2020-05-11 23:48:16.085]  Step 147940  [3.314 sec/step, loss=0.09912, avg_loss=0.09172, mel_loss=0.04488, linear_loss=0.05424]
[2020-05-11 23:48:19.111]  Step 147941  [3.338 sec/step, loss=0.09767, avg_loss=0.09197, mel_loss=0.04409, linear_loss=0.05357]
[2020-05-11 23:48:23.306]  Step 147942  [3.372 sec/step, loss=0.09956, avg_loss=0.09220, mel_loss=0.04585, linear_loss=0.05371]
[2020-05-11 23:48:24.439]  Step 147943  [3.330 sec/step, loss=0.08492, avg_loss=0.09207, mel_loss=0.03705, linear_loss=0.04787]
[2020-05-11 23:48:28.584]  Step 147944  [3.346 sec/step, loss=0.09827, avg_loss=0.09211, mel_loss=0.04452, linear_loss=0.05375]
[2020-05-11 23:48:31.364]  Step 147945  [3.317 sec/step, loss=0.09330, avg_loss=0.09206, mel_loss=0.04216, linear_loss=0.05115]
[2020-05-11 23:48:33.591]  Step 147946  [3.311 sec/step, loss=0.09320, avg_loss=0.09204, mel_loss=0.04174, linear_loss=0.05146]
[2020-05-11 23:48:37.349]  Step 147947  [3.299 sec/step, loss=0.09785, avg_loss=0.09203, mel_loss=0.04448, linear_loss=0.05338]
[2020-05-11 23:48:39.243]  Step 147948  [3.307 sec/step, loss=0.08955, avg_loss=0.09208, mel_loss=0.03962, linear_loss=0.04992]
[2020-05-11 23:48:40.550]  Step 147949  [3.300 sec/step, loss=0.08690, avg_loss=0.09205, mel_loss=0.03824, linear_loss=0.04866]
[2020-05-11 23:48:43.886]  Step 147950  [3.321 sec/step, loss=0.09658, avg_loss=0.09213, mel_loss=0.04397, linear_loss=0.05261]
[2020-05-11 23:48:43.886]  Writing summary at step: 147950
[2020-05-11 23:48:46.049]  Saving checkpoint to: ./logs-tacotron/model.ckpt-147950
[2020-05-11 23:48:47.436]  Saving audio and alignment...
[2020-05-11 23:48:49.045]  Input: 안녕~____
[2020-05-11 23:48:54.015]  Step 147951  [3.335 sec/step, loss=0.09762, avg_loss=0.09210, mel_loss=0.04446, linear_loss=0.05316]
[2020-05-11 23:48:54.954]  Step 147952  [3.317 sec/step, loss=0.08443, avg_loss=0.09200, mel_loss=0.03719, linear_loss=0.04724]
[2020-05-11 23:49:01.784]  Step 147953  [3.371 sec/step, loss=0.09993, avg_loss=0.09213, mel_loss=0.04624, linear_loss=0.05368]
[2020-05-11 23:49:05.381]  Step 147954  [3.319 sec/step, loss=0.09723, avg_loss=0.09212, mel_loss=0.04404, linear_loss=0.05318]
[2020-05-11 23:49:07.145]  Step 147955  [3.189 sec/step, loss=0.09146, avg_loss=0.09227, mel_loss=0.04044, linear_loss=0.05102]
[2020-05-11 23:49:08.502]  Step 147956  [3.162 sec/step, loss=0.08853, avg_loss=0.09217, mel_loss=0.03913, linear_loss=0.04941]
[2020-05-11 23:49:10.047]  Step 147957  [3.160 sec/step, loss=0.08593, avg_loss=0.09213, mel_loss=0.03803, linear_loss=0.04790]
[2020-05-11 23:49:10.936]  Step 147958  [3.102 sec/step, loss=0.08090, avg_loss=0.09194, mel_loss=0.03521, linear_loss=0.04569]
[2020-05-11 23:49:11.848]  Generated 32 batches of size 32 in 1.795 sec
[2020-05-11 23:49:16.655]  Step 147959  [3.152 sec/step, loss=0.10039, avg_loss=0.09215, mel_loss=0.04657, linear_loss=0.05382]
[2020-05-11 23:49:19.077]  Step 147960  [3.168 sec/step, loss=0.09476, avg_loss=0.09231, mel_loss=0.04249, linear_loss=0.05227]
[2020-05-11 23:49:20.147]  Step 147961  [3.156 sec/step, loss=0.08633, avg_loss=0.09225, mel_loss=0.03786, linear_loss=0.04847]
[2020-05-11 23:49:22.118]  Step 147962  [3.152 sec/step, loss=0.09287, avg_loss=0.09223, mel_loss=0.04141, linear_loss=0.05147]
[2020-05-11 23:49:38.778]  Step 147963  [3.285 sec/step, loss=0.08786, avg_loss=0.09214, mel_loss=0.04178, linear_loss=0.04608]
[2020-05-11 23:49:42.507]  Step 147964  [3.317 sec/step, loss=0.09455, avg_loss=0.09235, mel_loss=0.04246, linear_loss=0.05209]
[2020-05-11 23:49:51.283]  Step 147965  [3.360 sec/step, loss=0.09959, avg_loss=0.09234, mel_loss=0.04660, linear_loss=0.05299]
[2020-05-11 23:49:52.915]  Step 147966  [3.344 sec/step, loss=0.09245, avg_loss=0.09230, mel_loss=0.04133, linear_loss=0.05112]
[2020-05-11 23:50:01.975]  Step 147967  [3.424 sec/step, loss=0.09837, avg_loss=0.09239, mel_loss=0.04643, linear_loss=0.05194]
[2020-05-11 23:50:02.759]  Step 147968  [3.408 sec/step, loss=0.07942, avg_loss=0.09226, mel_loss=0.03481, linear_loss=0.04461]
[2020-05-11 23:50:05.152]  Step 147969  [3.398 sec/step, loss=0.09517, avg_loss=0.09226, mel_loss=0.04232, linear_loss=0.05285]
[2020-05-11 23:50:10.815]  Step 147970  [3.384 sec/step, loss=0.10030, avg_loss=0.09226, mel_loss=0.04639, linear_loss=0.05391]
[2020-05-11 23:50:11.801]  Step 147971  [3.378 sec/step, loss=0.08314, avg_loss=0.09218, mel_loss=0.03689, linear_loss=0.04624]
[2020-05-11 23:50:13.773]  Step 147972  [3.377 sec/step, loss=0.09184, avg_loss=0.09217, mel_loss=0.04092, linear_loss=0.05092]
[2020-05-11 23:50:14.759]  Step 147973  [3.350 sec/step, loss=0.08216, avg_loss=0.09201, mel_loss=0.03591, linear_loss=0.04625]
[2020-05-11 23:50:15.317]  Step 147974  [3.345 sec/step, loss=0.07391, avg_loss=0.09191, mel_loss=0.03311, linear_loss=0.04080]
[2020-05-11 23:50:16.680]  Step 147975  [3.218 sec/step, loss=0.08923, avg_loss=0.09205, mel_loss=0.03947, linear_loss=0.04976]
[2020-05-11 23:50:20.918]  Step 147976  [3.254 sec/step, loss=0.09639, avg_loss=0.09224, mel_loss=0.04397, linear_loss=0.05242]
[2020-05-11 23:50:22.008]  Step 147977  [3.235 sec/step, loss=0.08518, avg_loss=0.09211, mel_loss=0.03756, linear_loss=0.04762]
[2020-05-11 23:50:23.313]  Step 147978  [3.203 sec/step, loss=0.08966, avg_loss=0.09201, mel_loss=0.03936, linear_loss=0.05030]
[2020-05-11 23:50:24.858]  Step 147979  [3.201 sec/step, loss=0.09217, avg_loss=0.09203, mel_loss=0.04102, linear_loss=0.05115]
[2020-05-11 23:50:26.943]  Step 147980  [3.148 sec/step, loss=0.09455, avg_loss=0.09197, mel_loss=0.04256, linear_loss=0.05198]
[2020-05-11 23:50:29.880]  Step 147981  [3.167 sec/step, loss=0.09791, avg_loss=0.09214, mel_loss=0.04410, linear_loss=0.05381]
[2020-05-11 23:50:32.113]  Step 147982  [3.165 sec/step, loss=0.09316, avg_loss=0.09214, mel_loss=0.04196, linear_loss=0.05119]
[2020-05-11 23:50:37.382]  Step 147983  [3.178 sec/step, loss=0.09885, avg_loss=0.09213, mel_loss=0.04554, linear_loss=0.05331]
[2020-05-11 23:50:40.218]  Step 147984  [3.185 sec/step, loss=0.09589, avg_loss=0.09215, mel_loss=0.04355, linear_loss=0.05234]
[2020-05-11 23:50:55.070]  Step 147985  [3.321 sec/step, loss=0.08165, avg_loss=0.09210, mel_loss=0.03935, linear_loss=0.04230]
[2020-05-11 23:50:56.683]  Step 147986  [3.323 sec/step, loss=0.09240, avg_loss=0.09213, mel_loss=0.04143, linear_loss=0.05097]
[2020-05-11 23:51:01.087]  Step 147987  [3.348 sec/step, loss=0.10047, avg_loss=0.09222, mel_loss=0.04630, linear_loss=0.05417]
[2020-05-11 23:51:03.756]  Step 147988  [3.339 sec/step, loss=0.09603, avg_loss=0.09220, mel_loss=0.04337, linear_loss=0.05267]
[2020-05-11 23:51:07.407]  Step 147989  [3.359 sec/step, loss=0.09929, avg_loss=0.09227, mel_loss=0.04530, linear_loss=0.05399]
[2020-05-11 23:51:09.176]  Generated 32 batches of size 32 in 1.764 sec
[2020-05-11 23:51:12.319]  Step 147990  [3.388 sec/step, loss=0.09681, avg_loss=0.09230, mel_loss=0.04425, linear_loss=0.05256]
[2020-05-11 23:51:13.072]  Step 147991  [3.361 sec/step, loss=0.07490, avg_loss=0.09208, mel_loss=0.03308, linear_loss=0.04182]
[2020-05-11 23:51:16.595]  Step 147992  [3.369 sec/step, loss=0.09589, avg_loss=0.09210, mel_loss=0.04338, linear_loss=0.05251]
[2020-05-11 23:51:18.509]  Step 147993  [3.304 sec/step, loss=0.09257, avg_loss=0.09206, mel_loss=0.04103, linear_loss=0.05154]
[2020-05-11 23:51:19.816]  Step 147994  [3.283 sec/step, loss=0.08476, avg_loss=0.09193, mel_loss=0.03748, linear_loss=0.04728]
[2020-05-11 23:51:26.494]  Step 147995  [3.336 sec/step, loss=0.10083, avg_loss=0.09206, mel_loss=0.04706, linear_loss=0.05378]
[2020-05-11 23:51:34.141]  Step 147996  [3.403 sec/step, loss=0.09976, avg_loss=0.09227, mel_loss=0.04665, linear_loss=0.05311]
[2020-05-11 23:51:37.511]  Step 147997  [3.425 sec/step, loss=0.09619, avg_loss=0.09236, mel_loss=0.04365, linear_loss=0.05254]
[2020-05-11 23:51:39.242]  Step 147998  [3.386 sec/step, loss=0.09046, avg_loss=0.09227, mel_loss=0.04009, linear_loss=0.05037]
[2020-05-11 23:51:40.618]  Step 147999  [3.391 sec/step, loss=0.08898, avg_loss=0.09235, mel_loss=0.03967, linear_loss=0.04931]
[2020-05-11 23:51:42.708]  Step 148000  [3.396 sec/step, loss=0.09341, avg_loss=0.09239, mel_loss=0.04194, linear_loss=0.05146]
[2020-05-11 23:51:42.708]  Writing summary at step: 148000
[2020-05-11 23:51:43.513]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148000
[2020-05-11 23:51:44.916]  Saving audio and alignment...
[2020-05-11 23:51:48.282]  Input: 언어 사용에 습관이라고 할 수 있어요~_______
[2020-05-11 23:51:50.715]  Step 148001  [3.390 sec/step, loss=0.09279, avg_loss=0.09232, mel_loss=0.04143, linear_loss=0.05136]
[2020-05-11 23:51:53.568]  Step 148002  [3.354 sec/step, loss=0.09602, avg_loss=0.09230, mel_loss=0.04331, linear_loss=0.05272]
[2020-05-11 23:51:59.516]  Step 148003  [3.369 sec/step, loss=0.09889, avg_loss=0.09231, mel_loss=0.04589, linear_loss=0.05300]
[2020-05-11 23:52:00.613]  Step 148004  [3.328 sec/step, loss=0.08597, avg_loss=0.09219, mel_loss=0.03734, linear_loss=0.04864]
[2020-05-11 23:52:01.911]  Step 148005  [3.312 sec/step, loss=0.08690, avg_loss=0.09210, mel_loss=0.03863, linear_loss=0.04827]
[2020-05-11 23:52:02.911]  Step 148006  [3.307 sec/step, loss=0.08388, avg_loss=0.09205, mel_loss=0.03683, linear_loss=0.04705]
[2020-05-11 23:52:03.730]  Step 148007  [3.305 sec/step, loss=0.07866, avg_loss=0.09200, mel_loss=0.03450, linear_loss=0.04416]
[2020-05-11 23:52:09.193]  Step 148008  [3.304 sec/step, loss=0.10053, avg_loss=0.09200, mel_loss=0.04636, linear_loss=0.05417]
[2020-05-11 23:52:09.767]  Step 148009  [3.274 sec/step, loss=0.07199, avg_loss=0.09174, mel_loss=0.03247, linear_loss=0.03952]
[2020-05-11 23:52:13.003]  Step 148010  [3.290 sec/step, loss=0.09840, avg_loss=0.09181, mel_loss=0.04458, linear_loss=0.05382]
[2020-05-11 23:52:14.731]  Step 148011  [3.300 sec/step, loss=0.09302, avg_loss=0.09194, mel_loss=0.04131, linear_loss=0.05171]
[2020-05-11 23:52:19.529]  Step 148012  [3.307 sec/step, loss=0.09772, avg_loss=0.09194, mel_loss=0.04485, linear_loss=0.05287]
[2020-05-11 23:52:22.581]  Step 148013  [3.271 sec/step, loss=0.09809, avg_loss=0.09194, mel_loss=0.04468, linear_loss=0.05341]
[2020-05-11 23:52:26.097]  Step 148014  [3.284 sec/step, loss=0.09917, avg_loss=0.09201, mel_loss=0.04500, linear_loss=0.05417]
[2020-05-11 23:52:27.621]  Step 148015  [3.228 sec/step, loss=0.08931, avg_loss=0.09193, mel_loss=0.03968, linear_loss=0.04963]
[2020-05-11 23:52:29.260]  Step 148016  [3.225 sec/step, loss=0.09101, avg_loss=0.09191, mel_loss=0.04039, linear_loss=0.05063]
[2020-05-11 23:52:33.210]  Step 148017  [3.176 sec/step, loss=0.09826, avg_loss=0.09192, mel_loss=0.04465, linear_loss=0.05361]
[2020-05-11 23:52:45.415]  Step 148018  [3.269 sec/step, loss=0.08519, avg_loss=0.09183, mel_loss=0.04048, linear_loss=0.04471]
[2020-05-11 23:52:49.822]  Step 148019  [3.301 sec/step, loss=0.10166, avg_loss=0.09199, mel_loss=0.04667, linear_loss=0.05498]
[2020-05-11 23:52:50.874]  Step 148020  [3.293 sec/step, loss=0.08199, avg_loss=0.09190, mel_loss=0.03567, linear_loss=0.04631]
[2020-05-11 23:52:51.586]  Generated 32 batches of size 32 in 1.758 sec
[2020-05-11 23:52:54.337]  Step 148021  [3.282 sec/step, loss=0.09667, avg_loss=0.09185, mel_loss=0.04374, linear_loss=0.05293]
[2020-05-11 23:52:56.941]  Step 148022  [3.295 sec/step, loss=0.09260, avg_loss=0.09193, mel_loss=0.04175, linear_loss=0.05085]
[2020-05-11 23:53:05.701]  Step 148023  [3.375 sec/step, loss=0.09615, avg_loss=0.09207, mel_loss=0.04498, linear_loss=0.05117]
[2020-05-11 23:53:07.622]  Step 148024  [3.368 sec/step, loss=0.09151, avg_loss=0.09204, mel_loss=0.04060, linear_loss=0.05090]
[2020-05-11 23:53:08.848]  Step 148025  [3.375 sec/step, loss=0.08769, avg_loss=0.09215, mel_loss=0.03857, linear_loss=0.04913]
[2020-05-11 23:53:11.033]  Step 148026  [3.266 sec/step, loss=0.09264, avg_loss=0.09222, mel_loss=0.04149, linear_loss=0.05114]
[2020-05-11 23:53:18.351]  Step 148027  [3.307 sec/step, loss=0.10012, avg_loss=0.09226, mel_loss=0.04681, linear_loss=0.05330]
[2020-05-11 23:53:22.042]  Step 148028  [3.299 sec/step, loss=0.10004, avg_loss=0.09228, mel_loss=0.04581, linear_loss=0.05423]
[2020-05-11 23:53:24.134]  Step 148029  [3.303 sec/step, loss=0.09251, avg_loss=0.09228, mel_loss=0.04130, linear_loss=0.05121]
[2020-05-11 23:53:26.508]  Step 148030  [3.292 sec/step, loss=0.09555, avg_loss=0.09228, mel_loss=0.04271, linear_loss=0.05284]
[2020-05-11 23:53:30.539]  Step 148031  [3.324 sec/step, loss=0.09723, avg_loss=0.09249, mel_loss=0.04429, linear_loss=0.05294]
[2020-05-11 23:53:39.223]  Step 148032  [3.386 sec/step, loss=0.09639, avg_loss=0.09249, mel_loss=0.04521, linear_loss=0.05118]
[2020-05-11 23:53:43.362]  Step 148033  [3.407 sec/step, loss=0.09766, avg_loss=0.09253, mel_loss=0.04468, linear_loss=0.05298]
[2020-05-11 23:53:49.937]  Step 148034  [3.423 sec/step, loss=0.09859, avg_loss=0.09252, mel_loss=0.04568, linear_loss=0.05291]
[2020-05-11 23:53:57.255]  Step 148035  [3.486 sec/step, loss=0.10114, avg_loss=0.09268, mel_loss=0.04717, linear_loss=0.05398]
[2020-05-11 23:53:59.692]  Step 148036  [3.497 sec/step, loss=0.09464, avg_loss=0.09273, mel_loss=0.04229, linear_loss=0.05234]
[2020-05-11 23:54:01.069]  Step 148037  [3.457 sec/step, loss=0.08850, avg_loss=0.09261, mel_loss=0.03919, linear_loss=0.04931]
[2020-05-11 23:54:03.245]  Step 148038  [3.404 sec/step, loss=0.09436, avg_loss=0.09255, mel_loss=0.04214, linear_loss=0.05222]
[2020-05-11 23:54:04.082]  Step 148039  [3.406 sec/step, loss=0.07893, avg_loss=0.09256, mel_loss=0.03456, linear_loss=0.04437]
[2020-05-11 23:54:04.644]  Step 148040  [3.378 sec/step, loss=0.07316, avg_loss=0.09230, mel_loss=0.03258, linear_loss=0.04058]
[2020-05-11 23:54:06.603]  Step 148041  [3.367 sec/step, loss=0.09260, avg_loss=0.09225, mel_loss=0.04108, linear_loss=0.05151]
[2020-05-11 23:54:07.650]  Step 148042  [3.336 sec/step, loss=0.08223, avg_loss=0.09207, mel_loss=0.03610, linear_loss=0.04613]
[2020-05-11 23:54:21.352]  Step 148043  [3.462 sec/step, loss=0.07515, avg_loss=0.09198, mel_loss=0.03607, linear_loss=0.03909]
[2020-05-11 23:54:22.103]  Step 148044  [3.428 sec/step, loss=0.08162, avg_loss=0.09181, mel_loss=0.03533, linear_loss=0.04629]
[2020-05-11 23:54:27.033]  Step 148045  [3.449 sec/step, loss=0.09793, avg_loss=0.09186, mel_loss=0.04527, linear_loss=0.05266]
[2020-05-11 23:54:30.626]  Step 148046  [3.463 sec/step, loss=0.10211, avg_loss=0.09195, mel_loss=0.04670, linear_loss=0.05541]
[2020-05-11 23:54:32.356]  Step 148047  [3.442 sec/step, loss=0.09116, avg_loss=0.09188, mel_loss=0.04018, linear_loss=0.05098]
[2020-05-11 23:54:33.932]  Step 148048  [3.439 sec/step, loss=0.09145, avg_loss=0.09190, mel_loss=0.04076, linear_loss=0.05069]
[2020-05-11 23:54:37.337]  Step 148049  [3.460 sec/step, loss=0.09525, avg_loss=0.09198, mel_loss=0.04314, linear_loss=0.05212]
[2020-05-11 23:54:38.392]  Step 148050  [3.437 sec/step, loss=0.08732, avg_loss=0.09189, mel_loss=0.03789, linear_loss=0.04943]
[2020-05-11 23:54:38.392]  Writing summary at step: 148050
[2020-05-11 23:54:39.711]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148050
[2020-05-11 23:54:41.989]  Saving audio and alignment...
[2020-05-11 23:54:44.048]  Generated 32 batches of size 32 in 1.550 sec
[2020-05-11 23:54:47.427]  Input: 잡은 고기는 또 그 자리에서 매운탕을 끓여 먹어야 제맛이죠~___
[2020-05-11 23:54:50.537]  Step 148051  [3.419 sec/step, loss=0.09702, avg_loss=0.09188, mel_loss=0.04379, linear_loss=0.05322]
[2020-05-11 23:54:56.019]  Step 148052  [3.464 sec/step, loss=0.10024, avg_loss=0.09204, mel_loss=0.04634, linear_loss=0.05389]
[2020-05-11 23:55:00.542]  Step 148053  [3.441 sec/step, loss=0.09897, avg_loss=0.09203, mel_loss=0.04514, linear_loss=0.05383]
[2020-05-11 23:55:02.038]  Step 148054  [3.420 sec/step, loss=0.09131, avg_loss=0.09197, mel_loss=0.04019, linear_loss=0.05112]
[2020-05-11 23:55:03.911]  Step 148055  [3.421 sec/step, loss=0.09146, avg_loss=0.09197, mel_loss=0.04083, linear_loss=0.05062]
[2020-05-11 23:55:06.789]  Step 148056  [3.437 sec/step, loss=0.09897, avg_loss=0.09208, mel_loss=0.04474, linear_loss=0.05423]
[2020-05-11 23:55:09.497]  Step 148057  [3.448 sec/step, loss=0.09551, avg_loss=0.09217, mel_loss=0.04289, linear_loss=0.05262]
[2020-05-11 23:55:10.356]  Step 148058  [3.448 sec/step, loss=0.08034, avg_loss=0.09217, mel_loss=0.03522, linear_loss=0.04512]
[2020-05-11 23:55:15.889]  Step 148059  [3.446 sec/step, loss=0.09908, avg_loss=0.09215, mel_loss=0.04546, linear_loss=0.05362]
[2020-05-11 23:55:17.132]  Step 148060  [3.434 sec/step, loss=0.08908, avg_loss=0.09210, mel_loss=0.03907, linear_loss=0.05001]
[2020-05-11 23:55:18.187]  Step 148061  [3.434 sec/step, loss=0.08886, avg_loss=0.09212, mel_loss=0.03886, linear_loss=0.05000]
[2020-05-11 23:55:19.151]  Step 148062  [3.424 sec/step, loss=0.08578, avg_loss=0.09205, mel_loss=0.03748, linear_loss=0.04830]
[2020-05-11 23:55:33.301]  Step 148063  [3.399 sec/step, loss=0.07981, avg_loss=0.09197, mel_loss=0.03826, linear_loss=0.04155]
[2020-05-11 23:55:34.047]  Step 148064  [3.369 sec/step, loss=0.07508, avg_loss=0.09178, mel_loss=0.03292, linear_loss=0.04215]
[2020-05-11 23:55:34.844]  Step 148065  [3.289 sec/step, loss=0.08362, avg_loss=0.09162, mel_loss=0.03670, linear_loss=0.04692]
[2020-05-11 23:55:37.184]  Step 148066  [3.296 sec/step, loss=0.09491, avg_loss=0.09164, mel_loss=0.04271, linear_loss=0.05220]
[2020-05-11 23:55:40.127]  Step 148067  [3.235 sec/step, loss=0.09843, avg_loss=0.09164, mel_loss=0.04434, linear_loss=0.05409]
[2020-05-11 23:55:47.197]  Step 148068  [3.298 sec/step, loss=0.09954, avg_loss=0.09184, mel_loss=0.04648, linear_loss=0.05306]
[2020-05-11 23:55:50.631]  Step 148069  [3.308 sec/step, loss=0.10052, avg_loss=0.09190, mel_loss=0.04583, linear_loss=0.05469]
[2020-05-11 23:55:54.136]  Step 148070  [3.287 sec/step, loss=0.09763, avg_loss=0.09187, mel_loss=0.04456, linear_loss=0.05307]
[2020-05-11 23:55:55.522]  Step 148071  [3.291 sec/step, loss=0.09031, avg_loss=0.09194, mel_loss=0.03994, linear_loss=0.05038]
[2020-05-11 23:55:58.047]  Step 148072  [3.296 sec/step, loss=0.09479, avg_loss=0.09197, mel_loss=0.04276, linear_loss=0.05202]
[2020-05-11 23:56:02.045]  Step 148073  [3.327 sec/step, loss=0.10022, avg_loss=0.09215, mel_loss=0.04556, linear_loss=0.05466]
[2020-05-11 23:56:03.466]  Step 148074  [3.335 sec/step, loss=0.08799, avg_loss=0.09229, mel_loss=0.03925, linear_loss=0.04874]
[2020-05-11 23:56:08.066]  Step 148075  [3.368 sec/step, loss=0.10029, avg_loss=0.09240, mel_loss=0.04613, linear_loss=0.05416]
[2020-05-11 23:56:13.316]  Step 148076  [3.378 sec/step, loss=0.09963, avg_loss=0.09243, mel_loss=0.04585, linear_loss=0.05379]
[2020-05-11 23:56:15.102]  Step 148077  [3.385 sec/step, loss=0.09123, avg_loss=0.09250, mel_loss=0.04065, linear_loss=0.05058]
[2020-05-11 23:56:17.276]  Step 148078  [3.393 sec/step, loss=0.09346, avg_loss=0.09253, mel_loss=0.04212, linear_loss=0.05134]
[2020-05-11 23:56:18.273]  Step 148079  [3.388 sec/step, loss=0.08299, avg_loss=0.09244, mel_loss=0.03631, linear_loss=0.04667]
[2020-05-11 23:56:22.524]  Step 148080  [3.409 sec/step, loss=0.10006, avg_loss=0.09250, mel_loss=0.04564, linear_loss=0.05442]
[2020-05-11 23:56:24.173]  Step 148081  [3.397 sec/step, loss=0.09355, avg_loss=0.09245, mel_loss=0.04151, linear_loss=0.05204]
[2020-05-11 23:56:25.943]  Generated 32 batches of size 32 in 1.764 sec
[2020-05-11 23:56:26.302]  Step 148082  [3.396 sec/step, loss=0.09305, avg_loss=0.09245, mel_loss=0.04171, linear_loss=0.05134]
[2020-05-11 23:56:27.497]  Step 148083  [3.355 sec/step, loss=0.08883, avg_loss=0.09235, mel_loss=0.03898, linear_loss=0.04985]
[2020-05-11 23:56:30.501]  Step 148084  [3.356 sec/step, loss=0.09622, avg_loss=0.09236, mel_loss=0.04365, linear_loss=0.05258]
[2020-05-11 23:56:31.102]  Step 148085  [3.214 sec/step, loss=0.07355, avg_loss=0.09227, mel_loss=0.03303, linear_loss=0.04052]
[2020-05-11 23:56:39.862]  Step 148086  [3.285 sec/step, loss=0.09917, avg_loss=0.09234, mel_loss=0.04669, linear_loss=0.05248]
[2020-05-11 23:56:43.229]  Step 148087  [3.275 sec/step, loss=0.09910, avg_loss=0.09233, mel_loss=0.04501, linear_loss=0.05409]
[2020-05-11 23:56:49.436]  Step 148088  [3.310 sec/step, loss=0.09876, avg_loss=0.09236, mel_loss=0.04581, linear_loss=0.05295]
[2020-05-11 23:56:51.472]  Step 148089  [3.294 sec/step, loss=0.09354, avg_loss=0.09230, mel_loss=0.04205, linear_loss=0.05149]
[2020-05-11 23:56:53.094]  Step 148090  [3.261 sec/step, loss=0.09358, avg_loss=0.09227, mel_loss=0.04163, linear_loss=0.05195]
[2020-05-11 23:56:58.761]  Step 148091  [3.311 sec/step, loss=0.09971, avg_loss=0.09251, mel_loss=0.04607, linear_loss=0.05364]
[2020-05-11 23:56:59.329]  Step 148092  [3.281 sec/step, loss=0.07410, avg_loss=0.09230, mel_loss=0.03313, linear_loss=0.04097]
[2020-05-11 23:57:04.500]  Step 148093  [3.314 sec/step, loss=0.09923, avg_loss=0.09236, mel_loss=0.04586, linear_loss=0.05337]
[2020-05-11 23:57:05.662]  Step 148094  [3.312 sec/step, loss=0.08593, avg_loss=0.09237, mel_loss=0.03772, linear_loss=0.04821]
[2020-05-11 23:57:08.667]  Step 148095  [3.275 sec/step, loss=0.09817, avg_loss=0.09235, mel_loss=0.04441, linear_loss=0.05376]
[2020-05-11 23:57:11.086]  Step 148096  [3.223 sec/step, loss=0.09263, avg_loss=0.09228, mel_loss=0.04161, linear_loss=0.05102]
[2020-05-11 23:57:14.648]  Step 148097  [3.225 sec/step, loss=0.10052, avg_loss=0.09232, mel_loss=0.04572, linear_loss=0.05480]
[2020-05-11 23:57:15.946]  Step 148098  [3.221 sec/step, loss=0.08737, avg_loss=0.09229, mel_loss=0.03856, linear_loss=0.04881]
[2020-05-11 23:57:24.889]  Step 148099  [3.296 sec/step, loss=0.09684, avg_loss=0.09237, mel_loss=0.04562, linear_loss=0.05122]
[2020-05-11 23:57:26.802]  Step 148100  [3.295 sec/step, loss=0.09227, avg_loss=0.09236, mel_loss=0.04094, linear_loss=0.05132]
[2020-05-11 23:57:26.802]  Writing summary at step: 148100
[2020-05-11 23:57:27.931]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148100
[2020-05-11 23:57:29.316]  Saving audio and alignment...
[2020-05-11 23:57:35.535]  Input: 어법에 맞고 내 입에 잘 붙는 멘트로 진행이 가능하니까~____________________
[2020-05-11 23:57:38.051]  Step 148101  [3.295 sec/step, loss=0.09461, avg_loss=0.09237, mel_loss=0.04226, linear_loss=0.05235]
[2020-05-11 23:57:40.166]  Step 148102  [3.288 sec/step, loss=0.09356, avg_loss=0.09235, mel_loss=0.04206, linear_loss=0.05149]
[2020-05-11 23:57:41.903]  Step 148103  [3.246 sec/step, loss=0.09094, avg_loss=0.09227, mel_loss=0.04036, linear_loss=0.05058]
[2020-05-11 23:57:43.944]  Step 148104  [3.255 sec/step, loss=0.09255, avg_loss=0.09234, mel_loss=0.04141, linear_loss=0.05114]
[2020-05-11 23:57:44.741]  Step 148105  [3.250 sec/step, loss=0.07877, avg_loss=0.09225, mel_loss=0.03449, linear_loss=0.04428]
[2020-05-11 23:57:46.376]  Step 148106  [3.257 sec/step, loss=0.09027, avg_loss=0.09232, mel_loss=0.04002, linear_loss=0.05025]
[2020-05-11 23:57:49.729]  Step 148107  [3.282 sec/step, loss=0.09931, avg_loss=0.09252, mel_loss=0.04517, linear_loss=0.05415]
[2020-05-11 23:57:50.679]  Step 148108  [3.237 sec/step, loss=0.08402, avg_loss=0.09236, mel_loss=0.03673, linear_loss=0.04729]
[2020-05-11 23:57:54.636]  Step 148109  [3.271 sec/step, loss=0.09992, avg_loss=0.09264, mel_loss=0.04548, linear_loss=0.05443]
[2020-05-11 23:57:59.293]  Step 148110  [3.285 sec/step, loss=0.09890, avg_loss=0.09264, mel_loss=0.04549, linear_loss=0.05341]
[2020-05-11 23:58:02.726]  Step 148111  [3.302 sec/step, loss=0.09699, avg_loss=0.09268, mel_loss=0.04420, linear_loss=0.05279]
[2020-05-11 23:58:04.345]  Generated 32 batches of size 32 in 1.614 sec
[2020-05-11 23:58:10.363]  Step 148112  [3.330 sec/step, loss=0.09966, avg_loss=0.09270, mel_loss=0.04650, linear_loss=0.05316]
[2020-05-11 23:58:17.049]  Step 148113  [3.367 sec/step, loss=0.09979, avg_loss=0.09272, mel_loss=0.04633, linear_loss=0.05346]
[2020-05-11 23:58:17.796]  Step 148114  [3.339 sec/step, loss=0.07813, avg_loss=0.09251, mel_loss=0.03429, linear_loss=0.04383]
[2020-05-11 23:58:31.628]  Step 148115  [3.462 sec/step, loss=0.07802, avg_loss=0.09240, mel_loss=0.03755, linear_loss=0.04048]
[2020-05-11 23:58:34.338]  Step 148116  [3.473 sec/step, loss=0.09591, avg_loss=0.09245, mel_loss=0.04334, linear_loss=0.05258]
[2020-05-11 23:58:35.661]  Step 148117  [3.447 sec/step, loss=0.09013, avg_loss=0.09236, mel_loss=0.03970, linear_loss=0.05043]
[2020-05-11 23:58:38.521]  Step 148118  [3.353 sec/step, loss=0.09467, avg_loss=0.09246, mel_loss=0.04287, linear_loss=0.05180]
[2020-05-11 23:58:39.971]  Step 148119  [3.324 sec/step, loss=0.09031, avg_loss=0.09235, mel_loss=0.03991, linear_loss=0.05040]
[2020-05-11 23:58:40.949]  Step 148120  [3.323 sec/step, loss=0.08475, avg_loss=0.09237, mel_loss=0.03706, linear_loss=0.04769]
[2020-05-11 23:58:42.950]  Step 148121  [3.308 sec/step, loss=0.09090, avg_loss=0.09232, mel_loss=0.04032, linear_loss=0.05058]
[2020-05-11 23:58:44.218]  Step 148122  [3.295 sec/step, loss=0.08951, avg_loss=0.09228, mel_loss=0.03942, linear_loss=0.05009]
[2020-05-11 23:58:45.579]  Step 148123  [3.221 sec/step, loss=0.08829, avg_loss=0.09221, mel_loss=0.03924, linear_loss=0.04905]
[2020-05-11 23:58:48.208]  Step 148124  [3.228 sec/step, loss=0.09358, avg_loss=0.09223, mel_loss=0.04202, linear_loss=0.05156]
[2020-05-11 23:58:52.412]  Step 148125  [3.258 sec/step, loss=0.09887, avg_loss=0.09234, mel_loss=0.04522, linear_loss=0.05365]
[2020-05-11 23:58:53.895]  Step 148126  [3.251 sec/step, loss=0.09154, avg_loss=0.09233, mel_loss=0.04073, linear_loss=0.05081]
[2020-05-11 23:59:01.235]  Step 148127  [3.251 sec/step, loss=0.09997, avg_loss=0.09233, mel_loss=0.04651, linear_loss=0.05345]
[2020-05-11 23:59:02.966]  Step 148128  [3.231 sec/step, loss=0.09239, avg_loss=0.09225, mel_loss=0.04118, linear_loss=0.05121]
[2020-05-11 23:59:07.482]  Step 148129  [3.256 sec/step, loss=0.09998, avg_loss=0.09232, mel_loss=0.04576, linear_loss=0.05422]
[2020-05-11 23:59:08.571]  Step 148130  [3.243 sec/step, loss=0.08459, avg_loss=0.09222, mel_loss=0.03681, linear_loss=0.04778]
[2020-05-11 23:59:09.397]  Step 148131  [3.211 sec/step, loss=0.07835, avg_loss=0.09203, mel_loss=0.03402, linear_loss=0.04433]
[2020-05-11 23:59:15.604]  Step 148132  [3.186 sec/step, loss=0.09874, avg_loss=0.09205, mel_loss=0.04586, linear_loss=0.05288]
[2020-05-11 23:59:18.966]  Step 148133  [3.178 sec/step, loss=0.09725, avg_loss=0.09205, mel_loss=0.04421, linear_loss=0.05304]
[2020-05-11 23:59:22.172]  Step 148134  [3.144 sec/step, loss=0.09954, avg_loss=0.09206, mel_loss=0.04521, linear_loss=0.05433]
[2020-05-11 23:59:25.950]  Step 148135  [3.109 sec/step, loss=0.09719, avg_loss=0.09202, mel_loss=0.04427, linear_loss=0.05291]
[2020-05-11 23:59:28.827]  Step 148136  [3.113 sec/step, loss=0.09607, avg_loss=0.09203, mel_loss=0.04329, linear_loss=0.05278]
[2020-05-11 23:59:30.714]  Step 148137  [3.119 sec/step, loss=0.09254, avg_loss=0.09207, mel_loss=0.04099, linear_loss=0.05155]
[2020-05-11 23:59:31.502]  Step 148138  [3.105 sec/step, loss=0.08067, avg_loss=0.09193, mel_loss=0.03540, linear_loss=0.04526]
[2020-05-11 23:59:32.061]  Step 148139  [3.102 sec/step, loss=0.07261, avg_loss=0.09187, mel_loss=0.03245, linear_loss=0.04015]
[2020-05-11 23:59:35.186]  Step 148140  [3.127 sec/step, loss=0.09812, avg_loss=0.09212, mel_loss=0.04481, linear_loss=0.05331]
[2020-05-11 23:59:36.404]  Step 148141  [3.120 sec/step, loss=0.08810, avg_loss=0.09207, mel_loss=0.03892, linear_loss=0.04918]
[2020-05-11 23:59:46.833]  Step 148142  [3.214 sec/step, loss=0.09884, avg_loss=0.09224, mel_loss=0.04632, linear_loss=0.05252]
[2020-05-11 23:59:54.726]  Step 148143  [3.156 sec/step, loss=0.09782, avg_loss=0.09247, mel_loss=0.04503, linear_loss=0.05278]
[2020-05-11 23:59:57.286]  Step 148144  [3.174 sec/step, loss=0.09612, avg_loss=0.09261, mel_loss=0.04304, linear_loss=0.05308]
[2020-05-11 23:59:57.509]  Generated 32 batches of size 32 in 2.774 sec
[2020-05-11 23:59:59.592]  Step 148145  [3.148 sec/step, loss=0.09420, avg_loss=0.09258, mel_loss=0.04254, linear_loss=0.05166]
[2020-05-12 00:00:05.506]  Step 148146  [3.171 sec/step, loss=0.09877, avg_loss=0.09254, mel_loss=0.04574, linear_loss=0.05303]
[2020-05-12 00:00:06.390]  Step 148147  [3.162 sec/step, loss=0.08407, avg_loss=0.09247, mel_loss=0.03668, linear_loss=0.04739]
[2020-05-12 00:00:19.749]  Step 148148  [3.280 sec/step, loss=0.08405, avg_loss=0.09240, mel_loss=0.03994, linear_loss=0.04411]
[2020-05-12 00:00:20.712]  Step 148149  [3.256 sec/step, loss=0.08890, avg_loss=0.09233, mel_loss=0.03931, linear_loss=0.04959]
[2020-05-12 00:00:23.346]  Step 148150  [3.272 sec/step, loss=0.09422, avg_loss=0.09240, mel_loss=0.04276, linear_loss=0.05146]
[2020-05-12 00:00:23.346]  Writing summary at step: 148150
[2020-05-12 00:00:25.609]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148150
[2020-05-12 00:00:26.976]  Saving audio and alignment...
[2020-05-12 00:00:32.577]  Input: 거기 분들은요 이러면 이분들의 눈빛이 막 초롱초롱 해지면서~________
[2020-05-12 00:00:34.027]  Step 148151  [3.255 sec/step, loss=0.08807, avg_loss=0.09231, mel_loss=0.03902, linear_loss=0.04905]
[2020-05-12 00:00:37.655]  Step 148152  [3.236 sec/step, loss=0.09896, avg_loss=0.09230, mel_loss=0.04499, linear_loss=0.05396]
[2020-05-12 00:00:38.178]  Step 148153  [3.196 sec/step, loss=0.07588, avg_loss=0.09207, mel_loss=0.03377, linear_loss=0.04211]
[2020-05-12 00:00:52.529]  Step 148154  [3.325 sec/step, loss=0.07996, avg_loss=0.09196, mel_loss=0.03838, linear_loss=0.04158]
[2020-05-12 00:00:53.636]  Step 148155  [3.317 sec/step, loss=0.08699, avg_loss=0.09191, mel_loss=0.03772, linear_loss=0.04927]
[2020-05-12 00:00:54.665]  Step 148156  [3.299 sec/step, loss=0.08315, avg_loss=0.09175, mel_loss=0.03643, linear_loss=0.04672]
[2020-05-12 00:00:56.605]  Step 148157  [3.291 sec/step, loss=0.09346, avg_loss=0.09173, mel_loss=0.04122, linear_loss=0.05224]
[2020-05-12 00:00:57.451]  Step 148158  [3.291 sec/step, loss=0.08197, avg_loss=0.09175, mel_loss=0.03586, linear_loss=0.04611]
[2020-05-12 00:01:01.758]  Step 148159  [3.279 sec/step, loss=0.09845, avg_loss=0.09174, mel_loss=0.04503, linear_loss=0.05342]
[2020-05-12 00:01:03.892]  Step 148160  [3.288 sec/step, loss=0.09306, avg_loss=0.09178, mel_loss=0.04160, linear_loss=0.05146]
[2020-05-12 00:01:09.895]  Step 148161  [3.337 sec/step, loss=0.09855, avg_loss=0.09188, mel_loss=0.04557, linear_loss=0.05298]
[2020-05-12 00:01:13.329]  Step 148162  [3.362 sec/step, loss=0.09614, avg_loss=0.09198, mel_loss=0.04328, linear_loss=0.05287]
[2020-05-12 00:01:15.676]  Step 148163  [3.244 sec/step, loss=0.09428, avg_loss=0.09213, mel_loss=0.04229, linear_loss=0.05199]
[2020-05-12 00:01:17.406]  Step 148164  [3.254 sec/step, loss=0.09186, avg_loss=0.09230, mel_loss=0.04031, linear_loss=0.05154]
[2020-05-12 00:01:21.428]  Step 148165  [3.286 sec/step, loss=0.09934, avg_loss=0.09245, mel_loss=0.04535, linear_loss=0.05399]
[2020-05-12 00:01:23.898]  Step 148166  [3.287 sec/step, loss=0.09305, avg_loss=0.09243, mel_loss=0.04171, linear_loss=0.05134]
[2020-05-12 00:01:28.391]  Step 148167  [3.303 sec/step, loss=0.09919, avg_loss=0.09244, mel_loss=0.04537, linear_loss=0.05381]
[2020-05-12 00:01:29.396]  Step 148168  [3.242 sec/step, loss=0.08386, avg_loss=0.09228, mel_loss=0.03666, linear_loss=0.04720]
[2020-05-12 00:01:34.317]  Step 148169  [3.257 sec/step, loss=0.10114, avg_loss=0.09229, mel_loss=0.04658, linear_loss=0.05456]
[2020-05-12 00:01:39.634]  Step 148170  [3.275 sec/step, loss=0.10020, avg_loss=0.09232, mel_loss=0.04614, linear_loss=0.05407]
[2020-05-12 00:01:40.924]  Step 148171  [3.274 sec/step, loss=0.08640, avg_loss=0.09228, mel_loss=0.03831, linear_loss=0.04809]
[2020-05-12 00:01:42.619]  Step 148172  [3.266 sec/step, loss=0.09212, avg_loss=0.09225, mel_loss=0.04062, linear_loss=0.05150]
[2020-05-12 00:01:44.024]  Step 148173  [3.240 sec/step, loss=0.08939, avg_loss=0.09214, mel_loss=0.03927, linear_loss=0.05012]
[2020-05-12 00:01:45.759]  Generated 32 batches of size 32 in 1.730 sec
[2020-05-12 00:01:46.960]  Step 148174  [3.255 sec/step, loss=0.09546, avg_loss=0.09222, mel_loss=0.04289, linear_loss=0.05257]
[2020-05-12 00:01:55.377]  Step 148175  [3.293 sec/step, loss=0.09811, avg_loss=0.09220, mel_loss=0.04591, linear_loss=0.05220]
[2020-05-12 00:01:58.478]  Step 148176  [3.272 sec/step, loss=0.09865, avg_loss=0.09219, mel_loss=0.04490, linear_loss=0.05376]
[2020-05-12 00:02:01.906]  Step 148177  [3.288 sec/step, loss=0.09770, avg_loss=0.09225, mel_loss=0.04409, linear_loss=0.05361]
[2020-05-12 00:02:09.284]  Step 148178  [3.340 sec/step, loss=0.10066, avg_loss=0.09232, mel_loss=0.04673, linear_loss=0.05393]
[2020-05-12 00:02:12.205]  Step 148179  [3.359 sec/step, loss=0.09803, avg_loss=0.09247, mel_loss=0.04424, linear_loss=0.05379]
[2020-05-12 00:02:14.213]  Step 148180  [3.337 sec/step, loss=0.09414, avg_loss=0.09241, mel_loss=0.04217, linear_loss=0.05197]
[2020-05-12 00:02:15.905]  Step 148181  [3.337 sec/step, loss=0.09085, avg_loss=0.09239, mel_loss=0.04037, linear_loss=0.05048]
[2020-05-12 00:02:16.557]  Step 148182  [3.323 sec/step, loss=0.07921, avg_loss=0.09225, mel_loss=0.03501, linear_loss=0.04420]
[2020-05-12 00:02:19.597]  Step 148183  [3.341 sec/step, loss=0.09688, avg_loss=0.09233, mel_loss=0.04391, linear_loss=0.05298]
[2020-05-12 00:02:24.352]  Step 148184  [3.359 sec/step, loss=0.09742, avg_loss=0.09234, mel_loss=0.04470, linear_loss=0.05273]
[2020-05-12 00:02:25.688]  Step 148185  [3.366 sec/step, loss=0.08468, avg_loss=0.09245, mel_loss=0.03719, linear_loss=0.04749]
[2020-05-12 00:02:27.221]  Step 148186  [3.294 sec/step, loss=0.09086, avg_loss=0.09237, mel_loss=0.04009, linear_loss=0.05077]
[2020-05-12 00:02:31.582]  Step 148187  [3.304 sec/step, loss=0.09987, avg_loss=0.09238, mel_loss=0.04581, linear_loss=0.05406]
[2020-05-12 00:02:36.873]  Step 148188  [3.294 sec/step, loss=0.09839, avg_loss=0.09237, mel_loss=0.04507, linear_loss=0.05332]
[2020-05-12 00:02:37.396]  Step 148189  [3.279 sec/step, loss=0.07562, avg_loss=0.09219, mel_loss=0.03360, linear_loss=0.04202]
[2020-05-12 00:02:39.431]  Step 148190  [3.283 sec/step, loss=0.09221, avg_loss=0.09218, mel_loss=0.04123, linear_loss=0.05098]
[2020-05-12 00:02:40.311]  Step 148191  [3.236 sec/step, loss=0.07923, avg_loss=0.09198, mel_loss=0.03444, linear_loss=0.04480]
[2020-05-12 00:02:42.219]  Step 148192  [3.249 sec/step, loss=0.09206, avg_loss=0.09215, mel_loss=0.04115, linear_loss=0.05091]
[2020-05-12 00:02:45.690]  Step 148193  [3.232 sec/step, loss=0.09691, avg_loss=0.09213, mel_loss=0.04385, linear_loss=0.05306]
[2020-05-12 00:02:52.471]  Step 148194  [3.288 sec/step, loss=0.09851, avg_loss=0.09226, mel_loss=0.04559, linear_loss=0.05292]
[2020-05-12 00:02:53.309]  Step 148195  [3.267 sec/step, loss=0.08144, avg_loss=0.09209, mel_loss=0.03568, linear_loss=0.04576]
[2020-05-12 00:03:00.556]  Step 148196  [3.315 sec/step, loss=0.10046, avg_loss=0.09217, mel_loss=0.04669, linear_loss=0.05378]
[2020-05-12 00:03:02.968]  Step 148197  [3.303 sec/step, loss=0.09204, avg_loss=0.09208, mel_loss=0.04109, linear_loss=0.05095]
[2020-05-12 00:03:06.472]  Step 148198  [3.325 sec/step, loss=0.09799, avg_loss=0.09219, mel_loss=0.04453, linear_loss=0.05346]
[2020-05-12 00:03:08.116]  Step 148199  [3.252 sec/step, loss=0.08837, avg_loss=0.09211, mel_loss=0.03948, linear_loss=0.04889]
[2020-05-12 00:03:09.529]  Step 148200  [3.247 sec/step, loss=0.08840, avg_loss=0.09207, mel_loss=0.03922, linear_loss=0.04918]
[2020-05-12 00:03:09.529]  Writing summary at step: 148200
[2020-05-12 00:03:10.381]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148200
[2020-05-12 00:03:11.808]  Saving audio and alignment...
[2020-05-12 00:03:15.635]  Input: 이 답변에 내용을 요약하자면요 정답~______
[2020-05-12 00:03:19.799]  Step 148201  [3.264 sec/step, loss=0.09682, avg_loss=0.09209, mel_loss=0.04410, linear_loss=0.05272]
[2020-05-12 00:03:23.523]  Step 148202  [3.280 sec/step, loss=0.09678, avg_loss=0.09212, mel_loss=0.04417, linear_loss=0.05261]
[2020-05-12 00:03:24.544]  Step 148203  [3.273 sec/step, loss=0.08276, avg_loss=0.09204, mel_loss=0.03641, linear_loss=0.04635]
[2020-05-12 00:03:26.338]  Generated 32 batches of size 32 in 1.787 sec
[2020-05-12 00:03:27.511]  Step 148204  [3.282 sec/step, loss=0.09482, avg_loss=0.09206, mel_loss=0.04292, linear_loss=0.05190]
[2020-05-12 00:03:36.373]  Step 148205  [3.363 sec/step, loss=0.09832, avg_loss=0.09226, mel_loss=0.04617, linear_loss=0.05216]
[2020-05-12 00:03:49.498]  Step 148206  [3.478 sec/step, loss=0.08364, avg_loss=0.09219, mel_loss=0.03971, linear_loss=0.04392]
[2020-05-12 00:03:51.255]  Step 148207  [3.462 sec/step, loss=0.09110, avg_loss=0.09211, mel_loss=0.04027, linear_loss=0.05083]
[2020-05-12 00:03:53.740]  Step 148208  [3.477 sec/step, loss=0.09530, avg_loss=0.09222, mel_loss=0.04280, linear_loss=0.05250]
[2020-05-12 00:03:59.485]  Step 148209  [3.495 sec/step, loss=0.10008, avg_loss=0.09222, mel_loss=0.04641, linear_loss=0.05367]
[2020-05-12 00:04:00.649]  Step 148210  [3.460 sec/step, loss=0.08464, avg_loss=0.09208, mel_loss=0.03725, linear_loss=0.04739]
[2020-05-12 00:04:03.210]  Step 148211  [3.451 sec/step, loss=0.09651, avg_loss=0.09208, mel_loss=0.04339, linear_loss=0.05312]
[2020-05-12 00:04:04.308]  Step 148212  [3.386 sec/step, loss=0.08744, avg_loss=0.09195, mel_loss=0.03845, linear_loss=0.04899]
[2020-05-12 00:04:05.803]  Step 148213  [3.334 sec/step, loss=0.08924, avg_loss=0.09185, mel_loss=0.03953, linear_loss=0.04971]
[2020-05-12 00:04:06.798]  Step 148214  [3.336 sec/step, loss=0.08079, avg_loss=0.09187, mel_loss=0.03535, linear_loss=0.04544]
[2020-05-12 00:04:12.373]  Step 148215  [3.254 sec/step, loss=0.09931, avg_loss=0.09209, mel_loss=0.04590, linear_loss=0.05341]
[2020-05-12 00:04:19.827]  Step 148216  [3.301 sec/step, loss=0.10057, avg_loss=0.09213, mel_loss=0.04702, linear_loss=0.05355]
[2020-05-12 00:04:22.233]  Step 148217  [3.312 sec/step, loss=0.09493, avg_loss=0.09218, mel_loss=0.04262, linear_loss=0.05231]
[2020-05-12 00:04:23.978]  Step 148218  [3.301 sec/step, loss=0.09172, avg_loss=0.09215, mel_loss=0.04076, linear_loss=0.05096]
[2020-05-12 00:04:25.797]  Step 148219  [3.305 sec/step, loss=0.09206, avg_loss=0.09217, mel_loss=0.04049, linear_loss=0.05156]
[2020-05-12 00:04:28.018]  Step 148220  [3.317 sec/step, loss=0.09227, avg_loss=0.09225, mel_loss=0.04140, linear_loss=0.05087]
[2020-05-12 00:04:29.632]  Step 148221  [3.313 sec/step, loss=0.09128, avg_loss=0.09225, mel_loss=0.04033, linear_loss=0.05095]
[2020-05-12 00:04:33.012]  Step 148222  [3.334 sec/step, loss=0.09453, avg_loss=0.09230, mel_loss=0.04285, linear_loss=0.05168]
[2020-05-12 00:04:35.008]  Step 148223  [3.341 sec/step, loss=0.09431, avg_loss=0.09236, mel_loss=0.04191, linear_loss=0.05240]
[2020-05-12 00:04:38.711]  Step 148224  [3.351 sec/step, loss=0.09983, avg_loss=0.09242, mel_loss=0.04514, linear_loss=0.05469]
[2020-05-12 00:04:39.522]  Step 148225  [3.317 sec/step, loss=0.07903, avg_loss=0.09222, mel_loss=0.03466, linear_loss=0.04438]
[2020-05-12 00:04:52.463]  Step 148226  [3.432 sec/step, loss=0.08708, avg_loss=0.09218, mel_loss=0.04152, linear_loss=0.04555]
[2020-05-12 00:04:57.532]  Step 148227  [3.409 sec/step, loss=0.09903, avg_loss=0.09217, mel_loss=0.04537, linear_loss=0.05365]
[2020-05-12 00:04:59.477]  Step 148228  [3.411 sec/step, loss=0.09213, avg_loss=0.09217, mel_loss=0.04098, linear_loss=0.05115]
[2020-05-12 00:05:00.103]  Step 148229  [3.373 sec/step, loss=0.07894, avg_loss=0.09196, mel_loss=0.03477, linear_loss=0.04417]
[2020-05-12 00:05:03.663]  Step 148230  [3.397 sec/step, loss=0.09806, avg_loss=0.09209, mel_loss=0.04444, linear_loss=0.05361]
[2020-05-12 00:05:06.300]  Step 148231  [3.415 sec/step, loss=0.09349, avg_loss=0.09224, mel_loss=0.04167, linear_loss=0.05181]
[2020-05-12 00:05:06.830]  Step 148232  [3.359 sec/step, loss=0.07294, avg_loss=0.09198, mel_loss=0.03259, linear_loss=0.04035]
[2020-05-12 00:05:07.918]  Step 148233  [3.336 sec/step, loss=0.08282, avg_loss=0.09184, mel_loss=0.03606, linear_loss=0.04676]
[2020-05-12 00:05:14.239]  Step 148234  [3.367 sec/step, loss=0.09860, avg_loss=0.09183, mel_loss=0.04565, linear_loss=0.05296]
[2020-05-12 00:05:17.357]  Step 148235  [3.360 sec/step, loss=0.09748, avg_loss=0.09183, mel_loss=0.04424, linear_loss=0.05324]
[2020-05-12 00:05:19.357]  Generated 32 batches of size 32 in 1.993 sec
[2020-05-12 00:05:25.760]  Step 148236  [3.416 sec/step, loss=0.09695, avg_loss=0.09184, mel_loss=0.04543, linear_loss=0.05152]
[2020-05-12 00:05:26.733]  Step 148237  [3.407 sec/step, loss=0.08479, avg_loss=0.09177, mel_loss=0.03719, linear_loss=0.04760]
[2020-05-12 00:05:29.612]  Step 148238  [3.427 sec/step, loss=0.09396, avg_loss=0.09190, mel_loss=0.04222, linear_loss=0.05174]
[2020-05-12 00:05:30.796]  Step 148239  [3.434 sec/step, loss=0.08555, avg_loss=0.09203, mel_loss=0.03747, linear_loss=0.04808]
[2020-05-12 00:05:33.855]  Step 148240  [3.433 sec/step, loss=0.09792, avg_loss=0.09203, mel_loss=0.04422, linear_loss=0.05371]
[2020-05-12 00:05:35.213]  Step 148241  [3.434 sec/step, loss=0.08658, avg_loss=0.09201, mel_loss=0.03831, linear_loss=0.04826]
[2020-05-12 00:05:39.470]  Step 148242  [3.373 sec/step, loss=0.09806, avg_loss=0.09200, mel_loss=0.04469, linear_loss=0.05337]
[2020-05-12 00:05:44.053]  Step 148243  [3.340 sec/step, loss=0.09982, avg_loss=0.09202, mel_loss=0.04571, linear_loss=0.05411]
[2020-05-12 00:05:45.348]  Step 148244  [3.327 sec/step, loss=0.08849, avg_loss=0.09195, mel_loss=0.03906, linear_loss=0.04943]
[2020-05-12 00:05:48.320]  Step 148245  [3.334 sec/step, loss=0.09706, avg_loss=0.09197, mel_loss=0.04395, linear_loss=0.05311]
[2020-05-12 00:05:50.167]  Step 148246  [3.293 sec/step, loss=0.08884, avg_loss=0.09188, mel_loss=0.03925, linear_loss=0.04959]
[2020-05-12 00:05:52.871]  Step 148247  [3.311 sec/step, loss=0.09266, avg_loss=0.09196, mel_loss=0.04164, linear_loss=0.05101]
[2020-05-12 00:06:00.449]  Step 148248  [3.253 sec/step, loss=0.09721, avg_loss=0.09209, mel_loss=0.04506, linear_loss=0.05214]
[2020-05-12 00:06:01.781]  Step 148249  [3.257 sec/step, loss=0.08590, avg_loss=0.09206, mel_loss=0.03822, linear_loss=0.04767]
[2020-05-12 00:06:03.977]  Step 148250  [3.253 sec/step, loss=0.09322, avg_loss=0.09205, mel_loss=0.04178, linear_loss=0.05144]
[2020-05-12 00:06:03.977]  Writing summary at step: 148250
[2020-05-12 00:06:18.589]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148250
[2020-05-12 00:06:20.104]  Saving audio and alignment...
[2020-05-12 00:06:23.503]  Input: 뉴스를 뉴스 답게 만드는 것 바로~____________
[2020-05-12 00:06:27.219]  Step 148251  [3.275 sec/step, loss=0.09681, avg_loss=0.09214, mel_loss=0.04408, linear_loss=0.05272]
[2020-05-12 00:06:30.847]  Step 148252  [3.275 sec/step, loss=0.09791, avg_loss=0.09213, mel_loss=0.04434, linear_loss=0.05358]
[2020-05-12 00:06:36.452]  Step 148253  [3.326 sec/step, loss=0.10087, avg_loss=0.09238, mel_loss=0.04659, linear_loss=0.05428]
[2020-05-12 00:06:39.572]  Step 148254  [3.214 sec/step, loss=0.09631, avg_loss=0.09254, mel_loss=0.04353, linear_loss=0.05278]
[2020-05-12 00:06:41.983]  Step 148255  [3.227 sec/step, loss=0.09576, avg_loss=0.09263, mel_loss=0.04293, linear_loss=0.05283]
[2020-05-12 00:06:42.762]  Step 148256  [3.224 sec/step, loss=0.07485, avg_loss=0.09255, mel_loss=0.03242, linear_loss=0.04243]
[2020-05-12 00:06:47.253]  Step 148257  [3.250 sec/step, loss=0.09803, avg_loss=0.09259, mel_loss=0.04473, linear_loss=0.05330]
[2020-05-12 00:06:50.238]  Step 148258  [3.271 sec/step, loss=0.09521, avg_loss=0.09273, mel_loss=0.04305, linear_loss=0.05216]
[2020-05-12 00:06:59.499]  Step 148259  [3.321 sec/step, loss=0.09799, avg_loss=0.09272, mel_loss=0.04580, linear_loss=0.05219]
[2020-05-12 00:07:02.939]  Step 148260  [3.334 sec/step, loss=0.09578, avg_loss=0.09275, mel_loss=0.04353, linear_loss=0.05225]
[2020-05-12 00:07:04.534]  Step 148261  [3.290 sec/step, loss=0.09316, avg_loss=0.09269, mel_loss=0.04112, linear_loss=0.05205]
[2020-05-12 00:07:09.852]  Step 148262  [3.309 sec/step, loss=0.09754, avg_loss=0.09271, mel_loss=0.04479, linear_loss=0.05276]
[2020-05-12 00:07:16.494]  Step 148263  [3.352 sec/step, loss=0.09929, avg_loss=0.09276, mel_loss=0.04605, linear_loss=0.05324]
[2020-05-12 00:07:18.756]  Step 148264  [3.357 sec/step, loss=0.09181, avg_loss=0.09276, mel_loss=0.04124, linear_loss=0.05057]
[2020-05-12 00:07:19.567]  Step 148265  [3.325 sec/step, loss=0.08081, avg_loss=0.09257, mel_loss=0.03536, linear_loss=0.04545]
[2020-05-12 00:07:20.811]  Step 148266  [3.313 sec/step, loss=0.08629, avg_loss=0.09251, mel_loss=0.03772, linear_loss=0.04857]
[2020-05-12 00:07:21.606]  Generated 32 batches of size 32 in 2.033 sec
[2020-05-12 00:07:21.963]  Step 148267  [3.279 sec/step, loss=0.08415, avg_loss=0.09236, mel_loss=0.03655, linear_loss=0.04760]
[2020-05-12 00:07:23.591]  Step 148268  [3.285 sec/step, loss=0.08736, avg_loss=0.09239, mel_loss=0.03852, linear_loss=0.04884]
[2020-05-12 00:07:24.590]  Step 148269  [3.246 sec/step, loss=0.08228, avg_loss=0.09220, mel_loss=0.03566, linear_loss=0.04663]
[2020-05-12 00:07:28.884]  Step 148270  [3.236 sec/step, loss=0.09837, avg_loss=0.09218, mel_loss=0.04480, linear_loss=0.05357]
[2020-05-12 00:07:29.873]  Step 148271  [3.233 sec/step, loss=0.08246, avg_loss=0.09214, mel_loss=0.03627, linear_loss=0.04620]
[2020-05-12 00:07:31.619]  Step 148272  [3.233 sec/step, loss=0.09133, avg_loss=0.09214, mel_loss=0.04051, linear_loss=0.05082]
[2020-05-12 00:07:32.978]  Step 148273  [3.233 sec/step, loss=0.08698, avg_loss=0.09211, mel_loss=0.03844, linear_loss=0.04854]
[2020-05-12 00:07:33.539]  Step 148274  [3.209 sec/step, loss=0.07128, avg_loss=0.09187, mel_loss=0.03163, linear_loss=0.03966]
[2020-05-12 00:07:34.641]  Step 148275  [3.136 sec/step, loss=0.08679, avg_loss=0.09176, mel_loss=0.03795, linear_loss=0.04884]
[2020-05-12 00:07:36.332]  Step 148276  [3.122 sec/step, loss=0.09180, avg_loss=0.09169, mel_loss=0.04086, linear_loss=0.05095]
[2020-05-12 00:07:37.705]  Step 148277  [3.101 sec/step, loss=0.08776, avg_loss=0.09159, mel_loss=0.03866, linear_loss=0.04910]
[2020-05-12 00:07:44.026]  Step 148278  [3.091 sec/step, loss=0.09852, avg_loss=0.09157, mel_loss=0.04572, linear_loss=0.05281]
[2020-05-12 00:07:47.666]  Step 148279  [3.098 sec/step, loss=0.10057, avg_loss=0.09159, mel_loss=0.04561, linear_loss=0.05496]
[2020-05-12 00:07:51.088]  Step 148280  [3.112 sec/step, loss=0.09578, avg_loss=0.09161, mel_loss=0.04319, linear_loss=0.05259]
[2020-05-12 00:07:55.214]  Step 148281  [3.137 sec/step, loss=0.09920, avg_loss=0.09169, mel_loss=0.04503, linear_loss=0.05417]
[2020-05-12 00:07:56.230]  Step 148282  [3.140 sec/step, loss=0.08493, avg_loss=0.09175, mel_loss=0.03736, linear_loss=0.04756]
[2020-05-12 00:07:58.868]  Step 148283  [3.136 sec/step, loss=0.09565, avg_loss=0.09174, mel_loss=0.04291, linear_loss=0.05273]
[2020-05-12 00:08:00.796]  Step 148284  [3.108 sec/step, loss=0.09238, avg_loss=0.09169, mel_loss=0.04123, linear_loss=0.05115]
[2020-05-12 00:08:03.198]  Step 148285  [3.119 sec/step, loss=0.09471, avg_loss=0.09179, mel_loss=0.04235, linear_loss=0.05236]
[2020-05-12 00:08:07.829]  Step 148286  [3.150 sec/step, loss=0.10079, avg_loss=0.09189, mel_loss=0.04598, linear_loss=0.05481]
[2020-05-12 00:08:11.293]  Step 148287  [3.141 sec/step, loss=0.09839, avg_loss=0.09187, mel_loss=0.04465, linear_loss=0.05375]
[2020-05-12 00:08:12.112]  Step 148288  [3.096 sec/step, loss=0.07858, avg_loss=0.09167, mel_loss=0.03433, linear_loss=0.04424]
[2020-05-12 00:08:19.389]  Step 148289  [3.163 sec/step, loss=0.10111, avg_loss=0.09193, mel_loss=0.04709, linear_loss=0.05402]
[2020-05-12 00:08:24.931]  Step 148290  [3.198 sec/step, loss=0.09827, avg_loss=0.09199, mel_loss=0.04514, linear_loss=0.05313]
[2020-05-12 00:08:29.011]  Step 148291  [3.230 sec/step, loss=0.09919, avg_loss=0.09219, mel_loss=0.04530, linear_loss=0.05389]
[2020-05-12 00:08:31.968]  Step 148292  [3.241 sec/step, loss=0.09692, avg_loss=0.09224, mel_loss=0.04370, linear_loss=0.05322]
[2020-05-12 00:08:33.977]  Step 148293  [3.226 sec/step, loss=0.09374, avg_loss=0.09221, mel_loss=0.04176, linear_loss=0.05198]
[2020-05-12 00:08:42.612]  Step 148294  [3.245 sec/step, loss=0.09825, avg_loss=0.09220, mel_loss=0.04621, linear_loss=0.05203]
[2020-05-12 00:08:43.447]  Step 148295  [3.245 sec/step, loss=0.07960, avg_loss=0.09218, mel_loss=0.03505, linear_loss=0.04455]
[2020-05-12 00:08:45.652]  Step 148296  [3.194 sec/step, loss=0.09317, avg_loss=0.09211, mel_loss=0.04161, linear_loss=0.05156]
[2020-05-12 00:08:48.188]  Step 148297  [3.196 sec/step, loss=0.09398, avg_loss=0.09213, mel_loss=0.04204, linear_loss=0.05195]
[2020-05-12 00:08:49.830]  Generated 32 batches of size 32 in 1.637 sec
[2020-05-12 00:09:00.655]  Step 148298  [3.285 sec/step, loss=0.08759, avg_loss=0.09203, mel_loss=0.04180, linear_loss=0.04579]
[2020-05-12 00:09:02.408]  Step 148299  [3.286 sec/step, loss=0.09072, avg_loss=0.09205, mel_loss=0.04003, linear_loss=0.05069]
[2020-05-12 00:09:03.649]  Step 148300  [3.285 sec/step, loss=0.08463, avg_loss=0.09201, mel_loss=0.03750, linear_loss=0.04714]
[2020-05-12 00:09:03.649]  Writing summary at step: 148300
[2020-05-12 00:09:04.534]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148300
[2020-05-12 00:09:05.940]  Saving audio and alignment...
[2020-05-12 00:09:08.571]  Input: 이 등장하는 쪽으로~_____________
[2020-05-12 00:09:11.712]  Step 148301  [3.274 sec/step, loss=0.09966, avg_loss=0.09204, mel_loss=0.04475, linear_loss=0.05491]
[2020-05-12 00:09:13.278]  Step 148302  [3.253 sec/step, loss=0.08817, avg_loss=0.09196, mel_loss=0.03916, linear_loss=0.04901]
[2020-05-12 00:09:13.828]  Step 148303  [3.248 sec/step, loss=0.07525, avg_loss=0.09188, mel_loss=0.03373, linear_loss=0.04152]
[2020-05-12 00:09:19.011]  Step 148304  [3.270 sec/step, loss=0.09909, avg_loss=0.09192, mel_loss=0.04552, linear_loss=0.05358]
[2020-05-12 00:09:21.397]  Step 148305  [3.206 sec/step, loss=0.09388, avg_loss=0.09188, mel_loss=0.04192, linear_loss=0.05196]
[2020-05-12 00:09:25.148]  Step 148306  [3.112 sec/step, loss=0.09716, avg_loss=0.09201, mel_loss=0.04414, linear_loss=0.05303]
[2020-05-12 00:09:27.334]  Step 148307  [3.116 sec/step, loss=0.09236, avg_loss=0.09203, mel_loss=0.04142, linear_loss=0.05094]
[2020-05-12 00:09:30.759]  Step 148308  [3.125 sec/step, loss=0.09621, avg_loss=0.09204, mel_loss=0.04362, linear_loss=0.05259]
[2020-05-12 00:09:38.226]  Step 148309  [3.143 sec/step, loss=0.09844, avg_loss=0.09202, mel_loss=0.04570, linear_loss=0.05274]
[2020-05-12 00:09:39.443]  Step 148310  [3.143 sec/step, loss=0.08503, avg_loss=0.09202, mel_loss=0.03709, linear_loss=0.04795]
[2020-05-12 00:09:40.694]  Step 148311  [3.130 sec/step, loss=0.08797, avg_loss=0.09194, mel_loss=0.03863, linear_loss=0.04935]
[2020-05-12 00:09:41.330]  Step 148312  [3.125 sec/step, loss=0.07774, avg_loss=0.09184, mel_loss=0.03352, linear_loss=0.04422]
[2020-05-12 00:09:54.285]  Step 148313  [3.240 sec/step, loss=0.08305, avg_loss=0.09178, mel_loss=0.03965, linear_loss=0.04340]
[2020-05-12 00:09:56.949]  Step 148314  [3.257 sec/step, loss=0.09530, avg_loss=0.09192, mel_loss=0.04285, linear_loss=0.05245]
[2020-05-12 00:10:04.552]  Step 148315  [3.277 sec/step, loss=0.09765, avg_loss=0.09191, mel_loss=0.04480, linear_loss=0.05285]
[2020-05-12 00:10:05.913]  Step 148316  [3.216 sec/step, loss=0.08099, avg_loss=0.09171, mel_loss=0.03508, linear_loss=0.04591]
[2020-05-12 00:10:07.115]  Step 148317  [3.204 sec/step, loss=0.07790, avg_loss=0.09154, mel_loss=0.03385, linear_loss=0.04404]
[2020-05-12 00:10:13.634]  Step 148318  [3.252 sec/step, loss=0.09830, avg_loss=0.09161, mel_loss=0.04486, linear_loss=0.05344]
[2020-05-12 00:10:16.676]  Step 148319  [3.264 sec/step, loss=0.09775, avg_loss=0.09166, mel_loss=0.04404, linear_loss=0.05371]
[2020-05-12 00:10:18.639]  Step 148320  [3.261 sec/step, loss=0.08993, avg_loss=0.09164, mel_loss=0.04010, linear_loss=0.04983]
[2020-05-12 00:10:19.692]  Step 148321  [3.256 sec/step, loss=0.08366, avg_loss=0.09156, mel_loss=0.03654, linear_loss=0.04712]
[2020-05-12 00:10:20.664]  Step 148322  [3.232 sec/step, loss=0.08545, avg_loss=0.09147, mel_loss=0.03748, linear_loss=0.04797]
[2020-05-12 00:10:26.973]  Step 148323  [3.275 sec/step, loss=0.09721, avg_loss=0.09150, mel_loss=0.04501, linear_loss=0.05221]
[2020-05-12 00:10:28.430]  Step 148324  [3.252 sec/step, loss=0.08864, avg_loss=0.09139, mel_loss=0.03922, linear_loss=0.04942]
[2020-05-12 00:10:30.434]  Step 148325  [3.264 sec/step, loss=0.09260, avg_loss=0.09153, mel_loss=0.04134, linear_loss=0.05126]
[2020-05-12 00:10:33.438]  Step 148326  [3.165 sec/step, loss=0.09911, avg_loss=0.09165, mel_loss=0.04482, linear_loss=0.05428]
[2020-05-12 00:10:34.762]  Step 148327  [3.128 sec/step, loss=0.08790, avg_loss=0.09154, mel_loss=0.03863, linear_loss=0.04927]
[2020-05-12 00:10:36.450]  Generated 32 batches of size 32 in 1.682 sec
[2020-05-12 00:10:40.279]  Step 148328  [3.163 sec/step, loss=0.09915, avg_loss=0.09161, mel_loss=0.04566, linear_loss=0.05349]
[2020-05-12 00:10:42.104]  Step 148329  [3.175 sec/step, loss=0.09274, avg_loss=0.09174, mel_loss=0.04096, linear_loss=0.05178]
[2020-05-12 00:10:42.664]  Step 148330  [3.145 sec/step, loss=0.07300, avg_loss=0.09149, mel_loss=0.03221, linear_loss=0.04079]
[2020-05-12 00:10:46.093]  Step 148331  [3.153 sec/step, loss=0.09629, avg_loss=0.09152, mel_loss=0.04361, linear_loss=0.05268]
[2020-05-12 00:10:47.835]  Step 148332  [3.165 sec/step, loss=0.09011, avg_loss=0.09169, mel_loss=0.03995, linear_loss=0.05016]
[2020-05-12 00:10:49.493]  Step 148333  [3.171 sec/step, loss=0.08805, avg_loss=0.09174, mel_loss=0.03899, linear_loss=0.04906]
[2020-05-12 00:10:53.702]  Step 148334  [3.150 sec/step, loss=0.09800, avg_loss=0.09174, mel_loss=0.04459, linear_loss=0.05342]
[2020-05-12 00:10:56.499]  Step 148335  [3.147 sec/step, loss=0.09415, avg_loss=0.09171, mel_loss=0.04212, linear_loss=0.05203]
[2020-05-12 00:11:05.255]  Step 148336  [3.150 sec/step, loss=0.09854, avg_loss=0.09172, mel_loss=0.04608, linear_loss=0.05246]
[2020-05-12 00:11:06.085]  Step 148337  [3.149 sec/step, loss=0.07952, avg_loss=0.09167, mel_loss=0.03455, linear_loss=0.04496]
[2020-05-12 00:11:07.184]  Step 148338  [3.131 sec/step, loss=0.08702, avg_loss=0.09160, mel_loss=0.03771, linear_loss=0.04931]
[2020-05-12 00:11:10.094]  Step 148339  [3.148 sec/step, loss=0.09379, avg_loss=0.09168, mel_loss=0.04219, linear_loss=0.05160]
[2020-05-12 00:11:11.968]  Step 148340  [3.136 sec/step, loss=0.08960, avg_loss=0.09160, mel_loss=0.03975, linear_loss=0.04985]
[2020-05-12 00:11:14.198]  Step 148341  [3.145 sec/step, loss=0.09280, avg_loss=0.09166, mel_loss=0.04177, linear_loss=0.05103]
[2020-05-12 00:11:15.650]  Step 148342  [3.117 sec/step, loss=0.08971, avg_loss=0.09158, mel_loss=0.03964, linear_loss=0.05007]
[2020-05-12 00:11:18.047]  Step 148343  [3.095 sec/step, loss=0.09567, avg_loss=0.09154, mel_loss=0.04253, linear_loss=0.05314]
[2020-05-12 00:11:25.401]  Step 148344  [3.156 sec/step, loss=0.10109, avg_loss=0.09166, mel_loss=0.04730, linear_loss=0.05379]
[2020-05-12 00:11:28.449]  Step 148345  [3.157 sec/step, loss=0.09697, avg_loss=0.09166, mel_loss=0.04366, linear_loss=0.05331]
[2020-05-12 00:11:37.134]  Step 148346  [3.225 sec/step, loss=0.09666, avg_loss=0.09174, mel_loss=0.04504, linear_loss=0.05162]
[2020-05-12 00:11:41.257]  Step 148347  [3.239 sec/step, loss=0.09703, avg_loss=0.09178, mel_loss=0.04441, linear_loss=0.05263]
[2020-05-12 00:11:42.433]  Step 148348  [3.175 sec/step, loss=0.08551, avg_loss=0.09167, mel_loss=0.03796, linear_loss=0.04755]
[2020-05-12 00:11:45.642]  Step 148349  [3.194 sec/step, loss=0.09662, avg_loss=0.09177, mel_loss=0.04361, linear_loss=0.05301]
[2020-05-12 00:11:47.048]  Step 148350  [3.186 sec/step, loss=0.08519, avg_loss=0.09169, mel_loss=0.03785, linear_loss=0.04734]
[2020-05-12 00:11:47.048]  Writing summary at step: 148350
[2020-05-12 00:11:48.652]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148350
[2020-05-12 00:11:50.050]  Saving audio and alignment...
[2020-05-12 00:11:54.208]  Input: 그래서 우서비가 더 애틋한 집~___________________________
[2020-05-12 00:11:59.987]  Step 148351  [3.207 sec/step, loss=0.10074, avg_loss=0.09173, mel_loss=0.04655, linear_loss=0.05420]
[2020-05-12 00:12:01.065]  Step 148352  [3.181 sec/step, loss=0.08419, avg_loss=0.09159, mel_loss=0.03666, linear_loss=0.04753]
[2020-05-12 00:12:04.685]  Step 148353  [3.161 sec/step, loss=0.10002, avg_loss=0.09159, mel_loss=0.04550, linear_loss=0.05452]
[2020-05-12 00:12:05.762]  Step 148354  [3.141 sec/step, loss=0.08361, avg_loss=0.09146, mel_loss=0.03653, linear_loss=0.04708]
[2020-05-12 00:12:08.029]  Step 148355  [3.139 sec/step, loss=0.09119, avg_loss=0.09141, mel_loss=0.04059, linear_loss=0.05059]
[2020-05-12 00:12:12.429]  Step 148356  [3.176 sec/step, loss=0.10121, avg_loss=0.09168, mel_loss=0.04649, linear_loss=0.05473]
[2020-05-12 00:12:19.193]  Step 148357  [3.198 sec/step, loss=0.09999, avg_loss=0.09170, mel_loss=0.04629, linear_loss=0.05370]
[2020-05-12 00:12:20.031]  Step 148358  [3.177 sec/step, loss=0.07849, avg_loss=0.09153, mel_loss=0.03390, linear_loss=0.04458]
[2020-05-12 00:12:20.623]  Step 148359  [3.090 sec/step, loss=0.07203, avg_loss=0.09127, mel_loss=0.03262, linear_loss=0.03941]
[2020-05-12 00:12:20.941]  Generated 32 batches of size 32 in 1.741 sec
[2020-05-12 00:12:34.751]  Step 148360  [3.197 sec/step, loss=0.07673, avg_loss=0.09108, mel_loss=0.03662, linear_loss=0.04011]
[2020-05-12 00:12:38.446]  Step 148361  [3.218 sec/step, loss=0.09851, avg_loss=0.09113, mel_loss=0.04462, linear_loss=0.05389]
[2020-05-12 00:12:40.198]  Step 148362  [3.182 sec/step, loss=0.09162, avg_loss=0.09107, mel_loss=0.04061, linear_loss=0.05101]
[2020-05-12 00:12:44.935]  Step 148363  [3.163 sec/step, loss=0.09811, avg_loss=0.09106, mel_loss=0.04471, linear_loss=0.05340]
[2020-05-12 00:12:46.944]  Step 148364  [3.161 sec/step, loss=0.09210, avg_loss=0.09106, mel_loss=0.04091, linear_loss=0.05119]
[2020-05-12 00:12:50.365]  Step 148365  [3.187 sec/step, loss=0.09557, avg_loss=0.09121, mel_loss=0.04324, linear_loss=0.05234]
[2020-05-12 00:12:55.745]  Step 148366  [3.228 sec/step, loss=0.09996, avg_loss=0.09135, mel_loss=0.04593, linear_loss=0.05403]
[2020-05-12 00:12:56.307]  Step 148367  [3.222 sec/step, loss=0.07084, avg_loss=0.09122, mel_loss=0.03124, linear_loss=0.03960]
[2020-05-12 00:12:57.869]  Step 148368  [3.222 sec/step, loss=0.08931, avg_loss=0.09124, mel_loss=0.03952, linear_loss=0.04980]
[2020-05-12 00:13:00.217]  Step 148369  [3.235 sec/step, loss=0.09226, avg_loss=0.09134, mel_loss=0.04128, linear_loss=0.05098]
[2020-05-12 00:13:02.283]  Step 148370  [3.213 sec/step, loss=0.09384, avg_loss=0.09129, mel_loss=0.04188, linear_loss=0.05196]
[2020-05-12 00:13:08.522]  Step 148371  [3.265 sec/step, loss=0.09696, avg_loss=0.09144, mel_loss=0.04475, linear_loss=0.05221]
[2020-05-12 00:13:11.904]  Step 148372  [3.282 sec/step, loss=0.09759, avg_loss=0.09150, mel_loss=0.04420, linear_loss=0.05339]
[2020-05-12 00:13:13.005]  Step 148373  [3.279 sec/step, loss=0.08612, avg_loss=0.09149, mel_loss=0.03743, linear_loss=0.04869]
[2020-05-12 00:13:17.247]  Step 148374  [3.316 sec/step, loss=0.09828, avg_loss=0.09176, mel_loss=0.04476, linear_loss=0.05352]
[2020-05-12 00:13:18.213]  Step 148375  [3.315 sec/step, loss=0.08394, avg_loss=0.09173, mel_loss=0.03677, linear_loss=0.04717]
[2020-05-12 00:13:23.055]  Step 148376  [3.346 sec/step, loss=0.09881, avg_loss=0.09180, mel_loss=0.04537, linear_loss=0.05344]
[2020-05-12 00:13:24.666]  Step 148377  [3.349 sec/step, loss=0.09373, avg_loss=0.09186, mel_loss=0.04168, linear_loss=0.05205]
[2020-05-12 00:13:29.245]  Step 148378  [3.331 sec/step, loss=0.09904, avg_loss=0.09187, mel_loss=0.04509, linear_loss=0.05394]
[2020-05-12 00:13:30.053]  Step 148379  [3.303 sec/step, loss=0.08058, avg_loss=0.09167, mel_loss=0.03536, linear_loss=0.04522]
[2020-05-12 00:13:31.813]  Step 148380  [3.286 sec/step, loss=0.09099, avg_loss=0.09162, mel_loss=0.04005, linear_loss=0.05094]
[2020-05-12 00:13:32.975]  Step 148381  [3.257 sec/step, loss=0.08674, avg_loss=0.09149, mel_loss=0.03828, linear_loss=0.04846]
[2020-05-12 00:13:41.612]  Step 148382  [3.333 sec/step, loss=0.09687, avg_loss=0.09161, mel_loss=0.04523, linear_loss=0.05164]
[2020-05-12 00:13:44.372]  Step 148383  [3.334 sec/step, loss=0.09323, avg_loss=0.09159, mel_loss=0.04194, linear_loss=0.05129]
[2020-05-12 00:13:48.407]  Step 148384  [3.355 sec/step, loss=0.09957, avg_loss=0.09166, mel_loss=0.04536, linear_loss=0.05421]
[2020-05-12 00:13:51.283]  Step 148385  [3.360 sec/step, loss=0.09577, avg_loss=0.09167, mel_loss=0.04316, linear_loss=0.05261]
[2020-05-12 00:13:52.651]  Step 148386  [3.327 sec/step, loss=0.08729, avg_loss=0.09154, mel_loss=0.03832, linear_loss=0.04897]
[2020-05-12 00:13:55.802]  Step 148387  [3.324 sec/step, loss=0.09623, avg_loss=0.09151, mel_loss=0.04343, linear_loss=0.05280]
[2020-05-12 00:13:56.639]  Step 148388  [3.324 sec/step, loss=0.07816, avg_loss=0.09151, mel_loss=0.03436, linear_loss=0.04380]
[2020-05-12 00:13:58.012]  Step 148389  [3.265 sec/step, loss=0.08894, avg_loss=0.09139, mel_loss=0.03921, linear_loss=0.04973]
[2020-05-12 00:13:59.697]  Generated 32 batches of size 32 in 1.681 sec
[2020-05-12 00:14:00.018]  Step 148390  [3.230 sec/step, loss=0.09031, avg_loss=0.09131, mel_loss=0.03990, linear_loss=0.05041]
[2020-05-12 00:14:01.012]  Step 148391  [3.199 sec/step, loss=0.08184, avg_loss=0.09114, mel_loss=0.03555, linear_loss=0.04629]
[2020-05-12 00:14:03.003]  Step 148392  [3.189 sec/step, loss=0.09351, avg_loss=0.09110, mel_loss=0.04159, linear_loss=0.05192]
[2020-05-12 00:14:06.773]  Step 148393  [3.207 sec/step, loss=0.09655, avg_loss=0.09113, mel_loss=0.04365, linear_loss=0.05290]
[2020-05-12 00:14:09.235]  Step 148394  [3.145 sec/step, loss=0.09311, avg_loss=0.09108, mel_loss=0.04143, linear_loss=0.05168]
[2020-05-12 00:14:23.533]  Step 148395  [3.280 sec/step, loss=0.07787, avg_loss=0.09106, mel_loss=0.03727, linear_loss=0.04059]
[2020-05-12 00:14:30.935]  Step 148396  [3.332 sec/step, loss=0.09982, avg_loss=0.09113, mel_loss=0.04626, linear_loss=0.05356]
[2020-05-12 00:14:36.234]  Step 148397  [3.359 sec/step, loss=0.09764, avg_loss=0.09116, mel_loss=0.04493, linear_loss=0.05271]
[2020-05-12 00:14:39.829]  Step 148398  [3.271 sec/step, loss=0.09724, avg_loss=0.09126, mel_loss=0.04403, linear_loss=0.05321]
[2020-05-12 00:14:52.137]  Step 148399  [3.376 sec/step, loss=0.08953, avg_loss=0.09125, mel_loss=0.04262, linear_loss=0.04691]
[2020-05-12 00:14:56.901]  Step 148400  [3.411 sec/step, loss=0.09582, avg_loss=0.09136, mel_loss=0.04356, linear_loss=0.05226]
[2020-05-12 00:14:56.901]  Writing summary at step: 148400
[2020-05-12 00:14:59.510]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148400
[2020-05-12 00:15:00.926]  Saving audio and alignment...
[2020-05-12 00:15:03.576]  Input: 키워드 앞에서는 반드시~________
[2020-05-12 00:15:04.611]  Step 148401  [3.390 sec/step, loss=0.08686, avg_loss=0.09123, mel_loss=0.03792, linear_loss=0.04893]
[2020-05-12 00:15:06.216]  Step 148402  [3.391 sec/step, loss=0.08896, avg_loss=0.09124, mel_loss=0.03954, linear_loss=0.04942]
[2020-05-12 00:15:08.983]  Step 148403  [3.413 sec/step, loss=0.09430, avg_loss=0.09143, mel_loss=0.04223, linear_loss=0.05207]
[2020-05-12 00:15:16.647]  Step 148404  [3.438 sec/step, loss=0.09909, avg_loss=0.09143, mel_loss=0.04606, linear_loss=0.05304]
[2020-05-12 00:15:18.479]  Step 148405  [3.432 sec/step, loss=0.09004, avg_loss=0.09139, mel_loss=0.03981, linear_loss=0.05023]
[2020-05-12 00:15:23.744]  Step 148406  [3.447 sec/step, loss=0.09813, avg_loss=0.09140, mel_loss=0.04494, linear_loss=0.05319]
[2020-05-12 00:15:27.173]  Step 148407  [3.460 sec/step, loss=0.09415, avg_loss=0.09142, mel_loss=0.04270, linear_loss=0.05145]
[2020-05-12 00:15:27.922]  Step 148408  [3.433 sec/step, loss=0.08152, avg_loss=0.09127, mel_loss=0.03576, linear_loss=0.04577]
[2020-05-12 00:15:29.216]  Step 148409  [3.371 sec/step, loss=0.08671, avg_loss=0.09116, mel_loss=0.03809, linear_loss=0.04863]
[2020-05-12 00:15:30.952]  Step 148410  [3.376 sec/step, loss=0.09020, avg_loss=0.09121, mel_loss=0.03967, linear_loss=0.05053]
[2020-05-12 00:15:34.097]  Step 148411  [3.395 sec/step, loss=0.09721, avg_loss=0.09130, mel_loss=0.04412, linear_loss=0.05309]
[2020-05-12 00:15:34.948]  Step 148412  [3.398 sec/step, loss=0.08009, avg_loss=0.09132, mel_loss=0.03466, linear_loss=0.04542]
[2020-05-12 00:15:35.768]  Step 148413  [3.276 sec/step, loss=0.07777, avg_loss=0.09127, mel_loss=0.03360, linear_loss=0.04417]
[2020-05-12 00:15:37.746]  Step 148414  [3.269 sec/step, loss=0.09338, avg_loss=0.09125, mel_loss=0.04145, linear_loss=0.05193]
[2020-05-12 00:15:39.114]  Step 148415  [3.207 sec/step, loss=0.08771, avg_loss=0.09115, mel_loss=0.03863, linear_loss=0.04908]
[2020-05-12 00:15:45.533]  Step 148416  [3.258 sec/step, loss=0.10046, avg_loss=0.09135, mel_loss=0.04652, linear_loss=0.05394]
[2020-05-12 00:15:49.690]  Step 148417  [3.287 sec/step, loss=0.09742, avg_loss=0.09154, mel_loss=0.04469, linear_loss=0.05273]
[2020-05-12 00:15:50.648]  Step 148418  [3.232 sec/step, loss=0.08320, avg_loss=0.09139, mel_loss=0.03627, linear_loss=0.04692]
[2020-05-12 00:15:56.459]  Step 148419  [3.259 sec/step, loss=0.09895, avg_loss=0.09140, mel_loss=0.04580, linear_loss=0.05315]
[2020-05-12 00:15:57.738]  Step 148420  [3.252 sec/step, loss=0.08646, avg_loss=0.09137, mel_loss=0.03817, linear_loss=0.04829]
[2020-05-12 00:15:58.233]  Generated 32 batches of size 32 in 1.768 sec
[2020-05-12 00:16:01.567]  Step 148421  [3.280 sec/step, loss=0.09648, avg_loss=0.09150, mel_loss=0.04351, linear_loss=0.05298]
[2020-05-12 00:16:03.644]  Step 148422  [3.291 sec/step, loss=0.09460, avg_loss=0.09159, mel_loss=0.04208, linear_loss=0.05251]
[2020-05-12 00:16:06.050]  Step 148423  [3.252 sec/step, loss=0.09502, avg_loss=0.09157, mel_loss=0.04245, linear_loss=0.05257]
[2020-05-12 00:16:08.222]  Step 148424  [3.259 sec/step, loss=0.09305, avg_loss=0.09161, mel_loss=0.04166, linear_loss=0.05139]
[2020-05-12 00:16:08.789]  Step 148425  [3.245 sec/step, loss=0.07302, avg_loss=0.09141, mel_loss=0.03260, linear_loss=0.04042]
[2020-05-12 00:16:11.750]  Step 148426  [3.245 sec/step, loss=0.09575, avg_loss=0.09138, mel_loss=0.04318, linear_loss=0.05257]
[2020-05-12 00:16:15.431]  Step 148427  [3.268 sec/step, loss=0.09870, avg_loss=0.09149, mel_loss=0.04496, linear_loss=0.05375]
[2020-05-12 00:16:24.612]  Step 148428  [3.305 sec/step, loss=0.09955, avg_loss=0.09149, mel_loss=0.04713, linear_loss=0.05242]
[2020-05-12 00:16:25.601]  Step 148429  [3.296 sec/step, loss=0.08126, avg_loss=0.09138, mel_loss=0.03514, linear_loss=0.04612]
[2020-05-12 00:16:29.042]  Step 148430  [3.325 sec/step, loss=0.09876, avg_loss=0.09164, mel_loss=0.04475, linear_loss=0.05402]
[2020-05-12 00:16:32.049]  Step 148431  [3.321 sec/step, loss=0.09818, avg_loss=0.09165, mel_loss=0.04437, linear_loss=0.05381]
[2020-05-12 00:16:33.656]  Step 148432  [3.320 sec/step, loss=0.08909, avg_loss=0.09164, mel_loss=0.03946, linear_loss=0.04963]
[2020-05-12 00:16:34.402]  Step 148433  [3.310 sec/step, loss=0.07770, avg_loss=0.09154, mel_loss=0.03398, linear_loss=0.04373]
[2020-05-12 00:16:48.567]  Step 148434  [3.410 sec/step, loss=0.07753, avg_loss=0.09134, mel_loss=0.03695, linear_loss=0.04057]
[2020-05-12 00:16:51.907]  Step 148435  [3.415 sec/step, loss=0.09908, avg_loss=0.09139, mel_loss=0.04456, linear_loss=0.05451]
[2020-05-12 00:16:57.681]  Step 148436  [3.386 sec/step, loss=0.10149, avg_loss=0.09141, mel_loss=0.04703, linear_loss=0.05446]
[2020-05-12 00:17:00.391]  Step 148437  [3.404 sec/step, loss=0.09632, avg_loss=0.09158, mel_loss=0.04347, linear_loss=0.05286]
[2020-05-12 00:17:02.088]  Step 148438  [3.410 sec/step, loss=0.09112, avg_loss=0.09162, mel_loss=0.04064, linear_loss=0.05049]
[2020-05-12 00:17:02.879]  Step 148439  [3.389 sec/step, loss=0.07810, avg_loss=0.09147, mel_loss=0.03382, linear_loss=0.04428]
[2020-05-12 00:17:04.286]  Step 148440  [3.385 sec/step, loss=0.08967, avg_loss=0.09147, mel_loss=0.03979, linear_loss=0.04988]
[2020-05-12 00:17:06.687]  Step 148441  [3.386 sec/step, loss=0.09293, avg_loss=0.09147, mel_loss=0.04158, linear_loss=0.05135]
[2020-05-12 00:17:09.550]  Step 148442  [3.400 sec/step, loss=0.09648, avg_loss=0.09154, mel_loss=0.04360, linear_loss=0.05288]
[2020-05-12 00:17:14.680]  Step 148443  [3.428 sec/step, loss=0.09886, avg_loss=0.09157, mel_loss=0.04528, linear_loss=0.05358]
[2020-05-12 00:17:16.126]  Step 148444  [3.369 sec/step, loss=0.08775, avg_loss=0.09144, mel_loss=0.03853, linear_loss=0.04922]
[2020-05-12 00:17:17.299]  Step 148445  [3.350 sec/step, loss=0.08455, avg_loss=0.09131, mel_loss=0.03693, linear_loss=0.04762]
[2020-05-12 00:17:17.861]  Step 148446  [3.269 sec/step, loss=0.07305, avg_loss=0.09107, mel_loss=0.03279, linear_loss=0.04026]
[2020-05-12 00:17:21.315]  Step 148447  [3.262 sec/step, loss=0.09620, avg_loss=0.09107, mel_loss=0.04360, linear_loss=0.05260]
[2020-05-12 00:17:23.409]  Step 148448  [3.271 sec/step, loss=0.09365, avg_loss=0.09115, mel_loss=0.04181, linear_loss=0.05185]
[2020-05-12 00:17:24.616]  Step 148449  [3.251 sec/step, loss=0.08767, avg_loss=0.09106, mel_loss=0.03848, linear_loss=0.04919]
[2020-05-12 00:17:26.495]  Step 148450  [3.256 sec/step, loss=0.09275, avg_loss=0.09113, mel_loss=0.04119, linear_loss=0.05155]
[2020-05-12 00:17:26.495]  Writing summary at step: 148450
[2020-05-12 00:17:32.014]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148450
[2020-05-12 00:17:33.425]  Saving audio and alignment...
[2020-05-12 00:17:35.452]  Generated 32 batches of size 32 in 1.502 sec
[2020-05-12 00:17:35.967]  Input: 종결어미라고 해서~________
[2020-05-12 00:17:40.433]  Step 148451  [3.243 sec/step, loss=0.09833, avg_loss=0.09111, mel_loss=0.04522, linear_loss=0.05311]
[2020-05-12 00:17:42.163]  Step 148452  [3.249 sec/step, loss=0.09117, avg_loss=0.09118, mel_loss=0.04003, linear_loss=0.05114]
[2020-05-12 00:17:49.066]  Step 148453  [3.282 sec/step, loss=0.10094, avg_loss=0.09119, mel_loss=0.04683, linear_loss=0.05411]
[2020-05-12 00:17:53.201]  Step 148454  [3.313 sec/step, loss=0.09768, avg_loss=0.09133, mel_loss=0.04432, linear_loss=0.05336]
[2020-05-12 00:18:01.363]  Step 148455  [3.372 sec/step, loss=0.09756, avg_loss=0.09139, mel_loss=0.04561, linear_loss=0.05194]
[2020-05-12 00:18:05.055]  Step 148456  [3.365 sec/step, loss=0.09951, avg_loss=0.09138, mel_loss=0.04517, linear_loss=0.05434]
[2020-05-12 00:18:07.252]  Step 148457  [3.319 sec/step, loss=0.09201, avg_loss=0.09130, mel_loss=0.04115, linear_loss=0.05086]
[2020-05-12 00:18:09.250]  Step 148458  [3.330 sec/step, loss=0.09178, avg_loss=0.09143, mel_loss=0.04099, linear_loss=0.05079]
[2020-05-12 00:18:14.085]  Step 148459  [3.373 sec/step, loss=0.09731, avg_loss=0.09168, mel_loss=0.04455, linear_loss=0.05276]
[2020-05-12 00:18:16.024]  Step 148460  [3.251 sec/step, loss=0.09127, avg_loss=0.09183, mel_loss=0.04018, linear_loss=0.05109]
[2020-05-12 00:18:19.460]  Step 148461  [3.248 sec/step, loss=0.09507, avg_loss=0.09179, mel_loss=0.04314, linear_loss=0.05194]
[2020-05-12 00:18:20.292]  Step 148462  [3.239 sec/step, loss=0.07791, avg_loss=0.09166, mel_loss=0.03362, linear_loss=0.04429]
[2020-05-12 00:18:21.686]  Step 148463  [3.206 sec/step, loss=0.08801, avg_loss=0.09156, mel_loss=0.03882, linear_loss=0.04919]
[2020-05-12 00:18:24.493]  Step 148464  [3.214 sec/step, loss=0.09418, avg_loss=0.09158, mel_loss=0.04248, linear_loss=0.05170]
[2020-05-12 00:18:26.011]  Step 148465  [3.195 sec/step, loss=0.09204, avg_loss=0.09154, mel_loss=0.04053, linear_loss=0.05150]
[2020-05-12 00:18:29.108]  Step 148466  [3.172 sec/step, loss=0.09697, avg_loss=0.09151, mel_loss=0.04387, linear_loss=0.05310]
[2020-05-12 00:18:31.518]  Step 148467  [3.190 sec/step, loss=0.09528, avg_loss=0.09176, mel_loss=0.04248, linear_loss=0.05280]
[2020-05-12 00:18:35.108]  Step 148468  [3.211 sec/step, loss=0.09821, avg_loss=0.09184, mel_loss=0.04440, linear_loss=0.05382]
[2020-05-12 00:18:40.432]  Step 148469  [3.240 sec/step, loss=0.10126, avg_loss=0.09193, mel_loss=0.04660, linear_loss=0.05467]
[2020-05-12 00:18:41.779]  Step 148470  [3.233 sec/step, loss=0.08664, avg_loss=0.09186, mel_loss=0.03782, linear_loss=0.04881]
[2020-05-12 00:18:43.413]  Step 148471  [3.187 sec/step, loss=0.08873, avg_loss=0.09178, mel_loss=0.03921, linear_loss=0.04952]
[2020-05-12 00:18:45.606]  Step 148472  [3.175 sec/step, loss=0.09349, avg_loss=0.09174, mel_loss=0.04181, linear_loss=0.05168]
[2020-05-12 00:18:46.199]  Step 148473  [3.170 sec/step, loss=0.07315, avg_loss=0.09161, mel_loss=0.03242, linear_loss=0.04073]
[2020-05-12 00:18:48.756]  Step 148474  [3.153 sec/step, loss=0.09107, avg_loss=0.09154, mel_loss=0.04060, linear_loss=0.05047]
[2020-05-12 00:19:01.752]  Step 148475  [3.274 sec/step, loss=0.08468, avg_loss=0.09154, mel_loss=0.04032, linear_loss=0.04436]
[2020-05-12 00:19:09.371]  Step 148476  [3.301 sec/step, loss=0.10099, avg_loss=0.09157, mel_loss=0.04718, linear_loss=0.05382]
[2020-05-12 00:19:13.379]  Step 148477  [3.325 sec/step, loss=0.09839, avg_loss=0.09161, mel_loss=0.04465, linear_loss=0.05374]
[2020-05-12 00:19:19.126]  Step 148478  [3.337 sec/step, loss=0.09953, avg_loss=0.09162, mel_loss=0.04582, linear_loss=0.05371]
[2020-05-12 00:19:20.182]  Step 148479  [3.340 sec/step, loss=0.08340, avg_loss=0.09165, mel_loss=0.03654, linear_loss=0.04686]
[2020-05-12 00:19:21.281]  Step 148480  [3.333 sec/step, loss=0.08641, avg_loss=0.09160, mel_loss=0.03739, linear_loss=0.04902]
[2020-05-12 00:19:24.487]  Step 148481  [3.353 sec/step, loss=0.09914, avg_loss=0.09172, mel_loss=0.04492, linear_loss=0.05422]
[2020-05-12 00:19:26.206]  Generated 32 batches of size 32 in 1.714 sec
[2020-05-12 00:19:26.612]  Step 148482  [3.288 sec/step, loss=0.09178, avg_loss=0.09167, mel_loss=0.04096, linear_loss=0.05082]
[2020-05-12 00:19:31.000]  Step 148483  [3.305 sec/step, loss=0.10067, avg_loss=0.09175, mel_loss=0.04592, linear_loss=0.05475]
[2020-05-12 00:19:31.931]  Step 148484  [3.274 sec/step, loss=0.08089, avg_loss=0.09156, mel_loss=0.03523, linear_loss=0.04566]
[2020-05-12 00:19:33.140]  Step 148485  [3.257 sec/step, loss=0.08550, avg_loss=0.09146, mel_loss=0.03757, linear_loss=0.04794]
[2020-05-12 00:19:34.893]  Step 148486  [3.261 sec/step, loss=0.09034, avg_loss=0.09149, mel_loss=0.03981, linear_loss=0.05054]
[2020-05-12 00:19:35.671]  Step 148487  [3.237 sec/step, loss=0.07546, avg_loss=0.09128, mel_loss=0.03307, linear_loss=0.04239]
[2020-05-12 00:19:44.130]  Step 148488  [3.313 sec/step, loss=0.09977, avg_loss=0.09150, mel_loss=0.04662, linear_loss=0.05315]
[2020-05-12 00:19:50.504]  Step 148489  [3.363 sec/step, loss=0.10073, avg_loss=0.09162, mel_loss=0.04671, linear_loss=0.05402]
[2020-05-12 00:19:54.511]  Step 148490  [3.383 sec/step, loss=0.09942, avg_loss=0.09171, mel_loss=0.04499, linear_loss=0.05443]
[2020-05-12 00:19:56.675]  Step 148491  [3.395 sec/step, loss=0.09255, avg_loss=0.09181, mel_loss=0.04137, linear_loss=0.05119]
[2020-05-12 00:19:58.026]  Step 148492  [3.389 sec/step, loss=0.08934, avg_loss=0.09177, mel_loss=0.03953, linear_loss=0.04981]
[2020-05-12 00:20:00.435]  Step 148493  [3.375 sec/step, loss=0.09421, avg_loss=0.09175, mel_loss=0.04207, linear_loss=0.05215]
[2020-05-12 00:20:01.659]  Step 148494  [3.363 sec/step, loss=0.08471, avg_loss=0.09166, mel_loss=0.03735, linear_loss=0.04736]
[2020-05-12 00:20:02.485]  Step 148495  [3.228 sec/step, loss=0.08049, avg_loss=0.09169, mel_loss=0.03529, linear_loss=0.04520]
[2020-05-12 00:20:05.615]  Step 148496  [3.185 sec/step, loss=0.09869, avg_loss=0.09168, mel_loss=0.04443, linear_loss=0.05426]
[2020-05-12 00:20:06.139]  Step 148497  [3.137 sec/step, loss=0.07738, avg_loss=0.09148, mel_loss=0.03433, linear_loss=0.04305]
[2020-05-12 00:20:07.829]  Step 148498  [3.118 sec/step, loss=0.09178, avg_loss=0.09142, mel_loss=0.04091, linear_loss=0.05087]
[2020-05-12 00:20:12.571]  Step 148499  [3.043 sec/step, loss=0.09891, avg_loss=0.09152, mel_loss=0.04523, linear_loss=0.05367]
[2020-05-12 00:20:16.544]  Step 148500  [3.035 sec/step, loss=0.09841, avg_loss=0.09154, mel_loss=0.04433, linear_loss=0.05408]
[2020-05-12 00:20:16.544]  Writing summary at step: 148500
[2020-05-12 00:20:21.867]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148500
[2020-05-12 00:20:25.810]  Saving audio and alignment...
[2020-05-12 00:20:29.259]  Input: 자 어떤 색상의 의상~____________________________
[2020-05-12 00:20:43.799]  Step 148501  [3.170 sec/step, loss=0.07789, avg_loss=0.09145, mel_loss=0.03735, linear_loss=0.04054]
[2020-05-12 00:20:49.816]  Step 148502  [3.214 sec/step, loss=0.09775, avg_loss=0.09154, mel_loss=0.04540, linear_loss=0.05235]
[2020-05-12 00:20:50.655]  Step 148503  [3.195 sec/step, loss=0.07414, avg_loss=0.09134, mel_loss=0.03310, linear_loss=0.04104]
[2020-05-12 00:20:53.448]  Step 148504  [3.146 sec/step, loss=0.09510, avg_loss=0.09130, mel_loss=0.04272, linear_loss=0.05238]
[2020-05-12 00:20:54.397]  Step 148505  [3.137 sec/step, loss=0.08413, avg_loss=0.09124, mel_loss=0.03639, linear_loss=0.04773]
[2020-05-12 00:20:55.987]  Step 148506  [3.100 sec/step, loss=0.08834, avg_loss=0.09114, mel_loss=0.03900, linear_loss=0.04935]
[2020-05-12 00:20:59.662]  Step 148507  [3.103 sec/step, loss=0.09842, avg_loss=0.09118, mel_loss=0.04484, linear_loss=0.05358]
[2020-05-12 00:21:00.619]  Step 148508  [3.105 sec/step, loss=0.08511, avg_loss=0.09122, mel_loss=0.03736, linear_loss=0.04774]
[2020-05-12 00:21:09.293]  Step 148509  [3.179 sec/step, loss=0.09500, avg_loss=0.09130, mel_loss=0.04445, linear_loss=0.05055]
[2020-05-12 00:21:12.735]  Step 148510  [3.196 sec/step, loss=0.09601, avg_loss=0.09136, mel_loss=0.04363, linear_loss=0.05239]
[2020-05-12 00:21:18.166]  Step 148511  [3.219 sec/step, loss=0.09872, avg_loss=0.09138, mel_loss=0.04550, linear_loss=0.05322]
[2020-05-12 00:21:19.830]  Generated 32 batches of size 32 in 1.658 sec
[2020-05-12 00:21:22.587]  Step 148512  [3.254 sec/step, loss=0.09630, avg_loss=0.09154, mel_loss=0.04388, linear_loss=0.05242]
[2020-05-12 00:21:27.190]  Step 148513  [3.292 sec/step, loss=0.09859, avg_loss=0.09175, mel_loss=0.04496, linear_loss=0.05364]
[2020-05-12 00:21:28.282]  Step 148514  [3.283 sec/step, loss=0.08472, avg_loss=0.09166, mel_loss=0.03688, linear_loss=0.04784]
[2020-05-12 00:21:29.565]  Step 148515  [3.282 sec/step, loss=0.08911, avg_loss=0.09167, mel_loss=0.03948, linear_loss=0.04964]
[2020-05-12 00:21:31.463]  Step 148516  [3.237 sec/step, loss=0.09275, avg_loss=0.09160, mel_loss=0.04133, linear_loss=0.05142]
[2020-05-12 00:21:33.447]  Step 148517  [3.215 sec/step, loss=0.09453, avg_loss=0.09157, mel_loss=0.04214, linear_loss=0.05239]
[2020-05-12 00:21:36.075]  Step 148518  [3.232 sec/step, loss=0.09602, avg_loss=0.09170, mel_loss=0.04315, linear_loss=0.05287]
[2020-05-12 00:21:37.858]  Step 148519  [3.192 sec/step, loss=0.08953, avg_loss=0.09160, mel_loss=0.03950, linear_loss=0.05003]
[2020-05-12 00:21:44.995]  Step 148520  [3.250 sec/step, loss=0.10315, avg_loss=0.09177, mel_loss=0.04805, linear_loss=0.05510]
[2020-05-12 00:21:49.233]  Step 148521  [3.255 sec/step, loss=0.09706, avg_loss=0.09177, mel_loss=0.04401, linear_loss=0.05305]
[2020-05-12 00:21:51.708]  Step 148522  [3.259 sec/step, loss=0.09266, avg_loss=0.09176, mel_loss=0.04135, linear_loss=0.05132]
[2020-05-12 00:21:54.684]  Step 148523  [3.264 sec/step, loss=0.09589, avg_loss=0.09176, mel_loss=0.04300, linear_loss=0.05289]
[2020-05-12 00:21:56.294]  Step 148524  [3.259 sec/step, loss=0.09115, avg_loss=0.09174, mel_loss=0.04052, linear_loss=0.05062]
[2020-05-12 00:21:57.038]  Step 148525  [3.260 sec/step, loss=0.07632, avg_loss=0.09178, mel_loss=0.03335, linear_loss=0.04296]
[2020-05-12 00:21:59.087]  Step 148526  [3.251 sec/step, loss=0.09515, avg_loss=0.09177, mel_loss=0.04274, linear_loss=0.05241]
[2020-05-12 00:22:00.215]  Step 148527  [3.226 sec/step, loss=0.08308, avg_loss=0.09162, mel_loss=0.03634, linear_loss=0.04673]
[2020-05-12 00:22:08.840]  Step 148528  [3.220 sec/step, loss=0.09793, avg_loss=0.09160, mel_loss=0.04589, linear_loss=0.05205]
[2020-05-12 00:22:10.406]  Step 148529  [3.226 sec/step, loss=0.09239, avg_loss=0.09171, mel_loss=0.04076, linear_loss=0.05163]
[2020-05-12 00:22:13.275]  Step 148530  [3.220 sec/step, loss=0.09666, avg_loss=0.09169, mel_loss=0.04371, linear_loss=0.05294]
[2020-05-12 00:22:19.557]  Step 148531  [3.253 sec/step, loss=0.09922, avg_loss=0.09170, mel_loss=0.04587, linear_loss=0.05335]
[2020-05-12 00:22:20.957]  Step 148532  [3.251 sec/step, loss=0.08895, avg_loss=0.09170, mel_loss=0.03932, linear_loss=0.04963]
[2020-05-12 00:22:21.877]  Step 148533  [3.253 sec/step, loss=0.08390, avg_loss=0.09176, mel_loss=0.03665, linear_loss=0.04725]
[2020-05-12 00:22:27.583]  Step 148534  [3.168 sec/step, loss=0.09956, avg_loss=0.09198, mel_loss=0.04567, linear_loss=0.05388]
[2020-05-12 00:22:31.751]  Step 148535  [3.176 sec/step, loss=0.09818, avg_loss=0.09197, mel_loss=0.04447, linear_loss=0.05371]
[2020-05-12 00:22:33.488]  Step 148536  [3.136 sec/step, loss=0.09085, avg_loss=0.09187, mel_loss=0.03998, linear_loss=0.05086]
[2020-05-12 00:22:36.934]  Step 148537  [3.143 sec/step, loss=0.09621, avg_loss=0.09186, mel_loss=0.04364, linear_loss=0.05257]
[2020-05-12 00:22:38.811]  Step 148538  [3.145 sec/step, loss=0.09032, avg_loss=0.09186, mel_loss=0.03971, linear_loss=0.05061]
[2020-05-12 00:22:42.380]  Step 148539  [3.173 sec/step, loss=0.09939, avg_loss=0.09207, mel_loss=0.04513, linear_loss=0.05426]
[2020-05-12 00:22:55.357]  Step 148540  [3.289 sec/step, loss=0.08319, avg_loss=0.09200, mel_loss=0.03940, linear_loss=0.04379]
[2020-05-12 00:22:56.578]  Step 148541  [3.277 sec/step, loss=0.08600, avg_loss=0.09193, mel_loss=0.03777, linear_loss=0.04822]
[2020-05-12 00:22:59.322]  Step 148542  [3.276 sec/step, loss=0.09381, avg_loss=0.09191, mel_loss=0.04210, linear_loss=0.05171]
[2020-05-12 00:23:00.334]  Step 148543  [3.234 sec/step, loss=0.08421, avg_loss=0.09176, mel_loss=0.03682, linear_loss=0.04739]
[2020-05-12 00:23:01.167]  Step 148544  [3.228 sec/step, loss=0.07982, avg_loss=0.09168, mel_loss=0.03491, linear_loss=0.04491]
[2020-05-12 00:23:02.057]  Generated 32 batches of size 32 in 1.719 sec
[2020-05-12 00:23:02.560]  Step 148545  [3.231 sec/step, loss=0.08867, avg_loss=0.09172, mel_loss=0.03912, linear_loss=0.04955]
[2020-05-12 00:23:04.512]  Step 148546  [3.244 sec/step, loss=0.09284, avg_loss=0.09192, mel_loss=0.04136, linear_loss=0.05149]
[2020-05-12 00:23:08.952]  Step 148547  [3.254 sec/step, loss=0.09933, avg_loss=0.09195, mel_loss=0.04555, linear_loss=0.05377]
[2020-05-12 00:23:11.180]  Step 148548  [3.256 sec/step, loss=0.09449, avg_loss=0.09196, mel_loss=0.04230, linear_loss=0.05218]
[2020-05-12 00:23:14.393]  Step 148549  [3.276 sec/step, loss=0.09783, avg_loss=0.09206, mel_loss=0.04423, linear_loss=0.05360]
[2020-05-12 00:23:15.136]  Step 148550  [3.264 sec/step, loss=0.07645, avg_loss=0.09190, mel_loss=0.03468, linear_loss=0.04177]
[2020-05-12 00:23:15.137]  Writing summary at step: 148550
[2020-05-12 00:23:20.124]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148550
[2020-05-12 00:23:21.512]  Saving audio and alignment...
[2020-05-12 00:23:31.317]  Input: 여러분 호흡소리를 섞어 보시죠  지켜보는 이들도 흥미진진합니다 그러면 분위기 갑자기 확 사는게 있거든요~_______
[2020-05-12 00:23:45.288]  Step 148551  [3.359 sec/step, loss=0.07779, avg_loss=0.09169, mel_loss=0.03742, linear_loss=0.04037]
[2020-05-12 00:23:50.605]  Step 148552  [3.395 sec/step, loss=0.10064, avg_loss=0.09179, mel_loss=0.04629, linear_loss=0.05435]
[2020-05-12 00:23:52.134]  Step 148553  [3.341 sec/step, loss=0.08793, avg_loss=0.09166, mel_loss=0.03876, linear_loss=0.04917]
[2020-05-12 00:23:56.541]  Step 148554  [3.344 sec/step, loss=0.09960, avg_loss=0.09168, mel_loss=0.04564, linear_loss=0.05397]
[2020-05-12 00:23:58.586]  Step 148555  [3.283 sec/step, loss=0.08971, avg_loss=0.09160, mel_loss=0.03974, linear_loss=0.04997]
[2020-05-12 00:24:02.086]  Step 148556  [3.281 sec/step, loss=0.09578, avg_loss=0.09156, mel_loss=0.04342, linear_loss=0.05236]
[2020-05-12 00:24:03.386]  Step 148557  [3.272 sec/step, loss=0.08371, avg_loss=0.09148, mel_loss=0.03682, linear_loss=0.04689]
[2020-05-12 00:24:07.106]  Step 148558  [3.289 sec/step, loss=0.09842, avg_loss=0.09155, mel_loss=0.04472, linear_loss=0.05370]
[2020-05-12 00:24:07.940]  Step 148559  [3.249 sec/step, loss=0.07716, avg_loss=0.09134, mel_loss=0.03332, linear_loss=0.04384]
[2020-05-12 00:24:11.348]  Step 148560  [3.264 sec/step, loss=0.09704, avg_loss=0.09140, mel_loss=0.04390, linear_loss=0.05314]
[2020-05-12 00:24:12.976]  Step 148561  [3.246 sec/step, loss=0.08896, avg_loss=0.09134, mel_loss=0.03954, linear_loss=0.04942]
[2020-05-12 00:24:15.135]  Step 148562  [3.259 sec/step, loss=0.09294, avg_loss=0.09149, mel_loss=0.04136, linear_loss=0.05158]
[2020-05-12 00:24:22.755]  Step 148563  [3.321 sec/step, loss=0.09960, avg_loss=0.09161, mel_loss=0.04633, linear_loss=0.05328]
[2020-05-12 00:24:23.789]  Step 148564  [3.304 sec/step, loss=0.08398, avg_loss=0.09151, mel_loss=0.03672, linear_loss=0.04727]
[2020-05-12 00:24:28.473]  Step 148565  [3.335 sec/step, loss=0.09873, avg_loss=0.09157, mel_loss=0.04502, linear_loss=0.05372]
[2020-05-12 00:24:28.997]  Step 148566  [3.310 sec/step, loss=0.07458, avg_loss=0.09135, mel_loss=0.03248, linear_loss=0.04211]
[2020-05-12 00:24:31.367]  Step 148567  [3.309 sec/step, loss=0.09143, avg_loss=0.09131, mel_loss=0.04103, linear_loss=0.05041]
[2020-05-12 00:24:40.085]  Step 148568  [3.361 sec/step, loss=0.09895, avg_loss=0.09132, mel_loss=0.04646, linear_loss=0.05249]
[2020-05-12 00:24:40.663]  Step 148569  [3.313 sec/step, loss=0.08111, avg_loss=0.09112, mel_loss=0.03629, linear_loss=0.04482]
[2020-05-12 00:24:41.618]  Step 148570  [3.309 sec/step, loss=0.08157, avg_loss=0.09106, mel_loss=0.03559, linear_loss=0.04597]
[2020-05-12 00:24:45.820]  Step 148571  [3.335 sec/step, loss=0.09849, avg_loss=0.09116, mel_loss=0.04461, linear_loss=0.05388]
[2020-05-12 00:24:48.461]  Step 148572  [3.339 sec/step, loss=0.09405, avg_loss=0.09117, mel_loss=0.04215, linear_loss=0.05189]
[2020-05-12 00:24:49.314]  Step 148573  [3.342 sec/step, loss=0.08055, avg_loss=0.09124, mel_loss=0.03462, linear_loss=0.04594]
[2020-05-12 00:24:51.060]  Generated 32 batches of size 32 in 1.741 sec
[2020-05-12 00:24:51.171]  Step 148574  [3.335 sec/step, loss=0.09138, avg_loss=0.09125, mel_loss=0.04034, linear_loss=0.05104]
[2020-05-12 00:24:57.013]  Step 148575  [3.263 sec/step, loss=0.09951, avg_loss=0.09139, mel_loss=0.04582, linear_loss=0.05369]
[2020-05-12 00:24:59.428]  Step 148576  [3.211 sec/step, loss=0.09336, avg_loss=0.09132, mel_loss=0.04157, linear_loss=0.05179]
[2020-05-12 00:25:02.405]  Step 148577  [3.201 sec/step, loss=0.09569, avg_loss=0.09129, mel_loss=0.04321, linear_loss=0.05248]
[2020-05-12 00:25:03.565]  Step 148578  [3.155 sec/step, loss=0.08470, avg_loss=0.09114, mel_loss=0.03665, linear_loss=0.04805]
[2020-05-12 00:25:04.891]  Step 148579  [3.158 sec/step, loss=0.08844, avg_loss=0.09119, mel_loss=0.03887, linear_loss=0.04957]
[2020-05-12 00:25:08.047]  Step 148580  [3.178 sec/step, loss=0.09926, avg_loss=0.09132, mel_loss=0.04470, linear_loss=0.05456]
[2020-05-12 00:25:14.885]  Step 148581  [3.215 sec/step, loss=0.09928, avg_loss=0.09132, mel_loss=0.04610, linear_loss=0.05318]
[2020-05-12 00:25:16.746]  Step 148582  [3.212 sec/step, loss=0.09295, avg_loss=0.09133, mel_loss=0.04124, linear_loss=0.05171]
[2020-05-12 00:25:21.326]  Step 148583  [3.214 sec/step, loss=0.09894, avg_loss=0.09132, mel_loss=0.04521, linear_loss=0.05372]
[2020-05-12 00:25:27.366]  Step 148584  [3.265 sec/step, loss=0.09779, avg_loss=0.09149, mel_loss=0.04505, linear_loss=0.05275]
[2020-05-12 00:25:28.211]  Step 148585  [3.261 sec/step, loss=0.07750, avg_loss=0.09141, mel_loss=0.03390, linear_loss=0.04360]
[2020-05-12 00:25:29.262]  Step 148586  [3.254 sec/step, loss=0.08551, avg_loss=0.09136, mel_loss=0.03749, linear_loss=0.04802]
[2020-05-12 00:25:42.396]  Step 148587  [3.378 sec/step, loss=0.08562, avg_loss=0.09146, mel_loss=0.04084, linear_loss=0.04478]
[2020-05-12 00:25:44.575]  Step 148588  [3.315 sec/step, loss=0.09477, avg_loss=0.09141, mel_loss=0.04241, linear_loss=0.05236]
[2020-05-12 00:25:46.396]  Step 148589  [3.270 sec/step, loss=0.08973, avg_loss=0.09130, mel_loss=0.03943, linear_loss=0.05029]
[2020-05-12 00:25:55.210]  Step 148590  [3.318 sec/step, loss=0.09401, avg_loss=0.09124, mel_loss=0.04403, linear_loss=0.04998]
[2020-05-12 00:26:02.449]  Step 148591  [3.369 sec/step, loss=0.09846, avg_loss=0.09130, mel_loss=0.04573, linear_loss=0.05273]
[2020-05-12 00:26:05.892]  Step 148592  [3.389 sec/step, loss=0.09429, avg_loss=0.09135, mel_loss=0.04272, linear_loss=0.05157]
[2020-05-12 00:26:06.685]  Step 148593  [3.373 sec/step, loss=0.07425, avg_loss=0.09115, mel_loss=0.03226, linear_loss=0.04199]
[2020-05-12 00:26:09.513]  Step 148594  [3.389 sec/step, loss=0.09566, avg_loss=0.09126, mel_loss=0.04295, linear_loss=0.05271]
[2020-05-12 00:26:11.166]  Step 148595  [3.398 sec/step, loss=0.09025, avg_loss=0.09136, mel_loss=0.03980, linear_loss=0.05045]
[2020-05-12 00:26:12.201]  Step 148596  [3.377 sec/step, loss=0.08315, avg_loss=0.09121, mel_loss=0.03646, linear_loss=0.04669]
[2020-05-12 00:26:17.744]  Step 148597  [3.427 sec/step, loss=0.09961, avg_loss=0.09143, mel_loss=0.04592, linear_loss=0.05370]
[2020-05-12 00:26:22.733]  Step 148598  [3.460 sec/step, loss=0.09812, avg_loss=0.09149, mel_loss=0.04507, linear_loss=0.05305]
[2020-05-12 00:26:25.025]  Step 148599  [3.435 sec/step, loss=0.09244, avg_loss=0.09143, mel_loss=0.04132, linear_loss=0.05112]
[2020-05-12 00:26:26.477]  Step 148600  [3.410 sec/step, loss=0.08737, avg_loss=0.09132, mel_loss=0.03837, linear_loss=0.04900]
[2020-05-12 00:26:26.477]  Writing summary at step: 148600
[2020-05-12 00:26:27.676]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148600
[2020-05-12 00:26:29.155]  Saving audio and alignment...
[2020-05-12 00:26:32.754]  Input: 그저 그런 수준의 커리큘럼이 아닙니다~_
[2020-05-12 00:26:34.723]  Step 148601  [3.284 sec/step, loss=0.09223, avg_loss=0.09146, mel_loss=0.04062, linear_loss=0.05161]
[2020-05-12 00:26:36.035]  Step 148602  [3.237 sec/step, loss=0.08537, avg_loss=0.09134, mel_loss=0.03750, linear_loss=0.04786]
[2020-05-12 00:26:39.385]  Step 148603  [3.262 sec/step, loss=0.09592, avg_loss=0.09155, mel_loss=0.04334, linear_loss=0.05258]
[2020-05-12 00:26:41.216]  Generated 32 batches of size 32 in 1.825 sec
[2020-05-12 00:26:42.589]  Step 148604  [3.267 sec/step, loss=0.09691, avg_loss=0.09157, mel_loss=0.04383, linear_loss=0.05308]
[2020-05-12 00:26:45.041]  Step 148605  [3.282 sec/step, loss=0.09449, avg_loss=0.09167, mel_loss=0.04202, linear_loss=0.05248]
[2020-05-12 00:26:45.796]  Step 148606  [3.273 sec/step, loss=0.07736, avg_loss=0.09157, mel_loss=0.03495, linear_loss=0.04241]
[2020-05-12 00:26:49.883]  Step 148607  [3.277 sec/step, loss=0.09688, avg_loss=0.09155, mel_loss=0.04424, linear_loss=0.05264]
[2020-05-12 00:26:53.487]  Step 148608  [3.304 sec/step, loss=0.09916, avg_loss=0.09169, mel_loss=0.04501, linear_loss=0.05415]
[2020-05-12 00:26:55.125]  Step 148609  [3.233 sec/step, loss=0.09050, avg_loss=0.09165, mel_loss=0.04002, linear_loss=0.05048]
[2020-05-12 00:26:58.907]  Step 148610  [3.237 sec/step, loss=0.09963, avg_loss=0.09168, mel_loss=0.04514, linear_loss=0.05449]
[2020-05-12 00:27:01.567]  Step 148611  [3.209 sec/step, loss=0.09284, avg_loss=0.09162, mel_loss=0.04164, linear_loss=0.05120]
[2020-05-12 00:27:03.042]  Step 148612  [3.180 sec/step, loss=0.08780, avg_loss=0.09154, mel_loss=0.03882, linear_loss=0.04898]
[2020-05-12 00:27:04.787]  Step 148613  [3.151 sec/step, loss=0.09094, avg_loss=0.09146, mel_loss=0.03998, linear_loss=0.05096]
[2020-05-12 00:27:06.875]  Step 148614  [3.161 sec/step, loss=0.09326, avg_loss=0.09155, mel_loss=0.04127, linear_loss=0.05199]
[2020-05-12 00:27:07.844]  Step 148615  [3.158 sec/step, loss=0.08405, avg_loss=0.09150, mel_loss=0.03665, linear_loss=0.04739]
[2020-05-12 00:27:12.561]  Step 148616  [3.186 sec/step, loss=0.09787, avg_loss=0.09155, mel_loss=0.04464, linear_loss=0.05323]
[2020-05-12 00:27:16.021]  Step 148617  [3.201 sec/step, loss=0.09725, avg_loss=0.09157, mel_loss=0.04399, linear_loss=0.05326]
[2020-05-12 00:27:17.416]  Step 148618  [3.189 sec/step, loss=0.08782, avg_loss=0.09149, mel_loss=0.03858, linear_loss=0.04924]
[2020-05-12 00:27:18.546]  Step 148619  [3.182 sec/step, loss=0.08600, avg_loss=0.09146, mel_loss=0.03759, linear_loss=0.04841]
[2020-05-12 00:27:26.765]  Step 148620  [3.193 sec/step, loss=0.09950, avg_loss=0.09142, mel_loss=0.04642, linear_loss=0.05308]
[2020-05-12 00:27:30.827]  Step 148621  [3.191 sec/step, loss=0.09767, avg_loss=0.09143, mel_loss=0.04421, linear_loss=0.05346]
[2020-05-12 00:27:31.679]  Step 148622  [3.175 sec/step, loss=0.08400, avg_loss=0.09134, mel_loss=0.03643, linear_loss=0.04756]
[2020-05-12 00:27:38.440]  Step 148623  [3.213 sec/step, loss=0.10070, avg_loss=0.09139, mel_loss=0.04655, linear_loss=0.05414]
[2020-05-12 00:27:41.194]  Step 148624  [3.224 sec/step, loss=0.09285, avg_loss=0.09141, mel_loss=0.04145, linear_loss=0.05140]
[2020-05-12 00:27:44.340]  Step 148625  [3.248 sec/step, loss=0.09670, avg_loss=0.09161, mel_loss=0.04348, linear_loss=0.05322]
[2020-05-12 00:27:45.828]  Step 148626  [3.243 sec/step, loss=0.09109, avg_loss=0.09157, mel_loss=0.04009, linear_loss=0.05101]
[2020-05-12 00:27:48.812]  Step 148627  [3.261 sec/step, loss=0.09581, avg_loss=0.09170, mel_loss=0.04323, linear_loss=0.05259]
[2020-05-12 00:27:52.366]  Step 148628  [3.210 sec/step, loss=0.09484, avg_loss=0.09166, mel_loss=0.04298, linear_loss=0.05186]
[2020-05-12 00:27:53.125]  Step 148629  [3.202 sec/step, loss=0.08020, avg_loss=0.09154, mel_loss=0.03517, linear_loss=0.04503]
[2020-05-12 00:27:55.307]  Step 148630  [3.195 sec/step, loss=0.09174, avg_loss=0.09149, mel_loss=0.04090, linear_loss=0.05084]
[2020-05-12 00:27:56.368]  Step 148631  [3.143 sec/step, loss=0.08585, avg_loss=0.09136, mel_loss=0.03734, linear_loss=0.04851]
[2020-05-12 00:28:01.743]  Step 148632  [3.183 sec/step, loss=0.09799, avg_loss=0.09145, mel_loss=0.04498, linear_loss=0.05302]
[2020-05-12 00:28:03.649]  Step 148633  [3.193 sec/step, loss=0.09155, avg_loss=0.09153, mel_loss=0.04105, linear_loss=0.05050]
[2020-05-12 00:28:09.522]  Step 148634  [3.195 sec/step, loss=0.09913, avg_loss=0.09152, mel_loss=0.04562, linear_loss=0.05351]
[2020-05-12 00:28:13.787]  Step 148635  [3.196 sec/step, loss=0.09972, avg_loss=0.09154, mel_loss=0.04571, linear_loss=0.05401]
[2020-05-12 00:28:15.419]  Generated 32 batches of size 32 in 1.627 sec
[2020-05-12 00:28:27.882]  Step 148636  [3.319 sec/step, loss=0.07520, avg_loss=0.09138, mel_loss=0.03584, linear_loss=0.03936]
[2020-05-12 00:28:31.623]  Step 148637  [3.322 sec/step, loss=0.09846, avg_loss=0.09140, mel_loss=0.04480, linear_loss=0.05367]
[2020-05-12 00:28:33.985]  Step 148638  [3.327 sec/step, loss=0.09264, avg_loss=0.09143, mel_loss=0.04139, linear_loss=0.05126]
[2020-05-12 00:28:41.491]  Step 148639  [3.366 sec/step, loss=0.10139, avg_loss=0.09145, mel_loss=0.04718, linear_loss=0.05420]
[2020-05-12 00:28:42.838]  Step 148640  [3.250 sec/step, loss=0.08470, avg_loss=0.09146, mel_loss=0.03743, linear_loss=0.04728]
[2020-05-12 00:28:44.408]  Step 148641  [3.253 sec/step, loss=0.09184, avg_loss=0.09152, mel_loss=0.04082, linear_loss=0.05102]
[2020-05-12 00:28:44.940]  Step 148642  [3.231 sec/step, loss=0.07250, avg_loss=0.09131, mel_loss=0.03248, linear_loss=0.04002]
[2020-05-12 00:28:45.749]  Step 148643  [3.229 sec/step, loss=0.07867, avg_loss=0.09125, mel_loss=0.03430, linear_loss=0.04437]
[2020-05-12 00:28:48.509]  Step 148644  [3.249 sec/step, loss=0.09453, avg_loss=0.09140, mel_loss=0.04260, linear_loss=0.05193]
[2020-05-12 00:28:51.629]  Step 148645  [3.266 sec/step, loss=0.09732, avg_loss=0.09149, mel_loss=0.04383, linear_loss=0.05349]
[2020-05-12 00:28:59.171]  Step 148646  [3.322 sec/step, loss=0.09880, avg_loss=0.09155, mel_loss=0.04614, linear_loss=0.05266]
[2020-05-12 00:29:03.511]  Step 148647  [3.321 sec/step, loss=0.09777, avg_loss=0.09153, mel_loss=0.04449, linear_loss=0.05328]
[2020-05-12 00:29:04.332]  Step 148648  [3.307 sec/step, loss=0.08035, avg_loss=0.09139, mel_loss=0.03457, linear_loss=0.04578]
[2020-05-12 00:29:06.170]  Step 148649  [3.293 sec/step, loss=0.09227, avg_loss=0.09133, mel_loss=0.04051, linear_loss=0.05176]
[2020-05-12 00:29:07.406]  Step 148650  [3.298 sec/step, loss=0.08685, avg_loss=0.09144, mel_loss=0.03806, linear_loss=0.04878]
[2020-05-12 00:29:07.406]  Writing summary at step: 148650
[2020-05-12 00:29:10.013]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148650
[2020-05-12 00:29:11.449]  Saving audio and alignment...
[2020-05-12 00:29:17.126]  Input: 대본에도 기호로 적용해서 그걸 잘 지키기만 한다면~_________________
[2020-05-12 00:29:19.230]  Step 148651  [3.179 sec/step, loss=0.09373, avg_loss=0.09160, mel_loss=0.04203, linear_loss=0.05170]
[2020-05-12 00:29:22.214]  Step 148652  [3.156 sec/step, loss=0.09466, avg_loss=0.09154, mel_loss=0.04270, linear_loss=0.05196]
[2020-05-12 00:29:23.233]  Step 148653  [3.151 sec/step, loss=0.08448, avg_loss=0.09150, mel_loss=0.03651, linear_loss=0.04797]
[2020-05-12 00:29:25.431]  Step 148654  [3.129 sec/step, loss=0.09151, avg_loss=0.09142, mel_loss=0.04094, linear_loss=0.05057]
[2020-05-12 00:29:27.175]  Step 148655  [3.126 sec/step, loss=0.09103, avg_loss=0.09143, mel_loss=0.03998, linear_loss=0.05105]
[2020-05-12 00:29:28.665]  Step 148656  [3.106 sec/step, loss=0.09105, avg_loss=0.09139, mel_loss=0.04020, linear_loss=0.05085]
[2020-05-12 00:29:33.227]  Step 148657  [3.138 sec/step, loss=0.09951, avg_loss=0.09155, mel_loss=0.04534, linear_loss=0.05418]
[2020-05-12 00:29:35.197]  Step 148658  [3.121 sec/step, loss=0.09102, avg_loss=0.09147, mel_loss=0.04043, linear_loss=0.05059]
[2020-05-12 00:29:36.300]  Step 148659  [3.123 sec/step, loss=0.08546, avg_loss=0.09155, mel_loss=0.03681, linear_loss=0.04865]
[2020-05-12 00:29:38.730]  Step 148660  [3.114 sec/step, loss=0.09438, avg_loss=0.09153, mel_loss=0.04229, linear_loss=0.05209]
[2020-05-12 00:29:40.425]  Step 148661  [3.114 sec/step, loss=0.09197, avg_loss=0.09156, mel_loss=0.04078, linear_loss=0.05118]
[2020-05-12 00:29:49.362]  Step 148662  [3.182 sec/step, loss=0.09772, avg_loss=0.09161, mel_loss=0.04582, linear_loss=0.05190]
[2020-05-12 00:29:55.941]  Step 148663  [3.172 sec/step, loss=0.09870, avg_loss=0.09160, mel_loss=0.04570, linear_loss=0.05300]
[2020-05-12 00:29:59.184]  Step 148664  [3.194 sec/step, loss=0.09764, avg_loss=0.09173, mel_loss=0.04435, linear_loss=0.05330]
[2020-05-12 00:29:59.945]  Step 148665  [3.154 sec/step, loss=0.07311, avg_loss=0.09148, mel_loss=0.03282, linear_loss=0.04029]
[2020-05-12 00:30:01.580]  Generated 32 batches of size 32 in 1.630 sec
[2020-05-12 00:30:05.572]  Step 148666  [3.206 sec/step, loss=0.09978, avg_loss=0.09173, mel_loss=0.04576, linear_loss=0.05402]
[2020-05-12 00:30:06.284]  Step 148667  [3.189 sec/step, loss=0.07699, avg_loss=0.09158, mel_loss=0.03335, linear_loss=0.04364]
[2020-05-12 00:30:07.645]  Step 148668  [3.115 sec/step, loss=0.08582, avg_loss=0.09145, mel_loss=0.03781, linear_loss=0.04801]
[2020-05-12 00:30:11.781]  Step 148669  [3.151 sec/step, loss=0.09808, avg_loss=0.09162, mel_loss=0.04457, linear_loss=0.05351]
[2020-05-12 00:30:17.062]  Step 148670  [3.194 sec/step, loss=0.09881, avg_loss=0.09180, mel_loss=0.04540, linear_loss=0.05342]
[2020-05-12 00:30:32.356]  Step 148671  [3.305 sec/step, loss=0.08427, avg_loss=0.09165, mel_loss=0.04006, linear_loss=0.04421]
[2020-05-12 00:30:34.010]  Step 148672  [3.295 sec/step, loss=0.08388, avg_loss=0.09155, mel_loss=0.03685, linear_loss=0.04703]
[2020-05-12 00:30:39.486]  Step 148673  [3.341 sec/step, loss=0.09536, avg_loss=0.09170, mel_loss=0.04293, linear_loss=0.05243]
[2020-05-12 00:30:41.360]  Step 148674  [3.342 sec/step, loss=0.08831, avg_loss=0.09167, mel_loss=0.03909, linear_loss=0.04922]
[2020-05-12 00:30:43.147]  Step 148675  [3.301 sec/step, loss=0.09187, avg_loss=0.09159, mel_loss=0.04037, linear_loss=0.05150]
[2020-05-12 00:30:45.179]  Step 148676  [3.297 sec/step, loss=0.09428, avg_loss=0.09160, mel_loss=0.04187, linear_loss=0.05241]
[2020-05-12 00:30:49.417]  Step 148677  [3.310 sec/step, loss=0.09806, avg_loss=0.09163, mel_loss=0.04452, linear_loss=0.05353]
[2020-05-12 00:30:53.539]  Step 148678  [3.340 sec/step, loss=0.09882, avg_loss=0.09177, mel_loss=0.04499, linear_loss=0.05383]
[2020-05-12 00:31:02.708]  Step 148679  [3.418 sec/step, loss=0.09929, avg_loss=0.09188, mel_loss=0.04636, linear_loss=0.05293]
[2020-05-12 00:31:09.527]  Step 148680  [3.455 sec/step, loss=0.09784, avg_loss=0.09186, mel_loss=0.04528, linear_loss=0.05255]
[2020-05-12 00:31:12.212]  Step 148681  [3.413 sec/step, loss=0.09292, avg_loss=0.09180, mel_loss=0.04132, linear_loss=0.05160]
[2020-05-12 00:31:13.094]  Step 148682  [3.403 sec/step, loss=0.07798, avg_loss=0.09165, mel_loss=0.03391, linear_loss=0.04407]
[2020-05-12 00:31:14.548]  Step 148683  [3.372 sec/step, loss=0.08604, avg_loss=0.09152, mel_loss=0.03824, linear_loss=0.04780]
[2020-05-12 00:31:19.815]  Step 148684  [3.364 sec/step, loss=0.09888, avg_loss=0.09153, mel_loss=0.04551, linear_loss=0.05337]
[2020-05-12 00:31:22.198]  Step 148685  [3.380 sec/step, loss=0.09382, avg_loss=0.09169, mel_loss=0.04173, linear_loss=0.05209]
[2020-05-12 00:31:25.157]  Step 148686  [3.399 sec/step, loss=0.09682, avg_loss=0.09181, mel_loss=0.04352, linear_loss=0.05329]
[2020-05-12 00:31:25.714]  Step 148687  [3.273 sec/step, loss=0.07271, avg_loss=0.09168, mel_loss=0.03219, linear_loss=0.04052]
[2020-05-12 00:31:26.927]  Step 148688  [3.263 sec/step, loss=0.08564, avg_loss=0.09159, mel_loss=0.03762, linear_loss=0.04803]
[2020-05-12 00:31:30.007]  Step 148689  [3.276 sec/step, loss=0.09653, avg_loss=0.09165, mel_loss=0.04352, linear_loss=0.05301]
[2020-05-12 00:31:35.819]  Step 148690  [3.246 sec/step, loss=0.09917, avg_loss=0.09170, mel_loss=0.04557, linear_loss=0.05360]
[2020-05-12 00:31:37.179]  Step 148691  [3.187 sec/step, loss=0.08609, avg_loss=0.09158, mel_loss=0.03750, linear_loss=0.04860]
[2020-05-12 00:31:38.183]  Step 148692  [3.163 sec/step, loss=0.08495, avg_loss=0.09149, mel_loss=0.03730, linear_loss=0.04765]
[2020-05-12 00:31:39.989]  Step 148693  [3.173 sec/step, loss=0.08979, avg_loss=0.09164, mel_loss=0.03964, linear_loss=0.05015]
[2020-05-12 00:31:40.737]  Step 148694  [3.152 sec/step, loss=0.07592, avg_loss=0.09145, mel_loss=0.03321, linear_loss=0.04271]
[2020-05-12 00:31:45.149]  Step 148695  [3.180 sec/step, loss=0.09901, avg_loss=0.09153, mel_loss=0.04529, linear_loss=0.05372]
[2020-05-12 00:31:48.776]  Step 148696  [3.206 sec/step, loss=0.09868, avg_loss=0.09169, mel_loss=0.04484, linear_loss=0.05383]
[2020-05-12 00:31:50.432]  Step 148697  [3.167 sec/step, loss=0.08954, avg_loss=0.09159, mel_loss=0.03980, linear_loss=0.04974]
[2020-05-12 00:31:51.602]  Step 148698  [3.128 sec/step, loss=0.08392, avg_loss=0.09145, mel_loss=0.03661, linear_loss=0.04731]
[2020-05-12 00:31:52.210]  Generated 32 batches of size 32 in 1.773 sec
[2020-05-12 00:31:55.117]  Step 148699  [3.141 sec/step, loss=0.09799, avg_loss=0.09150, mel_loss=0.04441, linear_loss=0.05358]
[2020-05-12 00:31:57.296]  Step 148700  [3.148 sec/step, loss=0.09308, avg_loss=0.09156, mel_loss=0.04178, linear_loss=0.05130]
[2020-05-12 00:31:57.297]  Writing summary at step: 148700
[2020-05-12 00:32:04.903]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148700
[2020-05-12 00:32:06.327]  Saving audio and alignment...
[2020-05-12 00:32:10.980]  Input: 여전히 일 소리가 상당히 높은 것을 볼 수가 있습~
[2020-05-12 00:32:14.504]  Step 148701  [3.164 sec/step, loss=0.09446, avg_loss=0.09158, mel_loss=0.04272, linear_loss=0.05175]
[2020-05-12 00:32:29.092]  Step 148702  [3.296 sec/step, loss=0.07737, avg_loss=0.09150, mel_loss=0.03698, linear_loss=0.04039]
[2020-05-12 00:32:29.933]  Step 148703  [3.271 sec/step, loss=0.07805, avg_loss=0.09132, mel_loss=0.03399, linear_loss=0.04406]
[2020-05-12 00:32:31.912]  Step 148704  [3.259 sec/step, loss=0.09074, avg_loss=0.09126, mel_loss=0.04005, linear_loss=0.05069]
[2020-05-12 00:32:34.333]  Step 148705  [3.259 sec/step, loss=0.09406, avg_loss=0.09126, mel_loss=0.04206, linear_loss=0.05200]
[2020-05-12 00:32:35.441]  Step 148706  [3.262 sec/step, loss=0.08509, avg_loss=0.09133, mel_loss=0.03702, linear_loss=0.04807]
[2020-05-12 00:32:37.608]  Step 148707  [3.243 sec/step, loss=0.09408, avg_loss=0.09131, mel_loss=0.04200, linear_loss=0.05209]
[2020-05-12 00:32:39.622]  Step 148708  [3.227 sec/step, loss=0.09276, avg_loss=0.09124, mel_loss=0.04109, linear_loss=0.05168]
[2020-05-12 00:32:47.268]  Step 148709  [3.287 sec/step, loss=0.10040, avg_loss=0.09134, mel_loss=0.04652, linear_loss=0.05388]
[2020-05-12 00:32:48.166]  Step 148710  [3.258 sec/step, loss=0.07844, avg_loss=0.09113, mel_loss=0.03437, linear_loss=0.04406]
[2020-05-12 00:32:50.203]  Step 148711  [3.252 sec/step, loss=0.09204, avg_loss=0.09112, mel_loss=0.04074, linear_loss=0.05129]
[2020-05-12 00:32:55.969]  Step 148712  [3.295 sec/step, loss=0.09870, avg_loss=0.09123, mel_loss=0.04548, linear_loss=0.05322]
[2020-05-12 00:33:04.138]  Step 148713  [3.359 sec/step, loss=0.09672, avg_loss=0.09129, mel_loss=0.04513, linear_loss=0.05159]
[2020-05-12 00:33:07.731]  Step 148714  [3.374 sec/step, loss=0.09878, avg_loss=0.09134, mel_loss=0.04491, linear_loss=0.05387]
[2020-05-12 00:33:10.534]  Step 148715  [3.393 sec/step, loss=0.09547, avg_loss=0.09146, mel_loss=0.04298, linear_loss=0.05249]
[2020-05-12 00:33:11.543]  Step 148716  [3.356 sec/step, loss=0.08330, avg_loss=0.09131, mel_loss=0.03625, linear_loss=0.04705]
[2020-05-12 00:33:12.530]  Step 148717  [3.331 sec/step, loss=0.08200, avg_loss=0.09116, mel_loss=0.03565, linear_loss=0.04634]
[2020-05-12 00:33:15.998]  Step 148718  [3.352 sec/step, loss=0.09565, avg_loss=0.09124, mel_loss=0.04325, linear_loss=0.05240]
[2020-05-12 00:33:17.551]  Step 148719  [3.356 sec/step, loss=0.08981, avg_loss=0.09127, mel_loss=0.03972, linear_loss=0.05009]
[2020-05-12 00:33:20.716]  Step 148720  [3.305 sec/step, loss=0.09732, avg_loss=0.09125, mel_loss=0.04383, linear_loss=0.05349]
[2020-05-12 00:33:23.058]  Step 148721  [3.288 sec/step, loss=0.09389, avg_loss=0.09122, mel_loss=0.04204, linear_loss=0.05185]
[2020-05-12 00:33:24.799]  Step 148722  [3.297 sec/step, loss=0.09125, avg_loss=0.09129, mel_loss=0.04028, linear_loss=0.05097]
[2020-05-12 00:33:26.100]  Step 148723  [3.242 sec/step, loss=0.08504, avg_loss=0.09113, mel_loss=0.03754, linear_loss=0.04750]
[2020-05-12 00:33:31.212]  Step 148724  [3.266 sec/step, loss=0.09774, avg_loss=0.09118, mel_loss=0.04494, linear_loss=0.05281]
[2020-05-12 00:33:32.553]  Step 148725  [3.248 sec/step, loss=0.09022, avg_loss=0.09112, mel_loss=0.03960, linear_loss=0.05062]
[2020-05-12 00:33:33.694]  Step 148726  [3.244 sec/step, loss=0.08628, avg_loss=0.09107, mel_loss=0.03787, linear_loss=0.04841]
[2020-05-12 00:33:34.214]  Step 148727  [3.220 sec/step, loss=0.07673, avg_loss=0.09088, mel_loss=0.03376, linear_loss=0.04297]
[2020-05-12 00:33:35.002]  Step 148728  [3.192 sec/step, loss=0.08202, avg_loss=0.09075, mel_loss=0.03556, linear_loss=0.04646]
[2020-05-12 00:33:35.981]  Generated 32 batches of size 32 in 1.762 sec
[2020-05-12 00:33:39.624]  Step 148729  [3.231 sec/step, loss=0.09891, avg_loss=0.09094, mel_loss=0.04518, linear_loss=0.05372]
[2020-05-12 00:33:45.692]  Step 148730  [3.270 sec/step, loss=0.09864, avg_loss=0.09100, mel_loss=0.04556, linear_loss=0.05307]
[2020-05-12 00:33:58.661]  Step 148731  [3.389 sec/step, loss=0.08431, avg_loss=0.09099, mel_loss=0.04020, linear_loss=0.04410]
[2020-05-12 00:34:02.692]  Step 148732  [3.375 sec/step, loss=0.09721, avg_loss=0.09098, mel_loss=0.04393, linear_loss=0.05328]
[2020-05-12 00:34:07.065]  Step 148733  [3.400 sec/step, loss=0.09678, avg_loss=0.09103, mel_loss=0.04398, linear_loss=0.05281]
[2020-05-12 00:34:08.636]  Step 148734  [3.357 sec/step, loss=0.09126, avg_loss=0.09095, mel_loss=0.04002, linear_loss=0.05124]
[2020-05-12 00:34:11.282]  Step 148735  [3.341 sec/step, loss=0.09379, avg_loss=0.09090, mel_loss=0.04220, linear_loss=0.05159]
[2020-05-12 00:34:14.383]  Step 148736  [3.231 sec/step, loss=0.09601, avg_loss=0.09110, mel_loss=0.04318, linear_loss=0.05283]
[2020-05-12 00:34:28.490]  Step 148737  [3.334 sec/step, loss=0.07678, avg_loss=0.09089, mel_loss=0.03673, linear_loss=0.04005]
[2020-05-12 00:34:29.260]  Step 148738  [3.318 sec/step, loss=0.07750, avg_loss=0.09073, mel_loss=0.03388, linear_loss=0.04361]
[2020-05-12 00:34:31.280]  Step 148739  [3.264 sec/step, loss=0.09096, avg_loss=0.09063, mel_loss=0.04047, linear_loss=0.05049]
[2020-05-12 00:34:32.466]  Step 148740  [3.262 sec/step, loss=0.08392, avg_loss=0.09062, mel_loss=0.03649, linear_loss=0.04743]
[2020-05-12 00:34:33.382]  Step 148741  [3.255 sec/step, loss=0.08156, avg_loss=0.09052, mel_loss=0.03514, linear_loss=0.04642]
[2020-05-12 00:34:34.405]  Step 148742  [3.260 sec/step, loss=0.08298, avg_loss=0.09062, mel_loss=0.03613, linear_loss=0.04685]
[2020-05-12 00:34:36.847]  Step 148743  [3.277 sec/step, loss=0.09466, avg_loss=0.09078, mel_loss=0.04217, linear_loss=0.05248]
[2020-05-12 00:34:40.596]  Step 148744  [3.287 sec/step, loss=0.09816, avg_loss=0.09082, mel_loss=0.04451, linear_loss=0.05365]
[2020-05-12 00:34:49.516]  Step 148745  [3.345 sec/step, loss=0.09576, avg_loss=0.09081, mel_loss=0.04482, linear_loss=0.05094]
[2020-05-12 00:34:52.547]  Step 148746  [3.299 sec/step, loss=0.09608, avg_loss=0.09078, mel_loss=0.04317, linear_loss=0.05290]
[2020-05-12 00:34:56.014]  Step 148747  [3.291 sec/step, loss=0.09526, avg_loss=0.09075, mel_loss=0.04296, linear_loss=0.05230]
[2020-05-12 00:34:56.572]  Step 148748  [3.288 sec/step, loss=0.06999, avg_loss=0.09065, mel_loss=0.03094, linear_loss=0.03905]
[2020-05-12 00:35:02.545]  Step 148749  [3.329 sec/step, loss=0.09768, avg_loss=0.09070, mel_loss=0.04522, linear_loss=0.05246]
[2020-05-12 00:35:03.652]  Step 148750  [3.328 sec/step, loss=0.08477, avg_loss=0.09068, mel_loss=0.03689, linear_loss=0.04787]
[2020-05-12 00:35:03.652]  Writing summary at step: 148750
[2020-05-12 00:35:11.179]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148750
[2020-05-12 00:35:12.606]  Saving audio and alignment...
[2020-05-12 00:35:19.872]  Input: 이렇게 외쳐 주시고요 이런 부분에 있어서 실제로 제스쳐가 들어가면 훨씬~_______________________
[2020-05-12 00:35:21.521]  Step 148751  [3.324 sec/step, loss=0.09052, avg_loss=0.09065, mel_loss=0.04032, linear_loss=0.05020]
[2020-05-12 00:35:24.154]  Step 148752  [3.320 sec/step, loss=0.09299, avg_loss=0.09063, mel_loss=0.04184, linear_loss=0.05115]
[2020-05-12 00:35:25.950]  Step 148753  [3.328 sec/step, loss=0.09099, avg_loss=0.09070, mel_loss=0.04019, linear_loss=0.05080]
[2020-05-12 00:35:30.230]  Step 148754  [3.349 sec/step, loss=0.09714, avg_loss=0.09076, mel_loss=0.04420, linear_loss=0.05294]
[2020-05-12 00:35:31.044]  Step 148755  [3.339 sec/step, loss=0.07699, avg_loss=0.09061, mel_loss=0.03351, linear_loss=0.04348]
[2020-05-12 00:35:33.248]  Step 148756  [3.347 sec/step, loss=0.09238, avg_loss=0.09063, mel_loss=0.04127, linear_loss=0.05111]
[2020-05-12 00:35:34.707]  Step 148757  [3.315 sec/step, loss=0.08911, avg_loss=0.09052, mel_loss=0.03926, linear_loss=0.04985]
[2020-05-12 00:35:36.073]  Step 148758  [3.309 sec/step, loss=0.08764, avg_loss=0.09049, mel_loss=0.03858, linear_loss=0.04906]
[2020-05-12 00:35:36.497]  Generated 32 batches of size 32 in 1.786 sec
[2020-05-12 00:35:39.688]  Step 148759  [3.335 sec/step, loss=0.09647, avg_loss=0.09060, mel_loss=0.04380, linear_loss=0.05267]
[2020-05-12 00:35:42.588]  Step 148760  [3.339 sec/step, loss=0.09600, avg_loss=0.09062, mel_loss=0.04346, linear_loss=0.05253]
[2020-05-12 00:35:45.829]  Step 148761  [3.355 sec/step, loss=0.09912, avg_loss=0.09069, mel_loss=0.04495, linear_loss=0.05417]
[2020-05-12 00:35:50.314]  Step 148762  [3.310 sec/step, loss=0.09834, avg_loss=0.09069, mel_loss=0.04489, linear_loss=0.05345]
[2020-05-12 00:35:55.776]  Step 148763  [3.299 sec/step, loss=0.09922, avg_loss=0.09070, mel_loss=0.04556, linear_loss=0.05365]
[2020-05-12 00:35:57.515]  Step 148764  [3.284 sec/step, loss=0.09180, avg_loss=0.09064, mel_loss=0.04072, linear_loss=0.05108]
[2020-05-12 00:35:59.564]  Step 148765  [3.297 sec/step, loss=0.09379, avg_loss=0.09085, mel_loss=0.04180, linear_loss=0.05199]
[2020-05-12 00:36:00.900]  Step 148766  [3.254 sec/step, loss=0.08959, avg_loss=0.09075, mel_loss=0.03951, linear_loss=0.05008]
[2020-05-12 00:36:02.909]  Step 148767  [3.267 sec/step, loss=0.09186, avg_loss=0.09089, mel_loss=0.04113, linear_loss=0.05073]
[2020-05-12 00:36:04.341]  Step 148768  [3.268 sec/step, loss=0.08570, avg_loss=0.09089, mel_loss=0.03799, linear_loss=0.04771]
[2020-05-12 00:36:07.766]  Step 148769  [3.261 sec/step, loss=0.09454, avg_loss=0.09086, mel_loss=0.04255, linear_loss=0.05199]
[2020-05-12 00:36:10.670]  Step 148770  [3.237 sec/step, loss=0.09679, avg_loss=0.09084, mel_loss=0.04346, linear_loss=0.05334]
[2020-05-12 00:36:12.861]  Step 148771  [3.106 sec/step, loss=0.09196, avg_loss=0.09091, mel_loss=0.04105, linear_loss=0.05091]
[2020-05-12 00:36:15.296]  Step 148772  [3.114 sec/step, loss=0.09232, avg_loss=0.09100, mel_loss=0.04135, linear_loss=0.05097]
[2020-05-12 00:36:22.031]  Step 148773  [3.126 sec/step, loss=0.09914, avg_loss=0.09104, mel_loss=0.04585, linear_loss=0.05328]
[2020-05-12 00:36:22.872]  Step 148774  [3.116 sec/step, loss=0.08198, avg_loss=0.09097, mel_loss=0.03540, linear_loss=0.04658]
[2020-05-12 00:36:24.110]  Step 148775  [3.110 sec/step, loss=0.08665, avg_loss=0.09092, mel_loss=0.03826, linear_loss=0.04839]
[2020-05-12 00:36:25.140]  Step 148776  [3.100 sec/step, loss=0.08273, avg_loss=0.09081, mel_loss=0.03623, linear_loss=0.04650]
[2020-05-12 00:36:30.933]  Step 148777  [3.116 sec/step, loss=0.10014, avg_loss=0.09083, mel_loss=0.04608, linear_loss=0.05407]
[2020-05-12 00:36:32.015]  Step 148778  [3.085 sec/step, loss=0.08706, avg_loss=0.09071, mel_loss=0.03782, linear_loss=0.04923]
[2020-05-12 00:36:33.735]  Step 148779  [3.011 sec/step, loss=0.09130, avg_loss=0.09063, mel_loss=0.03987, linear_loss=0.05142]
[2020-05-12 00:36:39.105]  Step 148780  [2.996 sec/step, loss=0.09756, avg_loss=0.09063, mel_loss=0.04489, linear_loss=0.05267]
[2020-05-12 00:36:41.959]  Step 148781  [2.998 sec/step, loss=0.09333, avg_loss=0.09063, mel_loss=0.04182, linear_loss=0.05151]
[2020-05-12 00:36:46.308]  Step 148782  [3.033 sec/step, loss=0.09826, avg_loss=0.09083, mel_loss=0.04479, linear_loss=0.05347]
[2020-05-12 00:36:48.112]  Step 148783  [3.036 sec/step, loss=0.09203, avg_loss=0.09089, mel_loss=0.04068, linear_loss=0.05135]
[2020-05-12 00:37:01.128]  Step 148784  [3.114 sec/step, loss=0.08430, avg_loss=0.09075, mel_loss=0.03998, linear_loss=0.04432]
[2020-05-12 00:37:02.442]  Step 148785  [3.103 sec/step, loss=0.08611, avg_loss=0.09067, mel_loss=0.03773, linear_loss=0.04838]
[2020-05-12 00:37:04.065]  Step 148786  [3.090 sec/step, loss=0.08876, avg_loss=0.09059, mel_loss=0.03917, linear_loss=0.04960]
[2020-05-12 00:37:04.625]  Step 148787  [3.090 sec/step, loss=0.07153, avg_loss=0.09058, mel_loss=0.03174, linear_loss=0.03979]
[2020-05-12 00:37:07.716]  Step 148788  [3.109 sec/step, loss=0.09838, avg_loss=0.09071, mel_loss=0.04451, linear_loss=0.05388]
[2020-05-12 00:37:11.840]  Step 148789  [3.119 sec/step, loss=0.09750, avg_loss=0.09072, mel_loss=0.04432, linear_loss=0.05317]
[2020-05-12 00:37:13.510]  Generated 32 batches of size 32 in 1.664 sec
[2020-05-12 00:37:19.459]  Step 148790  [3.137 sec/step, loss=0.10006, avg_loss=0.09072, mel_loss=0.04639, linear_loss=0.05367]
[2020-05-12 00:37:23.161]  Step 148791  [3.161 sec/step, loss=0.09803, avg_loss=0.09084, mel_loss=0.04448, linear_loss=0.05355]
[2020-05-12 00:37:25.611]  Step 148792  [3.175 sec/step, loss=0.09482, avg_loss=0.09094, mel_loss=0.04231, linear_loss=0.05252]
[2020-05-12 00:37:26.446]  Step 148793  [3.165 sec/step, loss=0.07716, avg_loss=0.09082, mel_loss=0.03440, linear_loss=0.04275]
[2020-05-12 00:37:29.906]  Step 148794  [3.192 sec/step, loss=0.09754, avg_loss=0.09103, mel_loss=0.04416, linear_loss=0.05338]
[2020-05-12 00:37:38.230]  Step 148795  [3.232 sec/step, loss=0.09875, avg_loss=0.09103, mel_loss=0.04623, linear_loss=0.05252]
[2020-05-12 00:37:40.171]  Step 148796  [3.215 sec/step, loss=0.09053, avg_loss=0.09095, mel_loss=0.03991, linear_loss=0.05062]
[2020-05-12 00:37:40.919]  Step 148797  [3.206 sec/step, loss=0.08134, avg_loss=0.09087, mel_loss=0.03531, linear_loss=0.04603]
[2020-05-12 00:37:45.690]  Step 148798  [3.242 sec/step, loss=0.09839, avg_loss=0.09101, mel_loss=0.04491, linear_loss=0.05348]
[2020-05-12 00:37:47.057]  Step 148799  [3.220 sec/step, loss=0.08606, avg_loss=0.09089, mel_loss=0.03747, linear_loss=0.04859]
[2020-05-12 00:37:51.896]  Step 148800  [3.247 sec/step, loss=0.09840, avg_loss=0.09094, mel_loss=0.04499, linear_loss=0.05340]
[2020-05-12 00:37:51.896]  Writing summary at step: 148800
[2020-05-12 00:37:54.939]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148800
[2020-05-12 00:37:56.385]  Saving audio and alignment...
[2020-05-12 00:37:59.177]  Input: 일단 묵독을 통해서~___________
[2020-05-12 00:38:03.598]  Step 148801  [3.256 sec/step, loss=0.09604, avg_loss=0.09096, mel_loss=0.04355, linear_loss=0.05249]
[2020-05-12 00:38:04.666]  Step 148802  [3.120 sec/step, loss=0.08261, avg_loss=0.09101, mel_loss=0.03648, linear_loss=0.04613]
[2020-05-12 00:38:05.585]  Step 148803  [3.121 sec/step, loss=0.08281, avg_loss=0.09106, mel_loss=0.03598, linear_loss=0.04683]
[2020-05-12 00:38:09.980]  Step 148804  [3.145 sec/step, loss=0.10106, avg_loss=0.09116, mel_loss=0.04607, linear_loss=0.05499]
[2020-05-12 00:38:10.539]  Step 148805  [3.127 sec/step, loss=0.07155, avg_loss=0.09094, mel_loss=0.03186, linear_loss=0.03969]
[2020-05-12 00:38:23.616]  Step 148806  [3.246 sec/step, loss=0.08425, avg_loss=0.09093, mel_loss=0.03995, linear_loss=0.04430]
[2020-05-12 00:38:26.104]  Step 148807  [3.250 sec/step, loss=0.09304, avg_loss=0.09092, mel_loss=0.04137, linear_loss=0.05167]
[2020-05-12 00:38:28.905]  Step 148808  [3.258 sec/step, loss=0.09444, avg_loss=0.09094, mel_loss=0.04243, linear_loss=0.05202]
[2020-05-12 00:38:30.458]  Step 148809  [3.197 sec/step, loss=0.09089, avg_loss=0.09084, mel_loss=0.04041, linear_loss=0.05047]
[2020-05-12 00:38:34.178]  Step 148810  [3.225 sec/step, loss=0.09799, avg_loss=0.09104, mel_loss=0.04443, linear_loss=0.05356]
[2020-05-12 00:38:35.878]  Step 148811  [3.221 sec/step, loss=0.09088, avg_loss=0.09103, mel_loss=0.04011, linear_loss=0.05076]
[2020-05-12 00:38:37.650]  Step 148812  [3.182 sec/step, loss=0.09197, avg_loss=0.09096, mel_loss=0.04079, linear_loss=0.05118]
[2020-05-12 00:38:41.049]  Step 148813  [3.134 sec/step, loss=0.09392, avg_loss=0.09093, mel_loss=0.04257, linear_loss=0.05135]
[2020-05-12 00:38:43.476]  Step 148814  [3.122 sec/step, loss=0.09185, avg_loss=0.09086, mel_loss=0.04095, linear_loss=0.05089]
[2020-05-12 00:38:44.281]  Step 148815  [3.102 sec/step, loss=0.08047, avg_loss=0.09071, mel_loss=0.03480, linear_loss=0.04568]
[2020-05-12 00:38:53.150]  Step 148816  [3.181 sec/step, loss=0.09905, avg_loss=0.09087, mel_loss=0.04642, linear_loss=0.05263]
[2020-05-12 00:38:55.261]  Step 148817  [3.192 sec/step, loss=0.09060, avg_loss=0.09095, mel_loss=0.04035, linear_loss=0.05026]
[2020-05-12 00:39:00.973]  Step 148818  [3.214 sec/step, loss=0.10047, avg_loss=0.09100, mel_loss=0.04638, linear_loss=0.05409]
[2020-05-12 00:39:02.133]  Step 148819  [3.211 sec/step, loss=0.08596, avg_loss=0.09096, mel_loss=0.03740, linear_loss=0.04856]
[2020-05-12 00:39:03.248]  Step 148820  [3.190 sec/step, loss=0.08500, avg_loss=0.09084, mel_loss=0.03718, linear_loss=0.04782]
[2020-05-12 00:39:03.858]  Generated 32 batches of size 32 in 1.720 sec
[2020-05-12 00:39:06.831]  Step 148821  [3.202 sec/step, loss=0.09795, avg_loss=0.09088, mel_loss=0.04410, linear_loss=0.05386]
[2020-05-12 00:39:12.130]  Step 148822  [3.238 sec/step, loss=0.09920, avg_loss=0.09096, mel_loss=0.04548, linear_loss=0.05372]
[2020-05-12 00:39:15.298]  Step 148823  [3.257 sec/step, loss=0.09868, avg_loss=0.09110, mel_loss=0.04451, linear_loss=0.05417]
[2020-05-12 00:39:22.132]  Step 148824  [3.274 sec/step, loss=0.09942, avg_loss=0.09111, mel_loss=0.04595, linear_loss=0.05347]
[2020-05-12 00:39:22.924]  Step 148825  [3.268 sec/step, loss=0.07638, avg_loss=0.09098, mel_loss=0.03334, linear_loss=0.04304]
[2020-05-12 00:39:30.344]  Step 148826  [3.331 sec/step, loss=0.09936, avg_loss=0.09111, mel_loss=0.04607, linear_loss=0.05329]
[2020-05-12 00:39:32.263]  Step 148827  [3.345 sec/step, loss=0.09188, avg_loss=0.09126, mel_loss=0.04068, linear_loss=0.05120]
[2020-05-12 00:39:34.400]  Step 148828  [3.359 sec/step, loss=0.09354, avg_loss=0.09137, mel_loss=0.04154, linear_loss=0.05199]
[2020-05-12 00:39:41.005]  Step 148829  [3.379 sec/step, loss=0.09771, avg_loss=0.09136, mel_loss=0.04512, linear_loss=0.05259]
[2020-05-12 00:39:42.005]  Step 148830  [3.328 sec/step, loss=0.08164, avg_loss=0.09119, mel_loss=0.03542, linear_loss=0.04622]
[2020-05-12 00:39:46.398]  Step 148831  [3.242 sec/step, loss=0.09866, avg_loss=0.09134, mel_loss=0.04514, linear_loss=0.05352]
[2020-05-12 00:39:48.019]  Step 148832  [3.218 sec/step, loss=0.08810, avg_loss=0.09124, mel_loss=0.03884, linear_loss=0.04926]
[2020-05-12 00:40:02.386]  Step 148833  [3.318 sec/step, loss=0.07912, avg_loss=0.09107, mel_loss=0.03782, linear_loss=0.04130]
[2020-05-12 00:40:05.046]  Step 148834  [3.329 sec/step, loss=0.09291, avg_loss=0.09108, mel_loss=0.04175, linear_loss=0.05116]
[2020-05-12 00:40:08.191]  Step 148835  [3.334 sec/step, loss=0.09628, avg_loss=0.09111, mel_loss=0.04350, linear_loss=0.05277]
[2020-05-12 00:40:09.198]  Step 148836  [3.313 sec/step, loss=0.08295, avg_loss=0.09098, mel_loss=0.03601, linear_loss=0.04694]
[2020-05-12 00:40:10.537]  Step 148837  [3.185 sec/step, loss=0.08826, avg_loss=0.09109, mel_loss=0.03912, linear_loss=0.04914]
[2020-05-12 00:40:14.536]  Step 148838  [3.217 sec/step, loss=0.09977, avg_loss=0.09132, mel_loss=0.04544, linear_loss=0.05432]
[2020-05-12 00:40:15.289]  Step 148839  [3.205 sec/step, loss=0.07558, avg_loss=0.09116, mel_loss=0.03311, linear_loss=0.04247]
[2020-05-12 00:40:17.114]  Step 148840  [3.211 sec/step, loss=0.09110, avg_loss=0.09123, mel_loss=0.04045, linear_loss=0.05065]
[2020-05-12 00:40:20.590]  Step 148841  [3.237 sec/step, loss=0.09528, avg_loss=0.09137, mel_loss=0.04312, linear_loss=0.05216]
[2020-05-12 00:40:23.666]  Step 148842  [3.257 sec/step, loss=0.09735, avg_loss=0.09151, mel_loss=0.04397, linear_loss=0.05338]
[2020-05-12 00:40:24.772]  Step 148843  [3.244 sec/step, loss=0.08470, avg_loss=0.09141, mel_loss=0.03644, linear_loss=0.04826]
[2020-05-12 00:40:26.777]  Step 148844  [3.227 sec/step, loss=0.09398, avg_loss=0.09137, mel_loss=0.04192, linear_loss=0.05206]
[2020-05-12 00:40:31.635]  Step 148845  [3.186 sec/step, loss=0.09730, avg_loss=0.09139, mel_loss=0.04425, linear_loss=0.05305]
[2020-05-12 00:40:33.017]  Step 148846  [3.169 sec/step, loss=0.08869, avg_loss=0.09131, mel_loss=0.03923, linear_loss=0.04946]
[2020-05-12 00:40:33.818]  Step 148847  [3.143 sec/step, loss=0.07836, avg_loss=0.09115, mel_loss=0.03422, linear_loss=0.04414]
[2020-05-12 00:40:35.087]  Step 148848  [3.150 sec/step, loss=0.08499, avg_loss=0.09130, mel_loss=0.03753, linear_loss=0.04746]
[2020-05-12 00:40:35.847]  Step 148849  [3.098 sec/step, loss=0.07498, avg_loss=0.09107, mel_loss=0.03287, linear_loss=0.04211]
[2020-05-12 00:40:37.590]  Step 148850  [3.104 sec/step, loss=0.09187, avg_loss=0.09114, mel_loss=0.04004, linear_loss=0.05183]
[2020-05-12 00:40:37.590]  Writing summary at step: 148850
[2020-05-12 00:40:39.620]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148850
[2020-05-12 00:40:43.714]  Saving audio and alignment...
[2020-05-12 00:40:49.412]  Generated 32 batches of size 32 in 3.995 sec
[2020-05-12 00:40:53.322]  Input: 여덟시간은 잠을 자고 또 여덟시간은 생활에 필요한 다른 일에 쓰고~
[2020-05-12 00:40:55.829]  Step 148851  [3.113 sec/step, loss=0.09529, avg_loss=0.09119, mel_loss=0.04257, linear_loss=0.05273]
[2020-05-12 00:40:58.079]  Step 148852  [3.109 sec/step, loss=0.09199, avg_loss=0.09118, mel_loss=0.04114, linear_loss=0.05085]
[2020-05-12 00:41:01.985]  Step 148853  [3.130 sec/step, loss=0.09770, avg_loss=0.09124, mel_loss=0.04461, linear_loss=0.05308]
[2020-05-12 00:41:03.623]  Step 148854  [3.104 sec/step, loss=0.08899, avg_loss=0.09116, mel_loss=0.03927, linear_loss=0.04972]
[2020-05-12 00:41:09.406]  Step 148855  [3.153 sec/step, loss=0.09644, avg_loss=0.09136, mel_loss=0.04443, linear_loss=0.05200]
[2020-05-12 00:41:16.776]  Step 148856  [3.205 sec/step, loss=0.09785, avg_loss=0.09141, mel_loss=0.04564, linear_loss=0.05222]
[2020-05-12 00:41:19.577]  Step 148857  [3.218 sec/step, loss=0.09372, avg_loss=0.09146, mel_loss=0.04231, linear_loss=0.05142]
[2020-05-12 00:41:28.512]  Step 148858  [3.294 sec/step, loss=0.09753, avg_loss=0.09156, mel_loss=0.04566, linear_loss=0.05187]
[2020-05-12 00:41:29.071]  Step 148859  [3.263 sec/step, loss=0.07177, avg_loss=0.09131, mel_loss=0.03203, linear_loss=0.03974]
[2020-05-12 00:41:31.684]  Step 148860  [3.261 sec/step, loss=0.09523, avg_loss=0.09130, mel_loss=0.04253, linear_loss=0.05270]
[2020-05-12 00:41:32.698]  Step 148861  [3.238 sec/step, loss=0.08357, avg_loss=0.09115, mel_loss=0.03643, linear_loss=0.04714]
[2020-05-12 00:41:36.469]  Step 148862  [3.231 sec/step, loss=0.09752, avg_loss=0.09114, mel_loss=0.04408, linear_loss=0.05344]
[2020-05-12 00:41:42.094]  Step 148863  [3.233 sec/step, loss=0.09926, avg_loss=0.09114, mel_loss=0.04575, linear_loss=0.05350]
[2020-05-12 00:41:43.954]  Step 148864  [3.234 sec/step, loss=0.08859, avg_loss=0.09111, mel_loss=0.03901, linear_loss=0.04957]
[2020-05-12 00:41:45.406]  Step 148865  [3.228 sec/step, loss=0.08929, avg_loss=0.09106, mel_loss=0.03949, linear_loss=0.04980]
[2020-05-12 00:41:47.414]  Step 148866  [3.235 sec/step, loss=0.09250, avg_loss=0.09109, mel_loss=0.04081, linear_loss=0.05169]
[2020-05-12 00:41:49.874]  Step 148867  [3.239 sec/step, loss=0.09276, avg_loss=0.09110, mel_loss=0.04122, linear_loss=0.05154]
[2020-05-12 00:41:51.536]  Step 148868  [3.242 sec/step, loss=0.09247, avg_loss=0.09117, mel_loss=0.04091, linear_loss=0.05156]
[2020-05-12 00:41:56.765]  Step 148869  [3.260 sec/step, loss=0.09686, avg_loss=0.09119, mel_loss=0.04432, linear_loss=0.05254]
[2020-05-12 00:42:01.282]  Step 148870  [3.276 sec/step, loss=0.09840, avg_loss=0.09121, mel_loss=0.04512, linear_loss=0.05328]
[2020-05-12 00:42:04.875]  Step 148871  [3.290 sec/step, loss=0.09651, avg_loss=0.09125, mel_loss=0.04371, linear_loss=0.05281]
[2020-05-12 00:42:13.296]  Step 148872  [3.350 sec/step, loss=0.09707, avg_loss=0.09130, mel_loss=0.04532, linear_loss=0.05174]
[2020-05-12 00:42:16.271]  Step 148873  [3.312 sec/step, loss=0.09659, avg_loss=0.09127, mel_loss=0.04361, linear_loss=0.05298]
[2020-05-12 00:42:18.331]  Step 148874  [3.324 sec/step, loss=0.09368, avg_loss=0.09139, mel_loss=0.04164, linear_loss=0.05204]
[2020-05-12 00:42:19.132]  Step 148875  [3.320 sec/step, loss=0.07794, avg_loss=0.09130, mel_loss=0.03382, linear_loss=0.04413]
[2020-05-12 00:42:20.248]  Step 148876  [3.321 sec/step, loss=0.08653, avg_loss=0.09134, mel_loss=0.03779, linear_loss=0.04874]
[2020-05-12 00:42:23.668]  Step 148877  [3.297 sec/step, loss=0.09567, avg_loss=0.09130, mel_loss=0.04327, linear_loss=0.05240]
[2020-05-12 00:42:24.886]  Step 148878  [3.298 sec/step, loss=0.08604, avg_loss=0.09129, mel_loss=0.03769, linear_loss=0.04835]
[2020-05-12 00:42:26.222]  Step 148879  [3.294 sec/step, loss=0.08648, avg_loss=0.09124, mel_loss=0.03779, linear_loss=0.04870]
[2020-05-12 00:42:27.854]  Step 148880  [3.257 sec/step, loss=0.08791, avg_loss=0.09114, mel_loss=0.03906, linear_loss=0.04885]
[2020-05-12 00:42:34.768]  Step 148881  [3.298 sec/step, loss=0.09924, avg_loss=0.09120, mel_loss=0.04624, linear_loss=0.05300]
[2020-05-12 00:42:36.532]  Generated 32 batches of size 32 in 1.758 sec
[2020-05-12 00:42:36.835]  Step 148882  [3.275 sec/step, loss=0.09204, avg_loss=0.09114, mel_loss=0.04079, linear_loss=0.05124]
[2020-05-12 00:42:39.170]  Step 148883  [3.280 sec/step, loss=0.09346, avg_loss=0.09115, mel_loss=0.04174, linear_loss=0.05172]
[2020-05-12 00:42:43.450]  Step 148884  [3.193 sec/step, loss=0.09723, avg_loss=0.09128, mel_loss=0.04410, linear_loss=0.05313]
[2020-05-12 00:42:57.585]  Step 148885  [3.321 sec/step, loss=0.07543, avg_loss=0.09118, mel_loss=0.03606, linear_loss=0.03937]
[2020-05-12 00:42:58.332]  Step 148886  [3.312 sec/step, loss=0.07434, avg_loss=0.09103, mel_loss=0.03284, linear_loss=0.04150]
[2020-05-12 00:43:01.173]  Step 148887  [3.335 sec/step, loss=0.09499, avg_loss=0.09127, mel_loss=0.04273, linear_loss=0.05226]
[2020-05-12 00:43:02.088]  Step 148888  [3.313 sec/step, loss=0.08044, avg_loss=0.09109, mel_loss=0.03495, linear_loss=0.04548]
[2020-05-12 00:43:05.274]  Step 148889  [3.304 sec/step, loss=0.09845, avg_loss=0.09110, mel_loss=0.04429, linear_loss=0.05416]
[2020-05-12 00:43:11.608]  Step 148890  [3.291 sec/step, loss=0.09889, avg_loss=0.09109, mel_loss=0.04581, linear_loss=0.05308]
[2020-05-12 00:43:13.625]  Step 148891  [3.274 sec/step, loss=0.09132, avg_loss=0.09102, mel_loss=0.04039, linear_loss=0.05092]
[2020-05-12 00:43:15.398]  Step 148892  [3.267 sec/step, loss=0.08917, avg_loss=0.09096, mel_loss=0.03957, linear_loss=0.04960]
[2020-05-12 00:43:18.350]  Step 148893  [3.289 sec/step, loss=0.09623, avg_loss=0.09115, mel_loss=0.04341, linear_loss=0.05282]
[2020-05-12 00:43:20.585]  Step 148894  [3.276 sec/step, loss=0.09211, avg_loss=0.09110, mel_loss=0.04139, linear_loss=0.05072]
[2020-05-12 00:43:25.177]  Step 148895  [3.239 sec/step, loss=0.09953, avg_loss=0.09111, mel_loss=0.04547, linear_loss=0.05405]
[2020-05-12 00:43:39.067]  Step 148896  [3.359 sec/step, loss=0.07547, avg_loss=0.09096, mel_loss=0.03594, linear_loss=0.03953]
[2020-05-12 00:43:44.887]  Step 148897  [3.409 sec/step, loss=0.09708, avg_loss=0.09111, mel_loss=0.04475, linear_loss=0.05233]
[2020-05-12 00:43:45.653]  Step 148898  [3.369 sec/step, loss=0.07247, avg_loss=0.09085, mel_loss=0.03241, linear_loss=0.04007]
[2020-05-12 00:43:49.075]  Step 148899  [3.390 sec/step, loss=0.09606, avg_loss=0.09095, mel_loss=0.04357, linear_loss=0.05249]
[2020-05-12 00:43:54.215]  Step 148900  [3.393 sec/step, loss=0.09725, avg_loss=0.09094, mel_loss=0.04450, linear_loss=0.05276]
[2020-05-12 00:43:54.215]  Writing summary at step: 148900
[2020-05-12 00:43:55.416]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148900
[2020-05-12 00:43:56.835]  Saving audio and alignment...
[2020-05-12 00:44:00.303]  Input: 이렇게 나의 이름도 한번 홍보오~_____________
[2020-05-12 00:44:04.008]  Step 148901  [3.386 sec/step, loss=0.09883, avg_loss=0.09097, mel_loss=0.04475, linear_loss=0.05407]
[2020-05-12 00:44:07.836]  Step 148902  [3.413 sec/step, loss=0.09930, avg_loss=0.09114, mel_loss=0.04463, linear_loss=0.05467]
[2020-05-12 00:44:14.689]  Step 148903  [3.473 sec/step, loss=0.09791, avg_loss=0.09129, mel_loss=0.04532, linear_loss=0.05258]
[2020-05-12 00:44:19.059]  Step 148904  [3.472 sec/step, loss=0.09757, avg_loss=0.09125, mel_loss=0.04452, linear_loss=0.05305]
[2020-05-12 00:44:21.780]  Step 148905  [3.494 sec/step, loss=0.09402, avg_loss=0.09148, mel_loss=0.04203, linear_loss=0.05199]
[2020-05-12 00:44:23.938]  Step 148906  [3.385 sec/step, loss=0.09123, avg_loss=0.09155, mel_loss=0.04071, linear_loss=0.05051]
[2020-05-12 00:44:31.448]  Step 148907  [3.435 sec/step, loss=0.10038, avg_loss=0.09162, mel_loss=0.04670, linear_loss=0.05368]
[2020-05-12 00:44:33.876]  Step 148908  [3.431 sec/step, loss=0.09418, avg_loss=0.09162, mel_loss=0.04233, linear_loss=0.05185]
[2020-05-12 00:44:37.334]  Step 148909  [3.450 sec/step, loss=0.09746, avg_loss=0.09168, mel_loss=0.04408, linear_loss=0.05337]
[2020-05-12 00:44:38.793]  Step 148910  [3.428 sec/step, loss=0.08834, avg_loss=0.09159, mel_loss=0.03881, linear_loss=0.04952]
[2020-05-12 00:44:39.586]  Step 148911  [3.419 sec/step, loss=0.07362, avg_loss=0.09141, mel_loss=0.03190, linear_loss=0.04172]
[2020-05-12 00:44:40.647]  Step 148912  [3.412 sec/step, loss=0.08385, avg_loss=0.09133, mel_loss=0.03609, linear_loss=0.04777]
[2020-05-12 00:44:41.341]  Generated 32 batches of size 32 in 1.749 sec
[2020-05-12 00:44:41.790]  Step 148913  [3.389 sec/step, loss=0.08508, avg_loss=0.09124, mel_loss=0.03693, linear_loss=0.04815]
[2020-05-12 00:44:50.838]  Step 148914  [3.455 sec/step, loss=0.09839, avg_loss=0.09131, mel_loss=0.04577, linear_loss=0.05263]
[2020-05-12 00:44:52.223]  Step 148915  [3.461 sec/step, loss=0.08744, avg_loss=0.09138, mel_loss=0.03824, linear_loss=0.04921]
[2020-05-12 00:44:53.290]  Step 148916  [3.383 sec/step, loss=0.08131, avg_loss=0.09120, mel_loss=0.03520, linear_loss=0.04611]
[2020-05-12 00:44:55.359]  Step 148917  [3.383 sec/step, loss=0.08896, avg_loss=0.09119, mel_loss=0.03925, linear_loss=0.04971]
[2020-05-12 00:44:58.413]  Step 148918  [3.356 sec/step, loss=0.09857, avg_loss=0.09117, mel_loss=0.04438, linear_loss=0.05418]
[2020-05-12 00:44:59.225]  Step 148919  [3.352 sec/step, loss=0.08106, avg_loss=0.09112, mel_loss=0.03536, linear_loss=0.04570]
[2020-05-12 00:45:02.072]  Step 148920  [3.370 sec/step, loss=0.09367, avg_loss=0.09120, mel_loss=0.04212, linear_loss=0.05155]
[2020-05-12 00:45:03.811]  Step 148921  [3.351 sec/step, loss=0.08977, avg_loss=0.09112, mel_loss=0.03989, linear_loss=0.04988]
[2020-05-12 00:45:09.425]  Step 148922  [3.354 sec/step, loss=0.09951, avg_loss=0.09113, mel_loss=0.04556, linear_loss=0.05395]
[2020-05-12 00:45:12.837]  Step 148923  [3.357 sec/step, loss=0.09533, avg_loss=0.09109, mel_loss=0.04292, linear_loss=0.05240]
[2020-05-12 00:45:13.612]  Step 148924  [3.296 sec/step, loss=0.07989, avg_loss=0.09090, mel_loss=0.03441, linear_loss=0.04548]
[2020-05-12 00:45:14.579]  Step 148925  [3.298 sec/step, loss=0.08094, avg_loss=0.09094, mel_loss=0.03486, linear_loss=0.04608]
[2020-05-12 00:45:16.702]  Step 148926  [3.245 sec/step, loss=0.09299, avg_loss=0.09088, mel_loss=0.04143, linear_loss=0.05156]
[2020-05-12 00:45:22.733]  Step 148927  [3.286 sec/step, loss=0.09807, avg_loss=0.09094, mel_loss=0.04515, linear_loss=0.05292]
[2020-05-12 00:45:24.195]  Step 148928  [3.279 sec/step, loss=0.08788, avg_loss=0.09088, mel_loss=0.03874, linear_loss=0.04913]
[2020-05-12 00:45:27.785]  Step 148929  [3.249 sec/step, loss=0.09792, avg_loss=0.09089, mel_loss=0.04428, linear_loss=0.05364]
[2020-05-12 00:45:30.607]  Step 148930  [3.268 sec/step, loss=0.09288, avg_loss=0.09100, mel_loss=0.04173, linear_loss=0.05115]
[2020-05-12 00:45:31.747]  Step 148931  [3.235 sec/step, loss=0.08578, avg_loss=0.09087, mel_loss=0.03749, linear_loss=0.04829]
[2020-05-12 00:45:35.877]  Step 148932  [3.260 sec/step, loss=0.09624, avg_loss=0.09095, mel_loss=0.04370, linear_loss=0.05253]
[2020-05-12 00:45:37.256]  Step 148933  [3.130 sec/step, loss=0.08915, avg_loss=0.09105, mel_loss=0.03952, linear_loss=0.04963]
[2020-05-12 00:45:39.133]  Step 148934  [3.122 sec/step, loss=0.09222, avg_loss=0.09104, mel_loss=0.04087, linear_loss=0.05134]
[2020-05-12 00:45:39.904]  Step 148935  [3.099 sec/step, loss=0.07732, avg_loss=0.09086, mel_loss=0.03422, linear_loss=0.04310]
[2020-05-12 00:45:48.762]  Step 148936  [3.177 sec/step, loss=0.09724, avg_loss=0.09100, mel_loss=0.04550, linear_loss=0.05174]
[2020-05-12 00:45:50.788]  Step 148937  [3.184 sec/step, loss=0.09247, avg_loss=0.09104, mel_loss=0.04122, linear_loss=0.05125]
[2020-05-12 00:45:54.846]  Step 148938  [3.185 sec/step, loss=0.09764, avg_loss=0.09102, mel_loss=0.04447, linear_loss=0.05317]
[2020-05-12 00:45:59.467]  Step 148939  [3.223 sec/step, loss=0.10040, avg_loss=0.09127, mel_loss=0.04590, linear_loss=0.05450]
[2020-05-12 00:46:00.774]  Step 148940  [3.218 sec/step, loss=0.08562, avg_loss=0.09121, mel_loss=0.03766, linear_loss=0.04796]
[2020-05-12 00:46:04.091]  Step 148941  [3.217 sec/step, loss=0.09701, avg_loss=0.09123, mel_loss=0.04366, linear_loss=0.05335]
[2020-05-12 00:46:05.160]  Step 148942  [3.196 sec/step, loss=0.08407, avg_loss=0.09110, mel_loss=0.03672, linear_loss=0.04735]
[2020-05-12 00:46:06.125]  Step 148943  [3.195 sec/step, loss=0.08264, avg_loss=0.09108, mel_loss=0.03613, linear_loss=0.04651]
[2020-05-12 00:46:07.851]  Generated 32 batches of size 32 in 1.721 sec
[2020-05-12 00:46:11.268]  Step 148944  [3.226 sec/step, loss=0.09777, avg_loss=0.09111, mel_loss=0.04502, linear_loss=0.05276]
[2020-05-12 00:46:24.320]  Step 148945  [3.308 sec/step, loss=0.08442, avg_loss=0.09099, mel_loss=0.04024, linear_loss=0.04418]
[2020-05-12 00:46:26.146]  Step 148946  [3.313 sec/step, loss=0.08918, avg_loss=0.09099, mel_loss=0.03903, linear_loss=0.05015]
[2020-05-12 00:46:29.251]  Step 148947  [3.336 sec/step, loss=0.09745, avg_loss=0.09118, mel_loss=0.04396, linear_loss=0.05349]
[2020-05-12 00:46:31.554]  Step 148948  [3.346 sec/step, loss=0.09227, avg_loss=0.09125, mel_loss=0.04114, linear_loss=0.05113]
[2020-05-12 00:46:38.959]  Step 148949  [3.413 sec/step, loss=0.09875, avg_loss=0.09149, mel_loss=0.04584, linear_loss=0.05291]
[2020-05-12 00:46:41.508]  Step 148950  [3.421 sec/step, loss=0.09309, avg_loss=0.09150, mel_loss=0.04155, linear_loss=0.05154]
[2020-05-12 00:46:41.509]  Writing summary at step: 148950
[2020-05-12 00:46:42.074]  Saving checkpoint to: ./logs-tacotron/model.ckpt-148950
[2020-05-12 00:46:43.517]  Saving audio and alignment...
[2020-05-12 00:46:46.279]  Input: 캔버스 위에 피어난다~_______________
[2020-05-12 00:46:47.142]  Step 148951  [3.404 sec/step, loss=0.08140, avg_loss=0.09137, mel_loss=0.03511, linear_loss=0.04629]
[2020-05-12 00:46:49.785]  Step 148952  [3.408 sec/step, loss=0.09415, avg_loss=0.09139, mel_loss=0.04193, linear_loss=0.05222]
[2020-05-12 00:46:53.327]  Step 148953  [3.405 sec/step, loss=0.09429, avg_loss=0.09135, mel_loss=0.04247, linear_loss=0.05182]
[2020-05-12 00:46:59.473]  Step 148954  [3.450 sec/step, loss=0.09809, avg_loss=0.09144, mel_loss=0.04524, linear_loss=0.05285]
[2020-05-12 00:47:02.396]  Step 148955  [3.421 sec/step, loss=0.09511, avg_loss=0.09143, mel_loss=0.04295, linear_loss=0.05216]
[2020-05-12 00:47:03.219]  Step 148956  [3.356 sec/step, loss=0.07627, avg_loss=0.09121, mel_loss=0.03373, linear_loss=0.04255]
[2020-05-12 00:47:07.717]  Step 148957  [3.373 sec/step, loss=0.09951, avg_loss=0.09127, mel_loss=0.04521, linear_loss=0.05430]
[2020-05-12 00:47:08.665]  Step 148958  [3.293 sec/step, loss=0.08331, avg_loss=0.09113, mel_loss=0.03636, linear_loss=0.04695]
[2020-05-12 00:47:17.046]  Step 148959  [3.371 sec/step, loss=0.09590, avg_loss=0.09137, mel_loss=0.04460, linear_loss=0.05131]
[2020-05-12 00:47:19.466]  Step 148960  [3.369 sec/step, loss=0.09369, avg_loss=0.09136, mel_loss=0.04168, linear_loss=0.05201]
[2020-05-12 00:47:24.670]  Step 148961  [3.411 sec/step, loss=0.09696, avg_loss=0.09149, mel_loss=0.04448, linear_loss=0.05248]
[2020-05-12 00:47:28.250]  Step 148962  [3.409 sec/step, loss=0.09625, avg_loss=0.09148, mel_loss=0.04356, linear_loss=0.05269]
[2020-05-12 00:47:30.348]  Step 148963  [3.374 sec/step, loss=0.09323, avg_loss=0.09142, mel_loss=0.04149, linear_loss=0.05175]
[2020-05-12 00:47:31.675]  Step 148964  [3.368 sec/step, loss=0.08739, avg_loss=0.09141, mel_loss=0.03831, linear_loss=0.04908]
[2020-05-12 00:47:32.959]  Step 148965  [3.367 sec/step, loss=0.08566, avg_loss=0.09137, mel_loss=0.03766, linear_loss=0.04800]
[2020-05-12 00:47:37.092]  Step 148966  [3.388 sec/step, loss=0.09811, avg_loss=0.09142, mel_loss=0.04483, linear_loss=0.05327]
[2020-05-12 00:47:39.246]  Step 148967  [3.385 sec/step, loss=0.09248, avg_loss=0.09142, mel_loss=0.04140, linear_loss=0.05108]
[2020-05-12 00:47:40.354]  Step 148968  [3.379 sec/step, loss=0.08532, avg_loss=0.09135, mel_loss=0.03721, linear_loss=0.04812]
[2020-05-12 00:47:40.887]  Step 148969  [3.332 sec/step, loss=0.07736, avg_loss=0.09116, mel_loss=0.03426, linear_loss=0.04310]
[2020-05-12 00:47:41.635]  Step 148970  [3.295 sec/step, loss=0.08132, avg_loss=0.09098, mel_loss=0.03491, linear_loss=0.04641]
[2020-05-12 00:47:42.637]  Step 148971  [3.269 sec/step, loss=0.08583, avg_loss=0.09088, mel_loss=0.03723, linear_loss=0.04860]
[2020-05-12 00:47:48.172]  Step 148972  [3.240 sec/step, loss=0.09793, avg_loss=0.09089, mel_loss=0.04483, linear_loss=0.05309]
[2020-05-12 00:47:50.003]  Step 148973  [3.228 sec/step, loss=0.08856, avg_loss=0.09081, mel_loss=0.03898, linear_loss=0.04958]
[2020-05-12 00:47:51.774]  Generated 32 batches of size 32 in 1.766 sec
[2020-05-12 00:47:52.725]  Step 148974  [3.235 sec/step, loss=0.09397, avg_loss=0.09081, mel_loss=0.04202, linear_loss=0.05195]
[2020-05-12 00:48:04.123]  Step 148975  [3.341 sec/step, loss=0.09563, avg_loss=0.09099, mel_loss=0.04562, linear_loss=0.05000]
[2020-05-12 00:48:05.760]  Step 148976  [3.346 sec/step, loss=0.08908, avg_loss=0.09101, mel_loss=0.03975, linear_loss=0.04933]
[2020-05-12 00:48:07.183]  Step 148977  [3.326 sec/step, loss=0.08858, avg_loss=0.09094, mel_loss=0.03885, linear_loss=0.04973]
[2020-05-12 00:48:10.962]  Step 148978  [3.352 sec/step, loss=0.09672, avg_loss=0.09105, mel_loss=0.04384, linear_loss=0.05288]
[2020-05-12 00:48:14.124]  Step 148979  [3.370 sec/step, loss=0.09797, avg_loss=0.09116, mel_loss=0.04416, linear_loss=0.05382]
[2020-05-12 00:48:21.347]  Step 148980  [3.426 sec/step, loss=0.09961, avg_loss=0.09128, mel_loss=0.04620, linear_loss=0.05342]
[2020-05-12 00:48:23.451]  Step 148981  [3.378 sec/step, loss=0.09269, avg_loss=0.09121, mel_loss=0.04163, linear_loss=0.05107]
[2020-05-12 00:48:25.292]  Step 148982  [3.376 sec/step, loss=0.08894, avg_loss=0.09118, mel_loss=0.03940, linear_loss=0.04954]
[2020-05-12 00:48:26.819]  Step 148983  [3.368 sec/step, loss=0.08721, avg_loss=0.09112, mel_loss=0.03837, linear_loss=0.04884]
[2020-05-12 00:48:27.378]  Step 148984  [3.330 sec/step, loss=0.07471, avg_loss=0.09090, mel_loss=0.03301, linear_loss=0.04170]
[2020-05-12 00:48:30.175]  Step 148985  [3.217 sec/step, loss=0.09501, avg_loss=0.09109, mel_loss=0.04291, linear_loss=0.05210]
[2020-05-12 00:48:33.768]  Step 148986  [3.246 sec/step, loss=0.09871, avg_loss=0.09133, mel_loss=0.04482, linear_loss=0.05389]
[2020-05-12 00:48:34.602]  Step 148987  [3.225 sec/step, loss=0.07593, avg_loss=0.09114, mel_loss=0.03297, linear_loss=0.04296]
[2020-05-12 00:48:40.103]  Step 148988  [3.271 sec/step, loss=0.09960, avg_loss=0.09134, mel_loss=0.04578, linear_loss=0.05382]
[2020-05-12 00:48:42.131]  Step 148989  [3.260 sec/step, loss=0.09067, avg_loss=0.09126, mel_loss=0.04024, linear_loss=0.05044]
[2020-05-12 00:48:42.914]  Step 148990  [3.204 sec/step, loss=0.07515, avg_loss=0.09102, mel_loss=0.03274, linear_loss=0.04240]
[2020-05-12 00:48:47.525]  Step 148991  [3.230 sec/step, loss=0.09798, avg_loss=0.09109, mel_loss=0.04457, linear_loss=0.05341]
[2020-05-12 00:48:50.438]  Step 148992  [3.242 sec/step, loss=0.09794, avg_loss=0.09117, mel_loss=0.04387, linear_loss=0.05407]
[2020-05-12 00:48:52.131]  Step 148993  [3.229 sec/step, loss=0.09181, avg_loss=0.09113, mel_loss=0.04038, linear_loss=0.05143]
[2020-05-12 00:48:54.664]  Step 148994  [3.232 sec/step, loss=0.09278, avg_loss=0.09114, mel_loss=0.04150, linear_loss=0.05129]
[2020-05-12 00:48:58.054]  Step 148995  [3.220 sec/step, loss=0.09597, avg_loss=0.09110, mel_loss=0.04344, linear_loss=0.05254]
[2020-05-12 00:48:59.047]  Step 148996  [3.091 sec/step, loss=0.08587, avg_loss=0.09121, mel_loss=0.03721, linear_loss=0.04866]
[2020-05-12 00:49:07.754]  Step 148997  [3.120 sec/step, loss=0.09790, avg_loss=0.09121, mel_loss=0.04568, linear_loss=0.05222]
[2020-05-12 00:49:15.222]  Step 148998  [3.187 sec/step, loss=0.10004, avg_loss=0.09149, mel_loss=0.04658, linear_loss=0.05346]
[2020-05-12 00:49:17.569]  Step 148999  [3.176 sec/step, loss=0.09367, avg_loss=0.09147, mel_loss=0.04190, linear_loss=0.05177]
[2020-05-12 00:49:31.749]  Step 149000  [3.267 sec/step, loss=0.07684, avg_loss=0.09126, mel_loss=0.03643, linear_loss=0.04041]
[2020-05-12 00:49:31.749]  Writing summary at step: 149000
[2020-05-12 00:49:33.316]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149000
[2020-05-12 00:49:34.714]  Saving audio and alignment...
[2020-05-12 00:49:42.177]  Input: 길게 오프닝 멘트 준비했던 거 다 줄이고 좀 빨리 빨리 진행을 해 달라고 부탁을 하셨어요~________
[2020-05-12 00:49:46.216]  Step 149001  [3.270 sec/step, loss=0.09814, avg_loss=0.09125, mel_loss=0.04423, linear_loss=0.05391]
[2020-05-12 00:49:47.403]  Step 149002  [3.243 sec/step, loss=0.08758, avg_loss=0.09114, mel_loss=0.03864, linear_loss=0.04894]
[2020-05-12 00:49:53.948]  Step 149003  [3.240 sec/step, loss=0.09802, avg_loss=0.09114, mel_loss=0.04523, linear_loss=0.05279]
[2020-05-12 00:49:55.718]  Generated 32 batches of size 32 in 1.765 sec
[2020-05-12 00:49:55.971]  Step 149004  [3.217 sec/step, loss=0.09110, avg_loss=0.09107, mel_loss=0.04020, linear_loss=0.05090]
[2020-05-12 00:50:00.209]  Step 149005  [3.232 sec/step, loss=0.09798, avg_loss=0.09111, mel_loss=0.04461, linear_loss=0.05337]
[2020-05-12 00:50:03.604]  Step 149006  [3.244 sec/step, loss=0.09594, avg_loss=0.09116, mel_loss=0.04343, linear_loss=0.05251]
[2020-05-12 00:50:04.755]  Step 149007  [3.181 sec/step, loss=0.08268, avg_loss=0.09098, mel_loss=0.03612, linear_loss=0.04657]
[2020-05-12 00:50:05.810]  Step 149008  [3.167 sec/step, loss=0.08190, avg_loss=0.09086, mel_loss=0.03624, linear_loss=0.04566]
[2020-05-12 00:50:07.978]  Step 149009  [3.154 sec/step, loss=0.09220, avg_loss=0.09081, mel_loss=0.04104, linear_loss=0.05116]
[2020-05-12 00:50:09.347]  Step 149010  [3.153 sec/step, loss=0.08642, avg_loss=0.09079, mel_loss=0.03781, linear_loss=0.04860]
[2020-05-12 00:50:12.435]  Step 149011  [3.176 sec/step, loss=0.09774, avg_loss=0.09103, mel_loss=0.04414, linear_loss=0.05360]
[2020-05-12 00:50:14.200]  Step 149012  [3.183 sec/step, loss=0.09002, avg_loss=0.09109, mel_loss=0.03972, linear_loss=0.05030]
[2020-05-12 00:50:17.829]  Step 149013  [3.208 sec/step, loss=0.09798, avg_loss=0.09122, mel_loss=0.04425, linear_loss=0.05373]
[2020-05-12 00:50:18.812]  Step 149014  [3.127 sec/step, loss=0.08005, avg_loss=0.09104, mel_loss=0.03458, linear_loss=0.04547]
[2020-05-12 00:50:21.477]  Step 149015  [3.140 sec/step, loss=0.09287, avg_loss=0.09109, mel_loss=0.04167, linear_loss=0.05120]
[2020-05-12 00:50:27.159]  Step 149016  [3.186 sec/step, loss=0.09995, avg_loss=0.09128, mel_loss=0.04611, linear_loss=0.05383]
[2020-05-12 00:50:30.538]  Step 149017  [3.200 sec/step, loss=0.09693, avg_loss=0.09136, mel_loss=0.04373, linear_loss=0.05319]
[2020-05-12 00:50:32.094]  Step 149018  [3.185 sec/step, loss=0.08912, avg_loss=0.09126, mel_loss=0.03913, linear_loss=0.04999]
[2020-05-12 00:50:40.380]  Step 149019  [3.259 sec/step, loss=0.09713, avg_loss=0.09142, mel_loss=0.04516, linear_loss=0.05197]
[2020-05-12 00:50:43.790]  Step 149020  [3.265 sec/step, loss=0.09575, avg_loss=0.09145, mel_loss=0.04321, linear_loss=0.05254]
[2020-05-12 00:50:45.165]  Step 149021  [3.261 sec/step, loss=0.08794, avg_loss=0.09143, mel_loss=0.03883, linear_loss=0.04911]
[2020-05-12 00:50:47.047]  Step 149022  [3.224 sec/step, loss=0.08820, avg_loss=0.09131, mel_loss=0.03874, linear_loss=0.04946]
[2020-05-12 00:50:48.775]  Step 149023  [3.207 sec/step, loss=0.09029, avg_loss=0.09126, mel_loss=0.03981, linear_loss=0.05048]
[2020-05-12 00:50:49.780]  Step 149024  [3.209 sec/step, loss=0.08290, avg_loss=0.09129, mel_loss=0.03598, linear_loss=0.04692]
[2020-05-12 00:50:50.614]  Step 149025  [3.208 sec/step, loss=0.07686, avg_loss=0.09125, mel_loss=0.03331, linear_loss=0.04355]
[2020-05-12 00:50:58.898]  Step 149026  [3.270 sec/step, loss=0.09915, avg_loss=0.09131, mel_loss=0.04554, linear_loss=0.05361]
[2020-05-12 00:51:00.949]  Step 149027  [3.230 sec/step, loss=0.08798, avg_loss=0.09121, mel_loss=0.03879, linear_loss=0.04919]
[2020-05-12 00:51:02.243]  Step 149028  [3.228 sec/step, loss=0.07766, avg_loss=0.09111, mel_loss=0.03383, linear_loss=0.04383]
[2020-05-12 00:51:05.445]  Step 149029  [3.224 sec/step, loss=0.09089, avg_loss=0.09104, mel_loss=0.04053, linear_loss=0.05035]
[2020-05-12 00:51:06.063]  Step 149030  [3.202 sec/step, loss=0.07288, avg_loss=0.09084, mel_loss=0.03249, linear_loss=0.04039]
[2020-05-12 00:51:13.870]  Step 149031  [3.269 sec/step, loss=0.10004, avg_loss=0.09098, mel_loss=0.04641, linear_loss=0.05363]
[2020-05-12 00:51:16.676]  Step 149032  [3.256 sec/step, loss=0.09352, avg_loss=0.09096, mel_loss=0.04203, linear_loss=0.05149]
[2020-05-12 00:51:18.898]  Step 149033  [3.264 sec/step, loss=0.09095, avg_loss=0.09097, mel_loss=0.04069, linear_loss=0.05026]
[2020-05-12 00:51:23.642]  Step 149034  [3.293 sec/step, loss=0.09712, avg_loss=0.09102, mel_loss=0.04424, linear_loss=0.05287]
[2020-05-12 00:51:25.763]  Step 149035  [3.306 sec/step, loss=0.09317, avg_loss=0.09118, mel_loss=0.04156, linear_loss=0.05161]
[2020-05-12 00:51:27.482]  Generated 32 batches of size 32 in 1.714 sec
[2020-05-12 00:51:28.976]  Step 149036  [3.250 sec/step, loss=0.09684, avg_loss=0.09118, mel_loss=0.04364, linear_loss=0.05320]
[2020-05-12 00:51:30.592]  Step 149037  [3.246 sec/step, loss=0.09177, avg_loss=0.09117, mel_loss=0.04061, linear_loss=0.05115]
[2020-05-12 00:51:31.823]  Step 149038  [3.218 sec/step, loss=0.08753, avg_loss=0.09107, mel_loss=0.03841, linear_loss=0.04912]
[2020-05-12 00:51:34.284]  Step 149039  [3.196 sec/step, loss=0.09327, avg_loss=0.09100, mel_loss=0.04155, linear_loss=0.05172]
[2020-05-12 00:51:38.350]  Step 149040  [3.224 sec/step, loss=0.09686, avg_loss=0.09111, mel_loss=0.04389, linear_loss=0.05298]
[2020-05-12 00:51:44.962]  Step 149041  [3.256 sec/step, loss=0.09963, avg_loss=0.09114, mel_loss=0.04597, linear_loss=0.05366]
[2020-05-12 00:51:46.059]  Step 149042  [3.257 sec/step, loss=0.08533, avg_loss=0.09115, mel_loss=0.03689, linear_loss=0.04844]
[2020-05-12 00:51:50.401]  Step 149043  [3.291 sec/step, loss=0.09752, avg_loss=0.09130, mel_loss=0.04461, linear_loss=0.05290]
[2020-05-12 00:52:04.012]  Step 149044  [3.375 sec/step, loss=0.08409, avg_loss=0.09116, mel_loss=0.04001, linear_loss=0.04408]
[2020-05-12 00:52:05.571]  Step 149045  [3.260 sec/step, loss=0.08802, avg_loss=0.09120, mel_loss=0.03911, linear_loss=0.04891]
[2020-05-12 00:52:14.288]  Step 149046  [3.329 sec/step, loss=0.09792, avg_loss=0.09128, mel_loss=0.04584, linear_loss=0.05207]
[2020-05-12 00:52:19.295]  Step 149047  [3.348 sec/step, loss=0.09906, avg_loss=0.09130, mel_loss=0.04561, linear_loss=0.05345]
[2020-05-12 00:52:23.006]  Step 149048  [3.362 sec/step, loss=0.09905, avg_loss=0.09137, mel_loss=0.04481, linear_loss=0.05424]
[2020-05-12 00:52:23.645]  Step 149049  [3.295 sec/step, loss=0.07767, avg_loss=0.09116, mel_loss=0.03394, linear_loss=0.04372]
[2020-05-12 00:52:25.262]  Step 149050  [3.285 sec/step, loss=0.08875, avg_loss=0.09111, mel_loss=0.03935, linear_loss=0.04939]
[2020-05-12 00:52:25.262]  Writing summary at step: 149050
[2020-05-12 00:52:26.609]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149050
[2020-05-12 00:52:27.957]  Saving audio and alignment...
[2020-05-12 00:52:31.519]  Input: 계이름을 지금부터 읊어 보시죠~__________________
[2020-05-12 00:52:32.663]  Step 149051  [3.288 sec/step, loss=0.08427, avg_loss=0.09114, mel_loss=0.03684, linear_loss=0.04743]
[2020-05-12 00:52:38.636]  Step 149052  [3.321 sec/step, loss=0.09700, avg_loss=0.09117, mel_loss=0.04486, linear_loss=0.05214]
[2020-05-12 00:52:39.518]  Step 149053  [3.295 sec/step, loss=0.08055, avg_loss=0.09103, mel_loss=0.03476, linear_loss=0.04579]
[2020-05-12 00:52:43.873]  Step 149054  [3.277 sec/step, loss=0.10062, avg_loss=0.09106, mel_loss=0.04588, linear_loss=0.05474]
[2020-05-12 00:52:57.927]  Step 149055  [3.388 sec/step, loss=0.07690, avg_loss=0.09088, mel_loss=0.03700, linear_loss=0.03990]
[2020-05-12 00:52:58.716]  Step 149056  [3.388 sec/step, loss=0.07797, avg_loss=0.09089, mel_loss=0.03410, linear_loss=0.04387]
[2020-05-12 00:53:03.553]  Step 149057  [3.391 sec/step, loss=0.09725, avg_loss=0.09087, mel_loss=0.04434, linear_loss=0.05291]
[2020-05-12 00:53:06.485]  Step 149058  [3.411 sec/step, loss=0.09677, avg_loss=0.09101, mel_loss=0.04347, linear_loss=0.05330]
[2020-05-12 00:53:08.873]  Step 149059  [3.351 sec/step, loss=0.09409, avg_loss=0.09099, mel_loss=0.04156, linear_loss=0.05253]
[2020-05-12 00:53:11.664]  Step 149060  [3.355 sec/step, loss=0.09490, avg_loss=0.09100, mel_loss=0.04261, linear_loss=0.05228]
[2020-05-12 00:53:14.727]  Step 149061  [3.333 sec/step, loss=0.09678, avg_loss=0.09100, mel_loss=0.04378, linear_loss=0.05300]
[2020-05-12 00:53:18.115]  Step 149062  [3.332 sec/step, loss=0.09597, avg_loss=0.09100, mel_loss=0.04319, linear_loss=0.05277]
[2020-05-12 00:53:20.463]  Step 149063  [3.334 sec/step, loss=0.09263, avg_loss=0.09099, mel_loss=0.04128, linear_loss=0.05135]
[2020-05-12 00:53:22.356]  Step 149064  [3.340 sec/step, loss=0.09408, avg_loss=0.09106, mel_loss=0.04185, linear_loss=0.05223]
[2020-05-12 00:53:24.130]  Step 149065  [3.345 sec/step, loss=0.08941, avg_loss=0.09109, mel_loss=0.03938, linear_loss=0.05003]
[2020-05-12 00:53:25.191]  Step 149066  [3.314 sec/step, loss=0.08269, avg_loss=0.09094, mel_loss=0.03622, linear_loss=0.04647]
[2020-05-12 00:53:25.889]  Generated 32 batches of size 32 in 1.754 sec
[2020-05-12 00:53:32.475]  Step 149067  [3.365 sec/step, loss=0.10052, avg_loss=0.09102, mel_loss=0.04661, linear_loss=0.05391]
[2020-05-12 00:53:33.967]  Step 149068  [3.369 sec/step, loss=0.08773, avg_loss=0.09104, mel_loss=0.03870, linear_loss=0.04904]
[2020-05-12 00:53:35.160]  Step 149069  [3.376 sec/step, loss=0.08469, avg_loss=0.09112, mel_loss=0.03697, linear_loss=0.04772]
[2020-05-12 00:53:37.866]  Step 149070  [3.395 sec/step, loss=0.09411, avg_loss=0.09125, mel_loss=0.04199, linear_loss=0.05212]
[2020-05-12 00:53:41.861]  Step 149071  [3.425 sec/step, loss=0.09718, avg_loss=0.09136, mel_loss=0.04392, linear_loss=0.05326]
[2020-05-12 00:53:43.826]  Step 149072  [3.389 sec/step, loss=0.09331, avg_loss=0.09131, mel_loss=0.04142, linear_loss=0.05189]
[2020-05-12 00:53:44.347]  Step 149073  [3.376 sec/step, loss=0.07651, avg_loss=0.09119, mel_loss=0.03398, linear_loss=0.04252]
[2020-05-12 00:53:47.865]  Step 149074  [3.384 sec/step, loss=0.09778, avg_loss=0.09123, mel_loss=0.04425, linear_loss=0.05353]
[2020-05-12 00:53:51.956]  Step 149075  [3.311 sec/step, loss=0.09758, avg_loss=0.09125, mel_loss=0.04426, linear_loss=0.05332]
[2020-05-12 00:53:55.395]  Step 149076  [3.329 sec/step, loss=0.09527, avg_loss=0.09131, mel_loss=0.04290, linear_loss=0.05237]
[2020-05-12 00:53:56.385]  Step 149077  [3.325 sec/step, loss=0.08222, avg_loss=0.09125, mel_loss=0.03569, linear_loss=0.04653]
[2020-05-12 00:54:05.217]  Step 149078  [3.375 sec/step, loss=0.09826, avg_loss=0.09126, mel_loss=0.04576, linear_loss=0.05251]
[2020-05-12 00:54:06.871]  Step 149079  [3.360 sec/step, loss=0.09180, avg_loss=0.09120, mel_loss=0.04043, linear_loss=0.05137]
[2020-05-12 00:54:09.145]  Step 149080  [3.311 sec/step, loss=0.09093, avg_loss=0.09112, mel_loss=0.04088, linear_loss=0.05004]
[2020-05-12 00:54:14.825]  Step 149081  [3.347 sec/step, loss=0.09896, avg_loss=0.09118, mel_loss=0.04571, linear_loss=0.05325]
[2020-05-12 00:54:15.640]  Step 149082  [3.336 sec/step, loss=0.07797, avg_loss=0.09107, mel_loss=0.03352, linear_loss=0.04446]
[2020-05-12 00:54:16.668]  Step 149083  [3.331 sec/step, loss=0.08126, avg_loss=0.09101, mel_loss=0.03523, linear_loss=0.04603]
[2020-05-12 00:54:18.378]  Step 149084  [3.343 sec/step, loss=0.08884, avg_loss=0.09115, mel_loss=0.03916, linear_loss=0.04969]
[2020-05-12 00:54:20.392]  Step 149085  [3.335 sec/step, loss=0.09195, avg_loss=0.09112, mel_loss=0.04082, linear_loss=0.05113]
[2020-05-12 00:54:22.287]  Step 149086  [3.318 sec/step, loss=0.09170, avg_loss=0.09105, mel_loss=0.04053, linear_loss=0.05117]
[2020-05-12 00:54:25.653]  Step 149087  [3.343 sec/step, loss=0.09797, avg_loss=0.09127, mel_loss=0.04440, linear_loss=0.05357]
[2020-05-12 00:54:27.784]  Step 149088  [3.310 sec/step, loss=0.09271, avg_loss=0.09120, mel_loss=0.04127, linear_loss=0.05144]
[2020-05-12 00:54:28.542]  Step 149089  [3.297 sec/step, loss=0.07408, avg_loss=0.09104, mel_loss=0.03279, linear_loss=0.04129]
[2020-05-12 00:54:29.911]  Step 149090  [3.303 sec/step, loss=0.08765, avg_loss=0.09116, mel_loss=0.03873, linear_loss=0.04892]
[2020-05-12 00:54:33.005]  Step 149091  [3.288 sec/step, loss=0.09749, avg_loss=0.09116, mel_loss=0.04392, linear_loss=0.05357]
[2020-05-12 00:54:40.363]  Step 149092  [3.332 sec/step, loss=0.10029, avg_loss=0.09118, mel_loss=0.04668, linear_loss=0.05362]
[2020-05-12 00:54:41.436]  Step 149093  [3.326 sec/step, loss=0.08487, avg_loss=0.09111, mel_loss=0.03695, linear_loss=0.04792]
[2020-05-12 00:54:42.765]  Step 149094  [3.314 sec/step, loss=0.08577, avg_loss=0.09104, mel_loss=0.03772, linear_loss=0.04805]
[2020-05-12 00:54:43.974]  Step 149095  [3.292 sec/step, loss=0.08595, avg_loss=0.09094, mel_loss=0.03760, linear_loss=0.04835]
[2020-05-12 00:54:46.465]  Step 149096  [3.307 sec/step, loss=0.09239, avg_loss=0.09100, mel_loss=0.04116, linear_loss=0.05123]
[2020-05-12 00:54:52.911]  Step 149097  [3.284 sec/step, loss=0.09835, avg_loss=0.09101, mel_loss=0.04545, linear_loss=0.05290]
[2020-05-12 00:54:54.649]  Generated 32 batches of size 32 in 1.732 sec
[2020-05-12 00:54:55.732]  Step 149098  [3.238 sec/step, loss=0.09510, avg_loss=0.09096, mel_loss=0.04254, linear_loss=0.05256]
[2020-05-12 00:54:59.753]  Step 149099  [3.255 sec/step, loss=0.09740, avg_loss=0.09100, mel_loss=0.04407, linear_loss=0.05333]
[2020-05-12 00:55:04.325]  Step 149100  [3.159 sec/step, loss=0.09815, avg_loss=0.09121, mel_loss=0.04477, linear_loss=0.05338]
[2020-05-12 00:55:04.326]  Writing summary at step: 149100
[2020-05-12 00:55:07.965]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149100
[2020-05-12 00:55:09.362]  Saving audio and alignment...
[2020-05-12 00:55:12.148]  Input: 행사 의뢰하지 않으시겠어요~____________
[2020-05-12 00:55:17.473]  Step 149101  [3.172 sec/step, loss=0.09885, avg_loss=0.09122, mel_loss=0.04517, linear_loss=0.05368]
[2020-05-12 00:55:20.398]  Step 149102  [3.189 sec/step, loss=0.09684, avg_loss=0.09131, mel_loss=0.04345, linear_loss=0.05339]
[2020-05-12 00:55:21.187]  Step 149103  [3.131 sec/step, loss=0.07404, avg_loss=0.09107, mel_loss=0.03213, linear_loss=0.04191]
[2020-05-12 00:55:35.135]  Step 149104  [3.251 sec/step, loss=0.07734, avg_loss=0.09093, mel_loss=0.03686, linear_loss=0.04048]
[2020-05-12 00:55:37.338]  Step 149105  [3.230 sec/step, loss=0.09156, avg_loss=0.09087, mel_loss=0.04066, linear_loss=0.05091]
[2020-05-12 00:55:39.753]  Step 149106  [3.220 sec/step, loss=0.09302, avg_loss=0.09084, mel_loss=0.04134, linear_loss=0.05169]
[2020-05-12 00:55:43.347]  Step 149107  [3.245 sec/step, loss=0.09812, avg_loss=0.09099, mel_loss=0.04455, linear_loss=0.05357]
[2020-05-12 00:55:51.690]  Step 149108  [3.318 sec/step, loss=0.09708, avg_loss=0.09114, mel_loss=0.04542, linear_loss=0.05166]
[2020-05-12 00:55:52.869]  Step 149109  [3.308 sec/step, loss=0.08341, avg_loss=0.09106, mel_loss=0.03659, linear_loss=0.04681]
[2020-05-12 00:55:53.684]  Step 149110  [3.302 sec/step, loss=0.08017, avg_loss=0.09099, mel_loss=0.03472, linear_loss=0.04545]
[2020-05-12 00:55:58.899]  Step 149111  [3.324 sec/step, loss=0.09946, avg_loss=0.09101, mel_loss=0.04583, linear_loss=0.05363]
[2020-05-12 00:56:00.697]  Step 149112  [3.324 sec/step, loss=0.09056, avg_loss=0.09102, mel_loss=0.03984, linear_loss=0.05072]
[2020-05-12 00:56:05.128]  Step 149113  [3.332 sec/step, loss=0.09965, avg_loss=0.09103, mel_loss=0.04525, linear_loss=0.05439]
[2020-05-12 00:56:07.944]  Step 149114  [3.350 sec/step, loss=0.09540, avg_loss=0.09119, mel_loss=0.04292, linear_loss=0.05248]
[2020-05-12 00:56:09.383]  Step 149115  [3.338 sec/step, loss=0.08760, avg_loss=0.09113, mel_loss=0.03866, linear_loss=0.04894]
[2020-05-12 00:56:10.015]  Step 149116  [3.288 sec/step, loss=0.07559, avg_loss=0.09089, mel_loss=0.03382, linear_loss=0.04178]
[2020-05-12 00:56:13.072]  Step 149117  [3.284 sec/step, loss=0.09537, avg_loss=0.09088, mel_loss=0.04254, linear_loss=0.05282]
[2020-05-12 00:56:18.211]  Step 149118  [3.320 sec/step, loss=0.09954, avg_loss=0.09098, mel_loss=0.04596, linear_loss=0.05358]
[2020-05-12 00:56:21.568]  Step 149119  [3.271 sec/step, loss=0.09437, avg_loss=0.09095, mel_loss=0.04287, linear_loss=0.05150]
[2020-05-12 00:56:23.207]  Step 149120  [3.253 sec/step, loss=0.08753, avg_loss=0.09087, mel_loss=0.03852, linear_loss=0.04900]
[2020-05-12 00:56:26.521]  Step 149121  [3.273 sec/step, loss=0.09715, avg_loss=0.09096, mel_loss=0.04389, linear_loss=0.05326]
[2020-05-12 00:56:27.629]  Step 149122  [3.265 sec/step, loss=0.08329, avg_loss=0.09091, mel_loss=0.03589, linear_loss=0.04740]
[2020-05-12 00:56:31.305]  Step 149123  [3.284 sec/step, loss=0.09841, avg_loss=0.09099, mel_loss=0.04445, linear_loss=0.05395]
[2020-05-12 00:56:32.683]  Step 149124  [3.288 sec/step, loss=0.08604, avg_loss=0.09103, mel_loss=0.03760, linear_loss=0.04845]
[2020-05-12 00:56:38.782]  Step 149125  [3.341 sec/step, loss=0.09771, avg_loss=0.09123, mel_loss=0.04506, linear_loss=0.05265]
[2020-05-12 00:56:40.449]  Step 149126  [3.274 sec/step, loss=0.09092, avg_loss=0.09115, mel_loss=0.04030, linear_loss=0.05061]
[2020-05-12 00:56:42.390]  Step 149127  [3.273 sec/step, loss=0.09100, avg_loss=0.09118, mel_loss=0.04032, linear_loss=0.05068]
[2020-05-12 00:56:44.119]  Generated 32 batches of size 32 in 1.724 sec
[2020-05-12 00:56:44.500]  Step 149128  [3.282 sec/step, loss=0.09129, avg_loss=0.09132, mel_loss=0.04063, linear_loss=0.05065]
[2020-05-12 00:56:49.206]  Step 149129  [3.297 sec/step, loss=0.09854, avg_loss=0.09139, mel_loss=0.04488, linear_loss=0.05366]
[2020-05-12 00:56:56.894]  Step 149130  [3.367 sec/step, loss=0.10044, avg_loss=0.09167, mel_loss=0.04636, linear_loss=0.05408]
[2020-05-12 00:56:59.346]  Step 149131  [3.314 sec/step, loss=0.09383, avg_loss=0.09161, mel_loss=0.04201, linear_loss=0.05182]
[2020-05-12 00:57:03.676]  Step 149132  [3.329 sec/step, loss=0.09684, avg_loss=0.09164, mel_loss=0.04395, linear_loss=0.05289]
[2020-05-12 00:57:04.581]  Step 149133  [3.316 sec/step, loss=0.08038, avg_loss=0.09154, mel_loss=0.03465, linear_loss=0.04574]
[2020-05-12 00:57:05.129]  Step 149134  [3.274 sec/step, loss=0.07532, avg_loss=0.09132, mel_loss=0.03329, linear_loss=0.04203]
[2020-05-12 00:57:06.109]  Step 149135  [3.262 sec/step, loss=0.08082, avg_loss=0.09119, mel_loss=0.03555, linear_loss=0.04527]
[2020-05-12 00:57:19.057]  Step 149136  [3.360 sec/step, loss=0.08404, avg_loss=0.09107, mel_loss=0.04003, linear_loss=0.04401]
[2020-05-12 00:57:19.581]  Step 149137  [3.349 sec/step, loss=0.07570, avg_loss=0.09091, mel_loss=0.03369, linear_loss=0.04202]
[2020-05-12 00:57:26.216]  Step 149138  [3.403 sec/step, loss=0.09949, avg_loss=0.09102, mel_loss=0.04596, linear_loss=0.05353]
[2020-05-12 00:57:27.757]  Step 149139  [3.394 sec/step, loss=0.08968, avg_loss=0.09099, mel_loss=0.03984, linear_loss=0.04983]
[2020-05-12 00:57:29.084]  Step 149140  [3.366 sec/step, loss=0.08841, avg_loss=0.09090, mel_loss=0.03886, linear_loss=0.04955]
[2020-05-12 00:57:31.899]  Step 149141  [3.328 sec/step, loss=0.09449, avg_loss=0.09085, mel_loss=0.04241, linear_loss=0.05208]
[2020-05-12 00:57:34.063]  Step 149142  [3.339 sec/step, loss=0.09292, avg_loss=0.09093, mel_loss=0.04165, linear_loss=0.05127]
[2020-05-12 00:57:48.204]  Step 149143  [3.437 sec/step, loss=0.07657, avg_loss=0.09072, mel_loss=0.03650, linear_loss=0.04007]
[2020-05-12 00:57:53.518]  Step 149144  [3.354 sec/step, loss=0.09745, avg_loss=0.09085, mel_loss=0.04453, linear_loss=0.05292]
[2020-05-12 00:57:59.200]  Step 149145  [3.395 sec/step, loss=0.09996, avg_loss=0.09097, mel_loss=0.04603, linear_loss=0.05394]
[2020-05-12 00:58:00.583]  Step 149146  [3.322 sec/step, loss=0.08881, avg_loss=0.09088, mel_loss=0.03924, linear_loss=0.04958]
[2020-05-12 00:58:04.043]  Step 149147  [3.306 sec/step, loss=0.09614, avg_loss=0.09085, mel_loss=0.04346, linear_loss=0.05268]
[2020-05-12 00:58:07.219]  Step 149148  [3.301 sec/step, loss=0.09657, avg_loss=0.09083, mel_loss=0.04336, linear_loss=0.05321]
[2020-05-12 00:58:08.362]  Step 149149  [3.306 sec/step, loss=0.08307, avg_loss=0.09088, mel_loss=0.03627, linear_loss=0.04680]
[2020-05-12 00:58:09.400]  Step 149150  [3.300 sec/step, loss=0.08031, avg_loss=0.09080, mel_loss=0.03504, linear_loss=0.04527]
[2020-05-12 00:58:09.400]  Writing summary at step: 149150
[2020-05-12 00:58:12.415]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149150
[2020-05-12 00:58:13.825]  Saving audio and alignment...
[2020-05-12 00:58:17.239]  Input: 이렇게 하면 얼마나 깔끔 할까요~____________
[2020-05-12 00:58:21.488]  Step 149151  [3.331 sec/step, loss=0.09689, avg_loss=0.09092, mel_loss=0.04409, linear_loss=0.05280]
[2020-05-12 00:58:23.216]  Step 149152  [3.289 sec/step, loss=0.09146, avg_loss=0.09087, mel_loss=0.04011, linear_loss=0.05135]
[2020-05-12 00:58:26.800]  Step 149153  [3.316 sec/step, loss=0.09834, avg_loss=0.09105, mel_loss=0.04449, linear_loss=0.05386]
[2020-05-12 00:58:27.790]  Step 149154  [3.282 sec/step, loss=0.08507, avg_loss=0.09089, mel_loss=0.03681, linear_loss=0.04825]
[2020-05-12 00:58:30.497]  Step 149155  [3.169 sec/step, loss=0.09464, avg_loss=0.09107, mel_loss=0.04244, linear_loss=0.05220]
[2020-05-12 00:58:37.858]  Step 149156  [3.235 sec/step, loss=0.10053, avg_loss=0.09129, mel_loss=0.04679, linear_loss=0.05374]
[2020-05-12 00:58:38.622]  Step 149157  [3.194 sec/step, loss=0.07808, avg_loss=0.09110, mel_loss=0.03385, linear_loss=0.04423]
[2020-05-12 00:58:40.447]  Generated 32 batches of size 32 in 1.819 sec
[2020-05-12 00:58:41.284]  Step 149158  [3.191 sec/step, loss=0.09366, avg_loss=0.09107, mel_loss=0.04156, linear_loss=0.05210]
[2020-05-12 00:58:50.189]  Step 149159  [3.256 sec/step, loss=0.09796, avg_loss=0.09111, mel_loss=0.04556, linear_loss=0.05240]
[2020-05-12 00:58:54.829]  Step 149160  [3.275 sec/step, loss=0.09747, avg_loss=0.09114, mel_loss=0.04451, linear_loss=0.05296]
[2020-05-12 00:58:57.156]  Step 149161  [3.267 sec/step, loss=0.09520, avg_loss=0.09112, mel_loss=0.04251, linear_loss=0.05269]
[2020-05-12 00:58:58.405]  Step 149162  [3.246 sec/step, loss=0.08508, avg_loss=0.09101, mel_loss=0.03752, linear_loss=0.04756]
[2020-05-12 00:59:02.452]  Step 149163  [3.263 sec/step, loss=0.09784, avg_loss=0.09106, mel_loss=0.04438, linear_loss=0.05346]
[2020-05-12 00:59:04.139]  Step 149164  [3.261 sec/step, loss=0.09032, avg_loss=0.09102, mel_loss=0.03992, linear_loss=0.05040]
[2020-05-12 00:59:04.935]  Step 149165  [3.251 sec/step, loss=0.08095, avg_loss=0.09094, mel_loss=0.03495, linear_loss=0.04599]
[2020-05-12 00:59:06.800]  Step 149166  [3.259 sec/step, loss=0.09101, avg_loss=0.09102, mel_loss=0.04027, linear_loss=0.05074]
[2020-05-12 00:59:08.777]  Step 149167  [3.206 sec/step, loss=0.09208, avg_loss=0.09094, mel_loss=0.04088, linear_loss=0.05120]
[2020-05-12 00:59:09.519]  Step 149168  [3.199 sec/step, loss=0.08104, avg_loss=0.09087, mel_loss=0.03455, linear_loss=0.04649]
[2020-05-12 00:59:11.615]  Step 149169  [3.208 sec/step, loss=0.09270, avg_loss=0.09095, mel_loss=0.04092, linear_loss=0.05178]
[2020-05-12 00:59:17.672]  Step 149170  [3.241 sec/step, loss=0.09985, avg_loss=0.09101, mel_loss=0.04604, linear_loss=0.05381]
[2020-05-12 00:59:20.713]  Step 149171  [3.232 sec/step, loss=0.09831, avg_loss=0.09102, mel_loss=0.04438, linear_loss=0.05393]
[2020-05-12 00:59:22.979]  Step 149172  [3.235 sec/step, loss=0.09307, avg_loss=0.09102, mel_loss=0.04175, linear_loss=0.05132]
[2020-05-12 00:59:24.387]  Step 149173  [3.244 sec/step, loss=0.08811, avg_loss=0.09113, mel_loss=0.03898, linear_loss=0.04912]
[2020-05-12 00:59:24.939]  Step 149174  [3.214 sec/step, loss=0.06918, avg_loss=0.09085, mel_loss=0.03082, linear_loss=0.03836]
[2020-05-12 00:59:29.463]  Step 149175  [3.218 sec/step, loss=0.09740, avg_loss=0.09085, mel_loss=0.04424, linear_loss=0.05316]
[2020-05-12 00:59:36.884]  Step 149176  [3.258 sec/step, loss=0.09972, avg_loss=0.09089, mel_loss=0.04646, linear_loss=0.05326]
[2020-05-12 00:59:45.506]  Step 149177  [3.334 sec/step, loss=0.09672, avg_loss=0.09104, mel_loss=0.04497, linear_loss=0.05175]
[2020-05-12 00:59:47.268]  Step 149178  [3.264 sec/step, loss=0.09006, avg_loss=0.09095, mel_loss=0.03949, linear_loss=0.05057]
[2020-05-12 00:59:48.933]  Step 149179  [3.264 sec/step, loss=0.09226, avg_loss=0.09096, mel_loss=0.04095, linear_loss=0.05131]
[2020-05-12 00:59:50.435]  Step 149180  [3.256 sec/step, loss=0.08845, avg_loss=0.09093, mel_loss=0.03906, linear_loss=0.04939]
[2020-05-12 00:59:53.813]  Step 149181  [3.233 sec/step, loss=0.09792, avg_loss=0.09092, mel_loss=0.04410, linear_loss=0.05381]
[2020-05-12 01:00:08.011]  Step 149182  [3.367 sec/step, loss=0.07779, avg_loss=0.09092, mel_loss=0.03705, linear_loss=0.04074]
[2020-05-12 01:00:09.100]  Step 149183  [3.367 sec/step, loss=0.08322, avg_loss=0.09094, mel_loss=0.03622, linear_loss=0.04700]
[2020-05-12 01:00:13.315]  Step 149184  [3.393 sec/step, loss=0.09593, avg_loss=0.09101, mel_loss=0.04352, linear_loss=0.05241]
[2020-05-12 01:00:18.900]  Step 149185  [3.428 sec/step, loss=0.09585, avg_loss=0.09105, mel_loss=0.04394, linear_loss=0.05191]
[2020-05-12 01:00:19.729]  Step 149186  [3.418 sec/step, loss=0.07766, avg_loss=0.09091, mel_loss=0.03381, linear_loss=0.04385]
[2020-05-12 01:00:22.407]  Step 149187  [3.411 sec/step, loss=0.09628, avg_loss=0.09089, mel_loss=0.04327, linear_loss=0.05301]
[2020-05-12 01:00:23.408]  Step 149188  [3.399 sec/step, loss=0.07954, avg_loss=0.09076, mel_loss=0.03451, linear_loss=0.04503]
[2020-05-12 01:00:24.632]  Step 149189  [3.404 sec/step, loss=0.08733, avg_loss=0.09089, mel_loss=0.03819, linear_loss=0.04915]
[2020-05-12 01:00:26.416]  Generated 32 batches of size 32 in 1.778 sec
[2020-05-12 01:00:28.448]  Step 149190  [3.429 sec/step, loss=0.09789, avg_loss=0.09100, mel_loss=0.04437, linear_loss=0.05352]
[2020-05-12 01:00:31.306]  Step 149191  [3.426 sec/step, loss=0.09526, avg_loss=0.09097, mel_loss=0.04289, linear_loss=0.05237]
[2020-05-12 01:00:34.858]  Step 149192  [3.388 sec/step, loss=0.09820, avg_loss=0.09095, mel_loss=0.04436, linear_loss=0.05384]
[2020-05-12 01:00:36.141]  Step 149193  [3.390 sec/step, loss=0.08675, avg_loss=0.09097, mel_loss=0.03829, linear_loss=0.04847]
[2020-05-12 01:00:37.979]  Step 149194  [3.395 sec/step, loss=0.09128, avg_loss=0.09103, mel_loss=0.04014, linear_loss=0.05114]
[2020-05-12 01:00:42.853]  Step 149195  [3.432 sec/step, loss=0.09739, avg_loss=0.09114, mel_loss=0.04462, linear_loss=0.05277]
[2020-05-12 01:00:45.297]  Step 149196  [3.431 sec/step, loss=0.09350, avg_loss=0.09115, mel_loss=0.04182, linear_loss=0.05168]
[2020-05-12 01:00:46.319]  Step 149197  [3.377 sec/step, loss=0.08146, avg_loss=0.09098, mel_loss=0.03578, linear_loss=0.04568]
[2020-05-12 01:00:49.794]  Step 149198  [3.384 sec/step, loss=0.09566, avg_loss=0.09099, mel_loss=0.04334, linear_loss=0.05233]
[2020-05-12 01:00:51.717]  Step 149199  [3.363 sec/step, loss=0.08984, avg_loss=0.09091, mel_loss=0.03982, linear_loss=0.05003]
[2020-05-12 01:00:53.038]  Step 149200  [3.330 sec/step, loss=0.08394, avg_loss=0.09077, mel_loss=0.03686, linear_loss=0.04708]
[2020-05-12 01:00:53.038]  Writing summary at step: 149200
[2020-05-12 01:00:53.944]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149200
[2020-05-12 01:00:55.385]  Saving audio and alignment...
[2020-05-12 01:01:05.533]  Input: 바로 다음 문제 소개하고 이렇게 되면 공연을 흐름이 않거든요 그래서 앞서 본 무대에 대한 소감 살짝~___________________________________
[2020-05-12 01:01:13.656]  Step 149201  [3.358 sec/step, loss=0.09991, avg_loss=0.09078, mel_loss=0.04591, linear_loss=0.05399]
[2020-05-12 01:01:14.554]  Step 149202  [3.338 sec/step, loss=0.07332, avg_loss=0.09055, mel_loss=0.03247, linear_loss=0.04085]
[2020-05-12 01:01:18.002]  Step 149203  [3.365 sec/step, loss=0.09254, avg_loss=0.09073, mel_loss=0.04160, linear_loss=0.05094]
[2020-05-12 01:01:20.270]  Step 149204  [3.248 sec/step, loss=0.08550, avg_loss=0.09081, mel_loss=0.03745, linear_loss=0.04805]
[2020-05-12 01:01:25.174]  Step 149205  [3.275 sec/step, loss=0.09904, avg_loss=0.09089, mel_loss=0.04529, linear_loss=0.05375]
[2020-05-12 01:01:26.232]  Step 149206  [3.261 sec/step, loss=0.08679, avg_loss=0.09083, mel_loss=0.03747, linear_loss=0.04932]
[2020-05-12 01:01:32.064]  Step 149207  [3.284 sec/step, loss=0.09946, avg_loss=0.09084, mel_loss=0.04576, linear_loss=0.05370]
[2020-05-12 01:01:34.908]  Step 149208  [3.229 sec/step, loss=0.09422, avg_loss=0.09081, mel_loss=0.04227, linear_loss=0.05194]
[2020-05-12 01:01:38.001]  Step 149209  [3.248 sec/step, loss=0.09739, avg_loss=0.09095, mel_loss=0.04390, linear_loss=0.05349]
[2020-05-12 01:01:39.008]  Step 149210  [3.250 sec/step, loss=0.08269, avg_loss=0.09098, mel_loss=0.03616, linear_loss=0.04654]
[2020-05-12 01:01:40.969]  Step 149211  [3.217 sec/step, loss=0.09425, avg_loss=0.09092, mel_loss=0.04189, linear_loss=0.05236]
[2020-05-12 01:01:53.047]  Step 149212  [3.320 sec/step, loss=0.09212, avg_loss=0.09094, mel_loss=0.04396, linear_loss=0.04816]
[2020-05-12 01:02:01.924]  Step 149213  [3.364 sec/step, loss=0.09879, avg_loss=0.09093, mel_loss=0.04617, linear_loss=0.05262]
[2020-05-12 01:02:08.893]  Step 149214  [3.406 sec/step, loss=0.09585, avg_loss=0.09094, mel_loss=0.04446, linear_loss=0.05138]
[2020-05-12 01:02:11.388]  Step 149215  [3.416 sec/step, loss=0.09196, avg_loss=0.09098, mel_loss=0.04083, linear_loss=0.05113]
[2020-05-12 01:02:12.194]  Step 149216  [3.418 sec/step, loss=0.07915, avg_loss=0.09102, mel_loss=0.03451, linear_loss=0.04464]
[2020-05-12 01:02:13.955]  Step 149217  [3.405 sec/step, loss=0.09085, avg_loss=0.09097, mel_loss=0.04001, linear_loss=0.05084]
[2020-05-12 01:02:15.100]  Step 149218  [3.365 sec/step, loss=0.08526, avg_loss=0.09083, mel_loss=0.03702, linear_loss=0.04825]
[2020-05-12 01:02:17.476]  Step 149219  [3.355 sec/step, loss=0.09243, avg_loss=0.09081, mel_loss=0.04113, linear_loss=0.05130]
[2020-05-12 01:02:19.214]  Generated 32 batches of size 32 in 1.733 sec
[2020-05-12 01:02:20.751]  Step 149220  [3.372 sec/step, loss=0.09822, avg_loss=0.09091, mel_loss=0.04432, linear_loss=0.05389]
[2020-05-12 01:02:22.327]  Step 149221  [3.354 sec/step, loss=0.08883, avg_loss=0.09083, mel_loss=0.03900, linear_loss=0.04983]
[2020-05-12 01:02:25.955]  Step 149222  [3.380 sec/step, loss=0.09880, avg_loss=0.09099, mel_loss=0.04486, linear_loss=0.05394]
[2020-05-12 01:02:29.340]  Step 149223  [3.377 sec/step, loss=0.09495, avg_loss=0.09095, mel_loss=0.04296, linear_loss=0.05199]
[2020-05-12 01:02:32.048]  Step 149224  [3.390 sec/step, loss=0.09374, avg_loss=0.09103, mel_loss=0.04187, linear_loss=0.05186]
[2020-05-12 01:02:36.087]  Step 149225  [3.369 sec/step, loss=0.09802, avg_loss=0.09103, mel_loss=0.04432, linear_loss=0.05369]
[2020-05-12 01:02:36.954]  Step 149226  [3.361 sec/step, loss=0.07357, avg_loss=0.09086, mel_loss=0.03233, linear_loss=0.04123]
[2020-05-12 01:02:41.558]  Step 149227  [3.388 sec/step, loss=0.09838, avg_loss=0.09093, mel_loss=0.04470, linear_loss=0.05368]
[2020-05-12 01:02:43.163]  Step 149228  [3.383 sec/step, loss=0.09201, avg_loss=0.09094, mel_loss=0.04083, linear_loss=0.05118]
[2020-05-12 01:02:46.044]  Step 149229  [3.365 sec/step, loss=0.09482, avg_loss=0.09090, mel_loss=0.04240, linear_loss=0.05242]
[2020-05-12 01:02:47.832]  Step 149230  [3.306 sec/step, loss=0.09038, avg_loss=0.09080, mel_loss=0.03972, linear_loss=0.05066]
[2020-05-12 01:02:51.311]  Step 149231  [3.316 sec/step, loss=0.09612, avg_loss=0.09082, mel_loss=0.04332, linear_loss=0.05280]
[2020-05-12 01:02:52.113]  Step 149232  [3.281 sec/step, loss=0.07931, avg_loss=0.09065, mel_loss=0.03433, linear_loss=0.04499]
[2020-05-12 01:02:53.832]  Step 149233  [3.289 sec/step, loss=0.09055, avg_loss=0.09075, mel_loss=0.03990, linear_loss=0.05065]
[2020-05-12 01:02:59.447]  Step 149234  [3.340 sec/step, loss=0.09897, avg_loss=0.09099, mel_loss=0.04541, linear_loss=0.05356]
[2020-05-12 01:03:04.089]  Step 149235  [3.376 sec/step, loss=0.09768, avg_loss=0.09116, mel_loss=0.04432, linear_loss=0.05336]
[2020-05-12 01:03:05.096]  Step 149236  [3.257 sec/step, loss=0.08385, avg_loss=0.09115, mel_loss=0.03690, linear_loss=0.04695]
[2020-05-12 01:03:06.103]  Step 149237  [3.262 sec/step, loss=0.08156, avg_loss=0.09121, mel_loss=0.03530, linear_loss=0.04627]
[2020-05-12 01:03:09.324]  Step 149238  [3.227 sec/step, loss=0.09687, avg_loss=0.09119, mel_loss=0.04362, linear_loss=0.05325]
[2020-05-12 01:03:13.137]  Step 149239  [3.250 sec/step, loss=0.09734, avg_loss=0.09126, mel_loss=0.04414, linear_loss=0.05321]
[2020-05-12 01:03:19.908]  Step 149240  [3.305 sec/step, loss=0.09809, avg_loss=0.09136, mel_loss=0.04527, linear_loss=0.05283]
[2020-05-12 01:03:22.567]  Step 149241  [3.303 sec/step, loss=0.09234, avg_loss=0.09134, mel_loss=0.04160, linear_loss=0.05074]
[2020-05-12 01:03:26.761]  Step 149242  [3.323 sec/step, loss=0.09708, avg_loss=0.09138, mel_loss=0.04414, linear_loss=0.05294]
[2020-05-12 01:03:40.021]  Step 149243  [3.315 sec/step, loss=0.08196, avg_loss=0.09143, mel_loss=0.03864, linear_loss=0.04332]
[2020-05-12 01:03:47.224]  Step 149244  [3.333 sec/step, loss=0.09923, avg_loss=0.09145, mel_loss=0.04592, linear_loss=0.05330]
[2020-05-12 01:03:48.871]  Step 149245  [3.293 sec/step, loss=0.08887, avg_loss=0.09134, mel_loss=0.03944, linear_loss=0.04943]
[2020-05-12 01:03:50.083]  Step 149246  [3.291 sec/step, loss=0.08513, avg_loss=0.09130, mel_loss=0.03726, linear_loss=0.04787]
[2020-05-12 01:03:53.466]  Step 149247  [3.291 sec/step, loss=0.09621, avg_loss=0.09131, mel_loss=0.04352, linear_loss=0.05270]
[2020-05-12 01:03:54.395]  Step 149248  [3.268 sec/step, loss=0.07253, avg_loss=0.09106, mel_loss=0.03149, linear_loss=0.04104]
[2020-05-12 01:03:55.870]  Step 149249  [3.271 sec/step, loss=0.08764, avg_loss=0.09111, mel_loss=0.03881, linear_loss=0.04883]
[2020-05-12 01:03:56.473]  Step 149250  [3.267 sec/step, loss=0.07022, avg_loss=0.09101, mel_loss=0.03138, linear_loss=0.03884]
[2020-05-12 01:03:56.473]  Writing summary at step: 149250
[2020-05-12 01:03:57.922]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149250
[2020-05-12 01:03:59.408]  Saving audio and alignment...
[2020-05-12 01:04:01.451]  Generated 32 batches of size 32 in 1.470 sec
[2020-05-12 01:04:02.202]  Input: 알려 드리겠습니다~_________
[2020-05-12 01:04:05.891]  Step 149251  [3.262 sec/step, loss=0.09875, avg_loss=0.09103, mel_loss=0.04466, linear_loss=0.05409]
[2020-05-12 01:04:14.186]  Step 149252  [3.327 sec/step, loss=0.09791, avg_loss=0.09109, mel_loss=0.04574, linear_loss=0.05217]
[2020-05-12 01:04:16.254]  Step 149253  [3.312 sec/step, loss=0.09273, avg_loss=0.09104, mel_loss=0.04122, linear_loss=0.05151]
[2020-05-12 01:04:18.716]  Step 149254  [3.327 sec/step, loss=0.09345, avg_loss=0.09112, mel_loss=0.04147, linear_loss=0.05198]
[2020-05-12 01:04:20.682]  Step 149255  [3.319 sec/step, loss=0.09198, avg_loss=0.09109, mel_loss=0.04064, linear_loss=0.05134]
[2020-05-12 01:04:22.758]  Step 149256  [3.267 sec/step, loss=0.09414, avg_loss=0.09103, mel_loss=0.04204, linear_loss=0.05209]
[2020-05-12 01:04:25.081]  Step 149257  [3.282 sec/step, loss=0.09160, avg_loss=0.09116, mel_loss=0.04084, linear_loss=0.05076]
[2020-05-12 01:04:30.350]  Step 149258  [3.308 sec/step, loss=0.09761, avg_loss=0.09120, mel_loss=0.04452, linear_loss=0.05309]
[2020-05-12 01:04:31.112]  Step 149259  [3.227 sec/step, loss=0.07906, avg_loss=0.09102, mel_loss=0.03479, linear_loss=0.04426]
[2020-05-12 01:04:35.581]  Step 149260  [3.225 sec/step, loss=0.09910, avg_loss=0.09103, mel_loss=0.04546, linear_loss=0.05364]
[2020-05-12 01:04:36.809]  Step 149261  [3.214 sec/step, loss=0.08619, avg_loss=0.09094, mel_loss=0.03799, linear_loss=0.04820]
[2020-05-12 01:04:51.229]  Step 149262  [3.346 sec/step, loss=0.07913, avg_loss=0.09088, mel_loss=0.03800, linear_loss=0.04113]
[2020-05-12 01:04:52.552]  Step 149263  [3.318 sec/step, loss=0.08709, avg_loss=0.09077, mel_loss=0.03816, linear_loss=0.04893]
[2020-05-12 01:04:54.724]  Step 149264  [3.323 sec/step, loss=0.09128, avg_loss=0.09078, mel_loss=0.04049, linear_loss=0.05079]
[2020-05-12 01:04:56.541]  Step 149265  [3.334 sec/step, loss=0.08876, avg_loss=0.09086, mel_loss=0.03923, linear_loss=0.04954]
[2020-05-12 01:05:01.189]  Step 149266  [3.361 sec/step, loss=0.09994, avg_loss=0.09095, mel_loss=0.04568, linear_loss=0.05426]
[2020-05-12 01:05:04.234]  Step 149267  [3.372 sec/step, loss=0.09694, avg_loss=0.09100, mel_loss=0.04355, linear_loss=0.05339]
[2020-05-12 01:05:05.981]  Step 149268  [3.382 sec/step, loss=0.09057, avg_loss=0.09110, mel_loss=0.03988, linear_loss=0.05069]
[2020-05-12 01:05:06.974]  Step 149269  [3.371 sec/step, loss=0.08292, avg_loss=0.09100, mel_loss=0.03591, linear_loss=0.04701]
[2020-05-12 01:05:12.272]  Step 149270  [3.364 sec/step, loss=0.09801, avg_loss=0.09098, mel_loss=0.04487, linear_loss=0.05314]
[2020-05-12 01:05:13.320]  Step 149271  [3.344 sec/step, loss=0.08439, avg_loss=0.09084, mel_loss=0.03664, linear_loss=0.04775]
[2020-05-12 01:05:17.498]  Step 149272  [3.363 sec/step, loss=0.09741, avg_loss=0.09088, mel_loss=0.04409, linear_loss=0.05331]
[2020-05-12 01:05:18.278]  Step 149273  [3.356 sec/step, loss=0.07920, avg_loss=0.09079, mel_loss=0.03451, linear_loss=0.04469]
[2020-05-12 01:05:19.854]  Step 149274  [3.367 sec/step, loss=0.08911, avg_loss=0.09099, mel_loss=0.03940, linear_loss=0.04971]
[2020-05-12 01:05:20.726]  Step 149275  [3.330 sec/step, loss=0.07951, avg_loss=0.09081, mel_loss=0.03429, linear_loss=0.04521]
[2020-05-12 01:05:23.593]  Step 149276  [3.285 sec/step, loss=0.09792, avg_loss=0.09080, mel_loss=0.04411, linear_loss=0.05381]
[2020-05-12 01:05:26.087]  Step 149277  [3.223 sec/step, loss=0.09112, avg_loss=0.09074, mel_loss=0.04048, linear_loss=0.05065]
[2020-05-12 01:05:26.659]  Step 149278  [3.211 sec/step, loss=0.07283, avg_loss=0.09057, mel_loss=0.03200, linear_loss=0.04083]
[2020-05-12 01:05:29.373]  Step 149279  [3.222 sec/step, loss=0.09592, avg_loss=0.09060, mel_loss=0.04291, linear_loss=0.05301]
[2020-05-12 01:05:33.068]  Step 149280  [3.244 sec/step, loss=0.09819, avg_loss=0.09070, mel_loss=0.04447, linear_loss=0.05372]
[2020-05-12 01:05:34.537]  Step 149281  [3.225 sec/step, loss=0.09040, avg_loss=0.09063, mel_loss=0.03961, linear_loss=0.05079]
[2020-05-12 01:05:36.304]  Generated 32 batches of size 32 in 1.762 sec
[2020-05-12 01:05:36.640]  Step 149282  [3.104 sec/step, loss=0.09040, avg_loss=0.09075, mel_loss=0.04047, linear_loss=0.04992]
[2020-05-12 01:05:40.113]  Step 149283  [3.128 sec/step, loss=0.09536, avg_loss=0.09087, mel_loss=0.04322, linear_loss=0.05214]
[2020-05-12 01:05:46.483]  Step 149284  [3.149 sec/step, loss=0.09881, avg_loss=0.09090, mel_loss=0.04568, linear_loss=0.05313]
[2020-05-12 01:05:47.860]  Step 149285  [3.107 sec/step, loss=0.08844, avg_loss=0.09083, mel_loss=0.03893, linear_loss=0.04951]
[2020-05-12 01:05:53.571]  Step 149286  [3.156 sec/step, loss=0.09889, avg_loss=0.09104, mel_loss=0.04538, linear_loss=0.05350]
[2020-05-12 01:06:02.417]  Step 149287  [3.218 sec/step, loss=0.09929, avg_loss=0.09107, mel_loss=0.04666, linear_loss=0.05263]
[2020-05-12 01:06:04.780]  Step 149288  [3.231 sec/step, loss=0.09495, avg_loss=0.09123, mel_loss=0.04244, linear_loss=0.05252]
[2020-05-12 01:06:08.241]  Step 149289  [3.254 sec/step, loss=0.09749, avg_loss=0.09133, mel_loss=0.04411, linear_loss=0.05338]
[2020-05-12 01:06:15.511]  Step 149290  [3.288 sec/step, loss=0.09967, avg_loss=0.09135, mel_loss=0.04658, linear_loss=0.05310]
[2020-05-12 01:06:20.962]  Step 149291  [3.314 sec/step, loss=0.09886, avg_loss=0.09138, mel_loss=0.04541, linear_loss=0.05344]
[2020-05-12 01:06:21.523]  Step 149292  [3.284 sec/step, loss=0.07181, avg_loss=0.09112, mel_loss=0.03177, linear_loss=0.04003]
[2020-05-12 01:06:23.116]  Step 149293  [3.287 sec/step, loss=0.09034, avg_loss=0.09115, mel_loss=0.04004, linear_loss=0.05029]
[2020-05-12 01:06:27.501]  Step 149294  [3.313 sec/step, loss=0.09996, avg_loss=0.09124, mel_loss=0.04561, linear_loss=0.05435]
[2020-05-12 01:06:30.867]  Step 149295  [3.298 sec/step, loss=0.09581, avg_loss=0.09122, mel_loss=0.04327, linear_loss=0.05255]
[2020-05-12 01:06:32.883]  Step 149296  [3.293 sec/step, loss=0.09205, avg_loss=0.09121, mel_loss=0.04092, linear_loss=0.05113]
[2020-05-12 01:06:41.030]  Step 149297  [3.365 sec/step, loss=0.09733, avg_loss=0.09137, mel_loss=0.04535, linear_loss=0.05198]
[2020-05-12 01:06:41.847]  Step 149298  [3.338 sec/step, loss=0.07745, avg_loss=0.09119, mel_loss=0.03382, linear_loss=0.04363]
[2020-05-12 01:06:43.793]  Step 149299  [3.338 sec/step, loss=0.09233, avg_loss=0.09121, mel_loss=0.04092, linear_loss=0.05141]
[2020-05-12 01:06:47.394]  Step 149300  [3.361 sec/step, loss=0.09782, avg_loss=0.09135, mel_loss=0.04427, linear_loss=0.05354]
[2020-05-12 01:06:47.394]  Writing summary at step: 149300
[2020-05-12 01:06:48.414]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149300
[2020-05-12 01:06:49.792]  Saving audio and alignment...
[2020-05-12 01:06:52.689]  Input: 이 사람 하고 쳐 주시고요~__________________
[2020-05-12 01:06:54.450]  Step 149301  [3.297 sec/step, loss=0.09053, avg_loss=0.09126, mel_loss=0.03999, linear_loss=0.05054]
[2020-05-12 01:06:58.488]  Step 149302  [3.329 sec/step, loss=0.09845, avg_loss=0.09151, mel_loss=0.04456, linear_loss=0.05388]
[2020-05-12 01:06:59.312]  Step 149303  [3.303 sec/step, loss=0.07670, avg_loss=0.09135, mel_loss=0.03358, linear_loss=0.04312]
[2020-05-12 01:07:04.154]  Step 149304  [3.328 sec/step, loss=0.09728, avg_loss=0.09147, mel_loss=0.04432, linear_loss=0.05295]
[2020-05-12 01:07:07.010]  Step 149305  [3.308 sec/step, loss=0.09342, avg_loss=0.09141, mel_loss=0.04185, linear_loss=0.05157]
[2020-05-12 01:07:09.601]  Step 149306  [3.323 sec/step, loss=0.09437, avg_loss=0.09149, mel_loss=0.04246, linear_loss=0.05191]
[2020-05-12 01:07:16.824]  Step 149307  [3.337 sec/step, loss=0.09839, avg_loss=0.09148, mel_loss=0.04545, linear_loss=0.05294]
[2020-05-12 01:07:20.226]  Step 149308  [3.343 sec/step, loss=0.09602, avg_loss=0.09149, mel_loss=0.04323, linear_loss=0.05279]
[2020-05-12 01:07:23.167]  Step 149309  [3.341 sec/step, loss=0.09774, avg_loss=0.09150, mel_loss=0.04403, linear_loss=0.05371]
[2020-05-12 01:07:24.543]  Step 149310  [3.345 sec/step, loss=0.08594, avg_loss=0.09153, mel_loss=0.03794, linear_loss=0.04800]
[2020-05-12 01:07:26.703]  Step 149311  [3.347 sec/step, loss=0.09367, avg_loss=0.09152, mel_loss=0.04167, linear_loss=0.05199]
[2020-05-12 01:07:27.750]  Step 149312  [3.237 sec/step, loss=0.08178, avg_loss=0.09142, mel_loss=0.03526, linear_loss=0.04652]
[2020-05-12 01:07:28.418]  Generated 32 batches of size 32 in 1.710 sec
[2020-05-12 01:07:41.850]  Step 149313  [3.289 sec/step, loss=0.07449, avg_loss=0.09118, mel_loss=0.03562, linear_loss=0.03887]
[2020-05-12 01:07:43.044]  Step 149314  [3.231 sec/step, loss=0.08410, avg_loss=0.09106, mel_loss=0.03688, linear_loss=0.04722]
[2020-05-12 01:07:44.148]  Step 149315  [3.217 sec/step, loss=0.08672, avg_loss=0.09101, mel_loss=0.03761, linear_loss=0.04912]
[2020-05-12 01:07:45.617]  Step 149316  [3.224 sec/step, loss=0.08796, avg_loss=0.09110, mel_loss=0.03871, linear_loss=0.04926]
[2020-05-12 01:07:49.870]  Step 149317  [3.249 sec/step, loss=0.09808, avg_loss=0.09117, mel_loss=0.04443, linear_loss=0.05365]
[2020-05-12 01:07:55.924]  Step 149318  [3.298 sec/step, loss=0.09823, avg_loss=0.09130, mel_loss=0.04549, linear_loss=0.05274]
[2020-05-12 01:07:58.195]  Step 149319  [3.297 sec/step, loss=0.09218, avg_loss=0.09130, mel_loss=0.04118, linear_loss=0.05100]
[2020-05-12 01:08:00.661]  Step 149320  [3.289 sec/step, loss=0.09301, avg_loss=0.09124, mel_loss=0.04125, linear_loss=0.05176]
[2020-05-12 01:08:02.206]  Step 149321  [3.288 sec/step, loss=0.08957, avg_loss=0.09125, mel_loss=0.03929, linear_loss=0.05028]
[2020-05-12 01:08:03.505]  Step 149322  [3.265 sec/step, loss=0.08889, avg_loss=0.09115, mel_loss=0.03882, linear_loss=0.05007]
[2020-05-12 01:08:04.722]  Step 149323  [3.243 sec/step, loss=0.08447, avg_loss=0.09105, mel_loss=0.03678, linear_loss=0.04769]
[2020-05-12 01:08:05.476]  Step 149324  [3.224 sec/step, loss=0.08091, avg_loss=0.09092, mel_loss=0.03493, linear_loss=0.04597]
[2020-05-12 01:08:07.480]  Step 149325  [3.203 sec/step, loss=0.09216, avg_loss=0.09086, mel_loss=0.04059, linear_loss=0.05158]
[2020-05-12 01:08:11.616]  Step 149326  [3.236 sec/step, loss=0.09653, avg_loss=0.09109, mel_loss=0.04362, linear_loss=0.05291]
[2020-05-12 01:08:14.087]  Step 149327  [3.215 sec/step, loss=0.09273, avg_loss=0.09103, mel_loss=0.04153, linear_loss=0.05120]
[2020-05-12 01:08:14.990]  Step 149328  [3.208 sec/step, loss=0.07996, avg_loss=0.09091, mel_loss=0.03459, linear_loss=0.04536]
[2020-05-12 01:08:15.931]  Step 149329  [3.188 sec/step, loss=0.08589, avg_loss=0.09082, mel_loss=0.03765, linear_loss=0.04824]
[2020-05-12 01:08:18.691]  Step 149330  [3.198 sec/step, loss=0.09101, avg_loss=0.09083, mel_loss=0.04100, linear_loss=0.05001]
[2020-05-12 01:08:24.631]  Step 149331  [3.223 sec/step, loss=0.09823, avg_loss=0.09085, mel_loss=0.04524, linear_loss=0.05298]
[2020-05-12 01:08:29.149]  Step 149332  [3.260 sec/step, loss=0.09745, avg_loss=0.09103, mel_loss=0.04405, linear_loss=0.05340]
[2020-05-12 01:08:32.636]  Step 149333  [3.278 sec/step, loss=0.09477, avg_loss=0.09107, mel_loss=0.04267, linear_loss=0.05210]
[2020-05-12 01:08:37.516]  Step 149334  [3.270 sec/step, loss=0.09778, avg_loss=0.09106, mel_loss=0.04461, linear_loss=0.05317]
[2020-05-12 01:08:43.065]  Step 149335  [3.279 sec/step, loss=0.10048, avg_loss=0.09109, mel_loss=0.04614, linear_loss=0.05434]
[2020-05-12 01:08:51.667]  Step 149336  [3.355 sec/step, loss=0.09500, avg_loss=0.09120, mel_loss=0.04429, linear_loss=0.05071]
[2020-05-12 01:08:52.470]  Step 149337  [3.353 sec/step, loss=0.07997, avg_loss=0.09119, mel_loss=0.03488, linear_loss=0.04509]
[2020-05-12 01:08:56.310]  Step 149338  [3.359 sec/step, loss=0.09773, avg_loss=0.09119, mel_loss=0.04432, linear_loss=0.05341]
[2020-05-12 01:08:57.504]  Step 149339  [3.333 sec/step, loss=0.08549, avg_loss=0.09108, mel_loss=0.03711, linear_loss=0.04838]
[2020-05-12 01:09:05.018]  Step 149340  [3.341 sec/step, loss=0.09893, avg_loss=0.09108, mel_loss=0.04580, linear_loss=0.05313]
[2020-05-12 01:09:07.019]  Step 149341  [3.334 sec/step, loss=0.08974, avg_loss=0.09106, mel_loss=0.03948, linear_loss=0.05026]
[2020-05-12 01:09:09.310]  Step 149342  [3.315 sec/step, loss=0.09363, avg_loss=0.09102, mel_loss=0.04191, linear_loss=0.05172]
[2020-05-12 01:09:11.587]  Step 149343  [3.205 sec/step, loss=0.09243, avg_loss=0.09113, mel_loss=0.04132, linear_loss=0.05111]
[2020-05-12 01:09:12.184]  Step 149344  [3.139 sec/step, loss=0.07237, avg_loss=0.09086, mel_loss=0.03186, linear_loss=0.04051]
[2020-05-12 01:09:13.515]  Generated 32 batches of size 32 in 1.922 sec
[2020-05-12 01:09:15.438]  Step 149345  [3.155 sec/step, loss=0.09832, avg_loss=0.09095, mel_loss=0.04444, linear_loss=0.05388]
[2020-05-12 01:09:16.783]  Step 149346  [3.157 sec/step, loss=0.08848, avg_loss=0.09099, mel_loss=0.03899, linear_loss=0.04949]
[2020-05-12 01:09:20.562]  Step 149347  [3.160 sec/step, loss=0.09765, avg_loss=0.09100, mel_loss=0.04421, linear_loss=0.05344]
[2020-05-12 01:09:23.438]  Step 149348  [3.180 sec/step, loss=0.09597, avg_loss=0.09124, mel_loss=0.04329, linear_loss=0.05268]
[2020-05-12 01:09:26.557]  Step 149349  [3.196 sec/step, loss=0.09721, avg_loss=0.09133, mel_loss=0.04376, linear_loss=0.05345]
[2020-05-12 01:09:38.855]  Step 149350  [3.313 sec/step, loss=0.08824, avg_loss=0.09151, mel_loss=0.04183, linear_loss=0.04641]
[2020-05-12 01:09:38.855]  Writing summary at step: 149350
[2020-05-12 01:09:40.480]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149350
[2020-05-12 01:09:41.947]  Saving audio and alignment...
[2020-05-12 01:09:44.960]  Input: 강릉 새벽 바다~_________________________
[2020-05-12 01:09:45.994]  Step 149351  [3.287 sec/step, loss=0.08019, avg_loss=0.09133, mel_loss=0.03471, linear_loss=0.04548]
[2020-05-12 01:09:49.122]  Step 149352  [3.235 sec/step, loss=0.09471, avg_loss=0.09130, mel_loss=0.04283, linear_loss=0.05189]
[2020-05-12 01:09:51.746]  Step 149353  [3.241 sec/step, loss=0.09402, avg_loss=0.09131, mel_loss=0.04221, linear_loss=0.05181]
[2020-05-12 01:09:53.387]  Step 149354  [3.232 sec/step, loss=0.08990, avg_loss=0.09127, mel_loss=0.03946, linear_loss=0.05044]
[2020-05-12 01:09:54.183]  Step 149355  [3.221 sec/step, loss=0.07823, avg_loss=0.09113, mel_loss=0.03405, linear_loss=0.04419]
[2020-05-12 01:09:56.090]  Step 149356  [3.219 sec/step, loss=0.09265, avg_loss=0.09112, mel_loss=0.04101, linear_loss=0.05165]
[2020-05-12 01:09:57.662]  Step 149357  [3.212 sec/step, loss=0.08941, avg_loss=0.09110, mel_loss=0.03939, linear_loss=0.05002]
[2020-05-12 01:09:58.346]  Step 149358  [3.166 sec/step, loss=0.07321, avg_loss=0.09085, mel_loss=0.03213, linear_loss=0.04107]
[2020-05-12 01:09:58.906]  Step 149359  [3.164 sec/step, loss=0.07173, avg_loss=0.09078, mel_loss=0.03208, linear_loss=0.03965]
[2020-05-12 01:10:02.319]  Step 149360  [3.153 sec/step, loss=0.09743, avg_loss=0.09076, mel_loss=0.04400, linear_loss=0.05342]
[2020-05-12 01:10:05.950]  Step 149361  [3.177 sec/step, loss=0.09849, avg_loss=0.09089, mel_loss=0.04440, linear_loss=0.05409]
[2020-05-12 01:10:07.744]  Step 149362  [3.051 sec/step, loss=0.08916, avg_loss=0.09099, mel_loss=0.03922, linear_loss=0.04994]
[2020-05-12 01:10:12.529]  Step 149363  [3.086 sec/step, loss=0.09791, avg_loss=0.09110, mel_loss=0.04483, linear_loss=0.05307]
[2020-05-12 01:10:14.958]  Step 149364  [3.088 sec/step, loss=0.09505, avg_loss=0.09113, mel_loss=0.04217, linear_loss=0.05288]
[2020-05-12 01:10:23.722]  Step 149365  [3.158 sec/step, loss=0.10791, avg_loss=0.09132, mel_loss=0.05255, linear_loss=0.05536]
[2020-05-12 01:10:28.683]  Step 149366  [3.161 sec/step, loss=0.10253, avg_loss=0.09135, mel_loss=0.04815, linear_loss=0.05438]
[2020-05-12 01:10:32.105]  Step 149367  [3.164 sec/step, loss=0.09808, avg_loss=0.09136, mel_loss=0.04462, linear_loss=0.05345]
[2020-05-12 01:10:34.161]  Step 149368  [3.168 sec/step, loss=0.09321, avg_loss=0.09139, mel_loss=0.04180, linear_loss=0.05142]
[2020-05-12 01:10:40.892]  Step 149369  [3.225 sec/step, loss=0.10731, avg_loss=0.09163, mel_loss=0.05140, linear_loss=0.05591]
[2020-05-12 01:10:44.909]  Step 149370  [3.212 sec/step, loss=0.10862, avg_loss=0.09174, mel_loss=0.05126, linear_loss=0.05737]
[2020-05-12 01:10:52.546]  Step 149371  [3.278 sec/step, loss=0.10896, avg_loss=0.09198, mel_loss=0.05294, linear_loss=0.05602]
[2020-05-12 01:10:54.695]  Step 149372  [3.258 sec/step, loss=0.09628, avg_loss=0.09197, mel_loss=0.04318, linear_loss=0.05310]
[2020-05-12 01:11:00.454]  Step 149373  [3.308 sec/step, loss=0.10227, avg_loss=0.09220, mel_loss=0.04772, linear_loss=0.05455]
[2020-05-12 01:11:01.941]  Step 149374  [3.307 sec/step, loss=0.09086, avg_loss=0.09222, mel_loss=0.04060, linear_loss=0.05026]
[2020-05-12 01:11:02.286]  Generated 32 batches of size 32 in 1.826 sec
[2020-05-12 01:11:02.954]  Step 149375  [3.308 sec/step, loss=0.08375, avg_loss=0.09226, mel_loss=0.03686, linear_loss=0.04690]
[2020-05-12 01:11:07.270]  Step 149376  [3.323 sec/step, loss=0.10531, avg_loss=0.09234, mel_loss=0.04962, linear_loss=0.05570]
[2020-05-12 01:11:21.588]  Step 149377  [3.441 sec/step, loss=0.08793, avg_loss=0.09231, mel_loss=0.04433, linear_loss=0.04360]
[2020-05-12 01:11:23.500]  Step 149378  [3.454 sec/step, loss=0.09025, avg_loss=0.09248, mel_loss=0.04052, linear_loss=0.04974]
[2020-05-12 01:11:25.432]  Step 149379  [3.446 sec/step, loss=0.08803, avg_loss=0.09240, mel_loss=0.03915, linear_loss=0.04888]
[2020-05-12 01:11:27.204]  Step 149380  [3.427 sec/step, loss=0.08714, avg_loss=0.09229, mel_loss=0.03842, linear_loss=0.04872]
[2020-05-12 01:11:31.708]  Step 149381  [3.457 sec/step, loss=0.09999, avg_loss=0.09239, mel_loss=0.04556, linear_loss=0.05443]
[2020-05-12 01:11:35.482]  Step 149382  [3.474 sec/step, loss=0.09537, avg_loss=0.09244, mel_loss=0.04316, linear_loss=0.05221]
[2020-05-12 01:11:38.448]  Step 149383  [3.469 sec/step, loss=0.09497, avg_loss=0.09243, mel_loss=0.04240, linear_loss=0.05257]
[2020-05-12 01:11:39.499]  Step 149384  [3.416 sec/step, loss=0.08527, avg_loss=0.09230, mel_loss=0.03787, linear_loss=0.04740]
[2020-05-12 01:11:40.503]  Step 149385  [3.412 sec/step, loss=0.08596, avg_loss=0.09227, mel_loss=0.03774, linear_loss=0.04822]
[2020-05-12 01:11:41.357]  Step 149386  [3.364 sec/step, loss=0.07897, avg_loss=0.09207, mel_loss=0.03432, linear_loss=0.04465]
[2020-05-12 01:11:46.232]  Step 149387  [3.324 sec/step, loss=0.10366, avg_loss=0.09212, mel_loss=0.04842, linear_loss=0.05524]
[2020-05-12 01:11:47.393]  Step 149388  [3.312 sec/step, loss=0.08947, avg_loss=0.09206, mel_loss=0.03951, linear_loss=0.04995]
[2020-05-12 01:11:50.561]  Step 149389  [3.309 sec/step, loss=0.10082, avg_loss=0.09209, mel_loss=0.04609, linear_loss=0.05473]
[2020-05-12 01:11:51.911]  Step 149390  [3.250 sec/step, loss=0.08906, avg_loss=0.09199, mel_loss=0.03938, linear_loss=0.04967]
[2020-05-12 01:11:56.054]  Step 149391  [3.237 sec/step, loss=0.09907, avg_loss=0.09199, mel_loss=0.04568, linear_loss=0.05338]
[2020-05-12 01:11:57.695]  Step 149392  [3.247 sec/step, loss=0.09284, avg_loss=0.09220, mel_loss=0.04148, linear_loss=0.05136]
[2020-05-12 01:12:00.660]  Step 149393  [3.261 sec/step, loss=0.09846, avg_loss=0.09228, mel_loss=0.04492, linear_loss=0.05354]
[2020-05-12 01:12:02.163]  Step 149394  [3.232 sec/step, loss=0.08971, avg_loss=0.09218, mel_loss=0.03998, linear_loss=0.04973]
[2020-05-12 01:12:03.924]  Step 149395  [3.216 sec/step, loss=0.09249, avg_loss=0.09215, mel_loss=0.04093, linear_loss=0.05156]
[2020-05-12 01:12:05.889]  Step 149396  [3.216 sec/step, loss=0.09248, avg_loss=0.09215, mel_loss=0.04096, linear_loss=0.05153]
[2020-05-12 01:12:08.699]  Step 149397  [3.162 sec/step, loss=0.09689, avg_loss=0.09215, mel_loss=0.04402, linear_loss=0.05286]
[2020-05-12 01:12:14.454]  Step 149398  [3.212 sec/step, loss=0.10270, avg_loss=0.09240, mel_loss=0.04774, linear_loss=0.05496]
[2020-05-12 01:12:18.042]  Step 149399  [3.228 sec/step, loss=0.10147, avg_loss=0.09249, mel_loss=0.04633, linear_loss=0.05514]
[2020-05-12 01:12:21.647]  Step 149400  [3.228 sec/step, loss=0.09776, avg_loss=0.09249, mel_loss=0.04474, linear_loss=0.05303]
[2020-05-12 01:12:21.647]  Writing summary at step: 149400
[2020-05-12 01:12:27.052]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149400
[2020-05-12 01:12:28.485]  Saving audio and alignment...
[2020-05-12 01:12:30.117]  Input: 예컨대~___________________
[2020-05-12 01:12:31.235]  Step 149401  [3.222 sec/step, loss=0.08557, avg_loss=0.09244, mel_loss=0.03740, linear_loss=0.04817]
[2020-05-12 01:12:33.277]  Step 149402  [3.202 sec/step, loss=0.09342, avg_loss=0.09239, mel_loss=0.04228, linear_loss=0.05114]
[2020-05-12 01:12:35.490]  Step 149403  [3.216 sec/step, loss=0.09390, avg_loss=0.09256, mel_loss=0.04226, linear_loss=0.05164]
[2020-05-12 01:12:37.217]  Generated 32 batches of size 32 in 1.721 sec
[2020-05-12 01:12:47.147]  Step 149404  [3.284 sec/step, loss=0.09725, avg_loss=0.09256, mel_loss=0.04690, linear_loss=0.05034]
[2020-05-12 01:12:54.450]  Step 149405  [3.328 sec/step, loss=0.10064, avg_loss=0.09263, mel_loss=0.04722, linear_loss=0.05342]
[2020-05-12 01:13:00.926]  Step 149406  [3.367 sec/step, loss=0.10008, avg_loss=0.09269, mel_loss=0.04688, linear_loss=0.05320]
[2020-05-12 01:13:04.659]  Step 149407  [3.332 sec/step, loss=0.10155, avg_loss=0.09272, mel_loss=0.04669, linear_loss=0.05486]
[2020-05-12 01:13:05.414]  Step 149408  [3.306 sec/step, loss=0.07971, avg_loss=0.09256, mel_loss=0.03590, linear_loss=0.04381]
[2020-05-12 01:13:06.805]  Step 149409  [3.290 sec/step, loss=0.09151, avg_loss=0.09250, mel_loss=0.04064, linear_loss=0.05088]
[2020-05-12 01:13:09.486]  Step 149410  [3.303 sec/step, loss=0.09475, avg_loss=0.09259, mel_loss=0.04273, linear_loss=0.05202]
[2020-05-12 01:13:11.320]  Step 149411  [3.300 sec/step, loss=0.09265, avg_loss=0.09258, mel_loss=0.04102, linear_loss=0.05164]
[2020-05-12 01:13:19.938]  Step 149412  [3.376 sec/step, loss=0.10457, avg_loss=0.09280, mel_loss=0.05001, linear_loss=0.05457]
[2020-05-12 01:13:21.987]  Step 149413  [3.255 sec/step, loss=0.09509, avg_loss=0.09301, mel_loss=0.04290, linear_loss=0.05219]
[2020-05-12 01:13:23.077]  Step 149414  [3.254 sec/step, loss=0.08712, avg_loss=0.09304, mel_loss=0.03839, linear_loss=0.04873]
[2020-05-12 01:13:24.093]  Step 149415  [3.253 sec/step, loss=0.08453, avg_loss=0.09302, mel_loss=0.03738, linear_loss=0.04715]
[2020-05-12 01:13:31.589]  Step 149416  [3.314 sec/step, loss=0.10289, avg_loss=0.09317, mel_loss=0.04854, linear_loss=0.05435]
[2020-05-12 01:13:32.430]  Step 149417  [3.280 sec/step, loss=0.07789, avg_loss=0.09296, mel_loss=0.03499, linear_loss=0.04290]
[2020-05-12 01:13:35.564]  Step 149418  [3.250 sec/step, loss=0.09990, avg_loss=0.09298, mel_loss=0.04542, linear_loss=0.05448]
[2020-05-12 01:13:40.792]  Step 149419  [3.280 sec/step, loss=0.10164, avg_loss=0.09308, mel_loss=0.04718, linear_loss=0.05447]
[2020-05-12 01:13:43.729]  Step 149420  [3.285 sec/step, loss=0.09928, avg_loss=0.09314, mel_loss=0.04495, linear_loss=0.05433]
[2020-05-12 01:13:47.878]  Step 149421  [3.311 sec/step, loss=0.09891, avg_loss=0.09323, mel_loss=0.04512, linear_loss=0.05379]
[2020-05-12 01:13:51.332]  Step 149422  [3.332 sec/step, loss=0.09940, avg_loss=0.09334, mel_loss=0.04576, linear_loss=0.05363]
[2020-05-12 01:13:52.198]  Step 149423  [3.329 sec/step, loss=0.08551, avg_loss=0.09335, mel_loss=0.03728, linear_loss=0.04823]
[2020-05-12 01:13:56.777]  Step 149424  [3.367 sec/step, loss=0.09982, avg_loss=0.09354, mel_loss=0.04609, linear_loss=0.05373]
[2020-05-12 01:13:58.706]  Step 149425  [3.366 sec/step, loss=0.09368, avg_loss=0.09355, mel_loss=0.04214, linear_loss=0.05153]
[2020-05-12 01:14:05.353]  Step 149426  [3.391 sec/step, loss=0.10036, avg_loss=0.09359, mel_loss=0.04703, linear_loss=0.05334]
[2020-05-12 01:14:07.686]  Step 149427  [3.390 sec/step, loss=0.09432, avg_loss=0.09361, mel_loss=0.04261, linear_loss=0.05171]
[2020-05-12 01:14:09.043]  Step 149428  [3.395 sec/step, loss=0.08954, avg_loss=0.09370, mel_loss=0.04002, linear_loss=0.04952]
[2020-05-12 01:14:09.571]  Step 149429  [3.390 sec/step, loss=0.07248, avg_loss=0.09357, mel_loss=0.03227, linear_loss=0.04021]
[2020-05-12 01:14:11.153]  Step 149430  [3.379 sec/step, loss=0.09197, avg_loss=0.09358, mel_loss=0.04092, linear_loss=0.05105]
[2020-05-12 01:14:20.178]  Step 149431  [3.409 sec/step, loss=0.09765, avg_loss=0.09357, mel_loss=0.04618, linear_loss=0.05147]
[2020-05-12 01:14:24.665]  Step 149432  [3.409 sec/step, loss=0.10001, avg_loss=0.09360, mel_loss=0.04572, linear_loss=0.05429]
[2020-05-12 01:14:30.251]  Step 149433  [3.430 sec/step, loss=0.09974, avg_loss=0.09365, mel_loss=0.04615, linear_loss=0.05359]
[2020-05-12 01:14:33.058]  Step 149434  [3.409 sec/step, loss=0.09358, avg_loss=0.09361, mel_loss=0.04242, linear_loss=0.05116]
[2020-05-12 01:14:36.750]  Step 149435  [3.391 sec/step, loss=0.10026, avg_loss=0.09360, mel_loss=0.04591, linear_loss=0.05434]
[2020-05-12 01:14:38.504]  Generated 32 batches of size 32 in 1.748 sec
[2020-05-12 01:14:38.626]  Step 149436  [3.324 sec/step, loss=0.08986, avg_loss=0.09355, mel_loss=0.03994, linear_loss=0.04992]
[2020-05-12 01:14:41.121]  Step 149437  [3.340 sec/step, loss=0.09480, avg_loss=0.09370, mel_loss=0.04248, linear_loss=0.05232]
[2020-05-12 01:14:41.872]  Step 149438  [3.310 sec/step, loss=0.08274, avg_loss=0.09355, mel_loss=0.03628, linear_loss=0.04646]
[2020-05-12 01:14:43.169]  Step 149439  [3.311 sec/step, loss=0.08823, avg_loss=0.09358, mel_loss=0.03895, linear_loss=0.04928]
[2020-05-12 01:14:57.618]  Step 149440  [3.380 sec/step, loss=0.08022, avg_loss=0.09339, mel_loss=0.03872, linear_loss=0.04150]
[2020-05-12 01:14:58.836]  Step 149441  [3.372 sec/step, loss=0.08738, avg_loss=0.09337, mel_loss=0.03844, linear_loss=0.04894]
[2020-05-12 01:15:02.310]  Step 149442  [3.384 sec/step, loss=0.09666, avg_loss=0.09340, mel_loss=0.04385, linear_loss=0.05282]
[2020-05-12 01:15:04.014]  Step 149443  [3.378 sec/step, loss=0.09117, avg_loss=0.09338, mel_loss=0.04065, linear_loss=0.05053]
[2020-05-12 01:15:06.162]  Step 149444  [3.394 sec/step, loss=0.09481, avg_loss=0.09361, mel_loss=0.04247, linear_loss=0.05234]
[2020-05-12 01:15:12.604]  Step 149445  [3.426 sec/step, loss=0.09944, avg_loss=0.09362, mel_loss=0.04611, linear_loss=0.05333]
[2020-05-12 01:15:21.310]  Step 149446  [3.499 sec/step, loss=0.09715, avg_loss=0.09371, mel_loss=0.04550, linear_loss=0.05165]
[2020-05-12 01:15:25.546]  Step 149447  [3.504 sec/step, loss=0.10005, avg_loss=0.09373, mel_loss=0.04611, linear_loss=0.05393]
[2020-05-12 01:15:29.036]  Step 149448  [3.510 sec/step, loss=0.09737, avg_loss=0.09374, mel_loss=0.04431, linear_loss=0.05306]
[2020-05-12 01:15:32.212]  Step 149449  [3.511 sec/step, loss=0.09896, avg_loss=0.09376, mel_loss=0.04502, linear_loss=0.05394]
[2020-05-12 01:15:34.418]  Step 149450  [3.410 sec/step, loss=0.09308, avg_loss=0.09381, mel_loss=0.04165, linear_loss=0.05144]
[2020-05-12 01:15:34.418]  Writing summary at step: 149450
[2020-05-12 01:15:34.954]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149450
[2020-05-12 01:15:36.411]  Saving audio and alignment...
[2020-05-12 01:15:43.482]  Input: 안녕하세요 실전 결혼식 사회 강의를 맡은 아나운서 박은줍니다~___________________________
[2020-05-12 01:15:45.908]  Step 149451  [3.424 sec/step, loss=0.09360, avg_loss=0.09394, mel_loss=0.04206, linear_loss=0.05154]
[2020-05-12 01:15:47.856]  Step 149452  [3.412 sec/step, loss=0.09244, avg_loss=0.09392, mel_loss=0.04139, linear_loss=0.05105]
[2020-05-12 01:15:48.870]  Step 149453  [3.396 sec/step, loss=0.08260, avg_loss=0.09381, mel_loss=0.03613, linear_loss=0.04646]
[2020-05-12 01:15:50.125]  Step 149454  [3.392 sec/step, loss=0.08466, avg_loss=0.09376, mel_loss=0.03741, linear_loss=0.04725]
[2020-05-12 01:15:51.733]  Step 149455  [3.400 sec/step, loss=0.08888, avg_loss=0.09386, mel_loss=0.03928, linear_loss=0.04960]
[2020-05-12 01:15:53.418]  Step 149456  [3.398 sec/step, loss=0.09082, avg_loss=0.09384, mel_loss=0.04046, linear_loss=0.05036]
[2020-05-12 01:15:57.190]  Step 149457  [3.420 sec/step, loss=0.09935, avg_loss=0.09394, mel_loss=0.04556, linear_loss=0.05378]
[2020-05-12 01:15:58.596]  Step 149458  [3.427 sec/step, loss=0.08692, avg_loss=0.09408, mel_loss=0.03810, linear_loss=0.04882]
[2020-05-12 01:15:59.656]  Step 149459  [3.432 sec/step, loss=0.08595, avg_loss=0.09422, mel_loss=0.03729, linear_loss=0.04866]
[2020-05-12 01:16:02.627]  Step 149460  [3.427 sec/step, loss=0.09722, avg_loss=0.09422, mel_loss=0.04395, linear_loss=0.05328]
[2020-05-12 01:16:08.413]  Step 149461  [3.449 sec/step, loss=0.09944, avg_loss=0.09423, mel_loss=0.04584, linear_loss=0.05359]
[2020-05-12 01:16:12.411]  Step 149462  [3.471 sec/step, loss=0.09761, avg_loss=0.09431, mel_loss=0.04439, linear_loss=0.05322]
[2020-05-12 01:16:13.232]  Step 149463  [3.431 sec/step, loss=0.07950, avg_loss=0.09413, mel_loss=0.03466, linear_loss=0.04484]
[2020-05-12 01:16:14.692]  Step 149464  [3.422 sec/step, loss=0.08775, avg_loss=0.09406, mel_loss=0.03894, linear_loss=0.04881]
[2020-05-12 01:16:16.738]  Step 149465  [3.355 sec/step, loss=0.09235, avg_loss=0.09390, mel_loss=0.04111, linear_loss=0.05124]
[2020-05-12 01:16:18.421]  Generated 32 batches of size 32 in 1.678 sec
[2020-05-12 01:16:22.195]  Step 149466  [3.360 sec/step, loss=0.10016, avg_loss=0.09388, mel_loss=0.04624, linear_loss=0.05392]
[2020-05-12 01:16:29.743]  Step 149467  [3.401 sec/step, loss=0.10084, avg_loss=0.09391, mel_loss=0.04716, linear_loss=0.05367]
[2020-05-12 01:16:32.298]  Step 149468  [3.406 sec/step, loss=0.09374, avg_loss=0.09391, mel_loss=0.04181, linear_loss=0.05193]
[2020-05-12 01:16:33.180]  Step 149469  [3.347 sec/step, loss=0.07356, avg_loss=0.09357, mel_loss=0.03210, linear_loss=0.04146]
[2020-05-12 01:16:35.942]  Step 149470  [3.335 sec/step, loss=0.09536, avg_loss=0.09344, mel_loss=0.04302, linear_loss=0.05234]
[2020-05-12 01:16:37.747]  Step 149471  [3.276 sec/step, loss=0.09037, avg_loss=0.09325, mel_loss=0.04011, linear_loss=0.05026]
[2020-05-12 01:16:41.197]  Step 149472  [3.289 sec/step, loss=0.09676, avg_loss=0.09326, mel_loss=0.04406, linear_loss=0.05269]
[2020-05-12 01:16:53.281]  Step 149473  [3.353 sec/step, loss=0.08827, avg_loss=0.09312, mel_loss=0.04229, linear_loss=0.04598]
[2020-05-12 01:16:54.304]  Step 149474  [3.348 sec/step, loss=0.08130, avg_loss=0.09302, mel_loss=0.03529, linear_loss=0.04600]
[2020-05-12 01:16:56.740]  Step 149475  [3.362 sec/step, loss=0.09299, avg_loss=0.09312, mel_loss=0.04160, linear_loss=0.05138]
[2020-05-12 01:16:58.460]  Step 149476  [3.336 sec/step, loss=0.09164, avg_loss=0.09298, mel_loss=0.03995, linear_loss=0.05169]
[2020-05-12 01:17:05.206]  Step 149477  [3.261 sec/step, loss=0.09743, avg_loss=0.09307, mel_loss=0.04517, linear_loss=0.05226]
[2020-05-12 01:17:10.260]  Step 149478  [3.292 sec/step, loss=0.09691, avg_loss=0.09314, mel_loss=0.04449, linear_loss=0.05242]
[2020-05-12 01:17:18.796]  Step 149479  [3.358 sec/step, loss=0.09869, avg_loss=0.09325, mel_loss=0.04628, linear_loss=0.05241]
[2020-05-12 01:17:21.938]  Step 149480  [3.372 sec/step, loss=0.09888, avg_loss=0.09336, mel_loss=0.04449, linear_loss=0.05439]
[2020-05-12 01:17:24.221]  Step 149481  [3.350 sec/step, loss=0.09267, avg_loss=0.09329, mel_loss=0.04161, linear_loss=0.05106]
[2020-05-12 01:17:25.399]  Step 149482  [3.324 sec/step, loss=0.08599, avg_loss=0.09320, mel_loss=0.03763, linear_loss=0.04835]
[2020-05-12 01:17:40.201]  Step 149483  [3.442 sec/step, loss=0.07859, avg_loss=0.09303, mel_loss=0.03770, linear_loss=0.04089]
[2020-05-12 01:17:48.170]  Step 149484  [3.511 sec/step, loss=0.10137, avg_loss=0.09319, mel_loss=0.04743, linear_loss=0.05395]
[2020-05-12 01:17:51.959]  Step 149485  [3.539 sec/step, loss=0.09719, avg_loss=0.09331, mel_loss=0.04399, linear_loss=0.05320]
[2020-05-12 01:17:55.238]  Step 149486  [3.563 sec/step, loss=0.09719, avg_loss=0.09349, mel_loss=0.04371, linear_loss=0.05348]
[2020-05-12 01:17:59.831]  Step 149487  [3.560 sec/step, loss=0.09862, avg_loss=0.09344, mel_loss=0.04486, linear_loss=0.05376]
[2020-05-12 01:18:01.601]  Step 149488  [3.566 sec/step, loss=0.09419, avg_loss=0.09349, mel_loss=0.04171, linear_loss=0.05247]
[2020-05-12 01:18:02.708]  Step 149489  [3.546 sec/step, loss=0.08077, avg_loss=0.09329, mel_loss=0.03564, linear_loss=0.04512]
[2020-05-12 01:18:05.866]  Step 149490  [3.564 sec/step, loss=0.09551, avg_loss=0.09335, mel_loss=0.04328, linear_loss=0.05223]
[2020-05-12 01:18:07.909]  Step 149491  [3.543 sec/step, loss=0.09322, avg_loss=0.09329, mel_loss=0.04110, linear_loss=0.05212]
[2020-05-12 01:18:12.610]  Step 149492  [3.574 sec/step, loss=0.09710, avg_loss=0.09333, mel_loss=0.04440, linear_loss=0.05270]
[2020-05-12 01:18:18.223]  Step 149493  [3.600 sec/step, loss=0.09980, avg_loss=0.09335, mel_loss=0.04606, linear_loss=0.05374]
[2020-05-12 01:18:19.371]  Step 149494  [3.596 sec/step, loss=0.08609, avg_loss=0.09331, mel_loss=0.03787, linear_loss=0.04822]
[2020-05-12 01:18:20.771]  Step 149495  [3.593 sec/step, loss=0.08855, avg_loss=0.09327, mel_loss=0.03900, linear_loss=0.04955]
[2020-05-12 01:18:21.534]  Step 149496  [3.581 sec/step, loss=0.07900, avg_loss=0.09314, mel_loss=0.03462, linear_loss=0.04438]
[2020-05-12 01:18:25.271]  Step 149497  [3.590 sec/step, loss=0.09757, avg_loss=0.09314, mel_loss=0.04433, linear_loss=0.05324]
[2020-05-12 01:18:27.042]  Generated 32 batches of size 32 in 1.765 sec
[2020-05-12 01:18:27.374]  Step 149498  [3.554 sec/step, loss=0.09709, avg_loss=0.09309, mel_loss=0.04341, linear_loss=0.05367]
[2020-05-12 01:18:29.000]  Step 149499  [3.534 sec/step, loss=0.09024, avg_loss=0.09298, mel_loss=0.04026, linear_loss=0.04998]
[2020-05-12 01:18:31.701]  Step 149500  [3.525 sec/step, loss=0.09431, avg_loss=0.09294, mel_loss=0.04215, linear_loss=0.05216]
[2020-05-12 01:18:31.701]  Writing summary at step: 149500
[2020-05-12 01:18:33.853]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149500
[2020-05-12 01:18:35.298]  Saving audio and alignment...
[2020-05-12 01:18:37.257]  Input: 끝이 없다~____________
[2020-05-12 01:18:37.819]  Step 149501  [3.519 sec/step, loss=0.07431, avg_loss=0.09283, mel_loss=0.03319, linear_loss=0.04112]
[2020-05-12 01:18:41.282]  Step 149502  [3.534 sec/step, loss=0.09610, avg_loss=0.09286, mel_loss=0.04342, linear_loss=0.05268]
[2020-05-12 01:18:42.093]  Step 149503  [3.520 sec/step, loss=0.07819, avg_loss=0.09270, mel_loss=0.03384, linear_loss=0.04436]
[2020-05-12 01:18:43.441]  Step 149504  [3.416 sec/step, loss=0.08538, avg_loss=0.09258, mel_loss=0.03766, linear_loss=0.04772]
[2020-05-12 01:18:44.558]  Step 149505  [3.355 sec/step, loss=0.08469, avg_loss=0.09242, mel_loss=0.03676, linear_loss=0.04794]
[2020-05-12 01:18:48.698]  Step 149506  [3.331 sec/step, loss=0.09668, avg_loss=0.09239, mel_loss=0.04369, linear_loss=0.05300]
[2020-05-12 01:18:55.132]  Step 149507  [3.358 sec/step, loss=0.09987, avg_loss=0.09237, mel_loss=0.04622, linear_loss=0.05365]
[2020-05-12 01:18:57.317]  Step 149508  [3.373 sec/step, loss=0.09303, avg_loss=0.09250, mel_loss=0.04147, linear_loss=0.05156]
[2020-05-12 01:18:58.388]  Step 149509  [3.369 sec/step, loss=0.08145, avg_loss=0.09240, mel_loss=0.03587, linear_loss=0.04557]
[2020-05-12 01:19:01.707]  Step 149510  [3.376 sec/step, loss=0.09641, avg_loss=0.09242, mel_loss=0.04365, linear_loss=0.05276]
[2020-05-12 01:19:03.075]  Step 149511  [3.371 sec/step, loss=0.08727, avg_loss=0.09236, mel_loss=0.03858, linear_loss=0.04869]
[2020-05-12 01:19:04.976]  Step 149512  [3.304 sec/step, loss=0.08920, avg_loss=0.09221, mel_loss=0.03919, linear_loss=0.05001]
[2020-05-12 01:19:05.815]  Step 149513  [3.292 sec/step, loss=0.07680, avg_loss=0.09203, mel_loss=0.03347, linear_loss=0.04333]
[2020-05-12 01:19:13.434]  Step 149514  [3.357 sec/step, loss=0.09968, avg_loss=0.09215, mel_loss=0.04641, linear_loss=0.05328]
[2020-05-12 01:19:16.458]  Step 149515  [3.377 sec/step, loss=0.09804, avg_loss=0.09229, mel_loss=0.04429, linear_loss=0.05376]
[2020-05-12 01:19:17.627]  Step 149516  [3.314 sec/step, loss=0.08784, avg_loss=0.09214, mel_loss=0.03853, linear_loss=0.04931]
[2020-05-12 01:19:31.245]  Step 149517  [3.442 sec/step, loss=0.08426, avg_loss=0.09220, mel_loss=0.04005, linear_loss=0.04420]
[2020-05-12 01:19:32.068]  Step 149518  [3.419 sec/step, loss=0.07981, avg_loss=0.09200, mel_loss=0.03433, linear_loss=0.04548]
[2020-05-12 01:19:32.683]  Step 149519  [3.372 sec/step, loss=0.07036, avg_loss=0.09169, mel_loss=0.03141, linear_loss=0.03895]
[2020-05-12 01:19:36.431]  Step 149520  [3.381 sec/step, loss=0.09898, avg_loss=0.09169, mel_loss=0.04502, linear_loss=0.05396]
[2020-05-12 01:19:38.406]  Step 149521  [3.359 sec/step, loss=0.09188, avg_loss=0.09161, mel_loss=0.04074, linear_loss=0.05114]
[2020-05-12 01:19:39.891]  Step 149522  [3.339 sec/step, loss=0.09001, avg_loss=0.09152, mel_loss=0.03963, linear_loss=0.05038]
[2020-05-12 01:19:48.855]  Step 149523  [3.420 sec/step, loss=0.09736, avg_loss=0.09164, mel_loss=0.04564, linear_loss=0.05172]
[2020-05-12 01:19:49.712]  Step 149524  [3.383 sec/step, loss=0.07921, avg_loss=0.09143, mel_loss=0.03404, linear_loss=0.04517]
[2020-05-12 01:19:51.972]  Step 149525  [3.386 sec/step, loss=0.09308, avg_loss=0.09143, mel_loss=0.04156, linear_loss=0.05153]
[2020-05-12 01:19:54.616]  Step 149526  [3.346 sec/step, loss=0.09496, avg_loss=0.09137, mel_loss=0.04283, linear_loss=0.05213]
[2020-05-12 01:19:56.374]  Step 149527  [3.340 sec/step, loss=0.09120, avg_loss=0.09134, mel_loss=0.04027, linear_loss=0.05093]
[2020-05-12 01:19:57.798]  Step 149528  [3.341 sec/step, loss=0.08642, avg_loss=0.09131, mel_loss=0.03806, linear_loss=0.04837]
[2020-05-12 01:19:58.049]  Generated 32 batches of size 32 in 1.670 sec
[2020-05-12 01:20:00.714]  Step 149529  [3.365 sec/step, loss=0.09572, avg_loss=0.09154, mel_loss=0.04274, linear_loss=0.05298]
[2020-05-12 01:20:04.878]  Step 149530  [3.391 sec/step, loss=0.09778, avg_loss=0.09160, mel_loss=0.04471, linear_loss=0.05307]
[2020-05-12 01:20:10.134]  Step 149531  [3.353 sec/step, loss=0.09901, avg_loss=0.09162, mel_loss=0.04557, linear_loss=0.05345]
[2020-05-12 01:20:12.592]  Step 149532  [3.333 sec/step, loss=0.09251, avg_loss=0.09154, mel_loss=0.04125, linear_loss=0.05126]
[2020-05-12 01:20:18.155]  Step 149533  [3.333 sec/step, loss=0.09885, avg_loss=0.09153, mel_loss=0.04541, linear_loss=0.05344]
[2020-05-12 01:20:19.847]  Step 149534  [3.321 sec/step, loss=0.08964, avg_loss=0.09149, mel_loss=0.03983, linear_loss=0.04981]
[2020-05-12 01:20:24.533]  Step 149535  [3.331 sec/step, loss=0.09887, avg_loss=0.09148, mel_loss=0.04502, linear_loss=0.05385]
[2020-05-12 01:20:27.996]  Step 149536  [3.347 sec/step, loss=0.09485, avg_loss=0.09153, mel_loss=0.04278, linear_loss=0.05207]
[2020-05-12 01:20:29.867]  Step 149537  [3.341 sec/step, loss=0.08878, avg_loss=0.09147, mel_loss=0.03926, linear_loss=0.04952]
[2020-05-12 01:20:32.715]  Step 149538  [3.362 sec/step, loss=0.09584, avg_loss=0.09160, mel_loss=0.04310, linear_loss=0.05274]
[2020-05-12 01:20:35.071]  Step 149539  [3.373 sec/step, loss=0.09390, avg_loss=0.09166, mel_loss=0.04184, linear_loss=0.05206]
[2020-05-12 01:20:39.111]  Step 149540  [3.268 sec/step, loss=0.09930, avg_loss=0.09185, mel_loss=0.04523, linear_loss=0.05407]
[2020-05-12 01:20:40.711]  Step 149541  [3.272 sec/step, loss=0.08970, avg_loss=0.09187, mel_loss=0.03936, linear_loss=0.05033]
[2020-05-12 01:20:41.669]  Step 149542  [3.247 sec/step, loss=0.08556, avg_loss=0.09176, mel_loss=0.03681, linear_loss=0.04875]
[2020-05-12 01:20:44.085]  Step 149543  [3.254 sec/step, loss=0.09383, avg_loss=0.09178, mel_loss=0.04194, linear_loss=0.05189]
[2020-05-12 01:20:47.461]  Step 149544  [3.267 sec/step, loss=0.09651, avg_loss=0.09180, mel_loss=0.04339, linear_loss=0.05312]
[2020-05-12 01:20:49.998]  Step 149545  [3.227 sec/step, loss=0.09451, avg_loss=0.09175, mel_loss=0.04210, linear_loss=0.05241]
[2020-05-12 01:20:51.989]  Step 149546  [3.160 sec/step, loss=0.09314, avg_loss=0.09171, mel_loss=0.04160, linear_loss=0.05154]
[2020-05-12 01:21:04.326]  Step 149547  [3.241 sec/step, loss=0.08979, avg_loss=0.09161, mel_loss=0.04285, linear_loss=0.04693]
[2020-05-12 01:21:12.933]  Step 149548  [3.293 sec/step, loss=0.09750, avg_loss=0.09161, mel_loss=0.04554, linear_loss=0.05196]
[2020-05-12 01:21:13.760]  Step 149549  [3.269 sec/step, loss=0.07716, avg_loss=0.09139, mel_loss=0.03347, linear_loss=0.04369]
[2020-05-12 01:21:14.559]  Step 149550  [3.255 sec/step, loss=0.07741, avg_loss=0.09124, mel_loss=0.03381, linear_loss=0.04360]
[2020-05-12 01:21:14.559]  Writing summary at step: 149550
[2020-05-12 01:21:15.089]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149550
[2020-05-12 01:21:16.522]  Saving audio and alignment...
[2020-05-12 01:21:25.246]  Input: 이런 데서 방송 경력이 있는 사람들과 그렇지 않은 초보 준비생들에 차이가 드러나게 되니까요~_________
[2020-05-12 01:21:26.973]  Step 149551  [3.248 sec/step, loss=0.08781, avg_loss=0.09118, mel_loss=0.03864, linear_loss=0.04916]
[2020-05-12 01:21:30.032]  Step 149552  [3.259 sec/step, loss=0.09537, avg_loss=0.09121, mel_loss=0.04300, linear_loss=0.05237]
[2020-05-12 01:21:33.813]  Step 149553  [3.287 sec/step, loss=0.09926, avg_loss=0.09137, mel_loss=0.04488, linear_loss=0.05438]
[2020-05-12 01:21:34.789]  Step 149554  [3.284 sec/step, loss=0.08313, avg_loss=0.09136, mel_loss=0.03607, linear_loss=0.04705]
[2020-05-12 01:21:35.923]  Step 149555  [3.279 sec/step, loss=0.08363, avg_loss=0.09131, mel_loss=0.03616, linear_loss=0.04747]
[2020-05-12 01:21:41.021]  Step 149556  [3.313 sec/step, loss=0.09826, avg_loss=0.09138, mel_loss=0.04461, linear_loss=0.05365]
[2020-05-12 01:21:48.655]  Step 149557  [3.352 sec/step, loss=0.09765, avg_loss=0.09136, mel_loss=0.04450, linear_loss=0.05315]
[2020-05-12 01:21:50.856]  Step 149558  [3.360 sec/step, loss=0.08800, avg_loss=0.09137, mel_loss=0.03845, linear_loss=0.04955]
[2020-05-12 01:21:51.842]  Generated 32 batches of size 32 in 3.179 sec
[2020-05-12 01:21:58.788]  Step 149559  [3.429 sec/step, loss=0.09922, avg_loss=0.09151, mel_loss=0.04607, linear_loss=0.05315]
[2020-05-12 01:22:00.334]  Step 149560  [3.414 sec/step, loss=0.08864, avg_loss=0.09142, mel_loss=0.03899, linear_loss=0.04964]
[2020-05-12 01:22:01.664]  Step 149561  [3.370 sec/step, loss=0.08449, avg_loss=0.09127, mel_loss=0.03706, linear_loss=0.04744]
[2020-05-12 01:22:03.830]  Step 149562  [3.351 sec/step, loss=0.09217, avg_loss=0.09122, mel_loss=0.04109, linear_loss=0.05109]
[2020-05-12 01:22:07.192]  Step 149563  [3.377 sec/step, loss=0.09683, avg_loss=0.09139, mel_loss=0.04392, linear_loss=0.05291]
[2020-05-12 01:22:08.221]  Step 149564  [3.373 sec/step, loss=0.08421, avg_loss=0.09136, mel_loss=0.03682, linear_loss=0.04739]
[2020-05-12 01:22:13.700]  Step 149565  [3.407 sec/step, loss=0.09976, avg_loss=0.09143, mel_loss=0.04559, linear_loss=0.05417]
[2020-05-12 01:22:18.260]  Step 149566  [3.398 sec/step, loss=0.10104, avg_loss=0.09144, mel_loss=0.04644, linear_loss=0.05461]
[2020-05-12 01:22:21.151]  Step 149567  [3.351 sec/step, loss=0.09374, avg_loss=0.09137, mel_loss=0.04196, linear_loss=0.05178]
[2020-05-12 01:22:22.589]  Step 149568  [3.340 sec/step, loss=0.08715, avg_loss=0.09130, mel_loss=0.03842, linear_loss=0.04873]
[2020-05-12 01:22:23.723]  Step 149569  [3.343 sec/step, loss=0.08455, avg_loss=0.09141, mel_loss=0.03686, linear_loss=0.04769]
[2020-05-12 01:22:38.542]  Step 149570  [3.463 sec/step, loss=0.07815, avg_loss=0.09124, mel_loss=0.03734, linear_loss=0.04081]
[2020-05-12 01:22:44.244]  Step 149571  [3.502 sec/step, loss=0.09761, avg_loss=0.09131, mel_loss=0.04503, linear_loss=0.05258]
[2020-05-12 01:22:46.036]  Step 149572  [3.486 sec/step, loss=0.09165, avg_loss=0.09126, mel_loss=0.04031, linear_loss=0.05133]
[2020-05-12 01:22:50.038]  Step 149573  [3.405 sec/step, loss=0.09839, avg_loss=0.09136, mel_loss=0.04457, linear_loss=0.05382]
[2020-05-12 01:22:53.389]  Step 149574  [3.428 sec/step, loss=0.09832, avg_loss=0.09153, mel_loss=0.04455, linear_loss=0.05377]
[2020-05-12 01:22:53.941]  Step 149575  [3.409 sec/step, loss=0.07373, avg_loss=0.09134, mel_loss=0.03313, linear_loss=0.04061]
[2020-05-12 01:22:54.837]  Step 149576  [3.401 sec/step, loss=0.08336, avg_loss=0.09126, mel_loss=0.03606, linear_loss=0.04730]
[2020-05-12 01:22:55.626]  Step 149577  [3.342 sec/step, loss=0.07671, avg_loss=0.09105, mel_loss=0.03334, linear_loss=0.04337]
[2020-05-12 01:23:02.222]  Step 149578  [3.357 sec/step, loss=0.09932, avg_loss=0.09107, mel_loss=0.04597, linear_loss=0.05335]
[2020-05-12 01:23:03.268]  Step 149579  [3.282 sec/step, loss=0.08129, avg_loss=0.09090, mel_loss=0.03551, linear_loss=0.04578]
[2020-05-12 01:23:10.691]  Step 149580  [3.325 sec/step, loss=0.09961, avg_loss=0.09091, mel_loss=0.04640, linear_loss=0.05321]
[2020-05-12 01:23:12.623]  Step 149581  [3.321 sec/step, loss=0.09140, avg_loss=0.09089, mel_loss=0.04034, linear_loss=0.05107]
[2020-05-12 01:23:17.204]  Step 149582  [3.355 sec/step, loss=0.09839, avg_loss=0.09102, mel_loss=0.04477, linear_loss=0.05362]
[2020-05-12 01:23:22.495]  Step 149583  [3.260 sec/step, loss=0.09849, avg_loss=0.09122, mel_loss=0.04541, linear_loss=0.05308]
[2020-05-12 01:23:24.509]  Step 149584  [3.201 sec/step, loss=0.09202, avg_loss=0.09112, mel_loss=0.04093, linear_loss=0.05109]
[2020-05-12 01:23:27.571]  Step 149585  [3.193 sec/step, loss=0.09652, avg_loss=0.09112, mel_loss=0.04339, linear_loss=0.05313]
[2020-05-12 01:23:36.372]  Step 149586  [3.249 sec/step, loss=0.09664, avg_loss=0.09111, mel_loss=0.04517, linear_loss=0.05147]
[2020-05-12 01:23:38.755]  Step 149587  [3.227 sec/step, loss=0.09278, avg_loss=0.09105, mel_loss=0.04139, linear_loss=0.05139]
[2020-05-12 01:23:42.358]  Step 149588  [3.245 sec/step, loss=0.09799, avg_loss=0.09109, mel_loss=0.04428, linear_loss=0.05371]
[2020-05-12 01:23:44.493]  Step 149589  [3.255 sec/step, loss=0.09359, avg_loss=0.09122, mel_loss=0.04176, linear_loss=0.05183]
[2020-05-12 01:23:46.236]  Generated 32 batches of size 32 in 1.737 sec
[2020-05-12 01:23:47.295]  Step 149590  [3.252 sec/step, loss=0.09469, avg_loss=0.09121, mel_loss=0.04291, linear_loss=0.05178]
[2020-05-12 01:23:49.803]  Step 149591  [3.256 sec/step, loss=0.09098, avg_loss=0.09119, mel_loss=0.04035, linear_loss=0.05064]
[2020-05-12 01:23:51.014]  Step 149592  [3.221 sec/step, loss=0.08522, avg_loss=0.09107, mel_loss=0.03732, linear_loss=0.04791]
[2020-05-12 01:23:54.451]  Step 149593  [3.200 sec/step, loss=0.09532, avg_loss=0.09103, mel_loss=0.04296, linear_loss=0.05236]
[2020-05-12 01:23:56.160]  Step 149594  [3.205 sec/step, loss=0.09211, avg_loss=0.09109, mel_loss=0.04055, linear_loss=0.05157]
[2020-05-12 01:23:56.954]  Step 149595  [3.199 sec/step, loss=0.07980, avg_loss=0.09100, mel_loss=0.03453, linear_loss=0.04527]
[2020-05-12 01:23:58.493]  Step 149596  [3.207 sec/step, loss=0.08995, avg_loss=0.09111, mel_loss=0.03963, linear_loss=0.05031]
[2020-05-12 01:24:02.771]  Step 149597  [3.212 sec/step, loss=0.09700, avg_loss=0.09110, mel_loss=0.04405, linear_loss=0.05294]
[2020-05-12 01:24:04.142]  Step 149598  [3.205 sec/step, loss=0.08682, avg_loss=0.09100, mel_loss=0.03849, linear_loss=0.04833]
[2020-05-12 01:24:05.036]  Step 149599  [3.198 sec/step, loss=0.08157, avg_loss=0.09091, mel_loss=0.03534, linear_loss=0.04623]
[2020-05-12 01:24:09.881]  Step 149600  [3.219 sec/step, loss=0.09709, avg_loss=0.09094, mel_loss=0.04422, linear_loss=0.05287]
[2020-05-12 01:24:09.882]  Writing summary at step: 149600
[2020-05-12 01:24:11.379]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149600
[2020-05-12 01:24:12.822]  Saving audio and alignment...
[2020-05-12 01:24:15.756]  Input: 나는 코멘트가 없다~_____________________
[2020-05-12 01:24:19.444]  Step 149601  [3.250 sec/step, loss=0.09728, avg_loss=0.09117, mel_loss=0.04409, linear_loss=0.05319]
[2020-05-12 01:24:20.829]  Step 149602  [3.230 sec/step, loss=0.08802, avg_loss=0.09109, mel_loss=0.03867, linear_loss=0.04935]
[2020-05-12 01:24:23.610]  Step 149603  [3.249 sec/step, loss=0.09401, avg_loss=0.09125, mel_loss=0.04222, linear_loss=0.05179]
[2020-05-12 01:24:27.015]  Step 149604  [3.270 sec/step, loss=0.09869, avg_loss=0.09138, mel_loss=0.04465, linear_loss=0.05404]
[2020-05-12 01:24:29.542]  Step 149605  [3.284 sec/step, loss=0.09302, avg_loss=0.09146, mel_loss=0.04147, linear_loss=0.05155]
[2020-05-12 01:24:30.335]  Step 149606  [3.251 sec/step, loss=0.07593, avg_loss=0.09126, mel_loss=0.03239, linear_loss=0.04354]
[2020-05-12 01:24:43.714]  Step 149607  [3.320 sec/step, loss=0.07942, avg_loss=0.09105, mel_loss=0.03751, linear_loss=0.04192]
[2020-05-12 01:24:45.116]  Step 149608  [3.312 sec/step, loss=0.08660, avg_loss=0.09099, mel_loss=0.03783, linear_loss=0.04877]
[2020-05-12 01:24:49.303]  Step 149609  [3.343 sec/step, loss=0.09560, avg_loss=0.09113, mel_loss=0.04327, linear_loss=0.05232]
[2020-05-12 01:24:56.150]  Step 149610  [3.379 sec/step, loss=0.09960, avg_loss=0.09116, mel_loss=0.04609, linear_loss=0.05351]
[2020-05-12 01:24:57.867]  Step 149611  [3.382 sec/step, loss=0.09167, avg_loss=0.09121, mel_loss=0.04049, linear_loss=0.05118]
[2020-05-12 01:25:05.793]  Step 149612  [3.442 sec/step, loss=0.09919, avg_loss=0.09131, mel_loss=0.04597, linear_loss=0.05322]
[2020-05-12 01:25:06.315]  Step 149613  [3.439 sec/step, loss=0.07543, avg_loss=0.09129, mel_loss=0.03338, linear_loss=0.04206]
[2020-05-12 01:25:09.711]  Step 149614  [3.397 sec/step, loss=0.09562, avg_loss=0.09125, mel_loss=0.04314, linear_loss=0.05247]
[2020-05-12 01:25:11.643]  Step 149615  [3.386 sec/step, loss=0.09274, avg_loss=0.09120, mel_loss=0.04117, linear_loss=0.05156]
[2020-05-12 01:25:14.565]  Step 149616  [3.404 sec/step, loss=0.09604, avg_loss=0.09128, mel_loss=0.04296, linear_loss=0.05308]
[2020-05-12 01:25:15.617]  Step 149617  [3.278 sec/step, loss=0.08505, avg_loss=0.09129, mel_loss=0.03699, linear_loss=0.04807]
[2020-05-12 01:25:18.913]  Step 149618  [3.303 sec/step, loss=0.09779, avg_loss=0.09147, mel_loss=0.04400, linear_loss=0.05379]
[2020-05-12 01:25:24.304]  Step 149619  [3.350 sec/step, loss=0.09839, avg_loss=0.09175, mel_loss=0.04510, linear_loss=0.05329]
[2020-05-12 01:25:24.951]  Step 149620  [3.319 sec/step, loss=0.07698, avg_loss=0.09153, mel_loss=0.03408, linear_loss=0.04290]
[2020-05-12 01:25:26.137]  Generated 32 batches of size 32 in 1.827 sec
[2020-05-12 01:25:26.787]  Step 149621  [3.318 sec/step, loss=0.09087, avg_loss=0.09152, mel_loss=0.04020, linear_loss=0.05067]
[2020-05-12 01:25:28.862]  Step 149622  [3.324 sec/step, loss=0.09245, avg_loss=0.09154, mel_loss=0.04094, linear_loss=0.05151]
[2020-05-12 01:25:31.021]  Step 149623  [3.256 sec/step, loss=0.09263, avg_loss=0.09149, mel_loss=0.04119, linear_loss=0.05144]
[2020-05-12 01:25:36.686]  Step 149624  [3.304 sec/step, loss=0.10016, avg_loss=0.09170, mel_loss=0.04647, linear_loss=0.05369]
[2020-05-12 01:25:37.843]  Step 149625  [3.293 sec/step, loss=0.08613, avg_loss=0.09163, mel_loss=0.03754, linear_loss=0.04859]
[2020-05-12 01:25:40.196]  Step 149626  [3.290 sec/step, loss=0.09469, avg_loss=0.09163, mel_loss=0.04201, linear_loss=0.05268]
[2020-05-12 01:25:41.201]  Step 149627  [3.282 sec/step, loss=0.08366, avg_loss=0.09156, mel_loss=0.03663, linear_loss=0.04703]
[2020-05-12 01:25:45.573]  Step 149628  [3.312 sec/step, loss=0.10080, avg_loss=0.09170, mel_loss=0.04635, linear_loss=0.05445]
[2020-05-12 01:25:47.181]  Step 149629  [3.299 sec/step, loss=0.08835, avg_loss=0.09163, mel_loss=0.03912, linear_loss=0.04923]
[2020-05-12 01:25:49.119]  Step 149630  [3.277 sec/step, loss=0.09043, avg_loss=0.09155, mel_loss=0.03996, linear_loss=0.05047]
[2020-05-12 01:25:50.748]  Step 149631  [3.240 sec/step, loss=0.09031, avg_loss=0.09147, mel_loss=0.03979, linear_loss=0.05052]
[2020-05-12 01:25:51.964]  Step 149632  [3.228 sec/step, loss=0.08639, avg_loss=0.09141, mel_loss=0.03801, linear_loss=0.04839]
[2020-05-12 01:25:53.958]  Step 149633  [3.192 sec/step, loss=0.09238, avg_loss=0.09134, mel_loss=0.04098, linear_loss=0.05140]
[2020-05-12 01:25:55.328]  Step 149634  [3.189 sec/step, loss=0.08678, avg_loss=0.09131, mel_loss=0.03807, linear_loss=0.04871]
[2020-05-12 01:25:56.301]  Step 149635  [3.152 sec/step, loss=0.08584, avg_loss=0.09118, mel_loss=0.03727, linear_loss=0.04857]
[2020-05-12 01:26:00.965]  Step 149636  [3.164 sec/step, loss=0.09846, avg_loss=0.09122, mel_loss=0.04488, linear_loss=0.05359]
[2020-05-12 01:26:03.880]  Step 149637  [3.174 sec/step, loss=0.09731, avg_loss=0.09130, mel_loss=0.04378, linear_loss=0.05353]
[2020-05-12 01:26:09.012]  Step 149638  [3.197 sec/step, loss=0.09983, avg_loss=0.09134, mel_loss=0.04591, linear_loss=0.05392]
[2020-05-12 01:26:11.560]  Step 149639  [3.199 sec/step, loss=0.09292, avg_loss=0.09133, mel_loss=0.04132, linear_loss=0.05160]
[2020-05-12 01:26:12.131]  Step 149640  [3.164 sec/step, loss=0.07406, avg_loss=0.09108, mel_loss=0.03328, linear_loss=0.04078]
[2020-05-12 01:26:14.841]  Step 149641  [3.175 sec/step, loss=0.09396, avg_loss=0.09112, mel_loss=0.04213, linear_loss=0.05183]
[2020-05-12 01:26:20.633]  Step 149642  [3.224 sec/step, loss=0.09968, avg_loss=0.09126, mel_loss=0.04561, linear_loss=0.05407]
[2020-05-12 01:26:23.931]  Step 149643  [3.233 sec/step, loss=0.09642, avg_loss=0.09129, mel_loss=0.04356, linear_loss=0.05285]
[2020-05-12 01:26:31.719]  Step 149644  [3.277 sec/step, loss=0.09920, avg_loss=0.09132, mel_loss=0.04612, linear_loss=0.05309]
[2020-05-12 01:26:33.916]  Step 149645  [3.273 sec/step, loss=0.09272, avg_loss=0.09130, mel_loss=0.04132, linear_loss=0.05140]
[2020-05-12 01:26:37.056]  Step 149646  [3.285 sec/step, loss=0.09590, avg_loss=0.09133, mel_loss=0.04317, linear_loss=0.05273]
[2020-05-12 01:26:43.817]  Step 149647  [3.229 sec/step, loss=0.09988, avg_loss=0.09143, mel_loss=0.04629, linear_loss=0.05359]
[2020-05-12 01:26:44.695]  Step 149648  [3.152 sec/step, loss=0.07347, avg_loss=0.09119, mel_loss=0.03188, linear_loss=0.04159]
[2020-05-12 01:26:58.778]  Step 149649  [3.284 sec/step, loss=0.07815, avg_loss=0.09120, mel_loss=0.03745, linear_loss=0.04071]
[2020-05-12 01:27:03.135]  Step 149650  [3.320 sec/step, loss=0.09755, avg_loss=0.09140, mel_loss=0.04446, linear_loss=0.05309]
[2020-05-12 01:27:03.135]  Writing summary at step: 149650
[2020-05-12 01:27:06.591]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149650
[2020-05-12 01:27:08.062]  Saving audio and alignment...
[2020-05-12 01:27:10.199]  Generated 32 batches of size 32 in 1.582 sec
[2020-05-12 01:27:10.576]  Input: 소통입니다~____________________
[2020-05-12 01:27:19.583]  Step 149651  [3.393 sec/step, loss=0.09784, avg_loss=0.09150, mel_loss=0.04587, linear_loss=0.05198]
[2020-05-12 01:27:21.359]  Step 149652  [3.380 sec/step, loss=0.09113, avg_loss=0.09146, mel_loss=0.04011, linear_loss=0.05102]
[2020-05-12 01:27:22.456]  Step 149653  [3.353 sec/step, loss=0.08400, avg_loss=0.09130, mel_loss=0.03620, linear_loss=0.04780]
[2020-05-12 01:27:26.332]  Step 149654  [3.382 sec/step, loss=0.09649, avg_loss=0.09144, mel_loss=0.04363, linear_loss=0.05286]
[2020-05-12 01:27:27.128]  Step 149655  [3.379 sec/step, loss=0.07866, avg_loss=0.09139, mel_loss=0.03422, linear_loss=0.04444]
[2020-05-12 01:27:29.486]  Step 149656  [3.351 sec/step, loss=0.09137, avg_loss=0.09132, mel_loss=0.04071, linear_loss=0.05066]
[2020-05-12 01:27:33.128]  Step 149657  [3.311 sec/step, loss=0.09904, avg_loss=0.09133, mel_loss=0.04496, linear_loss=0.05408]
[2020-05-12 01:27:34.442]  Step 149658  [3.302 sec/step, loss=0.08637, avg_loss=0.09132, mel_loss=0.03772, linear_loss=0.04865]
[2020-05-12 01:27:38.173]  Step 149659  [3.260 sec/step, loss=0.09737, avg_loss=0.09130, mel_loss=0.04382, linear_loss=0.05355]
[2020-05-12 01:27:39.005]  Step 149660  [3.253 sec/step, loss=0.07306, avg_loss=0.09114, mel_loss=0.03177, linear_loss=0.04129]
[2020-05-12 01:27:43.216]  Step 149661  [3.282 sec/step, loss=0.09526, avg_loss=0.09125, mel_loss=0.04305, linear_loss=0.05221]
[2020-05-12 01:27:46.647]  Step 149662  [3.295 sec/step, loss=0.09425, avg_loss=0.09127, mel_loss=0.04266, linear_loss=0.05159]
[2020-05-12 01:27:47.894]  Step 149663  [3.274 sec/step, loss=0.08376, avg_loss=0.09114, mel_loss=0.03667, linear_loss=0.04709]
[2020-05-12 01:27:50.282]  Step 149664  [3.287 sec/step, loss=0.09335, avg_loss=0.09123, mel_loss=0.04165, linear_loss=0.05170]
[2020-05-12 01:27:53.099]  Step 149665  [3.261 sec/step, loss=0.09500, avg_loss=0.09118, mel_loss=0.04280, linear_loss=0.05220]
[2020-05-12 01:27:54.095]  Step 149666  [3.225 sec/step, loss=0.08022, avg_loss=0.09098, mel_loss=0.03482, linear_loss=0.04539]
[2020-05-12 01:27:55.893]  Step 149667  [3.214 sec/step, loss=0.08969, avg_loss=0.09094, mel_loss=0.03969, linear_loss=0.05000]
[2020-05-12 01:27:56.985]  Step 149668  [3.211 sec/step, loss=0.08554, avg_loss=0.09092, mel_loss=0.03713, linear_loss=0.04841]
[2020-05-12 01:27:59.001]  Step 149669  [3.219 sec/step, loss=0.09160, avg_loss=0.09099, mel_loss=0.04092, linear_loss=0.05069]
[2020-05-12 01:28:03.811]  Step 149670  [3.119 sec/step, loss=0.09828, avg_loss=0.09119, mel_loss=0.04500, linear_loss=0.05328]
[2020-05-12 01:28:05.195]  Step 149671  [3.076 sec/step, loss=0.08647, avg_loss=0.09108, mel_loss=0.03786, linear_loss=0.04861]
[2020-05-12 01:28:08.183]  Step 149672  [3.088 sec/step, loss=0.09462, avg_loss=0.09111, mel_loss=0.04256, linear_loss=0.05206]
[2020-05-12 01:28:12.740]  Step 149673  [3.094 sec/step, loss=0.09761, avg_loss=0.09110, mel_loss=0.04447, linear_loss=0.05313]
[2020-05-12 01:28:15.445]  Step 149674  [3.087 sec/step, loss=0.09212, avg_loss=0.09104, mel_loss=0.04104, linear_loss=0.05108]
[2020-05-12 01:28:29.764]  Step 149675  [3.225 sec/step, loss=0.08052, avg_loss=0.09111, mel_loss=0.03853, linear_loss=0.04199]
[2020-05-12 01:28:35.585]  Step 149676  [3.274 sec/step, loss=0.09922, avg_loss=0.09127, mel_loss=0.04581, linear_loss=0.05341]
[2020-05-12 01:28:36.974]  Step 149677  [3.280 sec/step, loss=0.08552, avg_loss=0.09135, mel_loss=0.03755, linear_loss=0.04797]
[2020-05-12 01:28:37.543]  Step 149678  [3.220 sec/step, loss=0.07339, avg_loss=0.09110, mel_loss=0.03256, linear_loss=0.04083]
[2020-05-12 01:28:39.204]  Step 149679  [3.226 sec/step, loss=0.08942, avg_loss=0.09118, mel_loss=0.03964, linear_loss=0.04978]
[2020-05-12 01:28:40.170]  Step 149680  [3.161 sec/step, loss=0.08528, avg_loss=0.09103, mel_loss=0.03696, linear_loss=0.04832]
[2020-05-12 01:28:40.972]  Step 149681  [3.150 sec/step, loss=0.07748, avg_loss=0.09089, mel_loss=0.03334, linear_loss=0.04414]
[2020-05-12 01:28:42.681]  Generated 32 batches of size 32 in 1.703 sec
[2020-05-12 01:28:48.243]  Step 149682  [3.177 sec/step, loss=0.10033, avg_loss=0.09091, mel_loss=0.04657, linear_loss=0.05377]
[2020-05-12 01:28:53.753]  Step 149683  [3.179 sec/step, loss=0.09854, avg_loss=0.09091, mel_loss=0.04527, linear_loss=0.05327]
[2020-05-12 01:28:55.942]  Step 149684  [3.181 sec/step, loss=0.09118, avg_loss=0.09091, mel_loss=0.04065, linear_loss=0.05053]
[2020-05-12 01:28:59.308]  Step 149685  [3.184 sec/step, loss=0.09677, avg_loss=0.09091, mel_loss=0.04368, linear_loss=0.05309]
[2020-05-12 01:29:08.468]  Step 149686  [3.188 sec/step, loss=0.09996, avg_loss=0.09094, mel_loss=0.04690, linear_loss=0.05306]
[2020-05-12 01:29:10.479]  Step 149687  [3.184 sec/step, loss=0.09156, avg_loss=0.09093, mel_loss=0.04062, linear_loss=0.05094]
[2020-05-12 01:29:14.202]  Step 149688  [3.185 sec/step, loss=0.09703, avg_loss=0.09092, mel_loss=0.04381, linear_loss=0.05322]
[2020-05-12 01:29:15.902]  Step 149689  [3.181 sec/step, loss=0.09186, avg_loss=0.09090, mel_loss=0.04026, linear_loss=0.05160]
[2020-05-12 01:29:23.701]  Step 149690  [3.231 sec/step, loss=0.09897, avg_loss=0.09094, mel_loss=0.04574, linear_loss=0.05323]
[2020-05-12 01:29:27.973]  Step 149691  [3.248 sec/step, loss=0.10026, avg_loss=0.09104, mel_loss=0.04572, linear_loss=0.05454]
[2020-05-12 01:29:29.960]  Step 149692  [3.256 sec/step, loss=0.09085, avg_loss=0.09109, mel_loss=0.04034, linear_loss=0.05052]
[2020-05-12 01:29:33.346]  Step 149693  [3.256 sec/step, loss=0.09719, avg_loss=0.09111, mel_loss=0.04393, linear_loss=0.05326]
[2020-05-12 01:29:40.877]  Step 149694  [3.314 sec/step, loss=0.09907, avg_loss=0.09118, mel_loss=0.04586, linear_loss=0.05321]
[2020-05-12 01:29:44.535]  Step 149695  [3.342 sec/step, loss=0.09942, avg_loss=0.09138, mel_loss=0.04507, linear_loss=0.05435]
[2020-05-12 01:29:46.333]  Step 149696  [3.345 sec/step, loss=0.08899, avg_loss=0.09137, mel_loss=0.03922, linear_loss=0.04977]
[2020-05-12 01:29:51.929]  Step 149697  [3.358 sec/step, loss=0.09704, avg_loss=0.09137, mel_loss=0.04405, linear_loss=0.05298]
[2020-05-12 01:29:54.736]  Step 149698  [3.373 sec/step, loss=0.09449, avg_loss=0.09145, mel_loss=0.04243, linear_loss=0.05206]
[2020-05-12 01:29:55.923]  Step 149699  [3.375 sec/step, loss=0.08355, avg_loss=0.09147, mel_loss=0.03614, linear_loss=0.04741]
[2020-05-12 01:29:56.973]  Step 149700  [3.338 sec/step, loss=0.08580, avg_loss=0.09135, mel_loss=0.03716, linear_loss=0.04864]
[2020-05-12 01:29:56.973]  Writing summary at step: 149700
[2020-05-12 01:29:57.975]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149700
[2020-05-12 01:29:59.359]  Saving audio and alignment...
[2020-05-12 01:30:04.583]  Input: 따라서 와이티엔 같은 보도 채널에 앵커들은~__________
[2020-05-12 01:30:11.342]  Step 149701  [3.368 sec/step, loss=0.10014, avg_loss=0.09138, mel_loss=0.04616, linear_loss=0.05398]
[2020-05-12 01:30:12.801]  Step 149702  [3.369 sec/step, loss=0.08855, avg_loss=0.09139, mel_loss=0.03893, linear_loss=0.04963]
[2020-05-12 01:30:14.981]  Step 149703  [3.363 sec/step, loss=0.09282, avg_loss=0.09137, mel_loss=0.04117, linear_loss=0.05165]
[2020-05-12 01:30:19.096]  Step 149704  [3.370 sec/step, loss=0.09675, avg_loss=0.09136, mel_loss=0.04372, linear_loss=0.05303]
[2020-05-12 01:30:20.388]  Step 149705  [3.358 sec/step, loss=0.08581, avg_loss=0.09128, mel_loss=0.03714, linear_loss=0.04867]
[2020-05-12 01:30:25.070]  Step 149706  [3.397 sec/step, loss=0.09752, avg_loss=0.09150, mel_loss=0.04410, linear_loss=0.05341]
[2020-05-12 01:30:30.837]  Step 149707  [3.320 sec/step, loss=0.09788, avg_loss=0.09168, mel_loss=0.04520, linear_loss=0.05267]
[2020-05-12 01:30:34.336]  Step 149708  [3.341 sec/step, loss=0.09334, avg_loss=0.09175, mel_loss=0.04214, linear_loss=0.05121]
[2020-05-12 01:30:35.942]  Step 149709  [3.316 sec/step, loss=0.08805, avg_loss=0.09168, mel_loss=0.03901, linear_loss=0.04904]
[2020-05-12 01:30:36.928]  Step 149710  [3.257 sec/step, loss=0.08087, avg_loss=0.09149, mel_loss=0.03529, linear_loss=0.04558]
[2020-05-12 01:30:38.709]  Step 149711  [3.258 sec/step, loss=0.08920, avg_loss=0.09146, mel_loss=0.03909, linear_loss=0.05011]
[2020-05-12 01:30:40.485]  Generated 32 batches of size 32 in 1.771 sec
[2020-05-12 01:30:41.261]  Step 149712  [3.204 sec/step, loss=0.09183, avg_loss=0.09139, mel_loss=0.04079, linear_loss=0.05104]
[2020-05-12 01:30:41.816]  Step 149713  [3.204 sec/step, loss=0.06990, avg_loss=0.09133, mel_loss=0.03103, linear_loss=0.03887]
[2020-05-12 01:30:43.138]  Step 149714  [3.184 sec/step, loss=0.08932, avg_loss=0.09127, mel_loss=0.03932, linear_loss=0.05000]
[2020-05-12 01:30:43.975]  Step 149715  [3.173 sec/step, loss=0.07723, avg_loss=0.09112, mel_loss=0.03391, linear_loss=0.04333]
[2020-05-12 01:30:46.090]  Step 149716  [3.165 sec/step, loss=0.09224, avg_loss=0.09108, mel_loss=0.04099, linear_loss=0.05125]
[2020-05-12 01:30:56.883]  Step 149717  [3.262 sec/step, loss=0.08746, avg_loss=0.09110, mel_loss=0.04120, linear_loss=0.04627]
[2020-05-12 01:30:59.751]  Step 149718  [3.258 sec/step, loss=0.09701, avg_loss=0.09109, mel_loss=0.04368, linear_loss=0.05333]
[2020-05-12 01:31:00.514]  Step 149719  [3.211 sec/step, loss=0.08022, avg_loss=0.09091, mel_loss=0.03462, linear_loss=0.04560]
[2020-05-12 01:31:03.658]  Step 149720  [3.236 sec/step, loss=0.09909, avg_loss=0.09113, mel_loss=0.04454, linear_loss=0.05455]
[2020-05-12 01:31:10.859]  Step 149721  [3.290 sec/step, loss=0.09844, avg_loss=0.09121, mel_loss=0.04563, linear_loss=0.05282]
[2020-05-12 01:31:12.956]  Step 149722  [3.290 sec/step, loss=0.09160, avg_loss=0.09120, mel_loss=0.04078, linear_loss=0.05082]
[2020-05-12 01:31:17.709]  Step 149723  [3.316 sec/step, loss=0.09702, avg_loss=0.09125, mel_loss=0.04436, linear_loss=0.05266]
[2020-05-12 01:31:21.099]  Step 149724  [3.293 sec/step, loss=0.09450, avg_loss=0.09119, mel_loss=0.04245, linear_loss=0.05205]
[2020-05-12 01:31:22.470]  Step 149725  [3.296 sec/step, loss=0.08736, avg_loss=0.09120, mel_loss=0.03854, linear_loss=0.04881]
[2020-05-12 01:31:28.153]  Step 149726  [3.329 sec/step, loss=0.09916, avg_loss=0.09125, mel_loss=0.04582, linear_loss=0.05334]
[2020-05-12 01:31:29.716]  Step 149727  [3.334 sec/step, loss=0.08931, avg_loss=0.09130, mel_loss=0.03911, linear_loss=0.05020]
[2020-05-12 01:31:32.494]  Step 149728  [3.318 sec/step, loss=0.09439, avg_loss=0.09124, mel_loss=0.04236, linear_loss=0.05203]
[2020-05-12 01:31:35.051]  Step 149729  [3.328 sec/step, loss=0.09333, avg_loss=0.09129, mel_loss=0.04169, linear_loss=0.05164]
[2020-05-12 01:31:36.059]  Step 149730  [3.319 sec/step, loss=0.08443, avg_loss=0.09123, mel_loss=0.03680, linear_loss=0.04763]
[2020-05-12 01:31:36.919]  Step 149731  [3.311 sec/step, loss=0.07335, avg_loss=0.09106, mel_loss=0.03170, linear_loss=0.04165]
[2020-05-12 01:31:37.752]  Step 149732  [3.307 sec/step, loss=0.07540, avg_loss=0.09095, mel_loss=0.03304, linear_loss=0.04236]
[2020-05-12 01:31:39.962]  Step 149733  [3.309 sec/step, loss=0.09116, avg_loss=0.09094, mel_loss=0.04044, linear_loss=0.05072]
[2020-05-12 01:31:46.682]  Step 149734  [3.363 sec/step, loss=0.09826, avg_loss=0.09105, mel_loss=0.04521, linear_loss=0.05305]
[2020-05-12 01:32:03.702]  Step 149735  [3.523 sec/step, loss=0.08511, avg_loss=0.09104, mel_loss=0.04024, linear_loss=0.04487]
[2020-05-12 01:32:05.405]  Step 149736  [3.494 sec/step, loss=0.08536, avg_loss=0.09091, mel_loss=0.03656, linear_loss=0.04880]
[2020-05-12 01:32:07.493]  Step 149737  [3.485 sec/step, loss=0.09015, avg_loss=0.09084, mel_loss=0.03982, linear_loss=0.05033]
[2020-05-12 01:32:12.096]  Step 149738  [3.480 sec/step, loss=0.09794, avg_loss=0.09082, mel_loss=0.04450, linear_loss=0.05345]
[2020-05-12 01:32:13.032]  Step 149739  [3.464 sec/step, loss=0.07938, avg_loss=0.09069, mel_loss=0.03434, linear_loss=0.04505]
[2020-05-12 01:32:13.591]  Step 149740  [3.464 sec/step, loss=0.07000, avg_loss=0.09065, mel_loss=0.03056, linear_loss=0.03944]
[2020-05-12 01:32:15.290]  Step 149741  [3.454 sec/step, loss=0.09305, avg_loss=0.09064, mel_loss=0.04095, linear_loss=0.05210]
[2020-05-12 01:32:17.712]  Step 149742  [3.420 sec/step, loss=0.09404, avg_loss=0.09058, mel_loss=0.04156, linear_loss=0.05247]
[2020-05-12 01:32:23.167]  Step 149743  [3.442 sec/step, loss=0.09859, avg_loss=0.09060, mel_loss=0.04528, linear_loss=0.05331]
[2020-05-12 01:32:24.829]  Generated 32 batches of size 32 in 1.657 sec
[2020-05-12 01:32:26.838]  Step 149744  [3.400 sec/step, loss=0.09648, avg_loss=0.09058, mel_loss=0.04368, linear_loss=0.05281]
[2020-05-12 01:32:28.812]  Step 149745  [3.398 sec/step, loss=0.08872, avg_loss=0.09054, mel_loss=0.03918, linear_loss=0.04955]
[2020-05-12 01:32:37.932]  Step 149746  [3.458 sec/step, loss=0.09767, avg_loss=0.09055, mel_loss=0.04566, linear_loss=0.05200]
[2020-05-12 01:32:39.140]  Step 149747  [3.402 sec/step, loss=0.08588, avg_loss=0.09041, mel_loss=0.03749, linear_loss=0.04839]
[2020-05-12 01:32:40.446]  Step 149748  [3.407 sec/step, loss=0.08668, avg_loss=0.09055, mel_loss=0.03804, linear_loss=0.04865]
[2020-05-12 01:32:42.356]  Step 149749  [3.285 sec/step, loss=0.08969, avg_loss=0.09066, mel_loss=0.03956, linear_loss=0.05013]
[2020-05-12 01:32:45.823]  Step 149750  [3.276 sec/step, loss=0.09791, avg_loss=0.09066, mel_loss=0.04413, linear_loss=0.05378]
[2020-05-12 01:32:45.823]  Writing summary at step: 149750
[2020-05-12 01:32:50.094]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149750
[2020-05-12 01:32:51.525]  Saving audio and alignment...
[2020-05-12 01:32:56.253]  Input: 그래서 오늘이 강의를 듣고 계신 모든 여러분과~_____________________
[2020-05-12 01:32:57.978]  Step 149751  [3.203 sec/step, loss=0.08988, avg_loss=0.09058, mel_loss=0.03942, linear_loss=0.05046]
[2020-05-12 01:33:01.560]  Step 149752  [3.221 sec/step, loss=0.09704, avg_loss=0.09064, mel_loss=0.04383, linear_loss=0.05321]
[2020-05-12 01:33:02.518]  Step 149753  [3.220 sec/step, loss=0.08130, avg_loss=0.09062, mel_loss=0.03523, linear_loss=0.04607]
[2020-05-12 01:33:06.254]  Step 149754  [3.219 sec/step, loss=0.09795, avg_loss=0.09063, mel_loss=0.04416, linear_loss=0.05379]
[2020-05-12 01:33:08.367]  Step 149755  [3.232 sec/step, loss=0.09313, avg_loss=0.09078, mel_loss=0.04166, linear_loss=0.05148]
[2020-05-12 01:33:22.374]  Step 149756  [3.348 sec/step, loss=0.07907, avg_loss=0.09065, mel_loss=0.03768, linear_loss=0.04139]
[2020-05-12 01:33:29.043]  Step 149757  [3.379 sec/step, loss=0.09704, avg_loss=0.09063, mel_loss=0.04478, linear_loss=0.05226]
[2020-05-12 01:33:32.999]  Step 149758  [3.405 sec/step, loss=0.09857, avg_loss=0.09076, mel_loss=0.04487, linear_loss=0.05370]
[2020-05-12 01:33:34.574]  Step 149759  [3.383 sec/step, loss=0.08880, avg_loss=0.09067, mel_loss=0.03930, linear_loss=0.04950]
[2020-05-12 01:33:35.997]  Step 149760  [3.389 sec/step, loss=0.08578, avg_loss=0.09080, mel_loss=0.03772, linear_loss=0.04807]
[2020-05-12 01:33:39.346]  Step 149761  [3.381 sec/step, loss=0.09606, avg_loss=0.09080, mel_loss=0.04348, linear_loss=0.05258]
[2020-05-12 01:33:40.390]  Step 149762  [3.357 sec/step, loss=0.08331, avg_loss=0.09070, mel_loss=0.03638, linear_loss=0.04694]
[2020-05-12 01:33:44.807]  Step 149763  [3.388 sec/step, loss=0.10015, avg_loss=0.09086, mel_loss=0.04611, linear_loss=0.05405]
[2020-05-12 01:33:45.627]  Step 149764  [3.373 sec/step, loss=0.07707, avg_loss=0.09070, mel_loss=0.03298, linear_loss=0.04409]
[2020-05-12 01:33:48.443]  Step 149765  [3.373 sec/step, loss=0.09215, avg_loss=0.09067, mel_loss=0.04150, linear_loss=0.05065]
[2020-05-12 01:33:53.920]  Step 149766  [3.418 sec/step, loss=0.09805, avg_loss=0.09085, mel_loss=0.04491, linear_loss=0.05313]
[2020-05-12 01:33:54.789]  Step 149767  [3.408 sec/step, loss=0.07789, avg_loss=0.09073, mel_loss=0.03328, linear_loss=0.04461]
[2020-05-12 01:33:56.796]  Step 149768  [3.417 sec/step, loss=0.09320, avg_loss=0.09080, mel_loss=0.04075, linear_loss=0.05244]
[2020-05-12 01:33:59.274]  Step 149769  [3.422 sec/step, loss=0.09379, avg_loss=0.09083, mel_loss=0.04163, linear_loss=0.05216]
[2020-05-12 01:34:02.298]  Step 149770  [3.404 sec/step, loss=0.09265, avg_loss=0.09077, mel_loss=0.04143, linear_loss=0.05121]
[2020-05-12 01:34:06.171]  Step 149771  [3.429 sec/step, loss=0.09778, avg_loss=0.09088, mel_loss=0.04393, linear_loss=0.05385]
[2020-05-12 01:34:07.685]  Step 149772  [3.414 sec/step, loss=0.08575, avg_loss=0.09079, mel_loss=0.03757, linear_loss=0.04818]
[2020-05-12 01:34:09.695]  Step 149773  [3.389 sec/step, loss=0.09211, avg_loss=0.09074, mel_loss=0.04075, linear_loss=0.05136]
[2020-05-12 01:34:11.408]  Generated 32 batches of size 32 in 1.707 sec
[2020-05-12 01:34:12.136]  Step 149774  [3.386 sec/step, loss=0.09473, avg_loss=0.09077, mel_loss=0.04256, linear_loss=0.05218]
[2020-05-12 01:34:19.645]  Step 149775  [3.318 sec/step, loss=0.10102, avg_loss=0.09097, mel_loss=0.04733, linear_loss=0.05368]
[2020-05-12 01:34:24.465]  Step 149776  [3.308 sec/step, loss=0.09771, avg_loss=0.09096, mel_loss=0.04467, linear_loss=0.05304]
[2020-05-12 01:34:27.489]  Step 149777  [3.325 sec/step, loss=0.09615, avg_loss=0.09106, mel_loss=0.04319, linear_loss=0.05296]
[2020-05-12 01:34:29.079]  Step 149778  [3.335 sec/step, loss=0.09318, avg_loss=0.09126, mel_loss=0.04108, linear_loss=0.05210]
[2020-05-12 01:34:29.918]  Step 149779  [3.326 sec/step, loss=0.07499, avg_loss=0.09112, mel_loss=0.03332, linear_loss=0.04167]
[2020-05-12 01:34:31.060]  Step 149780  [3.328 sec/step, loss=0.08329, avg_loss=0.09110, mel_loss=0.03642, linear_loss=0.04687]
[2020-05-12 01:34:39.729]  Step 149781  [3.407 sec/step, loss=0.09848, avg_loss=0.09131, mel_loss=0.04610, linear_loss=0.05238]
[2020-05-12 01:34:40.260]  Step 149782  [3.340 sec/step, loss=0.07284, avg_loss=0.09103, mel_loss=0.03277, linear_loss=0.04006]
[2020-05-12 01:34:45.825]  Step 149783  [3.340 sec/step, loss=0.09953, avg_loss=0.09104, mel_loss=0.04566, linear_loss=0.05386]
[2020-05-12 01:34:52.105]  Step 149784  [3.381 sec/step, loss=0.09891, avg_loss=0.09112, mel_loss=0.04580, linear_loss=0.05311]
[2020-05-12 01:34:53.806]  Step 149785  [3.364 sec/step, loss=0.09134, avg_loss=0.09106, mel_loss=0.04042, linear_loss=0.05092]
[2020-05-12 01:34:55.234]  Step 149786  [3.287 sec/step, loss=0.08990, avg_loss=0.09096, mel_loss=0.03969, linear_loss=0.05021]
[2020-05-12 01:34:58.192]  Step 149787  [3.296 sec/step, loss=0.09709, avg_loss=0.09102, mel_loss=0.04316, linear_loss=0.05392]
[2020-05-12 01:34:58.794]  Step 149788  [3.265 sec/step, loss=0.07448, avg_loss=0.09079, mel_loss=0.03322, linear_loss=0.04126]
[2020-05-12 01:35:01.451]  Step 149789  [3.275 sec/step, loss=0.09437, avg_loss=0.09082, mel_loss=0.04205, linear_loss=0.05232]
[2020-05-12 01:35:03.973]  Step 149790  [3.222 sec/step, loss=0.09225, avg_loss=0.09075, mel_loss=0.04117, linear_loss=0.05109]
[2020-05-12 01:35:05.093]  Step 149791  [3.191 sec/step, loss=0.08137, avg_loss=0.09056, mel_loss=0.03559, linear_loss=0.04578]
[2020-05-12 01:35:06.164]  Step 149792  [3.181 sec/step, loss=0.08388, avg_loss=0.09049, mel_loss=0.03616, linear_loss=0.04772]
[2020-05-12 01:35:10.387]  Step 149793  [3.190 sec/step, loss=0.09831, avg_loss=0.09050, mel_loss=0.04501, linear_loss=0.05330]
[2020-05-12 01:35:14.455]  Step 149794  [3.155 sec/step, loss=0.09694, avg_loss=0.09048, mel_loss=0.04395, linear_loss=0.05299]
[2020-05-12 01:35:16.592]  Step 149795  [3.140 sec/step, loss=0.09339, avg_loss=0.09042, mel_loss=0.04148, linear_loss=0.05191]
[2020-05-12 01:35:18.541]  Step 149796  [3.141 sec/step, loss=0.09322, avg_loss=0.09046, mel_loss=0.04148, linear_loss=0.05174]
[2020-05-12 01:35:22.016]  Step 149797  [3.120 sec/step, loss=0.09465, avg_loss=0.09044, mel_loss=0.04267, linear_loss=0.05199]
[2020-05-12 01:35:27.306]  Step 149798  [3.145 sec/step, loss=0.09924, avg_loss=0.09049, mel_loss=0.04563, linear_loss=0.05361]
[2020-05-12 01:35:28.834]  Step 149799  [3.148 sec/step, loss=0.08730, avg_loss=0.09053, mel_loss=0.03848, linear_loss=0.04883]
[2020-05-12 01:35:33.584]  Step 149800  [3.185 sec/step, loss=0.09925, avg_loss=0.09066, mel_loss=0.04540, linear_loss=0.05384]
[2020-05-12 01:35:33.585]  Writing summary at step: 149800
[2020-05-12 01:35:36.635]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149800
[2020-05-12 01:35:38.038]  Saving audio and alignment...
[2020-05-12 01:35:41.374]  Input: 한국석유공사는 이렇게 올릴까요~________
[2020-05-12 01:35:49.790]  Step 149801  [3.202 sec/step, loss=0.09743, avg_loss=0.09063, mel_loss=0.04532, linear_loss=0.05211]
[2020-05-12 01:35:50.925]  Step 149802  [3.199 sec/step, loss=0.08323, avg_loss=0.09058, mel_loss=0.03631, linear_loss=0.04691]
[2020-05-12 01:35:54.576]  Step 149803  [3.214 sec/step, loss=0.09855, avg_loss=0.09064, mel_loss=0.04453, linear_loss=0.05402]
[2020-05-12 01:35:55.863]  Step 149804  [3.185 sec/step, loss=0.08519, avg_loss=0.09052, mel_loss=0.03745, linear_loss=0.04774]
[2020-05-12 01:35:56.273]  Generated 32 batches of size 32 in 1.692 sec
[2020-05-12 01:35:57.233]  Step 149805  [3.186 sec/step, loss=0.08610, avg_loss=0.09052, mel_loss=0.03779, linear_loss=0.04831]
[2020-05-12 01:35:57.984]  Step 149806  [3.147 sec/step, loss=0.07674, avg_loss=0.09032, mel_loss=0.03340, linear_loss=0.04334]
[2020-05-12 01:36:11.012]  Step 149807  [3.219 sec/step, loss=0.08394, avg_loss=0.09018, mel_loss=0.04014, linear_loss=0.04380]
[2020-05-12 01:36:14.384]  Step 149808  [3.218 sec/step, loss=0.09610, avg_loss=0.09020, mel_loss=0.04322, linear_loss=0.05288]
[2020-05-12 01:36:16.166]  Step 149809  [3.220 sec/step, loss=0.08984, avg_loss=0.09022, mel_loss=0.03924, linear_loss=0.05061]
[2020-05-12 01:36:23.505]  Step 149810  [3.283 sec/step, loss=0.09872, avg_loss=0.09040, mel_loss=0.04565, linear_loss=0.05306]
[2020-05-12 01:36:24.347]  Step 149811  [3.274 sec/step, loss=0.07617, avg_loss=0.09027, mel_loss=0.03321, linear_loss=0.04296]
[2020-05-12 01:36:26.951]  Step 149812  [3.274 sec/step, loss=0.09527, avg_loss=0.09030, mel_loss=0.04287, linear_loss=0.05241]
[2020-05-12 01:36:27.650]  Step 149813  [3.276 sec/step, loss=0.07965, avg_loss=0.09040, mel_loss=0.03531, linear_loss=0.04434]
[2020-05-12 01:36:31.774]  Step 149814  [3.304 sec/step, loss=0.09618, avg_loss=0.09047, mel_loss=0.04341, linear_loss=0.05276]
[2020-05-12 01:36:35.233]  Step 149815  [3.330 sec/step, loss=0.09581, avg_loss=0.09066, mel_loss=0.04356, linear_loss=0.05224]
[2020-05-12 01:36:37.216]  Step 149816  [3.329 sec/step, loss=0.09245, avg_loss=0.09066, mel_loss=0.04110, linear_loss=0.05135]
[2020-05-12 01:36:41.316]  Step 149817  [3.262 sec/step, loss=0.09851, avg_loss=0.09077, mel_loss=0.04490, linear_loss=0.05361]
[2020-05-12 01:36:48.570]  Step 149818  [3.306 sec/step, loss=0.09840, avg_loss=0.09078, mel_loss=0.04568, linear_loss=0.05272]
[2020-05-12 01:36:52.116]  Step 149819  [3.334 sec/step, loss=0.09791, avg_loss=0.09096, mel_loss=0.04424, linear_loss=0.05367]
[2020-05-12 01:36:54.710]  Step 149820  [3.328 sec/step, loss=0.09426, avg_loss=0.09091, mel_loss=0.04231, linear_loss=0.05195]
[2020-05-12 01:36:56.419]  Step 149821  [3.273 sec/step, loss=0.08868, avg_loss=0.09081, mel_loss=0.03895, linear_loss=0.04973]
[2020-05-12 01:36:58.108]  Step 149822  [3.269 sec/step, loss=0.09185, avg_loss=0.09082, mel_loss=0.04026, linear_loss=0.05159]
[2020-05-12 01:37:00.400]  Step 149823  [3.244 sec/step, loss=0.09132, avg_loss=0.09076, mel_loss=0.04027, linear_loss=0.05105]
[2020-05-12 01:37:02.640]  Step 149824  [3.233 sec/step, loss=0.09267, avg_loss=0.09074, mel_loss=0.04162, linear_loss=0.05106]
[2020-05-12 01:37:03.584]  Step 149825  [3.229 sec/step, loss=0.07986, avg_loss=0.09067, mel_loss=0.03477, linear_loss=0.04509]
[2020-05-12 01:37:04.761]  Step 149826  [3.184 sec/step, loss=0.08661, avg_loss=0.09054, mel_loss=0.03797, linear_loss=0.04863]
[2020-05-12 01:37:05.806]  Step 149827  [3.178 sec/step, loss=0.08137, avg_loss=0.09046, mel_loss=0.03563, linear_loss=0.04574]
[2020-05-12 01:37:18.879]  Step 149828  [3.281 sec/step, loss=0.08361, avg_loss=0.09035, mel_loss=0.03981, linear_loss=0.04380]
[2020-05-12 01:37:20.248]  Step 149829  [3.270 sec/step, loss=0.08706, avg_loss=0.09029, mel_loss=0.03800, linear_loss=0.04905]
[2020-05-12 01:37:23.412]  Step 149830  [3.291 sec/step, loss=0.09604, avg_loss=0.09041, mel_loss=0.04339, linear_loss=0.05266]
[2020-05-12 01:37:29.005]  Step 149831  [3.338 sec/step, loss=0.09811, avg_loss=0.09065, mel_loss=0.04510, linear_loss=0.05301]
[2020-05-12 01:37:29.805]  Step 149832  [3.338 sec/step, loss=0.07996, avg_loss=0.09070, mel_loss=0.03469, linear_loss=0.04527]
[2020-05-12 01:37:38.408]  Step 149833  [3.402 sec/step, loss=0.09680, avg_loss=0.09076, mel_loss=0.04505, linear_loss=0.05175]
[2020-05-12 01:37:38.967]  Step 149834  [3.340 sec/step, loss=0.07406, avg_loss=0.09051, mel_loss=0.03247, linear_loss=0.04158]
[2020-05-12 01:37:45.044]  Step 149835  [3.231 sec/step, loss=0.09868, avg_loss=0.09065, mel_loss=0.04557, linear_loss=0.05310]
[2020-05-12 01:37:46.918]  Step 149836  [3.233 sec/step, loss=0.09084, avg_loss=0.09071, mel_loss=0.03994, linear_loss=0.05090]
[2020-05-12 01:37:47.124]  Generated 32 batches of size 32 in 2.074 sec
[2020-05-12 01:37:52.085]  Step 149837  [3.263 sec/step, loss=0.09772, avg_loss=0.09078, mel_loss=0.04463, linear_loss=0.05309]
[2020-05-12 01:37:53.469]  Step 149838  [3.231 sec/step, loss=0.08805, avg_loss=0.09068, mel_loss=0.03885, linear_loss=0.04920]
[2020-05-12 01:37:55.917]  Step 149839  [3.246 sec/step, loss=0.09324, avg_loss=0.09082, mel_loss=0.04142, linear_loss=0.05181]
[2020-05-12 01:37:59.316]  Step 149840  [3.275 sec/step, loss=0.09649, avg_loss=0.09109, mel_loss=0.04365, linear_loss=0.05284]
[2020-05-12 01:38:01.492]  Step 149841  [3.280 sec/step, loss=0.09081, avg_loss=0.09106, mel_loss=0.04039, linear_loss=0.05043]
[2020-05-12 01:38:02.613]  Step 149842  [3.267 sec/step, loss=0.08565, avg_loss=0.09098, mel_loss=0.03677, linear_loss=0.04888]
[2020-05-12 01:38:07.207]  Step 149843  [3.258 sec/step, loss=0.09814, avg_loss=0.09097, mel_loss=0.04438, linear_loss=0.05375]
[2020-05-12 01:38:10.018]  Step 149844  [3.249 sec/step, loss=0.09567, avg_loss=0.09097, mel_loss=0.04325, linear_loss=0.05242]
[2020-05-12 01:38:11.802]  Step 149845  [3.247 sec/step, loss=0.08926, avg_loss=0.09097, mel_loss=0.03919, linear_loss=0.05008]
[2020-05-12 01:38:16.475]  Step 149846  [3.203 sec/step, loss=0.09980, avg_loss=0.09099, mel_loss=0.04604, linear_loss=0.05376]
[2020-05-12 01:38:18.973]  Step 149847  [3.216 sec/step, loss=0.09266, avg_loss=0.09106, mel_loss=0.04140, linear_loss=0.05125]
[2020-05-12 01:38:20.906]  Step 149848  [3.222 sec/step, loss=0.09082, avg_loss=0.09110, mel_loss=0.04021, linear_loss=0.05061]
[2020-05-12 01:38:22.128]  Step 149849  [3.215 sec/step, loss=0.08643, avg_loss=0.09107, mel_loss=0.03777, linear_loss=0.04865]
[2020-05-12 01:38:24.148]  Step 149850  [3.201 sec/step, loss=0.09227, avg_loss=0.09101, mel_loss=0.04110, linear_loss=0.05117]
[2020-05-12 01:38:24.148]  Writing summary at step: 149850
[2020-05-12 01:38:25.264]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149850
[2020-05-12 01:38:26.755]  Saving audio and alignment...
[2020-05-12 01:38:31.467]  Input: 그런가하면 음악으로 사랑하는 여배우를 쟁취했으나~_________
[2020-05-12 01:38:35.503]  Step 149851  [3.224 sec/step, loss=0.09692, avg_loss=0.09108, mel_loss=0.04388, linear_loss=0.05304]
[2020-05-12 01:38:42.250]  Step 149852  [3.256 sec/step, loss=0.09915, avg_loss=0.09110, mel_loss=0.04580, linear_loss=0.05334]
[2020-05-12 01:38:45.635]  Step 149853  [3.280 sec/step, loss=0.09491, avg_loss=0.09124, mel_loss=0.04265, linear_loss=0.05226]
[2020-05-12 01:38:49.239]  Step 149854  [3.279 sec/step, loss=0.09802, avg_loss=0.09124, mel_loss=0.04454, linear_loss=0.05348]
[2020-05-12 01:38:50.573]  Step 149855  [3.271 sec/step, loss=0.08534, avg_loss=0.09116, mel_loss=0.03738, linear_loss=0.04796]
[2020-05-12 01:38:53.842]  Step 149856  [3.163 sec/step, loss=0.09792, avg_loss=0.09135, mel_loss=0.04440, linear_loss=0.05352]
[2020-05-12 01:38:58.083]  Step 149857  [3.139 sec/step, loss=0.09866, avg_loss=0.09137, mel_loss=0.04503, linear_loss=0.05363]
[2020-05-12 01:38:59.705]  Step 149858  [3.116 sec/step, loss=0.09048, avg_loss=0.09129, mel_loss=0.04037, linear_loss=0.05011]
[2020-05-12 01:39:00.712]  Step 149859  [3.110 sec/step, loss=0.08106, avg_loss=0.09121, mel_loss=0.03526, linear_loss=0.04579]
[2020-05-12 01:39:02.319]  Step 149860  [3.112 sec/step, loss=0.08744, avg_loss=0.09123, mel_loss=0.03870, linear_loss=0.04875]
[2020-05-12 01:39:04.476]  Step 149861  [3.100 sec/step, loss=0.09199, avg_loss=0.09119, mel_loss=0.04079, linear_loss=0.05120]
[2020-05-12 01:39:05.290]  Step 149862  [3.098 sec/step, loss=0.07602, avg_loss=0.09111, mel_loss=0.03308, linear_loss=0.04294]
[2020-05-12 01:39:14.071]  Step 149863  [3.141 sec/step, loss=0.09954, avg_loss=0.09111, mel_loss=0.04661, linear_loss=0.05293]
[2020-05-12 01:39:19.592]  Step 149864  [3.188 sec/step, loss=0.09963, avg_loss=0.09133, mel_loss=0.04577, linear_loss=0.05386]
[2020-05-12 01:39:24.858]  Step 149865  [3.213 sec/step, loss=0.09747, avg_loss=0.09139, mel_loss=0.04484, linear_loss=0.05263]
[2020-05-12 01:39:26.741]  Generated 32 batches of size 32 in 1.878 sec
[2020-05-12 01:39:27.682]  Step 149866  [3.186 sec/step, loss=0.09439, avg_loss=0.09135, mel_loss=0.04232, linear_loss=0.05207]
[2020-05-12 01:39:29.075]  Step 149867  [3.192 sec/step, loss=0.08869, avg_loss=0.09146, mel_loss=0.03909, linear_loss=0.04960]
[2020-05-12 01:39:36.650]  Step 149868  [3.247 sec/step, loss=0.09942, avg_loss=0.09152, mel_loss=0.04631, linear_loss=0.05311]
[2020-05-12 01:39:37.453]  Step 149869  [3.230 sec/step, loss=0.07638, avg_loss=0.09134, mel_loss=0.03282, linear_loss=0.04356]
[2020-05-12 01:39:51.313]  Step 149870  [3.339 sec/step, loss=0.07827, avg_loss=0.09120, mel_loss=0.03750, linear_loss=0.04077]
[2020-05-12 01:39:54.407]  Step 149871  [3.331 sec/step, loss=0.09849, avg_loss=0.09121, mel_loss=0.04443, linear_loss=0.05406]
[2020-05-12 01:39:54.962]  Step 149872  [3.321 sec/step, loss=0.07026, avg_loss=0.09105, mel_loss=0.03143, linear_loss=0.03883]
[2020-05-12 01:39:55.961]  Step 149873  [3.311 sec/step, loss=0.08138, avg_loss=0.09095, mel_loss=0.03539, linear_loss=0.04600]
[2020-05-12 01:39:58.227]  Step 149874  [3.310 sec/step, loss=0.09428, avg_loss=0.09094, mel_loss=0.04199, linear_loss=0.05229]
[2020-05-12 01:40:01.091]  Step 149875  [3.263 sec/step, loss=0.09399, avg_loss=0.09087, mel_loss=0.04192, linear_loss=0.05208]
[2020-05-12 01:40:01.737]  Step 149876  [3.221 sec/step, loss=0.07283, avg_loss=0.09062, mel_loss=0.03203, linear_loss=0.04080]
[2020-05-12 01:40:09.233]  Step 149877  [3.266 sec/step, loss=0.09893, avg_loss=0.09065, mel_loss=0.04609, linear_loss=0.05284]
[2020-05-12 01:40:13.491]  Step 149878  [3.293 sec/step, loss=0.09705, avg_loss=0.09069, mel_loss=0.04381, linear_loss=0.05324]
[2020-05-12 01:40:14.877]  Step 149879  [3.298 sec/step, loss=0.08635, avg_loss=0.09080, mel_loss=0.03790, linear_loss=0.04845]
[2020-05-12 01:40:20.575]  Step 149880  [3.344 sec/step, loss=0.09869, avg_loss=0.09096, mel_loss=0.04521, linear_loss=0.05348]
[2020-05-12 01:40:22.455]  Step 149881  [3.276 sec/step, loss=0.08994, avg_loss=0.09087, mel_loss=0.03963, linear_loss=0.05031]
[2020-05-12 01:40:31.172]  Step 149882  [3.358 sec/step, loss=0.09710, avg_loss=0.09111, mel_loss=0.04513, linear_loss=0.05197]
[2020-05-12 01:40:35.750]  Step 149883  [3.348 sec/step, loss=0.09753, avg_loss=0.09109, mel_loss=0.04417, linear_loss=0.05336]
[2020-05-12 01:40:38.485]  Step 149884  [3.312 sec/step, loss=0.09326, avg_loss=0.09104, mel_loss=0.04187, linear_loss=0.05140]
[2020-05-12 01:40:39.840]  Step 149885  [3.309 sec/step, loss=0.08755, avg_loss=0.09100, mel_loss=0.03846, linear_loss=0.04908]
[2020-05-12 01:40:42.329]  Step 149886  [3.320 sec/step, loss=0.09255, avg_loss=0.09103, mel_loss=0.04101, linear_loss=0.05154]
[2020-05-12 01:40:48.401]  Step 149887  [3.351 sec/step, loss=0.09624, avg_loss=0.09102, mel_loss=0.04432, linear_loss=0.05192]
[2020-05-12 01:40:49.199]  Step 149888  [3.353 sec/step, loss=0.07642, avg_loss=0.09104, mel_loss=0.03286, linear_loss=0.04356]
[2020-05-12 01:40:50.890]  Step 149889  [3.343 sec/step, loss=0.08882, avg_loss=0.09098, mel_loss=0.03933, linear_loss=0.04950]
[2020-05-12 01:40:53.043]  Step 149890  [3.339 sec/step, loss=0.09139, avg_loss=0.09097, mel_loss=0.04078, linear_loss=0.05061]
[2020-05-12 01:40:56.544]  Step 149891  [3.363 sec/step, loss=0.09569, avg_loss=0.09112, mel_loss=0.04299, linear_loss=0.05270]
[2020-05-12 01:40:58.203]  Step 149892  [3.369 sec/step, loss=0.08919, avg_loss=0.09117, mel_loss=0.03954, linear_loss=0.04965]
[2020-05-12 01:41:01.823]  Step 149893  [3.363 sec/step, loss=0.09832, avg_loss=0.09117, mel_loss=0.04462, linear_loss=0.05369]
[2020-05-12 01:41:02.345]  Step 149894  [3.328 sec/step, loss=0.07686, avg_loss=0.09097, mel_loss=0.03375, linear_loss=0.04311]
[2020-05-12 01:41:03.335]  Step 149895  [3.316 sec/step, loss=0.07969, avg_loss=0.09083, mel_loss=0.03448, linear_loss=0.04520]
[2020-05-12 01:41:07.622]  Step 149896  [3.339 sec/step, loss=0.09713, avg_loss=0.09087, mel_loss=0.04425, linear_loss=0.05287]
[2020-05-12 01:41:10.853]  Step 149897  [3.337 sec/step, loss=0.09620, avg_loss=0.09089, mel_loss=0.04350, linear_loss=0.05269]
[2020-05-12 01:41:12.725]  Generated 32 batches of size 32 in 1.866 sec
[2020-05-12 01:41:12.945]  Step 149898  [3.305 sec/step, loss=0.09151, avg_loss=0.09081, mel_loss=0.04054, linear_loss=0.05097]
[2020-05-12 01:41:25.955]  Step 149899  [3.420 sec/step, loss=0.08410, avg_loss=0.09078, mel_loss=0.03978, linear_loss=0.04432]
[2020-05-12 01:41:28.307]  Step 149900  [3.396 sec/step, loss=0.09217, avg_loss=0.09071, mel_loss=0.04103, linear_loss=0.05114]
[2020-05-12 01:41:28.307]  Writing summary at step: 149900
[2020-05-12 01:41:29.491]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149900
[2020-05-12 01:41:30.923]  Saving audio and alignment...
[2020-05-12 01:41:33.020]  Input: 또 어떤 날은~____________
[2020-05-12 01:41:34.509]  Step 149901  [3.327 sec/step, loss=0.08923, avg_loss=0.09062, mel_loss=0.03908, linear_loss=0.05015]
[2020-05-12 01:41:37.597]  Step 149902  [3.346 sec/step, loss=0.09714, avg_loss=0.09076, mel_loss=0.04385, linear_loss=0.05329]
[2020-05-12 01:41:38.565]  Step 149903  [3.319 sec/step, loss=0.08204, avg_loss=0.09060, mel_loss=0.03538, linear_loss=0.04667]
[2020-05-12 01:41:43.728]  Step 149904  [3.358 sec/step, loss=0.09715, avg_loss=0.09072, mel_loss=0.04463, linear_loss=0.05252]
[2020-05-12 01:41:44.718]  Step 149905  [3.354 sec/step, loss=0.08182, avg_loss=0.09067, mel_loss=0.03545, linear_loss=0.04637]
[2020-05-12 01:41:45.277]  Step 149906  [3.352 sec/step, loss=0.07379, avg_loss=0.09064, mel_loss=0.03318, linear_loss=0.04061]
[2020-05-12 01:41:47.367]  Step 149907  [3.243 sec/step, loss=0.09313, avg_loss=0.09074, mel_loss=0.04121, linear_loss=0.05192]
[2020-05-12 01:41:53.015]  Step 149908  [3.266 sec/step, loss=0.09835, avg_loss=0.09076, mel_loss=0.04510, linear_loss=0.05325]
[2020-05-12 01:41:56.151]  Step 149909  [3.279 sec/step, loss=0.09855, avg_loss=0.09085, mel_loss=0.04457, linear_loss=0.05397]
[2020-05-12 01:41:57.464]  Step 149910  [3.219 sec/step, loss=0.08821, avg_loss=0.09074, mel_loss=0.03862, linear_loss=0.04959]
[2020-05-12 01:42:01.945]  Step 149911  [3.255 sec/step, loss=0.09940, avg_loss=0.09097, mel_loss=0.04550, linear_loss=0.05390]
[2020-05-12 01:42:04.558]  Step 149912  [3.256 sec/step, loss=0.09407, avg_loss=0.09096, mel_loss=0.04211, linear_loss=0.05196]
[2020-05-12 01:42:07.334]  Step 149913  [3.276 sec/step, loss=0.09609, avg_loss=0.09113, mel_loss=0.04352, linear_loss=0.05257]
[2020-05-12 01:42:08.789]  Step 149914  [3.250 sec/step, loss=0.08340, avg_loss=0.09100, mel_loss=0.03662, linear_loss=0.04678]
[2020-05-12 01:42:10.034]  Step 149915  [3.227 sec/step, loss=0.07934, avg_loss=0.09083, mel_loss=0.03454, linear_loss=0.04480]
[2020-05-12 01:42:13.059]  Step 149916  [3.238 sec/step, loss=0.09156, avg_loss=0.09082, mel_loss=0.04070, linear_loss=0.05086]
[2020-05-12 01:42:19.352]  Step 149917  [3.260 sec/step, loss=0.09708, avg_loss=0.09081, mel_loss=0.04405, linear_loss=0.05304]
[2020-05-12 01:42:21.983]  Step 149918  [3.214 sec/step, loss=0.09148, avg_loss=0.09074, mel_loss=0.04025, linear_loss=0.05123]
[2020-05-12 01:42:26.059]  Step 149919  [3.219 sec/step, loss=0.09609, avg_loss=0.09072, mel_loss=0.04358, linear_loss=0.05251]
[2020-05-12 01:42:28.477]  Step 149920  [3.217 sec/step, loss=0.09364, avg_loss=0.09072, mel_loss=0.04196, linear_loss=0.05168]
[2020-05-12 01:42:43.142]  Step 149921  [3.347 sec/step, loss=0.07595, avg_loss=0.09059, mel_loss=0.03638, linear_loss=0.03957]
[2020-05-12 01:42:46.837]  Step 149922  [3.367 sec/step, loss=0.09867, avg_loss=0.09066, mel_loss=0.04480, linear_loss=0.05387]
[2020-05-12 01:42:48.631]  Step 149923  [3.362 sec/step, loss=0.09059, avg_loss=0.09065, mel_loss=0.03984, linear_loss=0.05075]
[2020-05-12 01:42:55.795]  Step 149924  [3.411 sec/step, loss=0.09947, avg_loss=0.09072, mel_loss=0.04602, linear_loss=0.05345]
[2020-05-12 01:42:59.485]  Step 149925  [3.438 sec/step, loss=0.09616, avg_loss=0.09088, mel_loss=0.04342, linear_loss=0.05275]
[2020-05-12 01:43:01.051]  Step 149926  [3.442 sec/step, loss=0.08820, avg_loss=0.09090, mel_loss=0.03868, linear_loss=0.04953]
[2020-05-12 01:43:02.287]  Step 149927  [3.444 sec/step, loss=0.08666, avg_loss=0.09095, mel_loss=0.03776, linear_loss=0.04890]
[2020-05-12 01:43:04.113]  Generated 32 batches of size 32 in 1.819 sec
[2020-05-12 01:43:04.821]  Step 149928  [3.339 sec/step, loss=0.09238, avg_loss=0.09104, mel_loss=0.04113, linear_loss=0.05125]
[2020-05-12 01:43:12.917]  Step 149929  [3.406 sec/step, loss=0.09655, avg_loss=0.09113, mel_loss=0.04522, linear_loss=0.05134]
[2020-05-12 01:43:14.833]  Step 149930  [3.394 sec/step, loss=0.09032, avg_loss=0.09108, mel_loss=0.03963, linear_loss=0.05069]
[2020-05-12 01:43:15.940]  Step 149931  [3.349 sec/step, loss=0.08590, avg_loss=0.09095, mel_loss=0.03703, linear_loss=0.04887]
[2020-05-12 01:43:17.335]  Step 149932  [3.355 sec/step, loss=0.08861, avg_loss=0.09104, mel_loss=0.03913, linear_loss=0.04947]
[2020-05-12 01:43:18.146]  Step 149933  [3.277 sec/step, loss=0.07901, avg_loss=0.09086, mel_loss=0.03421, linear_loss=0.04480]
[2020-05-12 01:43:21.122]  Step 149934  [3.301 sec/step, loss=0.09717, avg_loss=0.09109, mel_loss=0.04372, linear_loss=0.05345]
[2020-05-12 01:43:25.991]  Step 149935  [3.289 sec/step, loss=0.09695, avg_loss=0.09108, mel_loss=0.04426, linear_loss=0.05269]
[2020-05-12 01:43:32.331]  Step 149936  [3.334 sec/step, loss=0.09854, avg_loss=0.09115, mel_loss=0.04554, linear_loss=0.05300]
[2020-05-12 01:43:34.267]  Step 149937  [3.301 sec/step, loss=0.09059, avg_loss=0.09108, mel_loss=0.04008, linear_loss=0.05051]
[2020-05-12 01:43:41.702]  Step 149938  [3.362 sec/step, loss=0.10024, avg_loss=0.09120, mel_loss=0.04663, linear_loss=0.05361]
[2020-05-12 01:43:48.400]  Step 149939  [3.404 sec/step, loss=0.09800, avg_loss=0.09125, mel_loss=0.04525, linear_loss=0.05276]
[2020-05-12 01:43:52.567]  Step 149940  [3.412 sec/step, loss=0.09670, avg_loss=0.09125, mel_loss=0.04358, linear_loss=0.05312]
[2020-05-12 01:43:55.209]  Step 149941  [3.417 sec/step, loss=0.09428, avg_loss=0.09129, mel_loss=0.04216, linear_loss=0.05212]
[2020-05-12 01:43:56.562]  Step 149942  [3.419 sec/step, loss=0.08669, avg_loss=0.09130, mel_loss=0.03764, linear_loss=0.04905]
[2020-05-12 01:43:57.781]  Step 149943  [3.385 sec/step, loss=0.08526, avg_loss=0.09117, mel_loss=0.03745, linear_loss=0.04781]
[2020-05-12 01:44:01.448]  Step 149944  [3.394 sec/step, loss=0.09935, avg_loss=0.09121, mel_loss=0.04497, linear_loss=0.05438]
[2020-05-12 01:44:03.233]  Step 149945  [3.394 sec/step, loss=0.09116, avg_loss=0.09123, mel_loss=0.04006, linear_loss=0.05111]
[2020-05-12 01:44:04.371]  Step 149946  [3.358 sec/step, loss=0.08250, avg_loss=0.09105, mel_loss=0.03565, linear_loss=0.04686]
[2020-05-12 01:44:12.982]  Step 149947  [3.420 sec/step, loss=0.09575, avg_loss=0.09108, mel_loss=0.04449, linear_loss=0.05126]
[2020-05-12 01:44:16.410]  Step 149948  [3.434 sec/step, loss=0.09538, avg_loss=0.09113, mel_loss=0.04303, linear_loss=0.05235]
[2020-05-12 01:44:18.129]  Step 149949  [3.439 sec/step, loss=0.09102, avg_loss=0.09117, mel_loss=0.03996, linear_loss=0.05105]
[2020-05-12 01:44:22.879]  Step 149950  [3.467 sec/step, loss=0.09779, avg_loss=0.09123, mel_loss=0.04450, linear_loss=0.05329]
[2020-05-12 01:44:22.880]  Writing summary at step: 149950
[2020-05-12 01:44:23.964]  Saving checkpoint to: ./logs-tacotron/model.ckpt-149950
[2020-05-12 01:44:25.430]  Saving audio and alignment...
[2020-05-12 01:44:29.191]  Input: 자신들이 그렇게 되리라는 확신이 있었을까요~
[2020-05-12 01:44:31.676]  Step 149951  [3.451 sec/step, loss=0.09081, avg_loss=0.09117, mel_loss=0.04033, linear_loss=0.05048]
[2020-05-12 01:44:32.574]  Step 149952  [3.393 sec/step, loss=0.08272, avg_loss=0.09100, mel_loss=0.03552, linear_loss=0.04720]
[2020-05-12 01:44:35.730]  Step 149953  [3.390 sec/step, loss=0.09681, avg_loss=0.09102, mel_loss=0.04354, linear_loss=0.05327]
[2020-05-12 01:44:37.272]  Step 149954  [3.370 sec/step, loss=0.09097, avg_loss=0.09095, mel_loss=0.03995, linear_loss=0.05102]
[2020-05-12 01:44:39.275]  Step 149955  [3.377 sec/step, loss=0.09102, avg_loss=0.09101, mel_loss=0.04029, linear_loss=0.05072]
[2020-05-12 01:44:44.603]  Step 149956  [3.397 sec/step, loss=0.09793, avg_loss=0.09101, mel_loss=0.04466, linear_loss=0.05327]
[2020-05-12 01:44:46.980]  Step 149957  [3.378 sec/step, loss=0.09083, avg_loss=0.09093, mel_loss=0.04044, linear_loss=0.05039]
[2020-05-12 01:44:48.663]  Generated 32 batches of size 32 in 1.678 sec
[2020-05-12 01:44:51.500]  Step 149958  [3.407 sec/step, loss=0.09656, avg_loss=0.09099, mel_loss=0.04390, linear_loss=0.05266]
[2020-05-12 01:45:05.439]  Step 149959  [3.537 sec/step, loss=0.07735, avg_loss=0.09096, mel_loss=0.03708, linear_loss=0.04028]
[2020-05-12 01:45:08.986]  Step 149960  [3.556 sec/step, loss=0.09498, avg_loss=0.09103, mel_loss=0.04282, linear_loss=0.05216]
[2020-05-12 01:45:14.613]  Step 149961  [3.591 sec/step, loss=0.09780, avg_loss=0.09109, mel_loss=0.04490, linear_loss=0.05289]
[2020-05-12 01:45:17.539]  Step 149962  [3.612 sec/step, loss=0.09599, avg_loss=0.09129, mel_loss=0.04290, linear_loss=0.05309]
[2020-05-12 01:45:18.292]  Step 149963  [3.532 sec/step, loss=0.07288, avg_loss=0.09102, mel_loss=0.03232, linear_loss=0.04057]
[2020-05-12 01:45:19.801]  Step 149964  [3.492 sec/step, loss=0.08614, avg_loss=0.09089, mel_loss=0.03801, linear_loss=0.04813]
[2020-05-12 01:45:20.640]  Step 149965  [3.447 sec/step, loss=0.07521, avg_loss=0.09066, mel_loss=0.03245, linear_loss=0.04276]
[2020-05-12 01:45:21.496]  Step 149966  [3.428 sec/step, loss=0.07927, avg_loss=0.09051, mel_loss=0.03441, linear_loss=0.04486]
[2020-05-12 01:45:24.064]  Step 149967  [3.439 sec/step, loss=0.09179, avg_loss=0.09054, mel_loss=0.04065, linear_loss=0.05114]
[2020-05-12 01:45:25.236]  Step 149968  [3.375 sec/step, loss=0.08281, avg_loss=0.09038, mel_loss=0.03567, linear_loss=0.04715]
[2020-05-12 01:45:26.179]  Step 149969  [3.377 sec/step, loss=0.07900, avg_loss=0.09040, mel_loss=0.03385, linear_loss=0.04516]
[2020-05-12 01:45:26.855]  Step 149970  [3.245 sec/step, loss=0.07542, avg_loss=0.09038, mel_loss=0.03299, linear_loss=0.04243]
[2020-05-12 01:45:28.295]  Step 149971  [3.228 sec/step, loss=0.08676, avg_loss=0.09026, mel_loss=0.03809, linear_loss=0.04867]
[2020-05-12 01:45:31.809]  Step 149972  [3.258 sec/step, loss=0.09771, avg_loss=0.09053, mel_loss=0.04418, linear_loss=0.05353]
[2020-05-12 01:45:34.514]  Step 149973  [3.275 sec/step, loss=0.09392, avg_loss=0.09066, mel_loss=0.04204, linear_loss=0.05187]
[2020-05-12 01:45:36.405]  Step 149974  [3.271 sec/step, loss=0.08718, avg_loss=0.09059, mel_loss=0.03843, linear_loss=0.04875]
[2020-05-12 01:45:37.728]  Step 149975  [3.256 sec/step, loss=0.08859, avg_loss=0.09053, mel_loss=0.03872, linear_loss=0.04988]
[2020-05-12 01:45:40.677]  Step 149976  [3.279 sec/step, loss=0.09706, avg_loss=0.09078, mel_loss=0.04392, linear_loss=0.05314]
[2020-05-12 01:45:42.688]  Step 149977  [3.224 sec/step, loss=0.09021, avg_loss=0.09069, mel_loss=0.03979, linear_loss=0.05042]
[2020-05-12 01:45:46.742]  Step 149978  [3.222 sec/step, loss=0.09802, avg_loss=0.09070, mel_loss=0.04449, linear_loss=0.05354]
[2020-05-12 01:45:50.095]  Step 149979  [3.242 sec/step, loss=0.09468, avg_loss=0.09078, mel_loss=0.04253, linear_loss=0.05214]
[2020-05-12 01:46:02.973]  Step 149980  [3.313 sec/step, loss=0.08280, avg_loss=0.09062, mel_loss=0.03919, linear_loss=0.04361]
[2020-05-12 01:46:04.721]  Step 149981  [3.312 sec/step, loss=0.09048, avg_loss=0.09063, mel_loss=0.04001, linear_loss=0.05047]
[2020-05-12 01:46:05.245]  Step 149982  [3.230 sec/step, loss=0.07684, avg_loss=0.09043, mel_loss=0.03358, linear_loss=0.04326]
[2020-05-12 01:46:06.877]  Step 149983  [3.201 sec/step, loss=0.08949, avg_loss=0.09034, mel_loss=0.03958, linear_loss=0.04990]
[2020-05-12 01:46:08.978]  Step 149984  [3.194 sec/step, loss=0.09368, avg_loss=0.09035, mel_loss=0.04189, linear_loss=0.05179]
[2020-05-12 01:46:10.210]  Step 149985  [3.193 sec/step, loss=0.08392, avg_loss=0.09031, mel_loss=0.03674, linear_loss=0.04718]
[2020-05-12 01:46:11.766]  Step 149986  [3.184 sec/step, loss=0.08969, avg_loss=0.09028, mel_loss=0.03961, linear_loss=0.05007]
[2020-05-12 01:46:17.296]  Step 149987  [3.178 sec/step, loss=0.09897, avg_loss=0.09031, mel_loss=0.04521, linear_loss=0.05376]
[2020-05-12 01:46:24.773]  Step 149988  [3.245 sec/step, loss=0.09880, avg_loss=0.09054, mel_loss=0.04577, linear_loss=0.05304]
[2020-05-12 01:46:31.443]  Step 149989  [3.295 sec/step, loss=0.09870, avg_loss=0.09063, mel_loss=0.04551, linear_loss=0.05319]
[2020-05-12 01:46:33.193]  Generated 32 batches of size 32 in 1.744 sec
[2020-05-12 01:46:34.207]  Step 149990  [3.301 sec/step, loss=0.09394, avg_loss=0.09066, mel_loss=0.04200, linear_loss=0.05194]
[2020-05-12 01:46:39.355]  Step 149991  [3.318 sec/step, loss=0.09603, avg_loss=0.09066, mel_loss=0.04396, linear_loss=0.05206]
[2020-05-12 01:46:48.008]  Step 149992  [3.388 sec/step, loss=0.09884, avg_loss=0.09076, mel_loss=0.04619, linear_loss=0.05266]
[2020-05-12 01:46:51.358]  Step 149993  [3.385 sec/step, loss=0.09676, avg_loss=0.09074, mel_loss=0.04343, linear_loss=0.05333]
[2020-05-12 01:46:52.343]  Step 149994  [3.389 sec/step, loss=0.08072, avg_loss=0.09078, mel_loss=0.03527, linear_loss=0.04545]
[2020-05-12 01:46:53.131]  Step 149995  [3.387 sec/step, loss=0.08101, avg_loss=0.09080, mel_loss=0.03485, linear_loss=0.04615]
[2020-05-12 01:46:55.376]  Step 149996  [3.367 sec/step, loss=0.09384, avg_loss=0.09076, mel_loss=0.04198, linear_loss=0.05186]
[2020-05-12 01:46:59.811]  Step 149997  [3.379 sec/step, loss=0.09861, avg_loss=0.09079, mel_loss=0.04525, linear_loss=0.05336]
[2020-05-12 01:47:03.797]  Step 149998  [3.398 sec/step, loss=0.09728, avg_loss=0.09084, mel_loss=0.04393, linear_loss=0.05335]
[2020-05-12 01:47:06.223]  Step 149999  [3.292 sec/step, loss=0.09085, avg_loss=0.09091, mel_loss=0.04021, linear_loss=0.05064]
[2020-05-12 01:47:07.789]  Step 150000  [3.284 sec/step, loss=0.08855, avg_loss=0.09088, mel_loss=0.03888, linear_loss=0.04967]
[2020-05-12 01:47:07.789]  Writing summary at step: 150000
[2020-05-12 01:47:08.763]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150000
[2020-05-12 01:47:10.182]  Saving audio and alignment...
[2020-05-12 01:47:13.648]  Input: 행사 엠씨로서 나의 미래도~_____________________
[2020-05-12 01:47:14.792]  Step 150001  [3.281 sec/step, loss=0.08319, avg_loss=0.09082, mel_loss=0.03616, linear_loss=0.04704]
[2020-05-12 01:47:16.953]  Step 150002  [3.272 sec/step, loss=0.09288, avg_loss=0.09077, mel_loss=0.04123, linear_loss=0.05165]
[2020-05-12 01:47:18.917]  Step 150003  [3.282 sec/step, loss=0.09089, avg_loss=0.09086, mel_loss=0.04011, linear_loss=0.05078]
[2020-05-12 01:47:20.261]  Step 150004  [3.243 sec/step, loss=0.08897, avg_loss=0.09078, mel_loss=0.03877, linear_loss=0.05020]
[2020-05-12 01:47:23.660]  Step 150005  [3.267 sec/step, loss=0.09652, avg_loss=0.09093, mel_loss=0.04368, linear_loss=0.05284]
[2020-05-12 01:47:28.696]  Step 150006  [3.312 sec/step, loss=0.09844, avg_loss=0.09117, mel_loss=0.04521, linear_loss=0.05322]
[2020-05-12 01:47:32.371]  Step 150007  [3.328 sec/step, loss=0.09817, avg_loss=0.09122, mel_loss=0.04456, linear_loss=0.05361]
[2020-05-12 01:47:33.131]  Step 150008  [3.279 sec/step, loss=0.08078, avg_loss=0.09105, mel_loss=0.03488, linear_loss=0.04590]
[2020-05-12 01:47:34.430]  Step 150009  [3.261 sec/step, loss=0.08357, avg_loss=0.09090, mel_loss=0.03657, linear_loss=0.04701]
[2020-05-12 01:47:37.326]  Step 150010  [3.277 sec/step, loss=0.09468, avg_loss=0.09096, mel_loss=0.04252, linear_loss=0.05217]
[2020-05-12 01:47:40.797]  Step 150011  [3.267 sec/step, loss=0.09556, avg_loss=0.09092, mel_loss=0.04290, linear_loss=0.05267]
[2020-05-12 01:47:47.129]  Step 150012  [3.304 sec/step, loss=0.09716, avg_loss=0.09096, mel_loss=0.04486, linear_loss=0.05230]
[2020-05-12 01:48:00.187]  Step 150013  [3.407 sec/step, loss=0.08479, avg_loss=0.09084, mel_loss=0.04028, linear_loss=0.04452]
[2020-05-12 01:48:01.069]  Step 150014  [3.401 sec/step, loss=0.07572, avg_loss=0.09077, mel_loss=0.03283, linear_loss=0.04289]
[2020-05-12 01:48:05.499]  Step 150015  [3.433 sec/step, loss=0.09663, avg_loss=0.09094, mel_loss=0.04382, linear_loss=0.05281]
[2020-05-12 01:48:07.870]  Step 150016  [3.426 sec/step, loss=0.09198, avg_loss=0.09094, mel_loss=0.04090, linear_loss=0.05108]
[2020-05-12 01:48:08.818]  Step 150017  [3.373 sec/step, loss=0.08251, avg_loss=0.09080, mel_loss=0.03591, linear_loss=0.04661]
[2020-05-12 01:48:10.419]  Step 150018  [3.362 sec/step, loss=0.09277, avg_loss=0.09081, mel_loss=0.04093, linear_loss=0.05184]
[2020-05-12 01:48:13.132]  Step 150019  [3.349 sec/step, loss=0.09496, avg_loss=0.09080, mel_loss=0.04265, linear_loss=0.05231]
[2020-05-12 01:48:14.776]  Generated 32 batches of size 32 in 1.639 sec
[2020-05-12 01:48:20.402]  Step 150020  [3.397 sec/step, loss=0.09851, avg_loss=0.09085, mel_loss=0.04553, linear_loss=0.05298]
[2020-05-12 01:48:28.854]  Step 150021  [3.335 sec/step, loss=0.09822, avg_loss=0.09107, mel_loss=0.04576, linear_loss=0.05246]
[2020-05-12 01:48:30.626]  Step 150022  [3.316 sec/step, loss=0.09037, avg_loss=0.09099, mel_loss=0.03945, linear_loss=0.05091]
[2020-05-12 01:48:33.740]  Step 150023  [3.329 sec/step, loss=0.09796, avg_loss=0.09106, mel_loss=0.04427, linear_loss=0.05369]
[2020-05-12 01:48:39.312]  Step 150024  [3.313 sec/step, loss=0.09763, avg_loss=0.09104, mel_loss=0.04472, linear_loss=0.05291]
[2020-05-12 01:48:40.364]  Step 150025  [3.287 sec/step, loss=0.08521, avg_loss=0.09093, mel_loss=0.03714, linear_loss=0.04808]
[2020-05-12 01:48:45.070]  Step 150026  [3.318 sec/step, loss=0.09773, avg_loss=0.09103, mel_loss=0.04440, linear_loss=0.05333]
[2020-05-12 01:48:45.624]  Step 150027  [3.311 sec/step, loss=0.07264, avg_loss=0.09089, mel_loss=0.03212, linear_loss=0.04051]
[2020-05-12 01:48:49.459]  Step 150028  [3.324 sec/step, loss=0.09663, avg_loss=0.09093, mel_loss=0.04363, linear_loss=0.05301]
[2020-05-12 01:48:52.061]  Step 150029  [3.269 sec/step, loss=0.09376, avg_loss=0.09090, mel_loss=0.04170, linear_loss=0.05206]
[2020-05-12 01:48:53.750]  Step 150030  [3.267 sec/step, loss=0.08894, avg_loss=0.09089, mel_loss=0.03937, linear_loss=0.04957]
[2020-05-12 01:48:54.944]  Step 150031  [3.268 sec/step, loss=0.08386, avg_loss=0.09087, mel_loss=0.03698, linear_loss=0.04687]
[2020-05-12 01:48:58.492]  Step 150032  [3.290 sec/step, loss=0.09902, avg_loss=0.09097, mel_loss=0.04475, linear_loss=0.05427]
[2020-05-12 01:49:02.164]  Step 150033  [3.318 sec/step, loss=0.09713, avg_loss=0.09115, mel_loss=0.04379, linear_loss=0.05334]
[2020-05-12 01:49:04.167]  Step 150034  [3.308 sec/step, loss=0.09166, avg_loss=0.09110, mel_loss=0.04050, linear_loss=0.05117]
[2020-05-12 01:49:07.259]  Step 150035  [3.291 sec/step, loss=0.09577, avg_loss=0.09109, mel_loss=0.04323, linear_loss=0.05254]
[2020-05-12 01:49:09.431]  Step 150036  [3.249 sec/step, loss=0.09126, avg_loss=0.09101, mel_loss=0.04042, linear_loss=0.05084]
[2020-05-12 01:49:11.727]  Step 150037  [3.253 sec/step, loss=0.09253, avg_loss=0.09103, mel_loss=0.04134, linear_loss=0.05118]
[2020-05-12 01:49:16.057]  Step 150038  [3.222 sec/step, loss=0.09614, avg_loss=0.09099, mel_loss=0.04366, linear_loss=0.05249]
[2020-05-12 01:49:16.952]  Step 150039  [3.164 sec/step, loss=0.08295, avg_loss=0.09084, mel_loss=0.03600, linear_loss=0.04694]
[2020-05-12 01:49:24.345]  Step 150040  [3.196 sec/step, loss=0.09924, avg_loss=0.09087, mel_loss=0.04594, linear_loss=0.05330]
[2020-05-12 01:49:25.794]  Step 150041  [3.184 sec/step, loss=0.08624, avg_loss=0.09079, mel_loss=0.03777, linear_loss=0.04847]
[2020-05-12 01:49:27.590]  Step 150042  [3.188 sec/step, loss=0.09112, avg_loss=0.09083, mel_loss=0.03984, linear_loss=0.05127]
[2020-05-12 01:49:28.402]  Step 150043  [3.184 sec/step, loss=0.07700, avg_loss=0.09075, mel_loss=0.03335, linear_loss=0.04365]
[2020-05-12 01:49:42.651]  Step 150044  [3.290 sec/step, loss=0.07892, avg_loss=0.09054, mel_loss=0.03773, linear_loss=0.04119]
[2020-05-12 01:49:44.180]  Step 150045  [3.288 sec/step, loss=0.09014, avg_loss=0.09053, mel_loss=0.03996, linear_loss=0.05018]
[2020-05-12 01:49:44.743]  Step 150046  [3.282 sec/step, loss=0.07232, avg_loss=0.09043, mel_loss=0.03272, linear_loss=0.03960]
[2020-05-12 01:49:46.083]  Step 150047  [3.209 sec/step, loss=0.08680, avg_loss=0.09034, mel_loss=0.03813, linear_loss=0.04867]
[2020-05-12 01:49:48.506]  Step 150048  [3.199 sec/step, loss=0.09323, avg_loss=0.09032, mel_loss=0.04116, linear_loss=0.05207]
[2020-05-12 01:49:50.435]  Step 150049  [3.201 sec/step, loss=0.09120, avg_loss=0.09032, mel_loss=0.04045, linear_loss=0.05075]
[2020-05-12 01:49:57.155]  Step 150050  [3.221 sec/step, loss=0.10020, avg_loss=0.09035, mel_loss=0.04622, linear_loss=0.05398]
[2020-05-12 01:49:57.155]  Writing summary at step: 150050
[2020-05-12 01:49:57.921]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150050
[2020-05-12 01:49:59.318]  Saving audio and alignment...
[2020-05-12 01:50:01.399]  Generated 32 batches of size 32 in 1.546 sec
[2020-05-12 01:50:04.784]  Input: 어쩌고저쩌고 등락을 거듭했던 국제유가가~_______________________________
[2020-05-12 01:50:05.828]  Step 150051  [3.206 sec/step, loss=0.08725, avg_loss=0.09031, mel_loss=0.03754, linear_loss=0.04971]
[2020-05-12 01:50:06.869]  Step 150052  [3.208 sec/step, loss=0.08100, avg_loss=0.09029, mel_loss=0.03576, linear_loss=0.04525]
[2020-05-12 01:50:15.232]  Step 150053  [3.260 sec/step, loss=0.09758, avg_loss=0.09030, mel_loss=0.04531, linear_loss=0.05227]
[2020-05-12 01:50:20.906]  Step 150054  [3.301 sec/step, loss=0.09820, avg_loss=0.09037, mel_loss=0.04502, linear_loss=0.05319]
[2020-05-12 01:50:24.220]  Step 150055  [3.314 sec/step, loss=0.09685, avg_loss=0.09043, mel_loss=0.04339, linear_loss=0.05346]
[2020-05-12 01:50:29.172]  Step 150056  [3.311 sec/step, loss=0.09731, avg_loss=0.09043, mel_loss=0.04413, linear_loss=0.05318]
[2020-05-12 01:50:32.193]  Step 150057  [3.317 sec/step, loss=0.09687, avg_loss=0.09049, mel_loss=0.04333, linear_loss=0.05354]
[2020-05-12 01:50:37.736]  Step 150058  [3.327 sec/step, loss=0.09707, avg_loss=0.09049, mel_loss=0.04437, linear_loss=0.05270]
[2020-05-12 01:50:39.444]  Step 150059  [3.205 sec/step, loss=0.09170, avg_loss=0.09064, mel_loss=0.04029, linear_loss=0.05141]
[2020-05-12 01:50:43.980]  Step 150060  [3.215 sec/step, loss=0.09825, avg_loss=0.09067, mel_loss=0.04484, linear_loss=0.05342]
[2020-05-12 01:50:47.602]  Step 150061  [3.195 sec/step, loss=0.09790, avg_loss=0.09067, mel_loss=0.04413, linear_loss=0.05377]
[2020-05-12 01:50:48.402]  Step 150062  [3.174 sec/step, loss=0.07880, avg_loss=0.09050, mel_loss=0.03415, linear_loss=0.04465]
[2020-05-12 01:50:53.907]  Step 150063  [3.221 sec/step, loss=0.09837, avg_loss=0.09075, mel_loss=0.04517, linear_loss=0.05320]
[2020-05-12 01:50:56.614]  Step 150064  [3.233 sec/step, loss=0.09453, avg_loss=0.09084, mel_loss=0.04258, linear_loss=0.05194]
[2020-05-12 01:50:58.774]  Step 150065  [3.246 sec/step, loss=0.09276, avg_loss=0.09101, mel_loss=0.04129, linear_loss=0.05147]
[2020-05-12 01:50:59.777]  Step 150066  [3.248 sec/step, loss=0.08204, avg_loss=0.09104, mel_loss=0.03553, linear_loss=0.04651]
[2020-05-12 01:51:00.879]  Step 150067  [3.233 sec/step, loss=0.08380, avg_loss=0.09096, mel_loss=0.03628, linear_loss=0.04753]
[2020-05-12 01:51:14.804]  Step 150068  [3.361 sec/step, loss=0.07434, avg_loss=0.09087, mel_loss=0.03530, linear_loss=0.03904]
[2020-05-12 01:51:16.383]  Step 150069  [3.367 sec/step, loss=0.08774, avg_loss=0.09096, mel_loss=0.03850, linear_loss=0.04924]
[2020-05-12 01:51:17.698]  Step 150070  [3.373 sec/step, loss=0.08701, avg_loss=0.09108, mel_loss=0.03818, linear_loss=0.04882]
[2020-05-12 01:51:23.707]  Step 150071  [3.419 sec/step, loss=0.09759, avg_loss=0.09119, mel_loss=0.04498, linear_loss=0.05261]
[2020-05-12 01:51:26.174]  Step 150072  [3.409 sec/step, loss=0.09273, avg_loss=0.09114, mel_loss=0.04135, linear_loss=0.05138]
[2020-05-12 01:51:28.175]  Step 150073  [3.401 sec/step, loss=0.09153, avg_loss=0.09111, mel_loss=0.04076, linear_loss=0.05077]
[2020-05-12 01:51:32.008]  Step 150074  [3.421 sec/step, loss=0.09853, avg_loss=0.09123, mel_loss=0.04454, linear_loss=0.05399]
[2020-05-12 01:51:39.425]  Step 150075  [3.482 sec/step, loss=0.09851, avg_loss=0.09133, mel_loss=0.04572, linear_loss=0.05280]
[2020-05-12 01:51:40.799]  Step 150076  [3.466 sec/step, loss=0.08772, avg_loss=0.09123, mel_loss=0.03874, linear_loss=0.04899]
[2020-05-12 01:51:42.824]  Step 150077  [3.466 sec/step, loss=0.09232, avg_loss=0.09125, mel_loss=0.04116, linear_loss=0.05116]
[2020-05-12 01:51:43.575]  Step 150078  [3.433 sec/step, loss=0.07303, avg_loss=0.09100, mel_loss=0.03218, linear_loss=0.04085]
[2020-05-12 01:51:46.967]  Step 150079  [3.434 sec/step, loss=0.09489, avg_loss=0.09101, mel_loss=0.04284, linear_loss=0.05205]
[2020-05-12 01:51:51.283]  Step 150080  [3.348 sec/step, loss=0.09693, avg_loss=0.09115, mel_loss=0.04396, linear_loss=0.05297]
[2020-05-12 01:52:00.018]  Step 150081  [3.418 sec/step, loss=0.09663, avg_loss=0.09121, mel_loss=0.04519, linear_loss=0.05144]
[2020-05-12 01:52:01.702]  Generated 32 batches of size 32 in 1.680 sec
[2020-05-12 01:52:05.244]  Step 150082  [3.465 sec/step, loss=0.09775, avg_loss=0.09142, mel_loss=0.04478, linear_loss=0.05296]
[2020-05-12 01:52:07.098]  Step 150083  [3.467 sec/step, loss=0.08787, avg_loss=0.09140, mel_loss=0.03879, linear_loss=0.04908]
[2020-05-12 01:52:08.087]  Step 150084  [3.456 sec/step, loss=0.08080, avg_loss=0.09127, mel_loss=0.03495, linear_loss=0.04585]
[2020-05-12 01:52:09.816]  Step 150085  [3.461 sec/step, loss=0.09085, avg_loss=0.09134, mel_loss=0.03987, linear_loss=0.05099]
[2020-05-12 01:52:10.574]  Step 150086  [3.453 sec/step, loss=0.07287, avg_loss=0.09117, mel_loss=0.03173, linear_loss=0.04114]
[2020-05-12 01:52:13.696]  Step 150087  [3.429 sec/step, loss=0.09816, avg_loss=0.09117, mel_loss=0.04412, linear_loss=0.05403]
[2020-05-12 01:52:17.107]  Step 150088  [3.388 sec/step, loss=0.09757, avg_loss=0.09115, mel_loss=0.04402, linear_loss=0.05356]
[2020-05-12 01:52:18.324]  Step 150089  [3.334 sec/step, loss=0.08690, avg_loss=0.09103, mel_loss=0.03775, linear_loss=0.04916]
[2020-05-12 01:52:21.027]  Step 150090  [3.333 sec/step, loss=0.09230, avg_loss=0.09102, mel_loss=0.04136, linear_loss=0.05093]
[2020-05-12 01:52:27.814]  Step 150091  [3.349 sec/step, loss=0.09826, avg_loss=0.09104, mel_loss=0.04503, linear_loss=0.05323]
[2020-05-12 01:52:34.001]  Step 150092  [3.325 sec/step, loss=0.09677, avg_loss=0.09102, mel_loss=0.04378, linear_loss=0.05300]
[2020-05-12 01:52:37.373]  Step 150093  [3.325 sec/step, loss=0.09098, avg_loss=0.09096, mel_loss=0.04028, linear_loss=0.05070]
[2020-05-12 01:52:39.099]  Step 150094  [3.332 sec/step, loss=0.08957, avg_loss=0.09105, mel_loss=0.03940, linear_loss=0.05016]
[2020-05-12 01:52:39.975]  Step 150095  [3.333 sec/step, loss=0.07360, avg_loss=0.09098, mel_loss=0.03208, linear_loss=0.04152]
[2020-05-12 01:52:40.759]  Step 150096  [3.319 sec/step, loss=0.07843, avg_loss=0.09082, mel_loss=0.03405, linear_loss=0.04438]
[2020-05-12 01:52:45.091]  Step 150097  [3.318 sec/step, loss=0.09780, avg_loss=0.09081, mel_loss=0.04442, linear_loss=0.05338]
[2020-05-12 01:52:46.267]  Step 150098  [3.290 sec/step, loss=0.08448, avg_loss=0.09069, mel_loss=0.03697, linear_loss=0.04751]
[2020-05-12 01:52:51.942]  Step 150099  [3.322 sec/step, loss=0.09851, avg_loss=0.09076, mel_loss=0.04481, linear_loss=0.05370]
[2020-05-12 01:52:52.944]  Step 150100  [3.316 sec/step, loss=0.08168, avg_loss=0.09069, mel_loss=0.03553, linear_loss=0.04616]
[2020-05-12 01:52:52.944]  Writing summary at step: 150100
[2020-05-12 01:52:55.685]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150100
[2020-05-12 01:52:57.104]  Saving audio and alignment...
[2020-05-12 01:53:08.816]  Input: 우리 나이로는 환갑을 이미 넘어 칠순을 바라보네요 이러면 사람들이 아 감탄하셨고 벌써 그 아리따운 여배우가 벌써 칠순이야~_____________________
[2020-05-12 01:53:16.603]  Step 150101  [3.383 sec/step, loss=0.09763, avg_loss=0.09084, mel_loss=0.04495, linear_loss=0.05268]
[2020-05-12 01:53:19.977]  Step 150102  [3.395 sec/step, loss=0.09573, avg_loss=0.09087, mel_loss=0.04314, linear_loss=0.05259]
[2020-05-12 01:53:21.711]  Step 150103  [3.393 sec/step, loss=0.08920, avg_loss=0.09085, mel_loss=0.03910, linear_loss=0.05009]
[2020-05-12 01:53:23.350]  Step 150104  [3.396 sec/step, loss=0.09153, avg_loss=0.09088, mel_loss=0.04036, linear_loss=0.05117]
[2020-05-12 01:53:26.411]  Step 150105  [3.392 sec/step, loss=0.09657, avg_loss=0.09088, mel_loss=0.04372, linear_loss=0.05285]
[2020-05-12 01:53:27.831]  Step 150106  [3.356 sec/step, loss=0.08876, avg_loss=0.09078, mel_loss=0.03905, linear_loss=0.04971]
[2020-05-12 01:53:31.473]  Step 150107  [3.356 sec/step, loss=0.09770, avg_loss=0.09078, mel_loss=0.04423, linear_loss=0.05347]
[2020-05-12 01:53:33.681]  Step 150108  [3.370 sec/step, loss=0.09312, avg_loss=0.09090, mel_loss=0.04142, linear_loss=0.05170]
[2020-05-12 01:53:38.278]  Step 150109  [3.403 sec/step, loss=0.09659, avg_loss=0.09103, mel_loss=0.04393, linear_loss=0.05266]
[2020-05-12 01:53:40.772]  Step 150110  [3.399 sec/step, loss=0.09115, avg_loss=0.09099, mel_loss=0.04058, linear_loss=0.05057]
[2020-05-12 01:53:42.100]  Step 150111  [3.378 sec/step, loss=0.08565, avg_loss=0.09089, mel_loss=0.03748, linear_loss=0.04817]
[2020-05-12 01:53:42.685]  Step 150112  [3.320 sec/step, loss=0.06895, avg_loss=0.09061, mel_loss=0.03020, linear_loss=0.03875]
[2020-05-12 01:53:43.812]  Generated 32 batches of size 32 in 1.707 sec
[2020-05-12 01:53:45.614]  Step 150113  [3.219 sec/step, loss=0.09371, avg_loss=0.09070, mel_loss=0.04197, linear_loss=0.05174]
[2020-05-12 01:53:47.615]  Step 150114  [3.230 sec/step, loss=0.09026, avg_loss=0.09085, mel_loss=0.04002, linear_loss=0.05023]
[2020-05-12 01:53:49.477]  Step 150115  [3.205 sec/step, loss=0.09052, avg_loss=0.09079, mel_loss=0.03983, linear_loss=0.05068]
[2020-05-12 01:54:03.807]  Step 150116  [3.324 sec/step, loss=0.07779, avg_loss=0.09064, mel_loss=0.03725, linear_loss=0.04054]
[2020-05-12 01:54:10.380]  Step 150117  [3.380 sec/step, loss=0.09723, avg_loss=0.09079, mel_loss=0.04477, linear_loss=0.05246]
[2020-05-12 01:54:11.478]  Step 150118  [3.375 sec/step, loss=0.08618, avg_loss=0.09072, mel_loss=0.03739, linear_loss=0.04880]
[2020-05-12 01:54:14.879]  Step 150119  [3.382 sec/step, loss=0.09602, avg_loss=0.09074, mel_loss=0.04336, linear_loss=0.05266]
[2020-05-12 01:54:15.868]  Step 150120  [3.319 sec/step, loss=0.08067, avg_loss=0.09056, mel_loss=0.03496, linear_loss=0.04571]
[2020-05-12 01:54:21.816]  Step 150121  [3.294 sec/step, loss=0.10049, avg_loss=0.09058, mel_loss=0.04626, linear_loss=0.05423]
[2020-05-12 01:54:23.642]  Step 150122  [3.295 sec/step, loss=0.09066, avg_loss=0.09058, mel_loss=0.03996, linear_loss=0.05070]
[2020-05-12 01:54:24.623]  Step 150123  [3.274 sec/step, loss=0.08441, avg_loss=0.09045, mel_loss=0.03663, linear_loss=0.04777]
[2020-05-12 01:54:25.184]  Step 150124  [3.223 sec/step, loss=0.07461, avg_loss=0.09022, mel_loss=0.03355, linear_loss=0.04106]
[2020-05-12 01:54:26.602]  Step 150125  [3.227 sec/step, loss=0.08904, avg_loss=0.09026, mel_loss=0.03908, linear_loss=0.04995]
[2020-05-12 01:54:31.516]  Step 150126  [3.229 sec/step, loss=0.09801, avg_loss=0.09026, mel_loss=0.04506, linear_loss=0.05295]
[2020-05-12 01:54:33.236]  Step 150127  [3.241 sec/step, loss=0.09095, avg_loss=0.09044, mel_loss=0.03971, linear_loss=0.05124]
[2020-05-12 01:54:36.234]  Step 150128  [3.232 sec/step, loss=0.09580, avg_loss=0.09043, mel_loss=0.04304, linear_loss=0.05276]
[2020-05-12 01:54:42.891]  Step 150129  [3.273 sec/step, loss=0.10343, avg_loss=0.09053, mel_loss=0.04801, linear_loss=0.05541]
[2020-05-12 01:54:44.208]  Step 150130  [3.269 sec/step, loss=0.08782, avg_loss=0.09052, mel_loss=0.03856, linear_loss=0.04926]
[2020-05-12 01:54:48.181]  Step 150131  [3.297 sec/step, loss=0.09880, avg_loss=0.09067, mel_loss=0.04467, linear_loss=0.05413]
[2020-05-12 01:54:49.386]  Step 150132  [3.274 sec/step, loss=0.08547, avg_loss=0.09053, mel_loss=0.03718, linear_loss=0.04830]
[2020-05-12 01:54:50.188]  Step 150133  [3.245 sec/step, loss=0.07818, avg_loss=0.09034, mel_loss=0.03383, linear_loss=0.04435]
[2020-05-12 01:54:55.716]  Step 150134  [3.280 sec/step, loss=0.09831, avg_loss=0.09041, mel_loss=0.04519, linear_loss=0.05312]
[2020-05-12 01:54:57.292]  Step 150135  [3.265 sec/step, loss=0.09012, avg_loss=0.09035, mel_loss=0.03994, linear_loss=0.05018]
[2020-05-12 01:54:58.000]  Step 150136  [3.250 sec/step, loss=0.07808, avg_loss=0.09022, mel_loss=0.03388, linear_loss=0.04419]
[2020-05-12 01:55:00.539]  Step 150137  [3.253 sec/step, loss=0.09375, avg_loss=0.09023, mel_loss=0.04210, linear_loss=0.05165]
[2020-05-12 01:55:03.952]  Step 150138  [3.244 sec/step, loss=0.09505, avg_loss=0.09022, mel_loss=0.04292, linear_loss=0.05213]
[2020-05-12 01:55:05.281]  Step 150139  [3.248 sec/step, loss=0.08772, avg_loss=0.09027, mel_loss=0.03845, linear_loss=0.04926]
[2020-05-12 01:55:07.651]  Step 150140  [3.198 sec/step, loss=0.09403, avg_loss=0.09022, mel_loss=0.04137, linear_loss=0.05266]
[2020-05-12 01:55:11.853]  Step 150141  [3.225 sec/step, loss=0.09757, avg_loss=0.09033, mel_loss=0.04437, linear_loss=0.05321]
[2020-05-12 01:55:19.814]  Step 150142  [3.287 sec/step, loss=0.09862, avg_loss=0.09041, mel_loss=0.04596, linear_loss=0.05266]
[2020-05-12 01:55:22.969]  Step 150143  [3.310 sec/step, loss=0.09676, avg_loss=0.09060, mel_loss=0.04345, linear_loss=0.05330]
[2020-05-12 01:55:24.701]  Generated 32 batches of size 32 in 1.727 sec
[2020-05-12 01:55:25.911]  Step 150144  [3.197 sec/step, loss=0.09531, avg_loss=0.09077, mel_loss=0.04277, linear_loss=0.05254]
[2020-05-12 01:55:26.812]  Step 150145  [3.191 sec/step, loss=0.08282, avg_loss=0.09069, mel_loss=0.03576, linear_loss=0.04706]
[2020-05-12 01:55:27.886]  Step 150146  [3.196 sec/step, loss=0.08160, avg_loss=0.09079, mel_loss=0.03518, linear_loss=0.04642]
[2020-05-12 01:55:32.380]  Step 150147  [3.228 sec/step, loss=0.09902, avg_loss=0.09091, mel_loss=0.04511, linear_loss=0.05392]
[2020-05-12 01:55:34.708]  Step 150148  [3.227 sec/step, loss=0.09196, avg_loss=0.09090, mel_loss=0.04108, linear_loss=0.05088]
[2020-05-12 01:55:38.304]  Step 150149  [3.243 sec/step, loss=0.09676, avg_loss=0.09095, mel_loss=0.04354, linear_loss=0.05322]
[2020-05-12 01:55:40.439]  Step 150150  [3.198 sec/step, loss=0.09324, avg_loss=0.09088, mel_loss=0.04154, linear_loss=0.05170]
[2020-05-12 01:55:40.439]  Writing summary at step: 150150
[2020-05-12 01:55:53.939]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150150
[2020-05-12 01:55:55.340]  Saving audio and alignment...
[2020-05-12 01:55:58.660]  Input: 난설헌 문화제가 열리고 있다~_______________
[2020-05-12 01:56:02.908]  Step 150151  [3.230 sec/step, loss=0.09501, avg_loss=0.09096, mel_loss=0.04309, linear_loss=0.05192]
[2020-05-12 01:56:05.039]  Step 150152  [3.241 sec/step, loss=0.09249, avg_loss=0.09108, mel_loss=0.04113, linear_loss=0.05137]
[2020-05-12 01:56:09.886]  Step 150153  [3.205 sec/step, loss=0.09759, avg_loss=0.09108, mel_loss=0.04435, linear_loss=0.05324]
[2020-05-12 01:56:12.710]  Step 150154  [3.177 sec/step, loss=0.09418, avg_loss=0.09104, mel_loss=0.04225, linear_loss=0.05194]
[2020-05-12 01:56:21.331]  Step 150155  [3.230 sec/step, loss=0.09591, avg_loss=0.09103, mel_loss=0.04456, linear_loss=0.05135]
[2020-05-12 01:56:23.739]  Step 150156  [3.204 sec/step, loss=0.09241, avg_loss=0.09098, mel_loss=0.04109, linear_loss=0.05133]
[2020-05-12 01:56:24.991]  Step 150157  [3.187 sec/step, loss=0.08209, avg_loss=0.09083, mel_loss=0.03568, linear_loss=0.04641]
[2020-05-12 01:56:30.762]  Step 150158  [3.189 sec/step, loss=0.09886, avg_loss=0.09085, mel_loss=0.04550, linear_loss=0.05335]
[2020-05-12 01:56:34.427]  Step 150159  [3.209 sec/step, loss=0.09756, avg_loss=0.09091, mel_loss=0.04393, linear_loss=0.05363]
[2020-05-12 01:56:36.311]  Step 150160  [3.182 sec/step, loss=0.09340, avg_loss=0.09086, mel_loss=0.04104, linear_loss=0.05236]
[2020-05-12 01:56:38.071]  Step 150161  [3.163 sec/step, loss=0.08949, avg_loss=0.09077, mel_loss=0.03945, linear_loss=0.05005]
[2020-05-12 01:56:42.607]  Step 150162  [3.201 sec/step, loss=0.09822, avg_loss=0.09097, mel_loss=0.04464, linear_loss=0.05358]
[2020-05-12 01:56:44.205]  Step 150163  [3.162 sec/step, loss=0.08868, avg_loss=0.09087, mel_loss=0.03903, linear_loss=0.04965]
[2020-05-12 01:56:44.979]  Step 150164  [3.142 sec/step, loss=0.07309, avg_loss=0.09066, mel_loss=0.03184, linear_loss=0.04126]
[2020-05-12 01:56:45.767]  Step 150165  [3.129 sec/step, loss=0.07835, avg_loss=0.09051, mel_loss=0.03357, linear_loss=0.04477]
[2020-05-12 01:56:53.156]  Step 150166  [3.193 sec/step, loss=0.09617, avg_loss=0.09065, mel_loss=0.04446, linear_loss=0.05171]
[2020-05-12 01:56:54.141]  Step 150167  [3.191 sec/step, loss=0.07955, avg_loss=0.09061, mel_loss=0.03449, linear_loss=0.04505]
[2020-05-12 01:56:57.578]  Step 150168  [3.087 sec/step, loss=0.09356, avg_loss=0.09080, mel_loss=0.04203, linear_loss=0.05153]
[2020-05-12 01:56:58.678]  Step 150169  [3.082 sec/step, loss=0.08228, avg_loss=0.09075, mel_loss=0.03598, linear_loss=0.04630]
[2020-05-12 01:57:02.018]  Step 150170  [3.102 sec/step, loss=0.09573, avg_loss=0.09084, mel_loss=0.04296, linear_loss=0.05277]
[2020-05-12 01:57:04.036]  Step 150171  [3.062 sec/step, loss=0.09072, avg_loss=0.09077, mel_loss=0.04024, linear_loss=0.05047]
[2020-05-12 01:57:04.992]  Step 150172  [3.047 sec/step, loss=0.08386, avg_loss=0.09068, mel_loss=0.03624, linear_loss=0.04762]
[2020-05-12 01:57:06.321]  Step 150173  [3.040 sec/step, loss=0.08749, avg_loss=0.09064, mel_loss=0.03829, linear_loss=0.04921]
[2020-05-12 01:57:07.807]  Step 150174  [3.017 sec/step, loss=0.08819, avg_loss=0.09053, mel_loss=0.03902, linear_loss=0.04918]
[2020-05-12 01:57:08.194]  Generated 32 batches of size 32 in 1.867 sec
[2020-05-12 01:57:21.860]  Step 150175  [3.083 sec/step, loss=0.07679, avg_loss=0.09032, mel_loss=0.03669, linear_loss=0.04010]
[2020-05-12 01:57:24.132]  Step 150176  [3.092 sec/step, loss=0.09169, avg_loss=0.09036, mel_loss=0.04094, linear_loss=0.05075]
[2020-05-12 01:57:29.287]  Step 150177  [3.123 sec/step, loss=0.09848, avg_loss=0.09042, mel_loss=0.04515, linear_loss=0.05333]
[2020-05-12 01:57:32.659]  Step 150178  [3.150 sec/step, loss=0.09684, avg_loss=0.09066, mel_loss=0.04368, linear_loss=0.05316]
[2020-05-12 01:57:34.298]  Step 150179  [3.132 sec/step, loss=0.08955, avg_loss=0.09060, mel_loss=0.03936, linear_loss=0.05019]
[2020-05-12 01:57:36.869]  Step 150180  [3.115 sec/step, loss=0.09372, avg_loss=0.09057, mel_loss=0.04203, linear_loss=0.05169]
[2020-05-12 01:57:37.423]  Step 150181  [3.033 sec/step, loss=0.07019, avg_loss=0.09031, mel_loss=0.03096, linear_loss=0.03922]
[2020-05-12 01:57:40.961]  Step 150182  [3.016 sec/step, loss=0.09709, avg_loss=0.09030, mel_loss=0.04380, linear_loss=0.05329]
[2020-05-12 01:57:43.117]  Step 150183  [3.019 sec/step, loss=0.09064, avg_loss=0.09033, mel_loss=0.04037, linear_loss=0.05027]
[2020-05-12 01:57:43.862]  Step 150184  [3.017 sec/step, loss=0.07248, avg_loss=0.09024, mel_loss=0.03236, linear_loss=0.04011]
[2020-05-12 01:57:47.500]  Step 150185  [3.036 sec/step, loss=0.09945, avg_loss=0.09033, mel_loss=0.04517, linear_loss=0.05428]
[2020-05-12 01:57:51.884]  Step 150186  [3.072 sec/step, loss=0.09641, avg_loss=0.09057, mel_loss=0.04371, linear_loss=0.05270]
[2020-05-12 01:57:55.233]  Step 150187  [3.074 sec/step, loss=0.09551, avg_loss=0.09054, mel_loss=0.04307, linear_loss=0.05244]
[2020-05-12 01:58:00.713]  Step 150188  [3.095 sec/step, loss=0.09671, avg_loss=0.09053, mel_loss=0.04427, linear_loss=0.05243]
[2020-05-12 01:58:05.348]  Step 150189  [3.129 sec/step, loss=0.09827, avg_loss=0.09064, mel_loss=0.04482, linear_loss=0.05346]
[2020-05-12 01:58:08.319]  Step 150190  [3.132 sec/step, loss=0.09619, avg_loss=0.09068, mel_loss=0.04309, linear_loss=0.05310]
[2020-05-12 01:58:22.754]  Step 150191  [3.208 sec/step, loss=0.07802, avg_loss=0.09048, mel_loss=0.03747, linear_loss=0.04055]
[2020-05-12 01:58:28.605]  Step 150192  [3.205 sec/step, loss=0.09782, avg_loss=0.09049, mel_loss=0.04480, linear_loss=0.05302]
[2020-05-12 01:58:31.757]  Step 150193  [3.203 sec/step, loss=0.09473, avg_loss=0.09053, mel_loss=0.04229, linear_loss=0.05244]
[2020-05-12 01:58:33.862]  Step 150194  [3.206 sec/step, loss=0.09110, avg_loss=0.09054, mel_loss=0.04067, linear_loss=0.05043]
[2020-05-12 01:58:36.621]  Step 150195  [3.225 sec/step, loss=0.09298, avg_loss=0.09074, mel_loss=0.04172, linear_loss=0.05126]
[2020-05-12 01:58:38.429]  Step 150196  [3.236 sec/step, loss=0.08777, avg_loss=0.09083, mel_loss=0.03839, linear_loss=0.04939]
[2020-05-12 01:58:45.292]  Step 150197  [3.261 sec/step, loss=0.10286, avg_loss=0.09088, mel_loss=0.04771, linear_loss=0.05514]
[2020-05-12 01:58:46.921]  Step 150198  [3.265 sec/step, loss=0.08899, avg_loss=0.09093, mel_loss=0.03934, linear_loss=0.04966]
[2020-05-12 01:58:48.364]  Step 150199  [3.223 sec/step, loss=0.08715, avg_loss=0.09081, mel_loss=0.03825, linear_loss=0.04889]
[2020-05-12 01:58:51.029]  Step 150200  [3.240 sec/step, loss=0.09142, avg_loss=0.09091, mel_loss=0.04046, linear_loss=0.05096]
[2020-05-12 01:58:51.029]  Writing summary at step: 150200
[2020-05-12 01:58:53.029]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150200
[2020-05-12 01:58:54.473]  Saving audio and alignment...
[2020-05-12 01:58:56.786]  Input: 몽유광상산은~_____________
[2020-05-12 01:58:58.508]  Step 150201  [3.179 sec/step, loss=0.08936, avg_loss=0.09083, mel_loss=0.03932, linear_loss=0.05004]
[2020-05-12 01:59:02.476]  Step 150202  [3.185 sec/step, loss=0.09616, avg_loss=0.09083, mel_loss=0.04364, linear_loss=0.05252]
[2020-05-12 01:59:03.347]  Step 150203  [3.176 sec/step, loss=0.07988, avg_loss=0.09074, mel_loss=0.03462, linear_loss=0.04525]
[2020-05-12 01:59:05.086]  Generated 32 batches of size 32 in 1.733 sec
[2020-05-12 01:59:10.771]  Step 150204  [3.234 sec/step, loss=0.10034, avg_loss=0.09083, mel_loss=0.04653, linear_loss=0.05381]
[2020-05-12 01:59:11.808]  Step 150205  [3.214 sec/step, loss=0.08279, avg_loss=0.09069, mel_loss=0.03603, linear_loss=0.04676]
[2020-05-12 01:59:12.553]  Step 150206  [3.207 sec/step, loss=0.07655, avg_loss=0.09057, mel_loss=0.03327, linear_loss=0.04328]
[2020-05-12 01:59:15.879]  Step 150207  [3.204 sec/step, loss=0.09746, avg_loss=0.09056, mel_loss=0.04390, linear_loss=0.05356]
[2020-05-12 01:59:16.632]  Step 150208  [3.189 sec/step, loss=0.07762, avg_loss=0.09041, mel_loss=0.03348, linear_loss=0.04414]
[2020-05-12 01:59:25.263]  Step 150209  [3.230 sec/step, loss=0.09933, avg_loss=0.09044, mel_loss=0.04648, linear_loss=0.05285]
[2020-05-12 01:59:27.662]  Step 150210  [3.229 sec/step, loss=0.09272, avg_loss=0.09045, mel_loss=0.04124, linear_loss=0.05149]
[2020-05-12 01:59:28.961]  Step 150211  [3.229 sec/step, loss=0.08788, avg_loss=0.09048, mel_loss=0.03793, linear_loss=0.04995]
[2020-05-12 01:59:30.086]  Step 150212  [3.234 sec/step, loss=0.08307, avg_loss=0.09062, mel_loss=0.03625, linear_loss=0.04682]
[2020-05-12 01:59:31.903]  Step 150213  [3.223 sec/step, loss=0.08963, avg_loss=0.09058, mel_loss=0.03946, linear_loss=0.05017]
[2020-05-12 01:59:36.126]  Step 150214  [3.245 sec/step, loss=0.09795, avg_loss=0.09065, mel_loss=0.04430, linear_loss=0.05365]
[2020-05-12 01:59:38.175]  Step 150215  [3.247 sec/step, loss=0.09214, avg_loss=0.09067, mel_loss=0.04083, linear_loss=0.05131]
[2020-05-12 01:59:39.504]  Step 150216  [3.117 sec/step, loss=0.08327, avg_loss=0.09072, mel_loss=0.03656, linear_loss=0.04671]
[2020-05-12 01:59:42.172]  Step 150217  [3.078 sec/step, loss=0.09295, avg_loss=0.09068, mel_loss=0.04157, linear_loss=0.05138]
[2020-05-12 01:59:45.599]  Step 150218  [3.101 sec/step, loss=0.09596, avg_loss=0.09078, mel_loss=0.04353, linear_loss=0.05242]
[2020-05-12 01:59:49.198]  Step 150219  [3.103 sec/step, loss=0.09631, avg_loss=0.09078, mel_loss=0.04332, linear_loss=0.05300]
[2020-05-12 01:59:49.996]  Step 150220  [3.101 sec/step, loss=0.07818, avg_loss=0.09076, mel_loss=0.03391, linear_loss=0.04428]
[2020-05-12 01:59:51.694]  Step 150221  [3.059 sec/step, loss=0.09066, avg_loss=0.09066, mel_loss=0.04001, linear_loss=0.05066]
[2020-05-12 01:59:52.251]  Step 150222  [3.046 sec/step, loss=0.07117, avg_loss=0.09046, mel_loss=0.03138, linear_loss=0.03979]
[2020-05-12 01:59:53.421]  Step 150223  [3.048 sec/step, loss=0.08349, avg_loss=0.09045, mel_loss=0.03620, linear_loss=0.04729]
[2020-05-12 01:59:55.804]  Step 150224  [3.066 sec/step, loss=0.09388, avg_loss=0.09065, mel_loss=0.04170, linear_loss=0.05219]
[2020-05-12 02:00:00.464]  Step 150225  [3.099 sec/step, loss=0.09860, avg_loss=0.09074, mel_loss=0.04495, linear_loss=0.05365]
[2020-05-12 02:00:03.422]  Step 150226  [3.079 sec/step, loss=0.09428, avg_loss=0.09071, mel_loss=0.04204, linear_loss=0.05223]
[2020-05-12 02:00:11.809]  Step 150227  [3.146 sec/step, loss=0.09735, avg_loss=0.09077, mel_loss=0.04549, linear_loss=0.05187]
[2020-05-12 02:00:12.466]  Step 150228  [3.122 sec/step, loss=0.07413, avg_loss=0.09055, mel_loss=0.03297, linear_loss=0.04116]
[2020-05-12 02:00:16.493]  Step 150229  [3.096 sec/step, loss=0.09703, avg_loss=0.09049, mel_loss=0.04373, linear_loss=0.05330]
[2020-05-12 02:00:29.420]  Step 150230  [3.212 sec/step, loss=0.08394, avg_loss=0.09045, mel_loss=0.03983, linear_loss=0.04411]
[2020-05-12 02:00:30.470]  Step 150231  [3.183 sec/step, loss=0.08621, avg_loss=0.09032, mel_loss=0.03739, linear_loss=0.04882]
[2020-05-12 02:00:31.452]  Step 150232  [3.181 sec/step, loss=0.08001, avg_loss=0.09027, mel_loss=0.03442, linear_loss=0.04559]
[2020-05-12 02:00:33.644]  Step 150233  [3.195 sec/step, loss=0.09087, avg_loss=0.09040, mel_loss=0.04035, linear_loss=0.05052]
[2020-05-12 02:00:34.986]  Step 150234  [3.153 sec/step, loss=0.08912, avg_loss=0.09030, mel_loss=0.03894, linear_loss=0.05018]
[2020-05-12 02:00:40.565]  Step 150235  [3.193 sec/step, loss=0.09814, avg_loss=0.09038, mel_loss=0.04492, linear_loss=0.05323]
[2020-05-12 02:00:42.356]  Generated 32 batches of size 32 in 1.785 sec
[2020-05-12 02:00:42.625]  Step 150236  [3.206 sec/step, loss=0.09108, avg_loss=0.09051, mel_loss=0.04062, linear_loss=0.05046]
[2020-05-12 02:00:45.979]  Step 150237  [3.214 sec/step, loss=0.09753, avg_loss=0.09055, mel_loss=0.04407, linear_loss=0.05345]
[2020-05-12 02:00:53.549]  Step 150238  [3.256 sec/step, loss=0.09737, avg_loss=0.09058, mel_loss=0.04512, linear_loss=0.05225]
[2020-05-12 02:00:56.575]  Step 150239  [3.273 sec/step, loss=0.09487, avg_loss=0.09065, mel_loss=0.04260, linear_loss=0.05227]
[2020-05-12 02:01:02.205]  Step 150240  [3.306 sec/step, loss=0.09876, avg_loss=0.09069, mel_loss=0.04528, linear_loss=0.05348]
[2020-05-12 02:01:03.832]  Step 150241  [3.280 sec/step, loss=0.08982, avg_loss=0.09062, mel_loss=0.03980, linear_loss=0.05002]
[2020-05-12 02:01:09.934]  Step 150242  [3.261 sec/step, loss=0.09732, avg_loss=0.09060, mel_loss=0.04489, linear_loss=0.05243]
[2020-05-12 02:01:10.863]  Step 150243  [3.239 sec/step, loss=0.08493, avg_loss=0.09049, mel_loss=0.03694, linear_loss=0.04799]
[2020-05-12 02:01:12.300]  Step 150244  [3.224 sec/step, loss=0.08878, avg_loss=0.09042, mel_loss=0.03907, linear_loss=0.04971]
[2020-05-12 02:01:14.617]  Step 150245  [3.238 sec/step, loss=0.09158, avg_loss=0.09051, mel_loss=0.04074, linear_loss=0.05083]
[2020-05-12 02:01:15.940]  Step 150246  [3.241 sec/step, loss=0.08835, avg_loss=0.09058, mel_loss=0.03887, linear_loss=0.04948]
[2020-05-12 02:01:17.917]  Step 150247  [3.215 sec/step, loss=0.09065, avg_loss=0.09049, mel_loss=0.04014, linear_loss=0.05051]
[2020-05-12 02:01:19.079]  Step 150248  [3.204 sec/step, loss=0.08659, avg_loss=0.09044, mel_loss=0.03789, linear_loss=0.04870]
[2020-05-12 02:01:21.933]  Step 150249  [3.196 sec/step, loss=0.09406, avg_loss=0.09041, mel_loss=0.04244, linear_loss=0.05162]
[2020-05-12 02:01:34.120]  Step 150250  [3.297 sec/step, loss=0.08544, avg_loss=0.09033, mel_loss=0.04046, linear_loss=0.04498]
[2020-05-12 02:01:34.120]  Writing summary at step: 150250
[2020-05-12 02:01:41.122]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150250
[2020-05-12 02:01:42.581]  Saving audio and alignment...
[2020-05-12 02:01:48.041]  Input: 강조하고자 하는 단어 키워드 앞에서는 반드시 포즈를 주세요~_________
[2020-05-12 02:01:48.599]  Step 150251  [3.260 sec/step, loss=0.07055, avg_loss=0.09009, mel_loss=0.03112, linear_loss=0.03942]
[2020-05-12 02:01:52.917]  Step 150252  [3.282 sec/step, loss=0.09658, avg_loss=0.09013, mel_loss=0.04395, linear_loss=0.05263]
[2020-05-12 02:01:54.231]  Step 150253  [3.246 sec/step, loss=0.08848, avg_loss=0.09004, mel_loss=0.03885, linear_loss=0.04964]
[2020-05-12 02:01:55.960]  Step 150254  [3.235 sec/step, loss=0.08773, avg_loss=0.08997, mel_loss=0.03880, linear_loss=0.04893]
[2020-05-12 02:02:00.536]  Step 150255  [3.195 sec/step, loss=0.09847, avg_loss=0.09000, mel_loss=0.04463, linear_loss=0.05384]
[2020-05-12 02:02:02.089]  Step 150256  [3.186 sec/step, loss=0.08681, avg_loss=0.08994, mel_loss=0.03773, linear_loss=0.04908]
[2020-05-12 02:02:05.151]  Step 150257  [3.205 sec/step, loss=0.09790, avg_loss=0.09010, mel_loss=0.04378, linear_loss=0.05412]
[2020-05-12 02:02:06.971]  Step 150258  [3.165 sec/step, loss=0.08905, avg_loss=0.09000, mel_loss=0.03934, linear_loss=0.04971]
[2020-05-12 02:02:11.865]  Step 150259  [3.177 sec/step, loss=0.09785, avg_loss=0.09001, mel_loss=0.04453, linear_loss=0.05332]
[2020-05-12 02:02:15.852]  Step 150260  [3.198 sec/step, loss=0.09812, avg_loss=0.09005, mel_loss=0.04429, linear_loss=0.05382]
[2020-05-12 02:02:17.866]  Step 150261  [3.201 sec/step, loss=0.09176, avg_loss=0.09008, mel_loss=0.04066, linear_loss=0.05110]
[2020-05-12 02:02:23.140]  Step 150262  [3.208 sec/step, loss=0.09621, avg_loss=0.09006, mel_loss=0.04400, linear_loss=0.05221]
[2020-05-12 02:02:24.781]  Step 150263  [3.209 sec/step, loss=0.08936, avg_loss=0.09006, mel_loss=0.03933, linear_loss=0.05003]
[2020-05-12 02:02:27.207]  Step 150264  [3.225 sec/step, loss=0.09267, avg_loss=0.09026, mel_loss=0.04124, linear_loss=0.05143]
[2020-05-12 02:02:35.506]  Step 150265  [3.300 sec/step, loss=0.09512, avg_loss=0.09043, mel_loss=0.04404, linear_loss=0.05108]
[2020-05-12 02:02:36.370]  Step 150266  [3.235 sec/step, loss=0.07730, avg_loss=0.09024, mel_loss=0.03379, linear_loss=0.04351]
[2020-05-12 02:02:37.269]  Generated 32 batches of size 32 in 1.757 sec
[2020-05-12 02:02:45.707]  Step 150267  [3.319 sec/step, loss=0.09986, avg_loss=0.09044, mel_loss=0.04617, linear_loss=0.05368]
[2020-05-12 02:02:47.490]  Step 150268  [3.302 sec/step, loss=0.08550, avg_loss=0.09036, mel_loss=0.03689, linear_loss=0.04861]
[2020-05-12 02:02:49.121]  Step 150269  [3.307 sec/step, loss=0.08065, avg_loss=0.09034, mel_loss=0.03520, linear_loss=0.04545]
[2020-05-12 02:02:52.903]  Step 150270  [3.312 sec/step, loss=0.09541, avg_loss=0.09034, mel_loss=0.04271, linear_loss=0.05271]
[2020-05-12 02:02:53.800]  Step 150271  [3.301 sec/step, loss=0.07199, avg_loss=0.09015, mel_loss=0.03143, linear_loss=0.04056]
[2020-05-12 02:02:57.562]  Step 150272  [3.329 sec/step, loss=0.09825, avg_loss=0.09030, mel_loss=0.04441, linear_loss=0.05384]
[2020-05-12 02:02:58.547]  Step 150273  [3.325 sec/step, loss=0.07906, avg_loss=0.09021, mel_loss=0.03440, linear_loss=0.04466]
[2020-05-12 02:03:01.106]  Step 150274  [3.336 sec/step, loss=0.09379, avg_loss=0.09027, mel_loss=0.04180, linear_loss=0.05199]
[2020-05-12 02:03:10.245]  Step 150275  [3.287 sec/step, loss=0.09791, avg_loss=0.09048, mel_loss=0.04566, linear_loss=0.05225]
[2020-05-12 02:03:11.366]  Step 150276  [3.275 sec/step, loss=0.08497, avg_loss=0.09041, mel_loss=0.03683, linear_loss=0.04814]
[2020-05-12 02:03:16.677]  Step 150277  [3.277 sec/step, loss=0.09841, avg_loss=0.09041, mel_loss=0.04496, linear_loss=0.05345]
[2020-05-12 02:03:19.713]  Step 150278  [3.274 sec/step, loss=0.09674, avg_loss=0.09041, mel_loss=0.04348, linear_loss=0.05326]
[2020-05-12 02:03:22.029]  Step 150279  [3.280 sec/step, loss=0.09423, avg_loss=0.09046, mel_loss=0.04204, linear_loss=0.05220]
[2020-05-12 02:03:27.581]  Step 150280  [3.310 sec/step, loss=0.09923, avg_loss=0.09051, mel_loss=0.04551, linear_loss=0.05372]
[2020-05-12 02:03:29.376]  Step 150281  [3.322 sec/step, loss=0.08906, avg_loss=0.09070, mel_loss=0.03920, linear_loss=0.04986]
[2020-05-12 02:03:31.490]  Step 150282  [3.308 sec/step, loss=0.08996, avg_loss=0.09063, mel_loss=0.03981, linear_loss=0.05015]
[2020-05-12 02:03:32.246]  Step 150283  [3.294 sec/step, loss=0.07388, avg_loss=0.09046, mel_loss=0.03287, linear_loss=0.04101]
[2020-05-12 02:03:34.469]  Step 150284  [3.309 sec/step, loss=0.09132, avg_loss=0.09065, mel_loss=0.04058, linear_loss=0.05074]
[2020-05-12 02:03:35.672]  Step 150285  [3.285 sec/step, loss=0.08480, avg_loss=0.09050, mel_loss=0.03695, linear_loss=0.04785]
[2020-05-12 02:03:37.612]  Step 150286  [3.260 sec/step, loss=0.09243, avg_loss=0.09046, mel_loss=0.04099, linear_loss=0.05144]
[2020-05-12 02:03:41.035]  Step 150287  [3.261 sec/step, loss=0.09569, avg_loss=0.09047, mel_loss=0.04311, linear_loss=0.05258]
[2020-05-12 02:03:42.440]  Step 150288  [3.220 sec/step, loss=0.08777, avg_loss=0.09038, mel_loss=0.03860, linear_loss=0.04917]
[2020-05-12 02:03:43.444]  Step 150289  [3.184 sec/step, loss=0.08270, avg_loss=0.09022, mel_loss=0.03597, linear_loss=0.04673]
[2020-05-12 02:03:44.781]  Step 150290  [3.168 sec/step, loss=0.08746, avg_loss=0.09013, mel_loss=0.03812, linear_loss=0.04934]
[2020-05-12 02:03:51.508]  Step 150291  [3.091 sec/step, loss=0.09838, avg_loss=0.09034, mel_loss=0.04539, linear_loss=0.05299]
[2020-05-12 02:03:55.706]  Step 150292  [3.074 sec/step, loss=0.09670, avg_loss=0.09033, mel_loss=0.04399, linear_loss=0.05271]
[2020-05-12 02:04:10.188]  Step 150293  [3.187 sec/step, loss=0.07770, avg_loss=0.09016, mel_loss=0.03715, linear_loss=0.04055]
[2020-05-12 02:04:14.273]  Step 150294  [3.207 sec/step, loss=0.09654, avg_loss=0.09021, mel_loss=0.04360, linear_loss=0.05294]
[2020-05-12 02:04:16.820]  Step 150295  [3.205 sec/step, loss=0.09171, avg_loss=0.09020, mel_loss=0.04081, linear_loss=0.05091]
[2020-05-12 02:04:18.513]  Step 150296  [3.204 sec/step, loss=0.09201, avg_loss=0.09024, mel_loss=0.04035, linear_loss=0.05166]
[2020-05-12 02:04:19.261]  Step 150297  [3.143 sec/step, loss=0.07537, avg_loss=0.08997, mel_loss=0.03256, linear_loss=0.04281]
[2020-05-12 02:04:20.889]  Step 150298  [3.143 sec/step, loss=0.08933, avg_loss=0.08997, mel_loss=0.03938, linear_loss=0.04994]
[2020-05-12 02:04:20.975]  Generated 32 batches of size 32 in 1.709 sec
[2020-05-12 02:04:24.574]  Step 150299  [3.165 sec/step, loss=0.09625, avg_loss=0.09006, mel_loss=0.04352, linear_loss=0.05273]
[2020-05-12 02:04:25.481]  Step 150300  [3.147 sec/step, loss=0.08320, avg_loss=0.08998, mel_loss=0.03586, linear_loss=0.04734]
[2020-05-12 02:04:25.481]  Writing summary at step: 150300
[2020-05-12 02:04:28.919]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150300
[2020-05-12 02:04:30.373]  Saving audio and alignment...
[2020-05-12 02:04:35.567]  Input: 지금까지 쉰 한 번에 만남을 성공적으로 이어왔으니~______________________
[2020-05-12 02:04:40.291]  Step 150301  [3.178 sec/step, loss=0.09602, avg_loss=0.09004, mel_loss=0.04363, linear_loss=0.05239]
[2020-05-12 02:04:41.090]  Step 150302  [3.146 sec/step, loss=0.07975, avg_loss=0.08988, mel_loss=0.03423, linear_loss=0.04552]
[2020-05-12 02:04:43.833]  Step 150303  [3.165 sec/step, loss=0.09275, avg_loss=0.09001, mel_loss=0.04142, linear_loss=0.05133]
[2020-05-12 02:04:51.419]  Step 150304  [3.166 sec/step, loss=0.09877, avg_loss=0.08999, mel_loss=0.04584, linear_loss=0.05293]
[2020-05-12 02:04:53.834]  Step 150305  [3.180 sec/step, loss=0.09270, avg_loss=0.09009, mel_loss=0.04111, linear_loss=0.05159]
[2020-05-12 02:04:54.451]  Step 150306  [3.179 sec/step, loss=0.07599, avg_loss=0.09009, mel_loss=0.03353, linear_loss=0.04246]
[2020-05-12 02:04:55.257]  Step 150307  [3.153 sec/step, loss=0.07591, avg_loss=0.08987, mel_loss=0.03267, linear_loss=0.04324]
[2020-05-12 02:04:59.828]  Step 150308  [3.192 sec/step, loss=0.09877, avg_loss=0.09008, mel_loss=0.04492, linear_loss=0.05385]
[2020-05-12 02:05:13.774]  Step 150309  [3.245 sec/step, loss=0.07573, avg_loss=0.08985, mel_loss=0.03609, linear_loss=0.03963]
[2020-05-12 02:05:14.326]  Step 150310  [3.226 sec/step, loss=0.06972, avg_loss=0.08962, mel_loss=0.03045, linear_loss=0.03927]
[2020-05-12 02:05:21.591]  Step 150311  [3.286 sec/step, loss=0.09883, avg_loss=0.08973, mel_loss=0.04572, linear_loss=0.05311]
[2020-05-12 02:05:30.112]  Step 150312  [3.360 sec/step, loss=0.09622, avg_loss=0.08986, mel_loss=0.04484, linear_loss=0.05137]
[2020-05-12 02:05:34.152]  Step 150313  [3.382 sec/step, loss=0.09742, avg_loss=0.08994, mel_loss=0.04399, linear_loss=0.05343]
[2020-05-12 02:05:37.006]  Step 150314  [3.368 sec/step, loss=0.09325, avg_loss=0.08989, mel_loss=0.04200, linear_loss=0.05125]
[2020-05-12 02:05:38.181]  Step 150315  [3.360 sec/step, loss=0.08507, avg_loss=0.08982, mel_loss=0.03717, linear_loss=0.04790]
[2020-05-12 02:05:43.422]  Step 150316  [3.399 sec/step, loss=0.09688, avg_loss=0.08995, mel_loss=0.04432, linear_loss=0.05256]
[2020-05-12 02:05:44.860]  Step 150317  [3.387 sec/step, loss=0.08706, avg_loss=0.08989, mel_loss=0.03823, linear_loss=0.04884]
[2020-05-12 02:05:48.535]  Step 150318  [3.389 sec/step, loss=0.09352, avg_loss=0.08987, mel_loss=0.04209, linear_loss=0.05143]
[2020-05-12 02:05:49.411]  Step 150319  [3.362 sec/step, loss=0.07890, avg_loss=0.08970, mel_loss=0.03405, linear_loss=0.04486]
[2020-05-12 02:05:52.439]  Step 150320  [3.384 sec/step, loss=0.09716, avg_loss=0.08989, mel_loss=0.04372, linear_loss=0.05344]
[2020-05-12 02:05:53.960]  Step 150321  [3.382 sec/step, loss=0.08628, avg_loss=0.08984, mel_loss=0.03784, linear_loss=0.04844]
[2020-05-12 02:05:55.618]  Step 150322  [3.393 sec/step, loss=0.08988, avg_loss=0.09003, mel_loss=0.03947, linear_loss=0.05042]
[2020-05-12 02:05:57.651]  Step 150323  [3.402 sec/step, loss=0.09072, avg_loss=0.09010, mel_loss=0.04003, linear_loss=0.05070]
[2020-05-12 02:06:04.499]  Step 150324  [3.447 sec/step, loss=0.09748, avg_loss=0.09014, mel_loss=0.04500, linear_loss=0.05249]
[2020-05-12 02:06:06.494]  Step 150325  [3.420 sec/step, loss=0.08907, avg_loss=0.09004, mel_loss=0.03914, linear_loss=0.04993]
[2020-05-12 02:06:12.320]  Step 150326  [3.449 sec/step, loss=0.09778, avg_loss=0.09008, mel_loss=0.04491, linear_loss=0.05287]
[2020-05-12 02:06:16.501]  Step 150327  [3.407 sec/step, loss=0.09808, avg_loss=0.09008, mel_loss=0.04484, linear_loss=0.05324]
[2020-05-12 02:06:18.245]  Generated 32 batches of size 32 in 1.738 sec
[2020-05-12 02:06:18.346]  Step 150328  [3.418 sec/step, loss=0.09075, avg_loss=0.09025, mel_loss=0.03966, linear_loss=0.05110]
[2020-05-12 02:06:21.798]  Step 150329  [3.413 sec/step, loss=0.09731, avg_loss=0.09025, mel_loss=0.04421, linear_loss=0.05311]
[2020-05-12 02:06:24.449]  Step 150330  [3.310 sec/step, loss=0.09390, avg_loss=0.09035, mel_loss=0.04190, linear_loss=0.05200]
[2020-05-12 02:06:26.635]  Step 150331  [3.321 sec/step, loss=0.09236, avg_loss=0.09041, mel_loss=0.04126, linear_loss=0.05110]
[2020-05-12 02:06:27.752]  Step 150332  [3.323 sec/step, loss=0.08465, avg_loss=0.09046, mel_loss=0.03663, linear_loss=0.04802]
[2020-05-12 02:06:28.769]  Step 150333  [3.311 sec/step, loss=0.08126, avg_loss=0.09037, mel_loss=0.03517, linear_loss=0.04609]
[2020-05-12 02:06:30.891]  Step 150334  [3.319 sec/step, loss=0.09140, avg_loss=0.09039, mel_loss=0.04051, linear_loss=0.05089]
[2020-05-12 02:06:32.224]  Step 150335  [3.276 sec/step, loss=0.08554, avg_loss=0.09026, mel_loss=0.03770, linear_loss=0.04784]
[2020-05-12 02:06:35.552]  Step 150336  [3.289 sec/step, loss=0.09744, avg_loss=0.09033, mel_loss=0.04384, linear_loss=0.05360]
[2020-05-12 02:06:38.811]  Step 150337  [3.288 sec/step, loss=0.09617, avg_loss=0.09031, mel_loss=0.04357, linear_loss=0.05260]
[2020-05-12 02:06:41.103]  Step 150338  [3.235 sec/step, loss=0.09252, avg_loss=0.09026, mel_loss=0.04125, linear_loss=0.05127]
[2020-05-12 02:06:42.349]  Step 150339  [3.217 sec/step, loss=0.08440, avg_loss=0.09016, mel_loss=0.03697, linear_loss=0.04743]
[2020-05-12 02:06:44.776]  Step 150340  [3.185 sec/step, loss=0.09353, avg_loss=0.09011, mel_loss=0.04147, linear_loss=0.05205]
[2020-05-12 02:06:47.795]  Step 150341  [3.199 sec/step, loss=0.09564, avg_loss=0.09016, mel_loss=0.04298, linear_loss=0.05266]
[2020-05-12 02:06:49.464]  Step 150342  [3.155 sec/step, loss=0.09047, avg_loss=0.09010, mel_loss=0.04018, linear_loss=0.05029]
[2020-05-12 02:06:58.109]  Step 150343  [3.232 sec/step, loss=0.09681, avg_loss=0.09021, mel_loss=0.04479, linear_loss=0.05202]
[2020-05-12 02:07:04.072]  Step 150344  [3.277 sec/step, loss=0.09789, avg_loss=0.09031, mel_loss=0.04506, linear_loss=0.05283]
[2020-05-12 02:07:16.990]  Step 150345  [3.383 sec/step, loss=0.08439, avg_loss=0.09023, mel_loss=0.04013, linear_loss=0.04426]
[2020-05-12 02:07:18.730]  Step 150346  [3.388 sec/step, loss=0.08953, avg_loss=0.09025, mel_loss=0.03921, linear_loss=0.05033]
[2020-05-12 02:07:25.981]  Step 150347  [3.440 sec/step, loss=0.09929, avg_loss=0.09033, mel_loss=0.04609, linear_loss=0.05320]
[2020-05-12 02:07:26.982]  Step 150348  [3.439 sec/step, loss=0.08277, avg_loss=0.09029, mel_loss=0.03575, linear_loss=0.04703]
[2020-05-12 02:07:29.898]  Step 150349  [3.439 sec/step, loss=0.09586, avg_loss=0.09031, mel_loss=0.04307, linear_loss=0.05279]
[2020-05-12 02:07:30.993]  Step 150350  [3.328 sec/step, loss=0.08501, avg_loss=0.09031, mel_loss=0.03672, linear_loss=0.04829]
[2020-05-12 02:07:30.993]  Writing summary at step: 150350
[2020-05-12 02:07:35.556]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150350
[2020-05-12 02:07:36.966]  Saving audio and alignment...
[2020-05-12 02:07:39.854]  Input: 솔직히 말해서 저는 잘 모르겠습니다~
[2020-05-12 02:07:41.276]  Step 150351  [3.337 sec/step, loss=0.08624, avg_loss=0.09046, mel_loss=0.03802, linear_loss=0.04822]
[2020-05-12 02:07:44.915]  Step 150352  [3.330 sec/step, loss=0.09868, avg_loss=0.09049, mel_loss=0.04446, linear_loss=0.05422]
[2020-05-12 02:07:46.858]  Step 150353  [3.337 sec/step, loss=0.09113, avg_loss=0.09051, mel_loss=0.04010, linear_loss=0.05102]
[2020-05-12 02:07:51.921]  Step 150354  [3.370 sec/step, loss=0.09707, avg_loss=0.09061, mel_loss=0.04428, linear_loss=0.05279]
[2020-05-12 02:07:54.534]  Step 150355  [3.350 sec/step, loss=0.09444, avg_loss=0.09057, mel_loss=0.04229, linear_loss=0.05215]
[2020-05-12 02:07:56.561]  Step 150356  [3.355 sec/step, loss=0.09041, avg_loss=0.09060, mel_loss=0.04004, linear_loss=0.05036]
[2020-05-12 02:08:00.307]  Step 150357  [3.362 sec/step, loss=0.09779, avg_loss=0.09060, mel_loss=0.04422, linear_loss=0.05357]
[2020-05-12 02:08:01.389]  Step 150358  [3.354 sec/step, loss=0.08311, avg_loss=0.09054, mel_loss=0.03636, linear_loss=0.04676]
[2020-05-12 02:08:01.984]  Generated 32 batches of size 32 in 1.672 sec
[2020-05-12 02:08:06.950]  Step 150359  [3.361 sec/step, loss=0.09940, avg_loss=0.09056, mel_loss=0.04533, linear_loss=0.05407]
[2020-05-12 02:08:09.123]  Step 150360  [3.343 sec/step, loss=0.09362, avg_loss=0.09051, mel_loss=0.04211, linear_loss=0.05151]
[2020-05-12 02:08:09.935]  Step 150361  [3.331 sec/step, loss=0.07980, avg_loss=0.09039, mel_loss=0.03459, linear_loss=0.04521]
[2020-05-12 02:08:10.729]  Step 150362  [3.286 sec/step, loss=0.07428, avg_loss=0.09017, mel_loss=0.03204, linear_loss=0.04224]
[2020-05-12 02:08:11.479]  Step 150363  [3.277 sec/step, loss=0.07543, avg_loss=0.09003, mel_loss=0.03405, linear_loss=0.04138]
[2020-05-12 02:08:12.829]  Step 150364  [3.266 sec/step, loss=0.08825, avg_loss=0.08999, mel_loss=0.03829, linear_loss=0.04996]
[2020-05-12 02:08:16.215]  Step 150365  [3.217 sec/step, loss=0.09492, avg_loss=0.08999, mel_loss=0.04271, linear_loss=0.05221]
[2020-05-12 02:08:20.297]  Step 150366  [3.250 sec/step, loss=0.09760, avg_loss=0.09019, mel_loss=0.04425, linear_loss=0.05335]
[2020-05-12 02:08:23.921]  Step 150367  [3.192 sec/step, loss=0.09613, avg_loss=0.09015, mel_loss=0.04344, linear_loss=0.05269]
[2020-05-12 02:08:24.510]  Step 150368  [3.180 sec/step, loss=0.07048, avg_loss=0.09000, mel_loss=0.03126, linear_loss=0.03922]
[2020-05-12 02:08:29.809]  Step 150369  [3.217 sec/step, loss=0.09965, avg_loss=0.09019, mel_loss=0.04571, linear_loss=0.05394]
[2020-05-12 02:08:37.233]  Step 150370  [3.254 sec/step, loss=0.09907, avg_loss=0.09023, mel_loss=0.04588, linear_loss=0.05319]
[2020-05-12 02:08:39.030]  Step 150371  [3.263 sec/step, loss=0.08990, avg_loss=0.09041, mel_loss=0.03963, linear_loss=0.05027]
[2020-05-12 02:08:41.037]  Step 150372  [3.245 sec/step, loss=0.08937, avg_loss=0.09032, mel_loss=0.03956, linear_loss=0.04980]
[2020-05-12 02:08:44.133]  Step 150373  [3.266 sec/step, loss=0.09654, avg_loss=0.09049, mel_loss=0.04324, linear_loss=0.05330]
[2020-05-12 02:08:45.868]  Step 150374  [3.258 sec/step, loss=0.08962, avg_loss=0.09045, mel_loss=0.03946, linear_loss=0.05016]
[2020-05-12 02:08:48.757]  Step 150375  [3.195 sec/step, loss=0.09246, avg_loss=0.09040, mel_loss=0.04134, linear_loss=0.05112]
[2020-05-12 02:08:52.382]  Step 150376  [3.220 sec/step, loss=0.09759, avg_loss=0.09052, mel_loss=0.04419, linear_loss=0.05340]
[2020-05-12 02:08:53.706]  Step 150377  [3.181 sec/step, loss=0.08418, avg_loss=0.09038, mel_loss=0.03704, linear_loss=0.04714]
[2020-05-12 02:08:55.302]  Step 150378  [3.166 sec/step, loss=0.08845, avg_loss=0.09030, mel_loss=0.03904, linear_loss=0.04941]
[2020-05-12 02:08:59.643]  Step 150379  [3.186 sec/step, loss=0.09777, avg_loss=0.09033, mel_loss=0.04443, linear_loss=0.05334]
[2020-05-12 02:09:02.041]  Step 150380  [3.155 sec/step, loss=0.09300, avg_loss=0.09027, mel_loss=0.04112, linear_loss=0.05189]
[2020-05-12 02:09:04.129]  Step 150381  [3.158 sec/step, loss=0.09403, avg_loss=0.09032, mel_loss=0.04155, linear_loss=0.05248]
[2020-05-12 02:09:05.221]  Step 150382  [3.148 sec/step, loss=0.08452, avg_loss=0.09027, mel_loss=0.03662, linear_loss=0.04790]
[2020-05-12 02:09:19.304]  Step 150383  [3.281 sec/step, loss=0.07618, avg_loss=0.09029, mel_loss=0.03634, linear_loss=0.03984]
[2020-05-12 02:09:25.930]  Step 150384  [3.325 sec/step, loss=0.09850, avg_loss=0.09036, mel_loss=0.04542, linear_loss=0.05309]
[2020-05-12 02:09:26.733]  Step 150385  [3.321 sec/step, loss=0.07815, avg_loss=0.09030, mel_loss=0.03389, linear_loss=0.04426]
[2020-05-12 02:09:27.699]  Step 150386  [3.311 sec/step, loss=0.08581, avg_loss=0.09023, mel_loss=0.03725, linear_loss=0.04856]
[2020-05-12 02:09:30.258]  Step 150387  [3.303 sec/step, loss=0.09475, avg_loss=0.09022, mel_loss=0.04244, linear_loss=0.05231]
[2020-05-12 02:09:30.914]  Step 150388  [3.295 sec/step, loss=0.07365, avg_loss=0.09008, mel_loss=0.03244, linear_loss=0.04121]
[2020-05-12 02:09:34.100]  Step 150389  [3.317 sec/step, loss=0.09648, avg_loss=0.09022, mel_loss=0.04348, linear_loss=0.05300]
[2020-05-12 02:09:35.541]  Step 150390  [3.318 sec/step, loss=0.08618, avg_loss=0.09020, mel_loss=0.03777, linear_loss=0.04841]
[2020-05-12 02:09:35.861]  Generated 32 batches of size 32 in 1.755 sec
[2020-05-12 02:09:37.469]  Step 150391  [3.270 sec/step, loss=0.09010, avg_loss=0.09012, mel_loss=0.03981, linear_loss=0.05029]
[2020-05-12 02:09:42.989]  Step 150392  [3.283 sec/step, loss=0.09816, avg_loss=0.09014, mel_loss=0.04485, linear_loss=0.05332]
[2020-05-12 02:09:51.220]  Step 150393  [3.221 sec/step, loss=0.09611, avg_loss=0.09032, mel_loss=0.04473, linear_loss=0.05138]
[2020-05-12 02:09:55.967]  Step 150394  [3.227 sec/step, loss=0.09716, avg_loss=0.09033, mel_loss=0.04430, linear_loss=0.05286]
[2020-05-12 02:09:57.179]  Step 150395  [3.214 sec/step, loss=0.08382, avg_loss=0.09025, mel_loss=0.03657, linear_loss=0.04725]
[2020-05-12 02:09:58.060]  Step 150396  [3.206 sec/step, loss=0.07953, avg_loss=0.09012, mel_loss=0.03424, linear_loss=0.04529]
[2020-05-12 02:10:02.185]  Step 150397  [3.240 sec/step, loss=0.09584, avg_loss=0.09033, mel_loss=0.04329, linear_loss=0.05256]
[2020-05-12 02:10:04.502]  Step 150398  [3.246 sec/step, loss=0.09364, avg_loss=0.09037, mel_loss=0.04169, linear_loss=0.05195]
[2020-05-12 02:10:05.293]  Step 150399  [3.217 sec/step, loss=0.07710, avg_loss=0.09018, mel_loss=0.03328, linear_loss=0.04382]
[2020-05-12 02:10:06.529]  Step 150400  [3.221 sec/step, loss=0.08664, avg_loss=0.09021, mel_loss=0.03772, linear_loss=0.04892]
[2020-05-12 02:10:06.529]  Writing summary at step: 150400
[2020-05-12 02:10:10.555]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150400
[2020-05-12 02:10:12.013]  Saving audio and alignment...
[2020-05-12 02:10:14.613]  Input: 숫자 오십일회~___________________
[2020-05-12 02:10:27.521]  Step 150401  [3.303 sec/step, loss=0.08389, avg_loss=0.09009, mel_loss=0.03979, linear_loss=0.04410]
[2020-05-12 02:10:33.139]  Step 150402  [3.351 sec/step, loss=0.09806, avg_loss=0.09027, mel_loss=0.04507, linear_loss=0.05299]
[2020-05-12 02:10:38.477]  Step 150403  [3.377 sec/step, loss=0.09796, avg_loss=0.09033, mel_loss=0.04449, linear_loss=0.05348]
[2020-05-12 02:10:47.473]  Step 150404  [3.391 sec/step, loss=0.09801, avg_loss=0.09032, mel_loss=0.04581, linear_loss=0.05220]
[2020-05-12 02:10:49.624]  Step 150405  [3.388 sec/step, loss=0.09112, avg_loss=0.09030, mel_loss=0.04023, linear_loss=0.05089]
[2020-05-12 02:10:51.738]  Step 150406  [3.403 sec/step, loss=0.09176, avg_loss=0.09046, mel_loss=0.04094, linear_loss=0.05083]
[2020-05-12 02:10:54.655]  Step 150407  [3.424 sec/step, loss=0.09697, avg_loss=0.09067, mel_loss=0.04357, linear_loss=0.05340]
[2020-05-12 02:10:57.019]  Step 150408  [3.402 sec/step, loss=0.09321, avg_loss=0.09062, mel_loss=0.04151, linear_loss=0.05170]
[2020-05-12 02:11:00.486]  Step 150409  [3.297 sec/step, loss=0.09685, avg_loss=0.09083, mel_loss=0.04351, linear_loss=0.05333]
[2020-05-12 02:11:06.993]  Step 150410  [3.357 sec/step, loss=0.10093, avg_loss=0.09114, mel_loss=0.04655, linear_loss=0.05439]
[2020-05-12 02:11:07.756]  Step 150411  [3.292 sec/step, loss=0.07970, avg_loss=0.09095, mel_loss=0.03457, linear_loss=0.04513]
[2020-05-12 02:11:08.760]  Step 150412  [3.217 sec/step, loss=0.08110, avg_loss=0.09080, mel_loss=0.03512, linear_loss=0.04597]
[2020-05-12 02:11:13.140]  Step 150413  [3.220 sec/step, loss=0.09739, avg_loss=0.09080, mel_loss=0.04420, linear_loss=0.05319]
[2020-05-12 02:11:18.134]  Step 150414  [3.242 sec/step, loss=0.09559, avg_loss=0.09082, mel_loss=0.04319, linear_loss=0.05240]
[2020-05-12 02:11:26.244]  Step 150415  [3.311 sec/step, loss=0.09950, avg_loss=0.09096, mel_loss=0.04628, linear_loss=0.05322]
[2020-05-12 02:11:27.013]  Step 150416  [3.266 sec/step, loss=0.07347, avg_loss=0.09073, mel_loss=0.03263, linear_loss=0.04084]
[2020-05-12 02:11:28.852]  Step 150417  [3.270 sec/step, loss=0.08885, avg_loss=0.09075, mel_loss=0.03923, linear_loss=0.04962]
[2020-05-12 02:11:29.908]  Step 150418  [3.244 sec/step, loss=0.07946, avg_loss=0.09061, mel_loss=0.03491, linear_loss=0.04455]
[2020-05-12 02:11:31.044]  Step 150419  [3.247 sec/step, loss=0.08165, avg_loss=0.09064, mel_loss=0.03547, linear_loss=0.04618]
[2020-05-12 02:11:32.768]  Generated 32 batches of size 32 in 1.719 sec
[2020-05-12 02:11:33.798]  Step 150420  [3.244 sec/step, loss=0.09245, avg_loss=0.09059, mel_loss=0.04146, linear_loss=0.05099]
[2020-05-12 02:11:35.360]  Step 150421  [3.244 sec/step, loss=0.08992, avg_loss=0.09062, mel_loss=0.03921, linear_loss=0.05071]
[2020-05-12 02:11:38.827]  Step 150422  [3.262 sec/step, loss=0.09454, avg_loss=0.09067, mel_loss=0.04270, linear_loss=0.05183]
[2020-05-12 02:11:42.463]  Step 150423  [3.278 sec/step, loss=0.09799, avg_loss=0.09074, mel_loss=0.04417, linear_loss=0.05381]
[2020-05-12 02:11:44.199]  Step 150424  [3.227 sec/step, loss=0.09129, avg_loss=0.09068, mel_loss=0.04031, linear_loss=0.05098]
[2020-05-12 02:11:46.222]  Step 150425  [3.228 sec/step, loss=0.09173, avg_loss=0.09071, mel_loss=0.04040, linear_loss=0.05133]
[2020-05-12 02:11:49.282]  Step 150426  [3.200 sec/step, loss=0.09768, avg_loss=0.09071, mel_loss=0.04396, linear_loss=0.05373]
[2020-05-12 02:11:50.617]  Step 150427  [3.171 sec/step, loss=0.08741, avg_loss=0.09060, mel_loss=0.03878, linear_loss=0.04863]
[2020-05-12 02:11:53.215]  Step 150428  [3.179 sec/step, loss=0.09322, avg_loss=0.09063, mel_loss=0.04182, linear_loss=0.05140]
[2020-05-12 02:11:54.541]  Step 150429  [3.158 sec/step, loss=0.08792, avg_loss=0.09053, mel_loss=0.03853, linear_loss=0.04940]
[2020-05-12 02:11:55.705]  Step 150430  [3.143 sec/step, loss=0.08361, avg_loss=0.09043, mel_loss=0.03654, linear_loss=0.04707]
[2020-05-12 02:11:58.158]  Step 150431  [3.146 sec/step, loss=0.09297, avg_loss=0.09044, mel_loss=0.04112, linear_loss=0.05185]
[2020-05-12 02:11:59.161]  Step 150432  [3.144 sec/step, loss=0.08119, avg_loss=0.09040, mel_loss=0.03507, linear_loss=0.04612]
[2020-05-12 02:12:07.622]  Step 150433  [3.219 sec/step, loss=0.09599, avg_loss=0.09055, mel_loss=0.04468, linear_loss=0.05131]
[2020-05-12 02:12:09.973]  Step 150434  [3.221 sec/step, loss=0.09257, avg_loss=0.09056, mel_loss=0.04105, linear_loss=0.05152]
[2020-05-12 02:12:13.137]  Step 150435  [3.239 sec/step, loss=0.09603, avg_loss=0.09066, mel_loss=0.04320, linear_loss=0.05283]
[2020-05-12 02:12:17.729]  Step 150436  [3.252 sec/step, loss=0.09928, avg_loss=0.09068, mel_loss=0.04542, linear_loss=0.05386]
[2020-05-12 02:12:18.541]  Step 150437  [3.228 sec/step, loss=0.07906, avg_loss=0.09051, mel_loss=0.03404, linear_loss=0.04502]
[2020-05-12 02:12:19.830]  Step 150438  [3.218 sec/step, loss=0.08760, avg_loss=0.09046, mel_loss=0.03827, linear_loss=0.04932]
[2020-05-12 02:12:24.698]  Step 150439  [3.254 sec/step, loss=0.09807, avg_loss=0.09060, mel_loss=0.04466, linear_loss=0.05342]
[2020-05-12 02:12:27.606]  Step 150440  [3.259 sec/step, loss=0.09557, avg_loss=0.09062, mel_loss=0.04302, linear_loss=0.05255]
[2020-05-12 02:12:29.158]  Step 150441  [3.244 sec/step, loss=0.08866, avg_loss=0.09055, mel_loss=0.03913, linear_loss=0.04953]
[2020-05-12 02:12:30.172]  Step 150442  [3.237 sec/step, loss=0.08218, avg_loss=0.09047, mel_loss=0.03556, linear_loss=0.04661]
[2020-05-12 02:12:30.925]  Step 150443  [3.158 sec/step, loss=0.07528, avg_loss=0.09025, mel_loss=0.03362, linear_loss=0.04166]
[2020-05-12 02:12:38.381]  Step 150444  [3.173 sec/step, loss=0.09940, avg_loss=0.09027, mel_loss=0.04612, linear_loss=0.05328]
[2020-05-12 02:12:53.575]  Step 150445  [3.196 sec/step, loss=0.07590, avg_loss=0.09018, mel_loss=0.03592, linear_loss=0.03998]
[2020-05-12 02:12:57.979]  Step 150446  [3.223 sec/step, loss=0.09469, avg_loss=0.09023, mel_loss=0.04249, linear_loss=0.05220]
[2020-05-12 02:13:04.129]  Step 150447  [3.212 sec/step, loss=0.09448, avg_loss=0.09019, mel_loss=0.04261, linear_loss=0.05187]
[2020-05-12 02:13:07.343]  Step 150448  [3.234 sec/step, loss=0.09158, avg_loss=0.09027, mel_loss=0.04078, linear_loss=0.05080]
[2020-05-12 02:13:14.295]  Step 150449  [3.274 sec/step, loss=0.09728, avg_loss=0.09029, mel_loss=0.04483, linear_loss=0.05245]
[2020-05-12 02:13:19.857]  Step 150450  [3.319 sec/step, loss=0.09628, avg_loss=0.09040, mel_loss=0.04407, linear_loss=0.05221]
[2020-05-12 02:13:19.857]  Writing summary at step: 150450
[2020-05-12 02:13:20.972]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150450
[2020-05-12 02:13:22.503]  Saving audio and alignment...
[2020-05-12 02:13:25.331]  Generated 32 batches of size 32 in 2.263 sec
[2020-05-12 02:13:26.066]  Input: 나는 코멘트가 없다~_____________________
[2020-05-12 02:13:27.762]  Step 150451  [3.322 sec/step, loss=0.09008, avg_loss=0.09044, mel_loss=0.03969, linear_loss=0.05038]
[2020-05-12 02:13:31.498]  Step 150452  [3.323 sec/step, loss=0.09886, avg_loss=0.09044, mel_loss=0.04470, linear_loss=0.05417]
[2020-05-12 02:13:35.491]  Step 150453  [3.343 sec/step, loss=0.09742, avg_loss=0.09050, mel_loss=0.04409, linear_loss=0.05333]
[2020-05-12 02:13:36.249]  Step 150454  [3.300 sec/step, loss=0.07378, avg_loss=0.09027, mel_loss=0.03210, linear_loss=0.04169]
[2020-05-12 02:13:40.496]  Step 150455  [3.316 sec/step, loss=0.09680, avg_loss=0.09029, mel_loss=0.04385, linear_loss=0.05295]
[2020-05-12 02:13:42.355]  Step 150456  [3.315 sec/step, loss=0.09027, avg_loss=0.09029, mel_loss=0.03992, linear_loss=0.05035]
[2020-05-12 02:13:45.751]  Step 150457  [3.311 sec/step, loss=0.09660, avg_loss=0.09028, mel_loss=0.04354, linear_loss=0.05306]
[2020-05-12 02:13:47.846]  Step 150458  [3.321 sec/step, loss=0.09187, avg_loss=0.09037, mel_loss=0.04086, linear_loss=0.05101]
[2020-05-12 02:13:48.672]  Step 150459  [3.274 sec/step, loss=0.07617, avg_loss=0.09014, mel_loss=0.03296, linear_loss=0.04322]
[2020-05-12 02:13:52.704]  Step 150460  [3.293 sec/step, loss=0.09784, avg_loss=0.09018, mel_loss=0.04446, linear_loss=0.05338]
[2020-05-12 02:13:58.672]  Step 150461  [3.344 sec/step, loss=0.09863, avg_loss=0.09037, mel_loss=0.04551, linear_loss=0.05312]
[2020-05-12 02:13:59.715]  Step 150462  [3.347 sec/step, loss=0.08259, avg_loss=0.09045, mel_loss=0.03610, linear_loss=0.04649]
[2020-05-12 02:14:07.842]  Step 150463  [3.420 sec/step, loss=0.09661, avg_loss=0.09066, mel_loss=0.04502, linear_loss=0.05159]
[2020-05-12 02:14:09.221]  Step 150464  [3.421 sec/step, loss=0.08765, avg_loss=0.09066, mel_loss=0.03826, linear_loss=0.04939]
[2020-05-12 02:14:10.076]  Step 150465  [3.395 sec/step, loss=0.07678, avg_loss=0.09047, mel_loss=0.03307, linear_loss=0.04371]
[2020-05-12 02:14:11.312]  Step 150466  [3.367 sec/step, loss=0.08685, avg_loss=0.09037, mel_loss=0.03800, linear_loss=0.04885]
[2020-05-12 02:14:16.161]  Step 150467  [3.379 sec/step, loss=0.09715, avg_loss=0.09038, mel_loss=0.04419, linear_loss=0.05296]
[2020-05-12 02:14:21.614]  Step 150468  [3.428 sec/step, loss=0.09741, avg_loss=0.09065, mel_loss=0.04458, linear_loss=0.05283]
[2020-05-12 02:14:34.807]  Step 150469  [3.507 sec/step, loss=0.08093, avg_loss=0.09046, mel_loss=0.03840, linear_loss=0.04253]
[2020-05-12 02:14:37.093]  Step 150470  [3.455 sec/step, loss=0.09404, avg_loss=0.09041, mel_loss=0.04225, linear_loss=0.05179]
[2020-05-12 02:14:38.797]  Step 150471  [3.454 sec/step, loss=0.09008, avg_loss=0.09041, mel_loss=0.03937, linear_loss=0.05070]
[2020-05-12 02:14:41.199]  Step 150472  [3.458 sec/step, loss=0.09324, avg_loss=0.09045, mel_loss=0.04145, linear_loss=0.05179]
[2020-05-12 02:14:41.771]  Step 150473  [3.433 sec/step, loss=0.07879, avg_loss=0.09027, mel_loss=0.03481, linear_loss=0.04398]
[2020-05-12 02:14:48.860]  Step 150474  [3.487 sec/step, loss=0.09810, avg_loss=0.09036, mel_loss=0.04521, linear_loss=0.05289]
[2020-05-12 02:14:52.578]  Step 150475  [3.495 sec/step, loss=0.09737, avg_loss=0.09041, mel_loss=0.04395, linear_loss=0.05342]
[2020-05-12 02:14:53.713]  Step 150476  [3.470 sec/step, loss=0.08465, avg_loss=0.09028, mel_loss=0.03646, linear_loss=0.04819]
[2020-05-12 02:14:55.295]  Step 150477  [3.473 sec/step, loss=0.08889, avg_loss=0.09032, mel_loss=0.03926, linear_loss=0.04963]
[2020-05-12 02:14:59.690]  Step 150478  [3.501 sec/step, loss=0.09978, avg_loss=0.09044, mel_loss=0.04558, linear_loss=0.05420]
[2020-05-12 02:15:01.145]  Step 150479  [3.472 sec/step, loss=0.08843, avg_loss=0.09034, mel_loss=0.03876, linear_loss=0.04967]
[2020-05-12 02:15:04.013]  Step 150480  [3.477 sec/step, loss=0.09275, avg_loss=0.09034, mel_loss=0.04173, linear_loss=0.05103]
[2020-05-12 02:15:07.354]  Step 150481  [3.489 sec/step, loss=0.09471, avg_loss=0.09035, mel_loss=0.04259, linear_loss=0.05212]
[2020-05-12 02:15:09.952]  Generated 32 batches of size 32 in 2.592 sec
[2020-05-12 02:15:10.179]  Step 150482  [3.506 sec/step, loss=0.09334, avg_loss=0.09044, mel_loss=0.04171, linear_loss=0.05163]
[2020-05-12 02:15:11.994]  Step 150483  [3.384 sec/step, loss=0.08928, avg_loss=0.09057, mel_loss=0.03903, linear_loss=0.05025]
[2020-05-12 02:15:13.946]  Step 150484  [3.337 sec/step, loss=0.09088, avg_loss=0.09049, mel_loss=0.04037, linear_loss=0.05051]
[2020-05-12 02:15:17.396]  Step 150485  [3.363 sec/step, loss=0.09511, avg_loss=0.09066, mel_loss=0.04294, linear_loss=0.05217]
[2020-05-12 02:15:18.418]  Step 150486  [3.364 sec/step, loss=0.08343, avg_loss=0.09064, mel_loss=0.03641, linear_loss=0.04702]
[2020-05-12 02:15:21.549]  Step 150487  [3.370 sec/step, loss=0.09461, avg_loss=0.09064, mel_loss=0.04261, linear_loss=0.05200]
[2020-05-12 02:15:23.756]  Step 150488  [3.385 sec/step, loss=0.09291, avg_loss=0.09083, mel_loss=0.04145, linear_loss=0.05147]
[2020-05-12 02:15:25.721]  Step 150489  [3.373 sec/step, loss=0.09368, avg_loss=0.09080, mel_loss=0.04129, linear_loss=0.05238]
[2020-05-12 02:15:26.246]  Step 150490  [3.364 sec/step, loss=0.07208, avg_loss=0.09066, mel_loss=0.03165, linear_loss=0.04044]
[2020-05-12 02:15:28.275]  Step 150491  [3.365 sec/step, loss=0.09100, avg_loss=0.09067, mel_loss=0.04015, linear_loss=0.05085]
[2020-05-12 02:15:30.469]  Step 150492  [3.332 sec/step, loss=0.09014, avg_loss=0.09059, mel_loss=0.04024, linear_loss=0.04990]
[2020-05-12 02:15:33.910]  Step 150493  [3.284 sec/step, loss=0.09522, avg_loss=0.09058, mel_loss=0.04284, linear_loss=0.05238]
[2020-05-12 02:15:35.625]  Step 150494  [3.253 sec/step, loss=0.09075, avg_loss=0.09051, mel_loss=0.03992, linear_loss=0.05083]
[2020-05-12 02:15:38.042]  Step 150495  [3.265 sec/step, loss=0.09356, avg_loss=0.09061, mel_loss=0.04119, linear_loss=0.05237]
[2020-05-12 02:15:39.657]  Step 150496  [3.273 sec/step, loss=0.08918, avg_loss=0.09071, mel_loss=0.03935, linear_loss=0.04983]
[2020-05-12 02:15:40.855]  Step 150497  [3.244 sec/step, loss=0.08351, avg_loss=0.09059, mel_loss=0.03663, linear_loss=0.04688]
[2020-05-12 02:15:42.712]  Step 150498  [3.239 sec/step, loss=0.08832, avg_loss=0.09053, mel_loss=0.03903, linear_loss=0.04929]
[2020-05-12 02:15:50.109]  Step 150499  [3.305 sec/step, loss=0.10030, avg_loss=0.09076, mel_loss=0.04658, linear_loss=0.05372]
[2020-05-12 02:15:53.198]  Step 150500  [3.323 sec/step, loss=0.09836, avg_loss=0.09088, mel_loss=0.04440, linear_loss=0.05395]
[2020-05-12 02:15:53.198]  Writing summary at step: 150500
[2020-05-12 02:15:57.654]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150500
[2020-05-12 02:15:59.122]  Saving audio and alignment...
[2020-05-12 02:16:07.995]  Input: 안녕하세요 아나운서 시험 기출 대본의 비밀코드 강의를 맡은 박은줍니다~________________________________________
[2020-05-12 02:16:10.566]  Step 150501  [3.220 sec/step, loss=0.09160, avg_loss=0.09096, mel_loss=0.04093, linear_loss=0.05067]
[2020-05-12 02:16:11.931]  Step 150502  [3.178 sec/step, loss=0.08584, avg_loss=0.09084, mel_loss=0.03793, linear_loss=0.04791]
[2020-05-12 02:16:15.541]  Step 150503  [3.160 sec/step, loss=0.09823, avg_loss=0.09084, mel_loss=0.04457, linear_loss=0.05366]
[2020-05-12 02:16:21.117]  Step 150504  [3.126 sec/step, loss=0.09800, avg_loss=0.09084, mel_loss=0.04492, linear_loss=0.05308]
[2020-05-12 02:16:26.454]  Step 150505  [3.158 sec/step, loss=0.09832, avg_loss=0.09091, mel_loss=0.04482, linear_loss=0.05349]
[2020-05-12 02:16:29.506]  Step 150506  [3.167 sec/step, loss=0.09323, avg_loss=0.09093, mel_loss=0.04175, linear_loss=0.05148]
[2020-05-12 02:16:30.391]  Step 150507  [3.147 sec/step, loss=0.08047, avg_loss=0.09076, mel_loss=0.03465, linear_loss=0.04581]
[2020-05-12 02:16:39.258]  Step 150508  [3.212 sec/step, loss=0.09629, avg_loss=0.09079, mel_loss=0.04489, linear_loss=0.05140]
[2020-05-12 02:16:41.244]  Step 150509  [3.197 sec/step, loss=0.09176, avg_loss=0.09074, mel_loss=0.04060, linear_loss=0.05116]
[2020-05-12 02:16:42.187]  Step 150510  [3.142 sec/step, loss=0.08142, avg_loss=0.09055, mel_loss=0.03506, linear_loss=0.04636]
[2020-05-12 02:16:45.171]  Step 150511  [3.164 sec/step, loss=0.09607, avg_loss=0.09071, mel_loss=0.04302, linear_loss=0.05306]
[2020-05-12 02:16:46.700]  Step 150512  [3.169 sec/step, loss=0.08628, avg_loss=0.09076, mel_loss=0.03804, linear_loss=0.04824]
[2020-05-12 02:16:47.108]  Generated 32 batches of size 32 in 1.931 sec
[2020-05-12 02:16:51.367]  Step 150513  [3.172 sec/step, loss=0.09730, avg_loss=0.09076, mel_loss=0.04416, linear_loss=0.05315]
[2020-05-12 02:16:52.433]  Step 150514  [3.133 sec/step, loss=0.08460, avg_loss=0.09065, mel_loss=0.03685, linear_loss=0.04775]
[2020-05-12 02:16:53.220]  Step 150515  [3.059 sec/step, loss=0.07578, avg_loss=0.09041, mel_loss=0.03269, linear_loss=0.04310]
[2020-05-12 02:16:54.230]  Step 150516  [3.062 sec/step, loss=0.08292, avg_loss=0.09051, mel_loss=0.03594, linear_loss=0.04698]
[2020-05-12 02:16:57.644]  Step 150517  [3.078 sec/step, loss=0.09515, avg_loss=0.09057, mel_loss=0.04280, linear_loss=0.05235]
[2020-05-12 02:17:01.734]  Step 150518  [3.108 sec/step, loss=0.09692, avg_loss=0.09074, mel_loss=0.04366, linear_loss=0.05326]
[2020-05-12 02:17:15.910]  Step 150519  [3.238 sec/step, loss=0.07727, avg_loss=0.09070, mel_loss=0.03696, linear_loss=0.04031]
[2020-05-12 02:17:16.662]  Step 150520  [3.218 sec/step, loss=0.07425, avg_loss=0.09052, mel_loss=0.03271, linear_loss=0.04154]
[2020-05-12 02:17:23.030]  Step 150521  [3.266 sec/step, loss=0.09814, avg_loss=0.09060, mel_loss=0.04525, linear_loss=0.05288]
[2020-05-12 02:17:24.736]  Step 150522  [3.249 sec/step, loss=0.09048, avg_loss=0.09056, mel_loss=0.03977, linear_loss=0.05072]
[2020-05-12 02:17:27.187]  Step 150523  [3.237 sec/step, loss=0.09169, avg_loss=0.09050, mel_loss=0.04055, linear_loss=0.05114]
[2020-05-12 02:17:30.102]  Step 150524  [3.249 sec/step, loss=0.09426, avg_loss=0.09053, mel_loss=0.04230, linear_loss=0.05196]
[2020-05-12 02:17:35.155]  Step 150525  [3.279 sec/step, loss=0.09660, avg_loss=0.09058, mel_loss=0.04411, linear_loss=0.05249]
[2020-05-12 02:17:38.704]  Step 150526  [3.284 sec/step, loss=0.09555, avg_loss=0.09055, mel_loss=0.04304, linear_loss=0.05251]
[2020-05-12 02:17:47.584]  Step 150527  [3.359 sec/step, loss=0.09856, avg_loss=0.09067, mel_loss=0.04591, linear_loss=0.05265]
[2020-05-12 02:18:01.743]  Step 150528  [3.475 sec/step, loss=0.07628, avg_loss=0.09050, mel_loss=0.03626, linear_loss=0.04003]
[2020-05-12 02:18:04.377]  Step 150529  [3.488 sec/step, loss=0.09349, avg_loss=0.09055, mel_loss=0.04177, linear_loss=0.05173]
[2020-05-12 02:18:05.008]  Step 150530  [3.483 sec/step, loss=0.07714, avg_loss=0.09049, mel_loss=0.03442, linear_loss=0.04272]
[2020-05-12 02:18:06.351]  Step 150531  [3.472 sec/step, loss=0.08497, avg_loss=0.09041, mel_loss=0.03683, linear_loss=0.04814]
[2020-05-12 02:18:07.157]  Step 150532  [3.470 sec/step, loss=0.07453, avg_loss=0.09034, mel_loss=0.03217, linear_loss=0.04236]
[2020-05-12 02:18:11.799]  Step 150533  [3.431 sec/step, loss=0.09697, avg_loss=0.09035, mel_loss=0.04409, linear_loss=0.05288]
[2020-05-12 02:18:15.989]  Step 150534  [3.450 sec/step, loss=0.09944, avg_loss=0.09042, mel_loss=0.04527, linear_loss=0.05417]
[2020-05-12 02:18:19.455]  Step 150535  [3.453 sec/step, loss=0.09384, avg_loss=0.09040, mel_loss=0.04194, linear_loss=0.05190]
[2020-05-12 02:18:21.488]  Step 150536  [3.427 sec/step, loss=0.09368, avg_loss=0.09034, mel_loss=0.04143, linear_loss=0.05225]
[2020-05-12 02:18:22.440]  Step 150537  [3.429 sec/step, loss=0.08400, avg_loss=0.09039, mel_loss=0.03654, linear_loss=0.04745]
[2020-05-12 02:18:24.427]  Step 150538  [3.436 sec/step, loss=0.09166, avg_loss=0.09043, mel_loss=0.04072, linear_loss=0.05094]
[2020-05-12 02:18:26.642]  Step 150539  [3.409 sec/step, loss=0.09226, avg_loss=0.09037, mel_loss=0.04116, linear_loss=0.05110]
[2020-05-12 02:18:30.350]  Step 150540  [3.417 sec/step, loss=0.09792, avg_loss=0.09040, mel_loss=0.04419, linear_loss=0.05374]
[2020-05-12 02:18:31.495]  Step 150541  [3.413 sec/step, loss=0.08469, avg_loss=0.09036, mel_loss=0.03661, linear_loss=0.04808]
[2020-05-12 02:18:32.989]  Step 150542  [3.418 sec/step, loss=0.08655, avg_loss=0.09040, mel_loss=0.03820, linear_loss=0.04835]
[2020-05-12 02:18:33.574]  Step 150543  [3.416 sec/step, loss=0.06956, avg_loss=0.09034, mel_loss=0.03079, linear_loss=0.03877]
[2020-05-12 02:18:35.276]  Generated 32 batches of size 32 in 1.696 sec
[2020-05-12 02:18:37.961]  Step 150544  [3.385 sec/step, loss=0.09640, avg_loss=0.09031, mel_loss=0.04353, linear_loss=0.05287]
[2020-05-12 02:18:40.928]  Step 150545  [3.263 sec/step, loss=0.09498, avg_loss=0.09051, mel_loss=0.04279, linear_loss=0.05219]
[2020-05-12 02:18:46.599]  Step 150546  [3.276 sec/step, loss=0.09818, avg_loss=0.09054, mel_loss=0.04508, linear_loss=0.05310]
[2020-05-12 02:18:48.172]  Step 150547  [3.230 sec/step, loss=0.09080, avg_loss=0.09050, mel_loss=0.03975, linear_loss=0.05105]
[2020-05-12 02:18:49.056]  Step 150548  [3.207 sec/step, loss=0.07954, avg_loss=0.09038, mel_loss=0.03464, linear_loss=0.04490]
[2020-05-12 02:18:50.394]  Step 150549  [3.151 sec/step, loss=0.08495, avg_loss=0.09026, mel_loss=0.03723, linear_loss=0.04771]
[2020-05-12 02:18:58.050]  Step 150550  [3.172 sec/step, loss=0.09885, avg_loss=0.09029, mel_loss=0.04601, linear_loss=0.05284]
[2020-05-12 02:18:58.050]  Writing summary at step: 150550
[2020-05-12 02:18:59.132]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150550
[2020-05-12 02:19:00.603]  Saving audio and alignment...
[2020-05-12 02:19:03.789]  Input: 그래서 변화를 주셔야 합니다~_____________
[2020-05-12 02:19:06.227]  Step 150551  [3.179 sec/step, loss=0.09514, avg_loss=0.09034, mel_loss=0.04226, linear_loss=0.05288]
[2020-05-12 02:19:07.384]  Step 150552  [3.153 sec/step, loss=0.08427, avg_loss=0.09019, mel_loss=0.03658, linear_loss=0.04768]
[2020-05-12 02:19:08.443]  Step 150553  [3.124 sec/step, loss=0.08410, avg_loss=0.09006, mel_loss=0.03678, linear_loss=0.04732]
[2020-05-12 02:19:11.206]  Step 150554  [3.144 sec/step, loss=0.09280, avg_loss=0.09025, mel_loss=0.04175, linear_loss=0.05105]
[2020-05-12 02:19:15.839]  Step 150555  [3.148 sec/step, loss=0.09930, avg_loss=0.09027, mel_loss=0.04529, linear_loss=0.05402]
[2020-05-12 02:19:28.779]  Step 150556  [3.259 sec/step, loss=0.08465, avg_loss=0.09022, mel_loss=0.04046, linear_loss=0.04419]
[2020-05-12 02:19:30.315]  Step 150557  [3.240 sec/step, loss=0.08901, avg_loss=0.09014, mel_loss=0.03912, linear_loss=0.04989]
[2020-05-12 02:19:37.597]  Step 150558  [3.292 sec/step, loss=0.09837, avg_loss=0.09020, mel_loss=0.04563, linear_loss=0.05274]
[2020-05-12 02:19:39.706]  Step 150559  [3.305 sec/step, loss=0.09167, avg_loss=0.09036, mel_loss=0.04084, linear_loss=0.05083]
[2020-05-12 02:19:40.581]  Step 150560  [3.273 sec/step, loss=0.07615, avg_loss=0.09014, mel_loss=0.03295, linear_loss=0.04321]
[2020-05-12 02:19:49.033]  Step 150561  [3.298 sec/step, loss=0.09604, avg_loss=0.09012, mel_loss=0.04467, linear_loss=0.05137]
[2020-05-12 02:19:51.013]  Step 150562  [3.307 sec/step, loss=0.08993, avg_loss=0.09019, mel_loss=0.03990, linear_loss=0.05003]
[2020-05-12 02:19:56.256]  Step 150563  [3.279 sec/step, loss=0.09795, avg_loss=0.09020, mel_loss=0.04491, linear_loss=0.05304]
[2020-05-12 02:19:59.367]  Step 150564  [3.296 sec/step, loss=0.09696, avg_loss=0.09030, mel_loss=0.04362, linear_loss=0.05334]
[2020-05-12 02:20:04.972]  Step 150565  [3.343 sec/step, loss=0.09736, avg_loss=0.09050, mel_loss=0.04440, linear_loss=0.05296]
[2020-05-12 02:20:06.361]  Step 150566  [3.345 sec/step, loss=0.08937, avg_loss=0.09053, mel_loss=0.03939, linear_loss=0.04998]
[2020-05-12 02:20:06.923]  Step 150567  [3.302 sec/step, loss=0.07396, avg_loss=0.09030, mel_loss=0.03283, linear_loss=0.04113]
[2020-05-12 02:20:07.911]  Step 150568  [3.257 sec/step, loss=0.08228, avg_loss=0.09014, mel_loss=0.03514, linear_loss=0.04714]
[2020-05-12 02:20:11.248]  Step 150569  [3.159 sec/step, loss=0.09876, avg_loss=0.09032, mel_loss=0.04435, linear_loss=0.05441]
[2020-05-12 02:20:17.309]  Step 150570  [3.197 sec/step, loss=0.09881, avg_loss=0.09037, mel_loss=0.04564, linear_loss=0.05318]
[2020-05-12 02:20:20.179]  Step 150571  [3.208 sec/step, loss=0.09458, avg_loss=0.09042, mel_loss=0.04216, linear_loss=0.05242]
[2020-05-12 02:20:23.626]  Step 150572  [3.219 sec/step, loss=0.09818, avg_loss=0.09046, mel_loss=0.04452, linear_loss=0.05365]
[2020-05-12 02:20:24.840]  Step 150573  [3.225 sec/step, loss=0.08773, avg_loss=0.09055, mel_loss=0.03849, linear_loss=0.04924]
[2020-05-12 02:20:26.526]  Generated 32 batches of size 32 in 1.680 sec
[2020-05-12 02:20:28.919]  Step 150574  [3.195 sec/step, loss=0.09907, avg_loss=0.09056, mel_loss=0.04490, linear_loss=0.05417]
[2020-05-12 02:20:30.504]  Step 150575  [3.174 sec/step, loss=0.08978, avg_loss=0.09049, mel_loss=0.03987, linear_loss=0.04991]
[2020-05-12 02:20:31.305]  Step 150576  [3.170 sec/step, loss=0.08006, avg_loss=0.09044, mel_loss=0.03460, linear_loss=0.04546]
[2020-05-12 02:20:33.104]  Step 150577  [3.172 sec/step, loss=0.09023, avg_loss=0.09046, mel_loss=0.03956, linear_loss=0.05067]
[2020-05-12 02:20:35.469]  Step 150578  [3.152 sec/step, loss=0.09264, avg_loss=0.09038, mel_loss=0.04123, linear_loss=0.05141]
[2020-05-12 02:20:39.775]  Step 150579  [3.181 sec/step, loss=0.09674, avg_loss=0.09047, mel_loss=0.04371, linear_loss=0.05303]
[2020-05-12 02:20:41.934]  Step 150580  [3.174 sec/step, loss=0.09226, avg_loss=0.09046, mel_loss=0.04079, linear_loss=0.05148]
[2020-05-12 02:20:45.381]  Step 150581  [3.175 sec/step, loss=0.09473, avg_loss=0.09046, mel_loss=0.04282, linear_loss=0.05191]
[2020-05-12 02:20:47.117]  Step 150582  [3.164 sec/step, loss=0.09049, avg_loss=0.09043, mel_loss=0.04025, linear_loss=0.05025]
[2020-05-12 02:20:52.832]  Step 150583  [3.203 sec/step, loss=0.09833, avg_loss=0.09052, mel_loss=0.04502, linear_loss=0.05331]
[2020-05-12 02:20:54.416]  Step 150584  [3.199 sec/step, loss=0.09011, avg_loss=0.09052, mel_loss=0.03970, linear_loss=0.05041]
[2020-05-12 02:21:02.148]  Step 150585  [3.242 sec/step, loss=0.09844, avg_loss=0.09055, mel_loss=0.04563, linear_loss=0.05281]
[2020-05-12 02:21:16.419]  Step 150586  [3.374 sec/step, loss=0.07680, avg_loss=0.09048, mel_loss=0.03654, linear_loss=0.04026]
[2020-05-12 02:21:20.802]  Step 150587  [3.387 sec/step, loss=0.09638, avg_loss=0.09050, mel_loss=0.04383, linear_loss=0.05255]
[2020-05-12 02:21:23.330]  Step 150588  [3.390 sec/step, loss=0.09094, avg_loss=0.09048, mel_loss=0.04033, linear_loss=0.05061]
[2020-05-12 02:21:24.124]  Step 150589  [3.378 sec/step, loss=0.07752, avg_loss=0.09032, mel_loss=0.03332, linear_loss=0.04420]
[2020-05-12 02:21:30.947]  Step 150590  [3.441 sec/step, loss=0.09906, avg_loss=0.09059, mel_loss=0.04560, linear_loss=0.05345]
[2020-05-12 02:21:39.947]  Step 150591  [3.511 sec/step, loss=0.09782, avg_loss=0.09066, mel_loss=0.04558, linear_loss=0.05224]
[2020-05-12 02:21:42.097]  Step 150592  [3.511 sec/step, loss=0.09053, avg_loss=0.09066, mel_loss=0.03984, linear_loss=0.05069]
[2020-05-12 02:21:43.401]  Step 150593  [3.489 sec/step, loss=0.08530, avg_loss=0.09056, mel_loss=0.03696, linear_loss=0.04834]
[2020-05-12 02:21:47.083]  Step 150594  [3.509 sec/step, loss=0.09510, avg_loss=0.09061, mel_loss=0.04297, linear_loss=0.05214]
[2020-05-12 02:21:49.413]  Step 150595  [3.508 sec/step, loss=0.09324, avg_loss=0.09060, mel_loss=0.04145, linear_loss=0.05179]
[2020-05-12 02:21:51.183]  Step 150596  [3.510 sec/step, loss=0.08855, avg_loss=0.09060, mel_loss=0.03848, linear_loss=0.05006]
[2020-05-12 02:21:52.518]  Step 150597  [3.511 sec/step, loss=0.08463, avg_loss=0.09061, mel_loss=0.03705, linear_loss=0.04758]
[2020-05-12 02:21:54.061]  Step 150598  [3.508 sec/step, loss=0.08683, avg_loss=0.09059, mel_loss=0.03795, linear_loss=0.04888]
[2020-05-12 02:21:56.653]  Step 150599  [3.460 sec/step, loss=0.09390, avg_loss=0.09053, mel_loss=0.04192, linear_loss=0.05197]
[2020-05-12 02:21:59.728]  Step 150600  [3.460 sec/step, loss=0.09673, avg_loss=0.09051, mel_loss=0.04334, linear_loss=0.05340]
[2020-05-12 02:21:59.728]  Writing summary at step: 150600
[2020-05-12 02:22:05.199]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150600
[2020-05-12 02:22:07.532]  Saving audio and alignment...
[2020-05-12 02:22:09.025]  Input: 어디서든~____
[2020-05-12 02:22:11.901]  Step 150601  [3.463 sec/step, loss=0.09557, avg_loss=0.09055, mel_loss=0.04268, linear_loss=0.05289]
[2020-05-12 02:22:15.562]  Step 150602  [3.486 sec/step, loss=0.09668, avg_loss=0.09066, mel_loss=0.04364, linear_loss=0.05304]
[2020-05-12 02:22:17.455]  Step 150603  [3.469 sec/step, loss=0.09102, avg_loss=0.09059, mel_loss=0.04030, linear_loss=0.05072]
[2020-05-12 02:22:19.206]  Generated 32 batches of size 32 in 1.745 sec
[2020-05-12 02:22:19.700]  Step 150604  [3.435 sec/step, loss=0.09179, avg_loss=0.09053, mel_loss=0.04084, linear_loss=0.05095]
[2020-05-12 02:22:24.483]  Step 150605  [3.430 sec/step, loss=0.09576, avg_loss=0.09050, mel_loss=0.04349, linear_loss=0.05227]
[2020-05-12 02:22:25.593]  Step 150606  [3.410 sec/step, loss=0.08233, avg_loss=0.09039, mel_loss=0.03559, linear_loss=0.04674]
[2020-05-12 02:22:26.582]  Step 150607  [3.411 sec/step, loss=0.07981, avg_loss=0.09039, mel_loss=0.03428, linear_loss=0.04554]
[2020-05-12 02:22:27.543]  Step 150608  [3.332 sec/step, loss=0.08342, avg_loss=0.09026, mel_loss=0.03615, linear_loss=0.04727]
[2020-05-12 02:22:28.289]  Step 150609  [3.320 sec/step, loss=0.07316, avg_loss=0.09007, mel_loss=0.03261, linear_loss=0.04055]
[2020-05-12 02:22:29.654]  Step 150610  [3.324 sec/step, loss=0.08891, avg_loss=0.09015, mel_loss=0.03889, linear_loss=0.05002]
[2020-05-12 02:22:33.772]  Step 150611  [3.335 sec/step, loss=0.09489, avg_loss=0.09013, mel_loss=0.04275, linear_loss=0.05213]
[2020-05-12 02:22:37.186]  Step 150612  [3.354 sec/step, loss=0.09481, avg_loss=0.09022, mel_loss=0.04251, linear_loss=0.05230]
[2020-05-12 02:22:45.518]  Step 150613  [3.391 sec/step, loss=0.09292, avg_loss=0.09018, mel_loss=0.04320, linear_loss=0.04972]
[2020-05-12 02:22:50.111]  Step 150614  [3.426 sec/step, loss=0.09904, avg_loss=0.09032, mel_loss=0.04496, linear_loss=0.05408]
[2020-05-12 02:23:02.453]  Step 150615  [3.542 sec/step, loss=0.08671, avg_loss=0.09043, mel_loss=0.04109, linear_loss=0.04561]
[2020-05-12 02:23:06.123]  Step 150616  [3.568 sec/step, loss=0.09891, avg_loss=0.09059, mel_loss=0.04473, linear_loss=0.05418]
[2020-05-12 02:23:07.386]  Step 150617  [3.547 sec/step, loss=0.07867, avg_loss=0.09042, mel_loss=0.03402, linear_loss=0.04465]
[2020-05-12 02:23:19.011]  Step 150618  [3.622 sec/step, loss=0.09848, avg_loss=0.09044, mel_loss=0.04544, linear_loss=0.05304]
[2020-05-12 02:23:21.466]  Step 150619  [3.505 sec/step, loss=0.09191, avg_loss=0.09059, mel_loss=0.04075, linear_loss=0.05116]
[2020-05-12 02:23:24.628]  Step 150620  [3.529 sec/step, loss=0.09649, avg_loss=0.09081, mel_loss=0.04334, linear_loss=0.05315]
[2020-05-12 02:23:26.604]  Step 150621  [3.485 sec/step, loss=0.09285, avg_loss=0.09076, mel_loss=0.04116, linear_loss=0.05169]
[2020-05-12 02:23:30.574]  Step 150622  [3.508 sec/step, loss=0.09706, avg_loss=0.09082, mel_loss=0.04376, linear_loss=0.05329]
[2020-05-12 02:23:33.040]  Step 150623  [3.508 sec/step, loss=0.09327, avg_loss=0.09084, mel_loss=0.04129, linear_loss=0.05198]
[2020-05-12 02:23:37.412]  Step 150624  [3.523 sec/step, loss=0.09830, avg_loss=0.09088, mel_loss=0.04480, linear_loss=0.05350]
[2020-05-12 02:23:38.622]  Step 150625  [3.484 sec/step, loss=0.08322, avg_loss=0.09074, mel_loss=0.03635, linear_loss=0.04686]
[2020-05-12 02:23:39.422]  Step 150626  [3.457 sec/step, loss=0.08287, avg_loss=0.09062, mel_loss=0.03581, linear_loss=0.04707]
[2020-05-12 02:23:40.230]  Step 150627  [3.376 sec/step, loss=0.07766, avg_loss=0.09041, mel_loss=0.03344, linear_loss=0.04422]
[2020-05-12 02:23:41.349]  Step 150628  [3.245 sec/step, loss=0.08437, avg_loss=0.09049, mel_loss=0.03689, linear_loss=0.04747]
[2020-05-12 02:23:42.420]  Step 150629  [3.230 sec/step, loss=0.08335, avg_loss=0.09039, mel_loss=0.03615, linear_loss=0.04720]
[2020-05-12 02:23:45.914]  Step 150630  [3.258 sec/step, loss=0.09623, avg_loss=0.09058, mel_loss=0.04317, linear_loss=0.05306]
[2020-05-12 02:23:49.313]  Step 150631  [3.279 sec/step, loss=0.09628, avg_loss=0.09069, mel_loss=0.04339, linear_loss=0.05289]
[2020-05-12 02:23:50.946]  Step 150632  [3.287 sec/step, loss=0.08866, avg_loss=0.09083, mel_loss=0.03931, linear_loss=0.04935]
[2020-05-12 02:23:52.301]  Step 150633  [3.254 sec/step, loss=0.08547, avg_loss=0.09072, mel_loss=0.03733, linear_loss=0.04814]
[2020-05-12 02:23:55.067]  Step 150634  [3.240 sec/step, loss=0.09383, avg_loss=0.09066, mel_loss=0.04196, linear_loss=0.05187]
[2020-05-12 02:23:57.258]  Step 150635  [3.227 sec/step, loss=0.09097, avg_loss=0.09063, mel_loss=0.04044, linear_loss=0.05053]
[2020-05-12 02:23:58.885]  Generated 32 batches of size 32 in 1.623 sec
[2020-05-12 02:23:59.288]  Step 150636  [3.227 sec/step, loss=0.09166, avg_loss=0.09061, mel_loss=0.04033, linear_loss=0.05133]
[2020-05-12 02:24:01.100]  Step 150637  [3.236 sec/step, loss=0.08897, avg_loss=0.09066, mel_loss=0.03922, linear_loss=0.04975]
[2020-05-12 02:24:07.420]  Step 150638  [3.279 sec/step, loss=0.09774, avg_loss=0.09072, mel_loss=0.04504, linear_loss=0.05270]
[2020-05-12 02:24:08.180]  Step 150639  [3.265 sec/step, loss=0.07158, avg_loss=0.09052, mel_loss=0.03229, linear_loss=0.03929]
[2020-05-12 02:24:13.342]  Step 150640  [3.279 sec/step, loss=0.09869, avg_loss=0.09052, mel_loss=0.04503, linear_loss=0.05366]
[2020-05-12 02:24:15.064]  Step 150641  [3.285 sec/step, loss=0.09163, avg_loss=0.09059, mel_loss=0.04072, linear_loss=0.05091]
[2020-05-12 02:24:16.473]  Step 150642  [3.284 sec/step, loss=0.08649, avg_loss=0.09059, mel_loss=0.03807, linear_loss=0.04842]
[2020-05-12 02:24:19.399]  Step 150643  [3.308 sec/step, loss=0.09686, avg_loss=0.09087, mel_loss=0.04328, linear_loss=0.05358]
[2020-05-12 02:24:24.718]  Step 150644  [3.317 sec/step, loss=0.09874, avg_loss=0.09089, mel_loss=0.04549, linear_loss=0.05326]
[2020-05-12 02:24:26.330]  Step 150645  [3.303 sec/step, loss=0.09047, avg_loss=0.09084, mel_loss=0.03999, linear_loss=0.05048]
[2020-05-12 02:24:38.435]  Step 150646  [3.368 sec/step, loss=0.09128, avg_loss=0.09078, mel_loss=0.04331, linear_loss=0.04797]
[2020-05-12 02:24:41.023]  Step 150647  [3.378 sec/step, loss=0.09293, avg_loss=0.09080, mel_loss=0.04145, linear_loss=0.05148]
[2020-05-12 02:24:44.044]  Step 150648  [3.399 sec/step, loss=0.09625, avg_loss=0.09096, mel_loss=0.04298, linear_loss=0.05327]
[2020-05-12 02:24:45.343]  Step 150649  [3.399 sec/step, loss=0.08785, avg_loss=0.09099, mel_loss=0.03812, linear_loss=0.04973]
[2020-05-12 02:24:46.095]  Step 150650  [3.330 sec/step, loss=0.07629, avg_loss=0.09077, mel_loss=0.03295, linear_loss=0.04334]
[2020-05-12 02:24:46.095]  Writing summary at step: 150650
[2020-05-12 02:24:48.314]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150650
[2020-05-12 02:24:49.778]  Saving audio and alignment...
[2020-05-12 02:25:00.055]  Input: 이렇게 좋은 일이 많이 생기는 날은 오늘은 이렇게 좋은 일이 제가 굉장히 빨리 읽죠 이것을 속도의 완급이라고 합니다~__________
[2020-05-12 02:25:01.878]  Step 150651  [3.324 sec/step, loss=0.08943, avg_loss=0.09071, mel_loss=0.03913, linear_loss=0.05029]
[2020-05-12 02:25:02.407]  Step 150652  [3.317 sec/step, loss=0.07564, avg_loss=0.09062, mel_loss=0.03271, linear_loss=0.04293]
[2020-05-12 02:25:08.377]  Step 150653  [3.367 sec/step, loss=0.09586, avg_loss=0.09074, mel_loss=0.04401, linear_loss=0.05185]
[2020-05-12 02:25:10.125]  Step 150654  [3.356 sec/step, loss=0.09004, avg_loss=0.09071, mel_loss=0.03983, linear_loss=0.05021]
[2020-05-12 02:25:14.338]  Step 150655  [3.352 sec/step, loss=0.09519, avg_loss=0.09067, mel_loss=0.04309, linear_loss=0.05210]
[2020-05-12 02:25:17.246]  Step 150656  [3.252 sec/step, loss=0.09178, avg_loss=0.09074, mel_loss=0.04101, linear_loss=0.05077]
[2020-05-12 02:25:20.667]  Step 150657  [3.271 sec/step, loss=0.09375, avg_loss=0.09079, mel_loss=0.04247, linear_loss=0.05128]
[2020-05-12 02:25:24.053]  Step 150658  [3.232 sec/step, loss=0.09743, avg_loss=0.09078, mel_loss=0.04387, linear_loss=0.05356]
[2020-05-12 02:25:26.504]  Step 150659  [3.235 sec/step, loss=0.09172, avg_loss=0.09078, mel_loss=0.04054, linear_loss=0.05118]
[2020-05-12 02:25:28.642]  Step 150660  [3.248 sec/step, loss=0.09065, avg_loss=0.09093, mel_loss=0.04030, linear_loss=0.05035]
[2020-05-12 02:25:32.229]  Step 150661  [3.199 sec/step, loss=0.09700, avg_loss=0.09094, mel_loss=0.04369, linear_loss=0.05331]
[2020-05-12 02:25:32.993]  Step 150662  [3.187 sec/step, loss=0.08120, avg_loss=0.09085, mel_loss=0.03488, linear_loss=0.04632]
[2020-05-12 02:25:34.392]  Step 150663  [3.149 sec/step, loss=0.08648, avg_loss=0.09073, mel_loss=0.03799, linear_loss=0.04849]
[2020-05-12 02:25:35.412]  Step 150664  [3.128 sec/step, loss=0.07830, avg_loss=0.09055, mel_loss=0.03375, linear_loss=0.04455]
[2020-05-12 02:25:39.693]  Step 150665  [3.114 sec/step, loss=0.09898, avg_loss=0.09056, mel_loss=0.04511, linear_loss=0.05388]
[2020-05-12 02:25:41.466]  Generated 32 batches of size 32 in 1.768 sec
[2020-05-12 02:25:45.352]  Step 150666  [3.157 sec/step, loss=0.09603, avg_loss=0.09063, mel_loss=0.04375, linear_loss=0.05228]
[2020-05-12 02:25:47.382]  Step 150667  [3.172 sec/step, loss=0.09079, avg_loss=0.09080, mel_loss=0.04032, linear_loss=0.05047]
[2020-05-12 02:25:48.989]  Step 150668  [3.178 sec/step, loss=0.08859, avg_loss=0.09086, mel_loss=0.03901, linear_loss=0.04959]
[2020-05-12 02:25:57.664]  Step 150669  [3.231 sec/step, loss=0.09709, avg_loss=0.09085, mel_loss=0.04521, linear_loss=0.05188]
[2020-05-12 02:25:58.765]  Step 150670  [3.182 sec/step, loss=0.08317, avg_loss=0.09069, mel_loss=0.03585, linear_loss=0.04732]
[2020-05-12 02:26:02.458]  Step 150671  [3.190 sec/step, loss=0.09814, avg_loss=0.09072, mel_loss=0.04423, linear_loss=0.05390]
[2020-05-12 02:26:03.474]  Step 150672  [3.166 sec/step, loss=0.08031, avg_loss=0.09055, mel_loss=0.03498, linear_loss=0.04534]
[2020-05-12 02:26:04.692]  Step 150673  [3.166 sec/step, loss=0.08641, avg_loss=0.09053, mel_loss=0.03748, linear_loss=0.04892]
[2020-05-12 02:26:09.538]  Step 150674  [3.173 sec/step, loss=0.09533, avg_loss=0.09050, mel_loss=0.04332, linear_loss=0.05201]
[2020-05-12 02:26:18.059]  Step 150675  [3.243 sec/step, loss=0.09749, avg_loss=0.09057, mel_loss=0.04536, linear_loss=0.05214]
[2020-05-12 02:26:20.031]  Step 150676  [3.254 sec/step, loss=0.09136, avg_loss=0.09069, mel_loss=0.04019, linear_loss=0.05117]
[2020-05-12 02:26:21.872]  Step 150677  [3.255 sec/step, loss=0.09065, avg_loss=0.09069, mel_loss=0.03995, linear_loss=0.05070]
[2020-05-12 02:26:28.783]  Step 150678  [3.300 sec/step, loss=0.09918, avg_loss=0.09076, mel_loss=0.04584, linear_loss=0.05334]
[2020-05-12 02:26:35.140]  Step 150679  [3.321 sec/step, loss=0.09986, avg_loss=0.09079, mel_loss=0.04595, linear_loss=0.05391]
[2020-05-12 02:26:35.893]  Step 150680  [3.307 sec/step, loss=0.07827, avg_loss=0.09065, mel_loss=0.03349, linear_loss=0.04478]
[2020-05-12 02:26:38.718]  Step 150681  [3.301 sec/step, loss=0.09550, avg_loss=0.09065, mel_loss=0.04299, linear_loss=0.05251]
[2020-05-12 02:26:39.275]  Step 150682  [3.289 sec/step, loss=0.06984, avg_loss=0.09045, mel_loss=0.03107, linear_loss=0.03877]
[2020-05-12 02:26:40.578]  Step 150683  [3.245 sec/step, loss=0.08434, avg_loss=0.09031, mel_loss=0.03691, linear_loss=0.04742]
[2020-05-12 02:26:41.650]  Step 150684  [3.240 sec/step, loss=0.08560, avg_loss=0.09026, mel_loss=0.03751, linear_loss=0.04808]
[2020-05-12 02:26:46.274]  Step 150685  [3.208 sec/step, loss=0.09818, avg_loss=0.09026, mel_loss=0.04423, linear_loss=0.05395]
[2020-05-12 02:26:52.234]  Step 150686  [3.125 sec/step, loss=0.09764, avg_loss=0.09047, mel_loss=0.04467, linear_loss=0.05297]
[2020-05-12 02:26:56.258]  Step 150687  [3.122 sec/step, loss=0.09626, avg_loss=0.09047, mel_loss=0.04332, linear_loss=0.05294]
[2020-05-12 02:26:58.583]  Step 150688  [3.120 sec/step, loss=0.09137, avg_loss=0.09047, mel_loss=0.04065, linear_loss=0.05072]
[2020-05-12 02:27:01.673]  Step 150689  [3.143 sec/step, loss=0.09593, avg_loss=0.09066, mel_loss=0.04308, linear_loss=0.05284]
[2020-05-12 02:27:02.275]  Step 150690  [3.080 sec/step, loss=0.07806, avg_loss=0.09045, mel_loss=0.03458, linear_loss=0.04348]
[2020-05-12 02:27:05.771]  Step 150691  [3.025 sec/step, loss=0.09458, avg_loss=0.09041, mel_loss=0.04283, linear_loss=0.05175]
[2020-05-12 02:27:06.904]  Step 150692  [3.015 sec/step, loss=0.08647, avg_loss=0.09037, mel_loss=0.03765, linear_loss=0.04882]
[2020-05-12 02:27:09.610]  Step 150693  [3.029 sec/step, loss=0.09234, avg_loss=0.09044, mel_loss=0.04125, linear_loss=0.05109]
[2020-05-12 02:27:11.738]  Step 150694  [3.014 sec/step, loss=0.09387, avg_loss=0.09043, mel_loss=0.04159, linear_loss=0.05228]
[2020-05-12 02:27:13.316]  Step 150695  [3.006 sec/step, loss=0.09037, avg_loss=0.09040, mel_loss=0.03948, linear_loss=0.05090]
[2020-05-12 02:27:14.181]  Step 150696  [2.997 sec/step, loss=0.08306, avg_loss=0.09035, mel_loss=0.03567, linear_loss=0.04739]
[2020-05-12 02:27:15.537]  Step 150697  [2.997 sec/step, loss=0.08564, avg_loss=0.09036, mel_loss=0.03744, linear_loss=0.04821]
[2020-05-12 02:27:17.245]  Generated 32 batches of size 32 in 1.703 sec
[2020-05-12 02:27:19.813]  Step 150698  [3.025 sec/step, loss=0.09671, avg_loss=0.09046, mel_loss=0.04403, linear_loss=0.05268]
[2020-05-12 02:27:25.067]  Step 150699  [3.051 sec/step, loss=0.09794, avg_loss=0.09050, mel_loss=0.04478, linear_loss=0.05317]
[2020-05-12 02:27:39.519]  Step 150700  [3.165 sec/step, loss=0.07805, avg_loss=0.09031, mel_loss=0.03727, linear_loss=0.04078]
[2020-05-12 02:27:39.519]  Writing summary at step: 150700
[2020-05-12 02:27:40.519]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150700
[2020-05-12 02:27:41.972]  Saving audio and alignment...
[2020-05-12 02:27:44.718]  Input: 캔버스 위에 피어난다~_______________
[2020-05-12 02:27:48.094]  Step 150701  [3.170 sec/step, loss=0.09577, avg_loss=0.09031, mel_loss=0.04287, linear_loss=0.05290]
[2020-05-12 02:27:49.840]  Step 150702  [3.151 sec/step, loss=0.08939, avg_loss=0.09024, mel_loss=0.03908, linear_loss=0.05032]
[2020-05-12 02:27:52.311]  Step 150703  [3.157 sec/step, loss=0.09320, avg_loss=0.09026, mel_loss=0.04155, linear_loss=0.05164]
[2020-05-12 02:27:55.745]  Step 150704  [3.169 sec/step, loss=0.09689, avg_loss=0.09031, mel_loss=0.04345, linear_loss=0.05344]
[2020-05-12 02:28:02.465]  Step 150705  [3.188 sec/step, loss=0.09879, avg_loss=0.09034, mel_loss=0.04546, linear_loss=0.05333]
[2020-05-12 02:28:03.895]  Step 150706  [3.191 sec/step, loss=0.08833, avg_loss=0.09040, mel_loss=0.03868, linear_loss=0.04965]
[2020-05-12 02:28:11.225]  Step 150707  [3.255 sec/step, loss=0.09868, avg_loss=0.09059, mel_loss=0.04541, linear_loss=0.05327]
[2020-05-12 02:28:13.885]  Step 150708  [3.272 sec/step, loss=0.09364, avg_loss=0.09069, mel_loss=0.04171, linear_loss=0.05193]
[2020-05-12 02:28:19.167]  Step 150709  [3.317 sec/step, loss=0.09692, avg_loss=0.09093, mel_loss=0.04419, linear_loss=0.05273]
[2020-05-12 02:28:21.672]  Step 150710  [3.328 sec/step, loss=0.09093, avg_loss=0.09095, mel_loss=0.04052, linear_loss=0.05040]
[2020-05-12 02:28:22.232]  Step 150711  [3.293 sec/step, loss=0.07347, avg_loss=0.09074, mel_loss=0.03241, linear_loss=0.04106]
[2020-05-12 02:28:27.977]  Step 150712  [3.316 sec/step, loss=0.09982, avg_loss=0.09079, mel_loss=0.04571, linear_loss=0.05411]
[2020-05-12 02:28:31.409]  Step 150713  [3.267 sec/step, loss=0.09458, avg_loss=0.09080, mel_loss=0.04263, linear_loss=0.05195]
[2020-05-12 02:28:32.769]  Step 150714  [3.235 sec/step, loss=0.08656, avg_loss=0.09068, mel_loss=0.03776, linear_loss=0.04881]
[2020-05-12 02:28:33.819]  Step 150715  [3.122 sec/step, loss=0.08128, avg_loss=0.09062, mel_loss=0.03507, linear_loss=0.04621]
[2020-05-12 02:28:35.992]  Step 150716  [3.107 sec/step, loss=0.09134, avg_loss=0.09055, mel_loss=0.04037, linear_loss=0.05097]
[2020-05-12 02:28:37.587]  Step 150717  [3.110 sec/step, loss=0.08740, avg_loss=0.09064, mel_loss=0.03855, linear_loss=0.04885]
[2020-05-12 02:28:39.644]  Step 150718  [3.014 sec/step, loss=0.08969, avg_loss=0.09055, mel_loss=0.03976, linear_loss=0.04993]
[2020-05-12 02:28:40.692]  Step 150719  [3.000 sec/step, loss=0.08252, avg_loss=0.09045, mel_loss=0.03581, linear_loss=0.04671]
[2020-05-12 02:28:41.532]  Step 150720  [2.977 sec/step, loss=0.07702, avg_loss=0.09026, mel_loss=0.03320, linear_loss=0.04382]
[2020-05-12 02:28:43.457]  Step 150721  [2.977 sec/step, loss=0.09103, avg_loss=0.09024, mel_loss=0.04020, linear_loss=0.05083]
[2020-05-12 02:28:52.429]  Step 150722  [3.027 sec/step, loss=0.09840, avg_loss=0.09025, mel_loss=0.04593, linear_loss=0.05247]
[2020-05-12 02:28:56.163]  Step 150723  [3.039 sec/step, loss=0.09806, avg_loss=0.09030, mel_loss=0.04444, linear_loss=0.05362]
[2020-05-12 02:29:00.288]  Step 150724  [3.037 sec/step, loss=0.09586, avg_loss=0.09028, mel_loss=0.04312, linear_loss=0.05274]
[2020-05-12 02:29:14.583]  Step 150725  [3.168 sec/step, loss=0.07543, avg_loss=0.09020, mel_loss=0.03565, linear_loss=0.03978]
[2020-05-12 02:29:18.137]  Step 150726  [3.195 sec/step, loss=0.09719, avg_loss=0.09034, mel_loss=0.04381, linear_loss=0.05338]
[2020-05-12 02:29:22.470]  Step 150727  [3.231 sec/step, loss=0.09740, avg_loss=0.09054, mel_loss=0.04424, linear_loss=0.05316]
[2020-05-12 02:29:24.209]  Generated 32 batches of size 32 in 1.733 sec
[2020-05-12 02:29:25.435]  Step 150728  [3.249 sec/step, loss=0.09332, avg_loss=0.09063, mel_loss=0.04173, linear_loss=0.05159]
[2020-05-12 02:29:26.710]  Step 150729  [3.251 sec/step, loss=0.08439, avg_loss=0.09064, mel_loss=0.03692, linear_loss=0.04747]
[2020-05-12 02:29:31.451]  Step 150730  [3.264 sec/step, loss=0.09666, avg_loss=0.09064, mel_loss=0.04392, linear_loss=0.05274]
[2020-05-12 02:29:33.734]  Step 150731  [3.252 sec/step, loss=0.09276, avg_loss=0.09061, mel_loss=0.04128, linear_loss=0.05148]
[2020-05-12 02:29:34.539]  Step 150732  [3.244 sec/step, loss=0.07589, avg_loss=0.09048, mel_loss=0.03286, linear_loss=0.04302]
[2020-05-12 02:29:36.361]  Step 150733  [3.249 sec/step, loss=0.08879, avg_loss=0.09052, mel_loss=0.03893, linear_loss=0.04986]
[2020-05-12 02:29:37.496]  Step 150734  [3.232 sec/step, loss=0.08555, avg_loss=0.09043, mel_loss=0.03666, linear_loss=0.04889]
[2020-05-12 02:29:40.613]  Step 150735  [3.242 sec/step, loss=0.09498, avg_loss=0.09047, mel_loss=0.04250, linear_loss=0.05248]
[2020-05-12 02:29:42.338]  Step 150736  [3.239 sec/step, loss=0.08909, avg_loss=0.09045, mel_loss=0.03953, linear_loss=0.04957]
[2020-05-12 02:29:46.479]  Step 150737  [3.262 sec/step, loss=0.09722, avg_loss=0.09053, mel_loss=0.04398, linear_loss=0.05324]
[2020-05-12 02:29:48.042]  Step 150738  [3.214 sec/step, loss=0.09066, avg_loss=0.09046, mel_loss=0.03984, linear_loss=0.05083]
[2020-05-12 02:29:51.072]  Step 150739  [3.237 sec/step, loss=0.09581, avg_loss=0.09070, mel_loss=0.04284, linear_loss=0.05297]
[2020-05-12 02:29:53.238]  Step 150740  [3.207 sec/step, loss=0.09202, avg_loss=0.09063, mel_loss=0.04078, linear_loss=0.05124]
[2020-05-12 02:29:58.328]  Step 150741  [3.241 sec/step, loss=0.09755, avg_loss=0.09069, mel_loss=0.04437, linear_loss=0.05318]
[2020-05-12 02:29:59.681]  Step 150742  [3.240 sec/step, loss=0.09008, avg_loss=0.09073, mel_loss=0.03944, linear_loss=0.05064]
[2020-05-12 02:30:02.858]  Step 150743  [3.243 sec/step, loss=0.09538, avg_loss=0.09071, mel_loss=0.04271, linear_loss=0.05268]
[2020-05-12 02:30:05.288]  Step 150744  [3.214 sec/step, loss=0.09254, avg_loss=0.09065, mel_loss=0.04072, linear_loss=0.05182]
[2020-05-12 02:30:06.027]  Step 150745  [3.205 sec/step, loss=0.07315, avg_loss=0.09048, mel_loss=0.03208, linear_loss=0.04107]
[2020-05-12 02:30:07.098]  Step 150746  [3.095 sec/step, loss=0.08641, avg_loss=0.09043, mel_loss=0.03727, linear_loss=0.04914]
[2020-05-12 02:30:09.810]  Step 150747  [3.096 sec/step, loss=0.09403, avg_loss=0.09044, mel_loss=0.04175, linear_loss=0.05228]
[2020-05-12 02:30:10.714]  Step 150748  [3.075 sec/step, loss=0.08037, avg_loss=0.09028, mel_loss=0.03461, linear_loss=0.04576]
[2020-05-12 02:30:13.079]  Step 150749  [3.086 sec/step, loss=0.09139, avg_loss=0.09032, mel_loss=0.04076, linear_loss=0.05063]
[2020-05-12 02:30:20.710]  Step 150750  [3.154 sec/step, loss=0.09796, avg_loss=0.09053, mel_loss=0.04560, linear_loss=0.05236]
[2020-05-12 02:30:20.710]  Writing summary at step: 150750
[2020-05-12 02:30:22.035]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150750
[2020-05-12 02:30:23.489]  Saving audio and alignment...
[2020-05-12 02:30:25.488]  Input: 또 장음이란~_____________
[2020-05-12 02:30:26.290]  Step 150751  [3.144 sec/step, loss=0.07987, avg_loss=0.09044, mel_loss=0.03451, linear_loss=0.04536]
[2020-05-12 02:30:35.135]  Step 150752  [3.227 sec/step, loss=0.09726, avg_loss=0.09066, mel_loss=0.04531, linear_loss=0.05195]
[2020-05-12 02:30:36.393]  Step 150753  [3.180 sec/step, loss=0.08306, avg_loss=0.09053, mel_loss=0.03609, linear_loss=0.04697]
[2020-05-12 02:30:42.061]  Step 150754  [3.219 sec/step, loss=0.09820, avg_loss=0.09061, mel_loss=0.04491, linear_loss=0.05329]
[2020-05-12 02:30:44.047]  Step 150755  [3.197 sec/step, loss=0.09224, avg_loss=0.09058, mel_loss=0.04084, linear_loss=0.05140]
[2020-05-12 02:30:45.814]  Step 150756  [3.186 sec/step, loss=0.08969, avg_loss=0.09056, mel_loss=0.03929, linear_loss=0.05040]
[2020-05-12 02:30:49.981]  Step 150757  [3.193 sec/step, loss=0.09735, avg_loss=0.09059, mel_loss=0.04406, linear_loss=0.05329]
[2020-05-12 02:30:51.694]  Generated 32 batches of size 32 in 1.707 sec
[2020-05-12 02:30:54.636]  Step 150758  [3.206 sec/step, loss=0.09773, avg_loss=0.09060, mel_loss=0.04447, linear_loss=0.05326]
[2020-05-12 02:30:57.482]  Step 150759  [3.210 sec/step, loss=0.09446, avg_loss=0.09063, mel_loss=0.04235, linear_loss=0.05211]
[2020-05-12 02:30:58.237]  Step 150760  [3.196 sec/step, loss=0.07361, avg_loss=0.09045, mel_loss=0.03251, linear_loss=0.04110]
[2020-05-12 02:31:00.051]  Step 150761  [3.178 sec/step, loss=0.08752, avg_loss=0.09036, mel_loss=0.03846, linear_loss=0.04906]
[2020-05-12 02:31:06.719]  Step 150762  [3.237 sec/step, loss=0.09756, avg_loss=0.09052, mel_loss=0.04493, linear_loss=0.05263]
[2020-05-12 02:31:21.131]  Step 150763  [3.367 sec/step, loss=0.07796, avg_loss=0.09044, mel_loss=0.03715, linear_loss=0.04081]
[2020-05-12 02:31:24.802]  Step 150764  [3.394 sec/step, loss=0.09737, avg_loss=0.09063, mel_loss=0.04389, linear_loss=0.05348]
[2020-05-12 02:31:26.426]  Step 150765  [3.367 sec/step, loss=0.08938, avg_loss=0.09053, mel_loss=0.03956, linear_loss=0.04982]
[2020-05-12 02:31:29.875]  Step 150766  [3.345 sec/step, loss=0.09447, avg_loss=0.09052, mel_loss=0.04292, linear_loss=0.05155]
[2020-05-12 02:31:36.145]  Step 150767  [3.388 sec/step, loss=0.09781, avg_loss=0.09059, mel_loss=0.04521, linear_loss=0.05260]
[2020-05-12 02:31:36.707]  Step 150768  [3.377 sec/step, loss=0.06993, avg_loss=0.09040, mel_loss=0.03068, linear_loss=0.03925]
[2020-05-12 02:31:37.540]  Step 150769  [3.299 sec/step, loss=0.07884, avg_loss=0.09022, mel_loss=0.03400, linear_loss=0.04483]
[2020-05-12 02:31:42.784]  Step 150770  [3.340 sec/step, loss=0.09730, avg_loss=0.09036, mel_loss=0.04469, linear_loss=0.05261]
[2020-05-12 02:31:44.219]  Step 150771  [3.318 sec/step, loss=0.08396, avg_loss=0.09022, mel_loss=0.03683, linear_loss=0.04713]
[2020-05-12 02:31:45.587]  Step 150772  [3.321 sec/step, loss=0.08613, avg_loss=0.09028, mel_loss=0.03754, linear_loss=0.04860]
[2020-05-12 02:31:50.336]  Step 150773  [3.356 sec/step, loss=0.09846, avg_loss=0.09040, mel_loss=0.04474, linear_loss=0.05372]
[2020-05-12 02:31:58.843]  Step 150774  [3.393 sec/step, loss=0.09695, avg_loss=0.09041, mel_loss=0.04503, linear_loss=0.05192]
[2020-05-12 02:32:04.765]  Step 150775  [3.367 sec/step, loss=0.09710, avg_loss=0.09041, mel_loss=0.04443, linear_loss=0.05267]
[2020-05-12 02:32:06.675]  Step 150776  [3.366 sec/step, loss=0.09160, avg_loss=0.09041, mel_loss=0.04015, linear_loss=0.05145]
[2020-05-12 02:32:11.410]  Step 150777  [3.395 sec/step, loss=0.09716, avg_loss=0.09048, mel_loss=0.04407, linear_loss=0.05308]
[2020-05-12 02:32:12.473]  Step 150778  [3.337 sec/step, loss=0.08081, avg_loss=0.09029, mel_loss=0.03516, linear_loss=0.04565]
[2020-05-12 02:32:14.060]  Step 150779  [3.289 sec/step, loss=0.08934, avg_loss=0.09019, mel_loss=0.03912, linear_loss=0.05021]
[2020-05-12 02:32:17.775]  Step 150780  [3.319 sec/step, loss=0.09637, avg_loss=0.09037, mel_loss=0.04343, linear_loss=0.05294]
[2020-05-12 02:32:20.694]  Step 150781  [3.320 sec/step, loss=0.09494, avg_loss=0.09036, mel_loss=0.04234, linear_loss=0.05260]
[2020-05-12 02:32:24.613]  Step 150782  [3.353 sec/step, loss=0.09561, avg_loss=0.09062, mel_loss=0.04307, linear_loss=0.05254]
[2020-05-12 02:32:27.309]  Step 150783  [3.367 sec/step, loss=0.09284, avg_loss=0.09071, mel_loss=0.04149, linear_loss=0.05134]
[2020-05-12 02:32:29.377]  Step 150784  [3.377 sec/step, loss=0.09052, avg_loss=0.09075, mel_loss=0.03995, linear_loss=0.05058]
[2020-05-12 02:32:31.816]  Step 150785  [3.355 sec/step, loss=0.09311, avg_loss=0.09070, mel_loss=0.04147, linear_loss=0.05164]
[2020-05-12 02:32:33.797]  Step 150786  [3.316 sec/step, loss=0.09112, avg_loss=0.09064, mel_loss=0.04010, linear_loss=0.05102]
[2020-05-12 02:32:37.288]  Step 150787  [3.310 sec/step, loss=0.09579, avg_loss=0.09063, mel_loss=0.04298, linear_loss=0.05282]
[2020-05-12 02:32:38.298]  Step 150788  [3.297 sec/step, loss=0.07937, avg_loss=0.09051, mel_loss=0.03438, linear_loss=0.04499]
[2020-05-12 02:32:40.840]  Step 150789  [3.292 sec/step, loss=0.09162, avg_loss=0.09047, mel_loss=0.04070, linear_loss=0.05092]
[2020-05-12 02:32:42.096]  Step 150790  [3.298 sec/step, loss=0.08662, avg_loss=0.09056, mel_loss=0.03788, linear_loss=0.04874]
[2020-05-12 02:32:42.672]  Generated 32 batches of size 32 in 1.827 sec
[2020-05-12 02:32:43.233]  Step 150791  [3.275 sec/step, loss=0.08517, avg_loss=0.09046, mel_loss=0.03690, linear_loss=0.04827]
[2020-05-12 02:32:44.089]  Step 150792  [3.272 sec/step, loss=0.07485, avg_loss=0.09035, mel_loss=0.03304, linear_loss=0.04180]
[2020-05-12 02:32:47.623]  Step 150793  [3.280 sec/step, loss=0.09537, avg_loss=0.09038, mel_loss=0.04293, linear_loss=0.05243]
[2020-05-12 02:32:50.799]  Step 150794  [3.291 sec/step, loss=0.09643, avg_loss=0.09040, mel_loss=0.04356, linear_loss=0.05287]
[2020-05-12 02:32:52.987]  Step 150795  [3.297 sec/step, loss=0.09260, avg_loss=0.09042, mel_loss=0.04113, linear_loss=0.05147]
[2020-05-12 02:33:05.128]  Step 150796  [3.409 sec/step, loss=0.08682, avg_loss=0.09046, mel_loss=0.04121, linear_loss=0.04560]
[2020-05-12 02:33:06.941]  Step 150797  [3.414 sec/step, loss=0.09038, avg_loss=0.09051, mel_loss=0.03959, linear_loss=0.05079]
[2020-05-12 02:33:14.521]  Step 150798  [3.447 sec/step, loss=0.09899, avg_loss=0.09053, mel_loss=0.04554, linear_loss=0.05345]
[2020-05-12 02:33:17.883]  Step 150799  [3.428 sec/step, loss=0.09616, avg_loss=0.09051, mel_loss=0.04339, linear_loss=0.05277]
[2020-05-12 02:33:19.169]  Step 150800  [3.296 sec/step, loss=0.08576, avg_loss=0.09059, mel_loss=0.03739, linear_loss=0.04836]
[2020-05-12 02:33:19.169]  Writing summary at step: 150800
[2020-05-12 02:33:23.286]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150800
[2020-05-12 02:33:28.036]  Saving audio and alignment...
[2020-05-12 02:33:30.315]  Input: 떨어지게 되고요~_____________
[2020-05-12 02:33:34.808]  Step 150801  [3.308 sec/step, loss=0.09673, avg_loss=0.09060, mel_loss=0.04385, linear_loss=0.05288]
[2020-05-12 02:33:36.199]  Step 150802  [3.304 sec/step, loss=0.08660, avg_loss=0.09057, mel_loss=0.03802, linear_loss=0.04858]
[2020-05-12 02:33:45.254]  Step 150803  [3.370 sec/step, loss=0.09603, avg_loss=0.09060, mel_loss=0.04461, linear_loss=0.05142]
[2020-05-12 02:33:47.436]  Step 150804  [3.357 sec/step, loss=0.08936, avg_loss=0.09053, mel_loss=0.03944, linear_loss=0.04992]
[2020-05-12 02:33:49.847]  Step 150805  [3.314 sec/step, loss=0.09151, avg_loss=0.09045, mel_loss=0.04078, linear_loss=0.05073]
[2020-05-12 02:33:54.106]  Step 150806  [3.343 sec/step, loss=0.09602, avg_loss=0.09053, mel_loss=0.04315, linear_loss=0.05286]
[2020-05-12 02:33:55.781]  Step 150807  [3.286 sec/step, loss=0.09028, avg_loss=0.09045, mel_loss=0.03956, linear_loss=0.05072]
[2020-05-12 02:33:59.472]  Step 150808  [3.296 sec/step, loss=0.09536, avg_loss=0.09046, mel_loss=0.04297, linear_loss=0.05239]
[2020-05-12 02:34:02.174]  Step 150809  [3.271 sec/step, loss=0.09266, avg_loss=0.09042, mel_loss=0.04131, linear_loss=0.05135]
[2020-05-12 02:34:05.104]  Step 150810  [3.275 sec/step, loss=0.09541, avg_loss=0.09047, mel_loss=0.04251, linear_loss=0.05290]
[2020-05-12 02:34:08.131]  Step 150811  [3.299 sec/step, loss=0.09535, avg_loss=0.09068, mel_loss=0.04277, linear_loss=0.05258]
[2020-05-12 02:34:13.208]  Step 150812  [3.293 sec/step, loss=0.09603, avg_loss=0.09065, mel_loss=0.04390, linear_loss=0.05214]
[2020-05-12 02:34:13.791]  Step 150813  [3.264 sec/step, loss=0.07186, avg_loss=0.09042, mel_loss=0.03176, linear_loss=0.04011]
[2020-05-12 02:34:15.827]  Step 150814  [3.271 sec/step, loss=0.09128, avg_loss=0.09047, mel_loss=0.04053, linear_loss=0.05076]
[2020-05-12 02:34:16.846]  Step 150815  [3.271 sec/step, loss=0.08126, avg_loss=0.09047, mel_loss=0.03528, linear_loss=0.04598]
[2020-05-12 02:34:23.494]  Step 150816  [3.316 sec/step, loss=0.09669, avg_loss=0.09052, mel_loss=0.04447, linear_loss=0.05222]
[2020-05-12 02:34:25.417]  Step 150817  [3.319 sec/step, loss=0.08876, avg_loss=0.09053, mel_loss=0.03925, linear_loss=0.04951]
[2020-05-12 02:34:30.945]  Step 150818  [3.354 sec/step, loss=0.09775, avg_loss=0.09061, mel_loss=0.04460, linear_loss=0.05315]
[2020-05-12 02:34:45.393]  Step 150819  [3.488 sec/step, loss=0.07489, avg_loss=0.09054, mel_loss=0.03546, linear_loss=0.03944]
[2020-05-12 02:34:46.362]  Step 150820  [3.489 sec/step, loss=0.07877, avg_loss=0.09056, mel_loss=0.03387, linear_loss=0.04489]
[2020-05-12 02:34:47.112]  Generated 32 batches of size 32 in 1.713 sec
[2020-05-12 02:34:47.167]  Step 150821  [3.478 sec/step, loss=0.08087, avg_loss=0.09045, mel_loss=0.03480, linear_loss=0.04608]
[2020-05-12 02:34:48.006]  Step 150822  [3.396 sec/step, loss=0.07808, avg_loss=0.09025, mel_loss=0.03391, linear_loss=0.04417]
[2020-05-12 02:34:51.498]  Step 150823  [3.394 sec/step, loss=0.09469, avg_loss=0.09022, mel_loss=0.04261, linear_loss=0.05208]
[2020-05-12 02:34:52.847]  Step 150824  [3.366 sec/step, loss=0.08565, avg_loss=0.09011, mel_loss=0.03745, linear_loss=0.04820]
[2020-05-12 02:34:57.392]  Step 150825  [3.269 sec/step, loss=0.09833, avg_loss=0.09034, mel_loss=0.04484, linear_loss=0.05349]
[2020-05-12 02:35:04.824]  Step 150826  [3.307 sec/step, loss=0.09869, avg_loss=0.09036, mel_loss=0.04578, linear_loss=0.05291]
[2020-05-12 02:35:06.584]  Step 150827  [3.282 sec/step, loss=0.08947, avg_loss=0.09028, mel_loss=0.03921, linear_loss=0.05026]
[2020-05-12 02:35:08.100]  Step 150828  [3.267 sec/step, loss=0.08870, avg_loss=0.09023, mel_loss=0.03894, linear_loss=0.04976]
[2020-05-12 02:35:16.993]  Step 150829  [3.343 sec/step, loss=0.09747, avg_loss=0.09036, mel_loss=0.04530, linear_loss=0.05217]
[2020-05-12 02:35:17.956]  Step 150830  [3.306 sec/step, loss=0.08137, avg_loss=0.09021, mel_loss=0.03537, linear_loss=0.04600]
[2020-05-12 02:35:25.565]  Step 150831  [3.359 sec/step, loss=0.09849, avg_loss=0.09027, mel_loss=0.04524, linear_loss=0.05324]
[2020-05-12 02:35:26.665]  Step 150832  [3.362 sec/step, loss=0.08479, avg_loss=0.09036, mel_loss=0.03692, linear_loss=0.04788]
[2020-05-12 02:35:28.729]  Step 150833  [3.364 sec/step, loss=0.09044, avg_loss=0.09037, mel_loss=0.03980, linear_loss=0.05064]
[2020-05-12 02:35:29.533]  Step 150834  [3.361 sec/step, loss=0.07746, avg_loss=0.09029, mel_loss=0.03352, linear_loss=0.04394]
[2020-05-12 02:35:31.946]  Step 150835  [3.354 sec/step, loss=0.09278, avg_loss=0.09027, mel_loss=0.04100, linear_loss=0.05178]
[2020-05-12 02:35:35.034]  Step 150836  [3.367 sec/step, loss=0.09676, avg_loss=0.09035, mel_loss=0.04348, linear_loss=0.05328]
[2020-05-12 02:35:36.975]  Step 150837  [3.345 sec/step, loss=0.09135, avg_loss=0.09029, mel_loss=0.04021, linear_loss=0.05114]
[2020-05-12 02:35:43.348]  Step 150838  [3.394 sec/step, loss=0.09966, avg_loss=0.09038, mel_loss=0.04604, linear_loss=0.05362]
[2020-05-12 02:35:46.748]  Step 150839  [3.397 sec/step, loss=0.09554, avg_loss=0.09038, mel_loss=0.04255, linear_loss=0.05298]
[2020-05-12 02:35:47.303]  Step 150840  [3.381 sec/step, loss=0.07141, avg_loss=0.09017, mel_loss=0.03222, linear_loss=0.03919]
[2020-05-12 02:35:48.459]  Step 150841  [3.342 sec/step, loss=0.08442, avg_loss=0.09004, mel_loss=0.03691, linear_loss=0.04751]
[2020-05-12 02:36:00.305]  Step 150842  [3.447 sec/step, loss=0.09103, avg_loss=0.09005, mel_loss=0.04333, linear_loss=0.04770]
[2020-05-12 02:36:01.770]  Step 150843  [3.430 sec/step, loss=0.08514, avg_loss=0.08995, mel_loss=0.03732, linear_loss=0.04782]
[2020-05-12 02:36:07.105]  Step 150844  [3.459 sec/step, loss=0.09870, avg_loss=0.09001, mel_loss=0.04507, linear_loss=0.05363]
[2020-05-12 02:36:09.798]  Step 150845  [3.478 sec/step, loss=0.09293, avg_loss=0.09021, mel_loss=0.04142, linear_loss=0.05151]
[2020-05-12 02:36:10.792]  Step 150846  [3.477 sec/step, loss=0.07964, avg_loss=0.09014, mel_loss=0.03449, linear_loss=0.04515]
[2020-05-12 02:36:12.501]  Step 150847  [3.467 sec/step, loss=0.09301, avg_loss=0.09013, mel_loss=0.04074, linear_loss=0.05227]
[2020-05-12 02:36:13.850]  Step 150848  [3.472 sec/step, loss=0.08705, avg_loss=0.09019, mel_loss=0.03811, linear_loss=0.04894]
[2020-05-12 02:36:19.539]  Step 150849  [3.505 sec/step, loss=0.10136, avg_loss=0.09029, mel_loss=0.04660, linear_loss=0.05476]
[2020-05-12 02:36:20.291]  Step 150850  [3.436 sec/step, loss=0.07648, avg_loss=0.09008, mel_loss=0.03299, linear_loss=0.04349]
[2020-05-12 02:36:20.291]  Writing summary at step: 150850
[2020-05-12 02:36:25.202]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150850
[2020-05-12 02:36:26.669]  Saving audio and alignment...
[2020-05-12 02:36:28.848]  Generated 32 batches of size 32 in 1.632 sec
[2020-05-12 02:36:33.374]  Input: 대본에만 충실하며언 그냥 순서를 나열하는데 그치게 되겠죠~__________________________
[2020-05-12 02:36:35.138]  Step 150851  [3.446 sec/step, loss=0.09093, avg_loss=0.09019, mel_loss=0.03974, linear_loss=0.05119]
[2020-05-12 02:36:38.594]  Step 150852  [3.392 sec/step, loss=0.09478, avg_loss=0.09016, mel_loss=0.04241, linear_loss=0.05237]
[2020-05-12 02:36:40.330]  Step 150853  [3.397 sec/step, loss=0.08713, avg_loss=0.09021, mel_loss=0.03859, linear_loss=0.04854]
[2020-05-12 02:36:42.593]  Step 150854  [3.363 sec/step, loss=0.09397, avg_loss=0.09016, mel_loss=0.04164, linear_loss=0.05233]
[2020-05-12 02:36:46.806]  Step 150855  [3.385 sec/step, loss=0.09603, avg_loss=0.09020, mel_loss=0.04327, linear_loss=0.05276]
[2020-05-12 02:36:50.503]  Step 150856  [3.404 sec/step, loss=0.09826, avg_loss=0.09029, mel_loss=0.04440, linear_loss=0.05386]
[2020-05-12 02:36:53.326]  Step 150857  [3.391 sec/step, loss=0.09369, avg_loss=0.09025, mel_loss=0.04215, linear_loss=0.05153]
[2020-05-12 02:36:55.578]  Step 150858  [3.367 sec/step, loss=0.09278, avg_loss=0.09020, mel_loss=0.04121, linear_loss=0.05157]
[2020-05-12 02:36:58.039]  Step 150859  [3.363 sec/step, loss=0.09201, avg_loss=0.09018, mel_loss=0.04067, linear_loss=0.05134]
[2020-05-12 02:37:00.625]  Step 150860  [3.381 sec/step, loss=0.09438, avg_loss=0.09038, mel_loss=0.04215, linear_loss=0.05223]
[2020-05-12 02:37:01.615]  Step 150861  [3.373 sec/step, loss=0.08215, avg_loss=0.09033, mel_loss=0.03580, linear_loss=0.04635]
[2020-05-12 02:37:02.865]  Step 150862  [3.319 sec/step, loss=0.08595, avg_loss=0.09021, mel_loss=0.03738, linear_loss=0.04857]
[2020-05-12 02:37:03.708]  Step 150863  [3.183 sec/step, loss=0.07548, avg_loss=0.09019, mel_loss=0.03301, linear_loss=0.04247]
[2020-05-12 02:37:09.789]  Step 150864  [3.207 sec/step, loss=0.09637, avg_loss=0.09018, mel_loss=0.04426, linear_loss=0.05211]
[2020-05-12 02:37:13.312]  Step 150865  [3.226 sec/step, loss=0.09541, avg_loss=0.09024, mel_loss=0.04286, linear_loss=0.05255]
[2020-05-12 02:37:16.649]  Step 150866  [3.225 sec/step, loss=0.09571, avg_loss=0.09025, mel_loss=0.04278, linear_loss=0.05293]
[2020-05-12 02:37:20.313]  Step 150867  [3.199 sec/step, loss=0.09580, avg_loss=0.09023, mel_loss=0.04313, linear_loss=0.05266]
[2020-05-12 02:37:21.704]  Step 150868  [3.207 sec/step, loss=0.08428, avg_loss=0.09038, mel_loss=0.03673, linear_loss=0.04755]
[2020-05-12 02:37:22.856]  Step 150869  [3.211 sec/step, loss=0.08107, avg_loss=0.09040, mel_loss=0.03506, linear_loss=0.04601]
[2020-05-12 02:37:23.653]  Step 150870  [3.166 sec/step, loss=0.07573, avg_loss=0.09018, mel_loss=0.03247, linear_loss=0.04326]
[2020-05-12 02:37:26.014]  Step 150871  [3.175 sec/step, loss=0.09265, avg_loss=0.09027, mel_loss=0.04129, linear_loss=0.05136]
[2020-05-12 02:37:30.146]  Step 150872  [3.203 sec/step, loss=0.09666, avg_loss=0.09037, mel_loss=0.04385, linear_loss=0.05281]
[2020-05-12 02:37:32.311]  Step 150873  [3.177 sec/step, loss=0.09177, avg_loss=0.09031, mel_loss=0.04073, linear_loss=0.05104]
[2020-05-12 02:37:33.206]  Step 150874  [3.101 sec/step, loss=0.07997, avg_loss=0.09014, mel_loss=0.03436, linear_loss=0.04561]
[2020-05-12 02:37:35.056]  Step 150875  [3.060 sec/step, loss=0.08942, avg_loss=0.09006, mel_loss=0.03919, linear_loss=0.05023]
[2020-05-12 02:37:38.641]  Step 150876  [3.077 sec/step, loss=0.09859, avg_loss=0.09013, mel_loss=0.04440, linear_loss=0.05418]
[2020-05-12 02:37:41.474]  Step 150877  [3.058 sec/step, loss=0.09445, avg_loss=0.09010, mel_loss=0.04244, linear_loss=0.05202]
[2020-05-12 02:37:48.466]  Step 150878  [3.117 sec/step, loss=0.09770, avg_loss=0.09027, mel_loss=0.04520, linear_loss=0.05251]
[2020-05-12 02:37:54.007]  Step 150879  [3.157 sec/step, loss=0.09648, avg_loss=0.09034, mel_loss=0.04404, linear_loss=0.05245]
[2020-05-12 02:37:58.477]  Step 150880  [3.164 sec/step, loss=0.09869, avg_loss=0.09037, mel_loss=0.04488, linear_loss=0.05381]
[2020-05-12 02:38:00.072]  Step 150881  [3.151 sec/step, loss=0.09012, avg_loss=0.09032, mel_loss=0.03958, linear_loss=0.05054]
[2020-05-12 02:38:01.746]  Generated 32 batches of size 32 in 1.670 sec
[2020-05-12 02:38:02.208]  Step 150882  [3.133 sec/step, loss=0.08859, avg_loss=0.09025, mel_loss=0.03922, linear_loss=0.04936]
[2020-05-12 02:38:06.269]  Step 150883  [3.147 sec/step, loss=0.09651, avg_loss=0.09029, mel_loss=0.04345, linear_loss=0.05306]
[2020-05-12 02:38:07.860]  Step 150884  [3.142 sec/step, loss=0.08900, avg_loss=0.09027, mel_loss=0.03903, linear_loss=0.04996]
[2020-05-12 02:38:12.761]  Step 150885  [3.167 sec/step, loss=0.09705, avg_loss=0.09031, mel_loss=0.04415, linear_loss=0.05290]
[2020-05-12 02:38:13.292]  Step 150886  [3.152 sec/step, loss=0.07019, avg_loss=0.09010, mel_loss=0.03121, linear_loss=0.03898]
[2020-05-12 02:38:26.370]  Step 150887  [3.248 sec/step, loss=0.08281, avg_loss=0.08997, mel_loss=0.03898, linear_loss=0.04383]
[2020-05-12 02:38:35.067]  Step 150888  [3.325 sec/step, loss=0.09570, avg_loss=0.09013, mel_loss=0.04445, linear_loss=0.05125]
[2020-05-12 02:38:36.512]  Step 150889  [3.314 sec/step, loss=0.08944, avg_loss=0.09011, mel_loss=0.03951, linear_loss=0.04993]
[2020-05-12 02:38:38.271]  Step 150890  [3.319 sec/step, loss=0.08878, avg_loss=0.09013, mel_loss=0.03880, linear_loss=0.04997]
[2020-05-12 02:38:42.620]  Step 150891  [3.351 sec/step, loss=0.09604, avg_loss=0.09024, mel_loss=0.04376, linear_loss=0.05228]
[2020-05-12 02:38:43.180]  Step 150892  [3.348 sec/step, loss=0.07160, avg_loss=0.09021, mel_loss=0.03167, linear_loss=0.03993]
[2020-05-12 02:38:50.660]  Step 150893  [3.388 sec/step, loss=0.09896, avg_loss=0.09025, mel_loss=0.04560, linear_loss=0.05336]
[2020-05-12 02:38:52.651]  Step 150894  [3.376 sec/step, loss=0.09319, avg_loss=0.09021, mel_loss=0.04104, linear_loss=0.05215]
[2020-05-12 02:38:58.102]  Step 150895  [3.409 sec/step, loss=0.09686, avg_loss=0.09026, mel_loss=0.04430, linear_loss=0.05256]
[2020-05-12 02:39:00.667]  Step 150896  [3.313 sec/step, loss=0.09190, avg_loss=0.09031, mel_loss=0.04061, linear_loss=0.05128]
[2020-05-12 02:39:02.796]  Step 150897  [3.316 sec/step, loss=0.09082, avg_loss=0.09031, mel_loss=0.04000, linear_loss=0.05082]
[2020-05-12 02:39:03.855]  Step 150898  [3.251 sec/step, loss=0.08563, avg_loss=0.09018, mel_loss=0.03711, linear_loss=0.04851]
[2020-05-12 02:39:05.309]  Step 150899  [3.232 sec/step, loss=0.08693, avg_loss=0.09009, mel_loss=0.03832, linear_loss=0.04861]
[2020-05-12 02:39:08.063]  Step 150900  [3.246 sec/step, loss=0.09365, avg_loss=0.09016, mel_loss=0.04174, linear_loss=0.05191]
[2020-05-12 02:39:08.063]  Writing summary at step: 150900
[2020-05-12 02:39:08.850]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150900
[2020-05-12 02:39:10.332]  Saving audio and alignment...
[2020-05-12 02:39:13.391]  Input: 잠깐 쉬어 주시는 것이 좋습니~________
[2020-05-12 02:39:16.326]  Step 150901  [3.231 sec/step, loss=0.09338, avg_loss=0.09013, mel_loss=0.04161, linear_loss=0.05177]
[2020-05-12 02:39:18.153]  Step 150902  [3.235 sec/step, loss=0.08934, avg_loss=0.09016, mel_loss=0.03913, linear_loss=0.05021]
[2020-05-12 02:39:20.081]  Step 150903  [3.164 sec/step, loss=0.09098, avg_loss=0.09011, mel_loss=0.04008, linear_loss=0.05090]
[2020-05-12 02:39:24.213]  Step 150904  [3.183 sec/step, loss=0.09718, avg_loss=0.09019, mel_loss=0.04384, linear_loss=0.05333]
[2020-05-12 02:39:29.865]  Step 150905  [3.216 sec/step, loss=0.09709, avg_loss=0.09024, mel_loss=0.04417, linear_loss=0.05292]
[2020-05-12 02:39:38.344]  Step 150906  [3.258 sec/step, loss=0.09528, avg_loss=0.09023, mel_loss=0.04428, linear_loss=0.05100]
[2020-05-12 02:39:40.736]  Step 150907  [3.265 sec/step, loss=0.09242, avg_loss=0.09026, mel_loss=0.04122, linear_loss=0.05120]
[2020-05-12 02:39:44.257]  Step 150908  [3.263 sec/step, loss=0.09615, avg_loss=0.09026, mel_loss=0.04327, linear_loss=0.05288]
[2020-05-12 02:39:58.188]  Step 150909  [3.376 sec/step, loss=0.07522, avg_loss=0.09009, mel_loss=0.03600, linear_loss=0.03922]
[2020-05-12 02:39:59.307]  Step 150910  [3.358 sec/step, loss=0.08518, avg_loss=0.08999, mel_loss=0.03722, linear_loss=0.04796]
[2020-05-12 02:40:00.623]  Step 150911  [3.341 sec/step, loss=0.08578, avg_loss=0.08989, mel_loss=0.03748, linear_loss=0.04830]
[2020-05-12 02:40:02.041]  Step 150912  [3.304 sec/step, loss=0.08838, avg_loss=0.08981, mel_loss=0.03865, linear_loss=0.04973]
[2020-05-12 02:40:02.388]  Generated 32 batches of size 32 in 1.760 sec
[2020-05-12 02:40:05.229]  Step 150913  [3.330 sec/step, loss=0.09657, avg_loss=0.09006, mel_loss=0.04360, linear_loss=0.05297]
[2020-05-12 02:40:06.061]  Step 150914  [3.318 sec/step, loss=0.07695, avg_loss=0.08992, mel_loss=0.03358, linear_loss=0.04338]
[2020-05-12 02:40:12.733]  Step 150915  [3.375 sec/step, loss=0.09971, avg_loss=0.09010, mel_loss=0.04600, linear_loss=0.05371]
[2020-05-12 02:40:17.369]  Step 150916  [3.354 sec/step, loss=0.09689, avg_loss=0.09010, mel_loss=0.04396, linear_loss=0.05293]
[2020-05-12 02:40:18.363]  Step 150917  [3.345 sec/step, loss=0.07996, avg_loss=0.09002, mel_loss=0.03479, linear_loss=0.04517]
[2020-05-12 02:40:19.348]  Step 150918  [3.300 sec/step, loss=0.08511, avg_loss=0.08989, mel_loss=0.03698, linear_loss=0.04813]
[2020-05-12 02:40:22.993]  Step 150919  [3.192 sec/step, loss=0.09644, avg_loss=0.09011, mel_loss=0.04329, linear_loss=0.05315]
[2020-05-12 02:40:26.097]  Step 150920  [3.213 sec/step, loss=0.09747, avg_loss=0.09029, mel_loss=0.04371, linear_loss=0.05376]
[2020-05-12 02:40:31.047]  Step 150921  [3.254 sec/step, loss=0.09854, avg_loss=0.09047, mel_loss=0.04487, linear_loss=0.05367]
[2020-05-12 02:40:32.284]  Step 150922  [3.258 sec/step, loss=0.08409, avg_loss=0.09053, mel_loss=0.03661, linear_loss=0.04747]
[2020-05-12 02:40:33.172]  Step 150923  [3.232 sec/step, loss=0.07918, avg_loss=0.09037, mel_loss=0.03430, linear_loss=0.04488]
[2020-05-12 02:40:35.181]  Step 150924  [3.239 sec/step, loss=0.09311, avg_loss=0.09045, mel_loss=0.04121, linear_loss=0.05190]
[2020-05-12 02:40:36.588]  Step 150925  [3.208 sec/step, loss=0.08732, avg_loss=0.09034, mel_loss=0.03834, linear_loss=0.04898]
[2020-05-12 02:40:37.958]  Step 150926  [3.147 sec/step, loss=0.08374, avg_loss=0.09019, mel_loss=0.03678, linear_loss=0.04696]
[2020-05-12 02:40:39.740]  Step 150927  [3.147 sec/step, loss=0.08909, avg_loss=0.09019, mel_loss=0.03928, linear_loss=0.04981]
[2020-05-12 02:40:46.531]  Step 150928  [3.200 sec/step, loss=0.09629, avg_loss=0.09026, mel_loss=0.04454, linear_loss=0.05175]
[2020-05-12 02:41:00.956]  Step 150929  [3.255 sec/step, loss=0.07908, avg_loss=0.09008, mel_loss=0.03767, linear_loss=0.04141]
[2020-05-12 02:41:05.595]  Step 150930  [3.292 sec/step, loss=0.09899, avg_loss=0.09025, mel_loss=0.04504, linear_loss=0.05395]
[2020-05-12 02:41:10.197]  Step 150931  [3.262 sec/step, loss=0.09664, avg_loss=0.09024, mel_loss=0.04370, linear_loss=0.05294]
[2020-05-12 02:41:12.049]  Step 150932  [3.269 sec/step, loss=0.08954, avg_loss=0.09028, mel_loss=0.03933, linear_loss=0.05020]
[2020-05-12 02:41:14.065]  Step 150933  [3.269 sec/step, loss=0.09141, avg_loss=0.09029, mel_loss=0.04057, linear_loss=0.05083]
[2020-05-12 02:41:21.805]  Step 150934  [3.338 sec/step, loss=0.09911, avg_loss=0.09051, mel_loss=0.04608, linear_loss=0.05304]
[2020-05-12 02:41:22.606]  Step 150935  [3.322 sec/step, loss=0.07690, avg_loss=0.09035, mel_loss=0.03309, linear_loss=0.04381]
[2020-05-12 02:41:26.022]  Step 150936  [3.326 sec/step, loss=0.09437, avg_loss=0.09033, mel_loss=0.04285, linear_loss=0.05152]
[2020-05-12 02:41:26.873]  Step 150937  [3.315 sec/step, loss=0.07766, avg_loss=0.09019, mel_loss=0.03383, linear_loss=0.04383]
[2020-05-12 02:41:29.169]  Step 150938  [3.274 sec/step, loss=0.09030, avg_loss=0.09010, mel_loss=0.04028, linear_loss=0.05002]
[2020-05-12 02:41:32.177]  Step 150939  [3.270 sec/step, loss=0.09489, avg_loss=0.09009, mel_loss=0.04259, linear_loss=0.05230]
[2020-05-12 02:41:33.754]  Step 150940  [3.280 sec/step, loss=0.08822, avg_loss=0.09026, mel_loss=0.03866, linear_loss=0.04956]
[2020-05-12 02:41:37.773]  Step 150941  [3.309 sec/step, loss=0.09755, avg_loss=0.09039, mel_loss=0.04395, linear_loss=0.05360]
[2020-05-12 02:41:40.630]  Step 150942  [3.219 sec/step, loss=0.09365, avg_loss=0.09041, mel_loss=0.04203, linear_loss=0.05162]
[2020-05-12 02:41:41.657]  Step 150943  [3.215 sec/step, loss=0.08077, avg_loss=0.09037, mel_loss=0.03526, linear_loss=0.04551]
[2020-05-12 02:41:43.597]  Generated 32 batches of size 32 in 1.934 sec
[2020-05-12 02:41:44.240]  Step 150944  [3.187 sec/step, loss=0.09130, avg_loss=0.09030, mel_loss=0.04051, linear_loss=0.05078]
[2020-05-12 02:41:49.854]  Step 150945  [3.216 sec/step, loss=0.09728, avg_loss=0.09034, mel_loss=0.04458, linear_loss=0.05270]
[2020-05-12 02:41:58.899]  Step 150946  [3.297 sec/step, loss=0.09753, avg_loss=0.09052, mel_loss=0.04544, linear_loss=0.05209]
[2020-05-12 02:42:01.657]  Step 150947  [3.307 sec/step, loss=0.09198, avg_loss=0.09051, mel_loss=0.04082, linear_loss=0.05115]
[2020-05-12 02:42:02.790]  Step 150948  [3.305 sec/step, loss=0.08438, avg_loss=0.09048, mel_loss=0.03648, linear_loss=0.04789]
[2020-05-12 02:42:04.444]  Step 150949  [3.265 sec/step, loss=0.09232, avg_loss=0.09039, mel_loss=0.04073, linear_loss=0.05159]
[2020-05-12 02:42:05.014]  Step 150950  [3.263 sec/step, loss=0.07052, avg_loss=0.09033, mel_loss=0.03103, linear_loss=0.03949]
[2020-05-12 02:42:05.015]  Writing summary at step: 150950
[2020-05-12 02:42:08.453]  Saving checkpoint to: ./logs-tacotron/model.ckpt-150950
[2020-05-12 02:42:09.980]  Saving audio and alignment...
[2020-05-12 02:42:15.865]  Input: 바로 여러분의 목소리에 맞춰 새 인생에 출발을 하려고 합니다~__________
[2020-05-12 02:42:19.126]  Step 150951  [3.278 sec/step, loss=0.09623, avg_loss=0.09039, mel_loss=0.04347, linear_loss=0.05276]
[2020-05-12 02:42:20.178]  Step 150952  [3.254 sec/step, loss=0.08183, avg_loss=0.09026, mel_loss=0.03533, linear_loss=0.04650]
[2020-05-12 02:42:22.317]  Step 150953  [3.258 sec/step, loss=0.09292, avg_loss=0.09031, mel_loss=0.04112, linear_loss=0.05180]
[2020-05-12 02:42:24.911]  Step 150954  [3.261 sec/step, loss=0.09346, avg_loss=0.09031, mel_loss=0.04156, linear_loss=0.05191]
[2020-05-12 02:42:26.776]  Step 150955  [3.238 sec/step, loss=0.08913, avg_loss=0.09024, mel_loss=0.03920, linear_loss=0.04992]
[2020-05-12 02:42:40.264]  Step 150956  [3.336 sec/step, loss=0.08215, avg_loss=0.09008, mel_loss=0.03872, linear_loss=0.04342]
[2020-05-12 02:42:44.475]  Step 150957  [3.349 sec/step, loss=0.09746, avg_loss=0.09012, mel_loss=0.04433, linear_loss=0.05313]
[2020-05-12 02:42:45.796]  Step 150958  [3.340 sec/step, loss=0.08308, avg_loss=0.09002, mel_loss=0.03656, linear_loss=0.04651]
[2020-05-12 02:42:47.447]  Step 150959  [3.332 sec/step, loss=0.08954, avg_loss=0.08999, mel_loss=0.03947, linear_loss=0.05006]
[2020-05-12 02:42:54.270]  Step 150960  [3.374 sec/step, loss=0.09832, avg_loss=0.09003, mel_loss=0.04519, linear_loss=0.05313]
[2020-05-12 02:43:02.558]  Step 150961  [3.447 sec/step, loss=0.09721, avg_loss=0.09018, mel_loss=0.04514, linear_loss=0.05206]
[2020-05-12 02:43:06.039]  Step 150962  [3.470 sec/step, loss=0.09499, avg_loss=0.09028, mel_loss=0.04284, linear_loss=0.05215]
[2020-05-12 02:43:06.895]  Step 150963  [3.470 sec/step, loss=0.07581, avg_loss=0.09028, mel_loss=0.03277, linear_loss=0.04304]
[2020-05-12 02:43:09.531]  Step 150964  [3.435 sec/step, loss=0.09376, avg_loss=0.09025, mel_loss=0.04190, linear_loss=0.05186]
[2020-05-12 02:43:12.518]  Step 150965  [3.430 sec/step, loss=0.09617, avg_loss=0.09026, mel_loss=0.04271, linear_loss=0.05347]
[2020-05-12 02:43:15.923]  Step 150966  [3.431 sec/step, loss=0.09646, avg_loss=0.09027, mel_loss=0.04321, linear_loss=0.05325]
[2020-05-12 02:43:16.757]  Step 150967  [3.402 sec/step, loss=0.07355, avg_loss=0.09004, mel_loss=0.03202, linear_loss=0.04153]
[2020-05-12 02:43:18.112]  Step 150968  [3.402 sec/step, loss=0.08711, avg_loss=0.09007, mel_loss=0.03813, linear_loss=0.04898]
[2020-05-12 02:43:20.701]  Step 150969  [3.416 sec/step, loss=0.09258, avg_loss=0.09019, mel_loss=0.04118, linear_loss=0.05140]
[2020-05-12 02:43:25.496]  Step 150970  [3.456 sec/step, loss=0.09701, avg_loss=0.09040, mel_loss=0.04395, linear_loss=0.05306]
[2020-05-12 02:43:29.311]  Step 150971  [3.471 sec/step, loss=0.09842, avg_loss=0.09046, mel_loss=0.04442, linear_loss=0.05401]
[2020-05-12 02:43:30.974]  Step 150972  [3.446 sec/step, loss=0.08141, avg_loss=0.09031, mel_loss=0.03540, linear_loss=0.04601]
[2020-05-12 02:43:34.127]  Step 150973  [3.456 sec/step, loss=0.08870, avg_loss=0.09028, mel_loss=0.03913, linear_loss=0.04957]
[2020-05-12 02:43:37.663]  Generated 32 batches of size 32 in 3.526 sec
[2020-05-12 02:43:37.758]  Step 150974  [3.483 sec/step, loss=0.09057, avg_loss=0.09038, mel_loss=0.04027, linear_loss=0.05030]
[2020-05-12 02:43:44.869]  Step 150975  [3.536 sec/step, loss=0.09731, avg_loss=0.09046, mel_loss=0.04460, linear_loss=0.05272]
[2020-05-12 02:43:46.368]  Step 150976  [3.515 sec/step, loss=0.08936, avg_loss=0.09037, mel_loss=0.03941, linear_loss=0.04995]
[2020-05-12 02:43:52.463]  Step 150977  [3.548 sec/step, loss=0.09898, avg_loss=0.09041, mel_loss=0.04549, linear_loss=0.05349]
[2020-05-12 02:43:53.221]  Step 150978  [3.486 sec/step, loss=0.07767, avg_loss=0.09021, mel_loss=0.03425, linear_loss=0.04342]
[2020-05-12 02:43:57.103]  Step 150979  [3.469 sec/step, loss=0.09461, avg_loss=0.09019, mel_loss=0.04282, linear_loss=0.05179]
[2020-05-12 02:43:58.205]  Step 150980  [3.435 sec/step, loss=0.08613, avg_loss=0.09007, mel_loss=0.03699, linear_loss=0.04914]
[2020-05-12 02:44:00.024]  Step 150981  [3.437 sec/step, loss=0.08695, avg_loss=0.09004, mel_loss=0.03827, linear_loss=0.04869]
[2020-05-12 02:44:07.242]  Step 150982  [3.488 sec/step, loss=0.10022, avg_loss=0.09015, mel_loss=0.04630, linear_loss=0.05392]
[2020-05-12 02:44:07.969]  Step 150983  [3.455 sec/step, loss=0.07564, avg_loss=0.08994, mel_loss=0.03301, linear_loss=0.04263]
[2020-05-12 02:44:12.190]  Step 150984  [3.481 sec/step, loss=0.09699, avg_loss=0.09002, mel_loss=0.04376, linear_loss=0.05323]
[2020-05-12 02:44:13.805]  Step 150985  [3.448 sec/step, loss=0.09075, avg_loss=0.08996, mel_loss=0.03991, linear_loss=0.05084]
[2020-05-12 02:44:17.805]  Step 150986  [3.483 sec/step, loss=0.09659, avg_loss=0.09023, mel_loss=0.04361, linear_loss=0.05297]
[2020-05-12 02:44:20.657]  Step 150987  [3.381 sec/step, loss=0.09308, avg_loss=0.09033, mel_loss=0.04178, linear_loss=0.05130]
[2020-05-12 02:44:21.636]  Step 150988  [3.304 sec/step, loss=0.08273, avg_loss=0.09020, mel_loss=0.03599, linear_loss=0.04673]
[2020-05-12 02:44:23.634]  Step 150989  [3.309 sec/step, loss=0.09089, avg_loss=0.09021, mel_loss=0.04024, linear_loss=0.05065]
[2020-05-12 02:44:25.401]  Step 150990  [3.309 sec/step, loss=0.08964, avg_loss=0.09022, mel_loss=0.03913, linear_loss=0.05051]
[2020-05-12 02:44:28.491]  Step 150991  [3.297 sec/step, loss=0.09715, avg_loss=0.09023, mel_loss=0.04353, linear_loss=0.05362]
[2020-05-12 02:44:32.969]  Step 150992  [3.336 sec/step, loss=0.09889, avg_loss=0.09051, mel_loss=0.04484, linear_loss=0.05406]
[2020-05-12 02:44:35.998]  Step 150993  [3.291 sec/step, loss=0.09520, avg_loss=0.09047, mel_loss=0.04250, linear_loss=0.05270]
[2020-05-12 02:44:44.918]  Step 150994  [3.361 sec/step, loss=0.09771, avg_loss=0.09051, mel_loss=0.04546, linear_loss=0.05225]
[2020-05-12 02:44:47.055]  Step 150995  [3.327 sec/step, loss=0.09182, avg_loss=0.09046, mel_loss=0.04079, linear_loss=0.05103]
[2020-05-12 02:44:52.541]  Step 150996  [3.357 sec/step, loss=0.09865, avg_loss=0.09053, mel_loss=0.04501, linear_loss=0.05363]
[2020-05-12 02:44:59.984]  Step 150997  [3.410 sec/step, loss=0.09653, avg_loss=0.09059, mel_loss=0.04448, linear_loss=0.05205]
[2020-05-12 02:45:00.548]  Step 150998  [3.405 sec/step, loss=0.06771, avg_loss=0.09041, mel_loss=0.02968, linear_loss=0.03803]
[2020-05-12 02:45:03.280]  Step 150999  [3.418 sec/step, loss=0.09202, avg_loss=0.09046, mel_loss=0.04101, linear_loss=0.05101]
[2020-05-12 02:45:05.485]  Step 151000  [3.412 sec/step, loss=0.09126, avg_loss=0.09044, mel_loss=0.04038, linear_loss=0.05088]
[2020-05-12 02:45:05.485]  Writing summary at step: 151000
[2020-05-12 02:45:10.388]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151000
[2020-05-12 02:45:11.845]  Saving audio and alignment...
[2020-05-12 02:45:17.550]  Input: 그 질문 접하니까 어린 시절 아버지가 하신 말씀이 떠오르는데요~________
[2020-05-12 02:45:19.403]  Step 151001  [3.401 sec/step, loss=0.09008, avg_loss=0.09040, mel_loss=0.03942, linear_loss=0.05065]
[2020-05-12 02:45:20.479]  Step 151002  [3.394 sec/step, loss=0.08444, avg_loss=0.09035, mel_loss=0.03662, linear_loss=0.04782]
[2020-05-12 02:45:23.971]  Step 151003  [3.409 sec/step, loss=0.09535, avg_loss=0.09040, mel_loss=0.04293, linear_loss=0.05242]
[2020-05-12 02:45:25.576]  Step 151004  [3.384 sec/step, loss=0.08809, avg_loss=0.09031, mel_loss=0.03853, linear_loss=0.04955]
[2020-05-12 02:45:25.781]  Generated 32 batches of size 32 in 1.804 sec
[2020-05-12 02:45:31.544]  Step 151005  [3.387 sec/step, loss=0.09596, avg_loss=0.09029, mel_loss=0.04419, linear_loss=0.05178]
[2020-05-12 02:45:32.696]  Step 151006  [3.314 sec/step, loss=0.08259, avg_loss=0.09017, mel_loss=0.03625, linear_loss=0.04634]
[2020-05-12 02:45:46.838]  Step 151007  [3.432 sec/step, loss=0.07599, avg_loss=0.09000, mel_loss=0.03634, linear_loss=0.03965]
[2020-05-12 02:45:48.199]  Step 151008  [3.410 sec/step, loss=0.08864, avg_loss=0.08993, mel_loss=0.03876, linear_loss=0.04988]
[2020-05-12 02:45:50.551]  Step 151009  [3.294 sec/step, loss=0.09376, avg_loss=0.09011, mel_loss=0.04172, linear_loss=0.05204]
[2020-05-12 02:45:51.407]  Step 151010  [3.292 sec/step, loss=0.08201, avg_loss=0.09008, mel_loss=0.03515, linear_loss=0.04686]
[2020-05-12 02:45:52.166]  Step 151011  [3.286 sec/step, loss=0.08169, avg_loss=0.09004, mel_loss=0.03540, linear_loss=0.04629]
[2020-05-12 02:45:53.477]  Step 151012  [3.285 sec/step, loss=0.08625, avg_loss=0.09002, mel_loss=0.03741, linear_loss=0.04884]
[2020-05-12 02:45:57.609]  Step 151013  [3.294 sec/step, loss=0.09663, avg_loss=0.09002, mel_loss=0.04367, linear_loss=0.05296]
[2020-05-12 02:46:01.080]  Step 151014  [3.321 sec/step, loss=0.09459, avg_loss=0.09020, mel_loss=0.04263, linear_loss=0.05196]
[2020-05-12 02:46:04.178]  Step 151015  [3.285 sec/step, loss=0.09601, avg_loss=0.09016, mel_loss=0.04291, linear_loss=0.05310]
[2020-05-12 02:46:06.303]  Step 151016  [3.260 sec/step, loss=0.09188, avg_loss=0.09011, mel_loss=0.04074, linear_loss=0.05114]
[2020-05-12 02:46:08.821]  Step 151017  [3.275 sec/step, loss=0.09279, avg_loss=0.09024, mel_loss=0.04090, linear_loss=0.05190]
[2020-05-12 02:46:15.658]  Step 151018  [3.334 sec/step, loss=0.09927, avg_loss=0.09038, mel_loss=0.04574, linear_loss=0.05352]
[2020-05-12 02:46:16.716]  Step 151019  [3.308 sec/step, loss=0.08236, avg_loss=0.09024, mel_loss=0.03579, linear_loss=0.04657]
[2020-05-12 02:46:22.221]  Step 151020  [3.332 sec/step, loss=0.09787, avg_loss=0.09024, mel_loss=0.04461, linear_loss=0.05327]
[2020-05-12 02:46:22.789]  Step 151021  [3.288 sec/step, loss=0.07103, avg_loss=0.08997, mel_loss=0.03131, linear_loss=0.03972]
[2020-05-12 02:46:24.371]  Step 151022  [3.291 sec/step, loss=0.08695, avg_loss=0.09000, mel_loss=0.03837, linear_loss=0.04858]
[2020-05-12 02:46:26.726]  Step 151023  [3.306 sec/step, loss=0.09278, avg_loss=0.09013, mel_loss=0.04112, linear_loss=0.05166]
[2020-05-12 02:46:27.868]  Step 151024  [3.297 sec/step, loss=0.08166, avg_loss=0.09002, mel_loss=0.03517, linear_loss=0.04649]
[2020-05-12 02:46:29.647]  Step 151025  [3.301 sec/step, loss=0.08992, avg_loss=0.09004, mel_loss=0.03922, linear_loss=0.05070]
[2020-05-12 02:46:30.956]  Step 151026  [3.301 sec/step, loss=0.08335, avg_loss=0.09004, mel_loss=0.03626, linear_loss=0.04709]
[2020-05-12 02:46:35.331]  Step 151027  [3.326 sec/step, loss=0.09739, avg_loss=0.09012, mel_loss=0.04430, linear_loss=0.05309]
[2020-05-12 02:46:38.252]  Step 151028  [3.288 sec/step, loss=0.09503, avg_loss=0.09011, mel_loss=0.04254, linear_loss=0.05248]
[2020-05-12 02:46:39.062]  Step 151029  [3.152 sec/step, loss=0.07814, avg_loss=0.09010, mel_loss=0.03331, linear_loss=0.04482]
[2020-05-12 02:46:44.758]  Step 151030  [3.162 sec/step, loss=0.09892, avg_loss=0.09010, mel_loss=0.04533, linear_loss=0.05358]
[2020-05-12 02:46:46.179]  Step 151031  [3.130 sec/step, loss=0.08731, avg_loss=0.09001, mel_loss=0.03835, linear_loss=0.04896]
[2020-05-12 02:46:51.018]  Step 151032  [3.160 sec/step, loss=0.09650, avg_loss=0.09008, mel_loss=0.04374, linear_loss=0.05276]
[2020-05-12 02:46:51.924]  Step 151033  [3.149 sec/step, loss=0.07230, avg_loss=0.08989, mel_loss=0.03142, linear_loss=0.04088]
[2020-05-12 02:46:53.908]  Step 151034  [3.092 sec/step, loss=0.09006, avg_loss=0.08980, mel_loss=0.03963, linear_loss=0.05043]
[2020-05-12 02:46:55.933]  Step 151035  [3.104 sec/step, loss=0.09140, avg_loss=0.08994, mel_loss=0.04044, linear_loss=0.05095]
[2020-05-12 02:46:57.680]  Generated 32 batches of size 32 in 1.741 sec
[2020-05-12 02:46:57.733]  Step 151036  [3.088 sec/step, loss=0.09236, avg_loss=0.08992, mel_loss=0.04030, linear_loss=0.05207]
[2020-05-12 02:46:59.068]  Step 151037  [3.093 sec/step, loss=0.08774, avg_loss=0.09002, mel_loss=0.03839, linear_loss=0.04936]
[2020-05-12 02:47:02.516]  Step 151038  [3.104 sec/step, loss=0.09517, avg_loss=0.09007, mel_loss=0.04287, linear_loss=0.05230]
[2020-05-12 02:47:05.144]  Step 151039  [3.100 sec/step, loss=0.09385, avg_loss=0.09006, mel_loss=0.04207, linear_loss=0.05179]
[2020-05-12 02:47:06.187]  Step 151040  [3.095 sec/step, loss=0.07923, avg_loss=0.08997, mel_loss=0.03412, linear_loss=0.04511]
[2020-05-12 02:47:13.805]  Step 151041  [3.131 sec/step, loss=0.09922, avg_loss=0.08999, mel_loss=0.04611, linear_loss=0.05311]
[2020-05-12 02:47:26.122]  Step 151042  [3.226 sec/step, loss=0.08796, avg_loss=0.08993, mel_loss=0.04174, linear_loss=0.04622]
[2020-05-12 02:47:34.988]  Step 151043  [3.304 sec/step, loss=0.09764, avg_loss=0.09010, mel_loss=0.04553, linear_loss=0.05211]
[2020-05-12 02:47:38.830]  Step 151044  [3.316 sec/step, loss=0.09817, avg_loss=0.09017, mel_loss=0.04427, linear_loss=0.05391]
[2020-05-12 02:47:43.550]  Step 151045  [3.308 sec/step, loss=0.09712, avg_loss=0.09016, mel_loss=0.04420, linear_loss=0.05292]
[2020-05-12 02:47:44.337]  Step 151046  [3.225 sec/step, loss=0.07617, avg_loss=0.08995, mel_loss=0.03303, linear_loss=0.04315]
[2020-05-12 02:47:46.760]  Step 151047  [3.222 sec/step, loss=0.09196, avg_loss=0.08995, mel_loss=0.04063, linear_loss=0.05133]
[2020-05-12 02:47:49.843]  Step 151048  [3.241 sec/step, loss=0.09596, avg_loss=0.09007, mel_loss=0.04298, linear_loss=0.05298]
[2020-05-12 02:47:50.890]  Step 151049  [3.235 sec/step, loss=0.08341, avg_loss=0.08998, mel_loss=0.03627, linear_loss=0.04714]
[2020-05-12 02:48:05.254]  Step 151050  [3.373 sec/step, loss=0.07641, avg_loss=0.09004, mel_loss=0.03642, linear_loss=0.03998]
[2020-05-12 02:48:05.254]  Writing summary at step: 151050
[2020-05-12 02:48:06.401]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151050
[2020-05-12 02:48:07.857]  Saving audio and alignment...
[2020-05-12 02:48:09.398]  Input: 동요제~___________________
[2020-05-12 02:48:11.162]  Step 151051  [3.358 sec/step, loss=0.08868, avg_loss=0.08996, mel_loss=0.03878, linear_loss=0.04990]
[2020-05-12 02:48:14.794]  Step 151052  [3.384 sec/step, loss=0.09762, avg_loss=0.09012, mel_loss=0.04401, linear_loss=0.05361]
[2020-05-12 02:48:15.755]  Step 151053  [3.372 sec/step, loss=0.08206, avg_loss=0.09001, mel_loss=0.03513, linear_loss=0.04693]
[2020-05-12 02:48:18.583]  Step 151054  [3.374 sec/step, loss=0.09534, avg_loss=0.09003, mel_loss=0.04264, linear_loss=0.05270]
[2020-05-12 02:48:20.872]  Step 151055  [3.379 sec/step, loss=0.08940, avg_loss=0.09003, mel_loss=0.03982, linear_loss=0.04958]
[2020-05-12 02:48:23.020]  Step 151056  [3.265 sec/step, loss=0.09045, avg_loss=0.09012, mel_loss=0.04012, linear_loss=0.05033]
[2020-05-12 02:48:25.721]  Step 151057  [3.250 sec/step, loss=0.09262, avg_loss=0.09007, mel_loss=0.04142, linear_loss=0.05120]
[2020-05-12 02:48:26.669]  Step 151058  [3.246 sec/step, loss=0.08239, avg_loss=0.09006, mel_loss=0.03597, linear_loss=0.04642]
[2020-05-12 02:48:32.785]  Step 151059  [3.291 sec/step, loss=0.09461, avg_loss=0.09011, mel_loss=0.04343, linear_loss=0.05118]
[2020-05-12 02:48:34.782]  Step 151060  [3.243 sec/step, loss=0.09076, avg_loss=0.09003, mel_loss=0.03990, linear_loss=0.05086]
[2020-05-12 02:48:36.265]  Step 151061  [3.175 sec/step, loss=0.08835, avg_loss=0.08995, mel_loss=0.03882, linear_loss=0.04952]
[2020-05-12 02:48:40.360]  Step 151062  [3.181 sec/step, loss=0.09666, avg_loss=0.08996, mel_loss=0.04372, linear_loss=0.05295]
[2020-05-12 02:48:47.844]  Step 151063  [3.247 sec/step, loss=0.09612, avg_loss=0.09017, mel_loss=0.04421, linear_loss=0.05192]
[2020-05-12 02:48:56.267]  Step 151064  [3.305 sec/step, loss=0.09486, avg_loss=0.09018, mel_loss=0.04385, linear_loss=0.05101]
[2020-05-12 02:48:56.834]  Step 151065  [3.281 sec/step, loss=0.06964, avg_loss=0.08991, mel_loss=0.03091, linear_loss=0.03873]
[2020-05-12 02:48:58.584]  Generated 32 batches of size 32 in 1.744 sec
[2020-05-12 02:49:00.377]  Step 151066  [3.282 sec/step, loss=0.09570, avg_loss=0.08990, mel_loss=0.04302, linear_loss=0.05268]
[2020-05-12 02:49:05.278]  Step 151067  [3.323 sec/step, loss=0.09749, avg_loss=0.09014, mel_loss=0.04446, linear_loss=0.05304]
[2020-05-12 02:49:06.669]  Step 151068  [3.323 sec/step, loss=0.08470, avg_loss=0.09012, mel_loss=0.03703, linear_loss=0.04767]
[2020-05-12 02:49:12.251]  Step 151069  [3.353 sec/step, loss=0.09805, avg_loss=0.09017, mel_loss=0.04471, linear_loss=0.05334]
[2020-05-12 02:49:13.990]  Step 151070  [3.323 sec/step, loss=0.08902, avg_loss=0.09009, mel_loss=0.03918, linear_loss=0.04984]
[2020-05-12 02:49:17.165]  Step 151071  [3.316 sec/step, loss=0.09631, avg_loss=0.09007, mel_loss=0.04310, linear_loss=0.05321]
[2020-05-12 02:49:20.901]  Step 151072  [3.337 sec/step, loss=0.09763, avg_loss=0.09024, mel_loss=0.04388, linear_loss=0.05375]
[2020-05-12 02:49:22.184]  Step 151073  [3.318 sec/step, loss=0.08547, avg_loss=0.09020, mel_loss=0.03721, linear_loss=0.04826]
[2020-05-12 02:49:24.089]  Step 151074  [3.301 sec/step, loss=0.08777, avg_loss=0.09018, mel_loss=0.03858, linear_loss=0.04920]
[2020-05-12 02:49:25.414]  Step 151075  [3.243 sec/step, loss=0.08586, avg_loss=0.09006, mel_loss=0.03738, linear_loss=0.04848]
[2020-05-12 02:49:26.191]  Step 151076  [3.236 sec/step, loss=0.07704, avg_loss=0.08994, mel_loss=0.03318, linear_loss=0.04386]
[2020-05-12 02:49:27.264]  Step 151077  [3.186 sec/step, loss=0.08261, avg_loss=0.08977, mel_loss=0.03578, linear_loss=0.04682]
[2020-05-12 02:49:29.493]  Step 151078  [3.200 sec/step, loss=0.09098, avg_loss=0.08991, mel_loss=0.04031, linear_loss=0.05067]
[2020-05-12 02:49:35.193]  Step 151079  [3.219 sec/step, loss=0.09772, avg_loss=0.08994, mel_loss=0.04456, linear_loss=0.05316]
[2020-05-12 02:49:43.732]  Step 151080  [3.293 sec/step, loss=0.09684, avg_loss=0.09005, mel_loss=0.04490, linear_loss=0.05195]
[2020-05-12 02:49:46.924]  Step 151081  [3.307 sec/step, loss=0.09690, avg_loss=0.09014, mel_loss=0.04368, linear_loss=0.05322]
[2020-05-12 02:49:48.291]  Step 151082  [3.248 sec/step, loss=0.08709, avg_loss=0.09001, mel_loss=0.03801, linear_loss=0.04908]
[2020-05-12 02:49:55.766]  Step 151083  [3.316 sec/step, loss=0.09901, avg_loss=0.09025, mel_loss=0.04572, linear_loss=0.05329]
[2020-05-12 02:49:57.342]  Step 151084  [3.289 sec/step, loss=0.08788, avg_loss=0.09016, mel_loss=0.03860, linear_loss=0.04928]
[2020-05-12 02:49:59.199]  Step 151085  [3.292 sec/step, loss=0.08863, avg_loss=0.09014, mel_loss=0.03898, linear_loss=0.04965]
[2020-05-12 02:50:02.033]  Step 151086  [3.280 sec/step, loss=0.09269, avg_loss=0.09010, mel_loss=0.04135, linear_loss=0.05133]
[2020-05-12 02:50:05.746]  Step 151087  [3.289 sec/step, loss=0.09564, avg_loss=0.09012, mel_loss=0.04297, linear_loss=0.05267]
[2020-05-12 02:50:06.513]  Step 151088  [3.286 sec/step, loss=0.07524, avg_loss=0.09005, mel_loss=0.03315, linear_loss=0.04209]
[2020-05-12 02:50:08.545]  Step 151089  [3.287 sec/step, loss=0.08961, avg_loss=0.09003, mel_loss=0.03969, linear_loss=0.04992]
[2020-05-12 02:50:09.528]  Step 151090  [3.279 sec/step, loss=0.07892, avg_loss=0.08993, mel_loss=0.03407, linear_loss=0.04485]
[2020-05-12 02:50:12.579]  Step 151091  [3.279 sec/step, loss=0.09472, avg_loss=0.08990, mel_loss=0.04229, linear_loss=0.05242]
[2020-05-12 02:50:14.355]  Step 151092  [3.252 sec/step, loss=0.08683, avg_loss=0.08978, mel_loss=0.03805, linear_loss=0.04878]
[2020-05-12 02:50:15.180]  Step 151093  [3.229 sec/step, loss=0.07852, avg_loss=0.08962, mel_loss=0.03348, linear_loss=0.04504]
[2020-05-12 02:50:19.982]  Step 151094  [3.188 sec/step, loss=0.09658, avg_loss=0.08960, mel_loss=0.04377, linear_loss=0.05281]
[2020-05-12 02:50:22.569]  Step 151095  [3.193 sec/step, loss=0.09175, avg_loss=0.08960, mel_loss=0.04064, linear_loss=0.05111]
[2020-05-12 02:50:24.751]  Step 151096  [3.160 sec/step, loss=0.08995, avg_loss=0.08952, mel_loss=0.03972, linear_loss=0.05023]
[2020-05-12 02:50:26.384]  Step 151097  [3.102 sec/step, loss=0.08889, avg_loss=0.08944, mel_loss=0.03912, linear_loss=0.04977]
[2020-05-12 02:50:28.209]  Generated 32 batches of size 32 in 1.819 sec
[2020-05-12 02:50:29.838]  Step 151098  [3.131 sec/step, loss=0.09615, avg_loss=0.08972, mel_loss=0.04305, linear_loss=0.05310]
[2020-05-12 02:50:32.240]  Step 151099  [3.127 sec/step, loss=0.09336, avg_loss=0.08974, mel_loss=0.04133, linear_loss=0.05204]
[2020-05-12 02:50:39.012]  Step 151100  [3.173 sec/step, loss=0.09738, avg_loss=0.08980, mel_loss=0.04480, linear_loss=0.05258]
[2020-05-12 02:50:39.012]  Writing summary at step: 151100
[2020-05-12 02:50:52.262]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151100
[2020-05-12 02:50:53.759]  Saving audio and alignment...
[2020-05-12 02:51:00.455]  Input: 이번에는 후루룩 부쳤어요 물론 이 과정이 다 떨어지면 안 되겠습니다~________________
[2020-05-12 02:51:04.023]  Step 151101  [3.190 sec/step, loss=0.09526, avg_loss=0.08985, mel_loss=0.04281, linear_loss=0.05245]
[2020-05-12 02:51:05.218]  Step 151102  [3.191 sec/step, loss=0.08130, avg_loss=0.08982, mel_loss=0.03534, linear_loss=0.04596]
[2020-05-12 02:51:09.499]  Step 151103  [3.199 sec/step, loss=0.09558, avg_loss=0.08982, mel_loss=0.04291, linear_loss=0.05267]
[2020-05-12 02:51:14.870]  Step 151104  [3.237 sec/step, loss=0.09808, avg_loss=0.08992, mel_loss=0.04485, linear_loss=0.05323]
[2020-05-12 02:51:17.818]  Step 151105  [3.207 sec/step, loss=0.09362, avg_loss=0.08990, mel_loss=0.04193, linear_loss=0.05170]
[2020-05-12 02:51:19.315]  Step 151106  [3.210 sec/step, loss=0.08910, avg_loss=0.08996, mel_loss=0.03901, linear_loss=0.05009]
[2020-05-12 02:51:21.363]  Step 151107  [3.089 sec/step, loss=0.09059, avg_loss=0.09011, mel_loss=0.04001, linear_loss=0.05058]
[2020-05-12 02:51:27.083]  Step 151108  [3.133 sec/step, loss=0.09697, avg_loss=0.09019, mel_loss=0.04424, linear_loss=0.05273]
[2020-05-12 02:51:29.503]  Step 151109  [3.133 sec/step, loss=0.09143, avg_loss=0.09017, mel_loss=0.04047, linear_loss=0.05096]
[2020-05-12 02:51:31.495]  Step 151110  [3.145 sec/step, loss=0.09011, avg_loss=0.09025, mel_loss=0.03963, linear_loss=0.05048]
[2020-05-12 02:51:33.283]  Step 151111  [3.155 sec/step, loss=0.08983, avg_loss=0.09033, mel_loss=0.03936, linear_loss=0.05047]
[2020-05-12 02:51:35.856]  Step 151112  [3.168 sec/step, loss=0.09094, avg_loss=0.09038, mel_loss=0.04023, linear_loss=0.05071]
[2020-05-12 02:51:39.280]  Step 151113  [3.161 sec/step, loss=0.09476, avg_loss=0.09036, mel_loss=0.04249, linear_loss=0.05227]
[2020-05-12 02:51:42.763]  Step 151114  [3.161 sec/step, loss=0.09800, avg_loss=0.09039, mel_loss=0.04428, linear_loss=0.05372]
[2020-05-12 02:51:47.089]  Step 151115  [3.173 sec/step, loss=0.09633, avg_loss=0.09040, mel_loss=0.04345, linear_loss=0.05288]
[2020-05-12 02:51:48.131]  Step 151116  [3.162 sec/step, loss=0.08236, avg_loss=0.09030, mel_loss=0.03555, linear_loss=0.04680]
[2020-05-12 02:51:50.901]  Step 151117  [3.165 sec/step, loss=0.09369, avg_loss=0.09031, mel_loss=0.04162, linear_loss=0.05207]
[2020-05-12 02:51:53.117]  Step 151118  [3.118 sec/step, loss=0.09015, avg_loss=0.09022, mel_loss=0.04011, linear_loss=0.05004]
[2020-05-12 02:52:00.672]  Step 151119  [3.183 sec/step, loss=0.09746, avg_loss=0.09037, mel_loss=0.04506, linear_loss=0.05240]
[2020-05-12 02:52:01.750]  Step 151120  [3.139 sec/step, loss=0.08355, avg_loss=0.09023, mel_loss=0.03618, linear_loss=0.04737]
[2020-05-12 02:52:06.922]  Step 151121  [3.185 sec/step, loss=0.09657, avg_loss=0.09048, mel_loss=0.04420, linear_loss=0.05237]
[2020-05-12 02:52:07.681]  Step 151122  [3.177 sec/step, loss=0.07707, avg_loss=0.09038, mel_loss=0.03358, linear_loss=0.04350]
[2020-05-12 02:52:08.817]  Step 151123  [3.165 sec/step, loss=0.08442, avg_loss=0.09030, mel_loss=0.03654, linear_loss=0.04788]
[2020-05-12 02:52:12.645]  Step 151124  [3.192 sec/step, loss=0.09695, avg_loss=0.09045, mel_loss=0.04361, linear_loss=0.05335]
[2020-05-12 02:52:16.040]  Step 151125  [3.208 sec/step, loss=0.09678, avg_loss=0.09052, mel_loss=0.04340, linear_loss=0.05338]
[2020-05-12 02:52:16.896]  Step 151126  [3.203 sec/step, loss=0.08276, avg_loss=0.09052, mel_loss=0.03581, linear_loss=0.04695]
[2020-05-12 02:52:17.692]  Step 151127  [3.167 sec/step, loss=0.07840, avg_loss=0.09033, mel_loss=0.03368, linear_loss=0.04472]
[2020-05-12 02:52:19.427]  Step 151128  [3.156 sec/step, loss=0.09011, avg_loss=0.09028, mel_loss=0.03970, linear_loss=0.05042]
[2020-05-12 02:52:19.441]  Generated 32 batches of size 32 in 1.743 sec
[2020-05-12 02:52:19.995]  Step 151129  [3.153 sec/step, loss=0.07019, avg_loss=0.09020, mel_loss=0.03107, linear_loss=0.03912]
[2020-05-12 02:52:26.159]  Step 151130  [3.158 sec/step, loss=0.10005, avg_loss=0.09021, mel_loss=0.04608, linear_loss=0.05396]
[2020-05-12 02:52:27.430]  Step 151131  [3.156 sec/step, loss=0.08386, avg_loss=0.09017, mel_loss=0.03690, linear_loss=0.04696]
[2020-05-12 02:52:28.782]  Step 151132  [3.122 sec/step, loss=0.08772, avg_loss=0.09009, mel_loss=0.03817, linear_loss=0.04954]
[2020-05-12 02:52:41.128]  Step 151133  [3.236 sec/step, loss=0.09022, avg_loss=0.09027, mel_loss=0.04293, linear_loss=0.04728]
[2020-05-12 02:52:42.715]  Step 151134  [3.232 sec/step, loss=0.09047, avg_loss=0.09027, mel_loss=0.03972, linear_loss=0.05074]
[2020-05-12 02:52:47.746]  Step 151135  [3.262 sec/step, loss=0.09815, avg_loss=0.09034, mel_loss=0.04458, linear_loss=0.05357]
[2020-05-12 02:52:57.225]  Step 151136  [3.339 sec/step, loss=0.09568, avg_loss=0.09037, mel_loss=0.04454, linear_loss=0.05115]
[2020-05-12 02:52:58.565]  Step 151137  [3.339 sec/step, loss=0.08609, avg_loss=0.09035, mel_loss=0.03743, linear_loss=0.04865]
[2020-05-12 02:53:01.532]  Step 151138  [3.334 sec/step, loss=0.09551, avg_loss=0.09036, mel_loss=0.04242, linear_loss=0.05309]
[2020-05-12 02:53:02.414]  Step 151139  [3.317 sec/step, loss=0.07931, avg_loss=0.09021, mel_loss=0.03394, linear_loss=0.04537]
[2020-05-12 02:53:06.720]  Step 151140  [3.349 sec/step, loss=0.09523, avg_loss=0.09037, mel_loss=0.04305, linear_loss=0.05218]
[2020-05-12 02:53:15.414]  Step 151141  [3.360 sec/step, loss=0.09695, avg_loss=0.09035, mel_loss=0.04495, linear_loss=0.05200]
[2020-05-12 02:53:19.500]  Step 151142  [3.278 sec/step, loss=0.09707, avg_loss=0.09044, mel_loss=0.04376, linear_loss=0.05331]
[2020-05-12 02:53:23.177]  Step 151143  [3.226 sec/step, loss=0.09634, avg_loss=0.09043, mel_loss=0.04344, linear_loss=0.05290]
[2020-05-12 02:53:25.198]  Step 151144  [3.208 sec/step, loss=0.08982, avg_loss=0.09034, mel_loss=0.03964, linear_loss=0.05019]
[2020-05-12 02:53:25.734]  Step 151145  [3.166 sec/step, loss=0.07447, avg_loss=0.09012, mel_loss=0.03265, linear_loss=0.04182]
[2020-05-12 02:53:27.091]  Step 151146  [3.171 sec/step, loss=0.08803, avg_loss=0.09024, mel_loss=0.03874, linear_loss=0.04929]
[2020-05-12 02:53:41.520]  Step 151147  [3.291 sec/step, loss=0.07645, avg_loss=0.09008, mel_loss=0.03621, linear_loss=0.04023]
[2020-05-12 02:53:44.177]  Step 151148  [3.287 sec/step, loss=0.09151, avg_loss=0.09004, mel_loss=0.04081, linear_loss=0.05070]
[2020-05-12 02:53:55.867]  Step 151149  [3.394 sec/step, loss=0.09881, avg_loss=0.09019, mel_loss=0.04578, linear_loss=0.05303]
[2020-05-12 02:53:57.186]  Step 151150  [3.263 sec/step, loss=0.08560, avg_loss=0.09028, mel_loss=0.03698, linear_loss=0.04862]
[2020-05-12 02:53:57.186]  Writing summary at step: 151150
[2020-05-12 02:53:59.957]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151150
[2020-05-12 02:54:01.387]  Saving audio and alignment...
[2020-05-12 02:54:08.802]  Input: 그래서 우리 이 강의를 통해서 네가지 어미 처리하는 방법 모두 배워 볼거구요~_____________________________
[2020-05-12 02:54:10.674]  Step 151151  [3.264 sec/step, loss=0.09042, avg_loss=0.09030, mel_loss=0.03959, linear_loss=0.05083]
[2020-05-12 02:54:14.308]  Step 151152  [3.264 sec/step, loss=0.09358, avg_loss=0.09026, mel_loss=0.04213, linear_loss=0.05145]
[2020-05-12 02:54:19.256]  Step 151153  [3.304 sec/step, loss=0.09692, avg_loss=0.09041, mel_loss=0.04395, linear_loss=0.05297]
[2020-05-12 02:54:26.282]  Step 151154  [3.346 sec/step, loss=0.09646, avg_loss=0.09042, mel_loss=0.04434, linear_loss=0.05212]
[2020-05-12 02:54:27.961]  Step 151155  [3.340 sec/step, loss=0.08963, avg_loss=0.09042, mel_loss=0.03959, linear_loss=0.05003]
[2020-05-12 02:54:28.897]  Step 151156  [3.328 sec/step, loss=0.08226, avg_loss=0.09034, mel_loss=0.03567, linear_loss=0.04658]
[2020-05-12 02:54:31.369]  Step 151157  [3.326 sec/step, loss=0.09107, avg_loss=0.09032, mel_loss=0.04026, linear_loss=0.05081]
[2020-05-12 02:54:32.249]  Step 151158  [3.325 sec/step, loss=0.07814, avg_loss=0.09028, mel_loss=0.03367, linear_loss=0.04446]
[2020-05-12 02:54:33.117]  Generated 32 batches of size 32 in 1.742 sec
[2020-05-12 02:54:33.122]  Step 151159  [3.273 sec/step, loss=0.07339, avg_loss=0.09007, mel_loss=0.03243, linear_loss=0.04097]
[2020-05-12 02:54:38.787]  Step 151160  [3.309 sec/step, loss=0.09684, avg_loss=0.09013, mel_loss=0.04441, linear_loss=0.05244]
[2020-05-12 02:54:39.905]  Step 151161  [3.306 sec/step, loss=0.08558, avg_loss=0.09010, mel_loss=0.03724, linear_loss=0.04834]
[2020-05-12 02:54:42.926]  Step 151162  [3.295 sec/step, loss=0.09569, avg_loss=0.09009, mel_loss=0.04284, linear_loss=0.05286]
[2020-05-12 02:54:45.074]  Step 151163  [3.241 sec/step, loss=0.09246, avg_loss=0.09006, mel_loss=0.04082, linear_loss=0.05164]
[2020-05-12 02:54:48.477]  Step 151164  [3.191 sec/step, loss=0.09624, avg_loss=0.09007, mel_loss=0.04325, linear_loss=0.05299]
[2020-05-12 02:54:50.219]  Step 151165  [3.203 sec/step, loss=0.08965, avg_loss=0.09027, mel_loss=0.03911, linear_loss=0.05054]
[2020-05-12 02:54:51.651]  Step 151166  [3.182 sec/step, loss=0.08713, avg_loss=0.09018, mel_loss=0.03795, linear_loss=0.04917]
[2020-05-12 02:55:05.051]  Step 151167  [3.267 sec/step, loss=0.08346, avg_loss=0.09004, mel_loss=0.03939, linear_loss=0.04407]
[2020-05-12 02:55:11.066]  Step 151168  [3.313 sec/step, loss=0.09573, avg_loss=0.09015, mel_loss=0.04387, linear_loss=0.05186]
[2020-05-12 02:55:13.582]  Step 151169  [3.282 sec/step, loss=0.09285, avg_loss=0.09010, mel_loss=0.04096, linear_loss=0.05189]
[2020-05-12 02:55:16.233]  Step 151170  [3.292 sec/step, loss=0.09370, avg_loss=0.09015, mel_loss=0.04190, linear_loss=0.05180]
[2020-05-12 02:55:20.919]  Step 151171  [3.307 sec/step, loss=0.09827, avg_loss=0.09017, mel_loss=0.04460, linear_loss=0.05367]
[2020-05-12 02:55:22.671]  Step 151172  [3.287 sec/step, loss=0.09086, avg_loss=0.09010, mel_loss=0.03970, linear_loss=0.05116]
[2020-05-12 02:55:24.070]  Step 151173  [3.288 sec/step, loss=0.08608, avg_loss=0.09011, mel_loss=0.03756, linear_loss=0.04851]
[2020-05-12 02:55:26.980]  Step 151174  [3.298 sec/step, loss=0.09768, avg_loss=0.09021, mel_loss=0.04368, linear_loss=0.05400]
[2020-05-12 02:55:28.040]  Step 151175  [3.295 sec/step, loss=0.08157, avg_loss=0.09016, mel_loss=0.03545, linear_loss=0.04612]
[2020-05-12 02:55:30.223]  Step 151176  [3.309 sec/step, loss=0.09097, avg_loss=0.09030, mel_loss=0.04035, linear_loss=0.05063]
[2020-05-12 02:55:32.222]  Step 151177  [3.319 sec/step, loss=0.08814, avg_loss=0.09036, mel_loss=0.03878, linear_loss=0.04936]
[2020-05-12 02:55:35.438]  Step 151178  [3.329 sec/step, loss=0.09592, avg_loss=0.09041, mel_loss=0.04275, linear_loss=0.05318]
[2020-05-12 02:55:37.493]  Step 151179  [3.292 sec/step, loss=0.09206, avg_loss=0.09035, mel_loss=0.04063, linear_loss=0.05143]
[2020-05-12 02:55:38.655]  Step 151180  [3.218 sec/step, loss=0.08312, avg_loss=0.09021, mel_loss=0.03611, linear_loss=0.04700]
[2020-05-12 02:55:41.047]  Step 151181  [3.210 sec/step, loss=0.09195, avg_loss=0.09016, mel_loss=0.04093, linear_loss=0.05102]
[2020-05-12 02:55:41.902]  Step 151182  [3.205 sec/step, loss=0.07693, avg_loss=0.09006, mel_loss=0.03331, linear_loss=0.04362]
[2020-05-12 02:55:48.932]  Step 151183  [3.201 sec/step, loss=0.09742, avg_loss=0.09005, mel_loss=0.04483, linear_loss=0.05260]
[2020-05-12 02:55:50.515]  Step 151184  [3.201 sec/step, loss=0.08850, avg_loss=0.09005, mel_loss=0.03882, linear_loss=0.04968]
[2020-05-12 02:55:54.562]  Step 151185  [3.223 sec/step, loss=0.09631, avg_loss=0.09013, mel_loss=0.04314, linear_loss=0.05317]
[2020-05-12 02:55:59.586]  Step 151186  [3.245 sec/step, loss=0.09852, avg_loss=0.09019, mel_loss=0.04507, linear_loss=0.05345]
[2020-05-12 02:56:00.375]  Step 151187  [3.215 sec/step, loss=0.07648, avg_loss=0.09000, mel_loss=0.03272, linear_loss=0.04375]
[2020-05-12 02:56:01.871]  Step 151188  [3.223 sec/step, loss=0.08923, avg_loss=0.09014, mel_loss=0.03925, linear_loss=0.04998]
[2020-05-12 02:56:05.281]  Step 151189  [3.237 sec/step, loss=0.09454, avg_loss=0.09018, mel_loss=0.04237, linear_loss=0.05217]
[2020-05-12 02:56:06.365]  Step 151190  [3.238 sec/step, loss=0.07959, avg_loss=0.09019, mel_loss=0.03434, linear_loss=0.04525]
[2020-05-12 02:56:06.965]  Generated 32 batches of size 32 in 1.678 sec
[2020-05-12 02:56:10.010]  Step 151191  [3.243 sec/step, loss=0.09831, avg_loss=0.09023, mel_loss=0.04432, linear_loss=0.05399]
[2020-05-12 02:56:18.789]  Step 151192  [3.313 sec/step, loss=0.09441, avg_loss=0.09030, mel_loss=0.04363, linear_loss=0.05078]
[2020-05-12 02:56:22.924]  Step 151193  [3.347 sec/step, loss=0.09785, avg_loss=0.09050, mel_loss=0.04434, linear_loss=0.05351]
[2020-05-12 02:56:24.193]  Step 151194  [3.311 sec/step, loss=0.08669, avg_loss=0.09040, mel_loss=0.03798, linear_loss=0.04872]
[2020-05-12 02:56:27.341]  Step 151195  [3.317 sec/step, loss=0.09425, avg_loss=0.09042, mel_loss=0.04238, linear_loss=0.05188]
[2020-05-12 02:56:32.842]  Step 151196  [3.350 sec/step, loss=0.09896, avg_loss=0.09051, mel_loss=0.04500, linear_loss=0.05396]
[2020-05-12 02:56:34.665]  Step 151197  [3.352 sec/step, loss=0.08773, avg_loss=0.09050, mel_loss=0.03839, linear_loss=0.04934]
[2020-05-12 02:56:35.413]  Step 151198  [3.325 sec/step, loss=0.07525, avg_loss=0.09029, mel_loss=0.03381, linear_loss=0.04144]
[2020-05-12 02:56:36.468]  Step 151199  [3.311 sec/step, loss=0.08318, avg_loss=0.09019, mel_loss=0.03584, linear_loss=0.04734]
[2020-05-12 02:56:37.443]  Step 151200  [3.253 sec/step, loss=0.08456, avg_loss=0.09006, mel_loss=0.03652, linear_loss=0.04803]
[2020-05-12 02:56:37.443]  Writing summary at step: 151200
[2020-05-12 02:56:39.034]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151200
[2020-05-12 02:56:40.493]  Saving audio and alignment...
[2020-05-12 02:56:44.370]  Input: 여기에 대해서 간단히 답변부터 드리고 갈까요~
[2020-05-12 02:56:49.056]  Step 151201  [3.265 sec/step, loss=0.09791, avg_loss=0.09009, mel_loss=0.04438, linear_loss=0.05353]
[2020-05-12 02:56:51.961]  Step 151202  [3.282 sec/step, loss=0.09400, avg_loss=0.09022, mel_loss=0.04214, linear_loss=0.05187]
[2020-05-12 02:56:57.701]  Step 151203  [3.296 sec/step, loss=0.09738, avg_loss=0.09023, mel_loss=0.04466, linear_loss=0.05271]
[2020-05-12 02:57:01.142]  Step 151204  [3.277 sec/step, loss=0.09652, avg_loss=0.09022, mel_loss=0.04354, linear_loss=0.05298]
[2020-05-12 02:57:02.770]  Step 151205  [3.264 sec/step, loss=0.08918, avg_loss=0.09017, mel_loss=0.03932, linear_loss=0.04986]
[2020-05-12 02:57:04.026]  Step 151206  [3.261 sec/step, loss=0.08289, avg_loss=0.09011, mel_loss=0.03615, linear_loss=0.04674]
[2020-05-12 02:57:06.780]  Step 151207  [3.268 sec/step, loss=0.09302, avg_loss=0.09014, mel_loss=0.04173, linear_loss=0.05128]
[2020-05-12 02:57:08.808]  Step 151208  [3.232 sec/step, loss=0.09052, avg_loss=0.09007, mel_loss=0.03982, linear_loss=0.05070]
[2020-05-12 02:57:10.185]  Step 151209  [3.221 sec/step, loss=0.08703, avg_loss=0.09003, mel_loss=0.03817, linear_loss=0.04885]
[2020-05-12 02:57:14.261]  Step 151210  [3.242 sec/step, loss=0.09635, avg_loss=0.09009, mel_loss=0.04341, linear_loss=0.05294]
[2020-05-12 02:57:16.721]  Step 151211  [3.249 sec/step, loss=0.09288, avg_loss=0.09012, mel_loss=0.04092, linear_loss=0.05196]
[2020-05-12 02:57:18.074]  Step 151212  [3.236 sec/step, loss=0.08400, avg_loss=0.09005, mel_loss=0.03670, linear_loss=0.04730]
[2020-05-12 02:57:23.330]  Step 151213  [3.255 sec/step, loss=0.09611, avg_loss=0.09006, mel_loss=0.04374, linear_loss=0.05237]
[2020-05-12 02:57:24.136]  Step 151214  [3.228 sec/step, loss=0.07524, avg_loss=0.08984, mel_loss=0.03249, linear_loss=0.04275]
[2020-05-12 02:57:38.050]  Step 151215  [3.324 sec/step, loss=0.07563, avg_loss=0.08963, mel_loss=0.03594, linear_loss=0.03970]
[2020-05-12 02:57:38.959]  Step 151216  [3.323 sec/step, loss=0.07996, avg_loss=0.08961, mel_loss=0.03427, linear_loss=0.04569]
[2020-05-12 02:57:46.573]  Step 151217  [3.371 sec/step, loss=0.09940, avg_loss=0.08966, mel_loss=0.04602, linear_loss=0.05338]
[2020-05-12 02:57:50.253]  Step 151218  [3.386 sec/step, loss=0.09754, avg_loss=0.08974, mel_loss=0.04402, linear_loss=0.05352]
[2020-05-12 02:57:54.600]  Step 151219  [3.354 sec/step, loss=0.09668, avg_loss=0.08973, mel_loss=0.04378, linear_loss=0.05291]
[2020-05-12 02:57:56.384]  Generated 32 batches of size 32 in 1.778 sec
[2020-05-12 02:57:56.806]  Step 151220  [3.365 sec/step, loss=0.09144, avg_loss=0.08981, mel_loss=0.04051, linear_loss=0.05093]
[2020-05-12 02:57:57.583]  Step 151221  [3.321 sec/step, loss=0.07782, avg_loss=0.08962, mel_loss=0.03354, linear_loss=0.04429]
[2020-05-12 02:58:00.910]  Step 151222  [3.347 sec/step, loss=0.09628, avg_loss=0.08981, mel_loss=0.04327, linear_loss=0.05301]
[2020-05-12 02:58:09.593]  Step 151223  [3.422 sec/step, loss=0.09724, avg_loss=0.08994, mel_loss=0.04518, linear_loss=0.05206]
[2020-05-12 02:58:13.116]  Step 151224  [3.419 sec/step, loss=0.09476, avg_loss=0.08992, mel_loss=0.04281, linear_loss=0.05194]
[2020-05-12 02:58:19.852]  Step 151225  [3.452 sec/step, loss=0.09872, avg_loss=0.08994, mel_loss=0.04539, linear_loss=0.05333]
[2020-05-12 02:58:22.014]  Step 151226  [3.465 sec/step, loss=0.09021, avg_loss=0.09001, mel_loss=0.03980, linear_loss=0.05041]
[2020-05-12 02:58:22.574]  Step 151227  [3.463 sec/step, loss=0.07026, avg_loss=0.08993, mel_loss=0.03094, linear_loss=0.03932]
[2020-05-12 02:58:24.337]  Step 151228  [3.463 sec/step, loss=0.09049, avg_loss=0.08994, mel_loss=0.03963, linear_loss=0.05086]
[2020-05-12 02:58:26.810]  Step 151229  [3.482 sec/step, loss=0.09074, avg_loss=0.09014, mel_loss=0.04004, linear_loss=0.05069]
[2020-05-12 02:58:28.155]  Step 151230  [3.434 sec/step, loss=0.08516, avg_loss=0.08999, mel_loss=0.03724, linear_loss=0.04792]
[2020-05-12 02:58:31.550]  Step 151231  [3.456 sec/step, loss=0.09617, avg_loss=0.09011, mel_loss=0.04319, linear_loss=0.05298]
[2020-05-12 02:58:33.562]  Step 151232  [3.462 sec/step, loss=0.08962, avg_loss=0.09013, mel_loss=0.03964, linear_loss=0.04998]
[2020-05-12 02:58:34.940]  Step 151233  [3.352 sec/step, loss=0.08582, avg_loss=0.09009, mel_loss=0.03761, linear_loss=0.04821]
[2020-05-12 02:58:36.673]  Step 151234  [3.354 sec/step, loss=0.08969, avg_loss=0.09008, mel_loss=0.03937, linear_loss=0.05032]
[2020-05-12 02:58:37.757]  Step 151235  [3.314 sec/step, loss=0.08287, avg_loss=0.08993, mel_loss=0.03550, linear_loss=0.04736]
[2020-05-12 02:58:39.910]  Step 151236  [3.241 sec/step, loss=0.09228, avg_loss=0.08990, mel_loss=0.04094, linear_loss=0.05134]
[2020-05-12 02:58:44.041]  Step 151237  [3.269 sec/step, loss=0.09590, avg_loss=0.08999, mel_loss=0.04299, linear_loss=0.05292]
[2020-05-12 02:58:44.607]  Step 151238  [3.245 sec/step, loss=0.06899, avg_loss=0.08973, mel_loss=0.03071, linear_loss=0.03829]
[2020-05-12 02:58:47.640]  Step 151239  [3.267 sec/step, loss=0.09440, avg_loss=0.08988, mel_loss=0.04228, linear_loss=0.05211]
[2020-05-12 02:58:48.653]  Step 151240  [3.234 sec/step, loss=0.08120, avg_loss=0.08974, mel_loss=0.03491, linear_loss=0.04629]
[2020-05-12 02:58:51.955]  Step 151241  [3.180 sec/step, loss=0.09493, avg_loss=0.08972, mel_loss=0.04247, linear_loss=0.05246]
[2020-05-12 02:58:57.266]  Step 151242  [3.192 sec/step, loss=0.09796, avg_loss=0.08973, mel_loss=0.04482, linear_loss=0.05315]
[2020-05-12 02:58:59.635]  Step 151243  [3.179 sec/step, loss=0.09101, avg_loss=0.08967, mel_loss=0.04029, linear_loss=0.05071]
[2020-05-12 02:59:01.581]  Step 151244  [3.178 sec/step, loss=0.08806, avg_loss=0.08966, mel_loss=0.03864, linear_loss=0.04942]
[2020-05-12 02:59:08.713]  Step 151245  [3.244 sec/step, loss=0.09868, avg_loss=0.08990, mel_loss=0.04550, linear_loss=0.05318]
[2020-05-12 02:59:15.477]  Step 151246  [3.298 sec/step, loss=0.09790, avg_loss=0.09000, mel_loss=0.04520, linear_loss=0.05270]
[2020-05-12 02:59:18.200]  Step 151247  [3.181 sec/step, loss=0.09068, avg_loss=0.09014, mel_loss=0.04040, linear_loss=0.05028]
[2020-05-12 02:59:19.015]  Step 151248  [3.163 sec/step, loss=0.07721, avg_loss=0.09000, mel_loss=0.03303, linear_loss=0.04418]
[2020-05-12 02:59:20.035]  Step 151249  [3.056 sec/step, loss=0.08483, avg_loss=0.08986, mel_loss=0.03654, linear_loss=0.04829]
[2020-05-12 02:59:23.031]  Step 151250  [3.073 sec/step, loss=0.09531, avg_loss=0.08995, mel_loss=0.04261, linear_loss=0.05270]
[2020-05-12 02:59:23.031]  Writing summary at step: 151250
[2020-05-12 02:59:27.399]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151250
[2020-05-12 02:59:28.899]  Saving audio and alignment...
[2020-05-12 02:59:31.021]  Generated 32 batches of size 32 in 1.543 sec
[2020-05-12 02:59:31.703]  Input: 푸른 난세~___________________
[2020-05-12 02:59:43.656]  Step 151251  [3.174 sec/step, loss=0.08903, avg_loss=0.08994, mel_loss=0.04220, linear_loss=0.04683]
[2020-05-12 02:59:47.374]  Step 151252  [3.174 sec/step, loss=0.09614, avg_loss=0.08997, mel_loss=0.04324, linear_loss=0.05290]
[2020-05-12 02:59:48.980]  Step 151253  [3.141 sec/step, loss=0.08780, avg_loss=0.08987, mel_loss=0.03847, linear_loss=0.04933]
[2020-05-12 02:59:53.719]  Step 151254  [3.118 sec/step, loss=0.09800, avg_loss=0.08989, mel_loss=0.04434, linear_loss=0.05365]
[2020-05-12 02:59:55.352]  Step 151255  [3.118 sec/step, loss=0.09034, avg_loss=0.08990, mel_loss=0.03968, linear_loss=0.05066]
[2020-05-12 03:00:04.206]  Step 151256  [3.197 sec/step, loss=0.09604, avg_loss=0.09003, mel_loss=0.04464, linear_loss=0.05141]
[2020-05-12 03:00:04.970]  Step 151257  [3.180 sec/step, loss=0.07155, avg_loss=0.08984, mel_loss=0.03103, linear_loss=0.04052]
[2020-05-12 03:00:10.500]  Step 151258  [3.226 sec/step, loss=0.09594, avg_loss=0.09002, mel_loss=0.04369, linear_loss=0.05225]
[2020-05-12 03:00:15.710]  Step 151259  [3.270 sec/step, loss=0.09646, avg_loss=0.09025, mel_loss=0.04389, linear_loss=0.05257]
[2020-05-12 03:00:30.173]  Step 151260  [3.358 sec/step, loss=0.07585, avg_loss=0.09004, mel_loss=0.03586, linear_loss=0.03999]
[2020-05-12 03:00:31.505]  Step 151261  [3.360 sec/step, loss=0.08467, avg_loss=0.09003, mel_loss=0.03703, linear_loss=0.04764]
[2020-05-12 03:00:33.579]  Step 151262  [3.350 sec/step, loss=0.09032, avg_loss=0.08998, mel_loss=0.03988, linear_loss=0.05044]
[2020-05-12 03:00:35.761]  Step 151263  [3.351 sec/step, loss=0.09255, avg_loss=0.08998, mel_loss=0.04100, linear_loss=0.05155]
[2020-05-12 03:00:36.902]  Step 151264  [3.328 sec/step, loss=0.08472, avg_loss=0.08986, mel_loss=0.03664, linear_loss=0.04808]
[2020-05-12 03:00:40.317]  Step 151265  [3.345 sec/step, loss=0.09810, avg_loss=0.08995, mel_loss=0.04391, linear_loss=0.05419]
[2020-05-12 03:00:41.117]  Step 151266  [3.338 sec/step, loss=0.07822, avg_loss=0.08986, mel_loss=0.03387, linear_loss=0.04435]
[2020-05-12 03:00:43.771]  Step 151267  [3.231 sec/step, loss=0.09367, avg_loss=0.08996, mel_loss=0.04168, linear_loss=0.05198]
[2020-05-12 03:00:47.533]  Step 151268  [3.208 sec/step, loss=0.09784, avg_loss=0.08998, mel_loss=0.04412, linear_loss=0.05372]
[2020-05-12 03:00:51.919]  Step 151269  [3.227 sec/step, loss=0.09806, avg_loss=0.09003, mel_loss=0.04473, linear_loss=0.05333]
[2020-05-12 03:00:55.508]  Step 151270  [3.237 sec/step, loss=0.09755, avg_loss=0.09007, mel_loss=0.04374, linear_loss=0.05381]
[2020-05-12 03:01:01.589]  Step 151271  [3.250 sec/step, loss=0.09728, avg_loss=0.09006, mel_loss=0.04455, linear_loss=0.05273]
[2020-05-12 03:01:09.056]  Step 151272  [3.308 sec/step, loss=0.09846, avg_loss=0.09014, mel_loss=0.04562, linear_loss=0.05284]
[2020-05-12 03:01:10.978]  Step 151273  [3.313 sec/step, loss=0.09018, avg_loss=0.09018, mel_loss=0.03969, linear_loss=0.05049]
[2020-05-12 03:01:12.538]  Step 151274  [3.299 sec/step, loss=0.08836, avg_loss=0.09008, mel_loss=0.03888, linear_loss=0.04948]
[2020-05-12 03:01:15.997]  Step 151275  [3.323 sec/step, loss=0.09252, avg_loss=0.09019, mel_loss=0.04151, linear_loss=0.05101]
[2020-05-12 03:01:24.629]  Step 151276  [3.388 sec/step, loss=0.09715, avg_loss=0.09026, mel_loss=0.04510, linear_loss=0.05204]
[2020-05-12 03:01:25.628]  Step 151277  [3.378 sec/step, loss=0.08354, avg_loss=0.09021, mel_loss=0.03671, linear_loss=0.04683]
[2020-05-12 03:01:26.386]  Step 151278  [3.353 sec/step, loss=0.07491, avg_loss=0.09000, mel_loss=0.03289, linear_loss=0.04202]
[2020-05-12 03:01:28.096]  Step 151279  [3.350 sec/step, loss=0.08976, avg_loss=0.08998, mel_loss=0.03918, linear_loss=0.05058]
[2020-05-12 03:01:28.992]  Step 151280  [3.347 sec/step, loss=0.07821, avg_loss=0.08993, mel_loss=0.03366, linear_loss=0.04454]
[2020-05-12 03:01:30.797]  Step 151281  [3.341 sec/step, loss=0.08819, avg_loss=0.08989, mel_loss=0.03859, linear_loss=0.04960]
[2020-05-12 03:01:32.602]  Generated 32 batches of size 32 in 1.800 sec
[2020-05-12 03:01:33.153]  Step 151282  [3.356 sec/step, loss=0.09280, avg_loss=0.09005, mel_loss=0.04129, linear_loss=0.05151]
[2020-05-12 03:01:34.371]  Step 151283  [3.298 sec/step, loss=0.08593, avg_loss=0.08993, mel_loss=0.03728, linear_loss=0.04865]
[2020-05-12 03:01:35.752]  Step 151284  [3.296 sec/step, loss=0.08669, avg_loss=0.08992, mel_loss=0.03813, linear_loss=0.04856]
[2020-05-12 03:01:38.875]  Step 151285  [3.287 sec/step, loss=0.09736, avg_loss=0.08993, mel_loss=0.04356, linear_loss=0.05380]
[2020-05-12 03:01:41.768]  Step 151286  [3.266 sec/step, loss=0.09369, avg_loss=0.08988, mel_loss=0.04189, linear_loss=0.05180]
[2020-05-12 03:01:47.348]  Step 151287  [3.313 sec/step, loss=0.09774, avg_loss=0.09009, mel_loss=0.04449, linear_loss=0.05325]
[2020-05-12 03:01:49.822]  Step 151288  [3.323 sec/step, loss=0.09150, avg_loss=0.09011, mel_loss=0.04061, linear_loss=0.05089]
[2020-05-12 03:01:54.105]  Step 151289  [3.332 sec/step, loss=0.09530, avg_loss=0.09012, mel_loss=0.04318, linear_loss=0.05211]
[2020-05-12 03:01:54.880]  Step 151290  [3.329 sec/step, loss=0.07926, avg_loss=0.09012, mel_loss=0.03425, linear_loss=0.04501]
[2020-05-12 03:02:08.820]  Step 151291  [3.432 sec/step, loss=0.07786, avg_loss=0.08991, mel_loss=0.03708, linear_loss=0.04077]
[2020-05-12 03:02:09.774]  Step 151292  [3.354 sec/step, loss=0.08129, avg_loss=0.08978, mel_loss=0.03526, linear_loss=0.04603]
[2020-05-12 03:02:11.121]  Step 151293  [3.326 sec/step, loss=0.08430, avg_loss=0.08965, mel_loss=0.03683, linear_loss=0.04747]
[2020-05-12 03:02:12.111]  Step 151294  [3.323 sec/step, loss=0.07817, avg_loss=0.08956, mel_loss=0.03370, linear_loss=0.04447]
[2020-05-12 03:02:13.740]  Step 151295  [3.308 sec/step, loss=0.08831, avg_loss=0.08950, mel_loss=0.03901, linear_loss=0.04929]
[2020-05-12 03:02:15.114]  Step 151296  [3.266 sec/step, loss=0.08863, avg_loss=0.08940, mel_loss=0.03906, linear_loss=0.04957]
[2020-05-12 03:02:23.921]  Step 151297  [3.336 sec/step, loss=0.09744, avg_loss=0.08949, mel_loss=0.04529, linear_loss=0.05215]
[2020-05-12 03:02:26.317]  Step 151298  [3.353 sec/step, loss=0.09056, avg_loss=0.08965, mel_loss=0.04020, linear_loss=0.05036]
[2020-05-12 03:02:29.213]  Step 151299  [3.371 sec/step, loss=0.09374, avg_loss=0.08975, mel_loss=0.04176, linear_loss=0.05199]
[2020-05-12 03:02:32.653]  Step 151300  [3.396 sec/step, loss=0.09430, avg_loss=0.08985, mel_loss=0.04249, linear_loss=0.05182]
[2020-05-12 03:02:32.653]  Writing summary at step: 151300
[2020-05-12 03:02:33.230]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151300
[2020-05-12 03:02:34.732]  Saving audio and alignment...
[2020-05-12 03:02:38.267]  Input: 벤젠입니다 이런 걸로 다 바꾸고요~___________
[2020-05-12 03:02:39.315]  Step 151301  [3.359 sec/step, loss=0.08361, avg_loss=0.08971, mel_loss=0.03633, linear_loss=0.04728]
[2020-05-12 03:02:41.457]  Step 151302  [3.352 sec/step, loss=0.09209, avg_loss=0.08969, mel_loss=0.04081, linear_loss=0.05128]
[2020-05-12 03:02:43.926]  Step 151303  [3.319 sec/step, loss=0.09123, avg_loss=0.08963, mel_loss=0.04034, linear_loss=0.05089]
[2020-05-12 03:02:49.257]  Step 151304  [3.338 sec/step, loss=0.09771, avg_loss=0.08964, mel_loss=0.04457, linear_loss=0.05314]
[2020-05-12 03:02:52.912]  Step 151305  [3.358 sec/step, loss=0.09828, avg_loss=0.08973, mel_loss=0.04439, linear_loss=0.05389]
[2020-05-12 03:02:56.048]  Step 151306  [3.377 sec/step, loss=0.09505, avg_loss=0.08985, mel_loss=0.04271, linear_loss=0.05235]
[2020-05-12 03:03:00.694]  Step 151307  [3.396 sec/step, loss=0.09715, avg_loss=0.08989, mel_loss=0.04414, linear_loss=0.05301]
[2020-05-12 03:03:07.584]  Step 151308  [3.445 sec/step, loss=0.09704, avg_loss=0.08996, mel_loss=0.04448, linear_loss=0.05257]
[2020-05-12 03:03:13.618]  Step 151309  [3.491 sec/step, loss=0.09890, avg_loss=0.09008, mel_loss=0.04534, linear_loss=0.05356]
[2020-05-12 03:03:14.520]  Step 151310  [3.459 sec/step, loss=0.07581, avg_loss=0.08987, mel_loss=0.03326, linear_loss=0.04256]
[2020-05-12 03:03:16.411]  Step 151311  [3.454 sec/step, loss=0.08838, avg_loss=0.08983, mel_loss=0.03858, linear_loss=0.04981]
[2020-05-12 03:03:17.640]  Step 151312  [3.453 sec/step, loss=0.08358, avg_loss=0.08982, mel_loss=0.03641, linear_loss=0.04718]
[2020-05-12 03:03:18.160]  Generated 32 batches of size 32 in 1.743 sec
[2020-05-12 03:03:18.425]  Step 151313  [3.408 sec/step, loss=0.08013, avg_loss=0.08966, mel_loss=0.03423, linear_loss=0.04591]
[2020-05-12 03:03:21.061]  Step 151314  [3.426 sec/step, loss=0.09276, avg_loss=0.08984, mel_loss=0.04147, linear_loss=0.05129]
[2020-05-12 03:03:24.544]  Step 151315  [3.322 sec/step, loss=0.09480, avg_loss=0.09003, mel_loss=0.04278, linear_loss=0.05202]
[2020-05-12 03:03:28.905]  Step 151316  [3.356 sec/step, loss=0.09759, avg_loss=0.09021, mel_loss=0.04433, linear_loss=0.05326]
[2020-05-12 03:03:36.583]  Step 151317  [3.357 sec/step, loss=0.09676, avg_loss=0.09018, mel_loss=0.04464, linear_loss=0.05212]
[2020-05-12 03:03:38.170]  Step 151318  [3.336 sec/step, loss=0.08890, avg_loss=0.09009, mel_loss=0.03894, linear_loss=0.04996]
[2020-05-12 03:03:42.309]  Step 151319  [3.334 sec/step, loss=0.09568, avg_loss=0.09008, mel_loss=0.04298, linear_loss=0.05269]
[2020-05-12 03:03:44.262]  Step 151320  [3.331 sec/step, loss=0.08910, avg_loss=0.09006, mel_loss=0.03929, linear_loss=0.04981]
[2020-05-12 03:03:47.236]  Step 151321  [3.353 sec/step, loss=0.09653, avg_loss=0.09025, mel_loss=0.04301, linear_loss=0.05352]
[2020-05-12 03:03:48.128]  Step 151322  [3.329 sec/step, loss=0.07901, avg_loss=0.09007, mel_loss=0.03408, linear_loss=0.04493]
[2020-05-12 03:03:52.335]  Step 151323  [3.284 sec/step, loss=0.09643, avg_loss=0.09007, mel_loss=0.04379, linear_loss=0.05265]
[2020-05-12 03:04:11.812]  Step 151324  [3.444 sec/step, loss=0.07599, avg_loss=0.08988, mel_loss=0.03600, linear_loss=0.03999]
[2020-05-12 03:04:18.992]  Step 151325  [3.448 sec/step, loss=0.09826, avg_loss=0.08987, mel_loss=0.04521, linear_loss=0.05305]
[2020-05-12 03:04:19.524]  Step 151326  [3.432 sec/step, loss=0.07067, avg_loss=0.08968, mel_loss=0.03154, linear_loss=0.03913]
[2020-05-12 03:04:28.616]  Step 151327  [3.517 sec/step, loss=0.09737, avg_loss=0.08995, mel_loss=0.04524, linear_loss=0.05213]
[2020-05-12 03:04:30.645]  Step 151328  [3.520 sec/step, loss=0.09073, avg_loss=0.08995, mel_loss=0.03995, linear_loss=0.05078]
[2020-05-12 03:04:35.941]  Step 151329  [3.548 sec/step, loss=0.09713, avg_loss=0.09002, mel_loss=0.04428, linear_loss=0.05285]
[2020-05-12 03:04:37.975]  Step 151330  [3.555 sec/step, loss=0.09190, avg_loss=0.09008, mel_loss=0.04070, linear_loss=0.05121]
[2020-05-12 03:04:39.694]  Step 151331  [3.538 sec/step, loss=0.08782, avg_loss=0.09000, mel_loss=0.03849, linear_loss=0.04933]
[2020-05-12 03:04:41.016]  Step 151332  [3.531 sec/step, loss=0.08721, avg_loss=0.08998, mel_loss=0.03796, linear_loss=0.04924]
[2020-05-12 03:04:43.424]  Step 151333  [3.542 sec/step, loss=0.09174, avg_loss=0.09004, mel_loss=0.04078, linear_loss=0.05096]
[2020-05-12 03:04:46.949]  Step 151334  [3.560 sec/step, loss=0.09496, avg_loss=0.09009, mel_loss=0.04285, linear_loss=0.05212]
[2020-05-12 03:04:50.386]  Step 151335  [3.583 sec/step, loss=0.09365, avg_loss=0.09020, mel_loss=0.04170, linear_loss=0.05195]
[2020-05-12 03:04:51.200]  Step 151336  [3.570 sec/step, loss=0.07773, avg_loss=0.09005, mel_loss=0.03349, linear_loss=0.04424]
[2020-05-12 03:04:52.602]  Step 151337  [3.543 sec/step, loss=0.08488, avg_loss=0.08994, mel_loss=0.03704, linear_loss=0.04784]
[2020-05-12 03:05:00.076]  Step 151338  [3.612 sec/step, loss=0.09719, avg_loss=0.09022, mel_loss=0.04483, linear_loss=0.05236]
[2020-05-12 03:05:02.279]  Step 151339  [3.603 sec/step, loss=0.09225, avg_loss=0.09020, mel_loss=0.04110, linear_loss=0.05115]
[2020-05-12 03:05:04.082]  Step 151340  [3.611 sec/step, loss=0.08890, avg_loss=0.09028, mel_loss=0.03888, linear_loss=0.05002]
[2020-05-12 03:05:07.279]  Step 151341  [3.610 sec/step, loss=0.09653, avg_loss=0.09029, mel_loss=0.04357, linear_loss=0.05296]
[2020-05-12 03:05:13.428]  Step 151342  [3.619 sec/step, loss=0.09778, avg_loss=0.09029, mel_loss=0.04465, linear_loss=0.05313]
[2020-05-12 03:05:14.907]  Step 151343  [3.610 sec/step, loss=0.08900, avg_loss=0.09027, mel_loss=0.03903, linear_loss=0.04997]
[2020-05-12 03:05:16.959]  Generated 32 batches of size 32 in 2.045 sec
[2020-05-12 03:05:17.834]  Step 151344  [3.619 sec/step, loss=0.09365, avg_loss=0.09033, mel_loss=0.04188, linear_loss=0.05177]
[2020-05-12 03:05:20.544]  Step 151345  [3.575 sec/step, loss=0.09247, avg_loss=0.09027, mel_loss=0.04129, linear_loss=0.05118]
[2020-05-12 03:05:24.475]  Step 151346  [3.547 sec/step, loss=0.09637, avg_loss=0.09025, mel_loss=0.04332, linear_loss=0.05306]
[2020-05-12 03:05:25.632]  Step 151347  [3.531 sec/step, loss=0.08521, avg_loss=0.09020, mel_loss=0.03712, linear_loss=0.04809]
[2020-05-12 03:05:26.617]  Step 151348  [3.533 sec/step, loss=0.08240, avg_loss=0.09025, mel_loss=0.03574, linear_loss=0.04666]
[2020-05-12 03:05:30.328]  Step 151349  [3.560 sec/step, loss=0.09671, avg_loss=0.09037, mel_loss=0.04370, linear_loss=0.05302]
[2020-05-12 03:05:31.420]  Step 151350  [3.541 sec/step, loss=0.08483, avg_loss=0.09026, mel_loss=0.03633, linear_loss=0.04850]
[2020-05-12 03:05:31.420]  Writing summary at step: 151350
[2020-05-12 03:05:36.165]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151350
[2020-05-12 03:05:37.805]  Saving audio and alignment...
[2020-05-12 03:05:39.473]  Input: 다음으로~_________________
[2020-05-12 03:05:41.328]  Step 151351  [3.440 sec/step, loss=0.08867, avg_loss=0.09026, mel_loss=0.03911, linear_loss=0.04956]
[2020-05-12 03:05:44.413]  Step 151352  [3.433 sec/step, loss=0.09631, avg_loss=0.09026, mel_loss=0.04283, linear_loss=0.05348]
[2020-05-12 03:05:48.091]  Step 151353  [3.454 sec/step, loss=0.09818, avg_loss=0.09036, mel_loss=0.04422, linear_loss=0.05396]
[2020-05-12 03:05:49.820]  Step 151354  [3.424 sec/step, loss=0.09223, avg_loss=0.09031, mel_loss=0.04007, linear_loss=0.05216]
[2020-05-12 03:05:51.818]  Step 151355  [3.428 sec/step, loss=0.09094, avg_loss=0.09031, mel_loss=0.04016, linear_loss=0.05078]
[2020-05-12 03:05:53.216]  Step 151356  [3.353 sec/step, loss=0.08691, avg_loss=0.09022, mel_loss=0.03802, linear_loss=0.04890]
[2020-05-12 03:06:00.462]  Step 151357  [3.418 sec/step, loss=0.10086, avg_loss=0.09051, mel_loss=0.04655, linear_loss=0.05431]
[2020-05-12 03:06:01.504]  Step 151358  [3.373 sec/step, loss=0.08256, avg_loss=0.09038, mel_loss=0.03564, linear_loss=0.04692]
[2020-05-12 03:06:02.330]  Step 151359  [3.329 sec/step, loss=0.07663, avg_loss=0.09018, mel_loss=0.03295, linear_loss=0.04367]
[2020-05-12 03:06:05.818]  Step 151360  [3.220 sec/step, loss=0.09682, avg_loss=0.09039, mel_loss=0.04367, linear_loss=0.05315]
[2020-05-12 03:06:11.265]  Step 151361  [3.261 sec/step, loss=0.09704, avg_loss=0.09051, mel_loss=0.04419, linear_loss=0.05285]
[2020-05-12 03:06:13.678]  Step 151362  [3.264 sec/step, loss=0.09283, avg_loss=0.09054, mel_loss=0.04113, linear_loss=0.05169]
[2020-05-12 03:06:14.953]  Step 151363  [3.255 sec/step, loss=0.08188, avg_loss=0.09043, mel_loss=0.03579, linear_loss=0.04609]
[2020-05-12 03:06:19.946]  Step 151364  [3.294 sec/step, loss=0.09572, avg_loss=0.09054, mel_loss=0.04366, linear_loss=0.05206]
[2020-05-12 03:06:21.029]  Step 151365  [3.270 sec/step, loss=0.08548, avg_loss=0.09042, mel_loss=0.03708, linear_loss=0.04840]
[2020-05-12 03:06:29.060]  Step 151366  [3.342 sec/step, loss=0.09610, avg_loss=0.09060, mel_loss=0.04472, linear_loss=0.05138]
[2020-05-12 03:06:31.044]  Step 151367  [3.336 sec/step, loss=0.09229, avg_loss=0.09058, mel_loss=0.04075, linear_loss=0.05154]
[2020-05-12 03:06:35.316]  Step 151368  [3.341 sec/step, loss=0.09487, avg_loss=0.09055, mel_loss=0.04275, linear_loss=0.05212]
[2020-05-12 03:06:36.226]  Step 151369  [3.306 sec/step, loss=0.08201, avg_loss=0.09039, mel_loss=0.03528, linear_loss=0.04673]
[2020-05-12 03:06:37.749]  Step 151370  [3.285 sec/step, loss=0.08757, avg_loss=0.09029, mel_loss=0.03828, linear_loss=0.04929]
[2020-05-12 03:06:40.372]  Step 151371  [3.251 sec/step, loss=0.09297, avg_loss=0.09025, mel_loss=0.04142, linear_loss=0.05155]
[2020-05-12 03:06:42.566]  Step 151372  [3.198 sec/step, loss=0.09103, avg_loss=0.09017, mel_loss=0.04027, linear_loss=0.05076]
[2020-05-12 03:06:43.914]  Step 151373  [3.192 sec/step, loss=0.08707, avg_loss=0.09014, mel_loss=0.03795, linear_loss=0.04912]
[2020-05-12 03:06:45.786]  Generated 32 batches of size 32 in 1.866 sec
[2020-05-12 03:06:47.366]  Step 151374  [3.211 sec/step, loss=0.09455, avg_loss=0.09021, mel_loss=0.04237, linear_loss=0.05218]
[2020-05-12 03:06:48.116]  Step 151375  [3.184 sec/step, loss=0.07852, avg_loss=0.09007, mel_loss=0.03386, linear_loss=0.04466]
[2020-05-12 03:07:00.802]  Step 151376  [3.225 sec/step, loss=0.08453, avg_loss=0.08994, mel_loss=0.03987, linear_loss=0.04466]
[2020-05-12 03:07:05.244]  Step 151377  [3.259 sec/step, loss=0.09825, avg_loss=0.09009, mel_loss=0.04441, linear_loss=0.05384]
[2020-05-12 03:07:06.859]  Step 151378  [3.268 sec/step, loss=0.08964, avg_loss=0.09023, mel_loss=0.03947, linear_loss=0.05016]
[2020-05-12 03:07:09.803]  Step 151379  [3.280 sec/step, loss=0.09334, avg_loss=0.09027, mel_loss=0.04167, linear_loss=0.05167]
[2020-05-12 03:07:10.364]  Step 151380  [3.277 sec/step, loss=0.07133, avg_loss=0.09020, mel_loss=0.03137, linear_loss=0.03996]
[2020-05-12 03:07:16.364]  Step 151381  [3.319 sec/step, loss=0.09663, avg_loss=0.09028, mel_loss=0.04421, linear_loss=0.05241]
[2020-05-12 03:07:18.892]  Step 151382  [3.320 sec/step, loss=0.09195, avg_loss=0.09028, mel_loss=0.04062, linear_loss=0.05133]
[2020-05-12 03:07:19.460]  Step 151383  [3.314 sec/step, loss=0.07229, avg_loss=0.09014, mel_loss=0.03213, linear_loss=0.04016]
[2020-05-12 03:07:20.639]  Step 151384  [3.312 sec/step, loss=0.08211, avg_loss=0.09009, mel_loss=0.03576, linear_loss=0.04635]
[2020-05-12 03:07:25.098]  Step 151385  [3.325 sec/step, loss=0.09558, avg_loss=0.09008, mel_loss=0.04339, linear_loss=0.05219]
[2020-05-12 03:07:26.405]  Step 151386  [3.309 sec/step, loss=0.08548, avg_loss=0.08999, mel_loss=0.03699, linear_loss=0.04849]
[2020-05-12 03:07:27.479]  Step 151387  [3.264 sec/step, loss=0.08354, avg_loss=0.08985, mel_loss=0.03617, linear_loss=0.04738]
[2020-05-12 03:07:28.409]  Step 151388  [3.249 sec/step, loss=0.08181, avg_loss=0.08976, mel_loss=0.03529, linear_loss=0.04652]
[2020-05-12 03:07:31.761]  Step 151389  [3.240 sec/step, loss=0.09605, avg_loss=0.08976, mel_loss=0.04316, linear_loss=0.05289]
[2020-05-12 03:07:45.898]  Step 151390  [3.373 sec/step, loss=0.07558, avg_loss=0.08973, mel_loss=0.03609, linear_loss=0.03949]
[2020-05-12 03:07:49.901]  Step 151391  [3.274 sec/step, loss=0.09818, avg_loss=0.08993, mel_loss=0.04434, linear_loss=0.05383]
[2020-05-12 03:07:53.954]  Step 151392  [3.305 sec/step, loss=0.09703, avg_loss=0.09009, mel_loss=0.04359, linear_loss=0.05344]
[2020-05-12 03:07:55.284]  Step 151393  [3.305 sec/step, loss=0.08634, avg_loss=0.09011, mel_loss=0.03760, linear_loss=0.04874]
[2020-05-12 03:07:57.241]  Step 151394  [3.314 sec/step, loss=0.09035, avg_loss=0.09023, mel_loss=0.03983, linear_loss=0.05052]
[2020-05-12 03:08:00.666]  Step 151395  [3.332 sec/step, loss=0.09255, avg_loss=0.09027, mel_loss=0.04147, linear_loss=0.05108]
[2020-05-12 03:08:02.209]  Step 151396  [3.334 sec/step, loss=0.08825, avg_loss=0.09027, mel_loss=0.03836, linear_loss=0.04989]
[2020-05-12 03:08:04.622]  Step 151397  [3.270 sec/step, loss=0.09129, avg_loss=0.09021, mel_loss=0.04030, linear_loss=0.05099]
[2020-05-12 03:08:07.714]  Step 151398  [3.277 sec/step, loss=0.09587, avg_loss=0.09026, mel_loss=0.04296, linear_loss=0.05291]
[2020-05-12 03:08:14.887]  Step 151399  [3.320 sec/step, loss=0.09823, avg_loss=0.09030, mel_loss=0.04530, linear_loss=0.05293]
[2020-05-12 03:08:15.843]  Step 151400  [3.295 sec/step, loss=0.08383, avg_loss=0.09020, mel_loss=0.03600, linear_loss=0.04783]
[2020-05-12 03:08:15.843]  Writing summary at step: 151400
[2020-05-12 03:08:18.645]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151400
[2020-05-12 03:08:20.141]  Saving audio and alignment...
[2020-05-12 03:08:24.770]  Input: 예문 하나를 연습할 때도  네 정답은~_______________________
[2020-05-12 03:08:25.655]  Step 151401  [3.293 sec/step, loss=0.07715, avg_loss=0.09013, mel_loss=0.03327, linear_loss=0.04388]
[2020-05-12 03:08:27.520]  Step 151402  [3.291 sec/step, loss=0.08818, avg_loss=0.09010, mel_loss=0.03853, linear_loss=0.04965]
[2020-05-12 03:08:29.597]  Step 151403  [3.287 sec/step, loss=0.09164, avg_loss=0.09010, mel_loss=0.04046, linear_loss=0.05119]
[2020-05-12 03:08:31.476]  Generated 32 batches of size 32 in 1.873 sec
[2020-05-12 03:08:32.027]  Step 151404  [3.258 sec/step, loss=0.09205, avg_loss=0.09004, mel_loss=0.04097, linear_loss=0.05108]
[2020-05-12 03:08:38.260]  Step 151405  [3.283 sec/step, loss=0.09698, avg_loss=0.09003, mel_loss=0.04461, linear_loss=0.05236]
[2020-05-12 03:08:39.828]  Step 151406  [3.268 sec/step, loss=0.08992, avg_loss=0.08998, mel_loss=0.03941, linear_loss=0.05051]
[2020-05-12 03:08:41.641]  Step 151407  [3.239 sec/step, loss=0.08926, avg_loss=0.08990, mel_loss=0.03887, linear_loss=0.05040]
[2020-05-12 03:08:46.471]  Step 151408  [3.219 sec/step, loss=0.09832, avg_loss=0.08991, mel_loss=0.04447, linear_loss=0.05385]
[2020-05-12 03:08:55.043]  Step 151409  [3.244 sec/step, loss=0.09834, avg_loss=0.08991, mel_loss=0.04559, linear_loss=0.05275]
[2020-05-12 03:08:55.875]  Step 151410  [3.244 sec/step, loss=0.07542, avg_loss=0.08990, mel_loss=0.03236, linear_loss=0.04306]
[2020-05-12 03:08:59.447]  Step 151411  [3.260 sec/step, loss=0.09643, avg_loss=0.08998, mel_loss=0.04337, linear_loss=0.05305]
[2020-05-12 03:09:05.032]  Step 151412  [3.304 sec/step, loss=0.09684, avg_loss=0.09012, mel_loss=0.04447, linear_loss=0.05238]
[2020-05-12 03:09:09.423]  Step 151413  [3.340 sec/step, loss=0.09962, avg_loss=0.09031, mel_loss=0.04514, linear_loss=0.05449]
[2020-05-12 03:09:11.602]  Step 151414  [3.335 sec/step, loss=0.09023, avg_loss=0.09029, mel_loss=0.03991, linear_loss=0.05032]
[2020-05-12 03:09:19.124]  Step 151415  [3.376 sec/step, loss=0.09941, avg_loss=0.09033, mel_loss=0.04600, linear_loss=0.05341]
[2020-05-12 03:09:19.906]  Step 151416  [3.340 sec/step, loss=0.07393, avg_loss=0.09010, mel_loss=0.03208, linear_loss=0.04185]
[2020-05-12 03:09:25.581]  Step 151417  [3.320 sec/step, loss=0.09806, avg_loss=0.09011, mel_loss=0.04468, linear_loss=0.05338]
[2020-05-12 03:09:26.878]  Step 151418  [3.317 sec/step, loss=0.08789, avg_loss=0.09010, mel_loss=0.03862, linear_loss=0.04927]
[2020-05-12 03:09:30.256]  Step 151419  [3.309 sec/step, loss=0.09615, avg_loss=0.09010, mel_loss=0.04330, linear_loss=0.05285]
[2020-05-12 03:09:31.131]  Step 151420  [3.299 sec/step, loss=0.08094, avg_loss=0.09002, mel_loss=0.03482, linear_loss=0.04613]
[2020-05-12 03:09:32.399]  Step 151421  [3.282 sec/step, loss=0.08773, avg_loss=0.08993, mel_loss=0.03804, linear_loss=0.04969]
[2020-05-12 03:09:33.481]  Step 151422  [3.283 sec/step, loss=0.08260, avg_loss=0.08997, mel_loss=0.03567, linear_loss=0.04692]
[2020-05-12 03:09:34.318]  Step 151423  [3.250 sec/step, loss=0.07661, avg_loss=0.08977, mel_loss=0.03283, linear_loss=0.04377]
[2020-05-12 03:09:35.989]  Step 151424  [3.072 sec/step, loss=0.08906, avg_loss=0.08990, mel_loss=0.03922, linear_loss=0.04984]
[2020-05-12 03:09:37.475]  Step 151425  [3.015 sec/step, loss=0.08543, avg_loss=0.08977, mel_loss=0.03755, linear_loss=0.04788]
[2020-05-12 03:09:40.327]  Step 151426  [3.038 sec/step, loss=0.09565, avg_loss=0.09002, mel_loss=0.04253, linear_loss=0.05312]
[2020-05-12 03:09:41.079]  Step 151427  [2.955 sec/step, loss=0.07239, avg_loss=0.08977, mel_loss=0.03227, linear_loss=0.04013]
[2020-05-12 03:09:47.825]  Step 151428  [3.002 sec/step, loss=0.09767, avg_loss=0.08984, mel_loss=0.04503, linear_loss=0.05264]
[2020-05-12 03:09:56.649]  Step 151429  [3.037 sec/step, loss=0.09582, avg_loss=0.08983, mel_loss=0.04450, linear_loss=0.05132]
[2020-05-12 03:10:00.111]  Step 151430  [3.051 sec/step, loss=0.09484, avg_loss=0.08986, mel_loss=0.04254, linear_loss=0.05230]
[2020-05-12 03:10:03.755]  Step 151431  [3.071 sec/step, loss=0.09764, avg_loss=0.08996, mel_loss=0.04395, linear_loss=0.05369]
[2020-05-12 03:10:04.858]  Step 151432  [3.068 sec/step, loss=0.08559, avg_loss=0.08994, mel_loss=0.03672, linear_loss=0.04887]
[2020-05-12 03:10:10.183]  Step 151433  [3.098 sec/step, loss=0.09645, avg_loss=0.08999, mel_loss=0.04391, linear_loss=0.05254]
[2020-05-12 03:10:11.950]  Step 151434  [3.080 sec/step, loss=0.08915, avg_loss=0.08993, mel_loss=0.03951, linear_loss=0.04964]
[2020-05-12 03:10:16.130]  Step 151435  [3.087 sec/step, loss=0.09447, avg_loss=0.08994, mel_loss=0.04272, linear_loss=0.05175]
[2020-05-12 03:10:17.809]  Generated 32 batches of size 32 in 1.674 sec
[2020-05-12 03:10:18.922]  Step 151436  [3.107 sec/step, loss=0.09314, avg_loss=0.09009, mel_loss=0.04168, linear_loss=0.05146]
[2020-05-12 03:10:20.618]  Step 151437  [3.110 sec/step, loss=0.08970, avg_loss=0.09014, mel_loss=0.03928, linear_loss=0.05042]
[2020-05-12 03:10:33.614]  Step 151438  [3.165 sec/step, loss=0.08431, avg_loss=0.09001, mel_loss=0.03975, linear_loss=0.04456]
[2020-05-12 03:10:35.594]  Step 151439  [3.163 sec/step, loss=0.09009, avg_loss=0.08999, mel_loss=0.03977, linear_loss=0.05033]
[2020-05-12 03:10:38.629]  Step 151440  [3.175 sec/step, loss=0.09583, avg_loss=0.09006, mel_loss=0.04298, linear_loss=0.05285]
[2020-05-12 03:10:43.406]  Step 151441  [3.191 sec/step, loss=0.09558, avg_loss=0.09005, mel_loss=0.04328, linear_loss=0.05230]
[2020-05-12 03:10:45.850]  Step 151442  [3.154 sec/step, loss=0.09245, avg_loss=0.09000, mel_loss=0.04063, linear_loss=0.05182]
[2020-05-12 03:10:48.114]  Step 151443  [3.162 sec/step, loss=0.09321, avg_loss=0.09004, mel_loss=0.04144, linear_loss=0.05177]
[2020-05-12 03:10:50.134]  Step 151444  [3.153 sec/step, loss=0.09195, avg_loss=0.09002, mel_loss=0.04055, linear_loss=0.05140]
[2020-05-12 03:10:51.361]  Step 151445  [3.138 sec/step, loss=0.08256, avg_loss=0.08992, mel_loss=0.03591, linear_loss=0.04665]
[2020-05-12 03:10:52.204]  Step 151446  [3.107 sec/step, loss=0.07882, avg_loss=0.08975, mel_loss=0.03341, linear_loss=0.04541]
[2020-05-12 03:10:55.346]  Step 151447  [3.127 sec/step, loss=0.09717, avg_loss=0.08987, mel_loss=0.04353, linear_loss=0.05364]
[2020-05-12 03:10:57.344]  Step 151448  [3.137 sec/step, loss=0.09096, avg_loss=0.08995, mel_loss=0.04005, linear_loss=0.05091]
[2020-05-12 03:10:59.454]  Step 151449  [3.121 sec/step, loss=0.09191, avg_loss=0.08990, mel_loss=0.04067, linear_loss=0.05124]
[2020-05-12 03:11:00.211]  Step 151450  [3.118 sec/step, loss=0.07817, avg_loss=0.08984, mel_loss=0.03348, linear_loss=0.04469]
[2020-05-12 03:11:00.211]  Writing summary at step: 151450
[2020-05-12 03:11:01.842]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151450
[2020-05-12 03:11:03.300]  Saving audio and alignment...
[2020-05-12 03:11:08.239]  Input: 아직도 많은 분들의 기억 속에 남아 있을 텐데요 그녀가~_________
[2020-05-12 03:11:11.959]  Step 151451  [3.137 sec/step, loss=0.09657, avg_loss=0.08992, mel_loss=0.04348, linear_loss=0.05308]
[2020-05-12 03:11:15.448]  Step 151452  [3.141 sec/step, loss=0.09287, avg_loss=0.08988, mel_loss=0.04174, linear_loss=0.05112]
[2020-05-12 03:11:16.775]  Step 151453  [3.117 sec/step, loss=0.08689, avg_loss=0.08977, mel_loss=0.03771, linear_loss=0.04918]
[2020-05-12 03:11:18.257]  Step 151454  [3.115 sec/step, loss=0.09022, avg_loss=0.08975, mel_loss=0.03932, linear_loss=0.05090]
[2020-05-12 03:11:25.225]  Step 151455  [3.164 sec/step, loss=0.09813, avg_loss=0.08982, mel_loss=0.04505, linear_loss=0.05307]
[2020-05-12 03:11:28.773]  Step 151456  [3.186 sec/step, loss=0.09674, avg_loss=0.08992, mel_loss=0.04362, linear_loss=0.05313]
[2020-05-12 03:11:29.525]  Step 151457  [3.121 sec/step, loss=0.07642, avg_loss=0.08968, mel_loss=0.03318, linear_loss=0.04324]
[2020-05-12 03:11:31.710]  Step 151458  [3.132 sec/step, loss=0.09125, avg_loss=0.08976, mel_loss=0.04036, linear_loss=0.05088]
[2020-05-12 03:11:39.953]  Step 151459  [3.206 sec/step, loss=0.09398, avg_loss=0.08994, mel_loss=0.04360, linear_loss=0.05038]
[2020-05-12 03:11:45.928]  Step 151460  [3.231 sec/step, loss=0.09600, avg_loss=0.08993, mel_loss=0.04385, linear_loss=0.05215]
[2020-05-12 03:11:57.757]  Step 151461  [3.295 sec/step, loss=0.08777, avg_loss=0.08983, mel_loss=0.04164, linear_loss=0.04614]
[2020-05-12 03:11:58.509]  Step 151462  [3.279 sec/step, loss=0.07424, avg_loss=0.08965, mel_loss=0.03287, linear_loss=0.04137]
[2020-05-12 03:12:00.926]  Step 151463  [3.290 sec/step, loss=0.09206, avg_loss=0.08975, mel_loss=0.04090, linear_loss=0.05115]
[2020-05-12 03:12:05.056]  Step 151464  [3.281 sec/step, loss=0.09666, avg_loss=0.08976, mel_loss=0.04327, linear_loss=0.05339]
[2020-05-12 03:12:06.100]  Step 151465  [3.281 sec/step, loss=0.08388, avg_loss=0.08974, mel_loss=0.03630, linear_loss=0.04758]
[2020-05-12 03:12:07.845]  Generated 32 batches of size 32 in 1.739 sec
[2020-05-12 03:12:08.740]  Step 151466  [3.227 sec/step, loss=0.09303, avg_loss=0.08971, mel_loss=0.04128, linear_loss=0.05175]
[2020-05-12 03:12:11.601]  Step 151467  [3.236 sec/step, loss=0.09285, avg_loss=0.08972, mel_loss=0.04166, linear_loss=0.05119]
[2020-05-12 03:12:16.525]  Step 151468  [3.242 sec/step, loss=0.09664, avg_loss=0.08974, mel_loss=0.04364, linear_loss=0.05300]
[2020-05-12 03:12:20.758]  Step 151469  [3.276 sec/step, loss=0.09741, avg_loss=0.08989, mel_loss=0.04408, linear_loss=0.05334]
[2020-05-12 03:12:26.214]  Step 151470  [3.315 sec/step, loss=0.09751, avg_loss=0.08999, mel_loss=0.04439, linear_loss=0.05312]
[2020-05-12 03:12:27.602]  Step 151471  [3.303 sec/step, loss=0.08378, avg_loss=0.08990, mel_loss=0.03649, linear_loss=0.04729]
[2020-05-12 03:12:29.470]  Step 151472  [3.299 sec/step, loss=0.08742, avg_loss=0.08986, mel_loss=0.03839, linear_loss=0.04904]
[2020-05-12 03:12:31.220]  Step 151473  [3.303 sec/step, loss=0.09008, avg_loss=0.08989, mel_loss=0.03934, linear_loss=0.05073]
[2020-05-12 03:12:32.149]  Step 151474  [3.278 sec/step, loss=0.08150, avg_loss=0.08976, mel_loss=0.03512, linear_loss=0.04637]
[2020-05-12 03:12:34.174]  Step 151475  [3.291 sec/step, loss=0.09022, avg_loss=0.08988, mel_loss=0.04001, linear_loss=0.05020]
[2020-05-12 03:12:39.796]  Step 151476  [3.220 sec/step, loss=0.09968, avg_loss=0.09003, mel_loss=0.04565, linear_loss=0.05403]
[2020-05-12 03:12:40.474]  Step 151477  [3.183 sec/step, loss=0.07229, avg_loss=0.08977, mel_loss=0.03178, linear_loss=0.04051]
[2020-05-12 03:12:43.882]  Step 151478  [3.200 sec/step, loss=0.09406, avg_loss=0.08981, mel_loss=0.04204, linear_loss=0.05201]
[2020-05-12 03:12:46.314]  Step 151479  [3.195 sec/step, loss=0.09289, avg_loss=0.08981, mel_loss=0.04097, linear_loss=0.05192]
[2020-05-12 03:12:49.786]  Step 151480  [3.224 sec/step, loss=0.09337, avg_loss=0.09003, mel_loss=0.04181, linear_loss=0.05155]
[2020-05-12 03:13:04.069]  Step 151481  [3.307 sec/step, loss=0.07562, avg_loss=0.08982, mel_loss=0.03599, linear_loss=0.03963]
[2020-05-12 03:13:10.775]  Step 151482  [3.349 sec/step, loss=0.09841, avg_loss=0.08989, mel_loss=0.04541, linear_loss=0.05300]
[2020-05-12 03:13:12.554]  Step 151483  [3.361 sec/step, loss=0.08812, avg_loss=0.09004, mel_loss=0.03834, linear_loss=0.04977]
[2020-05-12 03:13:13.584]  Step 151484  [3.360 sec/step, loss=0.08246, avg_loss=0.09005, mel_loss=0.03574, linear_loss=0.04673]
[2020-05-12 03:13:15.504]  Step 151485  [3.334 sec/step, loss=0.08851, avg_loss=0.08998, mel_loss=0.03877, linear_loss=0.04975]
[2020-05-12 03:13:16.552]  Step 151486  [3.332 sec/step, loss=0.08245, avg_loss=0.08995, mel_loss=0.03601, linear_loss=0.04644]
[2020-05-12 03:13:18.170]  Step 151487  [3.337 sec/step, loss=0.08798, avg_loss=0.08999, mel_loss=0.03858, linear_loss=0.04940]
[2020-05-12 03:13:19.534]  Step 151488  [3.341 sec/step, loss=0.08800, avg_loss=0.09005, mel_loss=0.03864, linear_loss=0.04937]
[2020-05-12 03:13:20.368]  Step 151489  [3.316 sec/step, loss=0.07609, avg_loss=0.08985, mel_loss=0.03307, linear_loss=0.04301]
[2020-05-12 03:13:27.838]  Step 151490  [3.250 sec/step, loss=0.09817, avg_loss=0.09008, mel_loss=0.04555, linear_loss=0.05261]
[2020-05-12 03:13:28.389]  Step 151491  [3.215 sec/step, loss=0.06992, avg_loss=0.08980, mel_loss=0.03137, linear_loss=0.03855]
[2020-05-12 03:13:30.813]  Step 151492  [3.199 sec/step, loss=0.09218, avg_loss=0.08975, mel_loss=0.04099, linear_loss=0.05119]
[2020-05-12 03:13:32.532]  Step 151493  [3.203 sec/step, loss=0.08759, avg_loss=0.08976, mel_loss=0.03852, linear_loss=0.04907]
[2020-05-12 03:13:35.417]  Step 151494  [3.212 sec/step, loss=0.09449, avg_loss=0.08980, mel_loss=0.04251, linear_loss=0.05199]
[2020-05-12 03:13:39.965]  Step 151495  [3.223 sec/step, loss=0.09834, avg_loss=0.08986, mel_loss=0.04489, linear_loss=0.05344]
[2020-05-12 03:13:43.634]  Step 151496  [3.244 sec/step, loss=0.09898, avg_loss=0.08997, mel_loss=0.04457, linear_loss=0.05441]
[2020-05-12 03:13:47.773]  Step 151497  [3.262 sec/step, loss=0.09445, avg_loss=0.09000, mel_loss=0.04269, linear_loss=0.05176]
[2020-05-12 03:13:49.463]  Generated 32 batches of size 32 in 1.685 sec
[2020-05-12 03:13:52.567]  Step 151498  [3.279 sec/step, loss=0.09680, avg_loss=0.09001, mel_loss=0.04411, linear_loss=0.05269]
[2020-05-12 03:13:53.659]  Step 151499  [3.218 sec/step, loss=0.08738, avg_loss=0.08990, mel_loss=0.03758, linear_loss=0.04980]
[2020-05-12 03:13:56.555]  Step 151500  [3.237 sec/step, loss=0.09540, avg_loss=0.09001, mel_loss=0.04255, linear_loss=0.05284]
[2020-05-12 03:13:56.555]  Writing summary at step: 151500
[2020-05-12 03:13:57.925]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151500
[2020-05-12 03:13:59.376]  Saving audio and alignment...
[2020-05-12 03:14:04.214]  Input: 표정 제스처 감정 등이 아주 큰 영향을 미친다~_______________
[2020-05-12 03:14:09.333]  Step 151501  [3.280 sec/step, loss=0.09851, avg_loss=0.09023, mel_loss=0.04522, linear_loss=0.05330]
[2020-05-12 03:14:11.446]  Step 151502  [3.282 sec/step, loss=0.09085, avg_loss=0.09025, mel_loss=0.04021, linear_loss=0.05063]
[2020-05-12 03:14:24.744]  Step 151503  [3.394 sec/step, loss=0.09639, avg_loss=0.09030, mel_loss=0.04467, linear_loss=0.05172]
[2020-05-12 03:14:26.095]  Step 151504  [3.384 sec/step, loss=0.08655, avg_loss=0.09025, mel_loss=0.03775, linear_loss=0.04880]
[2020-05-12 03:14:27.503]  Step 151505  [3.335 sec/step, loss=0.08481, avg_loss=0.09013, mel_loss=0.03709, linear_loss=0.04771]
[2020-05-12 03:14:28.496]  Step 151506  [3.330 sec/step, loss=0.08107, avg_loss=0.09004, mel_loss=0.03500, linear_loss=0.04606]
[2020-05-12 03:14:29.301]  Step 151507  [3.319 sec/step, loss=0.07660, avg_loss=0.08991, mel_loss=0.03306, linear_loss=0.04354]
[2020-05-12 03:14:32.769]  Step 151508  [3.306 sec/step, loss=0.09569, avg_loss=0.08988, mel_loss=0.04284, linear_loss=0.05285]
[2020-05-12 03:14:35.517]  Step 151509  [3.248 sec/step, loss=0.09302, avg_loss=0.08983, mel_loss=0.04134, linear_loss=0.05168]
[2020-05-12 03:14:36.936]  Step 151510  [3.253 sec/step, loss=0.08656, avg_loss=0.08994, mel_loss=0.03784, linear_loss=0.04871]
[2020-05-12 03:14:38.066]  Step 151511  [3.229 sec/step, loss=0.08359, avg_loss=0.08981, mel_loss=0.03594, linear_loss=0.04765]
[2020-05-12 03:14:42.325]  Step 151512  [3.216 sec/step, loss=0.09540, avg_loss=0.08980, mel_loss=0.04298, linear_loss=0.05242]
[2020-05-12 03:14:43.936]  Step 151513  [3.188 sec/step, loss=0.08804, avg_loss=0.08968, mel_loss=0.03873, linear_loss=0.04931]
[2020-05-12 03:14:46.285]  Step 151514  [3.190 sec/step, loss=0.09352, avg_loss=0.08972, mel_loss=0.04149, linear_loss=0.05203]
[2020-05-12 03:14:48.375]  Step 151515  [3.135 sec/step, loss=0.08968, avg_loss=0.08962, mel_loss=0.03968, linear_loss=0.05000]
[2020-05-12 03:14:53.555]  Step 151516  [3.179 sec/step, loss=0.09494, avg_loss=0.08983, mel_loss=0.04325, linear_loss=0.05169]
[2020-05-12 03:14:59.194]  Step 151517  [3.179 sec/step, loss=0.09708, avg_loss=0.08982, mel_loss=0.04447, linear_loss=0.05261]
[2020-05-12 03:15:00.438]  Step 151518  [3.178 sec/step, loss=0.08254, avg_loss=0.08977, mel_loss=0.03610, linear_loss=0.04644]
[2020-05-12 03:15:03.691]  Step 151519  [3.177 sec/step, loss=0.09600, avg_loss=0.08976, mel_loss=0.04311, linear_loss=0.05290]
[2020-05-12 03:15:05.468]  Step 151520  [3.186 sec/step, loss=0.08943, avg_loss=0.08985, mel_loss=0.03914, linear_loss=0.05029]
[2020-05-12 03:15:07.586]  Step 151521  [3.195 sec/step, loss=0.09209, avg_loss=0.08989, mel_loss=0.04088, linear_loss=0.05121]
[2020-05-12 03:15:08.138]  Step 151522  [3.189 sec/step, loss=0.06972, avg_loss=0.08976, mel_loss=0.03094, linear_loss=0.03877]
[2020-05-12 03:15:10.069]  Step 151523  [3.200 sec/step, loss=0.08988, avg_loss=0.08990, mel_loss=0.03977, linear_loss=0.05011]
[2020-05-12 03:15:16.542]  Step 151524  [3.248 sec/step, loss=0.09741, avg_loss=0.08998, mel_loss=0.04490, linear_loss=0.05250]
[2020-05-12 03:15:29.074]  Step 151525  [3.359 sec/step, loss=0.08693, avg_loss=0.09000, mel_loss=0.04119, linear_loss=0.04574]
[2020-05-12 03:15:32.651]  Step 151526  [3.366 sec/step, loss=0.09681, avg_loss=0.09001, mel_loss=0.04363, linear_loss=0.05318]
[2020-05-12 03:15:35.722]  Step 151527  [3.389 sec/step, loss=0.09636, avg_loss=0.09025, mel_loss=0.04333, linear_loss=0.05303]
[2020-05-12 03:15:37.472]  Generated 32 batches of size 32 in 1.745 sec
[2020-05-12 03:15:37.517]  Step 151528  [3.340 sec/step, loss=0.08942, avg_loss=0.09016, mel_loss=0.03912, linear_loss=0.05030]
[2020-05-12 03:15:44.841]  Step 151529  [3.325 sec/step, loss=0.09825, avg_loss=0.09019, mel_loss=0.04537, linear_loss=0.05288]
[2020-05-12 03:15:53.569]  Step 151530  [3.377 sec/step, loss=0.09825, avg_loss=0.09022, mel_loss=0.04577, linear_loss=0.05248]
[2020-05-12 03:15:56.419]  Step 151531  [3.370 sec/step, loss=0.09383, avg_loss=0.09018, mel_loss=0.04200, linear_loss=0.05183]
[2020-05-12 03:15:58.887]  Step 151532  [3.383 sec/step, loss=0.09120, avg_loss=0.09024, mel_loss=0.04033, linear_loss=0.05087]
[2020-05-12 03:15:59.777]  Step 151533  [3.339 sec/step, loss=0.07995, avg_loss=0.09008, mel_loss=0.03420, linear_loss=0.04575]
[2020-05-12 03:16:04.353]  Step 151534  [3.367 sec/step, loss=0.09851, avg_loss=0.09017, mel_loss=0.04490, linear_loss=0.05361]
[2020-05-12 03:16:05.189]  Step 151535  [3.333 sec/step, loss=0.07826, avg_loss=0.09001, mel_loss=0.03386, linear_loss=0.04440]
[2020-05-12 03:16:09.355]  Step 151536  [3.347 sec/step, loss=0.09633, avg_loss=0.09004, mel_loss=0.04356, linear_loss=0.05277]
[2020-05-12 03:16:11.928]  Step 151537  [3.356 sec/step, loss=0.09273, avg_loss=0.09007, mel_loss=0.04133, linear_loss=0.05140]
[2020-05-12 03:16:14.755]  Step 151538  [3.254 sec/step, loss=0.09385, avg_loss=0.09016, mel_loss=0.04202, linear_loss=0.05183]
[2020-05-12 03:16:15.714]  Step 151539  [3.244 sec/step, loss=0.08291, avg_loss=0.09009, mel_loss=0.03537, linear_loss=0.04754]
[2020-05-12 03:16:17.616]  Step 151540  [3.233 sec/step, loss=0.09135, avg_loss=0.09005, mel_loss=0.04008, linear_loss=0.05127]
[2020-05-12 03:16:19.315]  Step 151541  [3.202 sec/step, loss=0.08868, avg_loss=0.08998, mel_loss=0.03899, linear_loss=0.04970]
[2020-05-12 03:16:21.046]  Step 151542  [3.195 sec/step, loss=0.08838, avg_loss=0.08994, mel_loss=0.03893, linear_loss=0.04945]
[2020-05-12 03:16:28.347]  Step 151543  [3.245 sec/step, loss=0.09912, avg_loss=0.09000, mel_loss=0.04570, linear_loss=0.05342]
[2020-05-12 03:16:30.472]  Step 151544  [3.246 sec/step, loss=0.09221, avg_loss=0.09000, mel_loss=0.04076, linear_loss=0.05145]
[2020-05-12 03:16:33.969]  Step 151545  [3.269 sec/step, loss=0.09407, avg_loss=0.09012, mel_loss=0.04245, linear_loss=0.05163]
[2020-05-12 03:16:38.899]  Step 151546  [3.310 sec/step, loss=0.09635, avg_loss=0.09029, mel_loss=0.04368, linear_loss=0.05266]
[2020-05-12 03:16:39.634]  Step 151547  [3.286 sec/step, loss=0.07752, avg_loss=0.09009, mel_loss=0.03364, linear_loss=0.04388]
[2020-05-12 03:16:43.032]  Step 151548  [3.300 sec/step, loss=0.09807, avg_loss=0.09016, mel_loss=0.04425, linear_loss=0.05381]
[2020-05-12 03:16:46.075]  Step 151549  [3.309 sec/step, loss=0.09671, avg_loss=0.09021, mel_loss=0.04335, linear_loss=0.05336]
[2020-05-12 03:16:48.091]  Step 151550  [3.322 sec/step, loss=0.09187, avg_loss=0.09035, mel_loss=0.04072, linear_loss=0.05114]
[2020-05-12 03:16:48.092]  Writing summary at step: 151550
[2020-05-12 03:16:49.158]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151550
[2020-05-12 03:16:51.674]  Saving audio and alignment...
[2020-05-12 03:16:53.043]  Input: 됐습니다~___
[2020-05-12 03:16:55.208]  Step 151551  [3.306 sec/step, loss=0.09253, avg_loss=0.09031, mel_loss=0.04093, linear_loss=0.05160]
[2020-05-12 03:17:09.456]  Step 151552  [3.414 sec/step, loss=0.07724, avg_loss=0.09015, mel_loss=0.03671, linear_loss=0.04052]
[2020-05-12 03:17:11.008]  Step 151553  [3.416 sec/step, loss=0.08740, avg_loss=0.09016, mel_loss=0.03856, linear_loss=0.04884]
[2020-05-12 03:17:12.147]  Step 151554  [3.413 sec/step, loss=0.08622, avg_loss=0.09012, mel_loss=0.03747, linear_loss=0.04875]
[2020-05-12 03:17:12.942]  Step 151555  [3.351 sec/step, loss=0.07970, avg_loss=0.08993, mel_loss=0.03451, linear_loss=0.04519]
[2020-05-12 03:17:13.922]  Step 151556  [3.325 sec/step, loss=0.08430, avg_loss=0.08981, mel_loss=0.03678, linear_loss=0.04752]
[2020-05-12 03:17:17.656]  Step 151557  [3.355 sec/step, loss=0.09835, avg_loss=0.09003, mel_loss=0.04440, linear_loss=0.05396]
[2020-05-12 03:17:19.440]  Generated 32 batches of size 32 in 1.778 sec
[2020-05-12 03:17:23.197]  Step 151558  [3.389 sec/step, loss=0.09746, avg_loss=0.09009, mel_loss=0.04440, linear_loss=0.05305]
[2020-05-12 03:17:26.797]  Step 151559  [3.342 sec/step, loss=0.09720, avg_loss=0.09012, mel_loss=0.04367, linear_loss=0.05353]
[2020-05-12 03:17:35.185]  Step 151560  [3.366 sec/step, loss=0.09418, avg_loss=0.09011, mel_loss=0.04356, linear_loss=0.05062]
[2020-05-12 03:17:37.615]  Step 151561  [3.272 sec/step, loss=0.09456, avg_loss=0.09017, mel_loss=0.04208, linear_loss=0.05248]
[2020-05-12 03:17:43.597]  Step 151562  [3.325 sec/step, loss=0.09690, avg_loss=0.09040, mel_loss=0.04433, linear_loss=0.05257]
[2020-05-12 03:17:48.155]  Step 151563  [3.346 sec/step, loss=0.09743, avg_loss=0.09045, mel_loss=0.04398, linear_loss=0.05344]
[2020-05-12 03:17:52.410]  Step 151564  [3.347 sec/step, loss=0.09501, avg_loss=0.09044, mel_loss=0.04283, linear_loss=0.05218]
[2020-05-12 03:17:53.792]  Step 151565  [3.351 sec/step, loss=0.08589, avg_loss=0.09046, mel_loss=0.03780, linear_loss=0.04809]
[2020-05-12 03:17:55.085]  Step 151566  [3.337 sec/step, loss=0.08706, avg_loss=0.09040, mel_loss=0.03799, linear_loss=0.04908]
[2020-05-12 03:17:55.924]  Step 151567  [3.317 sec/step, loss=0.07764, avg_loss=0.09025, mel_loss=0.03378, linear_loss=0.04386]
[2020-05-12 03:18:03.390]  Step 151568  [3.342 sec/step, loss=0.10003, avg_loss=0.09028, mel_loss=0.04639, linear_loss=0.05364]
[2020-05-12 03:18:04.406]  Step 151569  [3.310 sec/step, loss=0.08260, avg_loss=0.09013, mel_loss=0.03558, linear_loss=0.04703]
[2020-05-12 03:18:18.445]  Step 151570  [3.396 sec/step, loss=0.07666, avg_loss=0.08992, mel_loss=0.03674, linear_loss=0.03992]
[2020-05-12 03:18:20.014]  Step 151571  [3.398 sec/step, loss=0.08780, avg_loss=0.08996, mel_loss=0.03865, linear_loss=0.04915]
[2020-05-12 03:18:24.323]  Step 151572  [3.422 sec/step, loss=0.09755, avg_loss=0.09006, mel_loss=0.04439, linear_loss=0.05316]
[2020-05-12 03:18:27.808]  Step 151573  [3.440 sec/step, loss=0.09407, avg_loss=0.09010, mel_loss=0.04222, linear_loss=0.05185]
[2020-05-12 03:18:33.383]  Step 151574  [3.486 sec/step, loss=0.09778, avg_loss=0.09027, mel_loss=0.04467, linear_loss=0.05311]
[2020-05-12 03:18:34.203]  Step 151575  [3.474 sec/step, loss=0.07460, avg_loss=0.09011, mel_loss=0.03226, linear_loss=0.04234]
[2020-05-12 03:18:36.072]  Step 151576  [3.436 sec/step, loss=0.08845, avg_loss=0.09000, mel_loss=0.03861, linear_loss=0.04984]
[2020-05-12 03:18:39.709]  Step 151577  [3.466 sec/step, loss=0.09796, avg_loss=0.09025, mel_loss=0.04422, linear_loss=0.05374]
[2020-05-12 03:18:48.589]  Step 151578  [3.521 sec/step, loss=0.09541, avg_loss=0.09027, mel_loss=0.04438, linear_loss=0.05103]
[2020-05-12 03:18:50.763]  Step 151579  [3.518 sec/step, loss=0.09079, avg_loss=0.09025, mel_loss=0.04015, linear_loss=0.05064]
[2020-05-12 03:18:54.154]  Step 151580  [3.517 sec/step, loss=0.09613, avg_loss=0.09028, mel_loss=0.04322, linear_loss=0.05291]
[2020-05-12 03:18:55.195]  Step 151581  [3.385 sec/step, loss=0.08244, avg_loss=0.09034, mel_loss=0.03604, linear_loss=0.04640]
[2020-05-12 03:18:56.442]  Step 151582  [3.330 sec/step, loss=0.08496, avg_loss=0.09021, mel_loss=0.03704, linear_loss=0.04792]
[2020-05-12 03:18:59.555]  Step 151583  [3.344 sec/step, loss=0.09511, avg_loss=0.09028, mel_loss=0.04260, linear_loss=0.05251]
[2020-05-12 03:19:00.893]  Step 151584  [3.347 sec/step, loss=0.08741, avg_loss=0.09033, mel_loss=0.03819, linear_loss=0.04923]
[2020-05-12 03:19:05.582]  Step 151585  [3.374 sec/step, loss=0.09813, avg_loss=0.09042, mel_loss=0.04438, linear_loss=0.05375]
[2020-05-12 03:19:07.326]  Step 151586  [3.381 sec/step, loss=0.08995, avg_loss=0.09050, mel_loss=0.03932, linear_loss=0.05062]
[2020-05-12 03:19:09.809]  Step 151587  [3.390 sec/step, loss=0.09124, avg_loss=0.09053, mel_loss=0.04024, linear_loss=0.05100]
[2020-05-12 03:19:11.775]  Step 151588  [3.396 sec/step, loss=0.09253, avg_loss=0.09058, mel_loss=0.04092, linear_loss=0.05161]
[2020-05-12 03:19:15.895]  Step 151589  [3.429 sec/step, loss=0.09608, avg_loss=0.09078, mel_loss=0.04324, linear_loss=0.05284]
[2020-05-12 03:19:17.650]  Generated 32 batches of size 32 in 1.750 sec
[2020-05-12 03:19:18.618]  Step 151590  [3.381 sec/step, loss=0.09398, avg_loss=0.09074, mel_loss=0.04215, linear_loss=0.05184]
[2020-05-12 03:19:21.532]  Step 151591  [3.405 sec/step, loss=0.09465, avg_loss=0.09098, mel_loss=0.04214, linear_loss=0.05251]
[2020-05-12 03:19:26.582]  Step 151592  [3.431 sec/step, loss=0.09648, avg_loss=0.09103, mel_loss=0.04404, linear_loss=0.05244]
[2020-05-12 03:19:27.952]  Step 151593  [3.428 sec/step, loss=0.08648, avg_loss=0.09101, mel_loss=0.03795, linear_loss=0.04853]
[2020-05-12 03:19:29.556]  Step 151594  [3.415 sec/step, loss=0.08875, avg_loss=0.09096, mel_loss=0.03894, linear_loss=0.04981]
[2020-05-12 03:19:36.275]  Step 151595  [3.437 sec/step, loss=0.09701, avg_loss=0.09094, mel_loss=0.04473, linear_loss=0.05228]
[2020-05-12 03:19:37.417]  Step 151596  [3.411 sec/step, loss=0.08230, avg_loss=0.09078, mel_loss=0.03546, linear_loss=0.04685]
[2020-05-12 03:19:37.972]  Step 151597  [3.376 sec/step, loss=0.07379, avg_loss=0.09057, mel_loss=0.03264, linear_loss=0.04116]
[2020-05-12 03:19:40.359]  Step 151598  [3.352 sec/step, loss=0.08950, avg_loss=0.09050, mel_loss=0.03959, linear_loss=0.04991]
[2020-05-12 03:19:44.915]  Step 151599  [3.386 sec/step, loss=0.09634, avg_loss=0.09059, mel_loss=0.04368, linear_loss=0.05265]
[2020-05-12 03:19:46.318]  Step 151600  [3.371 sec/step, loss=0.08730, avg_loss=0.09051, mel_loss=0.03805, linear_loss=0.04925]
[2020-05-12 03:19:46.318]  Writing summary at step: 151600
[2020-05-12 03:19:48.514]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151600
[2020-05-12 03:19:49.963]  Saving audio and alignment...
[2020-05-12 03:19:56.327]  Input: 또한 기내에서는 보조 배터리에 사용을 자제해 주시기 바랍니다~____________________________
[2020-05-12 03:19:57.149]  Step 151601  [3.328 sec/step, loss=0.07642, avg_loss=0.09029, mel_loss=0.03262, linear_loss=0.04380]
[2020-05-12 03:20:02.432]  Step 151602  [3.360 sec/step, loss=0.09625, avg_loss=0.09034, mel_loss=0.04366, linear_loss=0.05259]
[2020-05-12 03:20:11.070]  Step 151603  [3.313 sec/step, loss=0.09569, avg_loss=0.09033, mel_loss=0.04443, linear_loss=0.05127]
[2020-05-12 03:20:14.602]  Step 151604  [3.335 sec/step, loss=0.09523, avg_loss=0.09042, mel_loss=0.04297, linear_loss=0.05226]
[2020-05-12 03:20:16.155]  Step 151605  [3.337 sec/step, loss=0.08964, avg_loss=0.09047, mel_loss=0.03948, linear_loss=0.05016]
[2020-05-12 03:20:18.140]  Step 151606  [3.347 sec/step, loss=0.09125, avg_loss=0.09057, mel_loss=0.04009, linear_loss=0.05116]
[2020-05-12 03:20:20.778]  Step 151607  [3.365 sec/step, loss=0.09386, avg_loss=0.09074, mel_loss=0.04178, linear_loss=0.05208]
[2020-05-12 03:20:27.788]  Step 151608  [3.400 sec/step, loss=0.09847, avg_loss=0.09077, mel_loss=0.04530, linear_loss=0.05317]
[2020-05-12 03:20:29.003]  Step 151609  [3.385 sec/step, loss=0.08225, avg_loss=0.09066, mel_loss=0.03584, linear_loss=0.04641]
[2020-05-12 03:20:32.405]  Step 151610  [3.405 sec/step, loss=0.09536, avg_loss=0.09075, mel_loss=0.04299, linear_loss=0.05237]
[2020-05-12 03:20:37.957]  Step 151611  [3.449 sec/step, loss=0.09780, avg_loss=0.09089, mel_loss=0.04479, linear_loss=0.05301]
[2020-05-12 03:20:39.610]  Step 151612  [3.423 sec/step, loss=0.08971, avg_loss=0.09083, mel_loss=0.03958, linear_loss=0.05013]
[2020-05-12 03:20:40.167]  Step 151613  [3.412 sec/step, loss=0.06892, avg_loss=0.09064, mel_loss=0.03044, linear_loss=0.03848]
[2020-05-12 03:20:46.741]  Step 151614  [3.455 sec/step, loss=0.09754, avg_loss=0.09068, mel_loss=0.04466, linear_loss=0.05289]
[2020-05-12 03:20:47.607]  Step 151615  [3.442 sec/step, loss=0.07721, avg_loss=0.09056, mel_loss=0.03340, linear_loss=0.04381]
[2020-05-12 03:20:49.331]  Step 151616  [3.408 sec/step, loss=0.08952, avg_loss=0.09051, mel_loss=0.03902, linear_loss=0.05050]
[2020-05-12 03:20:53.059]  Step 151617  [3.389 sec/step, loss=0.09571, avg_loss=0.09049, mel_loss=0.04298, linear_loss=0.05273]
[2020-05-12 03:20:54.492]  Step 151618  [3.391 sec/step, loss=0.08694, avg_loss=0.09054, mel_loss=0.03813, linear_loss=0.04880]
[2020-05-12 03:20:55.333]  Step 151619  [3.367 sec/step, loss=0.07462, avg_loss=0.09032, mel_loss=0.03264, linear_loss=0.04197]
[2020-05-12 03:20:57.024]  Generated 32 batches of size 32 in 1.686 sec
[2020-05-12 03:21:07.477]  Step 151620  [3.470 sec/step, loss=0.08729, avg_loss=0.09030, mel_loss=0.04121, linear_loss=0.04608]
[2020-05-12 03:21:09.876]  Step 151621  [3.473 sec/step, loss=0.09219, avg_loss=0.09030, mel_loss=0.04086, linear_loss=0.05133]
[2020-05-12 03:21:11.000]  Step 151622  [3.479 sec/step, loss=0.08436, avg_loss=0.09045, mel_loss=0.03614, linear_loss=0.04821]
[2020-05-12 03:21:13.841]  Step 151623  [3.488 sec/step, loss=0.09185, avg_loss=0.09047, mel_loss=0.04110, linear_loss=0.05074]
[2020-05-12 03:21:15.738]  Step 151624  [3.442 sec/step, loss=0.08799, avg_loss=0.09037, mel_loss=0.03858, linear_loss=0.04941]
[2020-05-12 03:21:19.107]  Step 151625  [3.350 sec/step, loss=0.09682, avg_loss=0.09047, mel_loss=0.04339, linear_loss=0.05342]
[2020-05-12 03:21:20.129]  Step 151626  [3.325 sec/step, loss=0.07935, avg_loss=0.09030, mel_loss=0.03427, linear_loss=0.04508]
[2020-05-12 03:21:22.314]  Step 151627  [3.316 sec/step, loss=0.09074, avg_loss=0.09024, mel_loss=0.04024, linear_loss=0.05050]
[2020-05-12 03:21:25.187]  Step 151628  [3.327 sec/step, loss=0.09478, avg_loss=0.09029, mel_loss=0.04232, linear_loss=0.05246]
[2020-05-12 03:21:31.486]  Step 151629  [3.317 sec/step, loss=0.09822, avg_loss=0.09029, mel_loss=0.04513, linear_loss=0.05309]
[2020-05-12 03:21:32.319]  Step 151630  [3.238 sec/step, loss=0.07695, avg_loss=0.09008, mel_loss=0.03343, linear_loss=0.04352]
[2020-05-12 03:21:33.371]  Step 151631  [3.220 sec/step, loss=0.08532, avg_loss=0.09000, mel_loss=0.03728, linear_loss=0.04804]
[2020-05-12 03:21:36.564]  Step 151632  [3.227 sec/step, loss=0.09521, avg_loss=0.09004, mel_loss=0.04249, linear_loss=0.05272]
[2020-05-12 03:21:37.685]  Step 151633  [3.229 sec/step, loss=0.08368, avg_loss=0.09007, mel_loss=0.03607, linear_loss=0.04761]
[2020-05-12 03:21:38.649]  Step 151634  [3.193 sec/step, loss=0.08430, avg_loss=0.08993, mel_loss=0.03615, linear_loss=0.04816]
[2020-05-12 03:21:44.255]  Step 151635  [3.241 sec/step, loss=0.09757, avg_loss=0.09012, mel_loss=0.04447, linear_loss=0.05310]
[2020-05-12 03:21:45.888]  Step 151636  [3.215 sec/step, loss=0.08777, avg_loss=0.09004, mel_loss=0.03866, linear_loss=0.04911]
[2020-05-12 03:21:49.470]  Step 151637  [3.226 sec/step, loss=0.09710, avg_loss=0.09008, mel_loss=0.04370, linear_loss=0.05340]
[2020-05-12 03:21:54.385]  Step 151638  [3.246 sec/step, loss=0.09818, avg_loss=0.09013, mel_loss=0.04480, linear_loss=0.05338]
[2020-05-12 03:21:55.352]  Step 151639  [3.247 sec/step, loss=0.08255, avg_loss=0.09012, mel_loss=0.03585, linear_loss=0.04670]
[2020-05-12 03:21:56.657]  Step 151640  [3.241 sec/step, loss=0.08586, avg_loss=0.09007, mel_loss=0.03755, linear_loss=0.04831]
[2020-05-12 03:22:05.506]  Step 151641  [3.312 sec/step, loss=0.09906, avg_loss=0.09017, mel_loss=0.04605, linear_loss=0.05301]
[2020-05-12 03:22:09.247]  Step 151642  [3.332 sec/step, loss=0.09745, avg_loss=0.09026, mel_loss=0.04376, linear_loss=0.05369]
[2020-05-12 03:22:11.260]  Step 151643  [3.279 sec/step, loss=0.08917, avg_loss=0.09016, mel_loss=0.03954, linear_loss=0.04963]
[2020-05-12 03:22:11.817]  Step 151644  [3.264 sec/step, loss=0.07068, avg_loss=0.08995, mel_loss=0.03079, linear_loss=0.03988]
[2020-05-12 03:22:14.813]  Step 151645  [3.259 sec/step, loss=0.09605, avg_loss=0.08997, mel_loss=0.04307, linear_loss=0.05298]
[2020-05-12 03:22:17.673]  Step 151646  [3.238 sec/step, loss=0.09445, avg_loss=0.08995, mel_loss=0.04219, linear_loss=0.05226]
[2020-05-12 03:22:19.544]  Step 151647  [3.249 sec/step, loss=0.08981, avg_loss=0.09007, mel_loss=0.03927, linear_loss=0.05053]
[2020-05-12 03:22:21.666]  Step 151648  [3.236 sec/step, loss=0.09244, avg_loss=0.09001, mel_loss=0.04110, linear_loss=0.05133]
[2020-05-12 03:22:23.887]  Step 151649  [3.228 sec/step, loss=0.09257, avg_loss=0.08997, mel_loss=0.04110, linear_loss=0.05147]
[2020-05-12 03:22:26.422]  Step 151650  [3.233 sec/step, loss=0.09471, avg_loss=0.09000, mel_loss=0.04224, linear_loss=0.05247]
[2020-05-12 03:22:26.422]  Writing summary at step: 151650
[2020-05-12 03:22:27.755]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151650
[2020-05-12 03:22:29.185]  Saving audio and alignment...
[2020-05-12 03:22:31.331]  Generated 32 batches of size 32 in 1.628 sec
[2020-05-12 03:22:35.927]  Input: 학교에 간 은주씨 올라갔다 내려갔다가 기본적으로 섞여야 되겠습니다~_____________________
[2020-05-12 03:22:37.656]  Step 151651  [3.229 sec/step, loss=0.08930, avg_loss=0.08997, mel_loss=0.03896, linear_loss=0.05035]
[2020-05-12 03:22:41.071]  Step 151652  [3.121 sec/step, loss=0.09499, avg_loss=0.09015, mel_loss=0.04272, linear_loss=0.05228]
[2020-05-12 03:22:45.237]  Step 151653  [3.147 sec/step, loss=0.09699, avg_loss=0.09024, mel_loss=0.04384, linear_loss=0.05315]
[2020-05-12 03:22:52.641]  Step 151654  [3.210 sec/step, loss=0.09737, avg_loss=0.09035, mel_loss=0.04499, linear_loss=0.05239]
[2020-05-12 03:22:53.438]  Step 151655  [3.210 sec/step, loss=0.07719, avg_loss=0.09033, mel_loss=0.03366, linear_loss=0.04353]
[2020-05-12 03:23:06.424]  Step 151656  [3.330 sec/step, loss=0.08402, avg_loss=0.09033, mel_loss=0.03976, linear_loss=0.04427]
[2020-05-12 03:23:07.842]  Step 151657  [3.306 sec/step, loss=0.08790, avg_loss=0.09022, mel_loss=0.03822, linear_loss=0.04968]
[2020-05-12 03:23:10.307]  Step 151658  [3.276 sec/step, loss=0.09245, avg_loss=0.09017, mel_loss=0.04072, linear_loss=0.05173]
[2020-05-12 03:23:14.615]  Step 151659  [3.283 sec/step, loss=0.09560, avg_loss=0.09016, mel_loss=0.04314, linear_loss=0.05246]
[2020-05-12 03:23:17.680]  Step 151660  [3.230 sec/step, loss=0.09491, avg_loss=0.09016, mel_loss=0.04248, linear_loss=0.05243]
[2020-05-12 03:23:26.486]  Step 151661  [3.293 sec/step, loss=0.09504, avg_loss=0.09017, mel_loss=0.04421, linear_loss=0.05083]
[2020-05-12 03:23:27.550]  Step 151662  [3.244 sec/step, loss=0.08310, avg_loss=0.09003, mel_loss=0.03593, linear_loss=0.04717]
[2020-05-12 03:23:31.260]  Step 151663  [3.236 sec/step, loss=0.09437, avg_loss=0.09000, mel_loss=0.04257, linear_loss=0.05180]
[2020-05-12 03:23:33.122]  Step 151664  [3.212 sec/step, loss=0.09003, avg_loss=0.08995, mel_loss=0.03984, linear_loss=0.05020]
[2020-05-12 03:23:47.035]  Step 151665  [3.337 sec/step, loss=0.08554, avg_loss=0.08995, mel_loss=0.04267, linear_loss=0.04287]
[2020-05-12 03:23:48.027]  Step 151666  [3.334 sec/step, loss=0.07860, avg_loss=0.08986, mel_loss=0.03366, linear_loss=0.04494]
[2020-05-12 03:23:50.894]  Step 151667  [3.354 sec/step, loss=0.09505, avg_loss=0.09004, mel_loss=0.04257, linear_loss=0.05248]
[2020-05-12 03:23:53.692]  Step 151668  [3.308 sec/step, loss=0.09248, avg_loss=0.08996, mel_loss=0.04123, linear_loss=0.05125]
[2020-05-12 03:23:54.525]  Step 151669  [3.306 sec/step, loss=0.08244, avg_loss=0.08996, mel_loss=0.03542, linear_loss=0.04702]
[2020-05-12 03:23:56.756]  Step 151670  [3.188 sec/step, loss=0.09100, avg_loss=0.09010, mel_loss=0.04065, linear_loss=0.05035]
[2020-05-12 03:23:59.077]  Step 151671  [3.195 sec/step, loss=0.09364, avg_loss=0.09016, mel_loss=0.04145, linear_loss=0.05220]
[2020-05-12 03:24:03.671]  Step 151672  [3.198 sec/step, loss=0.10851, avg_loss=0.09027, mel_loss=0.05136, linear_loss=0.05715]
[2020-05-12 03:24:06.053]  Step 151673  [3.187 sec/step, loss=0.09379, avg_loss=0.09027, mel_loss=0.04174, linear_loss=0.05205]
[2020-05-12 03:24:12.588]  Step 151674  [3.197 sec/step, loss=0.10235, avg_loss=0.09031, mel_loss=0.04832, linear_loss=0.05403]
[2020-05-12 03:24:17.662]  Step 151675  [3.239 sec/step, loss=0.09915, avg_loss=0.09056, mel_loss=0.04553, linear_loss=0.05361]
[2020-05-12 03:24:18.752]  Step 151676  [3.231 sec/step, loss=0.08480, avg_loss=0.09052, mel_loss=0.03662, linear_loss=0.04818]
[2020-05-12 03:24:21.117]  Step 151677  [3.219 sec/step, loss=0.09404, avg_loss=0.09048, mel_loss=0.04222, linear_loss=0.05182]
[2020-05-12 03:24:24.918]  Step 151678  [3.168 sec/step, loss=0.09851, avg_loss=0.09051, mel_loss=0.04480, linear_loss=0.05371]
[2020-05-12 03:24:25.492]  Step 151679  [3.152 sec/step, loss=0.07174, avg_loss=0.09032, mel_loss=0.03162, linear_loss=0.04012]
[2020-05-12 03:24:31.139]  Step 151680  [3.174 sec/step, loss=0.10222, avg_loss=0.09038, mel_loss=0.04699, linear_loss=0.05522]
[2020-05-12 03:24:41.621]  Step 151681  [3.269 sec/step, loss=0.10581, avg_loss=0.09062, mel_loss=0.05033, linear_loss=0.05548]
[2020-05-12 03:24:43.206]  Step 151682  [3.272 sec/step, loss=0.08737, avg_loss=0.09064, mel_loss=0.03830, linear_loss=0.04906]
[2020-05-12 03:24:43.403]  Generated 32 batches of size 32 in 1.776 sec
[2020-05-12 03:24:44.575]  Step 151683  [3.255 sec/step, loss=0.08920, avg_loss=0.09058, mel_loss=0.03920, linear_loss=0.05000]
[2020-05-12 03:24:47.969]  Step 151684  [3.275 sec/step, loss=0.09697, avg_loss=0.09068, mel_loss=0.04376, linear_loss=0.05321]
[2020-05-12 03:24:49.285]  Step 151685  [3.242 sec/step, loss=0.08616, avg_loss=0.09056, mel_loss=0.03771, linear_loss=0.04845]
[2020-05-12 03:24:50.471]  Step 151686  [3.236 sec/step, loss=0.08391, avg_loss=0.09050, mel_loss=0.03713, linear_loss=0.04678]
[2020-05-12 03:24:52.138]  Step 151687  [3.228 sec/step, loss=0.09158, avg_loss=0.09050, mel_loss=0.04028, linear_loss=0.05130]
[2020-05-12 03:24:53.055]  Step 151688  [3.217 sec/step, loss=0.07399, avg_loss=0.09032, mel_loss=0.03225, linear_loss=0.04173]
[2020-05-12 03:24:55.038]  Step 151689  [3.196 sec/step, loss=0.08917, avg_loss=0.09025, mel_loss=0.03922, linear_loss=0.04995]
[2020-05-12 03:25:00.776]  Step 151690  [3.226 sec/step, loss=0.09908, avg_loss=0.09030, mel_loss=0.04564, linear_loss=0.05345]
[2020-05-12 03:25:05.202]  Step 151691  [3.241 sec/step, loss=0.09893, avg_loss=0.09034, mel_loss=0.04567, linear_loss=0.05326]
[2020-05-12 03:25:08.370]  Step 151692  [3.222 sec/step, loss=0.09790, avg_loss=0.09036, mel_loss=0.04418, linear_loss=0.05373]
[2020-05-12 03:25:08.932]  Step 151693  [3.214 sec/step, loss=0.07391, avg_loss=0.09023, mel_loss=0.03320, linear_loss=0.04070]
[2020-05-12 03:25:22.374]  Step 151694  [3.333 sec/step, loss=0.09002, avg_loss=0.09024, mel_loss=0.04407, linear_loss=0.04596]
[2020-05-12 03:25:23.696]  Step 151695  [3.279 sec/step, loss=0.08589, avg_loss=0.09013, mel_loss=0.03797, linear_loss=0.04792]
[2020-05-12 03:25:27.882]  Step 151696  [3.309 sec/step, loss=0.09763, avg_loss=0.09028, mel_loss=0.04398, linear_loss=0.05365]
[2020-05-12 03:25:29.959]  Step 151697  [3.324 sec/step, loss=0.09305, avg_loss=0.09048, mel_loss=0.04137, linear_loss=0.05168]
[2020-05-12 03:25:36.380]  Step 151698  [3.365 sec/step, loss=0.09972, avg_loss=0.09058, mel_loss=0.04631, linear_loss=0.05341]
[2020-05-12 03:25:39.926]  Step 151699  [3.355 sec/step, loss=0.09781, avg_loss=0.09059, mel_loss=0.04430, linear_loss=0.05351]
[2020-05-12 03:25:45.306]  Step 151700  [3.394 sec/step, loss=0.09851, avg_loss=0.09071, mel_loss=0.04522, linear_loss=0.05329]
[2020-05-12 03:25:45.306]  Writing summary at step: 151700
[2020-05-12 03:25:47.523]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151700
[2020-05-12 03:25:49.066]  Saving audio and alignment...
[2020-05-12 03:25:59.199]  Input: 행복을 저축 해야 되는 날이라 생각이들어요 하시기 보다는 멘트의 맛을 살리려면 호흡소리를 섞어 보세요 스읍~__
[2020-05-12 03:26:02.874]  Step 151701  [3.423 sec/step, loss=0.09967, avg_loss=0.09094, mel_loss=0.04523, linear_loss=0.05444]
[2020-05-12 03:26:04.221]  Step 151702  [3.384 sec/step, loss=0.08854, avg_loss=0.09086, mel_loss=0.03882, linear_loss=0.04972]
[2020-05-12 03:26:05.129]  Step 151703  [3.306 sec/step, loss=0.08360, avg_loss=0.09074, mel_loss=0.03618, linear_loss=0.04742]
[2020-05-12 03:26:07.641]  Step 151704  [3.296 sec/step, loss=0.09379, avg_loss=0.09073, mel_loss=0.04190, linear_loss=0.05189]
[2020-05-12 03:26:08.456]  Step 151705  [3.289 sec/step, loss=0.07775, avg_loss=0.09061, mel_loss=0.03375, linear_loss=0.04400]
[2020-05-12 03:26:09.492]  Step 151706  [3.279 sec/step, loss=0.08333, avg_loss=0.09053, mel_loss=0.03679, linear_loss=0.04654]
[2020-05-12 03:26:17.966]  Step 151707  [3.338 sec/step, loss=0.09793, avg_loss=0.09057, mel_loss=0.04579, linear_loss=0.05214]
[2020-05-12 03:26:19.100]  Step 151708  [3.279 sec/step, loss=0.08413, avg_loss=0.09043, mel_loss=0.03608, linear_loss=0.04804]
[2020-05-12 03:26:21.800]  Step 151709  [3.294 sec/step, loss=0.09433, avg_loss=0.09055, mel_loss=0.04232, linear_loss=0.05201]
[2020-05-12 03:26:25.321]  Step 151710  [3.295 sec/step, loss=0.09506, avg_loss=0.09054, mel_loss=0.04287, linear_loss=0.05218]
[2020-05-12 03:26:30.157]  Step 151711  [3.288 sec/step, loss=0.09800, avg_loss=0.09054, mel_loss=0.04449, linear_loss=0.05351]
[2020-05-12 03:26:31.927]  Step 151712  [3.289 sec/step, loss=0.08949, avg_loss=0.09054, mel_loss=0.03972, linear_loss=0.04977]
[2020-05-12 03:26:31.952]  Generated 32 batches of size 32 in 1.789 sec
[2020-05-12 03:26:37.633]  Step 151713  [3.340 sec/step, loss=0.09957, avg_loss=0.09085, mel_loss=0.04559, linear_loss=0.05397]
[2020-05-12 03:26:40.496]  Step 151714  [3.303 sec/step, loss=0.09365, avg_loss=0.09081, mel_loss=0.04202, linear_loss=0.05163]
[2020-05-12 03:26:43.569]  Step 151715  [3.325 sec/step, loss=0.09857, avg_loss=0.09102, mel_loss=0.04437, linear_loss=0.05420]
[2020-05-12 03:26:45.381]  Step 151716  [3.326 sec/step, loss=0.09164, avg_loss=0.09105, mel_loss=0.04027, linear_loss=0.05137]
[2020-05-12 03:26:46.853]  Step 151717  [3.304 sec/step, loss=0.08914, avg_loss=0.09098, mel_loss=0.03925, linear_loss=0.04989]
[2020-05-12 03:26:47.611]  Step 151718  [3.297 sec/step, loss=0.07935, avg_loss=0.09090, mel_loss=0.03445, linear_loss=0.04490]
[2020-05-12 03:26:49.614]  Step 151719  [3.309 sec/step, loss=0.09094, avg_loss=0.09107, mel_loss=0.04044, linear_loss=0.05050]
[2020-05-12 03:26:51.373]  Step 151720  [3.205 sec/step, loss=0.08875, avg_loss=0.09108, mel_loss=0.03892, linear_loss=0.04982]
[2020-05-12 03:26:52.368]  Step 151721  [3.191 sec/step, loss=0.08338, avg_loss=0.09099, mel_loss=0.03588, linear_loss=0.04750]
[2020-05-12 03:26:54.628]  Step 151722  [3.202 sec/step, loss=0.09150, avg_loss=0.09106, mel_loss=0.04069, linear_loss=0.05081]
[2020-05-12 03:26:56.625]  Step 151723  [3.194 sec/step, loss=0.09124, avg_loss=0.09106, mel_loss=0.04039, linear_loss=0.05085]
[2020-05-12 03:26:59.037]  Step 151724  [3.199 sec/step, loss=0.09169, avg_loss=0.09110, mel_loss=0.04073, linear_loss=0.05096]
[2020-05-12 03:27:01.674]  Step 151725  [3.191 sec/step, loss=0.09056, avg_loss=0.09103, mel_loss=0.04048, linear_loss=0.05008]
[2020-05-12 03:27:03.132]  Step 151726  [3.196 sec/step, loss=0.08868, avg_loss=0.09113, mel_loss=0.03867, linear_loss=0.05001]
[2020-05-12 03:27:08.841]  Step 151727  [3.231 sec/step, loss=0.09803, avg_loss=0.09120, mel_loss=0.04515, linear_loss=0.05288]
[2020-05-12 03:27:13.926]  Step 151728  [3.253 sec/step, loss=0.09763, avg_loss=0.09123, mel_loss=0.04469, linear_loss=0.05294]
[2020-05-12 03:27:15.041]  Step 151729  [3.201 sec/step, loss=0.08665, avg_loss=0.09111, mel_loss=0.03754, linear_loss=0.04910]
[2020-05-12 03:27:18.360]  Step 151730  [3.226 sec/step, loss=0.09597, avg_loss=0.09130, mel_loss=0.04305, linear_loss=0.05292]
[2020-05-12 03:27:21.314]  Step 151731  [3.245 sec/step, loss=0.09434, avg_loss=0.09139, mel_loss=0.04207, linear_loss=0.05227]
[2020-05-12 03:27:23.102]  Step 151732  [3.231 sec/step, loss=0.09053, avg_loss=0.09135, mel_loss=0.03997, linear_loss=0.05056]
[2020-05-12 03:27:27.416]  Step 151733  [3.263 sec/step, loss=0.09625, avg_loss=0.09147, mel_loss=0.04359, linear_loss=0.05265]
[2020-05-12 03:27:36.202]  Step 151734  [3.341 sec/step, loss=0.09842, avg_loss=0.09161, mel_loss=0.04576, linear_loss=0.05265]
[2020-05-12 03:27:37.295]  Step 151735  [3.296 sec/step, loss=0.08101, avg_loss=0.09145, mel_loss=0.03558, linear_loss=0.04543]
[2020-05-12 03:27:40.940]  Step 151736  [3.316 sec/step, loss=0.09732, avg_loss=0.09154, mel_loss=0.04391, linear_loss=0.05341]
[2020-05-12 03:27:48.507]  Step 151737  [3.356 sec/step, loss=0.09885, avg_loss=0.09156, mel_loss=0.04572, linear_loss=0.05313]
[2020-05-12 03:27:50.643]  Step 151738  [3.328 sec/step, loss=0.09272, avg_loss=0.09151, mel_loss=0.04083, linear_loss=0.05189]
[2020-05-12 03:27:51.528]  Step 151739  [3.328 sec/step, loss=0.07236, avg_loss=0.09140, mel_loss=0.03141, linear_loss=0.04095]
[2020-05-12 03:27:58.321]  Step 151740  [3.382 sec/step, loss=0.09716, avg_loss=0.09152, mel_loss=0.04489, linear_loss=0.05227]
[2020-05-12 03:27:59.750]  Step 151741  [3.308 sec/step, loss=0.08583, avg_loss=0.09138, mel_loss=0.03741, linear_loss=0.04842]
[2020-05-12 03:28:04.435]  Step 151742  [3.318 sec/step, loss=0.09628, avg_loss=0.09137, mel_loss=0.04370, linear_loss=0.05258]
[2020-05-12 03:28:07.534]  Step 151743  [3.328 sec/step, loss=0.09498, avg_loss=0.09143, mel_loss=0.04254, linear_loss=0.05244]
[2020-05-12 03:28:09.230]  Generated 32 batches of size 32 in 1.691 sec
[2020-05-12 03:28:09.244]  Step 151744  [3.340 sec/step, loss=0.08942, avg_loss=0.09162, mel_loss=0.03936, linear_loss=0.05007]
[2020-05-12 03:28:12.718]  Step 151745  [3.345 sec/step, loss=0.09572, avg_loss=0.09161, mel_loss=0.04298, linear_loss=0.05274]
[2020-05-12 03:28:14.610]  Step 151746  [3.335 sec/step, loss=0.08846, avg_loss=0.09155, mel_loss=0.03882, linear_loss=0.04964]
[2020-05-12 03:28:15.775]  Step 151747  [3.328 sec/step, loss=0.08696, avg_loss=0.09153, mel_loss=0.03811, linear_loss=0.04885]
[2020-05-12 03:28:16.576]  Step 151748  [3.315 sec/step, loss=0.07831, avg_loss=0.09138, mel_loss=0.03379, linear_loss=0.04452]
[2020-05-12 03:28:17.132]  Step 151749  [3.298 sec/step, loss=0.06861, avg_loss=0.09115, mel_loss=0.03028, linear_loss=0.03833]
[2020-05-12 03:28:29.537]  Step 151750  [3.397 sec/step, loss=0.08920, avg_loss=0.09109, mel_loss=0.04249, linear_loss=0.04671]
[2020-05-12 03:28:29.537]  Writing summary at step: 151750
[2020-05-12 03:28:33.410]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151750
[2020-05-12 03:28:34.924]  Saving audio and alignment...
[2020-05-12 03:28:37.487]  Input: 존경하는 사람이 누구예요~______
[2020-05-12 03:28:44.123]  Step 151751  [3.446 sec/step, loss=0.09933, avg_loss=0.09119, mel_loss=0.04555, linear_loss=0.05378]
[2020-05-12 03:28:45.261]  Step 151752  [3.423 sec/step, loss=0.08485, avg_loss=0.09109, mel_loss=0.03655, linear_loss=0.04830]
[2020-05-12 03:28:46.327]  Step 151753  [3.392 sec/step, loss=0.08347, avg_loss=0.09095, mel_loss=0.03606, linear_loss=0.04741]
[2020-05-12 03:28:49.730]  Step 151754  [3.352 sec/step, loss=0.09416, avg_loss=0.09092, mel_loss=0.04251, linear_loss=0.05164]
[2020-05-12 03:28:52.616]  Step 151755  [3.373 sec/step, loss=0.09455, avg_loss=0.09110, mel_loss=0.04213, linear_loss=0.05242]
[2020-05-12 03:28:57.834]  Step 151756  [3.295 sec/step, loss=0.09743, avg_loss=0.09123, mel_loss=0.04444, linear_loss=0.05299]
[2020-05-12 03:28:59.737]  Step 151757  [3.300 sec/step, loss=0.08924, avg_loss=0.09124, mel_loss=0.03901, linear_loss=0.05023]
[2020-05-12 03:29:08.918]  Step 151758  [3.367 sec/step, loss=0.09607, avg_loss=0.09128, mel_loss=0.04469, linear_loss=0.05138]
[2020-05-12 03:29:13.801]  Step 151759  [3.373 sec/step, loss=0.09910, avg_loss=0.09131, mel_loss=0.04494, linear_loss=0.05416]
[2020-05-12 03:29:14.773]  Step 151760  [3.352 sec/step, loss=0.08205, avg_loss=0.09119, mel_loss=0.03553, linear_loss=0.04653]
[2020-05-12 03:29:15.582]  Step 151761  [3.272 sec/step, loss=0.07830, avg_loss=0.09102, mel_loss=0.03366, linear_loss=0.04464]
[2020-05-12 03:29:18.080]  Step 151762  [3.287 sec/step, loss=0.09124, avg_loss=0.09110, mel_loss=0.04048, linear_loss=0.05076]
[2020-05-12 03:29:22.463]  Step 151763  [3.293 sec/step, loss=0.09942, avg_loss=0.09115, mel_loss=0.04553, linear_loss=0.05389]
[2020-05-12 03:29:23.315]  Step 151764  [3.283 sec/step, loss=0.08302, avg_loss=0.09108, mel_loss=0.03560, linear_loss=0.04741]
[2020-05-12 03:29:30.844]  Step 151765  [3.219 sec/step, loss=0.09914, avg_loss=0.09122, mel_loss=0.04602, linear_loss=0.05312]
[2020-05-12 03:29:31.659]  Step 151766  [3.218 sec/step, loss=0.07357, avg_loss=0.09117, mel_loss=0.03221, linear_loss=0.04135]
[2020-05-12 03:29:32.233]  Step 151767  [3.195 sec/step, loss=0.07514, avg_loss=0.09097, mel_loss=0.03323, linear_loss=0.04191]
[2020-05-12 03:29:34.989]  Step 151768  [3.194 sec/step, loss=0.09451, avg_loss=0.09099, mel_loss=0.04211, linear_loss=0.05239]
[2020-05-12 03:29:38.412]  Step 151769  [3.220 sec/step, loss=0.09655, avg_loss=0.09113, mel_loss=0.04342, linear_loss=0.05313]
[2020-05-12 03:29:40.487]  Step 151770  [3.219 sec/step, loss=0.09297, avg_loss=0.09115, mel_loss=0.04131, linear_loss=0.05167]
[2020-05-12 03:29:41.887]  Step 151771  [3.209 sec/step, loss=0.08796, avg_loss=0.09109, mel_loss=0.03878, linear_loss=0.04918]
[2020-05-12 03:29:45.591]  Step 151772  [3.201 sec/step, loss=0.09798, avg_loss=0.09099, mel_loss=0.04424, linear_loss=0.05374]
[2020-05-12 03:29:51.056]  Step 151773  [3.231 sec/step, loss=0.09737, avg_loss=0.09102, mel_loss=0.04445, linear_loss=0.05292]
[2020-05-12 03:29:52.765]  Generated 32 batches of size 32 in 1.703 sec
[2020-05-12 03:29:52.916]  Step 151774  [3.185 sec/step, loss=0.08989, avg_loss=0.09090, mel_loss=0.03896, linear_loss=0.05093]
[2020-05-12 03:30:07.690]  Step 151775  [3.282 sec/step, loss=0.07665, avg_loss=0.09067, mel_loss=0.03654, linear_loss=0.04011]
[2020-05-12 03:30:09.045]  Step 151776  [3.284 sec/step, loss=0.08459, avg_loss=0.09067, mel_loss=0.03690, linear_loss=0.04769]
[2020-05-12 03:30:11.413]  Step 151777  [3.284 sec/step, loss=0.09240, avg_loss=0.09065, mel_loss=0.04106, linear_loss=0.05134]
[2020-05-12 03:30:13.051]  Step 151778  [3.263 sec/step, loss=0.08821, avg_loss=0.09055, mel_loss=0.03907, linear_loss=0.04913]
[2020-05-12 03:30:15.036]  Step 151779  [3.277 sec/step, loss=0.09186, avg_loss=0.09075, mel_loss=0.04062, linear_loss=0.05124]
[2020-05-12 03:30:18.040]  Step 151780  [3.250 sec/step, loss=0.09661, avg_loss=0.09070, mel_loss=0.04361, linear_loss=0.05300]
[2020-05-12 03:30:22.204]  Step 151781  [3.187 sec/step, loss=0.09550, avg_loss=0.09059, mel_loss=0.04308, linear_loss=0.05242]
[2020-05-12 03:30:23.876]  Step 151782  [3.188 sec/step, loss=0.09046, avg_loss=0.09062, mel_loss=0.03960, linear_loss=0.05086]
[2020-05-12 03:30:32.668]  Step 151783  [3.262 sec/step, loss=0.09641, avg_loss=0.09069, mel_loss=0.04490, linear_loss=0.05151]
[2020-05-12 03:30:33.842]  Step 151784  [3.240 sec/step, loss=0.08222, avg_loss=0.09055, mel_loss=0.03561, linear_loss=0.04661]
[2020-05-12 03:30:35.785]  Step 151785  [3.246 sec/step, loss=0.09066, avg_loss=0.09059, mel_loss=0.03977, linear_loss=0.05089]
[2020-05-12 03:30:37.590]  Step 151786  [3.253 sec/step, loss=0.08910, avg_loss=0.09064, mel_loss=0.03894, linear_loss=0.05017]
[2020-05-12 03:30:39.296]  Step 151787  [3.253 sec/step, loss=0.08899, avg_loss=0.09062, mel_loss=0.03918, linear_loss=0.04982]
[2020-05-12 03:30:42.407]  Step 151788  [3.275 sec/step, loss=0.09566, avg_loss=0.09084, mel_loss=0.04273, linear_loss=0.05294]
[2020-05-12 03:30:45.322]  Step 151789  [3.284 sec/step, loss=0.09475, avg_loss=0.09089, mel_loss=0.04249, linear_loss=0.05226]
[2020-05-12 03:30:50.441]  Step 151790  [3.278 sec/step, loss=0.09925, avg_loss=0.09089, mel_loss=0.04524, linear_loss=0.05401]
[2020-05-12 03:30:53.198]  Step 151791  [3.261 sec/step, loss=0.09271, avg_loss=0.09083, mel_loss=0.04152, linear_loss=0.05119]
[2020-05-12 03:30:59.551]  Step 151792  [3.293 sec/step, loss=0.09680, avg_loss=0.09082, mel_loss=0.04447, linear_loss=0.05233]
[2020-05-12 03:31:01.913]  Step 151793  [3.311 sec/step, loss=0.09418, avg_loss=0.09102, mel_loss=0.04195, linear_loss=0.05223]
[2020-05-12 03:31:05.330]  Step 151794  [3.211 sec/step, loss=0.09657, avg_loss=0.09109, mel_loss=0.04338, linear_loss=0.05319]
[2020-05-12 03:31:05.979]  Step 151795  [3.204 sec/step, loss=0.07655, avg_loss=0.09099, mel_loss=0.03368, linear_loss=0.04287]
[2020-05-12 03:31:10.689]  Step 151796  [3.209 sec/step, loss=0.09922, avg_loss=0.09101, mel_loss=0.04504, linear_loss=0.05419]
[2020-05-12 03:31:14.605]  Step 151797  [3.228 sec/step, loss=0.09683, avg_loss=0.09105, mel_loss=0.04359, linear_loss=0.05324]
[2020-05-12 03:31:15.358]  Step 151798  [3.171 sec/step, loss=0.07858, avg_loss=0.09084, mel_loss=0.03379, linear_loss=0.04478]
[2020-05-12 03:31:15.929]  Step 151799  [3.141 sec/step, loss=0.07024, avg_loss=0.09056, mel_loss=0.03118, linear_loss=0.03906]
[2020-05-12 03:31:16.951]  Step 151800  [3.098 sec/step, loss=0.07836, avg_loss=0.09036, mel_loss=0.03395, linear_loss=0.04441]
[2020-05-12 03:31:16.951]  Writing summary at step: 151800
[2020-05-12 03:31:17.968]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151800
[2020-05-12 03:31:19.452]  Saving audio and alignment...
[2020-05-12 03:31:23.160]  Input: 래서 총장님을 딱 소개해드린 후에~_____________
[2020-05-12 03:31:25.601]  Step 151801  [3.085 sec/step, loss=0.09434, avg_loss=0.09031, mel_loss=0.04203, linear_loss=0.05231]
[2020-05-12 03:31:31.304]  Step 151802  [3.129 sec/step, loss=0.10361, avg_loss=0.09046, mel_loss=0.04856, linear_loss=0.05505]
[2020-05-12 03:31:34.795]  Step 151803  [3.155 sec/step, loss=0.09740, avg_loss=0.09059, mel_loss=0.04430, linear_loss=0.05310]
[2020-05-12 03:31:36.491]  Step 151804  [3.147 sec/step, loss=0.09139, avg_loss=0.09057, mel_loss=0.04028, linear_loss=0.05111]
[2020-05-12 03:31:36.624]  Generated 32 batches of size 32 in 1.823 sec
[2020-05-12 03:31:38.560]  Step 151805  [3.159 sec/step, loss=0.09397, avg_loss=0.09073, mel_loss=0.04184, linear_loss=0.05213]
[2020-05-12 03:31:45.696]  Step 151806  [3.220 sec/step, loss=0.10253, avg_loss=0.09093, mel_loss=0.04815, linear_loss=0.05438]
[2020-05-12 03:31:58.714]  Step 151807  [3.266 sec/step, loss=0.08917, avg_loss=0.09084, mel_loss=0.04315, linear_loss=0.04603]
[2020-05-12 03:31:59.705]  Step 151808  [3.264 sec/step, loss=0.08534, avg_loss=0.09085, mel_loss=0.03747, linear_loss=0.04787]
[2020-05-12 03:32:03.469]  Step 151809  [3.275 sec/step, loss=0.10121, avg_loss=0.09092, mel_loss=0.04638, linear_loss=0.05483]
[2020-05-12 03:32:07.664]  Step 151810  [3.282 sec/step, loss=0.10471, avg_loss=0.09101, mel_loss=0.04902, linear_loss=0.05570]
[2020-05-12 03:32:09.043]  Step 151811  [3.247 sec/step, loss=0.09120, avg_loss=0.09095, mel_loss=0.04076, linear_loss=0.05044]
[2020-05-12 03:32:10.335]  Step 151812  [3.242 sec/step, loss=0.08748, avg_loss=0.09093, mel_loss=0.03891, linear_loss=0.04857]
[2020-05-12 03:32:12.912]  Step 151813  [3.211 sec/step, loss=0.09450, avg_loss=0.09088, mel_loss=0.04253, linear_loss=0.05197]
[2020-05-12 03:32:14.695]  Step 151814  [3.200 sec/step, loss=0.09337, avg_loss=0.09087, mel_loss=0.04145, linear_loss=0.05192]
[2020-05-12 03:32:16.800]  Step 151815  [3.190 sec/step, loss=0.09712, avg_loss=0.09086, mel_loss=0.04401, linear_loss=0.05311]
[2020-05-12 03:32:17.861]  Step 151816  [3.183 sec/step, loss=0.08520, avg_loss=0.09079, mel_loss=0.03779, linear_loss=0.04740]
[2020-05-12 03:32:21.537]  Step 151817  [3.205 sec/step, loss=0.11149, avg_loss=0.09102, mel_loss=0.05347, linear_loss=0.05802]
[2020-05-12 03:32:28.776]  Step 151818  [3.270 sec/step, loss=0.11788, avg_loss=0.09140, mel_loss=0.05862, linear_loss=0.05926]
[2020-05-12 03:32:30.525]  Step 151819  [3.267 sec/step, loss=0.09328, avg_loss=0.09143, mel_loss=0.04169, linear_loss=0.05159]
[2020-05-12 03:32:32.955]  Step 151820  [3.274 sec/step, loss=0.09904, avg_loss=0.09153, mel_loss=0.04510, linear_loss=0.05394]
[2020-05-12 03:32:39.440]  Step 151821  [3.329 sec/step, loss=0.10303, avg_loss=0.09173, mel_loss=0.04848, linear_loss=0.05455]
[2020-05-12 03:32:41.939]  Step 151822  [3.331 sec/step, loss=0.09436, avg_loss=0.09175, mel_loss=0.04260, linear_loss=0.05176]
[2020-05-12 03:32:43.072]  Step 151823  [3.323 sec/step, loss=0.09153, avg_loss=0.09176, mel_loss=0.03992, linear_loss=0.05161]
[2020-05-12 03:32:48.071]  Step 151824  [3.348 sec/step, loss=0.10567, avg_loss=0.09190, mel_loss=0.04990, linear_loss=0.05576]
[2020-05-12 03:32:48.872]  Step 151825  [3.330 sec/step, loss=0.07700, avg_loss=0.09176, mel_loss=0.03405, linear_loss=0.04295]
[2020-05-12 03:32:51.977]  Step 151826  [3.347 sec/step, loss=0.10506, avg_loss=0.09193, mel_loss=0.04841, linear_loss=0.05665]
[2020-05-12 03:33:00.886]  Step 151827  [3.379 sec/step, loss=0.10315, avg_loss=0.09198, mel_loss=0.04906, linear_loss=0.05408]
[2020-05-12 03:33:02.451]  Step 151828  [3.343 sec/step, loss=0.09042, avg_loss=0.09190, mel_loss=0.04040, linear_loss=0.05001]
[2020-05-12 03:33:03.212]  Step 151829  [3.340 sec/step, loss=0.07729, avg_loss=0.09181, mel_loss=0.03536, linear_loss=0.04193]
[2020-05-12 03:33:04.483]  Step 151830  [3.319 sec/step, loss=0.08769, avg_loss=0.09173, mel_loss=0.03903, linear_loss=0.04866]
[2020-05-12 03:33:09.100]  Step 151831  [3.336 sec/step, loss=0.10136, avg_loss=0.09180, mel_loss=0.04698, linear_loss=0.05438]
[2020-05-12 03:33:11.074]  Step 151832  [3.338 sec/step, loss=0.09283, avg_loss=0.09182, mel_loss=0.04177, linear_loss=0.05106]
[2020-05-12 03:33:14.585]  Step 151833  [3.330 sec/step, loss=0.10035, avg_loss=0.09186, mel_loss=0.04612, linear_loss=0.05424]
[2020-05-12 03:33:20.227]  Step 151834  [3.298 sec/step, loss=0.10214, avg_loss=0.09190, mel_loss=0.04777, linear_loss=0.05437]
[2020-05-12 03:33:23.679]  Step 151835  [3.322 sec/step, loss=0.09891, avg_loss=0.09208, mel_loss=0.04480, linear_loss=0.05411]
[2020-05-12 03:33:25.383]  Generated 32 batches of size 32 in 1.698 sec
[2020-05-12 03:33:36.289]  Step 151836  [3.412 sec/step, loss=0.09386, avg_loss=0.09204, mel_loss=0.04602, linear_loss=0.04784]
[2020-05-12 03:33:39.223]  Step 151837  [3.365 sec/step, loss=0.09878, avg_loss=0.09204, mel_loss=0.04485, linear_loss=0.05394]
[2020-05-12 03:33:40.042]  Step 151838  [3.352 sec/step, loss=0.08010, avg_loss=0.09192, mel_loss=0.03475, linear_loss=0.04535]
[2020-05-12 03:33:41.447]  Step 151839  [3.357 sec/step, loss=0.08880, avg_loss=0.09208, mel_loss=0.03977, linear_loss=0.04903]
[2020-05-12 03:33:42.339]  Step 151840  [3.298 sec/step, loss=0.08496, avg_loss=0.09196, mel_loss=0.03684, linear_loss=0.04812]
[2020-05-12 03:33:44.360]  Step 151841  [3.304 sec/step, loss=0.09403, avg_loss=0.09204, mel_loss=0.04212, linear_loss=0.05191]
[2020-05-12 03:33:48.446]  Step 151842  [3.298 sec/step, loss=0.10249, avg_loss=0.09210, mel_loss=0.04714, linear_loss=0.05535]
[2020-05-12 03:33:52.722]  Step 151843  [3.310 sec/step, loss=0.09931, avg_loss=0.09215, mel_loss=0.04542, linear_loss=0.05390]
[2020-05-12 03:33:54.119]  Step 151844  [3.307 sec/step, loss=0.09075, avg_loss=0.09216, mel_loss=0.04028, linear_loss=0.05047]
[2020-05-12 03:33:59.690]  Step 151845  [3.328 sec/step, loss=0.10217, avg_loss=0.09222, mel_loss=0.04727, linear_loss=0.05491]
[2020-05-12 03:34:00.501]  Step 151846  [3.317 sec/step, loss=0.07916, avg_loss=0.09213, mel_loss=0.03444, linear_loss=0.04471]
[2020-05-12 03:34:01.328]  Step 151847  [3.314 sec/step, loss=0.07767, avg_loss=0.09204, mel_loss=0.03377, linear_loss=0.04390]
[2020-05-12 03:34:02.705]  Step 151848  [3.319 sec/step, loss=0.08758, avg_loss=0.09213, mel_loss=0.03879, linear_loss=0.04878]
[2020-05-12 03:34:06.807]  Step 151849  [3.355 sec/step, loss=0.10023, avg_loss=0.09245, mel_loss=0.04607, linear_loss=0.05416]
[2020-05-12 03:34:14.098]  Step 151850  [3.304 sec/step, loss=0.10497, avg_loss=0.09261, mel_loss=0.04959, linear_loss=0.05539]
[2020-05-12 03:34:14.098]  Writing summary at step: 151850
[2020-05-12 03:34:15.605]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151850
[2020-05-12 03:34:17.091]  Saving audio and alignment...
[2020-05-12 03:34:21.547]  Input: 수많은  상처를 안고 살아가는 거리에 여자지만~____________
[2020-05-12 03:34:24.106]  Step 151851  [3.263 sec/step, loss=0.09414, avg_loss=0.09255, mel_loss=0.04210, linear_loss=0.05204]
[2020-05-12 03:34:28.996]  Step 151852  [3.301 sec/step, loss=0.09904, avg_loss=0.09270, mel_loss=0.04571, linear_loss=0.05333]
[2020-05-12 03:34:37.108]  Step 151853  [3.371 sec/step, loss=0.09853, avg_loss=0.09285, mel_loss=0.04626, linear_loss=0.05227]
[2020-05-12 03:34:41.848]  Step 151854  [3.384 sec/step, loss=0.09875, avg_loss=0.09289, mel_loss=0.04469, linear_loss=0.05406]
[2020-05-12 03:34:42.740]  Step 151855  [3.364 sec/step, loss=0.07363, avg_loss=0.09268, mel_loss=0.03270, linear_loss=0.04093]
[2020-05-12 03:34:44.686]  Step 151856  [3.332 sec/step, loss=0.08441, avg_loss=0.09255, mel_loss=0.03724, linear_loss=0.04718]
[2020-05-12 03:35:01.738]  Step 151857  [3.483 sec/step, loss=0.07551, avg_loss=0.09242, mel_loss=0.03626, linear_loss=0.03925]
[2020-05-12 03:35:05.265]  Step 151858  [3.427 sec/step, loss=0.09607, avg_loss=0.09242, mel_loss=0.04354, linear_loss=0.05253]
[2020-05-12 03:35:07.197]  Step 151859  [3.397 sec/step, loss=0.09137, avg_loss=0.09234, mel_loss=0.04035, linear_loss=0.05102]
[2020-05-12 03:35:09.219]  Step 151860  [3.408 sec/step, loss=0.09248, avg_loss=0.09244, mel_loss=0.04111, linear_loss=0.05138]
[2020-05-12 03:35:13.875]  Step 151861  [3.446 sec/step, loss=0.10047, avg_loss=0.09266, mel_loss=0.04609, linear_loss=0.05437]
[2020-05-12 03:35:14.861]  Step 151862  [3.431 sec/step, loss=0.08141, avg_loss=0.09257, mel_loss=0.03549, linear_loss=0.04592]
[2020-05-12 03:35:16.429]  Step 151863  [3.403 sec/step, loss=0.09053, avg_loss=0.09248, mel_loss=0.04029, linear_loss=0.05024]
[2020-05-12 03:35:19.551]  Step 151864  [3.426 sec/step, loss=0.09624, avg_loss=0.09261, mel_loss=0.04329, linear_loss=0.05295]
[2020-05-12 03:35:21.143]  Step 151865  [3.366 sec/step, loss=0.09186, avg_loss=0.09254, mel_loss=0.04078, linear_loss=0.05108]
[2020-05-12 03:35:23.419]  Step 151866  [3.381 sec/step, loss=0.09453, avg_loss=0.09275, mel_loss=0.04270, linear_loss=0.05183]
[2020-05-12 03:35:26.634]  Step 151867  [3.407 sec/step, loss=0.09652, avg_loss=0.09296, mel_loss=0.04348, linear_loss=0.05305]
[2020-05-12 03:35:28.785]  Step 151868  [3.401 sec/step, loss=0.09265, avg_loss=0.09294, mel_loss=0.04131, linear_loss=0.05134]
[2020-05-12 03:35:34.838]  Step 151869  [3.427 sec/step, loss=0.09918, avg_loss=0.09297, mel_loss=0.04611, linear_loss=0.05307]
[2020-05-12 03:35:37.650]  Step 151870  [3.435 sec/step, loss=0.09452, avg_loss=0.09298, mel_loss=0.04286, linear_loss=0.05167]
[2020-05-12 03:35:41.269]  Step 151871  [3.457 sec/step, loss=0.09882, avg_loss=0.09309, mel_loss=0.04499, linear_loss=0.05382]
[2020-05-12 03:35:42.345]  Step 151872  [3.431 sec/step, loss=0.08641, avg_loss=0.09298, mel_loss=0.03767, linear_loss=0.04874]
[2020-05-12 03:35:43.343]  Step 151873  [3.386 sec/step, loss=0.08479, avg_loss=0.09285, mel_loss=0.03715, linear_loss=0.04765]
[2020-05-12 03:35:45.052]  Step 151874  [3.385 sec/step, loss=0.09101, avg_loss=0.09286, mel_loss=0.03995, linear_loss=0.05106]
[2020-05-12 03:36:45.421]  Generated 32 batches of size 32 in 84.273 sec
[2020-05-12 03:36:47.632]  Step 151875  [3.863 sec/step, loss=0.09226, avg_loss=0.09302, mel_loss=0.04122, linear_loss=0.05104]
[2020-05-12 03:36:52.819]  Step 151876  [3.901 sec/step, loss=0.09650, avg_loss=0.09314, mel_loss=0.04416, linear_loss=0.05234]
[2020-05-12 03:36:55.608]  Step 151877  [3.905 sec/step, loss=0.09435, avg_loss=0.09316, mel_loss=0.04244, linear_loss=0.05191]
[2020-05-12 03:36:59.204]  Step 151878  [3.925 sec/step, loss=0.09808, avg_loss=0.09325, mel_loss=0.04441, linear_loss=0.05368]
[2020-05-12 03:37:00.416]  Step 151879  [3.917 sec/step, loss=0.08673, avg_loss=0.09320, mel_loss=0.03784, linear_loss=0.04888]
[2020-05-12 03:37:09.294]  Step 151880  [3.976 sec/step, loss=0.09679, avg_loss=0.09321, mel_loss=0.04504, linear_loss=0.05175]
[2020-05-12 03:37:15.476]  Step 151881  [3.996 sec/step, loss=0.09976, avg_loss=0.09325, mel_loss=0.04601, linear_loss=0.05375]
[2020-05-12 03:37:16.465]  Step 151882  [3.989 sec/step, loss=0.08303, avg_loss=0.09317, mel_loss=0.03573, linear_loss=0.04730]
[2020-05-12 03:37:17.809]  Step 151883  [3.915 sec/step, loss=0.09051, avg_loss=0.09311, mel_loss=0.03977, linear_loss=0.05074]
[2020-05-12 03:37:20.095]  Step 151884  [3.926 sec/step, loss=0.09101, avg_loss=0.09320, mel_loss=0.04051, linear_loss=0.05049]
[2020-05-12 03:37:24.122]  Step 151885  [3.947 sec/step, loss=0.09854, avg_loss=0.09328, mel_loss=0.04441, linear_loss=0.05413]
[2020-05-12 03:37:25.872]  Step 151886  [3.946 sec/step, loss=0.08855, avg_loss=0.09328, mel_loss=0.03887, linear_loss=0.04968]
[2020-05-12 03:37:27.297]  Step 151887  [3.943 sec/step, loss=0.08725, avg_loss=0.09326, mel_loss=0.03850, linear_loss=0.04875]
[2020-05-12 03:37:28.314]  Step 151888  [3.922 sec/step, loss=0.08052, avg_loss=0.09311, mel_loss=0.03521, linear_loss=0.04531]
[2020-05-12 03:37:33.949]  Step 151889  [3.949 sec/step, loss=0.09815, avg_loss=0.09314, mel_loss=0.04515, linear_loss=0.05299]
[2020-05-12 03:37:48.548]  Step 151890  [4.044 sec/step, loss=0.08019, avg_loss=0.09295, mel_loss=0.03828, linear_loss=0.04191]
[2020-05-12 03:37:49.124]  Step 151891  [4.022 sec/step, loss=0.07003, avg_loss=0.09272, mel_loss=0.03065, linear_loss=0.03937]
[2020-05-12 03:37:52.629]  Step 151892  [3.994 sec/step, loss=0.09603, avg_loss=0.09272, mel_loss=0.04349, linear_loss=0.05255]
[2020-05-12 03:37:55.746]  Step 151893  [4.001 sec/step, loss=0.09739, avg_loss=0.09275, mel_loss=0.04389, linear_loss=0.05349]
[2020-05-12 03:37:57.656]  Step 151894  [3.986 sec/step, loss=0.09115, avg_loss=0.09269, mel_loss=0.04017, linear_loss=0.05098]
[2020-05-12 03:38:00.399]  Step 151895  [4.007 sec/step, loss=0.09455, avg_loss=0.09287, mel_loss=0.04249, linear_loss=0.05206]
[2020-05-12 03:38:02.892]  Step 151896  [3.985 sec/step, loss=0.09347, avg_loss=0.09282, mel_loss=0.04162, linear_loss=0.05185]
[2020-05-12 03:38:04.479]  Step 151897  [3.962 sec/step, loss=0.08959, avg_loss=0.09274, mel_loss=0.03923, linear_loss=0.05036]
[2020-05-12 03:38:09.074]  Step 151898  [4.000 sec/step, loss=0.09868, avg_loss=0.09294, mel_loss=0.04478, linear_loss=0.05390]
[2020-05-12 03:38:11.115]  Step 151899  [4.015 sec/step, loss=0.09129, avg_loss=0.09316, mel_loss=0.04059, linear_loss=0.05070]
[2020-05-12 03:38:14.330]  Step 151900  [4.037 sec/step, loss=0.09850, avg_loss=0.09336, mel_loss=0.04431, linear_loss=0.05418]
[2020-05-12 03:38:14.330]  Writing summary at step: 151900
[2020-05-12 03:38:15.151]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151900
[2020-05-12 03:38:16.661]  Saving audio and alignment...
[2020-05-12 03:38:18.239]  Input: 가장~_________________
[2020-05-12 03:38:19.370]  Step 151901  [4.024 sec/step, loss=0.08308, avg_loss=0.09324, mel_loss=0.03618, linear_loss=0.04689]
[2020-05-12 03:38:21.036]  Step 151902  [3.983 sec/step, loss=0.09026, avg_loss=0.09311, mel_loss=0.04006, linear_loss=0.05019]
[2020-05-12 03:38:25.219]  Step 151903  [3.990 sec/step, loss=0.09817, avg_loss=0.09312, mel_loss=0.04474, linear_loss=0.05343]
[2020-05-12 03:38:32.426]  Step 151904  [4.046 sec/step, loss=0.10017, avg_loss=0.09321, mel_loss=0.04665, linear_loss=0.05351]
[2020-05-12 03:39:24.072]  Generated 32 batches of size 32 in 79.587 sec
[2020-05-12 03:39:25.639]  Step 151905  [4.557 sec/step, loss=0.08514, avg_loss=0.09312, mel_loss=0.03740, linear_loss=0.04773]
[2020-05-12 03:39:28.383]  Step 151906  [4.513 sec/step, loss=0.09264, avg_loss=0.09302, mel_loss=0.04107, linear_loss=0.05158]
[2020-05-12 03:39:36.554]  Step 151907  [4.465 sec/step, loss=0.09796, avg_loss=0.09311, mel_loss=0.04547, linear_loss=0.05249]
[2020-05-12 03:39:45.365]  Step 151908  [4.543 sec/step, loss=0.09929, avg_loss=0.09325, mel_loss=0.04629, linear_loss=0.05300]
[2020-05-12 03:39:47.047]  Step 151909  [4.522 sec/step, loss=0.08989, avg_loss=0.09313, mel_loss=0.03960, linear_loss=0.05029]
[2020-05-12 03:39:48.600]  Step 151910  [4.496 sec/step, loss=0.08995, avg_loss=0.09299, mel_loss=0.03962, linear_loss=0.05033]
[2020-05-12 03:39:51.994]  Step 151911  [4.516 sec/step, loss=0.09647, avg_loss=0.09304, mel_loss=0.04346, linear_loss=0.05300]
[2020-05-12 03:39:55.610]  Step 151912  [4.539 sec/step, loss=0.09880, avg_loss=0.09315, mel_loss=0.04462, linear_loss=0.05418]
[2020-05-12 03:40:00.921]  Step 151913  [4.566 sec/step, loss=0.09715, avg_loss=0.09318, mel_loss=0.04444, linear_loss=0.05271]
[2020-05-12 03:40:05.268]  Step 151914  [4.592 sec/step, loss=0.09773, avg_loss=0.09322, mel_loss=0.04469, linear_loss=0.05304]
[2020-05-12 03:40:08.829]  Step 151915  [4.606 sec/step, loss=0.09361, avg_loss=0.09319, mel_loss=0.04205, linear_loss=0.05156]
[2020-05-12 03:40:15.763]  Step 151916  [4.665 sec/step, loss=0.09699, avg_loss=0.09330, mel_loss=0.04479, linear_loss=0.05220]
[2020-05-12 03:40:16.635]  Step 151917  [4.637 sec/step, loss=0.08251, avg_loss=0.09301, mel_loss=0.03576, linear_loss=0.04675]
[2020-05-12 03:40:19.631]  Step 151918  [4.595 sec/step, loss=0.09773, avg_loss=0.09281, mel_loss=0.04412, linear_loss=0.05361]
[2020-05-12 03:40:24.319]  Step 151919  [4.624 sec/step, loss=0.09754, avg_loss=0.09286, mel_loss=0.04446, linear_loss=0.05308]
[2020-05-12 03:40:26.431]  Step 151920  [4.621 sec/step, loss=0.09333, avg_loss=0.09280, mel_loss=0.04148, linear_loss=0.05185]
[2020-05-12 03:40:29.347]  Step 151921  [4.585 sec/step, loss=0.09591, avg_loss=0.09273, mel_loss=0.04280, linear_loss=0.05311]
[2020-05-12 03:40:31.411]  Step 151922  [4.581 sec/step, loss=0.09110, avg_loss=0.09269, mel_loss=0.04027, linear_loss=0.05083]
[2020-05-12 03:40:32.727]  Step 151923  [4.583 sec/step, loss=0.08570, avg_loss=0.09264, mel_loss=0.03758, linear_loss=0.04812]
[2020-05-12 03:40:34.495]  Step 151924  [4.550 sec/step, loss=0.09044, avg_loss=0.09248, mel_loss=0.03958, linear_loss=0.05086]
[2020-05-12 03:40:35.663]  Step 151925  [4.554 sec/step, loss=0.08328, avg_loss=0.09255, mel_loss=0.03615, linear_loss=0.04713]
[2020-05-12 03:40:36.505]  Step 151926  [4.531 sec/step, loss=0.07770, avg_loss=0.09227, mel_loss=0.03386, linear_loss=0.04384]
[2020-05-12 03:40:37.064]  Step 151927  [4.448 sec/step, loss=0.07233, avg_loss=0.09196, mel_loss=0.03242, linear_loss=0.03991]
[2020-05-12 03:40:37.864]  Step 151928  [4.440 sec/step, loss=0.07988, avg_loss=0.09186, mel_loss=0.03442, linear_loss=0.04546]
[2020-05-12 03:40:38.903]  Generated 32 batches of size 32 in 1.833 sec
[2020-05-12 03:40:39.893]  Step 151929  [4.453 sec/step, loss=0.08963, avg_loss=0.09198, mel_loss=0.03951, linear_loss=0.05012]
[2020-05-12 03:40:42.540]  Step 151930  [4.467 sec/step, loss=0.09349, avg_loss=0.09204, mel_loss=0.04188, linear_loss=0.05161]
[2020-05-12 03:40:46.324]  Step 151931  [4.458 sec/step, loss=0.09757, avg_loss=0.09200, mel_loss=0.04422, linear_loss=0.05334]
[2020-05-12 03:40:47.410]  Step 151932  [4.450 sec/step, loss=0.08605, avg_loss=0.09194, mel_loss=0.03700, linear_loss=0.04905]
[2020-05-12 03:40:59.590]  Step 151933  [4.536 sec/step, loss=0.08862, avg_loss=0.09182, mel_loss=0.04222, linear_loss=0.04640]
[2020-05-12 03:41:01.939]  Step 151934  [4.503 sec/step, loss=0.09571, avg_loss=0.09175, mel_loss=0.04286, linear_loss=0.05285]
[2020-05-12 03:41:07.519]  Step 151935  [4.525 sec/step, loss=0.10024, avg_loss=0.09177, mel_loss=0.04628, linear_loss=0.05396]
[2020-05-12 03:41:08.483]  Step 151936  [4.408 sec/step, loss=0.08338, avg_loss=0.09166, mel_loss=0.03623, linear_loss=0.04715]
[2020-05-12 03:41:09.279]  Step 151937  [4.387 sec/step, loss=0.07826, avg_loss=0.09146, mel_loss=0.03363, linear_loss=0.04463]
[2020-05-12 03:41:18.095]  Step 151938  [4.467 sec/step, loss=0.09608, avg_loss=0.09162, mel_loss=0.04470, linear_loss=0.05138]
[2020-05-12 03:41:19.625]  Step 151939  [4.468 sec/step, loss=0.08826, avg_loss=0.09161, mel_loss=0.03844, linear_loss=0.04982]
[2020-05-12 03:41:22.795]  Step 151940  [4.491 sec/step, loss=0.09544, avg_loss=0.09172, mel_loss=0.04275, linear_loss=0.05269]
[2020-05-12 03:41:26.569]  Step 151941  [4.508 sec/step, loss=0.09806, avg_loss=0.09176, mel_loss=0.04402, linear_loss=0.05404]
[2020-05-12 03:41:29.960]  Step 151942  [4.501 sec/step, loss=0.09678, avg_loss=0.09170, mel_loss=0.04328, linear_loss=0.05350]
[2020-05-12 03:41:32.864]  Step 151943  [4.488 sec/step, loss=0.09375, avg_loss=0.09164, mel_loss=0.04199, linear_loss=0.05176]
[2020-05-12 03:41:35.032]  Step 151944  [4.495 sec/step, loss=0.09261, avg_loss=0.09166, mel_loss=0.04118, linear_loss=0.05143]
[2020-05-12 03:41:37.523]  Step 151945  [4.464 sec/step, loss=0.09263, avg_loss=0.09157, mel_loss=0.04104, linear_loss=0.05159]
[2020-05-12 03:41:38.449]  Step 151946  [4.466 sec/step, loss=0.07992, avg_loss=0.09157, mel_loss=0.03453, linear_loss=0.04540]
[2020-05-12 03:41:40.843]  Step 151947  [4.481 sec/step, loss=0.09090, avg_loss=0.09171, mel_loss=0.04029, linear_loss=0.05060]
[2020-05-12 03:41:41.812]  Step 151948  [4.477 sec/step, loss=0.08323, avg_loss=0.09166, mel_loss=0.03594, linear_loss=0.04729]
[2020-05-12 03:41:42.920]  Step 151949  [4.447 sec/step, loss=0.08237, avg_loss=0.09148, mel_loss=0.03564, linear_loss=0.04673]
[2020-05-12 03:41:44.783]  Step 151950  [4.393 sec/step, loss=0.08952, avg_loss=0.09133, mel_loss=0.03930, linear_loss=0.05022]
[2020-05-12 03:41:44.783]  Writing summary at step: 151950
[2020-05-12 03:41:49.980]  Saving checkpoint to: ./logs-tacotron/model.ckpt-151950
[2020-05-12 03:41:51.513]  Saving audio and alignment...
[2020-05-12 03:41:54.236]  Input: 이런 식으로 잘 넘어가서~_____
[2020-05-12 03:41:56.891]  Step 151951  [4.394 sec/step, loss=0.09219, avg_loss=0.09131, mel_loss=0.04131, linear_loss=0.05087]
[2020-05-12 03:42:00.542]  Step 151952  [4.382 sec/step, loss=0.09862, avg_loss=0.09131, mel_loss=0.04472, linear_loss=0.05389]
[2020-05-12 03:42:07.472]  Step 151953  [4.370 sec/step, loss=0.09735, avg_loss=0.09129, mel_loss=0.04503, linear_loss=0.05232]
[2020-05-12 03:42:09.518]  Step 151954  [4.343 sec/step, loss=0.09106, avg_loss=0.09122, mel_loss=0.04016, linear_loss=0.05090]
[2020-05-12 03:42:17.201]  Step 151955  [4.411 sec/step, loss=0.09958, avg_loss=0.09148, mel_loss=0.04613, linear_loss=0.05345]
[2020-05-12 03:42:17.862]  Step 151956  [4.398 sec/step, loss=0.07586, avg_loss=0.09139, mel_loss=0.03304, linear_loss=0.04281]
[2020-05-12 03:42:23.534]  Step 151957  [4.284 sec/step, loss=0.09883, avg_loss=0.09162, mel_loss=0.04550, linear_loss=0.05333]
[2020-05-12 03:42:25.326]  Generated 32 batches of size 32 in 1.785 sec
[2020-05-12 03:42:28.298]  Step 151958  [4.296 sec/step, loss=0.09877, avg_loss=0.09165, mel_loss=0.04491, linear_loss=0.05386]
[2020-05-12 03:42:30.095]  Step 151959  [4.295 sec/step, loss=0.09099, avg_loss=0.09165, mel_loss=0.03979, linear_loss=0.05120]
[2020-05-12 03:42:31.732]  Step 151960  [4.291 sec/step, loss=0.09027, avg_loss=0.09163, mel_loss=0.04007, linear_loss=0.05020]
[2020-05-12 03:42:32.300]  Step 151961  [4.250 sec/step, loss=0.07320, avg_loss=0.09135, mel_loss=0.03213, linear_loss=0.04107]
[2020-05-12 03:42:46.472]  Step 151962  [4.382 sec/step, loss=0.07651, avg_loss=0.09130, mel_loss=0.03639, linear_loss=0.04012]
[2020-05-12 03:42:50.715]  Step 151963  [4.409 sec/step, loss=0.09606, avg_loss=0.09136, mel_loss=0.04344, linear_loss=0.05262]
[2020-05-12 03:42:51.885]  Step 151964  [4.389 sec/step, loss=0.08275, avg_loss=0.09122, mel_loss=0.03584, linear_loss=0.04691]
[2020-05-12 03:42:55.336]  Step 151965  [4.408 sec/step, loss=0.09482, avg_loss=0.09125, mel_loss=0.04271, linear_loss=0.05211]
[2020-05-12 03:42:56.673]  Step 151966  [4.399 sec/step, loss=0.08428, avg_loss=0.09115, mel_loss=0.03676, linear_loss=0.04752]
[2020-05-12 03:42:57.690]  Step 151967  [4.377 sec/step, loss=0.08112, avg_loss=0.09100, mel_loss=0.03518, linear_loss=0.04594]
[2020-05-12 03:43:06.120]  Step 151968  [4.439 sec/step, loss=0.09594, avg_loss=0.09103, mel_loss=0.04460, linear_loss=0.05134]
[2020-05-12 03:43:11.967]  Step 151969  [4.437 sec/step, loss=0.09893, avg_loss=0.09103, mel_loss=0.04540, linear_loss=0.05353]
[2020-05-12 03:43:13.572]  Step 151970  [4.425 sec/step, loss=0.08803, avg_loss=0.09096, mel_loss=0.03878, linear_loss=0.04925]
[2020-05-12 03:43:16.996]  Step 151971  [4.423 sec/step, loss=0.09404, avg_loss=0.09092, mel_loss=0.04247, linear_loss=0.05156]
[2020-05-12 03:43:19.154]  Step 151972  [4.434 sec/step, loss=0.09154, avg_loss=0.09097, mel_loss=0.04040, linear_loss=0.05115]
[2020-05-12 03:43:20.891]  Step 151973  [4.442 sec/step, loss=0.08725, avg_loss=0.09099, mel_loss=0.03843, linear_loss=0.04882]
[2020-05-12 03:43:34.026]  Step 151974  [4.556 sec/step, loss=0.08267, avg_loss=0.09091, mel_loss=0.03934, linear_loss=0.04333]
[2020-05-12 03:43:34.855]  Step 151975  [3.938 sec/step, loss=0.07411, avg_loss=0.09073, mel_loss=0.03231, linear_loss=0.04179]
[2020-05-12 03:43:38.289]  Step 151976  [3.921 sec/step, loss=0.09646, avg_loss=0.09073, mel_loss=0.04346, linear_loss=0.05300]
[2020-05-12 03:43:41.053]  Step 151977  [3.921 sec/step, loss=0.09274, avg_loss=0.09071, mel_loss=0.04135, linear_loss=0.05138]
[2020-05-12 03:43:46.234]  Step 151978  [3.936 sec/step, loss=0.09955, avg_loss=0.09072, mel_loss=0.04564, linear_loss=0.05391]
[2020-05-12 03:43:48.019]  Step 151979  [3.942 sec/step, loss=0.08735, avg_loss=0.09073, mel_loss=0.03822, linear_loss=0.04914]
[2020-05-12 03:43:54.256]  Step 151980  [3.916 sec/step, loss=0.09877, avg_loss=0.09075, mel_loss=0.04523, linear_loss=0.05354]
[2020-05-12 03:43:55.569]  Step 151981  [3.867 sec/step, loss=0.08777, avg_loss=0.09063, mel_loss=0.03843, linear_loss=0.04935]
[2020-05-12 03:43:56.586]  Step 151982  [3.867 sec/step, loss=0.07983, avg_loss=0.09060, mel_loss=0.03442, linear_loss=0.04542]
[2020-05-12 03:43:57.694]  Step 151983  [3.865 sec/step, loss=0.08209, avg_loss=0.09051, mel_loss=0.03563, linear_loss=0.04645]
[2020-05-12 03:44:00.161]  Step 151984  [3.867 sec/step, loss=0.09167, avg_loss=0.09052, mel_loss=0.04055, linear_loss=0.05112]
[2020-05-12 03:44:07.134]  Step 151985  [3.896 sec/step, loss=0.09934, avg_loss=0.09053, mel_loss=0.04610, linear_loss=0.05324]
[2020-05-12 03:44:09.399]  Step 151986  [3.901 sec/step, loss=0.09299, avg_loss=0.09057, mel_loss=0.04170, linear_loss=0.05130]
[2020-05-12 03:44:11.325]  Step 151987  [3.906 sec/step, loss=0.09084, avg_loss=0.09061, mel_loss=0.03998, linear_loss=0.05086]
[2020-05-12 03:44:15.750]  Step 151988  [3.940 sec/step, loss=0.09923, avg_loss=0.09080, mel_loss=0.04552, linear_loss=0.05371]
[2020-05-12 03:44:16.915]  Step 151989  [3.896 sec/step, loss=0.08511, avg_loss=0.09067, mel_loss=0.03692, linear_loss=0.04819]
[2020-05-12 03:44:18.383]  Step 151990  [3.764 sec/step, loss=0.08611, avg_loss=0.09073, mel_loss=0.03756, linear_loss=0.04855]
[2020-05-12 03:44:18.661]  Generated 32 batches of size 32 in 1.740 sec
[2020-05-12 03:44:23.206]  Step 151991  [3.807 sec/step, loss=0.09793, avg_loss=0.09100, mel_loss=0.04444, linear_loss=0.05349]
[2020-05-12 03:44:23.769]  Step 151992  [3.778 sec/step, loss=0.06938, avg_loss=0.09074, mel_loss=0.03052, linear_loss=0.03886]
[2020-05-12 03:44:27.504]  Step 151993  [3.784 sec/step, loss=0.09750, avg_loss=0.09074, mel_loss=0.04394, linear_loss=0.05356]
[2020-05-12 03:44:28.345]  Step 151994  [3.773 sec/step, loss=0.07491, avg_loss=0.09058, mel_loss=0.03256, linear_loss=0.04235]
[2020-05-12 03:44:31.425]  Step 151995  [3.776 sec/step, loss=0.09746, avg_loss=0.09061, mel_loss=0.04377, linear_loss=0.05369]
[2020-05-12 03:44:34.310]  Step 151996  [3.780 sec/step, loss=0.09528, avg_loss=0.09062, mel_loss=0.04242, linear_loss=0.05287]
[2020-05-12 03:44:36.430]  Step 151997  [3.786 sec/step, loss=0.08830, avg_loss=0.09061, mel_loss=0.03901, linear_loss=0.04929]
[2020-05-12 03:44:40.853]  Step 151998  [3.784 sec/step, loss=0.09641, avg_loss=0.09059, mel_loss=0.04344, linear_loss=0.05297]
[2020-05-12 03:44:57.093]  Step 151999  [3.926 sec/step, loss=0.07681, avg_loss=0.09044, mel_loss=0.03649, linear_loss=0.04032]
[2020-05-12 03:45:04.129]  Step 152000  [3.964 sec/step, loss=0.09820, avg_loss=0.09044, mel_loss=0.04462, linear_loss=0.05358]
[2020-05-12 03:45:04.129]  Writing summary at step: 152000
[2020-05-12 03:45:07.353]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152000
[2020-05-12 03:45:08.852]  Saving audio and alignment...
[2020-05-12 03:45:10.831]  Input: 이금희 아나운서님~___
[2020-05-12 03:45:12.819]  Step 152001  [3.973 sec/step, loss=0.08864, avg_loss=0.09050, mel_loss=0.03873, linear_loss=0.04991]
[2020-05-12 03:45:14.923]  Step 152002  [3.977 sec/step, loss=0.09186, avg_loss=0.09051, mel_loss=0.04062, linear_loss=0.05124]
[2020-05-12 03:45:18.946]  Step 152003  [3.975 sec/step, loss=0.09752, avg_loss=0.09051, mel_loss=0.04392, linear_loss=0.05360]
[2020-05-12 03:45:19.796]  Step 152004  [3.912 sec/step, loss=0.07782, avg_loss=0.09028, mel_loss=0.03400, linear_loss=0.04382]
[2020-05-12 03:45:23.260]  Step 152005  [3.414 sec/step, loss=0.09454, avg_loss=0.09038, mel_loss=0.04240, linear_loss=0.05213]
[2020-05-12 03:45:24.563]  Step 152006  [3.400 sec/step, loss=0.08456, avg_loss=0.09030, mel_loss=0.03723, linear_loss=0.04733]
[2020-05-12 03:45:26.391]  Step 152007  [3.337 sec/step, loss=0.08921, avg_loss=0.09021, mel_loss=0.03890, linear_loss=0.05031]
[2020-05-12 03:45:28.820]  Step 152008  [3.273 sec/step, loss=0.09410, avg_loss=0.09016, mel_loss=0.04196, linear_loss=0.05214]
[2020-05-12 03:45:29.917]  Step 152009  [3.267 sec/step, loss=0.08263, avg_loss=0.09008, mel_loss=0.03586, linear_loss=0.04677]
[2020-05-12 03:45:30.688]  Step 152010  [3.259 sec/step, loss=0.08091, avg_loss=0.08999, mel_loss=0.03475, linear_loss=0.04617]
[2020-05-12 03:45:32.064]  Step 152011  [3.239 sec/step, loss=0.08820, avg_loss=0.08991, mel_loss=0.03871, linear_loss=0.04949]
[2020-05-12 03:45:33.078]  Step 152012  [3.213 sec/step, loss=0.07923, avg_loss=0.08971, mel_loss=0.03414, linear_loss=0.04509]
[2020-05-12 03:45:34.704]  Step 152013  [3.176 sec/step, loss=0.08947, avg_loss=0.08964, mel_loss=0.03933, linear_loss=0.05014]
[2020-05-12 03:45:36.918]  Step 152014  [3.155 sec/step, loss=0.09193, avg_loss=0.08958, mel_loss=0.04111, linear_loss=0.05082]
[2020-05-12 03:45:42.558]  Step 152015  [3.175 sec/step, loss=0.09741, avg_loss=0.08962, mel_loss=0.04439, linear_loss=0.05303]
[2020-05-12 03:45:43.125]  Step 152016  [3.112 sec/step, loss=0.07039, avg_loss=0.08935, mel_loss=0.03130, linear_loss=0.03909]
[2020-05-12 03:45:47.286]  Step 152017  [3.145 sec/step, loss=0.09689, avg_loss=0.08950, mel_loss=0.04364, linear_loss=0.05325]
[2020-05-12 03:45:49.413]  Step 152018  [3.136 sec/step, loss=0.09088, avg_loss=0.08943, mel_loss=0.03991, linear_loss=0.05097]
[2020-05-12 03:45:54.326]  Step 152019  [3.138 sec/step, loss=0.09542, avg_loss=0.08941, mel_loss=0.04326, linear_loss=0.05216]
[2020-05-12 03:45:55.622]  Step 152020  [3.130 sec/step, loss=0.08407, avg_loss=0.08931, mel_loss=0.03641, linear_loss=0.04766]
[2020-05-12 03:45:56.042]  Generated 32 batches of size 32 in 1.711 sec
[2020-05-12 03:46:01.613]  Step 152021  [3.161 sec/step, loss=0.09713, avg_loss=0.08933, mel_loss=0.04445, linear_loss=0.05269]
[2020-05-12 03:46:03.162]  Step 152022  [3.156 sec/step, loss=0.08895, avg_loss=0.08930, mel_loss=0.03879, linear_loss=0.05017]
[2020-05-12 03:46:12.231]  Step 152023  [3.233 sec/step, loss=0.09455, avg_loss=0.08939, mel_loss=0.04391, linear_loss=0.05064]
[2020-05-12 03:46:19.219]  Step 152024  [3.285 sec/step, loss=0.09927, avg_loss=0.08948, mel_loss=0.04552, linear_loss=0.05375]
[2020-05-12 03:46:22.249]  Step 152025  [3.304 sec/step, loss=0.09401, avg_loss=0.08959, mel_loss=0.04187, linear_loss=0.05214]
[2020-05-12 03:46:25.079]  Step 152026  [3.324 sec/step, loss=0.09450, avg_loss=0.08976, mel_loss=0.04224, linear_loss=0.05226]
[2020-05-12 03:46:28.232]  Step 152027  [3.350 sec/step, loss=0.09920, avg_loss=0.09002, mel_loss=0.04453, linear_loss=0.05467]
[2020-05-12 03:46:31.808]  Step 152028  [3.378 sec/step, loss=0.09498, avg_loss=0.09018, mel_loss=0.04253, linear_loss=0.05245]
[2020-05-12 03:46:37.478]  Step 152029  [3.414 sec/step, loss=0.10007, avg_loss=0.09028, mel_loss=0.04645, linear_loss=0.05362]
[2020-05-12 03:46:39.506]  Step 152030  [3.408 sec/step, loss=0.09311, avg_loss=0.09028, mel_loss=0.04158, linear_loss=0.05153]
[2020-05-12 03:46:44.664]  Step 152031  [3.422 sec/step, loss=0.09741, avg_loss=0.09027, mel_loss=0.04464, linear_loss=0.05277]
[2020-05-12 03:46:48.332]  Step 152032  [3.447 sec/step, loss=0.09652, avg_loss=0.09038, mel_loss=0.04348, linear_loss=0.05304]
[2020-05-12 03:46:57.369]  Step 152033  [3.416 sec/step, loss=0.09576, avg_loss=0.09045, mel_loss=0.04466, linear_loss=0.05110]
[2020-05-12 03:47:05.072]  Step 152034  [3.470 sec/step, loss=0.09855, avg_loss=0.09048, mel_loss=0.04579, linear_loss=0.05276]
[2020-05-12 03:47:06.145]  Step 152035  [3.424 sec/step, loss=0.08053, avg_loss=0.09028, mel_loss=0.03493, linear_loss=0.04560]
[2020-05-12 03:47:08.850]  Step 152036  [3.442 sec/step, loss=0.09151, avg_loss=0.09036, mel_loss=0.04069, linear_loss=0.05081]
[2020-05-12 03:47:12.218]  Step 152037  [3.468 sec/step, loss=0.09387, avg_loss=0.09052, mel_loss=0.04220, linear_loss=0.05167]
[2020-05-12 03:47:14.662]  Step 152038  [3.404 sec/step, loss=0.09299, avg_loss=0.09049, mel_loss=0.04091, linear_loss=0.05208]
[2020-05-12 03:47:19.362]  Step 152039  [3.436 sec/step, loss=0.09778, avg_loss=0.09058, mel_loss=0.04414, linear_loss=0.05364]
[2020-05-12 03:47:33.635]  Step 152040  [3.547 sec/step, loss=0.07774, avg_loss=0.09041, mel_loss=0.03725, linear_loss=0.04049]
[2020-05-12 03:47:35.440]  Step 152041  [3.527 sec/step, loss=0.08899, avg_loss=0.09032, mel_loss=0.03879, linear_loss=0.05019]
[2020-05-12 03:47:37.076]  Step 152042  [3.509 sec/step, loss=0.08910, avg_loss=0.09024, mel_loss=0.03907, linear_loss=0.05003]
[2020-05-12 03:47:38.434]  Step 152043  [3.494 sec/step, loss=0.08568, avg_loss=0.09016, mel_loss=0.03715, linear_loss=0.04853]
[2020-05-12 03:47:40.034]  Step 152044  [3.488 sec/step, loss=0.08635, avg_loss=0.09010, mel_loss=0.03801, linear_loss=0.04834]
[2020-05-12 03:47:41.038]  Step 152045  [3.473 sec/step, loss=0.08483, avg_loss=0.09002, mel_loss=0.03675, linear_loss=0.04808]
[2020-05-12 03:47:43.242]  Step 152046  [3.486 sec/step, loss=0.09173, avg_loss=0.09014, mel_loss=0.04030, linear_loss=0.05142]
[2020-05-12 03:47:46.090]  Step 152047  [3.491 sec/step, loss=0.09353, avg_loss=0.09016, mel_loss=0.04172, linear_loss=0.05181]
[2020-05-12 03:47:50.391]  Step 152048  [3.524 sec/step, loss=0.09766, avg_loss=0.09031, mel_loss=0.04457, linear_loss=0.05309]
[2020-05-12 03:47:51.254]  Step 152049  [3.522 sec/step, loss=0.07634, avg_loss=0.09025, mel_loss=0.03296, linear_loss=0.04338]
[2020-05-12 03:47:54.673]  Step 152050  [3.537 sec/step, loss=0.09601, avg_loss=0.09031, mel_loss=0.04328, linear_loss=0.05273]
[2020-05-12 03:47:54.673]  Writing summary at step: 152050
[2020-05-12 03:47:55.482]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152050
[2020-05-12 03:47:57.000]  Saving audio and alignment...
[2020-05-12 03:47:59.278]  Generated 32 batches of size 32 in 1.685 sec
[2020-05-12 03:48:03.702]  Input: 뉴스에서는 이종 모음을 잘 지키다가도 장르에만 오면~___________________________________
[2020-05-12 03:48:05.663]  Step 152051  [3.530 sec/step, loss=0.09138, avg_loss=0.09030, mel_loss=0.04035, linear_loss=0.05103]
[2020-05-12 03:48:06.956]  Step 152052  [3.507 sec/step, loss=0.08506, avg_loss=0.09017, mel_loss=0.03699, linear_loss=0.04806]
[2020-05-12 03:48:07.479]  Step 152053  [3.442 sec/step, loss=0.07182, avg_loss=0.08991, mel_loss=0.03177, linear_loss=0.04005]
[2020-05-12 03:48:11.217]  Step 152054  [3.459 sec/step, loss=0.09836, avg_loss=0.08999, mel_loss=0.04441, linear_loss=0.05396]
[2020-05-12 03:48:13.071]  Step 152055  [3.401 sec/step, loss=0.08912, avg_loss=0.08988, mel_loss=0.03901, linear_loss=0.05010]
[2020-05-12 03:48:19.473]  Step 152056  [3.459 sec/step, loss=0.09546, avg_loss=0.09008, mel_loss=0.04398, linear_loss=0.05148]
[2020-05-12 03:48:20.636]  Step 152057  [3.413 sec/step, loss=0.08367, avg_loss=0.08993, mel_loss=0.03659, linear_loss=0.04708]
[2020-05-12 03:48:23.621]  Step 152058  [3.396 sec/step, loss=0.09459, avg_loss=0.08988, mel_loss=0.04261, linear_loss=0.05198]
[2020-05-12 03:48:27.242]  Step 152059  [3.414 sec/step, loss=0.09671, avg_loss=0.08994, mel_loss=0.04363, linear_loss=0.05308]
[2020-05-12 03:48:31.348]  Step 152060  [3.439 sec/step, loss=0.09364, avg_loss=0.08997, mel_loss=0.04199, linear_loss=0.05165]
[2020-05-12 03:48:31.914]  Step 152061  [3.439 sec/step, loss=0.07164, avg_loss=0.08996, mel_loss=0.03152, linear_loss=0.04013]
[2020-05-12 03:48:33.600]  Step 152062  [3.314 sec/step, loss=0.09113, avg_loss=0.09010, mel_loss=0.04007, linear_loss=0.05105]
[2020-05-12 03:48:39.457]  Step 152063  [3.330 sec/step, loss=0.09856, avg_loss=0.09013, mel_loss=0.04529, linear_loss=0.05327]
[2020-05-12 03:48:41.395]  Step 152064  [3.338 sec/step, loss=0.08770, avg_loss=0.09018, mel_loss=0.03868, linear_loss=0.04902]
[2020-05-12 03:48:46.757]  Step 152065  [3.357 sec/step, loss=0.09818, avg_loss=0.09021, mel_loss=0.04472, linear_loss=0.05346]
[2020-05-12 03:48:49.018]  Step 152066  [3.366 sec/step, loss=0.09202, avg_loss=0.09029, mel_loss=0.04129, linear_loss=0.05073]
[2020-05-12 03:48:52.518]  Step 152067  [3.391 sec/step, loss=0.09277, avg_loss=0.09041, mel_loss=0.04154, linear_loss=0.05123]
[2020-05-12 03:48:54.049]  Step 152068  [3.322 sec/step, loss=0.08846, avg_loss=0.09033, mel_loss=0.03854, linear_loss=0.04991]
[2020-05-12 03:48:54.916]  Step 152069  [3.272 sec/step, loss=0.07224, avg_loss=0.09006, mel_loss=0.03142, linear_loss=0.04082]
[2020-05-12 03:48:56.024]  Step 152070  [3.267 sec/step, loss=0.08484, avg_loss=0.09003, mel_loss=0.03642, linear_loss=0.04843]
[2020-05-12 03:48:56.936]  Step 152071  [3.242 sec/step, loss=0.07987, avg_loss=0.08989, mel_loss=0.03419, linear_loss=0.04567]
[2020-05-12 03:49:01.207]  Step 152072  [3.263 sec/step, loss=0.09588, avg_loss=0.08993, mel_loss=0.04345, linear_loss=0.05243]
[2020-05-12 03:49:06.140]  Step 152073  [3.295 sec/step, loss=0.09701, avg_loss=0.09003, mel_loss=0.04401, linear_loss=0.05300]
[2020-05-12 03:49:07.523]  Step 152074  [3.177 sec/step, loss=0.08675, avg_loss=0.09007, mel_loss=0.03783, linear_loss=0.04891]
[2020-05-12 03:49:10.207]  Step 152075  [3.196 sec/step, loss=0.09187, avg_loss=0.09025, mel_loss=0.04092, linear_loss=0.05095]
[2020-05-12 03:49:14.246]  Step 152076  [3.202 sec/step, loss=0.09474, avg_loss=0.09023, mel_loss=0.04232, linear_loss=0.05243]
[2020-05-12 03:49:17.260]  Step 152077  [3.205 sec/step, loss=0.09433, avg_loss=0.09025, mel_loss=0.04194, linear_loss=0.05238]
[2020-05-12 03:49:18.297]  Step 152078  [3.163 sec/step, loss=0.08261, avg_loss=0.09008, mel_loss=0.03578, linear_loss=0.04683]
[2020-05-12 03:49:20.773]  Step 152079  [3.170 sec/step, loss=0.09186, avg_loss=0.09013, mel_loss=0.04078, linear_loss=0.05108]
[2020-05-12 03:49:22.561]  Step 152080  [3.125 sec/step, loss=0.08752, avg_loss=0.09001, mel_loss=0.03830, linear_loss=0.04922]
[2020-05-12 03:49:23.806]  Step 152081  [3.125 sec/step, loss=0.08287, avg_loss=0.08996, mel_loss=0.03593, linear_loss=0.04693]
[2020-05-12 03:49:25.648]  Generated 32 batches of size 32 in 1.835 sec
[2020-05-12 03:49:37.134]  Step 152082  [3.248 sec/step, loss=0.08196, avg_loss=0.08998, mel_loss=0.03870, linear_loss=0.04325]
[2020-05-12 03:49:40.233]  Step 152083  [3.268 sec/step, loss=0.09608, avg_loss=0.09012, mel_loss=0.04296, linear_loss=0.05312]
[2020-05-12 03:49:41.680]  Step 152084  [3.258 sec/step, loss=0.08649, avg_loss=0.09007, mel_loss=0.03795, linear_loss=0.04854]
[2020-05-12 03:49:48.641]  Step 152085  [3.258 sec/step, loss=0.09980, avg_loss=0.09008, mel_loss=0.04588, linear_loss=0.05392]
[2020-05-12 03:49:51.024]  Step 152086  [3.259 sec/step, loss=0.09067, avg_loss=0.09005, mel_loss=0.04018, linear_loss=0.05049]
[2020-05-12 03:49:53.263]  Step 152087  [3.262 sec/step, loss=0.09141, avg_loss=0.09006, mel_loss=0.04020, linear_loss=0.05121]
[2020-05-12 03:50:02.306]  Step 152088  [3.308 sec/step, loss=0.09674, avg_loss=0.09004, mel_loss=0.04473, linear_loss=0.05201]
[2020-05-12 03:50:10.006]  Step 152089  [3.373 sec/step, loss=0.09954, avg_loss=0.09018, mel_loss=0.04605, linear_loss=0.05349]
[2020-05-12 03:50:10.846]  Step 152090  [3.367 sec/step, loss=0.07775, avg_loss=0.09010, mel_loss=0.03357, linear_loss=0.04418]
[2020-05-12 03:50:14.660]  Step 152091  [3.357 sec/step, loss=0.09701, avg_loss=0.09009, mel_loss=0.04345, linear_loss=0.05356]
[2020-05-12 03:50:18.211]  Step 152092  [3.387 sec/step, loss=0.09412, avg_loss=0.09033, mel_loss=0.04245, linear_loss=0.05168]
[2020-05-12 03:50:20.757]  Step 152093  [3.375 sec/step, loss=0.09266, avg_loss=0.09029, mel_loss=0.04108, linear_loss=0.05158]
[2020-05-12 03:50:22.466]  Step 152094  [3.384 sec/step, loss=0.09011, avg_loss=0.09044, mel_loss=0.03950, linear_loss=0.05061]
[2020-05-12 03:50:23.902]  Step 152095  [3.367 sec/step, loss=0.08660, avg_loss=0.09033, mel_loss=0.03820, linear_loss=0.04840]
[2020-05-12 03:50:25.805]  Step 152096  [3.357 sec/step, loss=0.08922, avg_loss=0.09027, mel_loss=0.03892, linear_loss=0.05030]
[2020-05-12 03:50:27.320]  Step 152097  [3.351 sec/step, loss=0.08884, avg_loss=0.09027, mel_loss=0.03888, linear_loss=0.04997]
[2020-05-12 03:50:31.522]  Step 152098  [3.349 sec/step, loss=0.09653, avg_loss=0.09027, mel_loss=0.04351, linear_loss=0.05303]
[2020-05-12 03:50:33.645]  Step 152099  [3.208 sec/step, loss=0.09391, avg_loss=0.09045, mel_loss=0.04154, linear_loss=0.05237]
[2020-05-12 03:50:35.669]  Step 152100  [3.158 sec/step, loss=0.08951, avg_loss=0.09036, mel_loss=0.03946, linear_loss=0.05005]
[2020-05-12 03:50:35.669]  Writing summary at step: 152100
[2020-05-12 03:50:36.448]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152100
[2020-05-12 03:50:38.064]  Saving audio and alignment...
[2020-05-12 03:50:45.592]  Input: 자 됐습니다 됐 발음을 대충 되시라고 하지 않는지 스스로 점검합시다~_____________________________________
[2020-05-12 03:50:57.686]  Step 152101  [3.259 sec/step, loss=0.08537, avg_loss=0.09033, mel_loss=0.04026, linear_loss=0.04512]
[2020-05-12 03:50:59.475]  Step 152102  [3.256 sec/step, loss=0.08977, avg_loss=0.09031, mel_loss=0.03938, linear_loss=0.05039]
[2020-05-12 03:51:03.952]  Step 152103  [3.260 sec/step, loss=0.09845, avg_loss=0.09031, mel_loss=0.04496, linear_loss=0.05350]
[2020-05-12 03:51:04.993]  Step 152104  [3.262 sec/step, loss=0.08075, avg_loss=0.09034, mel_loss=0.03468, linear_loss=0.04608]
[2020-05-12 03:51:06.262]  Step 152105  [3.240 sec/step, loss=0.08483, avg_loss=0.09025, mel_loss=0.03709, linear_loss=0.04773]
[2020-05-12 03:51:07.099]  Step 152106  [3.236 sec/step, loss=0.07627, avg_loss=0.09016, mel_loss=0.03267, linear_loss=0.04360]
[2020-05-12 03:51:08.001]  Step 152107  [3.226 sec/step, loss=0.08434, avg_loss=0.09012, mel_loss=0.03637, linear_loss=0.04797]
[2020-05-12 03:51:09.120]  Step 152108  [3.213 sec/step, loss=0.08401, avg_loss=0.09001, mel_loss=0.03623, linear_loss=0.04777]
[2020-05-12 03:51:12.214]  Step 152109  [3.233 sec/step, loss=0.09668, avg_loss=0.09015, mel_loss=0.04326, linear_loss=0.05342]
[2020-05-12 03:51:15.677]  Step 152110  [3.260 sec/step, loss=0.09484, avg_loss=0.09029, mel_loss=0.04274, linear_loss=0.05210]
[2020-05-12 03:51:18.488]  Step 152111  [3.274 sec/step, loss=0.09225, avg_loss=0.09033, mel_loss=0.04128, linear_loss=0.05097]
[2020-05-12 03:51:20.428]  Generated 32 batches of size 32 in 1.934 sec
[2020-05-12 03:51:21.535]  Step 152112  [3.295 sec/step, loss=0.09623, avg_loss=0.09050, mel_loss=0.04282, linear_loss=0.05341]
[2020-05-12 03:51:22.120]  Step 152113  [3.284 sec/step, loss=0.06984, avg_loss=0.09031, mel_loss=0.03090, linear_loss=0.03894]
[2020-05-12 03:51:24.720]  Step 152114  [3.288 sec/step, loss=0.09272, avg_loss=0.09032, mel_loss=0.04125, linear_loss=0.05147]
[2020-05-12 03:51:30.857]  Step 152115  [3.293 sec/step, loss=0.09666, avg_loss=0.09031, mel_loss=0.04443, linear_loss=0.05224]
[2020-05-12 03:51:32.218]  Step 152116  [3.301 sec/step, loss=0.08493, avg_loss=0.09045, mel_loss=0.03668, linear_loss=0.04825]
[2020-05-12 03:51:39.381]  Step 152117  [3.331 sec/step, loss=0.10022, avg_loss=0.09049, mel_loss=0.04616, linear_loss=0.05406]
[2020-05-12 03:51:41.655]  Step 152118  [3.333 sec/step, loss=0.09086, avg_loss=0.09049, mel_loss=0.04036, linear_loss=0.05050]
[2020-05-12 03:51:47.282]  Step 152119  [3.340 sec/step, loss=0.09568, avg_loss=0.09049, mel_loss=0.04341, linear_loss=0.05227]
[2020-05-12 03:51:55.634]  Step 152120  [3.410 sec/step, loss=0.09619, avg_loss=0.09061, mel_loss=0.04457, linear_loss=0.05162]
[2020-05-12 03:51:56.472]  Step 152121  [3.359 sec/step, loss=0.07603, avg_loss=0.09040, mel_loss=0.03265, linear_loss=0.04338]
[2020-05-12 03:52:10.845]  Step 152122  [3.487 sec/step, loss=0.07905, avg_loss=0.09030, mel_loss=0.03749, linear_loss=0.04156]
[2020-05-12 03:52:12.132]  Step 152123  [3.409 sec/step, loss=0.08473, avg_loss=0.09020, mel_loss=0.03705, linear_loss=0.04768]
[2020-05-12 03:52:15.586]  Step 152124  [3.374 sec/step, loss=0.09476, avg_loss=0.09016, mel_loss=0.04243, linear_loss=0.05233]
[2020-05-12 03:52:19.100]  Step 152125  [3.379 sec/step, loss=0.09624, avg_loss=0.09018, mel_loss=0.04312, linear_loss=0.05313]
[2020-05-12 03:52:20.860]  Step 152126  [3.368 sec/step, loss=0.08912, avg_loss=0.09013, mel_loss=0.03885, linear_loss=0.05028]
[2020-05-12 03:52:21.904]  Step 152127  [3.347 sec/step, loss=0.08131, avg_loss=0.08995, mel_loss=0.03535, linear_loss=0.04596]
[2020-05-12 03:52:24.402]  Step 152128  [3.336 sec/step, loss=0.09053, avg_loss=0.08990, mel_loss=0.03993, linear_loss=0.05060]
[2020-05-12 03:52:25.551]  Step 152129  [3.291 sec/step, loss=0.08440, avg_loss=0.08975, mel_loss=0.03641, linear_loss=0.04799]
[2020-05-12 03:52:30.835]  Step 152130  [3.324 sec/step, loss=0.09736, avg_loss=0.08979, mel_loss=0.04448, linear_loss=0.05288]
[2020-05-12 03:52:34.823]  Step 152131  [3.312 sec/step, loss=0.09644, avg_loss=0.08978, mel_loss=0.04335, linear_loss=0.05309]
[2020-05-12 03:52:36.919]  Step 152132  [3.296 sec/step, loss=0.09011, avg_loss=0.08972, mel_loss=0.03988, linear_loss=0.05023]
[2020-05-12 03:52:39.736]  Step 152133  [3.234 sec/step, loss=0.09278, avg_loss=0.08969, mel_loss=0.04162, linear_loss=0.05116]
[2020-05-12 03:52:41.400]  Step 152134  [3.174 sec/step, loss=0.08894, avg_loss=0.08959, mel_loss=0.03926, linear_loss=0.04969]
[2020-05-12 03:52:47.832]  Step 152135  [3.227 sec/step, loss=0.09657, avg_loss=0.08975, mel_loss=0.04446, linear_loss=0.05211]
[2020-05-12 03:52:49.418]  Step 152136  [3.216 sec/step, loss=0.08878, avg_loss=0.08972, mel_loss=0.03874, linear_loss=0.05004]
[2020-05-12 03:52:54.169]  Step 152137  [3.230 sec/step, loss=0.09669, avg_loss=0.08975, mel_loss=0.04375, linear_loss=0.05294]
[2020-05-12 03:52:56.375]  Step 152138  [3.227 sec/step, loss=0.09082, avg_loss=0.08973, mel_loss=0.04020, linear_loss=0.05062]
[2020-05-12 03:52:57.250]  Step 152139  [3.189 sec/step, loss=0.07876, avg_loss=0.08954, mel_loss=0.03374, linear_loss=0.04503]
[2020-05-12 03:52:58.328]  Step 152140  [3.057 sec/step, loss=0.08346, avg_loss=0.08960, mel_loss=0.03629, linear_loss=0.04717]
[2020-05-12 03:53:02.058]  Step 152141  [3.076 sec/step, loss=0.09781, avg_loss=0.08968, mel_loss=0.04419, linear_loss=0.05362]
[2020-05-12 03:53:04.005]  Step 152142  [3.080 sec/step, loss=0.08854, avg_loss=0.08968, mel_loss=0.03876, linear_loss=0.04979]
[2020-05-12 03:53:06.968]  Step 152143  [3.096 sec/step, loss=0.09488, avg_loss=0.08977, mel_loss=0.04237, linear_loss=0.05251]
[2020-05-12 03:53:08.450]  Step 152144  [3.094 sec/step, loss=0.08584, avg_loss=0.08977, mel_loss=0.03745, linear_loss=0.04839]
[2020-05-12 03:53:08.767]  Generated 32 batches of size 32 in 1.794 sec
[2020-05-12 03:53:09.043]  Step 152145  [3.090 sec/step, loss=0.07030, avg_loss=0.08962, mel_loss=0.03107, linear_loss=0.03923]
[2020-05-12 03:53:13.424]  Step 152146  [3.112 sec/step, loss=0.09787, avg_loss=0.08968, mel_loss=0.04460, linear_loss=0.05327]
[2020-05-12 03:53:21.055]  Step 152147  [3.160 sec/step, loss=0.09842, avg_loss=0.08973, mel_loss=0.04563, linear_loss=0.05279]
[2020-05-12 03:53:26.640]  Step 152148  [3.173 sec/step, loss=0.09909, avg_loss=0.08974, mel_loss=0.04556, linear_loss=0.05352]
[2020-05-12 03:53:29.756]  Step 152149  [3.195 sec/step, loss=0.09732, avg_loss=0.08995, mel_loss=0.04375, linear_loss=0.05357]
[2020-05-12 03:53:39.001]  Step 152150  [3.254 sec/step, loss=0.09607, avg_loss=0.08996, mel_loss=0.04479, linear_loss=0.05128]
[2020-05-12 03:53:39.001]  Writing summary at step: 152150
[2020-05-12 03:53:39.765]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152150
[2020-05-12 03:53:41.307]  Saving audio and alignment...
[2020-05-12 03:53:45.369]  Input: 하지만 그때 얻은 저의 만족감이 일이라면~__________
[2020-05-12 03:53:47.042]  Step 152151  [3.251 sec/step, loss=0.08628, avg_loss=0.08990, mel_loss=0.03781, linear_loss=0.04847]
[2020-05-12 03:53:53.714]  Step 152152  [3.304 sec/step, loss=0.09621, avg_loss=0.09002, mel_loss=0.04412, linear_loss=0.05209]
[2020-05-12 03:53:55.768]  Step 152153  [3.320 sec/step, loss=0.08898, avg_loss=0.09019, mel_loss=0.03904, linear_loss=0.04995]
[2020-05-12 03:54:08.969]  Step 152154  [3.414 sec/step, loss=0.08201, avg_loss=0.09002, mel_loss=0.03856, linear_loss=0.04346]
[2020-05-12 03:54:10.002]  Step 152155  [3.406 sec/step, loss=0.08139, avg_loss=0.08995, mel_loss=0.03527, linear_loss=0.04613]
[2020-05-12 03:54:13.404]  Step 152156  [3.376 sec/step, loss=0.09470, avg_loss=0.08994, mel_loss=0.04266, linear_loss=0.05204]
[2020-05-12 03:54:19.070]  Step 152157  [3.421 sec/step, loss=0.09683, avg_loss=0.09007, mel_loss=0.04400, linear_loss=0.05282]
[2020-05-12 03:54:21.322]  Step 152158  [3.414 sec/step, loss=0.09156, avg_loss=0.09004, mel_loss=0.04043, linear_loss=0.05113]
[2020-05-12 03:54:24.432]  Step 152159  [3.409 sec/step, loss=0.09112, avg_loss=0.08998, mel_loss=0.04030, linear_loss=0.05082]
[2020-05-12 03:54:29.838]  Step 152160  [3.422 sec/step, loss=0.09723, avg_loss=0.09002, mel_loss=0.04407, linear_loss=0.05316]
[2020-05-12 03:54:34.424]  Step 152161  [3.462 sec/step, loss=0.09640, avg_loss=0.09027, mel_loss=0.04348, linear_loss=0.05291]
[2020-05-12 03:54:39.417]  Step 152162  [3.495 sec/step, loss=0.09495, avg_loss=0.09031, mel_loss=0.04264, linear_loss=0.05231]
[2020-05-12 03:54:41.383]  Step 152163  [3.456 sec/step, loss=0.09101, avg_loss=0.09023, mel_loss=0.04008, linear_loss=0.05092]
[2020-05-12 03:54:44.880]  Step 152164  [3.472 sec/step, loss=0.09589, avg_loss=0.09031, mel_loss=0.04300, linear_loss=0.05289]
[2020-05-12 03:54:52.346]  Step 152165  [3.493 sec/step, loss=0.09782, avg_loss=0.09031, mel_loss=0.04502, linear_loss=0.05281]
[2020-05-12 03:54:53.119]  Step 152166  [3.478 sec/step, loss=0.07284, avg_loss=0.09012, mel_loss=0.03204, linear_loss=0.04079]
[2020-05-12 03:54:55.938]  Step 152167  [3.471 sec/step, loss=0.09170, avg_loss=0.09011, mel_loss=0.04075, linear_loss=0.05095]
[2020-05-12 03:54:59.265]  Step 152168  [3.489 sec/step, loss=0.09594, avg_loss=0.09018, mel_loss=0.04278, linear_loss=0.05316]
[2020-05-12 03:55:00.498]  Step 152169  [3.493 sec/step, loss=0.08371, avg_loss=0.09030, mel_loss=0.03611, linear_loss=0.04760]
[2020-05-12 03:55:02.445]  Step 152170  [3.501 sec/step, loss=0.08946, avg_loss=0.09034, mel_loss=0.03897, linear_loss=0.05049]
[2020-05-12 03:55:03.808]  Step 152171  [3.506 sec/step, loss=0.08380, avg_loss=0.09038, mel_loss=0.03666, linear_loss=0.04714]
[2020-05-12 03:55:05.340]  Step 152172  [3.478 sec/step, loss=0.08610, avg_loss=0.09028, mel_loss=0.03750, linear_loss=0.04861]
[2020-05-12 03:55:06.546]  Step 152173  [3.441 sec/step, loss=0.07842, avg_loss=0.09010, mel_loss=0.03360, linear_loss=0.04482]
[2020-05-12 03:55:09.736]  Generated 32 batches of size 32 in 3.181 sec
[2020-05-12 03:55:15.029]  Step 152174  [3.512 sec/step, loss=0.09522, avg_loss=0.09018, mel_loss=0.04347, linear_loss=0.05175]
[2020-05-12 03:55:17.740]  Step 152175  [3.512 sec/step, loss=0.09057, avg_loss=0.09017, mel_loss=0.03935, linear_loss=0.05122]
[2020-05-12 03:55:22.775]  Step 152176  [3.522 sec/step, loss=0.09768, avg_loss=0.09020, mel_loss=0.04413, linear_loss=0.05356]
[2020-05-12 03:55:24.189]  Step 152177  [3.506 sec/step, loss=0.08510, avg_loss=0.09011, mel_loss=0.03729, linear_loss=0.04781]
[2020-05-12 03:55:25.014]  Step 152178  [3.504 sec/step, loss=0.07344, avg_loss=0.09002, mel_loss=0.03168, linear_loss=0.04177]
[2020-05-12 03:55:27.803]  Step 152179  [3.507 sec/step, loss=0.09127, avg_loss=0.09001, mel_loss=0.04034, linear_loss=0.05092]
[2020-05-12 03:55:28.878]  Step 152180  [3.500 sec/step, loss=0.08144, avg_loss=0.08995, mel_loss=0.03493, linear_loss=0.04651]
[2020-05-12 03:55:37.635]  Step 152181  [3.575 sec/step, loss=0.09614, avg_loss=0.09008, mel_loss=0.04478, linear_loss=0.05136]
[2020-05-12 03:55:40.562]  Step 152182  [3.471 sec/step, loss=0.09287, avg_loss=0.09019, mel_loss=0.04137, linear_loss=0.05150]
[2020-05-12 03:55:41.897]  Step 152183  [3.453 sec/step, loss=0.08595, avg_loss=0.09009, mel_loss=0.03711, linear_loss=0.04884]
[2020-05-12 03:55:50.769]  Step 152184  [3.528 sec/step, loss=0.09571, avg_loss=0.09018, mel_loss=0.04432, linear_loss=0.05139]
[2020-05-12 03:55:51.797]  Step 152185  [3.468 sec/step, loss=0.08156, avg_loss=0.09000, mel_loss=0.03502, linear_loss=0.04654]
[2020-05-12 03:55:53.994]  Step 152186  [3.467 sec/step, loss=0.09114, avg_loss=0.09000, mel_loss=0.04052, linear_loss=0.05061]
[2020-05-12 03:55:57.799]  Step 152187  [3.482 sec/step, loss=0.09779, avg_loss=0.09007, mel_loss=0.04403, linear_loss=0.05376]
[2020-05-12 03:56:04.276]  Step 152188  [3.457 sec/step, loss=0.09765, avg_loss=0.09008, mel_loss=0.04501, linear_loss=0.05265]
[2020-05-12 03:56:07.752]  Step 152189  [3.414 sec/step, loss=0.09406, avg_loss=0.09002, mel_loss=0.04214, linear_loss=0.05192]
[2020-05-12 03:56:09.219]  Step 152190  [3.421 sec/step, loss=0.08914, avg_loss=0.09014, mel_loss=0.03916, linear_loss=0.04997]
[2020-05-12 03:56:11.999]  Step 152191  [3.410 sec/step, loss=0.09415, avg_loss=0.09011, mel_loss=0.04223, linear_loss=0.05192]
[2020-05-12 03:56:15.653]  Step 152192  [3.411 sec/step, loss=0.09660, avg_loss=0.09013, mel_loss=0.04355, linear_loss=0.05304]
[2020-05-12 03:56:16.208]  Step 152193  [3.391 sec/step, loss=0.06876, avg_loss=0.08989, mel_loss=0.03049, linear_loss=0.03827]
[2020-05-12 03:56:21.445]  Step 152194  [3.427 sec/step, loss=0.09679, avg_loss=0.08996, mel_loss=0.04396, linear_loss=0.05283]
[2020-05-12 03:56:22.662]  Step 152195  [3.424 sec/step, loss=0.08442, avg_loss=0.08994, mel_loss=0.03658, linear_loss=0.04783]
[2020-05-12 03:56:25.172]  Step 152196  [3.430 sec/step, loss=0.09243, avg_loss=0.08997, mel_loss=0.04107, linear_loss=0.05136]
[2020-05-12 03:56:26.962]  Step 152197  [3.433 sec/step, loss=0.08914, avg_loss=0.08997, mel_loss=0.03880, linear_loss=0.05034]
[2020-05-12 03:56:30.405]  Step 152198  [3.426 sec/step, loss=0.09635, avg_loss=0.08997, mel_loss=0.04319, linear_loss=0.05316]
[2020-05-12 03:56:44.891]  Step 152199  [3.549 sec/step, loss=0.07598, avg_loss=0.08979, mel_loss=0.03611, linear_loss=0.03988]
[2020-05-12 03:56:50.630]  Step 152200  [3.586 sec/step, loss=0.10055, avg_loss=0.08990, mel_loss=0.04631, linear_loss=0.05424]
[2020-05-12 03:56:50.630]  Writing summary at step: 152200
[2020-05-12 03:56:55.002]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152200
[2020-05-12 03:56:56.545]  Saving audio and alignment...
[2020-05-12 03:57:01.432]  Input: 톤을 살짝 낮추시고요 표정도 조금 진지하게 해서~__________________
[2020-05-12 03:57:02.503]  Step 152201  [3.476 sec/step, loss=0.08581, avg_loss=0.08991, mel_loss=0.03699, linear_loss=0.04882]
[2020-05-12 03:57:07.332]  Step 152202  [3.507 sec/step, loss=0.09784, avg_loss=0.08999, mel_loss=0.04445, linear_loss=0.05339]
[2020-05-12 03:57:09.265]  Step 152203  [3.481 sec/step, loss=0.09037, avg_loss=0.08991, mel_loss=0.03954, linear_loss=0.05082]
[2020-05-12 03:57:10.119]  Step 152204  [3.479 sec/step, loss=0.07671, avg_loss=0.08987, mel_loss=0.03303, linear_loss=0.04369]
[2020-05-12 03:57:11.030]  Generated 32 batches of size 32 in 1.760 sec
[2020-05-12 03:57:12.179]  Step 152205  [3.487 sec/step, loss=0.09287, avg_loss=0.08995, mel_loss=0.04097, linear_loss=0.05190]
[2020-05-12 03:57:15.068]  Step 152206  [3.508 sec/step, loss=0.09593, avg_loss=0.09014, mel_loss=0.04282, linear_loss=0.05311]
[2020-05-12 03:57:16.743]  Step 152207  [3.515 sec/step, loss=0.09089, avg_loss=0.09021, mel_loss=0.04003, linear_loss=0.05086]
[2020-05-12 03:57:17.653]  Step 152208  [3.513 sec/step, loss=0.07895, avg_loss=0.09016, mel_loss=0.03397, linear_loss=0.04498]
[2020-05-12 03:57:19.940]  Step 152209  [3.505 sec/step, loss=0.09365, avg_loss=0.09013, mel_loss=0.04178, linear_loss=0.05187]
[2020-05-12 03:57:20.732]  Step 152210  [3.479 sec/step, loss=0.07198, avg_loss=0.08990, mel_loss=0.03156, linear_loss=0.04042]
[2020-05-12 03:57:22.325]  Step 152211  [3.466 sec/step, loss=0.08883, avg_loss=0.08986, mel_loss=0.03888, linear_loss=0.04995]
[2020-05-12 03:57:29.709]  Step 152212  [3.510 sec/step, loss=0.10092, avg_loss=0.08991, mel_loss=0.04668, linear_loss=0.05423]
[2020-05-12 03:57:33.882]  Step 152213  [3.546 sec/step, loss=0.09553, avg_loss=0.09017, mel_loss=0.04294, linear_loss=0.05259]
[2020-05-12 03:57:39.504]  Step 152214  [3.576 sec/step, loss=0.09817, avg_loss=0.09022, mel_loss=0.04505, linear_loss=0.05312]
[2020-05-12 03:57:42.372]  Step 152215  [3.543 sec/step, loss=0.09234, avg_loss=0.09018, mel_loss=0.04112, linear_loss=0.05122]
[2020-05-12 03:57:44.755]  Step 152216  [3.553 sec/step, loss=0.09368, avg_loss=0.09027, mel_loss=0.04173, linear_loss=0.05195]
[2020-05-12 03:57:53.651]  Step 152217  [3.571 sec/step, loss=0.09781, avg_loss=0.09024, mel_loss=0.04550, linear_loss=0.05231]
[2020-05-12 03:57:55.248]  Step 152218  [3.564 sec/step, loss=0.08808, avg_loss=0.09022, mel_loss=0.03874, linear_loss=0.04934]
[2020-05-12 03:57:55.998]  Step 152219  [3.515 sec/step, loss=0.08035, avg_loss=0.09006, mel_loss=0.03431, linear_loss=0.04604]
[2020-05-12 03:57:57.147]  Step 152220  [3.443 sec/step, loss=0.08406, avg_loss=0.08994, mel_loss=0.03627, linear_loss=0.04779]
[2020-05-12 03:57:57.712]  Step 152221  [3.440 sec/step, loss=0.06939, avg_loss=0.08987, mel_loss=0.03033, linear_loss=0.03905]
[2020-05-12 03:57:58.688]  Step 152222  [3.306 sec/step, loss=0.08331, avg_loss=0.08992, mel_loss=0.03589, linear_loss=0.04742]
[2020-05-12 03:58:00.855]  Step 152223  [3.315 sec/step, loss=0.09105, avg_loss=0.08998, mel_loss=0.03997, linear_loss=0.05108]
[2020-05-12 03:58:03.908]  Step 152224  [3.311 sec/step, loss=0.09551, avg_loss=0.08999, mel_loss=0.04290, linear_loss=0.05261]
[2020-05-12 03:58:07.350]  Step 152225  [3.311 sec/step, loss=0.09664, avg_loss=0.08999, mel_loss=0.04334, linear_loss=0.05330]
[2020-05-12 03:58:14.994]  Step 152226  [3.369 sec/step, loss=0.09663, avg_loss=0.09007, mel_loss=0.04474, linear_loss=0.05190]
[2020-05-12 03:58:16.043]  Step 152227  [3.369 sec/step, loss=0.08425, avg_loss=0.09010, mel_loss=0.03610, linear_loss=0.04815]
[2020-05-12 03:58:18.496]  Step 152228  [3.369 sec/step, loss=0.09134, avg_loss=0.09010, mel_loss=0.04026, linear_loss=0.05108]
[2020-05-12 03:58:21.086]  Step 152229  [3.383 sec/step, loss=0.09176, avg_loss=0.09018, mel_loss=0.04070, linear_loss=0.05106]
[2020-05-12 03:58:23.042]  Step 152230  [3.350 sec/step, loss=0.09001, avg_loss=0.09010, mel_loss=0.03943, linear_loss=0.05058]
[2020-05-12 03:58:27.598]  Step 152231  [3.356 sec/step, loss=0.09771, avg_loss=0.09012, mel_loss=0.04416, linear_loss=0.05354]
[2020-05-12 03:58:40.714]  Step 152232  [3.466 sec/step, loss=0.08589, avg_loss=0.09007, mel_loss=0.04073, linear_loss=0.04516]
[2020-05-12 03:58:47.076]  Step 152233  [3.501 sec/step, loss=0.09616, avg_loss=0.09011, mel_loss=0.04413, linear_loss=0.05203]
[2020-05-12 03:58:50.449]  Step 152234  [3.519 sec/step, loss=0.09486, avg_loss=0.09017, mel_loss=0.04250, linear_loss=0.05236]
[2020-05-12 03:58:51.907]  Step 152235  [3.469 sec/step, loss=0.08791, avg_loss=0.09008, mel_loss=0.03829, linear_loss=0.04962]
[2020-05-12 03:58:53.688]  Generated 32 batches of size 32 in 1.775 sec
[2020-05-12 03:58:53.972]  Step 152236  [3.474 sec/step, loss=0.09213, avg_loss=0.09011, mel_loss=0.04054, linear_loss=0.05159]
[2020-05-12 03:58:54.965]  Step 152237  [3.436 sec/step, loss=0.07753, avg_loss=0.08992, mel_loss=0.03345, linear_loss=0.04408]
[2020-05-12 03:58:56.261]  Step 152238  [3.427 sec/step, loss=0.08360, avg_loss=0.08985, mel_loss=0.03635, linear_loss=0.04725]
[2020-05-12 03:59:00.605]  Step 152239  [3.462 sec/step, loss=0.09830, avg_loss=0.09005, mel_loss=0.04469, linear_loss=0.05360]
[2020-05-12 03:59:02.316]  Step 152240  [3.468 sec/step, loss=0.08792, avg_loss=0.09009, mel_loss=0.03832, linear_loss=0.04960]
[2020-05-12 03:59:07.303]  Step 152241  [3.480 sec/step, loss=0.09791, avg_loss=0.09009, mel_loss=0.04468, linear_loss=0.05322]
[2020-05-12 03:59:08.678]  Step 152242  [3.475 sec/step, loss=0.08562, avg_loss=0.09006, mel_loss=0.03744, linear_loss=0.04817]
[2020-05-12 03:59:09.507]  Step 152243  [3.453 sec/step, loss=0.07586, avg_loss=0.08987, mel_loss=0.03275, linear_loss=0.04311]
[2020-05-12 03:59:13.120]  Step 152244  [3.475 sec/step, loss=0.09720, avg_loss=0.08999, mel_loss=0.04369, linear_loss=0.05351]
[2020-05-12 03:59:13.926]  Step 152245  [3.477 sec/step, loss=0.07615, avg_loss=0.09004, mel_loss=0.03272, linear_loss=0.04343]
[2020-05-12 03:59:17.148]  Step 152246  [3.465 sec/step, loss=0.09444, avg_loss=0.09001, mel_loss=0.04216, linear_loss=0.05228]
[2020-05-12 03:59:19.406]  Step 152247  [3.412 sec/step, loss=0.09231, avg_loss=0.08995, mel_loss=0.04136, linear_loss=0.05095]
[2020-05-12 03:59:21.307]  Step 152248  [3.375 sec/step, loss=0.08741, avg_loss=0.08983, mel_loss=0.03847, linear_loss=0.04894]
[2020-05-12 03:59:22.935]  Step 152249  [3.360 sec/step, loss=0.09015, avg_loss=0.08976, mel_loss=0.03938, linear_loss=0.05077]
[2020-05-12 03:59:24.050]  Step 152250  [3.279 sec/step, loss=0.08573, avg_loss=0.08966, mel_loss=0.03695, linear_loss=0.04878]
[2020-05-12 03:59:24.050]  Writing summary at step: 152250
[2020-05-12 03:59:26.108]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152250
[2020-05-12 03:59:27.653]  Saving audio and alignment...
[2020-05-12 03:59:29.342]  Input: 당연히~__________________________
[2020-05-12 03:59:33.123]  Step 152251  [3.300 sec/step, loss=0.09534, avg_loss=0.08975, mel_loss=0.04291, linear_loss=0.05243]
[2020-05-12 03:59:38.650]  Step 152252  [3.288 sec/step, loss=0.09698, avg_loss=0.08975, mel_loss=0.04409, linear_loss=0.05289]
[2020-05-12 03:59:40.815]  Step 152253  [3.289 sec/step, loss=0.09138, avg_loss=0.08978, mel_loss=0.04049, linear_loss=0.05090]
[2020-05-12 03:59:42.213]  Step 152254  [3.171 sec/step, loss=0.08800, avg_loss=0.08984, mel_loss=0.03872, linear_loss=0.04928]
[2020-05-12 03:59:56.329]  Step 152255  [3.302 sec/step, loss=0.07276, avg_loss=0.08975, mel_loss=0.03459, linear_loss=0.03818]
[2020-05-12 03:59:57.334]  Step 152256  [3.278 sec/step, loss=0.08192, avg_loss=0.08962, mel_loss=0.03557, linear_loss=0.04635]
[2020-05-12 04:00:02.278]  Step 152257  [3.271 sec/step, loss=0.09839, avg_loss=0.08964, mel_loss=0.04484, linear_loss=0.05354]
[2020-05-12 04:00:04.717]  Step 152258  [3.273 sec/step, loss=0.09118, avg_loss=0.08964, mel_loss=0.04009, linear_loss=0.05110]
[2020-05-12 04:00:07.465]  Step 152259  [3.269 sec/step, loss=0.09157, avg_loss=0.08964, mel_loss=0.04112, linear_loss=0.05045]
[2020-05-12 04:00:08.732]  Step 152260  [3.228 sec/step, loss=0.08188, avg_loss=0.08949, mel_loss=0.03570, linear_loss=0.04619]
[2020-05-12 04:00:12.537]  Step 152261  [3.220 sec/step, loss=0.09679, avg_loss=0.08949, mel_loss=0.04365, linear_loss=0.05314]
[2020-05-12 04:00:20.068]  Step 152262  [3.245 sec/step, loss=0.09837, avg_loss=0.08953, mel_loss=0.04543, linear_loss=0.05295]
[2020-05-12 04:00:26.041]  Step 152263  [3.285 sec/step, loss=0.09686, avg_loss=0.08958, mel_loss=0.04447, linear_loss=0.05239]
[2020-05-12 04:00:26.952]  Step 152264  [3.260 sec/step, loss=0.08034, avg_loss=0.08943, mel_loss=0.03423, linear_loss=0.04611]
[2020-05-12 04:00:28.553]  Step 152265  [3.201 sec/step, loss=0.08810, avg_loss=0.08933, mel_loss=0.03849, linear_loss=0.04961]
[2020-05-12 04:00:30.317]  Generated 32 batches of size 32 in 1.758 sec
[2020-05-12 04:00:32.143]  Step 152266  [3.229 sec/step, loss=0.09443, avg_loss=0.08955, mel_loss=0.04226, linear_loss=0.05217]
[2020-05-12 04:00:33.971]  Step 152267  [3.219 sec/step, loss=0.08951, avg_loss=0.08953, mel_loss=0.03906, linear_loss=0.05046]
[2020-05-12 04:00:34.553]  Step 152268  [3.192 sec/step, loss=0.07098, avg_loss=0.08928, mel_loss=0.03122, linear_loss=0.03976]
[2020-05-12 04:00:42.806]  Step 152269  [3.262 sec/step, loss=0.09525, avg_loss=0.08939, mel_loss=0.04393, linear_loss=0.05132]
[2020-05-12 04:00:44.154]  Step 152270  [3.256 sec/step, loss=0.08552, avg_loss=0.08935, mel_loss=0.03695, linear_loss=0.04857]
[2020-05-12 04:00:47.179]  Step 152271  [3.273 sec/step, loss=0.09508, avg_loss=0.08946, mel_loss=0.04256, linear_loss=0.05252]
[2020-05-12 04:00:50.067]  Step 152272  [3.286 sec/step, loss=0.09462, avg_loss=0.08955, mel_loss=0.04230, linear_loss=0.05233]
[2020-05-12 04:00:54.233]  Step 152273  [3.316 sec/step, loss=0.09523, avg_loss=0.08972, mel_loss=0.04302, linear_loss=0.05221]
[2020-05-12 04:00:58.885]  Step 152274  [3.277 sec/step, loss=0.09815, avg_loss=0.08975, mel_loss=0.04456, linear_loss=0.05359]
[2020-05-12 04:01:04.146]  Step 152275  [3.303 sec/step, loss=0.09497, avg_loss=0.08979, mel_loss=0.04309, linear_loss=0.05188]
[2020-05-12 04:01:08.289]  Step 152276  [3.294 sec/step, loss=0.09544, avg_loss=0.08977, mel_loss=0.04289, linear_loss=0.05255]
[2020-05-12 04:01:09.599]  Step 152277  [3.293 sec/step, loss=0.08672, avg_loss=0.08979, mel_loss=0.03763, linear_loss=0.04910]
[2020-05-12 04:01:10.508]  Step 152278  [3.294 sec/step, loss=0.07926, avg_loss=0.08984, mel_loss=0.03410, linear_loss=0.04517]
[2020-05-12 04:01:11.747]  Step 152279  [3.278 sec/step, loss=0.08172, avg_loss=0.08975, mel_loss=0.03541, linear_loss=0.04631]
[2020-05-12 04:01:13.760]  Step 152280  [3.288 sec/step, loss=0.09128, avg_loss=0.08985, mel_loss=0.04032, linear_loss=0.05096]
[2020-05-12 04:01:16.462]  Step 152281  [3.227 sec/step, loss=0.09360, avg_loss=0.08982, mel_loss=0.04152, linear_loss=0.05208]
[2020-05-12 04:01:18.564]  Step 152282  [3.219 sec/step, loss=0.09050, avg_loss=0.08980, mel_loss=0.04023, linear_loss=0.05026]
[2020-05-12 04:01:26.094]  Step 152283  [3.281 sec/step, loss=0.09820, avg_loss=0.08992, mel_loss=0.04534, linear_loss=0.05285]
[2020-05-12 04:01:31.938]  Step 152284  [3.250 sec/step, loss=0.09776, avg_loss=0.08994, mel_loss=0.04479, linear_loss=0.05297]
[2020-05-12 04:01:38.288]  Step 152285  [3.304 sec/step, loss=0.09668, avg_loss=0.09009, mel_loss=0.04438, linear_loss=0.05230]
[2020-05-12 04:01:39.141]  Step 152286  [3.290 sec/step, loss=0.07586, avg_loss=0.08994, mel_loss=0.03240, linear_loss=0.04346]
[2020-05-12 04:01:42.668]  Step 152287  [3.288 sec/step, loss=0.09312, avg_loss=0.08989, mel_loss=0.04178, linear_loss=0.05134]
[2020-05-12 04:01:44.396]  Step 152288  [3.240 sec/step, loss=0.08935, avg_loss=0.08981, mel_loss=0.03891, linear_loss=0.05044]
[2020-05-12 04:01:45.163]  Step 152289  [3.213 sec/step, loss=0.07707, avg_loss=0.08964, mel_loss=0.03320, linear_loss=0.04388]
[2020-05-12 04:01:47.086]  Step 152290  [3.217 sec/step, loss=0.08953, avg_loss=0.08964, mel_loss=0.03921, linear_loss=0.05032]
[2020-05-12 04:01:49.935]  Step 152291  [3.218 sec/step, loss=0.09304, avg_loss=0.08963, mel_loss=0.04154, linear_loss=0.05149]
[2020-05-12 04:01:51.535]  Step 152292  [3.198 sec/step, loss=0.08862, avg_loss=0.08955, mel_loss=0.03881, linear_loss=0.04981]
[2020-05-12 04:01:56.256]  Step 152293  [3.239 sec/step, loss=0.09730, avg_loss=0.08984, mel_loss=0.04387, linear_loss=0.05343]
[2020-05-12 04:01:59.677]  Step 152294  [3.221 sec/step, loss=0.09694, avg_loss=0.08984, mel_loss=0.04345, linear_loss=0.05349]
[2020-05-12 04:02:08.288]  Step 152295  [3.295 sec/step, loss=0.09565, avg_loss=0.08995, mel_loss=0.04422, linear_loss=0.05142]
[2020-05-12 04:02:10.710]  Step 152296  [3.294 sec/step, loss=0.09178, avg_loss=0.08994, mel_loss=0.04045, linear_loss=0.05133]
[2020-05-12 04:02:25.364]  Step 152297  [3.423 sec/step, loss=0.07659, avg_loss=0.08982, mel_loss=0.03626, linear_loss=0.04032]
[2020-05-12 04:02:27.110]  Generated 32 batches of size 32 in 1.740 sec
[2020-05-12 04:02:28.522]  Step 152298  [3.420 sec/step, loss=0.09357, avg_loss=0.08979, mel_loss=0.04173, linear_loss=0.05184]
[2020-05-12 04:02:29.666]  Step 152299  [3.287 sec/step, loss=0.08366, avg_loss=0.08987, mel_loss=0.03594, linear_loss=0.04772]
[2020-05-12 04:02:34.133]  Step 152300  [3.274 sec/step, loss=0.09638, avg_loss=0.08983, mel_loss=0.04371, linear_loss=0.05266]
[2020-05-12 04:02:34.133]  Writing summary at step: 152300
[2020-05-12 04:02:34.709]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152300
[2020-05-12 04:02:36.224]  Saving audio and alignment...
[2020-05-12 04:02:39.444]  Input: 대본을 악보화 하자~______________________
[2020-05-12 04:02:40.944]  Step 152301  [3.278 sec/step, loss=0.08495, avg_loss=0.08982, mel_loss=0.03735, linear_loss=0.04760]
[2020-05-12 04:02:44.667]  Step 152302  [3.267 sec/step, loss=0.09579, avg_loss=0.08980, mel_loss=0.04306, linear_loss=0.05274]
[2020-05-12 04:02:45.736]  Step 152303  [3.258 sec/step, loss=0.08017, avg_loss=0.08970, mel_loss=0.03465, linear_loss=0.04552]
[2020-05-12 04:02:48.298]  Step 152304  [3.275 sec/step, loss=0.09175, avg_loss=0.08985, mel_loss=0.04043, linear_loss=0.05132]
[2020-05-12 04:02:49.666]  Step 152305  [3.269 sec/step, loss=0.08448, avg_loss=0.08976, mel_loss=0.03667, linear_loss=0.04781]
[2020-05-12 04:02:50.815]  Step 152306  [3.251 sec/step, loss=0.08197, avg_loss=0.08962, mel_loss=0.03551, linear_loss=0.04646]
[2020-05-12 04:02:53.142]  Step 152307  [3.258 sec/step, loss=0.09316, avg_loss=0.08964, mel_loss=0.04134, linear_loss=0.05182]
[2020-05-12 04:02:55.343]  Step 152308  [3.271 sec/step, loss=0.09174, avg_loss=0.08977, mel_loss=0.04037, linear_loss=0.05136]
[2020-05-12 04:02:56.881]  Step 152309  [3.263 sec/step, loss=0.08740, avg_loss=0.08971, mel_loss=0.03805, linear_loss=0.04935]
[2020-05-12 04:02:58.299]  Step 152310  [3.269 sec/step, loss=0.08719, avg_loss=0.08986, mel_loss=0.03805, linear_loss=0.04913]
[2020-05-12 04:03:01.043]  Step 152311  [3.281 sec/step, loss=0.09179, avg_loss=0.08989, mel_loss=0.04102, linear_loss=0.05077]
[2020-05-12 04:03:06.819]  Step 152312  [3.265 sec/step, loss=0.09679, avg_loss=0.08985, mel_loss=0.04419, linear_loss=0.05260]
[2020-05-12 04:03:08.657]  Step 152313  [3.241 sec/step, loss=0.08717, avg_loss=0.08977, mel_loss=0.03839, linear_loss=0.04878]
[2020-05-12 04:03:16.599]  Step 152314  [3.265 sec/step, loss=0.09747, avg_loss=0.08976, mel_loss=0.04503, linear_loss=0.05244]
[2020-05-12 04:03:17.155]  Step 152315  [3.242 sec/step, loss=0.07404, avg_loss=0.08958, mel_loss=0.03285, linear_loss=0.04119]
[2020-05-12 04:03:22.333]  Step 152316  [3.269 sec/step, loss=0.09541, avg_loss=0.08959, mel_loss=0.04355, linear_loss=0.05187]
[2020-05-12 04:03:25.571]  Step 152317  [3.213 sec/step, loss=0.09605, avg_loss=0.08958, mel_loss=0.04323, linear_loss=0.05282]
[2020-05-12 04:03:34.896]  Step 152318  [3.290 sec/step, loss=0.09733, avg_loss=0.08967, mel_loss=0.04535, linear_loss=0.05198]
[2020-05-12 04:03:39.072]  Step 152319  [3.324 sec/step, loss=0.09708, avg_loss=0.08984, mel_loss=0.04374, linear_loss=0.05334]
[2020-05-12 04:03:42.105]  Step 152320  [3.343 sec/step, loss=0.09443, avg_loss=0.08994, mel_loss=0.04183, linear_loss=0.05260]
[2020-05-12 04:03:46.264]  Step 152321  [3.379 sec/step, loss=0.09780, avg_loss=0.09022, mel_loss=0.04403, linear_loss=0.05377]
[2020-05-12 04:03:47.286]  Step 152322  [3.380 sec/step, loss=0.08394, avg_loss=0.09023, mel_loss=0.03610, linear_loss=0.04784]
[2020-05-12 04:03:50.814]  Step 152323  [3.393 sec/step, loss=0.09607, avg_loss=0.09028, mel_loss=0.04335, linear_loss=0.05273]
[2020-05-12 04:03:51.706]  Step 152324  [3.372 sec/step, loss=0.07267, avg_loss=0.09005, mel_loss=0.03187, linear_loss=0.04079]
[2020-05-12 04:03:56.220]  Step 152325  [3.382 sec/step, loss=0.09824, avg_loss=0.09007, mel_loss=0.04478, linear_loss=0.05346]
[2020-05-12 04:03:58.169]  Step 152326  [3.325 sec/step, loss=0.08672, avg_loss=0.08997, mel_loss=0.03777, linear_loss=0.04895]
[2020-05-12 04:03:59.846]  Step 152327  [3.332 sec/step, loss=0.08876, avg_loss=0.09001, mel_loss=0.03877, linear_loss=0.04998]
[2020-05-12 04:04:01.578]  Generated 32 batches of size 32 in 1.727 sec
[2020-05-12 04:04:03.392]  Step 152328  [3.343 sec/step, loss=0.09521, avg_loss=0.09005, mel_loss=0.04285, linear_loss=0.05235]
[2020-05-12 04:04:04.236]  Step 152329  [3.325 sec/step, loss=0.07803, avg_loss=0.08992, mel_loss=0.03358, linear_loss=0.04444]
[2020-05-12 04:04:16.691]  Step 152330  [3.430 sec/step, loss=0.08979, avg_loss=0.08991, mel_loss=0.04277, linear_loss=0.04702]
[2020-05-12 04:04:20.363]  Step 152331  [3.421 sec/step, loss=0.09575, avg_loss=0.08989, mel_loss=0.04304, linear_loss=0.05270]
[2020-05-12 04:04:22.870]  Step 152332  [3.315 sec/step, loss=0.09197, avg_loss=0.08995, mel_loss=0.04088, linear_loss=0.05109]
[2020-05-12 04:04:24.888]  Step 152333  [3.272 sec/step, loss=0.08941, avg_loss=0.08989, mel_loss=0.03958, linear_loss=0.04983]
[2020-05-12 04:04:26.058]  Step 152334  [3.250 sec/step, loss=0.08161, avg_loss=0.08975, mel_loss=0.03524, linear_loss=0.04637]
[2020-05-12 04:04:27.077]  Step 152335  [3.245 sec/step, loss=0.07967, avg_loss=0.08967, mel_loss=0.03423, linear_loss=0.04544]
[2020-05-12 04:04:33.524]  Step 152336  [3.289 sec/step, loss=0.09755, avg_loss=0.08973, mel_loss=0.04479, linear_loss=0.05275]
[2020-05-12 04:04:34.672]  Step 152337  [3.291 sec/step, loss=0.08140, avg_loss=0.08977, mel_loss=0.03509, linear_loss=0.04631]
[2020-05-12 04:04:39.472]  Step 152338  [3.326 sec/step, loss=0.09778, avg_loss=0.08991, mel_loss=0.04393, linear_loss=0.05385]
[2020-05-12 04:04:47.858]  Step 152339  [3.366 sec/step, loss=0.09555, avg_loss=0.08988, mel_loss=0.04426, linear_loss=0.05129]
[2020-05-12 04:04:48.426]  Step 152340  [3.355 sec/step, loss=0.06979, avg_loss=0.08970, mel_loss=0.03065, linear_loss=0.03914]
[2020-05-12 04:04:52.156]  Step 152341  [3.342 sec/step, loss=0.09745, avg_loss=0.08969, mel_loss=0.04385, linear_loss=0.05360]
[2020-05-12 04:04:59.685]  Step 152342  [3.404 sec/step, loss=0.09885, avg_loss=0.08983, mel_loss=0.04552, linear_loss=0.05333]
[2020-05-12 04:05:02.164]  Step 152343  [3.420 sec/step, loss=0.09237, avg_loss=0.08999, mel_loss=0.04066, linear_loss=0.05171]
[2020-05-12 04:05:03.761]  Step 152344  [3.400 sec/step, loss=0.08834, avg_loss=0.08990, mel_loss=0.03907, linear_loss=0.04927]
[2020-05-12 04:05:06.693]  Step 152345  [3.421 sec/step, loss=0.09262, avg_loss=0.09007, mel_loss=0.04147, linear_loss=0.05115]
[2020-05-12 04:05:12.128]  Step 152346  [3.444 sec/step, loss=0.09599, avg_loss=0.09008, mel_loss=0.04370, linear_loss=0.05229]
[2020-05-12 04:05:18.835]  Step 152347  [3.488 sec/step, loss=0.09773, avg_loss=0.09014, mel_loss=0.04479, linear_loss=0.05294]
[2020-05-12 04:05:20.719]  Step 152348  [3.488 sec/step, loss=0.08555, avg_loss=0.09012, mel_loss=0.03739, linear_loss=0.04816]
[2020-05-12 04:05:21.692]  Step 152349  [3.481 sec/step, loss=0.07769, avg_loss=0.08999, mel_loss=0.03381, linear_loss=0.04388]
[2020-05-12 04:05:28.105]  Step 152350  [3.534 sec/step, loss=0.09514, avg_loss=0.09009, mel_loss=0.04279, linear_loss=0.05234]
[2020-05-12 04:05:28.105]  Writing summary at step: 152350
[2020-05-12 04:05:32.481]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152350
[2020-05-12 04:05:34.813]  Saving audio and alignment...
[2020-05-12 04:05:40.545]  Input: 습도가 조금만 높아도 잎사귀에 곰팡이가 생겼고요~_____________________
[2020-05-12 04:05:41.942]  Step 152351  [3.510 sec/step, loss=0.08380, avg_loss=0.08997, mel_loss=0.03672, linear_loss=0.04708]
[2020-05-12 04:05:48.124]  Step 152352  [3.517 sec/step, loss=0.09945, avg_loss=0.09000, mel_loss=0.04567, linear_loss=0.05379]
[2020-05-12 04:05:48.896]  Step 152353  [3.503 sec/step, loss=0.08091, avg_loss=0.08989, mel_loss=0.03474, linear_loss=0.04617]
[2020-05-12 04:05:50.991]  Step 152354  [3.510 sec/step, loss=0.09023, avg_loss=0.08991, mel_loss=0.03959, linear_loss=0.05064]
[2020-05-12 04:05:52.844]  Step 152355  [3.387 sec/step, loss=0.08776, avg_loss=0.09006, mel_loss=0.03844, linear_loss=0.04932]
[2020-05-12 04:05:53.892]  Step 152356  [3.388 sec/step, loss=0.08097, avg_loss=0.09006, mel_loss=0.03537, linear_loss=0.04560]
[2020-05-12 04:06:08.661]  Step 152357  [3.486 sec/step, loss=0.07388, avg_loss=0.08981, mel_loss=0.03499, linear_loss=0.03888]
[2020-05-12 04:06:10.518]  Generated 32 batches of size 32 in 1.851 sec
[2020-05-12 04:06:11.218]  Step 152358  [3.487 sec/step, loss=0.09122, avg_loss=0.08981, mel_loss=0.04040, linear_loss=0.05082]
[2020-05-12 04:06:14.738]  Step 152359  [3.495 sec/step, loss=0.09719, avg_loss=0.08987, mel_loss=0.04343, linear_loss=0.05376]
[2020-05-12 04:06:15.754]  Step 152360  [3.492 sec/step, loss=0.07860, avg_loss=0.08983, mel_loss=0.03391, linear_loss=0.04469]
[2020-05-12 04:06:17.993]  Step 152361  [3.477 sec/step, loss=0.09136, avg_loss=0.08978, mel_loss=0.04053, linear_loss=0.05083]
[2020-05-12 04:06:19.774]  Step 152362  [3.419 sec/step, loss=0.09091, avg_loss=0.08970, mel_loss=0.03982, linear_loss=0.05109]
[2020-05-12 04:06:21.137]  Step 152363  [3.373 sec/step, loss=0.08584, avg_loss=0.08959, mel_loss=0.03753, linear_loss=0.04831]
[2020-05-12 04:06:25.588]  Step 152364  [3.409 sec/step, loss=0.09699, avg_loss=0.08976, mel_loss=0.04410, linear_loss=0.05289]
[2020-05-12 04:06:28.665]  Step 152365  [3.423 sec/step, loss=0.09555, avg_loss=0.08984, mel_loss=0.04265, linear_loss=0.05291]
[2020-05-12 04:06:30.601]  Step 152366  [3.407 sec/step, loss=0.09053, avg_loss=0.08980, mel_loss=0.03967, linear_loss=0.05087]
[2020-05-12 04:06:36.683]  Step 152367  [3.449 sec/step, loss=0.09733, avg_loss=0.08987, mel_loss=0.04446, linear_loss=0.05287]
[2020-05-12 04:06:38.489]  Step 152368  [3.462 sec/step, loss=0.08946, avg_loss=0.09006, mel_loss=0.03942, linear_loss=0.05004]
[2020-05-12 04:06:39.524]  Step 152369  [3.389 sec/step, loss=0.08493, avg_loss=0.08996, mel_loss=0.03679, linear_loss=0.04815]
[2020-05-12 04:06:41.423]  Step 152370  [3.395 sec/step, loss=0.08872, avg_loss=0.08999, mel_loss=0.03875, linear_loss=0.04996]
[2020-05-12 04:06:43.038]  Step 152371  [3.381 sec/step, loss=0.08886, avg_loss=0.08993, mel_loss=0.03881, linear_loss=0.05005]
[2020-05-12 04:06:46.094]  Step 152372  [3.382 sec/step, loss=0.09637, avg_loss=0.08994, mel_loss=0.04322, linear_loss=0.05315]
[2020-05-12 04:06:48.371]  Step 152373  [3.364 sec/step, loss=0.09022, avg_loss=0.08989, mel_loss=0.04007, linear_loss=0.05014]
[2020-05-12 04:06:49.341]  Step 152374  [3.327 sec/step, loss=0.08241, avg_loss=0.08974, mel_loss=0.03550, linear_loss=0.04691]
[2020-05-12 04:06:54.798]  Step 152375  [3.329 sec/step, loss=0.09748, avg_loss=0.08976, mel_loss=0.04443, linear_loss=0.05306]
[2020-05-12 04:06:56.195]  Step 152376  [3.301 sec/step, loss=0.08574, avg_loss=0.08966, mel_loss=0.03738, linear_loss=0.04836]
[2020-05-12 04:06:59.173]  Step 152377  [3.318 sec/step, loss=0.09369, avg_loss=0.08973, mel_loss=0.04182, linear_loss=0.05187]
[2020-05-12 04:07:00.030]  Step 152378  [3.317 sec/step, loss=0.07619, avg_loss=0.08970, mel_loss=0.03314, linear_loss=0.04305]
[2020-05-12 04:07:01.069]  Step 152379  [3.315 sec/step, loss=0.08112, avg_loss=0.08970, mel_loss=0.03476, linear_loss=0.04635]
[2020-05-12 04:07:08.187]  Step 152380  [3.366 sec/step, loss=0.09745, avg_loss=0.08976, mel_loss=0.04459, linear_loss=0.05286]
[2020-05-12 04:07:08.754]  Step 152381  [3.345 sec/step, loss=0.06710, avg_loss=0.08949, mel_loss=0.02941, linear_loss=0.03769]
[2020-05-12 04:07:10.754]  Step 152382  [3.344 sec/step, loss=0.09108, avg_loss=0.08950, mel_loss=0.04010, linear_loss=0.05098]
[2020-05-12 04:07:11.519]  Step 152383  [3.276 sec/step, loss=0.08105, avg_loss=0.08933, mel_loss=0.03463, linear_loss=0.04642]
[2020-05-12 04:07:14.284]  Step 152384  [3.246 sec/step, loss=0.09322, avg_loss=0.08928, mel_loss=0.04166, linear_loss=0.05156]
[2020-05-12 04:07:17.833]  Step 152385  [3.218 sec/step, loss=0.09409, avg_loss=0.08926, mel_loss=0.04209, linear_loss=0.05200]
[2020-05-12 04:07:22.653]  Step 152386  [3.257 sec/step, loss=0.09771, avg_loss=0.08948, mel_loss=0.04408, linear_loss=0.05362]
[2020-05-12 04:07:28.298]  Step 152387  [3.279 sec/step, loss=0.09720, avg_loss=0.08952, mel_loss=0.04431, linear_loss=0.05289]
[2020-05-12 04:07:40.656]  Step 152388  [3.385 sec/step, loss=0.08880, avg_loss=0.08951, mel_loss=0.04217, linear_loss=0.04663]
[2020-05-12 04:07:44.900]  Step 152389  [3.420 sec/step, loss=0.09739, avg_loss=0.08971, mel_loss=0.04380, linear_loss=0.05359]
[2020-05-12 04:07:46.144]  Step 152390  [3.413 sec/step, loss=0.08302, avg_loss=0.08965, mel_loss=0.03580, linear_loss=0.04722]
[2020-05-12 04:07:46.663]  Generated 32 batches of size 32 in 1.758 sec
[2020-05-12 04:07:47.696]  Step 152391  [3.400 sec/step, loss=0.08811, avg_loss=0.08960, mel_loss=0.03843, linear_loss=0.04967]
[2020-05-12 04:07:51.377]  Step 152392  [3.421 sec/step, loss=0.09759, avg_loss=0.08969, mel_loss=0.04392, linear_loss=0.05367]
[2020-05-12 04:07:52.689]  Step 152393  [3.387 sec/step, loss=0.08271, avg_loss=0.08954, mel_loss=0.03620, linear_loss=0.04650]
[2020-05-12 04:08:01.559]  Step 152394  [3.441 sec/step, loss=0.09507, avg_loss=0.08952, mel_loss=0.04404, linear_loss=0.05103]
[2020-05-12 04:08:05.800]  Step 152395  [3.397 sec/step, loss=0.09699, avg_loss=0.08954, mel_loss=0.04403, linear_loss=0.05296]
[2020-05-12 04:08:08.349]  Step 152396  [3.399 sec/step, loss=0.09111, avg_loss=0.08953, mel_loss=0.04007, linear_loss=0.05104]
[2020-05-12 04:08:11.806]  Step 152397  [3.287 sec/step, loss=0.09530, avg_loss=0.08972, mel_loss=0.04282, linear_loss=0.05248]
[2020-05-12 04:08:13.929]  Step 152398  [3.276 sec/step, loss=0.09124, avg_loss=0.08970, mel_loss=0.04049, linear_loss=0.05075]
[2020-05-12 04:08:15.997]  Step 152399  [3.286 sec/step, loss=0.09004, avg_loss=0.08976, mel_loss=0.03977, linear_loss=0.05027]
[2020-05-12 04:08:17.035]  Step 152400  [3.251 sec/step, loss=0.08219, avg_loss=0.08962, mel_loss=0.03554, linear_loss=0.04665]
[2020-05-12 04:08:17.035]  Writing summary at step: 152400
[2020-05-12 04:08:20.554]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152400
[2020-05-12 04:08:22.069]  Saving audio and alignment...
[2020-05-12 04:08:29.067]  Input: 리포터와 클럽에이스 어린이 사이의 불꽃 튀는 진검승부가 펼쳐지는데요~___________________
[2020-05-12 04:08:36.753]  Step 152401  [3.313 sec/step, loss=0.09899, avg_loss=0.08976, mel_loss=0.04573, linear_loss=0.05327]
[2020-05-12 04:08:38.204]  Step 152402  [3.290 sec/step, loss=0.08698, avg_loss=0.08967, mel_loss=0.03819, linear_loss=0.04879]
[2020-05-12 04:08:45.048]  Step 152403  [3.348 sec/step, loss=0.09892, avg_loss=0.08986, mel_loss=0.04559, linear_loss=0.05334]
[2020-05-12 04:08:46.783]  Step 152404  [3.340 sec/step, loss=0.08989, avg_loss=0.08984, mel_loss=0.03930, linear_loss=0.05059]
[2020-05-12 04:08:48.728]  Step 152405  [3.346 sec/step, loss=0.08892, avg_loss=0.08988, mel_loss=0.03929, linear_loss=0.04963]
[2020-05-12 04:08:53.671]  Step 152406  [3.384 sec/step, loss=0.09610, avg_loss=0.09002, mel_loss=0.04375, linear_loss=0.05236]
[2020-05-12 04:08:56.880]  Step 152407  [3.392 sec/step, loss=0.09501, avg_loss=0.09004, mel_loss=0.04241, linear_loss=0.05261]
[2020-05-12 04:08:59.591]  Step 152408  [3.397 sec/step, loss=0.09183, avg_loss=0.09004, mel_loss=0.04092, linear_loss=0.05090]
[2020-05-12 04:09:14.457]  Step 152409  [3.531 sec/step, loss=0.07503, avg_loss=0.08992, mel_loss=0.03556, linear_loss=0.03948]
[2020-05-12 04:09:18.094]  Step 152410  [3.553 sec/step, loss=0.09495, avg_loss=0.09000, mel_loss=0.04240, linear_loss=0.05254]
[2020-05-12 04:09:21.788]  Step 152411  [3.562 sec/step, loss=0.09756, avg_loss=0.09006, mel_loss=0.04382, linear_loss=0.05374]
[2020-05-12 04:09:22.597]  Step 152412  [3.513 sec/step, loss=0.07229, avg_loss=0.08981, mel_loss=0.03128, linear_loss=0.04101]
[2020-05-12 04:09:24.387]  Step 152413  [3.512 sec/step, loss=0.08766, avg_loss=0.08982, mel_loss=0.03818, linear_loss=0.04948]
[2020-05-12 04:09:25.266]  Step 152414  [3.442 sec/step, loss=0.08039, avg_loss=0.08964, mel_loss=0.03439, linear_loss=0.04600]
[2020-05-12 04:09:31.012]  Step 152415  [3.494 sec/step, loss=0.09667, avg_loss=0.08987, mel_loss=0.04430, linear_loss=0.05236]
[2020-05-12 04:09:34.429]  Step 152416  [3.476 sec/step, loss=0.09564, avg_loss=0.08987, mel_loss=0.04292, linear_loss=0.05272]
[2020-05-12 04:09:35.542]  Step 152417  [3.455 sec/step, loss=0.08518, avg_loss=0.08976, mel_loss=0.03644, linear_loss=0.04874]
[2020-05-12 04:09:36.069]  Step 152418  [3.367 sec/step, loss=0.07355, avg_loss=0.08953, mel_loss=0.03287, linear_loss=0.04068]
[2020-05-12 04:09:38.313]  Step 152419  [3.347 sec/step, loss=0.08953, avg_loss=0.08945, mel_loss=0.03949, linear_loss=0.05004]
[2020-05-12 04:09:40.443]  Generated 32 batches of size 32 in 2.124 sec
[2020-05-12 04:09:40.810]  Step 152420  [3.342 sec/step, loss=0.09516, avg_loss=0.08946, mel_loss=0.04236, linear_loss=0.05280]
[2020-05-12 04:09:45.107]  Step 152421  [3.343 sec/step, loss=0.09630, avg_loss=0.08944, mel_loss=0.04362, linear_loss=0.05269]
[2020-05-12 04:09:46.474]  Step 152422  [3.347 sec/step, loss=0.08859, avg_loss=0.08949, mel_loss=0.03857, linear_loss=0.05002]
[2020-05-12 04:09:50.508]  Step 152423  [3.352 sec/step, loss=0.09609, avg_loss=0.08949, mel_loss=0.04305, linear_loss=0.05304]
[2020-05-12 04:09:52.140]  Step 152424  [3.359 sec/step, loss=0.08796, avg_loss=0.08964, mel_loss=0.03877, linear_loss=0.04919]
[2020-05-12 04:09:53.335]  Step 152425  [3.326 sec/step, loss=0.08467, avg_loss=0.08951, mel_loss=0.03694, linear_loss=0.04772]
[2020-05-12 04:09:54.147]  Step 152426  [3.315 sec/step, loss=0.07641, avg_loss=0.08940, mel_loss=0.03287, linear_loss=0.04353]
[2020-05-12 04:09:56.707]  Step 152427  [3.324 sec/step, loss=0.09200, avg_loss=0.08944, mel_loss=0.04087, linear_loss=0.05113]
[2020-05-12 04:10:05.552]  Step 152428  [3.377 sec/step, loss=0.09617, avg_loss=0.08945, mel_loss=0.04480, linear_loss=0.05137]
[2020-05-12 04:10:08.874]  Step 152429  [3.401 sec/step, loss=0.09479, avg_loss=0.08961, mel_loss=0.04225, linear_loss=0.05254]
[2020-05-12 04:10:11.659]  Step 152430  [3.305 sec/step, loss=0.09099, avg_loss=0.08963, mel_loss=0.04071, linear_loss=0.05028]
[2020-05-12 04:10:16.036]  Step 152431  [3.312 sec/step, loss=0.09611, avg_loss=0.08963, mel_loss=0.04341, linear_loss=0.05270]
[2020-05-12 04:10:20.148]  Step 152432  [3.328 sec/step, loss=0.09667, avg_loss=0.08968, mel_loss=0.04344, linear_loss=0.05324]
[2020-05-12 04:10:26.287]  Step 152433  [3.369 sec/step, loss=0.09686, avg_loss=0.08975, mel_loss=0.04432, linear_loss=0.05254]
[2020-05-12 04:10:27.898]  Step 152434  [3.373 sec/step, loss=0.08921, avg_loss=0.08983, mel_loss=0.03913, linear_loss=0.05008]
[2020-05-12 04:10:29.116]  Step 152435  [3.375 sec/step, loss=0.08444, avg_loss=0.08987, mel_loss=0.03682, linear_loss=0.04762]
[2020-05-12 04:10:32.053]  Step 152436  [3.340 sec/step, loss=0.09204, avg_loss=0.08982, mel_loss=0.04116, linear_loss=0.05088]
[2020-05-12 04:10:33.728]  Step 152437  [3.346 sec/step, loss=0.08770, avg_loss=0.08988, mel_loss=0.03803, linear_loss=0.04967]
[2020-05-12 04:10:35.575]  Step 152438  [3.316 sec/step, loss=0.08880, avg_loss=0.08979, mel_loss=0.03854, linear_loss=0.05027]
[2020-05-12 04:10:41.373]  Step 152439  [3.290 sec/step, loss=0.09691, avg_loss=0.08981, mel_loss=0.04445, linear_loss=0.05246]
[2020-05-12 04:10:42.140]  Step 152440  [3.292 sec/step, loss=0.08049, avg_loss=0.08991, mel_loss=0.03442, linear_loss=0.04607]
[2020-05-12 04:10:44.116]  Step 152441  [3.275 sec/step, loss=0.08674, avg_loss=0.08981, mel_loss=0.03766, linear_loss=0.04908]
[2020-05-12 04:10:45.317]  Step 152442  [3.211 sec/step, loss=0.08346, avg_loss=0.08965, mel_loss=0.03608, linear_loss=0.04737]
[2020-05-12 04:10:47.932]  Step 152443  [3.213 sec/step, loss=0.09156, avg_loss=0.08964, mel_loss=0.04041, linear_loss=0.05115]
[2020-05-12 04:10:55.197]  Step 152444  [3.269 sec/step, loss=0.09946, avg_loss=0.08976, mel_loss=0.04593, linear_loss=0.05353]
[2020-05-12 04:10:56.550]  Step 152445  [3.254 sec/step, loss=0.08859, avg_loss=0.08972, mel_loss=0.03863, linear_loss=0.04995]
[2020-05-12 04:11:01.448]  Step 152446  [3.248 sec/step, loss=0.09729, avg_loss=0.08973, mel_loss=0.04400, linear_loss=0.05329]
[2020-05-12 04:11:04.925]  Step 152447  [3.216 sec/step, loss=0.09368, avg_loss=0.08969, mel_loss=0.04210, linear_loss=0.05158]
[2020-05-12 04:11:05.754]  Step 152448  [3.205 sec/step, loss=0.07744, avg_loss=0.08961, mel_loss=0.03374, linear_loss=0.04370]
[2020-05-12 04:11:07.757]  Step 152449  [3.216 sec/step, loss=0.08977, avg_loss=0.08973, mel_loss=0.03969, linear_loss=0.05007]
[2020-05-12 04:11:11.377]  Step 152450  [3.188 sec/step, loss=0.09707, avg_loss=0.08975, mel_loss=0.04353, linear_loss=0.05354]
[2020-05-12 04:11:11.377]  Writing summary at step: 152450
[2020-05-12 04:11:13.516]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152450
[2020-05-12 04:11:15.029]  Saving audio and alignment...
[2020-05-12 04:11:17.341]  Generated 32 batches of size 32 in 1.723 sec
[2020-05-12 04:11:19.246]  Input: 하락장하강 마이너스 의미거든요~_____________
[2020-05-12 04:11:27.468]  Step 152451  [3.256 sec/step, loss=0.09436, avg_loss=0.08985, mel_loss=0.04354, linear_loss=0.05082]
[2020-05-12 04:11:30.734]  Step 152452  [3.227 sec/step, loss=0.09753, avg_loss=0.08983, mel_loss=0.04366, linear_loss=0.05387]
[2020-05-12 04:11:31.636]  Step 152453  [3.228 sec/step, loss=0.07795, avg_loss=0.08980, mel_loss=0.03363, linear_loss=0.04432]
[2020-05-12 04:11:32.607]  Step 152454  [3.217 sec/step, loss=0.08290, avg_loss=0.08973, mel_loss=0.03582, linear_loss=0.04708]
[2020-05-12 04:11:33.176]  Step 152455  [3.204 sec/step, loss=0.06938, avg_loss=0.08955, mel_loss=0.03034, linear_loss=0.03903]
[2020-05-12 04:11:47.535]  Step 152456  [3.337 sec/step, loss=0.07451, avg_loss=0.08948, mel_loss=0.03527, linear_loss=0.03923]
[2020-05-12 04:11:48.870]  Step 152457  [3.203 sec/step, loss=0.08504, avg_loss=0.08959, mel_loss=0.03713, linear_loss=0.04791]
[2020-05-12 04:11:53.439]  Step 152458  [3.223 sec/step, loss=0.09738, avg_loss=0.08965, mel_loss=0.04397, linear_loss=0.05341]
[2020-05-12 04:12:02.356]  Step 152459  [3.277 sec/step, loss=0.09781, avg_loss=0.08966, mel_loss=0.04523, linear_loss=0.05258]
[2020-05-12 04:12:08.058]  Step 152460  [3.324 sec/step, loss=0.09745, avg_loss=0.08985, mel_loss=0.04443, linear_loss=0.05302]
[2020-05-12 04:12:12.755]  Step 152461  [3.348 sec/step, loss=0.09637, avg_loss=0.08990, mel_loss=0.04381, linear_loss=0.05256]
[2020-05-12 04:12:14.502]  Step 152462  [3.348 sec/step, loss=0.08800, avg_loss=0.08987, mel_loss=0.03871, linear_loss=0.04930]
[2020-05-12 04:12:15.297]  Step 152463  [3.342 sec/step, loss=0.07433, avg_loss=0.08976, mel_loss=0.03219, linear_loss=0.04214]
[2020-05-12 04:12:17.804]  Step 152464  [3.323 sec/step, loss=0.09116, avg_loss=0.08970, mel_loss=0.04027, linear_loss=0.05089]
[2020-05-12 04:12:20.523]  Step 152465  [3.319 sec/step, loss=0.09286, avg_loss=0.08967, mel_loss=0.04128, linear_loss=0.05158]
[2020-05-12 04:12:22.754]  Step 152466  [3.322 sec/step, loss=0.08904, avg_loss=0.08966, mel_loss=0.03938, linear_loss=0.04966]
[2020-05-12 04:12:23.906]  Step 152467  [3.273 sec/step, loss=0.08048, avg_loss=0.08949, mel_loss=0.03454, linear_loss=0.04594]
[2020-05-12 04:12:25.385]  Step 152468  [3.270 sec/step, loss=0.08707, avg_loss=0.08946, mel_loss=0.03811, linear_loss=0.04896]
[2020-05-12 04:12:26.757]  Step 152469  [3.273 sec/step, loss=0.08516, avg_loss=0.08947, mel_loss=0.03725, linear_loss=0.04791]
[2020-05-12 04:12:29.842]  Step 152470  [3.285 sec/step, loss=0.09662, avg_loss=0.08954, mel_loss=0.04335, linear_loss=0.05327]
[2020-05-12 04:12:35.195]  Step 152471  [3.322 sec/step, loss=0.09523, avg_loss=0.08961, mel_loss=0.04330, linear_loss=0.05193]
[2020-05-12 04:12:38.572]  Step 152472  [3.326 sec/step, loss=0.09435, avg_loss=0.08959, mel_loss=0.04238, linear_loss=0.05197]
[2020-05-12 04:12:40.540]  Step 152473  [3.322 sec/step, loss=0.09214, avg_loss=0.08961, mel_loss=0.04063, linear_loss=0.05151]
[2020-05-12 04:12:42.148]  Step 152474  [3.329 sec/step, loss=0.08756, avg_loss=0.08966, mel_loss=0.03846, linear_loss=0.04910]
[2020-05-12 04:12:44.121]  Step 152475  [3.294 sec/step, loss=0.08824, avg_loss=0.08957, mel_loss=0.03880, linear_loss=0.04944]
[2020-05-12 04:12:56.505]  Step 152476  [3.404 sec/step, loss=0.08997, avg_loss=0.08961, mel_loss=0.04252, linear_loss=0.04745]
[2020-05-12 04:12:57.354]  Step 152477  [3.383 sec/step, loss=0.07610, avg_loss=0.08943, mel_loss=0.03267, linear_loss=0.04342]
[2020-05-12 04:12:58.394]  Step 152478  [3.384 sec/step, loss=0.08043, avg_loss=0.08947, mel_loss=0.03480, linear_loss=0.04563]
[2020-05-12 04:13:00.842]  Step 152479  [3.398 sec/step, loss=0.09082, avg_loss=0.08957, mel_loss=0.04002, linear_loss=0.05080]
[2020-05-12 04:13:02.099]  Step 152480  [3.340 sec/step, loss=0.08426, avg_loss=0.08944, mel_loss=0.03652, linear_loss=0.04774]
[2020-05-12 04:13:06.244]  Step 152481  [3.376 sec/step, loss=0.09524, avg_loss=0.08972, mel_loss=0.04287, linear_loss=0.05237]
[2020-05-12 04:13:06.832]  Step 152482  [3.362 sec/step, loss=0.07217, avg_loss=0.08953, mel_loss=0.03156, linear_loss=0.04060]
[2020-05-12 04:13:08.026]  Generated 32 batches of size 32 in 1.777 sec
[2020-05-12 04:13:08.720]  Step 152483  [3.373 sec/step, loss=0.08761, avg_loss=0.08960, mel_loss=0.03859, linear_loss=0.04902]
[2020-05-12 04:13:11.602]  Step 152484  [3.374 sec/step, loss=0.09519, avg_loss=0.08962, mel_loss=0.04227, linear_loss=0.05292]
[2020-05-12 04:13:12.649]  Step 152485  [3.349 sec/step, loss=0.08092, avg_loss=0.08949, mel_loss=0.03523, linear_loss=0.04570]
[2020-05-12 04:13:15.990]  Step 152486  [3.334 sec/step, loss=0.09493, avg_loss=0.08946, mel_loss=0.04235, linear_loss=0.05258]
[2020-05-12 04:13:23.511]  Step 152487  [3.353 sec/step, loss=0.09866, avg_loss=0.08947, mel_loss=0.04565, linear_loss=0.05301]
[2020-05-12 04:13:29.955]  Step 152488  [3.294 sec/step, loss=0.09879, avg_loss=0.08957, mel_loss=0.04544, linear_loss=0.05335]
[2020-05-12 04:13:33.622]  Step 152489  [3.288 sec/step, loss=0.09587, avg_loss=0.08956, mel_loss=0.04305, linear_loss=0.05283]
[2020-05-12 04:13:37.684]  Step 152490  [3.316 sec/step, loss=0.09669, avg_loss=0.08969, mel_loss=0.04328, linear_loss=0.05340]
[2020-05-12 04:13:45.230]  Step 152491  [3.376 sec/step, loss=0.09864, avg_loss=0.08980, mel_loss=0.04555, linear_loss=0.05309]
[2020-05-12 04:13:48.954]  Step 152492  [3.377 sec/step, loss=0.09613, avg_loss=0.08978, mel_loss=0.04326, linear_loss=0.05287]
[2020-05-12 04:13:50.241]  Step 152493  [3.376 sec/step, loss=0.08592, avg_loss=0.08982, mel_loss=0.03714, linear_loss=0.04878]
[2020-05-12 04:13:56.913]  Step 152494  [3.354 sec/step, loss=0.09702, avg_loss=0.08984, mel_loss=0.04427, linear_loss=0.05275]
[2020-05-12 04:13:57.746]  Step 152495  [3.320 sec/step, loss=0.07481, avg_loss=0.08961, mel_loss=0.03266, linear_loss=0.04215]
[2020-05-12 04:13:58.894]  Step 152496  [3.306 sec/step, loss=0.08411, avg_loss=0.08954, mel_loss=0.03637, linear_loss=0.04774]
[2020-05-12 04:13:59.743]  Step 152497  [3.280 sec/step, loss=0.08014, avg_loss=0.08939, mel_loss=0.03422, linear_loss=0.04592]
[2020-05-12 04:14:08.259]  Step 152498  [3.344 sec/step, loss=0.09554, avg_loss=0.08944, mel_loss=0.04434, linear_loss=0.05119]
[2020-05-12 04:14:09.856]  Step 152499  [3.339 sec/step, loss=0.08655, avg_loss=0.08940, mel_loss=0.03765, linear_loss=0.04890]
[2020-05-12 04:14:14.146]  Step 152500  [3.372 sec/step, loss=0.09819, avg_loss=0.08956, mel_loss=0.04449, linear_loss=0.05370]
[2020-05-12 04:14:14.146]  Writing summary at step: 152500
[2020-05-12 04:14:19.475]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152500
[2020-05-12 04:14:20.944]  Saving audio and alignment...
[2020-05-12 04:14:23.102]  Input: 자 앞부분에서는~___________
[2020-05-12 04:14:24.519]  Step 152501  [3.309 sec/step, loss=0.08609, avg_loss=0.08943, mel_loss=0.03762, linear_loss=0.04847]
[2020-05-12 04:14:28.664]  Step 152502  [3.336 sec/step, loss=0.09553, avg_loss=0.08952, mel_loss=0.04306, linear_loss=0.05247]
[2020-05-12 04:14:31.357]  Step 152503  [3.295 sec/step, loss=0.09355, avg_loss=0.08946, mel_loss=0.04182, linear_loss=0.05172]
[2020-05-12 04:14:31.919]  Step 152504  [3.283 sec/step, loss=0.07145, avg_loss=0.08928, mel_loss=0.03127, linear_loss=0.04018]
[2020-05-12 04:14:33.873]  Step 152505  [3.283 sec/step, loss=0.09163, avg_loss=0.08931, mel_loss=0.04021, linear_loss=0.05141]
[2020-05-12 04:14:36.010]  Step 152506  [3.255 sec/step, loss=0.09029, avg_loss=0.08925, mel_loss=0.04001, linear_loss=0.05028]
[2020-05-12 04:14:40.674]  Step 152507  [3.269 sec/step, loss=0.09739, avg_loss=0.08927, mel_loss=0.04402, linear_loss=0.05337]
[2020-05-12 04:14:43.500]  Step 152508  [3.271 sec/step, loss=0.09476, avg_loss=0.08930, mel_loss=0.04226, linear_loss=0.05251]
[2020-05-12 04:14:46.570]  Step 152509  [3.153 sec/step, loss=0.09283, avg_loss=0.08948, mel_loss=0.04156, linear_loss=0.05127]
[2020-05-12 04:14:50.058]  Step 152510  [3.151 sec/step, loss=0.09341, avg_loss=0.08946, mel_loss=0.04194, linear_loss=0.05147]
[2020-05-12 04:14:52.495]  Step 152511  [3.139 sec/step, loss=0.09170, avg_loss=0.08941, mel_loss=0.04042, linear_loss=0.05129]
[2020-05-12 04:14:55.209]  Step 152512  [3.158 sec/step, loss=0.08853, avg_loss=0.08957, mel_loss=0.03866, linear_loss=0.04987]
[2020-05-12 04:14:56.289]  Generated 32 batches of size 32 in 3.788 sec
[2020-05-12 04:14:57.046]  Step 152513  [3.158 sec/step, loss=0.08880, avg_loss=0.08958, mel_loss=0.03881, linear_loss=0.04999]
[2020-05-12 04:14:58.667]  Step 152514  [3.166 sec/step, loss=0.08859, avg_loss=0.08966, mel_loss=0.03878, linear_loss=0.04981]
[2020-05-12 04:14:59.429]  Step 152515  [3.116 sec/step, loss=0.08033, avg_loss=0.08950, mel_loss=0.03445, linear_loss=0.04587]
[2020-05-12 04:15:13.716]  Step 152516  [3.224 sec/step, loss=0.07589, avg_loss=0.08930, mel_loss=0.03603, linear_loss=0.03986]
[2020-05-12 04:15:19.173]  Step 152517  [3.268 sec/step, loss=0.09741, avg_loss=0.08942, mel_loss=0.04437, linear_loss=0.05304]
[2020-05-12 04:15:21.438]  Step 152518  [3.285 sec/step, loss=0.09178, avg_loss=0.08961, mel_loss=0.04066, linear_loss=0.05112]
[2020-05-12 04:15:24.815]  Step 152519  [3.297 sec/step, loss=0.09503, avg_loss=0.08966, mel_loss=0.04243, linear_loss=0.05259]
[2020-05-12 04:15:25.795]  Step 152520  [3.281 sec/step, loss=0.08341, avg_loss=0.08954, mel_loss=0.03613, linear_loss=0.04728]
[2020-05-12 04:15:33.184]  Step 152521  [3.312 sec/step, loss=0.09749, avg_loss=0.08955, mel_loss=0.04467, linear_loss=0.05282]
[2020-05-12 04:15:34.751]  Step 152522  [3.314 sec/step, loss=0.08586, avg_loss=0.08953, mel_loss=0.03728, linear_loss=0.04858]
[2020-05-12 04:15:36.870]  Step 152523  [3.295 sec/step, loss=0.08408, avg_loss=0.08941, mel_loss=0.03634, linear_loss=0.04773]
[2020-05-12 04:15:38.650]  Step 152524  [3.297 sec/step, loss=0.07961, avg_loss=0.08932, mel_loss=0.03452, linear_loss=0.04509]
[2020-05-12 04:15:53.055]  Step 152525  [3.429 sec/step, loss=0.09183, avg_loss=0.08940, mel_loss=0.04303, linear_loss=0.04880]
[2020-05-12 04:15:54.069]  Step 152526  [3.431 sec/step, loss=0.08379, avg_loss=0.08947, mel_loss=0.03609, linear_loss=0.04770]
[2020-05-12 04:15:56.219]  Step 152527  [3.427 sec/step, loss=0.09231, avg_loss=0.08947, mel_loss=0.04063, linear_loss=0.05168]
[2020-05-12 04:15:59.850]  Step 152528  [3.374 sec/step, loss=0.09671, avg_loss=0.08948, mel_loss=0.04339, linear_loss=0.05331]
[2020-05-12 04:16:01.688]  Step 152529  [3.360 sec/step, loss=0.08976, avg_loss=0.08943, mel_loss=0.03923, linear_loss=0.05053]
[2020-05-12 04:16:03.424]  Step 152530  [3.349 sec/step, loss=0.08855, avg_loss=0.08940, mel_loss=0.03854, linear_loss=0.05001]
[2020-05-12 04:16:05.709]  Step 152531  [3.328 sec/step, loss=0.09177, avg_loss=0.08936, mel_loss=0.04078, linear_loss=0.05099]
[2020-05-12 04:16:06.516]  Step 152532  [3.295 sec/step, loss=0.07528, avg_loss=0.08915, mel_loss=0.03233, linear_loss=0.04295]
[2020-05-12 04:16:09.105]  Step 152533  [3.260 sec/step, loss=0.09134, avg_loss=0.08909, mel_loss=0.04058, linear_loss=0.05075]
[2020-05-12 04:16:11.915]  Step 152534  [3.272 sec/step, loss=0.09379, avg_loss=0.08914, mel_loss=0.04172, linear_loss=0.05206]
[2020-05-12 04:16:12.783]  Step 152535  [3.268 sec/step, loss=0.08155, avg_loss=0.08911, mel_loss=0.03455, linear_loss=0.04700]
[2020-05-12 04:16:18.416]  Step 152536  [3.295 sec/step, loss=0.09931, avg_loss=0.08918, mel_loss=0.04550, linear_loss=0.05381]
[2020-05-12 04:16:20.187]  Step 152537  [3.296 sec/step, loss=0.09045, avg_loss=0.08921, mel_loss=0.03932, linear_loss=0.05114]
[2020-05-12 04:16:21.589]  Step 152538  [3.292 sec/step, loss=0.08591, avg_loss=0.08918, mel_loss=0.03771, linear_loss=0.04820]
[2020-05-12 04:16:25.898]  Step 152539  [3.277 sec/step, loss=0.09499, avg_loss=0.08916, mel_loss=0.04258, linear_loss=0.05241]
[2020-05-12 04:16:30.641]  Step 152540  [3.317 sec/step, loss=0.09655, avg_loss=0.08932, mel_loss=0.04378, linear_loss=0.05277]
[2020-05-12 04:16:31.212]  Step 152541  [3.302 sec/step, loss=0.06822, avg_loss=0.08913, mel_loss=0.03009, linear_loss=0.03813]
[2020-05-12 04:16:37.954]  Step 152542  [3.358 sec/step, loss=0.09494, avg_loss=0.08925, mel_loss=0.04346, linear_loss=0.05148]
[2020-05-12 04:16:41.153]  Step 152543  [3.364 sec/step, loss=0.09558, avg_loss=0.08929, mel_loss=0.04276, linear_loss=0.05282]
[2020-05-12 04:16:42.688]  Step 152544  [3.306 sec/step, loss=0.08761, avg_loss=0.08917, mel_loss=0.03836, linear_loss=0.04926]
[2020-05-12 04:16:44.648]  Step 152545  [3.312 sec/step, loss=0.09088, avg_loss=0.08919, mel_loss=0.03998, linear_loss=0.05090]
[2020-05-12 04:16:47.110]  Step 152546  [3.288 sec/step, loss=0.09238, avg_loss=0.08914, mel_loss=0.04065, linear_loss=0.05173]
[2020-05-12 04:16:50.540]  Step 152547  [3.288 sec/step, loss=0.09246, avg_loss=0.08913, mel_loss=0.04150, linear_loss=0.05096]
[2020-05-12 04:16:53.613]  Step 152548  [3.310 sec/step, loss=0.09494, avg_loss=0.08931, mel_loss=0.04266, linear_loss=0.05228]
[2020-05-12 04:16:54.361]  Step 152549  [3.298 sec/step, loss=0.07826, avg_loss=0.08919, mel_loss=0.03404, linear_loss=0.04422]
[2020-05-12 04:17:02.631]  Step 152550  [3.344 sec/step, loss=0.09706, avg_loss=0.08919, mel_loss=0.04488, linear_loss=0.05218]
[2020-05-12 04:17:02.631]  Writing summary at step: 152550
[2020-05-12 04:17:06.431]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152550
[2020-05-12 04:17:07.937]  Saving audio and alignment...
[2020-05-12 04:17:14.631]  Input: 빨랐다 느렸다를 이야기 합니다 빠른 부분이 있는가하면~______________________________
[2020-05-12 04:18:00.554]  Generated 32 batches of size 32 in 79.395 sec
[2020-05-12 04:18:06.013]  Step 152551  [3.776 sec/step, loss=0.09709, avg_loss=0.08922, mel_loss=0.04428, linear_loss=0.05281]
[2020-05-12 04:18:10.795]  Step 152552  [3.791 sec/step, loss=0.09733, avg_loss=0.08922, mel_loss=0.04404, linear_loss=0.05330]
[2020-05-12 04:18:12.581]  Step 152553  [3.800 sec/step, loss=0.08759, avg_loss=0.08931, mel_loss=0.03812, linear_loss=0.04948]
[2020-05-12 04:18:14.738]  Step 152554  [3.811 sec/step, loss=0.08990, avg_loss=0.08938, mel_loss=0.03976, linear_loss=0.05014]
[2020-05-12 04:18:18.219]  Step 152555  [3.841 sec/step, loss=0.09342, avg_loss=0.08962, mel_loss=0.04167, linear_loss=0.05175]
[2020-05-12 04:18:18.776]  Step 152556  [3.703 sec/step, loss=0.07112, avg_loss=0.08959, mel_loss=0.03122, linear_loss=0.03990]
[2020-05-12 04:18:20.006]  Step 152557  [3.702 sec/step, loss=0.08181, avg_loss=0.08956, mel_loss=0.03565, linear_loss=0.04616]
[2020-05-12 04:18:21.024]  Step 152558  [3.666 sec/step, loss=0.08027, avg_loss=0.08939, mel_loss=0.03459, linear_loss=0.04569]
[2020-05-12 04:18:22.646]  Step 152559  [3.593 sec/step, loss=0.08677, avg_loss=0.08928, mel_loss=0.03799, linear_loss=0.04877]
[2020-05-12 04:18:30.491]  Step 152560  [3.615 sec/step, loss=0.09823, avg_loss=0.08928, mel_loss=0.04523, linear_loss=0.05299]
[2020-05-12 04:18:33.388]  Step 152561  [3.597 sec/step, loss=0.09563, avg_loss=0.08928, mel_loss=0.04247, linear_loss=0.05316]
[2020-05-12 04:18:36.410]  Step 152562  [3.609 sec/step, loss=0.09590, avg_loss=0.08936, mel_loss=0.04294, linear_loss=0.05296]
[2020-05-12 04:18:38.453]  Step 152563  [3.622 sec/step, loss=0.09083, avg_loss=0.08952, mel_loss=0.03983, linear_loss=0.05100]
[2020-05-12 04:18:47.652]  Step 152564  [3.689 sec/step, loss=0.09769, avg_loss=0.08959, mel_loss=0.04537, linear_loss=0.05232]
[2020-05-12 04:18:48.760]  Step 152565  [3.673 sec/step, loss=0.08475, avg_loss=0.08951, mel_loss=0.03645, linear_loss=0.04830]
[2020-05-12 04:18:50.718]  Step 152566  [3.670 sec/step, loss=0.08951, avg_loss=0.08951, mel_loss=0.03927, linear_loss=0.05024]
[2020-05-12 04:19:05.144]  Step 152567  [3.803 sec/step, loss=0.07928, avg_loss=0.08950, mel_loss=0.03764, linear_loss=0.04164]
[2020-05-12 04:19:09.309]  Step 152568  [3.829 sec/step, loss=0.09727, avg_loss=0.08960, mel_loss=0.04416, linear_loss=0.05310]
[2020-05-12 04:19:11.590]  Step 152569  [3.839 sec/step, loss=0.09148, avg_loss=0.08966, mel_loss=0.04031, linear_loss=0.05117]
[2020-05-12 04:19:15.027]  Step 152570  [3.842 sec/step, loss=0.09482, avg_loss=0.08965, mel_loss=0.04250, linear_loss=0.05232]
[2020-05-12 04:19:16.393]  Step 152571  [3.802 sec/step, loss=0.08772, avg_loss=0.08957, mel_loss=0.03814, linear_loss=0.04958]
[2020-05-12 04:19:22.145]  Step 152572  [3.826 sec/step, loss=0.09632, avg_loss=0.08959, mel_loss=0.04413, linear_loss=0.05219]
[2020-05-12 04:19:22.948]  Step 152573  [3.814 sec/step, loss=0.07737, avg_loss=0.08944, mel_loss=0.03307, linear_loss=0.04430]
[2020-05-12 04:19:29.411]  Step 152574  [3.863 sec/step, loss=0.09876, avg_loss=0.08955, mel_loss=0.04532, linear_loss=0.05344]
[2020-05-12 04:19:30.276]  Step 152575  [3.852 sec/step, loss=0.07241, avg_loss=0.08940, mel_loss=0.03109, linear_loss=0.04132]
[2020-05-12 04:19:31.747]  Step 152576  [3.743 sec/step, loss=0.08543, avg_loss=0.08935, mel_loss=0.03728, linear_loss=0.04815]
[2020-05-12 04:19:33.418]  Step 152577  [3.751 sec/step, loss=0.08774, avg_loss=0.08947, mel_loss=0.03853, linear_loss=0.04921]
[2020-05-12 04:19:34.430]  Step 152578  [3.751 sec/step, loss=0.08175, avg_loss=0.08948, mel_loss=0.03517, linear_loss=0.04658]
[2020-05-12 04:19:37.110]  Step 152579  [3.753 sec/step, loss=0.09027, avg_loss=0.08948, mel_loss=0.03990, linear_loss=0.05037]
[2020-05-12 04:19:40.832]  Step 152580  [3.778 sec/step, loss=0.09626, avg_loss=0.08960, mel_loss=0.04335, linear_loss=0.05290]
[2020-05-12 04:19:44.808]  Step 152581  [3.776 sec/step, loss=0.09574, avg_loss=0.08960, mel_loss=0.04289, linear_loss=0.05285]
[2020-05-12 04:19:47.650]  Step 152582  [3.798 sec/step, loss=0.09220, avg_loss=0.08980, mel_loss=0.04115, linear_loss=0.05105]
[2020-05-12 04:19:58.829]  Generated 32 batches of size 32 in 35.876 sec
[2020-05-12 04:20:01.985]  Step 152583  [3.923 sec/step, loss=0.09501, avg_loss=0.08987, mel_loss=0.04225, linear_loss=0.05276]
[2020-05-12 04:20:04.257]  Step 152584  [3.917 sec/step, loss=0.09082, avg_loss=0.08983, mel_loss=0.04028, linear_loss=0.05055]
[2020-05-12 04:20:11.272]  Step 152585  [3.976 sec/step, loss=0.09863, avg_loss=0.09001, mel_loss=0.04552, linear_loss=0.05311]
[2020-05-12 04:20:13.745]  Step 152586  [3.968 sec/step, loss=0.09183, avg_loss=0.08998, mel_loss=0.04039, linear_loss=0.05144]
[2020-05-12 04:20:15.470]  Step 152587  [3.910 sec/step, loss=0.08711, avg_loss=0.08986, mel_loss=0.03848, linear_loss=0.04863]
[2020-05-12 04:20:18.643]  Step 152588  [3.877 sec/step, loss=0.09477, avg_loss=0.08982, mel_loss=0.04232, linear_loss=0.05245]
[2020-05-12 04:20:19.939]  Step 152589  [3.853 sec/step, loss=0.08649, avg_loss=0.08973, mel_loss=0.03751, linear_loss=0.04898]
[2020-05-12 04:20:25.547]  Step 152590  [3.869 sec/step, loss=0.09838, avg_loss=0.08974, mel_loss=0.04473, linear_loss=0.05365]
[2020-05-12 04:20:26.779]  Step 152591  [3.806 sec/step, loss=0.08293, avg_loss=0.08959, mel_loss=0.03580, linear_loss=0.04713]
[2020-05-12 04:20:29.502]  Step 152592  [3.796 sec/step, loss=0.09268, avg_loss=0.08955, mel_loss=0.04142, linear_loss=0.05126]
[2020-05-12 04:20:36.158]  Step 152593  [3.849 sec/step, loss=0.09795, avg_loss=0.08967, mel_loss=0.04495, linear_loss=0.05300]
[2020-05-12 04:20:37.517]  Step 152594  [3.796 sec/step, loss=0.08726, avg_loss=0.08958, mel_loss=0.03804, linear_loss=0.04923]
[2020-05-12 04:20:38.525]  Step 152595  [3.798 sec/step, loss=0.07931, avg_loss=0.08962, mel_loss=0.03399, linear_loss=0.04532]
[2020-05-12 04:20:46.580]  Step 152596  [3.867 sec/step, loss=0.09641, avg_loss=0.08974, mel_loss=0.04468, linear_loss=0.05173]
[2020-05-12 04:20:48.349]  Step 152597  [3.876 sec/step, loss=0.08899, avg_loss=0.08983, mel_loss=0.03847, linear_loss=0.05051]
[2020-05-12 04:20:52.458]  Step 152598  [3.832 sec/step, loss=0.09468, avg_loss=0.08982, mel_loss=0.04249, linear_loss=0.05219]
[2020-05-12 04:20:54.493]  Step 152599  [3.837 sec/step, loss=0.08778, avg_loss=0.08984, mel_loss=0.03844, linear_loss=0.04934]
[2020-05-12 04:20:59.612]  Step 152600  [3.845 sec/step, loss=0.09686, avg_loss=0.08982, mel_loss=0.04363, linear_loss=0.05324]
[2020-05-12 04:20:59.613]  Writing summary at step: 152600
[2020-05-12 04:21:00.867]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152600
[2020-05-12 04:21:02.334]  Saving audio and alignment...
[2020-05-12 04:21:04.006]  Input: 어디서든~__________
[2020-05-12 04:21:09.338]  Step 152601  [3.884 sec/step, loss=0.09789, avg_loss=0.08994, mel_loss=0.04467, linear_loss=0.05323]
[2020-05-12 04:21:10.875]  Step 152602  [3.858 sec/step, loss=0.08611, avg_loss=0.08985, mel_loss=0.03730, linear_loss=0.04881]
[2020-05-12 04:21:12.931]  Step 152603  [3.852 sec/step, loss=0.08833, avg_loss=0.08979, mel_loss=0.03894, linear_loss=0.04939]
[2020-05-12 04:21:16.679]  Step 152604  [3.883 sec/step, loss=0.09631, avg_loss=0.09004, mel_loss=0.04315, linear_loss=0.05316]
[2020-05-12 04:21:17.318]  Step 152605  [3.870 sec/step, loss=0.07426, avg_loss=0.08987, mel_loss=0.03273, linear_loss=0.04153]
[2020-05-12 04:21:19.504]  Step 152606  [3.871 sec/step, loss=0.09016, avg_loss=0.08987, mel_loss=0.03971, linear_loss=0.05045]
[2020-05-12 04:21:22.947]  Step 152607  [3.859 sec/step, loss=0.09443, avg_loss=0.08984, mel_loss=0.04248, linear_loss=0.05195]
[2020-05-12 04:21:25.827]  Step 152608  [3.859 sec/step, loss=0.09259, avg_loss=0.08982, mel_loss=0.04113, linear_loss=0.05146]
[2020-05-12 04:21:30.102]  Step 152609  [3.871 sec/step, loss=0.09612, avg_loss=0.08985, mel_loss=0.04361, linear_loss=0.05252]
[2020-05-12 04:21:41.440]  Generated 32 batches of size 32 in 28.503 sec
[2020-05-12 04:21:42.073]  Step 152610  [3.956 sec/step, loss=0.09150, avg_loss=0.08983, mel_loss=0.04334, linear_loss=0.04816]
[2020-05-12 04:21:42.595]  Step 152611  [3.937 sec/step, loss=0.07459, avg_loss=0.08966, mel_loss=0.03262, linear_loss=0.04198]
[2020-05-12 04:21:43.602]  Step 152612  [3.920 sec/step, loss=0.07856, avg_loss=0.08956, mel_loss=0.03388, linear_loss=0.04468]
[2020-05-12 04:21:45.691]  Step 152613  [3.922 sec/step, loss=0.09180, avg_loss=0.08959, mel_loss=0.04060, linear_loss=0.05120]
[2020-05-12 04:21:48.825]  Step 152614  [3.937 sec/step, loss=0.09415, avg_loss=0.08964, mel_loss=0.04212, linear_loss=0.05203]
[2020-05-12 04:21:49.710]  Step 152615  [3.939 sec/step, loss=0.07740, avg_loss=0.08962, mel_loss=0.03317, linear_loss=0.04423]
[2020-05-12 04:21:53.124]  Step 152616  [3.830 sec/step, loss=0.09341, avg_loss=0.08979, mel_loss=0.04180, linear_loss=0.05161]
[2020-05-12 04:21:54.917]  Step 152617  [3.793 sec/step, loss=0.08925, avg_loss=0.08971, mel_loss=0.03921, linear_loss=0.05004]
[2020-05-12 04:22:09.317]  Step 152618  [3.915 sec/step, loss=0.07462, avg_loss=0.08954, mel_loss=0.03524, linear_loss=0.03938]
[2020-05-12 04:22:10.132]  Step 152619  [3.889 sec/step, loss=0.07432, avg_loss=0.08933, mel_loss=0.03212, linear_loss=0.04220]
[2020-05-12 04:22:17.674]  Step 152620  [3.955 sec/step, loss=0.09823, avg_loss=0.08948, mel_loss=0.04513, linear_loss=0.05310]
[2020-05-12 04:22:18.449]  Step 152621  [3.888 sec/step, loss=0.07355, avg_loss=0.08924, mel_loss=0.03227, linear_loss=0.04127]
[2020-05-12 04:22:23.607]  Step 152622  [3.924 sec/step, loss=0.09789, avg_loss=0.08936, mel_loss=0.04512, linear_loss=0.05277]
[2020-05-12 04:22:25.212]  Step 152623  [3.919 sec/step, loss=0.08844, avg_loss=0.08940, mel_loss=0.03879, linear_loss=0.04965]
[2020-05-12 04:22:26.912]  Step 152624  [3.918 sec/step, loss=0.08715, avg_loss=0.08948, mel_loss=0.03779, linear_loss=0.04935]
[2020-05-12 04:22:31.393]  Step 152625  [3.819 sec/step, loss=0.09813, avg_loss=0.08954, mel_loss=0.04445, linear_loss=0.05368]
[2020-05-12 04:22:39.976]  Step 152626  [3.895 sec/step, loss=0.09418, avg_loss=0.08965, mel_loss=0.04354, linear_loss=0.05064]
[2020-05-12 04:22:43.370]  Step 152627  [3.907 sec/step, loss=0.09581, avg_loss=0.08968, mel_loss=0.04288, linear_loss=0.05294]
[2020-05-12 04:22:45.803]  Step 152628  [3.895 sec/step, loss=0.09275, avg_loss=0.08964, mel_loss=0.04080, linear_loss=0.05196]
[2020-05-12 04:22:46.868]  Step 152629  [3.888 sec/step, loss=0.08564, avg_loss=0.08960, mel_loss=0.03680, linear_loss=0.04884]
[2020-05-12 04:22:48.006]  Step 152630  [3.882 sec/step, loss=0.08470, avg_loss=0.08956, mel_loss=0.03644, linear_loss=0.04827]
[2020-05-12 04:22:52.300]  Step 152631  [3.902 sec/step, loss=0.09644, avg_loss=0.08961, mel_loss=0.04358, linear_loss=0.05286]
[2020-05-12 04:22:54.520]  Step 152632  [3.916 sec/step, loss=0.09047, avg_loss=0.08976, mel_loss=0.04020, linear_loss=0.05027]
[2020-05-12 04:22:56.483]  Step 152633  [3.910 sec/step, loss=0.08946, avg_loss=0.08974, mel_loss=0.03947, linear_loss=0.04999]
[2020-05-12 04:22:57.803]  Step 152634  [3.895 sec/step, loss=0.08763, avg_loss=0.08968, mel_loss=0.03801, linear_loss=0.04961]
[2020-05-12 04:23:00.502]  Step 152635  [3.913 sec/step, loss=0.09274, avg_loss=0.08979, mel_loss=0.04161, linear_loss=0.05113]
[2020-05-12 04:23:02.263]  Generated 32 batches of size 32 in 1.756 sec
[2020-05-12 04:23:04.279]  Step 152636  [3.894 sec/step, loss=0.09675, avg_loss=0.08977, mel_loss=0.04359, linear_loss=0.05316]
[2020-05-12 04:23:05.259]  Step 152637  [3.887 sec/step, loss=0.08430, avg_loss=0.08970, mel_loss=0.03642, linear_loss=0.04788]
[2020-05-12 04:23:06.053]  Step 152638  [3.880 sec/step, loss=0.07797, avg_loss=0.08963, mel_loss=0.03346, linear_loss=0.04450]
[2020-05-12 04:23:10.933]  Step 152639  [3.886 sec/step, loss=0.09578, avg_loss=0.08963, mel_loss=0.04323, linear_loss=0.05255]
[2020-05-12 04:23:12.183]  Step 152640  [3.851 sec/step, loss=0.08538, avg_loss=0.08952, mel_loss=0.03707, linear_loss=0.04831]
[2020-05-12 04:23:15.793]  Step 152641  [3.882 sec/step, loss=0.09622, avg_loss=0.08980, mel_loss=0.04314, linear_loss=0.05309]
[2020-05-12 04:23:17.330]  Step 152642  [3.830 sec/step, loss=0.08830, avg_loss=0.08973, mel_loss=0.03883, linear_loss=0.04946]
[2020-05-12 04:23:19.920]  Step 152643  [3.823 sec/step, loss=0.09201, avg_loss=0.08970, mel_loss=0.04089, linear_loss=0.05113]
[2020-05-12 04:23:26.513]  Step 152644  [3.874 sec/step, loss=0.09491, avg_loss=0.08977, mel_loss=0.04345, linear_loss=0.05145]
[2020-05-12 04:23:28.696]  Step 152645  [3.876 sec/step, loss=0.09204, avg_loss=0.08978, mel_loss=0.04075, linear_loss=0.05129]
[2020-05-12 04:23:31.582]  Step 152646  [3.881 sec/step, loss=0.09162, avg_loss=0.08978, mel_loss=0.04090, linear_loss=0.05072]
[2020-05-12 04:23:37.250]  Step 152647  [3.903 sec/step, loss=0.09691, avg_loss=0.08982, mel_loss=0.04424, linear_loss=0.05267]
[2020-05-12 04:23:38.091]  Step 152648  [3.881 sec/step, loss=0.07597, avg_loss=0.08963, mel_loss=0.03295, linear_loss=0.04302]
[2020-05-12 04:23:39.185]  Step 152649  [3.884 sec/step, loss=0.08204, avg_loss=0.08967, mel_loss=0.03556, linear_loss=0.04648]
[2020-05-12 04:23:46.277]  Step 152650  [3.872 sec/step, loss=0.09726, avg_loss=0.08967, mel_loss=0.04481, linear_loss=0.05245]
[2020-05-12 04:23:46.277]  Writing summary at step: 152650
[2020-05-12 04:23:51.204]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152650
[2020-05-12 04:23:52.704]  Saving audio and alignment...
[2020-05-12 04:23:59.041]  Input: 아 며칠 전에 제가 에스케이 브로드밴드 상담사 님들 상대로 교육을 했는데~____________
[2020-05-12 04:24:01.764]  Step 152651  [3.386 sec/step, loss=0.09286, avg_loss=0.08963, mel_loss=0.04075, linear_loss=0.05210]
[2020-05-12 04:24:03.132]  Step 152652  [3.352 sec/step, loss=0.08460, avg_loss=0.08950, mel_loss=0.03694, linear_loss=0.04766]
[2020-05-12 04:24:04.053]  Step 152653  [3.343 sec/step, loss=0.08173, avg_loss=0.08944, mel_loss=0.03494, linear_loss=0.04679]
[2020-05-12 04:24:04.620]  Step 152654  [3.327 sec/step, loss=0.06986, avg_loss=0.08924, mel_loss=0.03104, linear_loss=0.03881]
[2020-05-12 04:24:09.970]  Step 152655  [3.346 sec/step, loss=0.09794, avg_loss=0.08929, mel_loss=0.04469, linear_loss=0.05325]
[2020-05-12 04:24:12.380]  Step 152656  [3.364 sec/step, loss=0.09204, avg_loss=0.08950, mel_loss=0.04084, linear_loss=0.05120]
[2020-05-12 04:24:14.530]  Step 152657  [3.373 sec/step, loss=0.09238, avg_loss=0.08960, mel_loss=0.04078, linear_loss=0.05160]
[2020-05-12 04:24:17.955]  Step 152658  [3.397 sec/step, loss=0.09425, avg_loss=0.08974, mel_loss=0.04230, linear_loss=0.05196]
[2020-05-12 04:24:26.995]  Step 152659  [3.472 sec/step, loss=0.09738, avg_loss=0.08985, mel_loss=0.04522, linear_loss=0.05215]
[2020-05-12 04:24:30.194]  Step 152660  [3.425 sec/step, loss=0.09664, avg_loss=0.08983, mel_loss=0.04321, linear_loss=0.05343]
[2020-05-12 04:24:32.233]  Step 152661  [3.417 sec/step, loss=0.09106, avg_loss=0.08979, mel_loss=0.04009, linear_loss=0.05098]
[2020-05-12 04:24:34.134]  Step 152662  [3.405 sec/step, loss=0.08597, avg_loss=0.08969, mel_loss=0.03760, linear_loss=0.04836]
[2020-05-12 04:24:37.159]  Step 152663  [3.415 sec/step, loss=0.09515, avg_loss=0.08973, mel_loss=0.04237, linear_loss=0.05278]
[2020-05-12 04:24:38.442]  Step 152664  [3.336 sec/step, loss=0.08413, avg_loss=0.08959, mel_loss=0.03624, linear_loss=0.04789]
[2020-05-12 04:24:40.030]  Step 152665  [3.341 sec/step, loss=0.09021, avg_loss=0.08965, mel_loss=0.03950, linear_loss=0.05070]
[2020-05-12 04:24:41.756]  Generated 32 batches of size 32 in 1.720 sec
[2020-05-12 04:24:46.397]  Step 152666  [3.385 sec/step, loss=0.09606, avg_loss=0.08971, mel_loss=0.04402, linear_loss=0.05204]
[2020-05-12 04:24:50.122]  Step 152667  [3.278 sec/step, loss=0.09688, avg_loss=0.08989, mel_loss=0.04358, linear_loss=0.05330]
[2020-05-12 04:24:51.179]  Step 152668  [3.247 sec/step, loss=0.07813, avg_loss=0.08970, mel_loss=0.03403, linear_loss=0.04410]
[2020-05-12 04:24:52.834]  Step 152669  [3.241 sec/step, loss=0.09028, avg_loss=0.08969, mel_loss=0.03949, linear_loss=0.05079]
[2020-05-12 04:24:53.634]  Step 152670  [3.214 sec/step, loss=0.07599, avg_loss=0.08950, mel_loss=0.03217, linear_loss=0.04382]
[2020-05-12 04:25:08.071]  Step 152671  [3.345 sec/step, loss=0.07665, avg_loss=0.08939, mel_loss=0.03633, linear_loss=0.04032]
[2020-05-12 04:25:11.571]  Step 152672  [3.322 sec/step, loss=0.09415, avg_loss=0.08937, mel_loss=0.04227, linear_loss=0.05188]
[2020-05-12 04:25:13.035]  Step 152673  [3.329 sec/step, loss=0.08579, avg_loss=0.08945, mel_loss=0.03732, linear_loss=0.04848]
[2020-05-12 04:25:17.233]  Step 152674  [3.306 sec/step, loss=0.09699, avg_loss=0.08943, mel_loss=0.04384, linear_loss=0.05314]
[2020-05-12 04:25:20.890]  Step 152675  [3.334 sec/step, loss=0.09540, avg_loss=0.08966, mel_loss=0.04281, linear_loss=0.05259]
[2020-05-12 04:25:23.968]  Step 152676  [3.350 sec/step, loss=0.09514, avg_loss=0.08976, mel_loss=0.04228, linear_loss=0.05285]
[2020-05-12 04:25:27.469]  Step 152677  [3.369 sec/step, loss=0.09368, avg_loss=0.08982, mel_loss=0.04186, linear_loss=0.05182]
[2020-05-12 04:25:31.596]  Step 152678  [3.400 sec/step, loss=0.09679, avg_loss=0.08997, mel_loss=0.04393, linear_loss=0.05286]
[2020-05-12 04:25:37.254]  Step 152679  [3.430 sec/step, loss=0.09882, avg_loss=0.09006, mel_loss=0.04493, linear_loss=0.05389]
[2020-05-12 04:25:38.641]  Step 152680  [3.406 sec/step, loss=0.08629, avg_loss=0.08996, mel_loss=0.03783, linear_loss=0.04846]
[2020-05-12 04:25:53.955]  Step 152681  [3.520 sec/step, loss=0.08301, avg_loss=0.08983, mel_loss=0.03918, linear_loss=0.04384]
[2020-05-12 04:25:56.609]  Step 152682  [3.518 sec/step, loss=0.08926, avg_loss=0.08980, mel_loss=0.03892, linear_loss=0.05034]
[2020-05-12 04:25:58.280]  Step 152683  [3.391 sec/step, loss=0.08434, avg_loss=0.08969, mel_loss=0.03654, linear_loss=0.04780]
[2020-05-12 04:26:00.467]  Step 152684  [3.390 sec/step, loss=0.09071, avg_loss=0.08969, mel_loss=0.04007, linear_loss=0.05065]
[2020-05-12 04:26:01.502]  Step 152685  [3.330 sec/step, loss=0.08006, avg_loss=0.08951, mel_loss=0.03408, linear_loss=0.04599]
[2020-05-12 04:26:02.305]  Step 152686  [3.314 sec/step, loss=0.07703, avg_loss=0.08936, mel_loss=0.03300, linear_loss=0.04403]
[2020-05-12 04:26:04.189]  Step 152687  [3.315 sec/step, loss=0.08666, avg_loss=0.08935, mel_loss=0.03791, linear_loss=0.04876]
[2020-05-12 04:26:05.314]  Step 152688  [3.295 sec/step, loss=0.07993, avg_loss=0.08920, mel_loss=0.03449, linear_loss=0.04543]
[2020-05-12 04:26:07.838]  Step 152689  [3.307 sec/step, loss=0.08992, avg_loss=0.08924, mel_loss=0.03976, linear_loss=0.05016]
[2020-05-12 04:26:12.382]  Step 152690  [3.297 sec/step, loss=0.09634, avg_loss=0.08922, mel_loss=0.04285, linear_loss=0.05349]
[2020-05-12 04:26:20.243]  Step 152691  [3.363 sec/step, loss=0.10117, avg_loss=0.08940, mel_loss=0.04658, linear_loss=0.05460]
[2020-05-12 04:26:22.096]  Step 152692  [3.354 sec/step, loss=0.08818, avg_loss=0.08936, mel_loss=0.03846, linear_loss=0.04972]
[2020-05-12 04:26:26.685]  Step 152693  [3.333 sec/step, loss=0.09930, avg_loss=0.08937, mel_loss=0.04506, linear_loss=0.05425]
[2020-05-12 04:26:27.221]  Step 152694  [3.325 sec/step, loss=0.07008, avg_loss=0.08920, mel_loss=0.03129, linear_loss=0.03879]
[2020-05-12 04:26:29.803]  Step 152695  [3.341 sec/step, loss=0.09217, avg_loss=0.08933, mel_loss=0.04105, linear_loss=0.05112]
[2020-05-12 04:26:30.923]  Step 152696  [3.272 sec/step, loss=0.08280, avg_loss=0.08919, mel_loss=0.03539, linear_loss=0.04741]
[2020-05-12 04:26:33.020]  Step 152697  [3.275 sec/step, loss=0.09029, avg_loss=0.08920, mel_loss=0.03959, linear_loss=0.05069]
[2020-05-12 04:26:34.707]  Generated 32 batches of size 32 in 1.681 sec
[2020-05-12 04:26:41.238]  Step 152698  [3.316 sec/step, loss=0.09385, avg_loss=0.08919, mel_loss=0.04335, linear_loss=0.05050]
[2020-05-12 04:26:42.075]  Step 152699  [3.304 sec/step, loss=0.07711, avg_loss=0.08909, mel_loss=0.03340, linear_loss=0.04371]
[2020-05-12 04:26:47.408]  Step 152700  [3.306 sec/step, loss=0.09518, avg_loss=0.08907, mel_loss=0.04325, linear_loss=0.05193]
[2020-05-12 04:26:47.408]  Writing summary at step: 152700
[2020-05-12 04:26:50.836]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152700
[2020-05-12 04:26:52.348]  Saving audio and alignment...
[2020-05-12 04:26:57.010]  Input: 예문 하나를 연습할 때도  네 정답은~________________________
[2020-05-12 04:27:03.241]  Step 152701  [3.315 sec/step, loss=0.09648, avg_loss=0.08906, mel_loss=0.04407, linear_loss=0.05241]
[2020-05-12 04:27:05.754]  Step 152702  [3.325 sec/step, loss=0.09298, avg_loss=0.08913, mel_loss=0.04098, linear_loss=0.05200]
[2020-05-12 04:27:07.548]  Step 152703  [3.322 sec/step, loss=0.09032, avg_loss=0.08915, mel_loss=0.03914, linear_loss=0.05117]
[2020-05-12 04:27:08.928]  Step 152704  [3.299 sec/step, loss=0.08475, avg_loss=0.08903, mel_loss=0.03710, linear_loss=0.04765]
[2020-05-12 04:27:09.745]  Step 152705  [3.300 sec/step, loss=0.07548, avg_loss=0.08904, mel_loss=0.03221, linear_loss=0.04326]
[2020-05-12 04:27:13.460]  Step 152706  [3.316 sec/step, loss=0.09642, avg_loss=0.08910, mel_loss=0.04326, linear_loss=0.05317]
[2020-05-12 04:27:14.787]  Step 152707  [3.294 sec/step, loss=0.08523, avg_loss=0.08901, mel_loss=0.03704, linear_loss=0.04819]
[2020-05-12 04:27:15.779]  Step 152708  [3.276 sec/step, loss=0.08353, avg_loss=0.08892, mel_loss=0.03594, linear_loss=0.04758]
[2020-05-12 04:27:17.970]  Step 152709  [3.255 sec/step, loss=0.09080, avg_loss=0.08887, mel_loss=0.03992, linear_loss=0.05088]
[2020-05-12 04:27:20.050]  Step 152710  [3.156 sec/step, loss=0.08886, avg_loss=0.08884, mel_loss=0.03910, linear_loss=0.04976]
[2020-05-12 04:27:23.697]  Step 152711  [3.187 sec/step, loss=0.09355, avg_loss=0.08903, mel_loss=0.04204, linear_loss=0.05151]
[2020-05-12 04:27:29.429]  Step 152712  [3.234 sec/step, loss=0.09534, avg_loss=0.08920, mel_loss=0.04351, linear_loss=0.05183]
[2020-05-12 04:27:42.803]  Step 152713  [3.347 sec/step, loss=0.08240, avg_loss=0.08911, mel_loss=0.03878, linear_loss=0.04363]
[2020-05-12 04:27:43.818]  Step 152714  [3.326 sec/step, loss=0.07980, avg_loss=0.08896, mel_loss=0.03418, linear_loss=0.04562]
[2020-05-12 04:27:52.776]  Step 152715  [3.407 sec/step, loss=0.09667, avg_loss=0.08915, mel_loss=0.04466, linear_loss=0.05201]
[2020-05-12 04:27:54.507]  Step 152716  [3.390 sec/step, loss=0.09101, avg_loss=0.08913, mel_loss=0.04004, linear_loss=0.05097]
[2020-05-12 04:27:56.294]  Step 152717  [3.390 sec/step, loss=0.08954, avg_loss=0.08913, mel_loss=0.03903, linear_loss=0.05052]
[2020-05-12 04:27:59.382]  Step 152718  [3.277 sec/step, loss=0.09476, avg_loss=0.08934, mel_loss=0.04222, linear_loss=0.05254]
[2020-05-12 04:28:02.290]  Step 152719  [3.298 sec/step, loss=0.09262, avg_loss=0.08952, mel_loss=0.04146, linear_loss=0.05116]
[2020-05-12 04:28:09.112]  Step 152720  [3.290 sec/step, loss=0.09708, avg_loss=0.08951, mel_loss=0.04454, linear_loss=0.05253]
[2020-05-12 04:28:13.283]  Step 152721  [3.324 sec/step, loss=0.09572, avg_loss=0.08973, mel_loss=0.04291, linear_loss=0.05281]
[2020-05-12 04:28:15.774]  Step 152722  [3.298 sec/step, loss=0.08999, avg_loss=0.08965, mel_loss=0.03948, linear_loss=0.05050]
[2020-05-12 04:28:18.273]  Step 152723  [3.307 sec/step, loss=0.08963, avg_loss=0.08966, mel_loss=0.03965, linear_loss=0.04997]
[2020-05-12 04:28:22.377]  Step 152724  [3.331 sec/step, loss=0.09722, avg_loss=0.08976, mel_loss=0.04375, linear_loss=0.05347]
[2020-05-12 04:28:23.572]  Step 152725  [3.298 sec/step, loss=0.08132, avg_loss=0.08959, mel_loss=0.03509, linear_loss=0.04623]
[2020-05-12 04:28:24.660]  Step 152726  [3.223 sec/step, loss=0.08566, avg_loss=0.08951, mel_loss=0.03673, linear_loss=0.04893]
[2020-05-12 04:28:32.183]  Step 152727  [3.264 sec/step, loss=0.09771, avg_loss=0.08953, mel_loss=0.04489, linear_loss=0.05282]
[2020-05-12 04:28:32.780]  Step 152728  [3.246 sec/step, loss=0.06875, avg_loss=0.08929, mel_loss=0.02999, linear_loss=0.03876]
[2020-05-12 04:28:33.932]  Generated 32 batches of size 32 in 1.743 sec
[2020-05-12 04:28:34.395]  Step 152729  [3.251 sec/step, loss=0.08653, avg_loss=0.08930, mel_loss=0.03776, linear_loss=0.04877]
[2020-05-12 04:28:37.739]  Step 152730  [3.273 sec/step, loss=0.09515, avg_loss=0.08940, mel_loss=0.04276, linear_loss=0.05238]
[2020-05-12 04:28:38.589]  Step 152731  [3.239 sec/step, loss=0.07527, avg_loss=0.08919, mel_loss=0.03228, linear_loss=0.04298]
[2020-05-12 04:28:43.251]  Step 152732  [3.263 sec/step, loss=0.09695, avg_loss=0.08925, mel_loss=0.04377, linear_loss=0.05318]
[2020-05-12 04:28:45.192]  Step 152733  [3.263 sec/step, loss=0.08991, avg_loss=0.08926, mel_loss=0.03931, linear_loss=0.05061]
[2020-05-12 04:28:50.277]  Step 152734  [3.301 sec/step, loss=0.09629, avg_loss=0.08935, mel_loss=0.04359, linear_loss=0.05270]
[2020-05-12 04:28:51.697]  Step 152735  [3.288 sec/step, loss=0.08504, avg_loss=0.08927, mel_loss=0.03694, linear_loss=0.04810]
[2020-05-12 04:28:54.453]  Step 152736  [3.278 sec/step, loss=0.09228, avg_loss=0.08922, mel_loss=0.04107, linear_loss=0.05121]
[2020-05-12 04:28:58.954]  Step 152737  [3.313 sec/step, loss=0.09638, avg_loss=0.08934, mel_loss=0.04340, linear_loss=0.05298]
[2020-05-12 04:29:01.112]  Step 152738  [3.327 sec/step, loss=0.09073, avg_loss=0.08947, mel_loss=0.04025, linear_loss=0.05047]
[2020-05-12 04:29:02.847]  Step 152739  [3.295 sec/step, loss=0.08972, avg_loss=0.08941, mel_loss=0.03910, linear_loss=0.05062]
[2020-05-12 04:29:05.294]  Step 152740  [3.307 sec/step, loss=0.09461, avg_loss=0.08950, mel_loss=0.04162, linear_loss=0.05300]
[2020-05-12 04:29:10.146]  Step 152741  [3.320 sec/step, loss=0.09687, avg_loss=0.08951, mel_loss=0.04385, linear_loss=0.05302]
[2020-05-12 04:29:12.166]  Step 152742  [3.324 sec/step, loss=0.08844, avg_loss=0.08951, mel_loss=0.03908, linear_loss=0.04937]
[2020-05-12 04:29:13.502]  Step 152743  [3.312 sec/step, loss=0.08578, avg_loss=0.08945, mel_loss=0.03714, linear_loss=0.04863]
[2020-05-12 04:29:20.910]  Step 152744  [3.320 sec/step, loss=0.09750, avg_loss=0.08948, mel_loss=0.04466, linear_loss=0.05284]
[2020-05-12 04:29:22.481]  Step 152745  [3.314 sec/step, loss=0.08807, avg_loss=0.08944, mel_loss=0.03804, linear_loss=0.05003]
[2020-05-12 04:29:23.238]  Step 152746  [3.293 sec/step, loss=0.07408, avg_loss=0.08926, mel_loss=0.03236, linear_loss=0.04172]
[2020-05-12 04:29:25.456]  Step 152747  [3.258 sec/step, loss=0.09012, avg_loss=0.08919, mel_loss=0.03980, linear_loss=0.05032]
[2020-05-12 04:29:28.468]  Step 152748  [3.280 sec/step, loss=0.09537, avg_loss=0.08939, mel_loss=0.04270, linear_loss=0.05267]
[2020-05-12 04:29:31.881]  Step 152749  [3.303 sec/step, loss=0.09173, avg_loss=0.08948, mel_loss=0.04108, linear_loss=0.05066]
[2020-05-12 04:29:40.727]  Step 152750  [3.321 sec/step, loss=0.09720, avg_loss=0.08948, mel_loss=0.04490, linear_loss=0.05229]
[2020-05-12 04:29:40.727]  Writing summary at step: 152750
[2020-05-12 04:29:46.146]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152750
[2020-05-12 04:29:47.694]  Saving audio and alignment...
[2020-05-12 04:29:53.575]  Input: 귀에 들리는 것은 곧 허공으로 사라진다고 생각할 수도 있으나~________
[2020-05-12 04:29:55.477]  Step 152751  [3.312 sec/step, loss=0.08624, avg_loss=0.08942, mel_loss=0.03758, linear_loss=0.04866]
[2020-05-12 04:29:59.667]  Step 152752  [3.341 sec/step, loss=0.09609, avg_loss=0.08953, mel_loss=0.04319, linear_loss=0.05290]
[2020-05-12 04:30:00.514]  Step 152753  [3.340 sec/step, loss=0.07752, avg_loss=0.08949, mel_loss=0.03306, linear_loss=0.04445]
[2020-05-12 04:30:01.949]  Step 152754  [3.349 sec/step, loss=0.08402, avg_loss=0.08963, mel_loss=0.03642, linear_loss=0.04760]
[2020-05-12 04:30:05.192]  Step 152755  [3.327 sec/step, loss=0.09572, avg_loss=0.08961, mel_loss=0.04269, linear_loss=0.05303]
[2020-05-12 04:30:06.121]  Step 152756  [3.313 sec/step, loss=0.07987, avg_loss=0.08949, mel_loss=0.03419, linear_loss=0.04568]
[2020-05-12 04:30:08.952]  Step 152757  [3.319 sec/step, loss=0.09275, avg_loss=0.08949, mel_loss=0.04133, linear_loss=0.05142]
[2020-05-12 04:30:09.810]  Step 152758  [3.294 sec/step, loss=0.07355, avg_loss=0.08928, mel_loss=0.03196, linear_loss=0.04159]
[2020-05-12 04:30:11.009]  Generated 32 batches of size 32 in 2.052 sec
[2020-05-12 04:30:24.441]  Step 152759  [3.350 sec/step, loss=0.07752, avg_loss=0.08909, mel_loss=0.03673, linear_loss=0.04079]
[2020-05-12 04:30:32.338]  Step 152760  [3.397 sec/step, loss=0.09865, avg_loss=0.08911, mel_loss=0.04556, linear_loss=0.05309]
[2020-05-12 04:30:38.231]  Step 152761  [3.435 sec/step, loss=0.09875, avg_loss=0.08918, mel_loss=0.04534, linear_loss=0.05340]
[2020-05-12 04:30:40.778]  Step 152762  [3.442 sec/step, loss=0.09256, avg_loss=0.08925, mel_loss=0.04070, linear_loss=0.05186]
[2020-05-12 04:30:42.013]  Step 152763  [3.424 sec/step, loss=0.08343, avg_loss=0.08913, mel_loss=0.03632, linear_loss=0.04711]
[2020-05-12 04:30:43.137]  Step 152764  [3.422 sec/step, loss=0.08376, avg_loss=0.08913, mel_loss=0.03626, linear_loss=0.04749]
[2020-05-12 04:30:44.746]  Step 152765  [3.422 sec/step, loss=0.08627, avg_loss=0.08909, mel_loss=0.03772, linear_loss=0.04856]
[2020-05-12 04:30:45.772]  Step 152766  [3.369 sec/step, loss=0.08008, avg_loss=0.08893, mel_loss=0.03468, linear_loss=0.04540]
[2020-05-12 04:30:48.951]  Step 152767  [3.364 sec/step, loss=0.09546, avg_loss=0.08891, mel_loss=0.04246, linear_loss=0.05300]
[2020-05-12 04:30:50.023]  Step 152768  [3.364 sec/step, loss=0.08274, avg_loss=0.08896, mel_loss=0.03542, linear_loss=0.04733]
[2020-05-12 04:30:55.770]  Step 152769  [3.405 sec/step, loss=0.09634, avg_loss=0.08902, mel_loss=0.04418, linear_loss=0.05216]
[2020-05-12 04:31:02.214]  Step 152770  [3.461 sec/step, loss=0.09560, avg_loss=0.08922, mel_loss=0.04381, linear_loss=0.05179]
[2020-05-12 04:31:03.248]  Step 152771  [3.327 sec/step, loss=0.07753, avg_loss=0.08923, mel_loss=0.03346, linear_loss=0.04407]
[2020-05-12 04:31:06.789]  Step 152772  [3.327 sec/step, loss=0.09451, avg_loss=0.08923, mel_loss=0.04220, linear_loss=0.05230]
[2020-05-12 04:31:09.930]  Step 152773  [3.344 sec/step, loss=0.09462, avg_loss=0.08932, mel_loss=0.04213, linear_loss=0.05248]
[2020-05-12 04:31:10.541]  Step 152774  [3.308 sec/step, loss=0.06892, avg_loss=0.08904, mel_loss=0.03022, linear_loss=0.03870]
[2020-05-12 04:31:11.589]  Step 152775  [3.282 sec/step, loss=0.08336, avg_loss=0.08892, mel_loss=0.03572, linear_loss=0.04764]
[2020-05-12 04:31:12.276]  Step 152776  [3.258 sec/step, loss=0.07599, avg_loss=0.08872, mel_loss=0.03338, linear_loss=0.04261]
[2020-05-12 04:31:14.398]  Step 152777  [3.245 sec/step, loss=0.08940, avg_loss=0.08868, mel_loss=0.03927, linear_loss=0.05013]
[2020-05-12 04:31:18.000]  Step 152778  [3.239 sec/step, loss=0.09642, avg_loss=0.08868, mel_loss=0.04316, linear_loss=0.05326]
[2020-05-12 04:31:19.993]  Step 152779  [3.203 sec/step, loss=0.08823, avg_loss=0.08857, mel_loss=0.03862, linear_loss=0.04961]
[2020-05-12 04:31:22.341]  Step 152780  [3.212 sec/step, loss=0.09251, avg_loss=0.08863, mel_loss=0.04113, linear_loss=0.05138]
[2020-05-12 04:31:25.152]  Step 152781  [3.087 sec/step, loss=0.09069, avg_loss=0.08871, mel_loss=0.04028, linear_loss=0.05041]
[2020-05-12 04:31:27.722]  Step 152782  [3.086 sec/step, loss=0.08956, avg_loss=0.08871, mel_loss=0.03947, linear_loss=0.05009]
[2020-05-12 04:31:29.160]  Step 152783  [3.084 sec/step, loss=0.08596, avg_loss=0.08873, mel_loss=0.03765, linear_loss=0.04831]
[2020-05-12 04:31:30.348]  Step 152784  [3.074 sec/step, loss=0.08388, avg_loss=0.08866, mel_loss=0.03616, linear_loss=0.04772]
[2020-05-12 04:31:31.748]  Step 152785  [3.078 sec/step, loss=0.08479, avg_loss=0.08871, mel_loss=0.03693, linear_loss=0.04786]
[2020-05-12 04:31:44.128]  Step 152786  [3.193 sec/step, loss=0.08888, avg_loss=0.08883, mel_loss=0.04234, linear_loss=0.04655]
[2020-05-12 04:31:48.247]  Step 152787  [3.216 sec/step, loss=0.09595, avg_loss=0.08892, mel_loss=0.04313, linear_loss=0.05283]
[2020-05-12 04:31:50.220]  Step 152788  [3.224 sec/step, loss=0.08887, avg_loss=0.08901, mel_loss=0.03868, linear_loss=0.05019]
[2020-05-12 04:31:53.023]  Step 152789  [3.227 sec/step, loss=0.09192, avg_loss=0.08903, mel_loss=0.04074, linear_loss=0.05118]
[2020-05-12 04:31:54.737]  Generated 32 batches of size 32 in 1.708 sec
[2020-05-12 04:31:58.183]  Step 152790  [3.233 sec/step, loss=0.09615, avg_loss=0.08903, mel_loss=0.04376, linear_loss=0.05239]
[2020-05-12 04:32:05.820]  Step 152791  [3.231 sec/step, loss=0.09787, avg_loss=0.08899, mel_loss=0.04513, linear_loss=0.05274]
[2020-05-12 04:32:10.517]  Step 152792  [3.259 sec/step, loss=0.09764, avg_loss=0.08909, mel_loss=0.04434, linear_loss=0.05330]
[2020-05-12 04:32:12.288]  Step 152793  [3.231 sec/step, loss=0.08923, avg_loss=0.08899, mel_loss=0.03885, linear_loss=0.05038]
[2020-05-12 04:32:13.861]  Step 152794  [3.242 sec/step, loss=0.08662, avg_loss=0.08915, mel_loss=0.03817, linear_loss=0.04845]
[2020-05-12 04:32:17.512]  Step 152795  [3.252 sec/step, loss=0.09659, avg_loss=0.08920, mel_loss=0.04348, linear_loss=0.05311]
[2020-05-12 04:32:21.694]  Step 152796  [3.283 sec/step, loss=0.09688, avg_loss=0.08934, mel_loss=0.04382, linear_loss=0.05306]
[2020-05-12 04:32:30.517]  Step 152797  [3.350 sec/step, loss=0.09381, avg_loss=0.08937, mel_loss=0.04348, linear_loss=0.05032]
[2020-05-12 04:32:31.326]  Step 152798  [3.276 sec/step, loss=0.07701, avg_loss=0.08921, mel_loss=0.03294, linear_loss=0.04407]
[2020-05-12 04:32:32.364]  Step 152799  [3.278 sec/step, loss=0.08209, avg_loss=0.08926, mel_loss=0.03540, linear_loss=0.04670]
[2020-05-12 04:32:45.552]  Step 152800  [3.357 sec/step, loss=0.08353, avg_loss=0.08914, mel_loss=0.03934, linear_loss=0.04419]
[2020-05-12 04:32:45.552]  Writing summary at step: 152800
[2020-05-12 04:32:46.495]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152800
[2020-05-12 04:32:48.038]  Saving audio and alignment...
[2020-05-12 04:32:51.757]  Input: 그게 가장 궁금하고 또 답답했습니다~_____
[2020-05-12 04:32:52.455]  Step 152801  [3.301 sec/step, loss=0.07660, avg_loss=0.08894, mel_loss=0.03336, linear_loss=0.04325]
[2020-05-12 04:32:54.510]  Step 152802  [3.297 sec/step, loss=0.08917, avg_loss=0.08890, mel_loss=0.03886, linear_loss=0.05032]
[2020-05-12 04:32:57.182]  Step 152803  [3.306 sec/step, loss=0.09330, avg_loss=0.08893, mel_loss=0.04161, linear_loss=0.05168]
[2020-05-12 04:32:58.845]  Step 152804  [3.308 sec/step, loss=0.08960, avg_loss=0.08898, mel_loss=0.03938, linear_loss=0.05023]
[2020-05-12 04:33:00.711]  Step 152805  [3.319 sec/step, loss=0.08762, avg_loss=0.08910, mel_loss=0.03852, linear_loss=0.04910]
[2020-05-12 04:33:03.679]  Step 152806  [3.311 sec/step, loss=0.09451, avg_loss=0.08908, mel_loss=0.04194, linear_loss=0.05257]
[2020-05-12 04:33:04.248]  Step 152807  [3.304 sec/step, loss=0.06994, avg_loss=0.08893, mel_loss=0.03066, linear_loss=0.03928]
[2020-05-12 04:33:09.753]  Step 152808  [3.349 sec/step, loss=0.09808, avg_loss=0.08908, mel_loss=0.04490, linear_loss=0.05318]
[2020-05-12 04:33:11.284]  Step 152809  [3.342 sec/step, loss=0.08868, avg_loss=0.08905, mel_loss=0.03835, linear_loss=0.05034]
[2020-05-12 04:33:19.112]  Step 152810  [3.400 sec/step, loss=0.09616, avg_loss=0.08913, mel_loss=0.04405, linear_loss=0.05211]
[2020-05-12 04:33:22.350]  Step 152811  [3.396 sec/step, loss=0.09413, avg_loss=0.08913, mel_loss=0.04218, linear_loss=0.05195]
[2020-05-12 04:33:23.521]  Step 152812  [3.350 sec/step, loss=0.08540, avg_loss=0.08903, mel_loss=0.03651, linear_loss=0.04889]
[2020-05-12 04:33:24.362]  Step 152813  [3.225 sec/step, loss=0.07892, avg_loss=0.08900, mel_loss=0.03375, linear_loss=0.04517]
[2020-05-12 04:33:26.999]  Step 152814  [3.241 sec/step, loss=0.09203, avg_loss=0.08912, mel_loss=0.04093, linear_loss=0.05110]
[2020-05-12 04:33:31.610]  Step 152815  [3.198 sec/step, loss=0.09520, avg_loss=0.08911, mel_loss=0.04292, linear_loss=0.05228]
[2020-05-12 04:33:35.236]  Step 152816  [3.216 sec/step, loss=0.09488, avg_loss=0.08915, mel_loss=0.04240, linear_loss=0.05248]
[2020-05-12 04:33:38.797]  Step 152817  [3.234 sec/step, loss=0.09387, avg_loss=0.08919, mel_loss=0.04225, linear_loss=0.05163]
[2020-05-12 04:33:40.314]  Step 152818  [3.219 sec/step, loss=0.08678, avg_loss=0.08911, mel_loss=0.03793, linear_loss=0.04885]
[2020-05-12 04:33:45.505]  Step 152819  [3.241 sec/step, loss=0.09435, avg_loss=0.08913, mel_loss=0.04275, linear_loss=0.05160]
[2020-05-12 04:33:46.876]  Step 152820  [3.187 sec/step, loss=0.08305, avg_loss=0.08899, mel_loss=0.03642, linear_loss=0.04663]
[2020-05-12 04:33:47.348]  Generated 32 batches of size 32 in 1.837 sec
[2020-05-12 04:33:53.742]  Step 152821  [3.214 sec/step, loss=0.09612, avg_loss=0.08899, mel_loss=0.04407, linear_loss=0.05205]
[2020-05-12 04:33:58.088]  Step 152822  [3.232 sec/step, loss=0.09476, avg_loss=0.08904, mel_loss=0.04259, linear_loss=0.05218]
[2020-05-12 04:34:00.311]  Step 152823  [3.230 sec/step, loss=0.09161, avg_loss=0.08906, mel_loss=0.04065, linear_loss=0.05096]
[2020-05-12 04:34:02.821]  Step 152824  [3.214 sec/step, loss=0.09228, avg_loss=0.08901, mel_loss=0.04058, linear_loss=0.05169]
[2020-05-12 04:34:06.633]  Step 152825  [3.240 sec/step, loss=0.09619, avg_loss=0.08916, mel_loss=0.04318, linear_loss=0.05302]
[2020-05-12 04:34:09.937]  Step 152826  [3.262 sec/step, loss=0.09570, avg_loss=0.08926, mel_loss=0.04297, linear_loss=0.05272]
[2020-05-12 04:34:18.942]  Step 152827  [3.277 sec/step, loss=0.09622, avg_loss=0.08924, mel_loss=0.04467, linear_loss=0.05155]
[2020-05-12 04:34:20.341]  Step 152828  [3.285 sec/step, loss=0.08483, avg_loss=0.08940, mel_loss=0.03692, linear_loss=0.04791]
[2020-05-12 04:34:21.566]  Step 152829  [3.281 sec/step, loss=0.08404, avg_loss=0.08938, mel_loss=0.03644, linear_loss=0.04760]
[2020-05-12 04:34:28.882]  Step 152830  [3.321 sec/step, loss=0.09806, avg_loss=0.08941, mel_loss=0.04518, linear_loss=0.05288]
[2020-05-12 04:34:31.693]  Step 152831  [3.340 sec/step, loss=0.09103, avg_loss=0.08956, mel_loss=0.04025, linear_loss=0.05078]
[2020-05-12 04:34:32.497]  Step 152832  [3.302 sec/step, loss=0.07994, avg_loss=0.08939, mel_loss=0.03439, linear_loss=0.04554]
[2020-05-12 04:34:36.485]  Step 152833  [3.322 sec/step, loss=0.09580, avg_loss=0.08945, mel_loss=0.04312, linear_loss=0.05268]
[2020-05-12 04:34:41.168]  Step 152834  [3.318 sec/step, loss=0.09888, avg_loss=0.08948, mel_loss=0.04484, linear_loss=0.05404]
[2020-05-12 04:34:43.192]  Step 152835  [3.324 sec/step, loss=0.08922, avg_loss=0.08952, mel_loss=0.03947, linear_loss=0.04974]
[2020-05-12 04:34:45.435]  Step 152836  [3.319 sec/step, loss=0.09108, avg_loss=0.08951, mel_loss=0.04028, linear_loss=0.05080]
[2020-05-12 04:34:59.708]  Step 152837  [3.417 sec/step, loss=0.07540, avg_loss=0.08930, mel_loss=0.03561, linear_loss=0.03979]
[2020-05-12 04:35:03.157]  Step 152838  [3.430 sec/step, loss=0.09521, avg_loss=0.08934, mel_loss=0.04261, linear_loss=0.05259]
[2020-05-12 04:35:06.267]  Step 152839  [3.443 sec/step, loss=0.09593, avg_loss=0.08941, mel_loss=0.04293, linear_loss=0.05300]
[2020-05-12 04:35:11.902]  Step 152840  [3.475 sec/step, loss=0.09653, avg_loss=0.08943, mel_loss=0.04384, linear_loss=0.05269]
[2020-05-12 04:35:20.574]  Step 152841  [3.513 sec/step, loss=0.09590, avg_loss=0.08942, mel_loss=0.04443, linear_loss=0.05147]
[2020-05-12 04:35:23.455]  Step 152842  [3.522 sec/step, loss=0.09384, avg_loss=0.08947, mel_loss=0.04176, linear_loss=0.05208]
[2020-05-12 04:35:25.937]  Step 152843  [3.534 sec/step, loss=0.09043, avg_loss=0.08952, mel_loss=0.04002, linear_loss=0.05042]
[2020-05-12 04:35:29.603]  Step 152844  [3.496 sec/step, loss=0.09667, avg_loss=0.08951, mel_loss=0.04338, linear_loss=0.05329]
[2020-05-12 04:35:33.115]  Step 152845  [3.516 sec/step, loss=0.09421, avg_loss=0.08957, mel_loss=0.04217, linear_loss=0.05205]
[2020-05-12 04:35:34.216]  Step 152846  [3.519 sec/step, loss=0.08226, avg_loss=0.08965, mel_loss=0.03544, linear_loss=0.04682]
[2020-05-12 04:35:36.017]  Step 152847  [3.515 sec/step, loss=0.08937, avg_loss=0.08964, mel_loss=0.03890, linear_loss=0.05047]
[2020-05-12 04:35:37.768]  Step 152848  [3.502 sec/step, loss=0.08832, avg_loss=0.08957, mel_loss=0.03827, linear_loss=0.05005]
[2020-05-12 04:35:38.599]  Step 152849  [3.476 sec/step, loss=0.07523, avg_loss=0.08941, mel_loss=0.03240, linear_loss=0.04283]
[2020-05-12 04:35:39.974]  Step 152850  [3.402 sec/step, loss=0.08551, avg_loss=0.08929, mel_loss=0.03731, linear_loss=0.04819]
[2020-05-12 04:35:39.974]  Writing summary at step: 152850
[2020-05-12 04:35:41.574]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152850
[2020-05-12 04:35:43.121]  Saving audio and alignment...
[2020-05-12 04:35:45.238]  Generated 32 batches of size 32 in 1.544 sec
[2020-05-12 04:35:46.545]  Input: 아무도 안 일어나시더래요~_____________
[2020-05-12 04:35:47.558]  Step 152851  [3.393 sec/step, loss=0.07852, avg_loss=0.08921, mel_loss=0.03394, linear_loss=0.04459]
[2020-05-12 04:35:48.571]  Step 152852  [3.361 sec/step, loss=0.07757, avg_loss=0.08903, mel_loss=0.03337, linear_loss=0.04420]
[2020-05-12 04:35:55.016]  Step 152853  [3.417 sec/step, loss=0.09654, avg_loss=0.08922, mel_loss=0.04426, linear_loss=0.05228]
[2020-05-12 04:35:57.180]  Step 152854  [3.424 sec/step, loss=0.09193, avg_loss=0.08930, mel_loss=0.04071, linear_loss=0.05122]
[2020-05-12 04:36:03.070]  Step 152855  [3.451 sec/step, loss=0.09707, avg_loss=0.08931, mel_loss=0.04394, linear_loss=0.05314]
[2020-05-12 04:36:03.872]  Step 152856  [3.449 sec/step, loss=0.07131, avg_loss=0.08923, mel_loss=0.03117, linear_loss=0.04013]
[2020-05-12 04:36:05.932]  Step 152857  [3.442 sec/step, loss=0.08318, avg_loss=0.08913, mel_loss=0.03612, linear_loss=0.04706]
[2020-05-12 04:36:13.505]  Step 152858  [3.509 sec/step, loss=0.09731, avg_loss=0.08937, mel_loss=0.04429, linear_loss=0.05303]
[2020-05-12 04:36:17.516]  Step 152859  [3.403 sec/step, loss=0.09668, avg_loss=0.08956, mel_loss=0.04341, linear_loss=0.05326]
[2020-05-12 04:36:18.331]  Step 152860  [3.332 sec/step, loss=0.07276, avg_loss=0.08930, mel_loss=0.03125, linear_loss=0.04151]
[2020-05-12 04:36:23.686]  Step 152861  [3.327 sec/step, loss=0.09563, avg_loss=0.08927, mel_loss=0.04361, linear_loss=0.05202]
[2020-05-12 04:36:29.418]  Step 152862  [3.358 sec/step, loss=0.09685, avg_loss=0.08931, mel_loss=0.04400, linear_loss=0.05284]
[2020-05-12 04:36:44.205]  Step 152863  [3.494 sec/step, loss=0.07645, avg_loss=0.08924, mel_loss=0.03650, linear_loss=0.03996]
[2020-05-12 04:36:45.317]  Step 152864  [3.494 sec/step, loss=0.08326, avg_loss=0.08924, mel_loss=0.03567, linear_loss=0.04758]
[2020-05-12 04:36:47.298]  Step 152865  [3.498 sec/step, loss=0.09084, avg_loss=0.08928, mel_loss=0.03988, linear_loss=0.05096]
[2020-05-12 04:36:51.643]  Step 152866  [3.531 sec/step, loss=0.09791, avg_loss=0.08946, mel_loss=0.04432, linear_loss=0.05359]
[2020-05-12 04:36:54.111]  Step 152867  [3.524 sec/step, loss=0.09214, avg_loss=0.08943, mel_loss=0.04040, linear_loss=0.05174]
[2020-05-12 04:36:57.543]  Step 152868  [3.547 sec/step, loss=0.09451, avg_loss=0.08955, mel_loss=0.04219, linear_loss=0.05232]
[2020-05-12 04:36:59.503]  Step 152869  [3.509 sec/step, loss=0.08892, avg_loss=0.08947, mel_loss=0.03882, linear_loss=0.05010]
[2020-05-12 04:37:02.395]  Step 152870  [3.474 sec/step, loss=0.09293, avg_loss=0.08945, mel_loss=0.04118, linear_loss=0.05175]
[2020-05-12 04:37:05.510]  Step 152871  [3.495 sec/step, loss=0.09501, avg_loss=0.08962, mel_loss=0.04230, linear_loss=0.05271]
[2020-05-12 04:37:06.985]  Step 152872  [3.474 sec/step, loss=0.08546, avg_loss=0.08953, mel_loss=0.03742, linear_loss=0.04804]
[2020-05-12 04:37:08.006]  Step 152873  [3.453 sec/step, loss=0.08103, avg_loss=0.08939, mel_loss=0.03511, linear_loss=0.04592]
[2020-05-12 04:37:12.544]  Step 152874  [3.492 sec/step, loss=0.09790, avg_loss=0.08968, mel_loss=0.04424, linear_loss=0.05366]
[2020-05-12 04:37:14.699]  Step 152875  [3.503 sec/step, loss=0.09294, avg_loss=0.08978, mel_loss=0.04094, linear_loss=0.05200]
[2020-05-12 04:37:16.081]  Step 152876  [3.510 sec/step, loss=0.08370, avg_loss=0.08986, mel_loss=0.03688, linear_loss=0.04683]
[2020-05-12 04:37:22.692]  Step 152877  [3.555 sec/step, loss=0.09720, avg_loss=0.08993, mel_loss=0.04456, linear_loss=0.05264]
[2020-05-12 04:37:23.948]  Step 152878  [3.531 sec/step, loss=0.08112, avg_loss=0.08978, mel_loss=0.03515, linear_loss=0.04597]
[2020-05-12 04:37:25.575]  Step 152879  [3.528 sec/step, loss=0.08880, avg_loss=0.08979, mel_loss=0.03897, linear_loss=0.04983]
[2020-05-12 04:37:26.132]  Step 152880  [3.510 sec/step, loss=0.07161, avg_loss=0.08958, mel_loss=0.03120, linear_loss=0.04041]
[2020-05-12 04:37:30.011]  Step 152881  [3.521 sec/step, loss=0.09492, avg_loss=0.08962, mel_loss=0.04261, linear_loss=0.05231]
[2020-05-12 04:37:31.765]  Generated 32 batches of size 32 in 1.748 sec
[2020-05-12 04:37:32.431]  Step 152882  [3.519 sec/step, loss=0.09038, avg_loss=0.08963, mel_loss=0.04004, linear_loss=0.05034]
[2020-05-12 04:37:33.246]  Step 152883  [3.513 sec/step, loss=0.07745, avg_loss=0.08954, mel_loss=0.03317, linear_loss=0.04428]
[2020-05-12 04:37:36.576]  Step 152884  [3.534 sec/step, loss=0.09391, avg_loss=0.08964, mel_loss=0.04188, linear_loss=0.05203]
[2020-05-12 04:37:37.577]  Step 152885  [3.530 sec/step, loss=0.08029, avg_loss=0.08960, mel_loss=0.03445, linear_loss=0.04584]
[2020-05-12 04:37:39.231]  Step 152886  [3.423 sec/step, loss=0.09003, avg_loss=0.08961, mel_loss=0.03963, linear_loss=0.05040]
[2020-05-12 04:37:47.560]  Step 152887  [3.465 sec/step, loss=0.09616, avg_loss=0.08961, mel_loss=0.04449, linear_loss=0.05168]
[2020-05-12 04:37:54.945]  Step 152888  [3.519 sec/step, loss=0.09731, avg_loss=0.08970, mel_loss=0.04470, linear_loss=0.05260]
[2020-05-12 04:37:57.712]  Step 152889  [3.519 sec/step, loss=0.09326, avg_loss=0.08971, mel_loss=0.04146, linear_loss=0.05179]
[2020-05-12 04:37:59.515]  Step 152890  [3.485 sec/step, loss=0.08770, avg_loss=0.08963, mel_loss=0.03837, linear_loss=0.04933]
[2020-05-12 04:38:04.829]  Step 152891  [3.462 sec/step, loss=0.09771, avg_loss=0.08962, mel_loss=0.04413, linear_loss=0.05358]
[2020-05-12 04:38:08.214]  Step 152892  [3.449 sec/step, loss=0.09770, avg_loss=0.08963, mel_loss=0.04375, linear_loss=0.05395]
[2020-05-12 04:38:10.579]  Step 152893  [3.455 sec/step, loss=0.09163, avg_loss=0.08965, mel_loss=0.04068, linear_loss=0.05095]
[2020-05-12 04:38:11.165]  Step 152894  [3.445 sec/step, loss=0.06716, avg_loss=0.08945, mel_loss=0.02941, linear_loss=0.03775]
[2020-05-12 04:38:12.669]  Step 152895  [3.424 sec/step, loss=0.08866, avg_loss=0.08938, mel_loss=0.03861, linear_loss=0.05005]
[2020-05-12 04:38:16.093]  Step 152896  [3.416 sec/step, loss=0.09543, avg_loss=0.08936, mel_loss=0.04291, linear_loss=0.05252]
[2020-05-12 04:38:18.999]  Step 152897  [3.357 sec/step, loss=0.09332, avg_loss=0.08936, mel_loss=0.04142, linear_loss=0.05190]
[2020-05-12 04:38:25.371]  Step 152898  [3.412 sec/step, loss=0.09740, avg_loss=0.08956, mel_loss=0.04476, linear_loss=0.05265]
[2020-05-12 04:38:28.174]  Step 152899  [3.430 sec/step, loss=0.09215, avg_loss=0.08966, mel_loss=0.04127, linear_loss=0.05087]
[2020-05-12 04:38:30.101]  Step 152900  [3.317 sec/step, loss=0.09031, avg_loss=0.08973, mel_loss=0.03974, linear_loss=0.05056]
[2020-05-12 04:38:30.102]  Writing summary at step: 152900
[2020-05-12 04:38:32.295]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152900
[2020-05-12 04:38:33.796]  Saving audio and alignment...
[2020-05-12 04:38:35.478]  Input: 결과는~________
[2020-05-12 04:38:48.640]  Step 152901  [3.442 sec/step, loss=0.08406, avg_loss=0.08980, mel_loss=0.03964, linear_loss=0.04442]
[2020-05-12 04:38:57.691]  Step 152902  [3.512 sec/step, loss=0.09701, avg_loss=0.08988, mel_loss=0.04511, linear_loss=0.05190]
[2020-05-12 04:38:58.963]  Step 152903  [3.498 sec/step, loss=0.08569, avg_loss=0.08980, mel_loss=0.03719, linear_loss=0.04850]
[2020-05-12 04:39:01.011]  Step 152904  [3.502 sec/step, loss=0.08794, avg_loss=0.08979, mel_loss=0.03876, linear_loss=0.04918]
[2020-05-12 04:39:01.968]  Step 152905  [3.493 sec/step, loss=0.08170, avg_loss=0.08973, mel_loss=0.03502, linear_loss=0.04668]
[2020-05-12 04:39:03.714]  Step 152906  [3.481 sec/step, loss=0.08928, avg_loss=0.08968, mel_loss=0.03872, linear_loss=0.05056]
[2020-05-12 04:39:07.315]  Step 152907  [3.511 sec/step, loss=0.09760, avg_loss=0.08995, mel_loss=0.04395, linear_loss=0.05365]
[2020-05-12 04:39:11.404]  Step 152908  [3.497 sec/step, loss=0.09561, avg_loss=0.08993, mel_loss=0.04284, linear_loss=0.05277]
[2020-05-12 04:39:12.515]  Step 152909  [3.493 sec/step, loss=0.08223, avg_loss=0.08986, mel_loss=0.03543, linear_loss=0.04680]
[2020-05-12 04:39:17.192]  Step 152910  [3.461 sec/step, loss=0.09665, avg_loss=0.08987, mel_loss=0.04347, linear_loss=0.05318]
[2020-05-12 04:39:20.308]  Step 152911  [3.460 sec/step, loss=0.09545, avg_loss=0.08988, mel_loss=0.04297, linear_loss=0.05249]
[2020-05-12 04:39:21.956]  Step 152912  [3.465 sec/step, loss=0.08791, avg_loss=0.08991, mel_loss=0.03850, linear_loss=0.04942]
[2020-05-12 04:39:22.088]  Generated 32 batches of size 32 in 1.774 sec
[2020-05-12 04:39:23.295]  Step 152913  [3.470 sec/step, loss=0.08739, avg_loss=0.08999, mel_loss=0.03789, linear_loss=0.04950]
[2020-05-12 04:39:24.458]  Step 152914  [3.455 sec/step, loss=0.08364, avg_loss=0.08991, mel_loss=0.03593, linear_loss=0.04770]
[2020-05-12 04:39:26.923]  Step 152915  [3.433 sec/step, loss=0.09069, avg_loss=0.08986, mel_loss=0.03984, linear_loss=0.05084]
[2020-05-12 04:39:27.757]  Step 152916  [3.405 sec/step, loss=0.07438, avg_loss=0.08966, mel_loss=0.03299, linear_loss=0.04139]
[2020-05-12 04:39:28.755]  Step 152917  [3.380 sec/step, loss=0.08006, avg_loss=0.08952, mel_loss=0.03466, linear_loss=0.04541]
[2020-05-12 04:39:36.363]  Step 152918  [3.441 sec/step, loss=0.09822, avg_loss=0.08963, mel_loss=0.04538, linear_loss=0.05284]
[2020-05-12 04:39:40.602]  Step 152919  [3.431 sec/step, loss=0.09519, avg_loss=0.08964, mel_loss=0.04316, linear_loss=0.05203]
[2020-05-12 04:39:46.272]  Step 152920  [3.474 sec/step, loss=0.09798, avg_loss=0.08979, mel_loss=0.04478, linear_loss=0.05319]
[2020-05-12 04:39:47.336]  Step 152921  [3.416 sec/step, loss=0.08434, avg_loss=0.08967, mel_loss=0.03625, linear_loss=0.04809]
[2020-05-12 04:40:01.817]  Step 152922  [3.518 sec/step, loss=0.07561, avg_loss=0.08948, mel_loss=0.03570, linear_loss=0.03991]
[2020-05-12 04:40:05.430]  Step 152923  [3.531 sec/step, loss=0.09587, avg_loss=0.08953, mel_loss=0.04291, linear_loss=0.05296]
[2020-05-12 04:40:10.782]  Step 152924  [3.560 sec/step, loss=0.09685, avg_loss=0.08957, mel_loss=0.04408, linear_loss=0.05277]
[2020-05-12 04:40:12.548]  Step 152925  [3.539 sec/step, loss=0.08872, avg_loss=0.08950, mel_loss=0.03886, linear_loss=0.04986]
[2020-05-12 04:40:13.117]  Step 152926  [3.512 sec/step, loss=0.07378, avg_loss=0.08928, mel_loss=0.03268, linear_loss=0.04110]
[2020-05-12 04:40:14.626]  Step 152927  [3.437 sec/step, loss=0.08561, avg_loss=0.08917, mel_loss=0.03725, linear_loss=0.04836]
[2020-05-12 04:40:17.110]  Step 152928  [3.448 sec/step, loss=0.08975, avg_loss=0.08922, mel_loss=0.03967, linear_loss=0.05008]
[2020-05-12 04:40:18.086]  Step 152929  [3.445 sec/step, loss=0.08265, avg_loss=0.08921, mel_loss=0.03551, linear_loss=0.04714]
[2020-05-12 04:40:24.778]  Step 152930  [3.439 sec/step, loss=0.09682, avg_loss=0.08919, mel_loss=0.04441, linear_loss=0.05241]
[2020-05-12 04:40:33.293]  Step 152931  [3.496 sec/step, loss=0.09372, avg_loss=0.08922, mel_loss=0.04331, linear_loss=0.05041]
[2020-05-12 04:40:37.228]  Step 152932  [3.528 sec/step, loss=0.09445, avg_loss=0.08937, mel_loss=0.04234, linear_loss=0.05212]
[2020-05-12 04:40:40.099]  Step 152933  [3.516 sec/step, loss=0.09372, avg_loss=0.08935, mel_loss=0.04173, linear_loss=0.05198]
[2020-05-12 04:40:44.481]  Step 152934  [3.513 sec/step, loss=0.09729, avg_loss=0.08933, mel_loss=0.04394, linear_loss=0.05335]
[2020-05-12 04:40:45.804]  Step 152935  [3.506 sec/step, loss=0.08637, avg_loss=0.08930, mel_loss=0.03738, linear_loss=0.04899]
[2020-05-12 04:40:46.566]  Step 152936  [3.492 sec/step, loss=0.07362, avg_loss=0.08913, mel_loss=0.03218, linear_loss=0.04144]
[2020-05-12 04:40:48.813]  Step 152937  [3.371 sec/step, loss=0.09172, avg_loss=0.08929, mel_loss=0.04059, linear_loss=0.05113]
[2020-05-12 04:40:49.741]  Step 152938  [3.346 sec/step, loss=0.07914, avg_loss=0.08913, mel_loss=0.03401, linear_loss=0.04512]
[2020-05-12 04:40:51.732]  Step 152939  [3.335 sec/step, loss=0.09006, avg_loss=0.08907, mel_loss=0.03961, linear_loss=0.05046]
[2020-05-12 04:40:52.541]  Step 152940  [3.287 sec/step, loss=0.07702, avg_loss=0.08887, mel_loss=0.03312, linear_loss=0.04390]
[2020-05-12 04:40:53.718]  Step 152941  [3.212 sec/step, loss=0.08211, avg_loss=0.08874, mel_loss=0.03544, linear_loss=0.04667]
[2020-05-12 04:40:56.737]  Step 152942  [3.213 sec/step, loss=0.09499, avg_loss=0.08875, mel_loss=0.04233, linear_loss=0.05266]
[2020-05-12 04:40:58.352]  Step 152943  [3.204 sec/step, loss=0.08993, avg_loss=0.08874, mel_loss=0.03950, linear_loss=0.05042]
[2020-05-12 04:41:00.086]  Generated 32 batches of size 32 in 1.728 sec
[2020-05-12 04:41:00.563]  Step 152944  [3.190 sec/step, loss=0.09152, avg_loss=0.08869, mel_loss=0.04051, linear_loss=0.05101]
[2020-05-12 04:41:03.754]  Step 152945  [3.187 sec/step, loss=0.09538, avg_loss=0.08870, mel_loss=0.04250, linear_loss=0.05288]
[2020-05-12 04:41:09.458]  Step 152946  [3.233 sec/step, loss=0.09869, avg_loss=0.08887, mel_loss=0.04545, linear_loss=0.05324]
[2020-05-12 04:41:12.954]  Step 152947  [3.250 sec/step, loss=0.09268, avg_loss=0.08890, mel_loss=0.04161, linear_loss=0.05107]
[2020-05-12 04:41:14.301]  Step 152948  [3.246 sec/step, loss=0.08722, avg_loss=0.08889, mel_loss=0.03785, linear_loss=0.04937]
[2020-05-12 04:41:19.000]  Step 152949  [3.284 sec/step, loss=0.09772, avg_loss=0.08911, mel_loss=0.04432, linear_loss=0.05340]
[2020-05-12 04:41:21.800]  Step 152950  [3.299 sec/step, loss=0.09036, avg_loss=0.08916, mel_loss=0.03995, linear_loss=0.05041]
[2020-05-12 04:41:21.800]  Writing summary at step: 152950
[2020-05-12 04:41:29.441]  Saving checkpoint to: ./logs-tacotron/model.ckpt-152950
[2020-05-12 04:41:30.973]  Saving audio and alignment...
[2020-05-12 04:41:34.388]  Input: 다으음 대본에 이렇게 적혀 있어요~________
[2020-05-12 04:41:42.853]  Step 152951  [3.373 sec/step, loss=0.09523, avg_loss=0.08933, mel_loss=0.04396, linear_loss=0.05127]
[2020-05-12 04:41:44.410]  Step 152952  [3.378 sec/step, loss=0.08659, avg_loss=0.08942, mel_loss=0.03773, linear_loss=0.04887]
[2020-05-12 04:41:46.866]  Step 152953  [3.339 sec/step, loss=0.09210, avg_loss=0.08938, mel_loss=0.04062, linear_loss=0.05148]
[2020-05-12 04:41:48.740]  Step 152954  [3.336 sec/step, loss=0.09094, avg_loss=0.08937, mel_loss=0.03974, linear_loss=0.05120]
[2020-05-12 04:41:51.757]  Step 152955  [3.307 sec/step, loss=0.09128, avg_loss=0.08931, mel_loss=0.04073, linear_loss=0.05055]
[2020-05-12 04:41:55.571]  Step 152956  [3.337 sec/step, loss=0.09473, avg_loss=0.08954, mel_loss=0.04224, linear_loss=0.05249]
[2020-05-12 04:41:58.278]  Step 152957  [3.344 sec/step, loss=0.09107, avg_loss=0.08962, mel_loss=0.04004, linear_loss=0.05103]
[2020-05-12 04:41:59.445]  Step 152958  [3.280 sec/step, loss=0.08456, avg_loss=0.08949, mel_loss=0.03652, linear_loss=0.04804]
[2020-05-12 04:42:03.720]  Step 152959  [3.282 sec/step, loss=0.09473, avg_loss=0.08947, mel_loss=0.04253, linear_loss=0.05220]
[2020-05-12 04:42:05.178]  Step 152960  [3.289 sec/step, loss=0.08563, avg_loss=0.08960, mel_loss=0.03740, linear_loss=0.04823]
[2020-05-12 04:42:07.242]  Step 152961  [3.256 sec/step, loss=0.08869, avg_loss=0.08953, mel_loss=0.03920, linear_loss=0.04949]
[2020-05-12 04:42:09.023]  Step 152962  [3.216 sec/step, loss=0.08764, avg_loss=0.08944, mel_loss=0.03811, linear_loss=0.04953]
[2020-05-12 04:42:12.757]  Step 152963  [3.106 sec/step, loss=0.09788, avg_loss=0.08966, mel_loss=0.04380, linear_loss=0.05407]
[2020-05-12 04:42:18.848]  Step 152964  [3.155 sec/step, loss=0.09743, avg_loss=0.08980, mel_loss=0.04445, linear_loss=0.05298]
[2020-05-12 04:42:20.773]  Step 152965  [3.155 sec/step, loss=0.08749, avg_loss=0.08976, mel_loss=0.03841, linear_loss=0.04908]
[2020-05-12 04:42:26.412]  Step 152966  [3.168 sec/step, loss=0.09532, avg_loss=0.08974, mel_loss=0.04341, linear_loss=0.05191]
[2020-05-12 04:42:31.412]  Step 152967  [3.193 sec/step, loss=0.09579, avg_loss=0.08978, mel_loss=0.04347, linear_loss=0.05232]
[2020-05-12 04:42:34.478]  Step 152968  [3.189 sec/step, loss=0.09436, avg_loss=0.08977, mel_loss=0.04235, linear_loss=0.05202]
[2020-05-12 04:42:41.853]  Step 152969  [3.244 sec/step, loss=0.09674, avg_loss=0.08985, mel_loss=0.04450, linear_loss=0.05224]
[2020-05-12 04:42:46.425]  Step 152970  [3.260 sec/step, loss=0.09569, avg_loss=0.08988, mel_loss=0.04326, linear_loss=0.05243]
[2020-05-12 04:42:48.102]  Step 152971  [3.246 sec/step, loss=0.08816, avg_loss=0.08981, mel_loss=0.03877, linear_loss=0.04939]
[2020-05-12 04:42:59.739]  Step 152972  [3.348 sec/step, loss=0.08807, avg_loss=0.08984, mel_loss=0.04132, linear_loss=0.04675]
[2020-05-12 04:43:01.027]  Step 152973  [3.350 sec/step, loss=0.08427, avg_loss=0.08987, mel_loss=0.03681, linear_loss=0.04746]
[2020-05-12 04:43:01.901]  Step 152974  [3.314 sec/step, loss=0.07692, avg_loss=0.08966, mel_loss=0.03277, linear_loss=0.04415]
[2020-05-12 04:43:02.805]  Generated 32 batches of size 32 in 1.772 sec
[2020-05-12 04:43:04.893]  Step 152975  [3.322 sec/step, loss=0.09285, avg_loss=0.08966, mel_loss=0.04133, linear_loss=0.05152]
[2020-05-12 04:43:05.471]  Step 152976  [3.314 sec/step, loss=0.06400, avg_loss=0.08946, mel_loss=0.02817, linear_loss=0.03583]
[2020-05-12 04:43:09.061]  Step 152977  [3.284 sec/step, loss=0.09666, avg_loss=0.08946, mel_loss=0.04318, linear_loss=0.05348]
[2020-05-12 04:43:11.456]  Step 152978  [3.295 sec/step, loss=0.09133, avg_loss=0.08956, mel_loss=0.04038, linear_loss=0.05095]
[2020-05-12 04:43:12.462]  Step 152979  [3.289 sec/step, loss=0.08198, avg_loss=0.08949, mel_loss=0.03517, linear_loss=0.04681]
[2020-05-12 04:43:13.458]  Step 152980  [3.293 sec/step, loss=0.08349, avg_loss=0.08961, mel_loss=0.03605, linear_loss=0.04744]
[2020-05-12 04:43:14.255]  Step 152981  [3.263 sec/step, loss=0.07421, avg_loss=0.08940, mel_loss=0.03179, linear_loss=0.04242]
[2020-05-12 04:43:17.683]  Step 152982  [3.273 sec/step, loss=0.09300, avg_loss=0.08943, mel_loss=0.04172, linear_loss=0.05128]
[2020-05-12 04:43:18.783]  Step 152983  [3.275 sec/step, loss=0.08105, avg_loss=0.08946, mel_loss=0.03480, linear_loss=0.04625]
[2020-05-12 04:43:19.628]  Step 152984  [3.251 sec/step, loss=0.07441, avg_loss=0.08927, mel_loss=0.03284, linear_loss=0.04156]
[2020-05-12 04:43:34.052]  Step 152985  [3.385 sec/step, loss=0.07678, avg_loss=0.08923, mel_loss=0.03640, linear_loss=0.04038]
[2020-05-12 04:43:39.223]  Step 152986  [3.420 sec/step, loss=0.09667, avg_loss=0.08930, mel_loss=0.04384, linear_loss=0.05284]
[2020-05-12 04:43:40.579]  Step 152987  [3.350 sec/step, loss=0.08634, avg_loss=0.08920, mel_loss=0.03773, linear_loss=0.04862]
[2020-05-12 04:43:44.743]  Step 152988  [3.318 sec/step, loss=0.09608, avg_loss=0.08919, mel_loss=0.04334, linear_loss=0.05275]
[2020-05-12 04:43:45.907]  Step 152989  [3.302 sec/step, loss=0.08335, avg_loss=0.08909, mel_loss=0.03605, linear_loss=0.04731]
[2020-05-12 04:43:48.818]  Step 152990  [3.313 sec/step, loss=0.09174, avg_loss=0.08913, mel_loss=0.04081, linear_loss=0.05093]
[2020-05-12 04:43:50.275]  Step 152991  [3.275 sec/step, loss=0.08931, avg_loss=0.08905, mel_loss=0.03899, linear_loss=0.05032]
[2020-05-12 04:43:52.321]  Step 152992  [3.261 sec/step, loss=0.09114, avg_loss=0.08898, mel_loss=0.03999, linear_loss=0.05115]
[2020-05-12 04:43:53.643]  Step 152993  [3.251 sec/step, loss=0.08556, avg_loss=0.08892, mel_loss=0.03729, linear_loss=0.04827]
[2020-05-12 04:43:55.804]  Step 152994  [3.266 sec/step, loss=0.08854, avg_loss=0.08914, mel_loss=0.03906, linear_loss=0.04948]
[2020-05-12 04:43:58.191]  Step 152995  [3.275 sec/step, loss=0.09092, avg_loss=0.08916, mel_loss=0.04014, linear_loss=0.05078]
[2020-05-12 04:43:59.810]  Step 152996  [3.257 sec/step, loss=0.08762, avg_loss=0.08908, mel_loss=0.03835, linear_loss=0.04927]
[2020-05-12 04:44:02.998]  Step 152997  [3.260 sec/step, loss=0.09574, avg_loss=0.08910, mel_loss=0.04282, linear_loss=0.05293]
[2020-05-12 04:44:06.721]  Step 152998  [3.234 sec/step, loss=0.09666, avg_loss=0.08910, mel_loss=0.04348, linear_loss=0.05318]
[2020-05-12 04:44:07.709]  Step 152999  [3.215 sec/step, loss=0.08274, avg_loss=0.08900, mel_loss=0.03573, linear_loss=0.04701]
[2020-05-12 04:44:11.197]  Step 153000  [3.231 sec/step, loss=0.09486, avg_loss=0.08905, mel_loss=0.04258, linear_loss=0.05227]
[2020-05-12 04:44:11.197]  Writing summary at step: 153000
[2020-05-12 04:44:11.739]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153000
[2020-05-12 04:44:13.303]  Saving audio and alignment...
[2020-05-12 04:44:19.492]  Input: 자 계속해서 부산 엠비씨와 울산 엠비씨 기출질문 다섯~_________________________________
[2020-05-12 04:44:25.036]  Step 153001  [3.155 sec/step, loss=0.09873, avg_loss=0.08919, mel_loss=0.04516, linear_loss=0.05358]
[2020-05-12 04:44:29.602]  Step 153002  [3.110 sec/step, loss=0.09661, avg_loss=0.08919, mel_loss=0.04374, linear_loss=0.05287]
[2020-05-12 04:44:30.439]  Step 153003  [3.106 sec/step, loss=0.07810, avg_loss=0.08911, mel_loss=0.03349, linear_loss=0.04461]
[2020-05-12 04:44:32.240]  Generated 32 batches of size 32 in 1.795 sec
[2020-05-12 04:44:32.282]  Step 153004  [3.104 sec/step, loss=0.08687, avg_loss=0.08910, mel_loss=0.03793, linear_loss=0.04894]
[2020-05-12 04:44:34.512]  Step 153005  [3.116 sec/step, loss=0.09103, avg_loss=0.08920, mel_loss=0.04039, linear_loss=0.05064]
[2020-05-12 04:44:41.304]  Step 153006  [3.167 sec/step, loss=0.09548, avg_loss=0.08926, mel_loss=0.04364, linear_loss=0.05184]
[2020-05-12 04:44:50.136]  Step 153007  [3.219 sec/step, loss=0.09587, avg_loss=0.08924, mel_loss=0.04435, linear_loss=0.05152]
[2020-05-12 04:44:53.707]  Step 153008  [3.214 sec/step, loss=0.09171, avg_loss=0.08920, mel_loss=0.04089, linear_loss=0.05081]
[2020-05-12 04:44:56.366]  Step 153009  [3.229 sec/step, loss=0.09304, avg_loss=0.08931, mel_loss=0.04138, linear_loss=0.05166]
[2020-05-12 04:44:57.301]  Step 153010  [3.192 sec/step, loss=0.07775, avg_loss=0.08912, mel_loss=0.03329, linear_loss=0.04446]
[2020-05-12 04:44:59.190]  Step 153011  [3.180 sec/step, loss=0.08729, avg_loss=0.08904, mel_loss=0.03843, linear_loss=0.04887]
[2020-05-12 04:45:06.593]  Step 153012  [3.237 sec/step, loss=0.09818, avg_loss=0.08914, mel_loss=0.04529, linear_loss=0.05289]
[2020-05-12 04:45:07.816]  Step 153013  [3.236 sec/step, loss=0.08284, avg_loss=0.08910, mel_loss=0.03600, linear_loss=0.04684]
[2020-05-12 04:45:11.337]  Step 153014  [3.260 sec/step, loss=0.09356, avg_loss=0.08920, mel_loss=0.04199, linear_loss=0.05157]
[2020-05-12 04:45:13.941]  Step 153015  [3.261 sec/step, loss=0.09158, avg_loss=0.08921, mel_loss=0.04056, linear_loss=0.05102]
[2020-05-12 04:45:19.299]  Step 153016  [3.306 sec/step, loss=0.09779, avg_loss=0.08944, mel_loss=0.04441, linear_loss=0.05338]
[2020-05-12 04:45:22.325]  Step 153017  [3.327 sec/step, loss=0.09338, avg_loss=0.08957, mel_loss=0.04136, linear_loss=0.05202]
[2020-05-12 04:45:23.127]  Step 153018  [3.259 sec/step, loss=0.07580, avg_loss=0.08935, mel_loss=0.03268, linear_loss=0.04312]
[2020-05-12 04:45:25.545]  Step 153019  [3.240 sec/step, loss=0.09172, avg_loss=0.08931, mel_loss=0.04070, linear_loss=0.05102]
[2020-05-12 04:45:27.653]  Step 153020  [3.205 sec/step, loss=0.09143, avg_loss=0.08925, mel_loss=0.04036, linear_loss=0.05108]
[2020-05-12 04:45:34.473]  Step 153021  [3.262 sec/step, loss=0.09527, avg_loss=0.08936, mel_loss=0.04369, linear_loss=0.05158]
[2020-05-12 04:45:35.940]  Step 153022  [3.132 sec/step, loss=0.08556, avg_loss=0.08946, mel_loss=0.03722, linear_loss=0.04834]
[2020-05-12 04:45:36.954]  Step 153023  [3.106 sec/step, loss=0.08206, avg_loss=0.08932, mel_loss=0.03505, linear_loss=0.04702]
[2020-05-12 04:45:37.772]  Step 153024  [3.061 sec/step, loss=0.07941, avg_loss=0.08915, mel_loss=0.03412, linear_loss=0.04530]
[2020-05-12 04:45:42.626]  Step 153025  [3.092 sec/step, loss=0.09876, avg_loss=0.08925, mel_loss=0.04458, linear_loss=0.05418]
[2020-05-12 04:45:49.718]  Step 153026  [3.157 sec/step, loss=0.09857, avg_loss=0.08949, mel_loss=0.04537, linear_loss=0.05320]
[2020-05-12 04:45:55.418]  Step 153027  [3.199 sec/step, loss=0.09822, avg_loss=0.08962, mel_loss=0.04488, linear_loss=0.05334]
[2020-05-12 04:45:59.908]  Step 153028  [3.219 sec/step, loss=0.09593, avg_loss=0.08968, mel_loss=0.04330, linear_loss=0.05263]
[2020-05-12 04:46:02.741]  Step 153029  [3.237 sec/step, loss=0.09308, avg_loss=0.08979, mel_loss=0.04131, linear_loss=0.05178]
[2020-05-12 04:46:04.101]  Step 153030  [3.184 sec/step, loss=0.08543, avg_loss=0.08967, mel_loss=0.03717, linear_loss=0.04826]
[2020-05-12 04:46:05.786]  Step 153031  [3.116 sec/step, loss=0.08644, avg_loss=0.08960, mel_loss=0.03804, linear_loss=0.04840]
[2020-05-12 04:46:06.919]  Step 153032  [3.088 sec/step, loss=0.08538, avg_loss=0.08951, mel_loss=0.03658, linear_loss=0.04880]
[2020-05-12 04:46:08.659]  Step 153033  [3.077 sec/step, loss=0.08889, avg_loss=0.08946, mel_loss=0.03887, linear_loss=0.05003]
[2020-05-12 04:46:18.910]  Step 153034  [3.135 sec/step, loss=0.09623, avg_loss=0.08945, mel_loss=0.04445, linear_loss=0.05178]
[2020-05-12 04:46:24.675]  Step 153035  [3.180 sec/step, loss=0.09620, avg_loss=0.08955, mel_loss=0.04316, linear_loss=0.05304]
[2020-05-12 04:46:27.248]  Generated 32 batches of size 32 in 2.563 sec
[2020-05-12 04:46:28.891]  Step 153036  [3.214 sec/step, loss=0.09629, avg_loss=0.08977, mel_loss=0.04303, linear_loss=0.05326]
[2020-05-12 04:46:43.835]  Step 153037  [3.341 sec/step, loss=0.07423, avg_loss=0.08960, mel_loss=0.03516, linear_loss=0.03907]
[2020-05-12 04:46:44.405]  Step 153038  [3.338 sec/step, loss=0.07383, avg_loss=0.08955, mel_loss=0.03257, linear_loss=0.04126]
[2020-05-12 04:46:46.442]  Step 153039  [3.338 sec/step, loss=0.08822, avg_loss=0.08953, mel_loss=0.03877, linear_loss=0.04945]
[2020-05-12 04:46:48.310]  Step 153040  [3.349 sec/step, loss=0.08823, avg_loss=0.08964, mel_loss=0.03841, linear_loss=0.04983]
[2020-05-12 04:46:52.094]  Step 153041  [3.375 sec/step, loss=0.09501, avg_loss=0.08977, mel_loss=0.04249, linear_loss=0.05252]
[2020-05-12 04:46:54.514]  Step 153042  [3.369 sec/step, loss=0.09110, avg_loss=0.08973, mel_loss=0.04015, linear_loss=0.05095]
[2020-05-12 04:46:59.111]  Step 153043  [3.398 sec/step, loss=0.09736, avg_loss=0.08980, mel_loss=0.04386, linear_loss=0.05350]
[2020-05-12 04:47:00.224]  Step 153044  [3.388 sec/step, loss=0.08076, avg_loss=0.08970, mel_loss=0.03467, linear_loss=0.04609]
[2020-05-12 04:47:09.259]  Step 153045  [3.446 sec/step, loss=0.09789, avg_loss=0.08972, mel_loss=0.04541, linear_loss=0.05248]
[2020-05-12 04:47:11.086]  Step 153046  [3.407 sec/step, loss=0.08807, avg_loss=0.08962, mel_loss=0.03828, linear_loss=0.04979]
[2020-05-12 04:47:12.338]  Step 153047  [3.385 sec/step, loss=0.08449, avg_loss=0.08953, mel_loss=0.03642, linear_loss=0.04806]
[2020-05-12 04:47:13.998]  Step 153048  [3.388 sec/step, loss=0.08830, avg_loss=0.08954, mel_loss=0.03854, linear_loss=0.04977]
[2020-05-12 04:47:15.557]  Step 153049  [3.356 sec/step, loss=0.08612, avg_loss=0.08943, mel_loss=0.03762, linear_loss=0.04850]
[2020-05-12 04:47:18.060]  Step 153050  [3.354 sec/step, loss=0.09152, avg_loss=0.08944, mel_loss=0.04005, linear_loss=0.05147]
[2020-05-12 04:47:18.060]  Writing summary at step: 153050
[2020-05-12 04:47:20.287]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153050
[2020-05-12 04:47:21.847]  Saving audio and alignment...
[2020-05-12 04:47:26.675]  Input: 또 완성되면 멘트한부 저에게도 보내 주십시오~__________________
[2020-05-12 04:47:28.592]  Step 153051  [3.288 sec/step, loss=0.08729, avg_loss=0.08936, mel_loss=0.03804, linear_loss=0.04926]
[2020-05-12 04:47:33.981]  Step 153052  [3.326 sec/step, loss=0.09550, avg_loss=0.08945, mel_loss=0.04354, linear_loss=0.05196]
[2020-05-12 04:47:47.289]  Step 153053  [3.435 sec/step, loss=0.08429, avg_loss=0.08937, mel_loss=0.03976, linear_loss=0.04454]
[2020-05-12 04:47:48.109]  Step 153054  [3.424 sec/step, loss=0.07506, avg_loss=0.08921, mel_loss=0.03179, linear_loss=0.04327]
[2020-05-12 04:47:50.156]  Step 153055  [3.415 sec/step, loss=0.09039, avg_loss=0.08920, mel_loss=0.03989, linear_loss=0.05050]
[2020-05-12 04:47:57.905]  Step 153056  [3.454 sec/step, loss=0.09691, avg_loss=0.08923, mel_loss=0.04463, linear_loss=0.05229]
[2020-05-12 04:47:58.943]  Step 153057  [3.437 sec/step, loss=0.08287, avg_loss=0.08914, mel_loss=0.03554, linear_loss=0.04733]
[2020-05-12 04:48:00.316]  Step 153058  [3.439 sec/step, loss=0.08816, avg_loss=0.08918, mel_loss=0.03849, linear_loss=0.04966]
[2020-05-12 04:48:03.100]  Step 153059  [3.424 sec/step, loss=0.09247, avg_loss=0.08916, mel_loss=0.04101, linear_loss=0.05145]
[2020-05-12 04:48:04.437]  Step 153060  [3.423 sec/step, loss=0.08662, avg_loss=0.08917, mel_loss=0.03756, linear_loss=0.04906]
[2020-05-12 04:48:09.867]  Step 153061  [3.457 sec/step, loss=0.09680, avg_loss=0.08925, mel_loss=0.04412, linear_loss=0.05269]
[2020-05-12 04:48:10.445]  Step 153062  [3.445 sec/step, loss=0.06963, avg_loss=0.08907, mel_loss=0.03062, linear_loss=0.03901]
[2020-05-12 04:48:11.296]  Step 153063  [3.416 sec/step, loss=0.07584, avg_loss=0.08885, mel_loss=0.03258, linear_loss=0.04326]
[2020-05-12 04:48:12.225]  Step 153064  [3.364 sec/step, loss=0.07856, avg_loss=0.08866, mel_loss=0.03352, linear_loss=0.04503]
[2020-05-12 04:48:16.072]  Step 153065  [3.384 sec/step, loss=0.09695, avg_loss=0.08875, mel_loss=0.04340, linear_loss=0.05354]
[2020-05-12 04:48:17.200]  Step 153066  [3.339 sec/step, loss=0.08385, avg_loss=0.08864, mel_loss=0.03622, linear_loss=0.04763]
[2020-05-12 04:48:17.816]  Generated 32 batches of size 32 in 1.738 sec
[2020-05-12 04:48:21.861]  Step 153067  [3.335 sec/step, loss=0.09669, avg_loss=0.08865, mel_loss=0.04384, linear_loss=0.05285]
[2020-05-12 04:48:26.072]  Step 153068  [3.347 sec/step, loss=0.09576, avg_loss=0.08866, mel_loss=0.04322, linear_loss=0.05253]
[2020-05-12 04:48:29.500]  Step 153069  [3.307 sec/step, loss=0.09510, avg_loss=0.08865, mel_loss=0.04243, linear_loss=0.05267]
[2020-05-12 04:48:35.882]  Step 153070  [3.325 sec/step, loss=0.09746, avg_loss=0.08866, mel_loss=0.04457, linear_loss=0.05289]
[2020-05-12 04:48:38.175]  Step 153071  [3.331 sec/step, loss=0.08924, avg_loss=0.08867, mel_loss=0.03971, linear_loss=0.04952]
[2020-05-12 04:48:41.761]  Step 153072  [3.251 sec/step, loss=0.09403, avg_loss=0.08873, mel_loss=0.04238, linear_loss=0.05165]
[2020-05-12 04:48:44.677]  Step 153073  [3.267 sec/step, loss=0.09281, avg_loss=0.08882, mel_loss=0.04138, linear_loss=0.05143]
[2020-05-12 04:48:48.413]  Step 153074  [3.296 sec/step, loss=0.09632, avg_loss=0.08901, mel_loss=0.04316, linear_loss=0.05317]
[2020-05-12 04:48:50.225]  Step 153075  [3.284 sec/step, loss=0.08893, avg_loss=0.08897, mel_loss=0.03880, linear_loss=0.05013]
[2020-05-12 04:48:54.027]  Step 153076  [3.316 sec/step, loss=0.09754, avg_loss=0.08931, mel_loss=0.04378, linear_loss=0.05376]
[2020-05-12 04:48:57.514]  Step 153077  [3.315 sec/step, loss=0.09247, avg_loss=0.08927, mel_loss=0.04110, linear_loss=0.05137]
[2020-05-12 04:49:01.217]  Step 153078  [3.328 sec/step, loss=0.09532, avg_loss=0.08931, mel_loss=0.04285, linear_loss=0.05247]
[2020-05-12 04:49:06.140]  Step 153079  [3.367 sec/step, loss=0.09639, avg_loss=0.08945, mel_loss=0.04350, linear_loss=0.05288]
[2020-05-12 04:49:07.808]  Step 153080  [3.374 sec/step, loss=0.08982, avg_loss=0.08951, mel_loss=0.03940, linear_loss=0.05041]
[2020-05-12 04:49:10.861]  Step 153081  [3.397 sec/step, loss=0.09492, avg_loss=0.08972, mel_loss=0.04229, linear_loss=0.05263]
[2020-05-12 04:49:11.689]  Step 153082  [3.371 sec/step, loss=0.07704, avg_loss=0.08956, mel_loss=0.03297, linear_loss=0.04407]
[2020-05-12 04:49:12.263]  Step 153083  [3.365 sec/step, loss=0.07124, avg_loss=0.08946, mel_loss=0.03081, linear_loss=0.04044]
[2020-05-12 04:49:14.526]  Step 153084  [3.380 sec/step, loss=0.09044, avg_loss=0.08962, mel_loss=0.03992, linear_loss=0.05052]
[2020-05-12 04:49:18.702]  Step 153085  [3.277 sec/step, loss=0.09447, avg_loss=0.08980, mel_loss=0.04253, linear_loss=0.05194]
[2020-05-12 04:49:20.406]  Step 153086  [3.242 sec/step, loss=0.08647, avg_loss=0.08970, mel_loss=0.03751, linear_loss=0.04895]
[2020-05-12 04:49:23.273]  Step 153087  [3.258 sec/step, loss=0.09240, avg_loss=0.08976, mel_loss=0.04102, linear_loss=0.05137]
[2020-05-12 04:49:25.731]  Step 153088  [3.241 sec/step, loss=0.09258, avg_loss=0.08972, mel_loss=0.04088, linear_loss=0.05170]
[2020-05-12 04:49:27.786]  Step 153089  [3.249 sec/step, loss=0.08990, avg_loss=0.08979, mel_loss=0.03949, linear_loss=0.05041]
[2020-05-12 04:49:35.358]  Step 153090  [3.296 sec/step, loss=0.09692, avg_loss=0.08984, mel_loss=0.04477, linear_loss=0.05214]
[2020-05-12 04:49:36.369]  Step 153091  [3.292 sec/step, loss=0.07914, avg_loss=0.08974, mel_loss=0.03389, linear_loss=0.04525]
[2020-05-12 04:49:39.776]  Step 153092  [3.305 sec/step, loss=0.09633, avg_loss=0.08979, mel_loss=0.04305, linear_loss=0.05328]
[2020-05-12 04:49:40.965]  Step 153093  [3.304 sec/step, loss=0.08327, avg_loss=0.08977, mel_loss=0.03586, linear_loss=0.04741]
[2020-05-12 04:49:42.009]  Step 153094  [3.293 sec/step, loss=0.07962, avg_loss=0.08968, mel_loss=0.03421, linear_loss=0.04541]
[2020-05-12 04:49:43.938]  Step 153095  [3.288 sec/step, loss=0.08789, avg_loss=0.08965, mel_loss=0.03806, linear_loss=0.04984]
[2020-05-12 04:49:50.077]  Step 153096  [3.333 sec/step, loss=0.09461, avg_loss=0.08972, mel_loss=0.04323, linear_loss=0.05138]
[2020-05-12 04:49:52.824]  Step 153097  [3.329 sec/step, loss=0.09172, avg_loss=0.08968, mel_loss=0.04042, linear_loss=0.05130]
[2020-05-12 04:49:54.045]  Step 153098  [3.304 sec/step, loss=0.08248, avg_loss=0.08954, mel_loss=0.03567, linear_loss=0.04681]
[2020-05-12 04:49:54.741]  Generated 32 batches of size 32 in 1.913 sec
[2020-05-12 04:49:54.997]  Step 153099  [3.304 sec/step, loss=0.07010, avg_loss=0.08941, mel_loss=0.02995, linear_loss=0.04016]
[2020-05-12 04:49:56.422]  Step 153100  [3.283 sec/step, loss=0.08528, avg_loss=0.08931, mel_loss=0.03723, linear_loss=0.04805]
[2020-05-12 04:49:56.422]  Writing summary at step: 153100
[2020-05-12 04:49:58.076]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153100
[2020-05-12 04:49:59.719]  Saving audio and alignment...
[2020-05-12 04:50:03.572]  Input: 세련된 요령 중에 하나라고 할 수 있습니다~
[2020-05-12 04:50:17.025]  Step 153101  [3.362 sec/step, loss=0.08184, avg_loss=0.08915, mel_loss=0.03863, linear_loss=0.04321]
[2020-05-12 04:50:22.553]  Step 153102  [3.372 sec/step, loss=0.09718, avg_loss=0.08915, mel_loss=0.04447, linear_loss=0.05271]
[2020-05-12 04:50:27.202]  Step 153103  [3.410 sec/step, loss=0.09634, avg_loss=0.08933, mel_loss=0.04364, linear_loss=0.05271]
[2020-05-12 04:50:35.923]  Step 153104  [3.478 sec/step, loss=0.09503, avg_loss=0.08942, mel_loss=0.04400, linear_loss=0.05103]
[2020-05-12 04:50:50.408]  Step 153105  [3.601 sec/step, loss=0.07639, avg_loss=0.08927, mel_loss=0.03599, linear_loss=0.04041]
[2020-05-12 04:50:51.321]  Step 153106  [3.542 sec/step, loss=0.07896, avg_loss=0.08910, mel_loss=0.03377, linear_loss=0.04519]
[2020-05-12 04:50:54.860]  Step 153107  [3.489 sec/step, loss=0.09574, avg_loss=0.08910, mel_loss=0.04290, linear_loss=0.05284]
[2020-05-12 04:50:58.587]  Step 153108  [3.491 sec/step, loss=0.09586, avg_loss=0.08914, mel_loss=0.04294, linear_loss=0.05292]
[2020-05-12 04:51:01.193]  Step 153109  [3.490 sec/step, loss=0.08944, avg_loss=0.08911, mel_loss=0.03944, linear_loss=0.05000]
[2020-05-12 04:51:02.012]  Step 153110  [3.489 sec/step, loss=0.07720, avg_loss=0.08910, mel_loss=0.03313, linear_loss=0.04408]
[2020-05-12 04:51:07.499]  Step 153111  [3.525 sec/step, loss=0.09562, avg_loss=0.08919, mel_loss=0.04338, linear_loss=0.05224]
[2020-05-12 04:51:13.289]  Step 153112  [3.509 sec/step, loss=0.09750, avg_loss=0.08918, mel_loss=0.04435, linear_loss=0.05315]
[2020-05-12 04:51:17.513]  Step 153113  [3.539 sec/step, loss=0.09547, avg_loss=0.08931, mel_loss=0.04288, linear_loss=0.05259]
[2020-05-12 04:51:18.910]  Step 153114  [3.518 sec/step, loss=0.08482, avg_loss=0.08922, mel_loss=0.03692, linear_loss=0.04790]
[2020-05-12 04:51:21.318]  Step 153115  [3.516 sec/step, loss=0.09127, avg_loss=0.08921, mel_loss=0.04033, linear_loss=0.05094]
[2020-05-12 04:51:23.401]  Step 153116  [3.483 sec/step, loss=0.08954, avg_loss=0.08913, mel_loss=0.03961, linear_loss=0.04992]
[2020-05-12 04:51:23.962]  Step 153117  [3.458 sec/step, loss=0.07106, avg_loss=0.08891, mel_loss=0.03189, linear_loss=0.03918]
[2020-05-12 04:51:25.363]  Step 153118  [3.464 sec/step, loss=0.08466, avg_loss=0.08900, mel_loss=0.03673, linear_loss=0.04793]
[2020-05-12 04:51:27.568]  Step 153119  [3.462 sec/step, loss=0.09132, avg_loss=0.08899, mel_loss=0.04051, linear_loss=0.05081]
[2020-05-12 04:51:30.796]  Step 153120  [3.474 sec/step, loss=0.09507, avg_loss=0.08903, mel_loss=0.04255, linear_loss=0.05252]
[2020-05-12 04:51:35.888]  Step 153121  [3.456 sec/step, loss=0.09739, avg_loss=0.08905, mel_loss=0.04394, linear_loss=0.05344]
[2020-05-12 04:51:37.174]  Step 153122  [3.454 sec/step, loss=0.08497, avg_loss=0.08905, mel_loss=0.03677, linear_loss=0.04821]
[2020-05-12 04:51:38.220]  Step 153123  [3.455 sec/step, loss=0.07979, avg_loss=0.08902, mel_loss=0.03461, linear_loss=0.04518]
[2020-05-12 04:51:44.549]  Step 153124  [3.510 sec/step, loss=0.09794, avg_loss=0.08921, mel_loss=0.04488, linear_loss=0.05306]
[2020-05-12 04:51:53.606]  Step 153125  [3.552 sec/step, loss=0.09666, avg_loss=0.08919, mel_loss=0.04482, linear_loss=0.05185]
[2020-05-12 04:51:54.725]  Step 153126  [3.492 sec/step, loss=0.08385, avg_loss=0.08904, mel_loss=0.03610, linear_loss=0.04775]
[2020-05-12 04:51:55.532]  Step 153127  [3.443 sec/step, loss=0.07368, avg_loss=0.08879, mel_loss=0.03209, linear_loss=0.04159]
[2020-05-12 04:51:57.210]  Step 153128  [3.415 sec/step, loss=0.08757, avg_loss=0.08871, mel_loss=0.03836, linear_loss=0.04921]
[2020-05-12 04:51:57.374]  Generated 32 batches of size 32 in 1.836 sec
[2020-05-12 04:51:59.175]  Step 153129  [3.406 sec/step, loss=0.09170, avg_loss=0.08870, mel_loss=0.04039, linear_loss=0.05131]
[2020-05-12 04:52:02.185]  Step 153130  [3.423 sec/step, loss=0.09587, avg_loss=0.08880, mel_loss=0.04258, linear_loss=0.05329]
[2020-05-12 04:52:04.144]  Step 153131  [3.426 sec/step, loss=0.08785, avg_loss=0.08882, mel_loss=0.03820, linear_loss=0.04965]
[2020-05-12 04:52:06.992]  Step 153132  [3.443 sec/step, loss=0.09068, avg_loss=0.08887, mel_loss=0.04026, linear_loss=0.05042]
[2020-05-12 04:52:14.386]  Step 153133  [3.499 sec/step, loss=0.09809, avg_loss=0.08896, mel_loss=0.04506, linear_loss=0.05304]
[2020-05-12 04:52:16.137]  Step 153134  [3.414 sec/step, loss=0.08727, avg_loss=0.08887, mel_loss=0.03835, linear_loss=0.04892]
[2020-05-12 04:52:20.559]  Step 153135  [3.401 sec/step, loss=0.09693, avg_loss=0.08888, mel_loss=0.04399, linear_loss=0.05293]
[2020-05-12 04:52:23.872]  Step 153136  [3.392 sec/step, loss=0.09494, avg_loss=0.08886, mel_loss=0.04243, linear_loss=0.05251]
[2020-05-12 04:52:25.217]  Step 153137  [3.256 sec/step, loss=0.08677, avg_loss=0.08899, mel_loss=0.03766, linear_loss=0.04911]
[2020-05-12 04:52:26.081]  Step 153138  [3.259 sec/step, loss=0.07379, avg_loss=0.08899, mel_loss=0.03194, linear_loss=0.04185]
[2020-05-12 04:52:26.907]  Step 153139  [3.247 sec/step, loss=0.07563, avg_loss=0.08886, mel_loss=0.03261, linear_loss=0.04301]
[2020-05-12 04:52:28.703]  Step 153140  [3.246 sec/step, loss=0.08882, avg_loss=0.08887, mel_loss=0.03889, linear_loss=0.04992]
[2020-05-12 04:52:30.269]  Step 153141  [3.224 sec/step, loss=0.08833, avg_loss=0.08880, mel_loss=0.03852, linear_loss=0.04981]
[2020-05-12 04:52:32.017]  Step 153142  [3.217 sec/step, loss=0.08913, avg_loss=0.08878, mel_loss=0.03899, linear_loss=0.05015]
[2020-05-12 04:52:36.593]  Step 153143  [3.217 sec/step, loss=0.09725, avg_loss=0.08878, mel_loss=0.04397, linear_loss=0.05328]
[2020-05-12 04:52:40.708]  Step 153144  [3.247 sec/step, loss=0.09444, avg_loss=0.08892, mel_loss=0.04236, linear_loss=0.05208]
[2020-05-12 04:52:43.232]  Step 153145  [3.182 sec/step, loss=0.09306, avg_loss=0.08887, mel_loss=0.04106, linear_loss=0.05200]
[2020-05-12 04:52:45.405]  Step 153146  [3.185 sec/step, loss=0.09106, avg_loss=0.08890, mel_loss=0.04012, linear_loss=0.05094]
[2020-05-12 04:52:59.785]  Step 153147  [3.317 sec/step, loss=0.07719, avg_loss=0.08883, mel_loss=0.03664, linear_loss=0.04055]
[2020-05-12 04:53:03.268]  Step 153148  [3.335 sec/step, loss=0.09619, avg_loss=0.08891, mel_loss=0.04310, linear_loss=0.05308]
[2020-05-12 04:53:06.482]  Step 153149  [3.351 sec/step, loss=0.09421, avg_loss=0.08899, mel_loss=0.04215, linear_loss=0.05206]
[2020-05-12 04:53:08.449]  Step 153150  [3.346 sec/step, loss=0.08931, avg_loss=0.08897, mel_loss=0.03901, linear_loss=0.05030]
[2020-05-12 04:53:08.449]  Writing summary at step: 153150
[2020-05-12 04:53:09.489]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153150
[2020-05-12 04:53:10.964]  Saving audio and alignment...
[2020-05-12 04:53:21.467]  Input: 어 저도 이제 온라인 강의 좀 들어보려고 하는데 저처럼 이렇게 제주도 같은 지역에서 지방에서도 많이 들으시나요~_________________________
[2020-05-12 04:53:27.177]  Step 153151  [3.384 sec/step, loss=0.09876, avg_loss=0.08908, mel_loss=0.04494, linear_loss=0.05382]
[2020-05-12 04:53:36.021]  Step 153152  [3.418 sec/step, loss=0.09643, avg_loss=0.08909, mel_loss=0.04487, linear_loss=0.05156]
[2020-05-12 04:53:37.187]  Step 153153  [3.297 sec/step, loss=0.08491, avg_loss=0.08910, mel_loss=0.03684, linear_loss=0.04806]
[2020-05-12 04:53:40.639]  Step 153154  [3.323 sec/step, loss=0.09459, avg_loss=0.08929, mel_loss=0.04237, linear_loss=0.05223]
[2020-05-12 04:53:42.709]  Step 153155  [3.324 sec/step, loss=0.08976, avg_loss=0.08928, mel_loss=0.03937, linear_loss=0.05038]
[2020-05-12 04:53:48.043]  Step 153156  [3.299 sec/step, loss=0.09615, avg_loss=0.08928, mel_loss=0.04378, linear_loss=0.05237]
[2020-05-12 04:53:51.757]  Step 153157  [3.326 sec/step, loss=0.09556, avg_loss=0.08940, mel_loss=0.04293, linear_loss=0.05263]
[2020-05-12 04:53:53.502]  Generated 32 batches of size 32 in 1.740 sec
[2020-05-12 04:53:58.248]  Step 153158  [3.377 sec/step, loss=0.09652, avg_loss=0.08949, mel_loss=0.04432, linear_loss=0.05220]
[2020-05-12 04:53:59.149]  Step 153159  [3.359 sec/step, loss=0.08084, avg_loss=0.08937, mel_loss=0.03473, linear_loss=0.04611]
[2020-05-12 04:54:02.078]  Step 153160  [3.374 sec/step, loss=0.09589, avg_loss=0.08946, mel_loss=0.04273, linear_loss=0.05316]
[2020-05-12 04:54:04.496]  Step 153161  [3.344 sec/step, loss=0.09267, avg_loss=0.08942, mel_loss=0.04090, linear_loss=0.05177]
[2020-05-12 04:54:05.876]  Step 153162  [3.352 sec/step, loss=0.08656, avg_loss=0.08959, mel_loss=0.03775, linear_loss=0.04882]
[2020-05-12 04:54:10.210]  Step 153163  [3.387 sec/step, loss=0.09704, avg_loss=0.08980, mel_loss=0.04384, linear_loss=0.05320]
[2020-05-12 04:54:10.768]  Step 153164  [3.383 sec/step, loss=0.06831, avg_loss=0.08970, mel_loss=0.03031, linear_loss=0.03800]
[2020-05-12 04:54:13.486]  Step 153165  [3.372 sec/step, loss=0.09416, avg_loss=0.08967, mel_loss=0.04187, linear_loss=0.05228]
[2020-05-12 04:54:14.540]  Step 153166  [3.371 sec/step, loss=0.08526, avg_loss=0.08969, mel_loss=0.03672, linear_loss=0.04854]
[2020-05-12 04:54:19.324]  Step 153167  [3.373 sec/step, loss=0.09646, avg_loss=0.08969, mel_loss=0.04352, linear_loss=0.05294]
[2020-05-12 04:54:21.817]  Step 153168  [3.356 sec/step, loss=0.08923, avg_loss=0.08962, mel_loss=0.03911, linear_loss=0.05012]
[2020-05-12 04:54:23.768]  Step 153169  [3.341 sec/step, loss=0.09010, avg_loss=0.08957, mel_loss=0.03964, linear_loss=0.05046]
[2020-05-12 04:54:26.639]  Step 153170  [3.306 sec/step, loss=0.09272, avg_loss=0.08952, mel_loss=0.04130, linear_loss=0.05143]
[2020-05-12 04:54:27.200]  Step 153171  [3.288 sec/step, loss=0.07216, avg_loss=0.08935, mel_loss=0.03137, linear_loss=0.04079]
[2020-05-12 04:54:30.534]  Step 153172  [3.286 sec/step, loss=0.09625, avg_loss=0.08937, mel_loss=0.04295, linear_loss=0.05330]
[2020-05-12 04:54:34.981]  Step 153173  [3.301 sec/step, loss=0.09627, avg_loss=0.08941, mel_loss=0.04345, linear_loss=0.05282]
[2020-05-12 04:54:35.953]  Step 153174  [3.273 sec/step, loss=0.08204, avg_loss=0.08927, mel_loss=0.03518, linear_loss=0.04686]
[2020-05-12 04:54:39.395]  Step 153175  [3.290 sec/step, loss=0.09435, avg_loss=0.08932, mel_loss=0.04217, linear_loss=0.05217]
[2020-05-12 04:54:40.709]  Step 153176  [3.265 sec/step, loss=0.08637, avg_loss=0.08921, mel_loss=0.03776, linear_loss=0.04861]
[2020-05-12 04:54:46.234]  Step 153177  [3.285 sec/step, loss=0.09591, avg_loss=0.08924, mel_loss=0.04387, linear_loss=0.05204]
[2020-05-12 04:54:47.817]  Step 153178  [3.264 sec/step, loss=0.08780, avg_loss=0.08917, mel_loss=0.03862, linear_loss=0.04919]
[2020-05-12 04:54:49.624]  Step 153179  [3.233 sec/step, loss=0.08871, avg_loss=0.08909, mel_loss=0.03883, linear_loss=0.04989]
[2020-05-12 04:54:51.861]  Step 153180  [3.239 sec/step, loss=0.09042, avg_loss=0.08910, mel_loss=0.03982, linear_loss=0.05059]
[2020-05-12 04:54:58.707]  Step 153181  [3.277 sec/step, loss=0.09837, avg_loss=0.08913, mel_loss=0.04515, linear_loss=0.05322]
[2020-05-12 04:54:59.500]  Step 153182  [3.276 sec/step, loss=0.07534, avg_loss=0.08911, mel_loss=0.03225, linear_loss=0.04309]
[2020-05-12 04:55:00.672]  Step 153183  [3.282 sec/step, loss=0.08395, avg_loss=0.08924, mel_loss=0.03633, linear_loss=0.04762]
[2020-05-12 04:55:01.732]  Step 153184  [3.270 sec/step, loss=0.08445, avg_loss=0.08918, mel_loss=0.03633, linear_loss=0.04812]
[2020-05-12 04:55:04.721]  Step 153185  [3.258 sec/step, loss=0.09660, avg_loss=0.08920, mel_loss=0.04326, linear_loss=0.05335]
[2020-05-12 04:55:08.486]  Step 153186  [3.279 sec/step, loss=0.09628, avg_loss=0.08930, mel_loss=0.04318, linear_loss=0.05310]
[2020-05-12 04:55:10.015]  Step 153187  [3.265 sec/step, loss=0.08822, avg_loss=0.08926, mel_loss=0.03832, linear_loss=0.04989]
[2020-05-12 04:55:10.769]  Step 153188  [3.248 sec/step, loss=0.08045, avg_loss=0.08914, mel_loss=0.03449, linear_loss=0.04596]
[2020-05-12 04:55:14.350]  Step 153189  [3.264 sec/step, loss=0.09786, avg_loss=0.08922, mel_loss=0.04392, linear_loss=0.05393]
[2020-05-12 04:55:16.014]  Generated 32 batches of size 32 in 1.658 sec
[2020-05-12 04:55:22.752]  Step 153190  [3.272 sec/step, loss=0.09375, avg_loss=0.08919, mel_loss=0.04324, linear_loss=0.05051]
[2020-05-12 04:55:34.981]  Step 153191  [3.384 sec/step, loss=0.08581, avg_loss=0.08925, mel_loss=0.04015, linear_loss=0.04565]
[2020-05-12 04:55:39.051]  Step 153192  [3.391 sec/step, loss=0.09659, avg_loss=0.08926, mel_loss=0.04347, linear_loss=0.05312]
[2020-05-12 04:55:41.693]  Step 153193  [3.405 sec/step, loss=0.09166, avg_loss=0.08934, mel_loss=0.04078, linear_loss=0.05087]
[2020-05-12 04:55:42.716]  Step 153194  [3.405 sec/step, loss=0.07714, avg_loss=0.08931, mel_loss=0.03333, linear_loss=0.04381]
[2020-05-12 04:55:44.414]  Step 153195  [3.403 sec/step, loss=0.08805, avg_loss=0.08932, mel_loss=0.03843, linear_loss=0.04962]
[2020-05-12 04:55:46.418]  Step 153196  [3.361 sec/step, loss=0.09045, avg_loss=0.08927, mel_loss=0.04018, linear_loss=0.05027]
[2020-05-12 04:55:52.991]  Step 153197  [3.400 sec/step, loss=0.09647, avg_loss=0.08932, mel_loss=0.04413, linear_loss=0.05234]
[2020-05-12 04:55:54.345]  Step 153198  [3.401 sec/step, loss=0.08854, avg_loss=0.08938, mel_loss=0.03843, linear_loss=0.05011]
[2020-05-12 04:55:58.929]  Step 153199  [3.437 sec/step, loss=0.09586, avg_loss=0.08964, mel_loss=0.04319, linear_loss=0.05267]
[2020-05-12 04:56:13.377]  Step 153200  [3.568 sec/step, loss=0.07457, avg_loss=0.08953, mel_loss=0.03522, linear_loss=0.03935]
[2020-05-12 04:56:13.377]  Writing summary at step: 153200
[2020-05-12 04:56:15.571]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153200
[2020-05-12 04:56:17.102]  Saving audio and alignment...
[2020-05-12 04:56:21.624]  Input: 사회 부탁을 받고 걱정 반 설렘반~__________________________
[2020-05-12 04:56:27.884]  Step 153201  [3.496 sec/step, loss=0.09712, avg_loss=0.08969, mel_loss=0.04443, linear_loss=0.05269]
[2020-05-12 04:56:30.860]  Step 153202  [3.470 sec/step, loss=0.09004, avg_loss=0.08961, mel_loss=0.03949, linear_loss=0.05054]
[2020-05-12 04:56:33.397]  Step 153203  [3.449 sec/step, loss=0.08751, avg_loss=0.08953, mel_loss=0.03837, linear_loss=0.04914]
[2020-05-12 04:56:38.442]  Step 153204  [3.412 sec/step, loss=0.09593, avg_loss=0.08954, mel_loss=0.04282, linear_loss=0.05311]
[2020-05-12 04:56:39.259]  Step 153205  [3.276 sec/step, loss=0.07000, avg_loss=0.08947, mel_loss=0.03098, linear_loss=0.03902]
[2020-05-12 04:56:40.628]  Step 153206  [3.280 sec/step, loss=0.08244, avg_loss=0.08951, mel_loss=0.03578, linear_loss=0.04667]
[2020-05-12 04:56:41.902]  Step 153207  [3.258 sec/step, loss=0.08365, avg_loss=0.08939, mel_loss=0.03578, linear_loss=0.04787]
[2020-05-12 04:56:43.242]  Step 153208  [3.234 sec/step, loss=0.08313, avg_loss=0.08926, mel_loss=0.03605, linear_loss=0.04709]
[2020-05-12 04:56:46.056]  Step 153209  [3.236 sec/step, loss=0.09077, avg_loss=0.08927, mel_loss=0.04008, linear_loss=0.05069]
[2020-05-12 04:56:51.469]  Step 153210  [3.282 sec/step, loss=0.09651, avg_loss=0.08946, mel_loss=0.04386, linear_loss=0.05264]
[2020-05-12 04:56:59.968]  Step 153211  [3.312 sec/step, loss=0.09438, avg_loss=0.08945, mel_loss=0.04375, linear_loss=0.05063]
[2020-05-12 04:57:03.370]  Step 153212  [3.288 sec/step, loss=0.09381, avg_loss=0.08941, mel_loss=0.04210, linear_loss=0.05172]
[2020-05-12 04:57:10.794]  Step 153213  [3.320 sec/step, loss=0.09857, avg_loss=0.08945, mel_loss=0.04533, linear_loss=0.05324]
[2020-05-12 04:57:13.882]  Step 153214  [3.337 sec/step, loss=0.09467, avg_loss=0.08954, mel_loss=0.04228, linear_loss=0.05240]
[2020-05-12 04:57:18.120]  Step 153215  [3.355 sec/step, loss=0.09711, avg_loss=0.08960, mel_loss=0.04344, linear_loss=0.05367]
[2020-05-12 04:57:19.811]  Step 153216  [3.351 sec/step, loss=0.08560, avg_loss=0.08956, mel_loss=0.03742, linear_loss=0.04818]
[2020-05-12 04:57:23.623]  Step 153217  [3.384 sec/step, loss=0.09572, avg_loss=0.08981, mel_loss=0.04296, linear_loss=0.05277]
[2020-05-12 04:57:25.374]  Step 153218  [3.387 sec/step, loss=0.09002, avg_loss=0.08986, mel_loss=0.03915, linear_loss=0.05088]
[2020-05-12 04:57:26.760]  Step 153219  [3.379 sec/step, loss=0.08372, avg_loss=0.08979, mel_loss=0.03654, linear_loss=0.04718]
[2020-05-12 04:57:27.554]  Step 153220  [3.355 sec/step, loss=0.07797, avg_loss=0.08962, mel_loss=0.03358, linear_loss=0.04439]
[2020-05-12 04:57:28.521]  Generated 32 batches of size 32 in 1.755 sec
[2020-05-12 04:57:29.662]  Step 153221  [3.325 sec/step, loss=0.08970, avg_loss=0.08954, mel_loss=0.03944, linear_loss=0.05026]
[2020-05-12 04:57:32.211]  Step 153222  [3.337 sec/step, loss=0.09189, avg_loss=0.08961, mel_loss=0.04063, linear_loss=0.05126]
[2020-05-12 04:57:36.565]  Step 153223  [3.371 sec/step, loss=0.09541, avg_loss=0.08977, mel_loss=0.04301, linear_loss=0.05240]
[2020-05-12 04:57:37.680]  Step 153224  [3.318 sec/step, loss=0.08481, avg_loss=0.08963, mel_loss=0.03656, linear_loss=0.04825]
[2020-05-12 04:57:40.021]  Step 153225  [3.251 sec/step, loss=0.09172, avg_loss=0.08958, mel_loss=0.04055, linear_loss=0.05116]
[2020-05-12 04:57:45.803]  Step 153226  [3.298 sec/step, loss=0.09775, avg_loss=0.08972, mel_loss=0.04460, linear_loss=0.05315]
[2020-05-12 04:57:46.650]  Step 153227  [3.298 sec/step, loss=0.07320, avg_loss=0.08972, mel_loss=0.03215, linear_loss=0.04105]
[2020-05-12 04:57:47.509]  Step 153228  [3.290 sec/step, loss=0.07910, avg_loss=0.08963, mel_loss=0.03361, linear_loss=0.04549]
[2020-05-12 04:57:54.145]  Step 153229  [3.337 sec/step, loss=0.09716, avg_loss=0.08969, mel_loss=0.04447, linear_loss=0.05269]
[2020-05-12 04:57:58.295]  Step 153230  [3.348 sec/step, loss=0.09694, avg_loss=0.08970, mel_loss=0.04412, linear_loss=0.05282]
[2020-05-12 04:58:12.771]  Step 153231  [3.473 sec/step, loss=0.07682, avg_loss=0.08959, mel_loss=0.03645, linear_loss=0.04036]
[2020-05-12 04:58:16.434]  Step 153232  [3.482 sec/step, loss=0.09627, avg_loss=0.08965, mel_loss=0.04330, linear_loss=0.05297]
[2020-05-12 04:58:19.369]  Step 153233  [3.437 sec/step, loss=0.09445, avg_loss=0.08961, mel_loss=0.04202, linear_loss=0.05243]
[2020-05-12 04:58:21.496]  Step 153234  [3.441 sec/step, loss=0.09291, avg_loss=0.08966, mel_loss=0.04110, linear_loss=0.05181]
[2020-05-12 04:58:27.050]  Step 153235  [3.452 sec/step, loss=0.09776, avg_loss=0.08967, mel_loss=0.04454, linear_loss=0.05323]
[2020-05-12 04:58:29.846]  Step 153236  [3.447 sec/step, loss=0.09273, avg_loss=0.08965, mel_loss=0.04137, linear_loss=0.05136]
[2020-05-12 04:58:30.946]  Step 153237  [3.444 sec/step, loss=0.08212, avg_loss=0.08960, mel_loss=0.03555, linear_loss=0.04656]
[2020-05-12 04:58:32.543]  Step 153238  [3.452 sec/step, loss=0.08690, avg_loss=0.08974, mel_loss=0.03808, linear_loss=0.04882]
[2020-05-12 04:58:34.332]  Step 153239  [3.461 sec/step, loss=0.08765, avg_loss=0.08986, mel_loss=0.03874, linear_loss=0.04891]
[2020-05-12 04:58:35.927]  Step 153240  [3.459 sec/step, loss=0.08913, avg_loss=0.08986, mel_loss=0.03905, linear_loss=0.05008]
[2020-05-12 04:58:38.151]  Step 153241  [3.466 sec/step, loss=0.09068, avg_loss=0.08988, mel_loss=0.04029, linear_loss=0.05040]
[2020-05-12 04:58:43.364]  Step 153242  [3.501 sec/step, loss=0.09743, avg_loss=0.08997, mel_loss=0.04436, linear_loss=0.05307]
[2020-05-12 04:58:46.891]  Step 153243  [3.490 sec/step, loss=0.09302, avg_loss=0.08992, mel_loss=0.04154, linear_loss=0.05148]
[2020-05-12 04:58:48.209]  Step 153244  [3.462 sec/step, loss=0.08544, avg_loss=0.08983, mel_loss=0.03691, linear_loss=0.04853]
[2020-05-12 04:58:49.014]  Step 153245  [3.445 sec/step, loss=0.07417, avg_loss=0.08964, mel_loss=0.03211, linear_loss=0.04206]
[2020-05-12 04:58:52.482]  Step 153246  [3.458 sec/step, loss=0.09435, avg_loss=0.08968, mel_loss=0.04220, linear_loss=0.05215]
[2020-05-12 04:58:55.081]  Step 153247  [3.340 sec/step, loss=0.09243, avg_loss=0.08983, mel_loss=0.04107, linear_loss=0.05136]
[2020-05-12 04:58:55.821]  Step 153248  [3.313 sec/step, loss=0.07029, avg_loss=0.08957, mel_loss=0.03122, linear_loss=0.03907]
[2020-05-12 04:59:04.437]  Step 153249  [3.367 sec/step, loss=0.09703, avg_loss=0.08960, mel_loss=0.04464, linear_loss=0.05239]
[2020-05-12 04:59:11.617]  Step 153250  [3.419 sec/step, loss=0.09710, avg_loss=0.08968, mel_loss=0.04462, linear_loss=0.05249]
[2020-05-12 04:59:11.617]  Writing summary at step: 153250
[2020-05-12 04:59:13.384]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153250
[2020-05-12 04:59:14.909]  Saving audio and alignment...
[2020-05-12 04:59:17.016]  Generated 32 batches of size 32 in 1.546 sec
[2020-05-12 04:59:18.745]  Input: 후원 침조 하는 이유가 뭘까요~_______________
[2020-05-12 04:59:20.107]  Step 153251  [3.375 sec/step, loss=0.08454, avg_loss=0.08953, mel_loss=0.03698, linear_loss=0.04755]
[2020-05-12 04:59:22.574]  Step 153252  [3.312 sec/step, loss=0.09285, avg_loss=0.08950, mel_loss=0.04120, linear_loss=0.05165]
[2020-05-12 04:59:26.543]  Step 153253  [3.340 sec/step, loss=0.09454, avg_loss=0.08960, mel_loss=0.04262, linear_loss=0.05192]
[2020-05-12 04:59:27.378]  Step 153254  [3.313 sec/step, loss=0.07617, avg_loss=0.08941, mel_loss=0.03265, linear_loss=0.04352]
[2020-05-12 04:59:28.440]  Step 153255  [3.303 sec/step, loss=0.08119, avg_loss=0.08933, mel_loss=0.03530, linear_loss=0.04588]
[2020-05-12 04:59:29.425]  Step 153256  [3.260 sec/step, loss=0.08333, avg_loss=0.08920, mel_loss=0.03580, linear_loss=0.04753]
[2020-05-12 04:59:34.185]  Step 153257  [3.270 sec/step, loss=0.09727, avg_loss=0.08921, mel_loss=0.04404, linear_loss=0.05323]
[2020-05-12 04:59:37.378]  Step 153258  [3.237 sec/step, loss=0.09535, avg_loss=0.08920, mel_loss=0.04231, linear_loss=0.05304]
[2020-05-12 04:59:37.944]  Step 153259  [3.234 sec/step, loss=0.07293, avg_loss=0.08912, mel_loss=0.03215, linear_loss=0.04078]
[2020-05-12 04:59:40.380]  Step 153260  [3.229 sec/step, loss=0.09069, avg_loss=0.08907, mel_loss=0.03980, linear_loss=0.05089]
[2020-05-12 04:59:42.593]  Step 153261  [3.227 sec/step, loss=0.09032, avg_loss=0.08905, mel_loss=0.03987, linear_loss=0.05046]
[2020-05-12 04:59:45.917]  Step 153262  [3.246 sec/step, loss=0.09517, avg_loss=0.08913, mel_loss=0.04276, linear_loss=0.05241]
[2020-05-12 04:59:47.232]  Step 153263  [3.216 sec/step, loss=0.08519, avg_loss=0.08902, mel_loss=0.03702, linear_loss=0.04817]
[2020-05-12 04:59:49.247]  Step 153264  [3.231 sec/step, loss=0.08942, avg_loss=0.08923, mel_loss=0.03945, linear_loss=0.04997]
[2020-05-12 04:59:51.767]  Step 153265  [3.229 sec/step, loss=0.09128, avg_loss=0.08920, mel_loss=0.04020, linear_loss=0.05107]
[2020-05-12 04:59:52.875]  Step 153266  [3.229 sec/step, loss=0.08274, avg_loss=0.08917, mel_loss=0.03551, linear_loss=0.04722]
[2020-05-12 04:59:54.087]  Step 153267  [3.194 sec/step, loss=0.08307, avg_loss=0.08904, mel_loss=0.03602, linear_loss=0.04705]
[2020-05-12 04:59:55.833]  Step 153268  [3.186 sec/step, loss=0.08821, avg_loss=0.08903, mel_loss=0.03826, linear_loss=0.04995]
[2020-05-12 04:59:59.226]  Step 153269  [3.201 sec/step, loss=0.09481, avg_loss=0.08908, mel_loss=0.04238, linear_loss=0.05244]
[2020-05-12 05:00:03.534]  Step 153270  [3.215 sec/step, loss=0.09742, avg_loss=0.08912, mel_loss=0.04390, linear_loss=0.05353]
[2020-05-12 05:00:12.445]  Step 153271  [3.298 sec/step, loss=0.09576, avg_loss=0.08936, mel_loss=0.04468, linear_loss=0.05107]
[2020-05-12 05:00:13.926]  Step 153272  [3.280 sec/step, loss=0.08700, avg_loss=0.08927, mel_loss=0.03786, linear_loss=0.04915]
[2020-05-12 05:00:25.888]  Step 153273  [3.355 sec/step, loss=0.08827, avg_loss=0.08919, mel_loss=0.04174, linear_loss=0.04653]
[2020-05-12 05:00:27.505]  Step 153274  [3.362 sec/step, loss=0.08752, avg_loss=0.08924, mel_loss=0.03848, linear_loss=0.04904]
[2020-05-12 05:00:28.523]  Step 153275  [3.337 sec/step, loss=0.07978, avg_loss=0.08910, mel_loss=0.03459, linear_loss=0.04519]
[2020-05-12 05:00:33.899]  Step 153276  [3.378 sec/step, loss=0.09541, avg_loss=0.08919, mel_loss=0.04342, linear_loss=0.05200]
[2020-05-12 05:00:38.495]  Step 153277  [3.369 sec/step, loss=0.09702, avg_loss=0.08920, mel_loss=0.04381, linear_loss=0.05321]
[2020-05-12 05:00:42.165]  Step 153278  [3.389 sec/step, loss=0.09596, avg_loss=0.08928, mel_loss=0.04301, linear_loss=0.05295]
[2020-05-12 05:00:42.969]  Step 153279  [3.379 sec/step, loss=0.07571, avg_loss=0.08915, mel_loss=0.03253, linear_loss=0.04318]
[2020-05-12 05:00:44.819]  Step 153280  [3.376 sec/step, loss=0.08962, avg_loss=0.08914, mel_loss=0.03898, linear_loss=0.05065]
[2020-05-12 05:00:46.877]  Step 153281  [3.328 sec/step, loss=0.08956, avg_loss=0.08905, mel_loss=0.03939, linear_loss=0.05017]
[2020-05-12 05:00:48.587]  Generated 32 batches of size 32 in 1.705 sec
[2020-05-12 05:00:50.058]  Step 153282  [3.352 sec/step, loss=0.09707, avg_loss=0.08927, mel_loss=0.04346, linear_loss=0.05361]
[2020-05-12 05:00:50.929]  Step 153283  [3.349 sec/step, loss=0.07742, avg_loss=0.08920, mel_loss=0.03318, linear_loss=0.04424]
[2020-05-12 05:00:52.276]  Step 153284  [3.351 sec/step, loss=0.08671, avg_loss=0.08923, mel_loss=0.03780, linear_loss=0.04890]
[2020-05-12 05:00:58.599]  Step 153285  [3.385 sec/step, loss=0.09680, avg_loss=0.08923, mel_loss=0.04432, linear_loss=0.05248]
[2020-05-12 05:01:02.726]  Step 153286  [3.388 sec/step, loss=0.09556, avg_loss=0.08922, mel_loss=0.04279, linear_loss=0.05277]
[2020-05-12 05:01:08.382]  Step 153287  [3.430 sec/step, loss=0.09852, avg_loss=0.08932, mel_loss=0.04521, linear_loss=0.05330]
[2020-05-12 05:01:09.033]  Step 153288  [3.429 sec/step, loss=0.07649, avg_loss=0.08928, mel_loss=0.03304, linear_loss=0.04346]
[2020-05-12 05:01:11.925]  Step 153289  [3.422 sec/step, loss=0.09239, avg_loss=0.08923, mel_loss=0.04118, linear_loss=0.05121]
[2020-05-12 05:01:19.601]  Step 153290  [3.414 sec/step, loss=0.09777, avg_loss=0.08927, mel_loss=0.04490, linear_loss=0.05287]
[2020-05-12 05:01:20.774]  Step 153291  [3.304 sec/step, loss=0.08148, avg_loss=0.08923, mel_loss=0.03522, linear_loss=0.04626]
[2020-05-12 05:01:22.382]  Step 153292  [3.279 sec/step, loss=0.08915, avg_loss=0.08915, mel_loss=0.03909, linear_loss=0.05006]
[2020-05-12 05:01:25.394]  Step 153293  [3.283 sec/step, loss=0.09390, avg_loss=0.08918, mel_loss=0.04184, linear_loss=0.05207]
[2020-05-12 05:01:27.163]  Step 153294  [3.290 sec/step, loss=0.08715, avg_loss=0.08928, mel_loss=0.03779, linear_loss=0.04935]
[2020-05-12 05:01:32.608]  Step 153295  [3.328 sec/step, loss=0.09772, avg_loss=0.08937, mel_loss=0.04473, linear_loss=0.05299]
[2020-05-12 05:01:34.111]  Step 153296  [3.323 sec/step, loss=0.08687, avg_loss=0.08934, mel_loss=0.03769, linear_loss=0.04918]
[2020-05-12 05:01:38.574]  Step 153297  [3.302 sec/step, loss=0.09650, avg_loss=0.08934, mel_loss=0.04357, linear_loss=0.05293]
[2020-05-12 05:01:40.782]  Step 153298  [3.310 sec/step, loss=0.09051, avg_loss=0.08936, mel_loss=0.03997, linear_loss=0.05054]
[2020-05-12 05:01:41.535]  Step 153299  [3.272 sec/step, loss=0.07619, avg_loss=0.08916, mel_loss=0.03264, linear_loss=0.04355]
[2020-05-12 05:01:42.979]  Step 153300  [3.142 sec/step, loss=0.08527, avg_loss=0.08927, mel_loss=0.03736, linear_loss=0.04791]
[2020-05-12 05:01:42.979]  Writing summary at step: 153300
[2020-05-12 05:01:44.309]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153300
[2020-05-12 05:01:45.878]  Saving audio and alignment...
[2020-05-12 05:01:55.767]  Input: 이런 데서 방송 경력이 있는 사람들과 그렇지 않은 초보 준비생들에 차이가 드러나게 되니까요~___________________________________________
[2020-05-12 05:01:59.942]  Step 153301  [3.121 sec/step, loss=0.09566, avg_loss=0.08925, mel_loss=0.04291, linear_loss=0.05275]
[2020-05-12 05:02:02.767]  Step 153302  [3.120 sec/step, loss=0.09331, avg_loss=0.08928, mel_loss=0.04143, linear_loss=0.05188]
[2020-05-12 05:02:06.504]  Step 153303  [3.132 sec/step, loss=0.09628, avg_loss=0.08937, mel_loss=0.04322, linear_loss=0.05307]
[2020-05-12 05:02:14.698]  Step 153304  [3.163 sec/step, loss=0.09499, avg_loss=0.08936, mel_loss=0.04377, linear_loss=0.05123]
[2020-05-12 05:02:15.454]  Step 153305  [3.163 sec/step, loss=0.07018, avg_loss=0.08936, mel_loss=0.03116, linear_loss=0.03902]
[2020-05-12 05:02:16.471]  Step 153306  [3.159 sec/step, loss=0.08098, avg_loss=0.08935, mel_loss=0.03477, linear_loss=0.04621]
[2020-05-12 05:02:17.275]  Step 153307  [3.154 sec/step, loss=0.07592, avg_loss=0.08927, mel_loss=0.03232, linear_loss=0.04360]
[2020-05-12 05:02:18.157]  Step 153308  [3.150 sec/step, loss=0.07878, avg_loss=0.08923, mel_loss=0.03379, linear_loss=0.04499]
[2020-05-12 05:02:32.429]  Step 153309  [3.264 sec/step, loss=0.07264, avg_loss=0.08905, mel_loss=0.03448, linear_loss=0.03817]
[2020-05-12 05:02:35.274]  Step 153310  [3.239 sec/step, loss=0.09174, avg_loss=0.08900, mel_loss=0.04069, linear_loss=0.05105]
[2020-05-12 05:02:37.132]  Step 153311  [3.172 sec/step, loss=0.08938, avg_loss=0.08895, mel_loss=0.03911, linear_loss=0.05027]
[2020-05-12 05:02:38.894]  Generated 32 batches of size 32 in 1.756 sec
[2020-05-12 05:02:40.843]  Step 153312  [3.175 sec/step, loss=0.09582, avg_loss=0.08897, mel_loss=0.04290, linear_loss=0.05292]
[2020-05-12 05:02:43.972]  Step 153313  [3.132 sec/step, loss=0.09667, avg_loss=0.08895, mel_loss=0.04297, linear_loss=0.05370]
[2020-05-12 05:02:45.335]  Step 153314  [3.115 sec/step, loss=0.08435, avg_loss=0.08885, mel_loss=0.03662, linear_loss=0.04774]
[2020-05-12 05:02:50.272]  Step 153315  [3.122 sec/step, loss=0.09480, avg_loss=0.08883, mel_loss=0.04294, linear_loss=0.05186]
[2020-05-12 05:02:52.319]  Step 153316  [3.126 sec/step, loss=0.08772, avg_loss=0.08885, mel_loss=0.03852, linear_loss=0.04920]
[2020-05-12 05:02:55.783]  Step 153317  [3.122 sec/step, loss=0.09290, avg_loss=0.08882, mel_loss=0.04155, linear_loss=0.05135]
[2020-05-12 05:03:01.761]  Step 153318  [3.164 sec/step, loss=0.09416, avg_loss=0.08886, mel_loss=0.04290, linear_loss=0.05126]
[2020-05-12 05:03:03.920]  Step 153319  [3.172 sec/step, loss=0.09329, avg_loss=0.08896, mel_loss=0.04142, linear_loss=0.05188]
[2020-05-12 05:03:06.386]  Step 153320  [3.189 sec/step, loss=0.09093, avg_loss=0.08908, mel_loss=0.04001, linear_loss=0.05091]
[2020-05-12 05:03:09.809]  Step 153321  [3.202 sec/step, loss=0.09514, avg_loss=0.08914, mel_loss=0.04259, linear_loss=0.05255]
[2020-05-12 05:03:10.893]  Step 153322  [3.187 sec/step, loss=0.08114, avg_loss=0.08903, mel_loss=0.03510, linear_loss=0.04604]
[2020-05-12 05:03:11.629]  Step 153323  [3.151 sec/step, loss=0.07537, avg_loss=0.08883, mel_loss=0.03257, linear_loss=0.04280]
[2020-05-12 05:03:16.125]  Step 153324  [3.185 sec/step, loss=0.09825, avg_loss=0.08897, mel_loss=0.04445, linear_loss=0.05380]
[2020-05-12 05:03:22.105]  Step 153325  [3.221 sec/step, loss=0.09779, avg_loss=0.08903, mel_loss=0.04470, linear_loss=0.05310]
[2020-05-12 05:03:24.074]  Step 153326  [3.183 sec/step, loss=0.09031, avg_loss=0.08895, mel_loss=0.03957, linear_loss=0.05074]
[2020-05-12 05:03:28.996]  Step 153327  [3.224 sec/step, loss=0.09434, avg_loss=0.08916, mel_loss=0.04259, linear_loss=0.05174]
[2020-05-12 05:03:29.819]  Step 153328  [3.224 sec/step, loss=0.07601, avg_loss=0.08913, mel_loss=0.03274, linear_loss=0.04327]
[2020-05-12 05:03:30.386]  Step 153329  [3.163 sec/step, loss=0.06955, avg_loss=0.08886, mel_loss=0.03040, linear_loss=0.03915]
[2020-05-12 05:03:31.397]  Step 153330  [3.132 sec/step, loss=0.07901, avg_loss=0.08868, mel_loss=0.03376, linear_loss=0.04525]
[2020-05-12 05:03:33.502]  Step 153331  [3.008 sec/step, loss=0.09180, avg_loss=0.08883, mel_loss=0.04040, linear_loss=0.05140]
[2020-05-12 05:03:42.725]  Step 153332  [3.064 sec/step, loss=0.09740, avg_loss=0.08884, mel_loss=0.04515, linear_loss=0.05225]
[2020-05-12 05:03:50.460]  Step 153333  [3.112 sec/step, loss=0.09881, avg_loss=0.08888, mel_loss=0.04533, linear_loss=0.05348]
[2020-05-12 05:03:54.230]  Step 153334  [3.128 sec/step, loss=0.09730, avg_loss=0.08893, mel_loss=0.04352, linear_loss=0.05378]
[2020-05-12 05:03:55.857]  Step 153335  [3.089 sec/step, loss=0.08758, avg_loss=0.08882, mel_loss=0.03844, linear_loss=0.04914]
[2020-05-12 05:03:59.230]  Step 153336  [3.094 sec/step, loss=0.09545, avg_loss=0.08885, mel_loss=0.04283, linear_loss=0.05262]
[2020-05-12 05:04:01.998]  Step 153337  [3.111 sec/step, loss=0.09361, avg_loss=0.08897, mel_loss=0.04180, linear_loss=0.05181]
[2020-05-12 05:04:03.318]  Step 153338  [3.108 sec/step, loss=0.08707, avg_loss=0.08897, mel_loss=0.03769, linear_loss=0.04938]
[2020-05-12 05:04:05.128]  Step 153339  [3.109 sec/step, loss=0.08906, avg_loss=0.08898, mel_loss=0.03884, linear_loss=0.05022]
[2020-05-12 05:04:07.199]  Step 153340  [3.113 sec/step, loss=0.08955, avg_loss=0.08899, mel_loss=0.03931, linear_loss=0.05024]
[2020-05-12 05:04:08.679]  Step 153341  [3.106 sec/step, loss=0.08465, avg_loss=0.08893, mel_loss=0.03725, linear_loss=0.04741]
[2020-05-12 05:04:09.691]  Step 153342  [3.064 sec/step, loss=0.08186, avg_loss=0.08877, mel_loss=0.03540, linear_loss=0.04646]
[2020-05-12 05:04:11.365]  Step 153343  [3.045 sec/step, loss=0.08899, avg_loss=0.08873, mel_loss=0.03903, linear_loss=0.04996]
[2020-05-12 05:04:13.089]  Generated 32 batches of size 32 in 1.718 sec
[2020-05-12 05:04:14.426]  Step 153344  [3.063 sec/step, loss=0.09535, avg_loss=0.08883, mel_loss=0.04247, linear_loss=0.05288]
[2020-05-12 05:04:18.510]  Step 153345  [3.096 sec/step, loss=0.09637, avg_loss=0.08905, mel_loss=0.04329, linear_loss=0.05308]
[2020-05-12 05:04:20.982]  Step 153346  [3.086 sec/step, loss=0.09184, avg_loss=0.08903, mel_loss=0.04066, linear_loss=0.05119]
[2020-05-12 05:04:34.038]  Step 153347  [3.190 sec/step, loss=0.08477, avg_loss=0.08895, mel_loss=0.04003, linear_loss=0.04474]
[2020-05-12 05:04:37.709]  Step 153348  [3.219 sec/step, loss=0.09573, avg_loss=0.08920, mel_loss=0.04307, linear_loss=0.05266]
[2020-05-12 05:04:44.616]  Step 153349  [3.202 sec/step, loss=0.10084, avg_loss=0.08924, mel_loss=0.04627, linear_loss=0.05457]
[2020-05-12 05:04:49.978]  Step 153350  [3.184 sec/step, loss=0.09752, avg_loss=0.08925, mel_loss=0.04431, linear_loss=0.05321]
[2020-05-12 05:04:49.978]  Writing summary at step: 153350
[2020-05-12 05:04:51.183]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153350
[2020-05-12 05:04:52.721]  Saving audio and alignment...
[2020-05-12 05:04:56.732]  Input: 어제 거래된 두바이유 현물가격이~______________________
[2020-05-12 05:04:58.198]  Step 153351  [3.185 sec/step, loss=0.08666, avg_loss=0.08927, mel_loss=0.03791, linear_loss=0.04875]
[2020-05-12 05:05:01.690]  Step 153352  [3.195 sec/step, loss=0.09408, avg_loss=0.08928, mel_loss=0.04212, linear_loss=0.05197]
[2020-05-12 05:05:09.413]  Step 153353  [3.233 sec/step, loss=0.09681, avg_loss=0.08930, mel_loss=0.04459, linear_loss=0.05222]
[2020-05-12 05:05:11.664]  Step 153354  [3.247 sec/step, loss=0.08962, avg_loss=0.08944, mel_loss=0.03953, linear_loss=0.05009]
[2020-05-12 05:05:13.321]  Step 153355  [3.253 sec/step, loss=0.08612, avg_loss=0.08949, mel_loss=0.03748, linear_loss=0.04864]
[2020-05-12 05:05:20.183]  Step 153356  [3.312 sec/step, loss=0.09682, avg_loss=0.08962, mel_loss=0.04441, linear_loss=0.05241]
[2020-05-12 05:05:22.439]  Step 153357  [3.287 sec/step, loss=0.08880, avg_loss=0.08954, mel_loss=0.03884, linear_loss=0.04996]
[2020-05-12 05:05:27.872]  Step 153358  [3.309 sec/step, loss=0.09808, avg_loss=0.08956, mel_loss=0.04465, linear_loss=0.05343]
[2020-05-12 05:05:28.453]  Step 153359  [3.309 sec/step, loss=0.06975, avg_loss=0.08953, mel_loss=0.03106, linear_loss=0.03869]
[2020-05-12 05:05:32.909]  Step 153360  [3.330 sec/step, loss=0.09772, avg_loss=0.08960, mel_loss=0.04440, linear_loss=0.05332]
[2020-05-12 05:05:37.103]  Step 153361  [3.349 sec/step, loss=0.09625, avg_loss=0.08966, mel_loss=0.04330, linear_loss=0.05295]
[2020-05-12 05:05:40.662]  Step 153362  [3.352 sec/step, loss=0.09531, avg_loss=0.08966, mel_loss=0.04286, linear_loss=0.05245]
[2020-05-12 05:05:41.547]  Step 153363  [3.347 sec/step, loss=0.07159, avg_loss=0.08953, mel_loss=0.03081, linear_loss=0.04078]
[2020-05-12 05:05:46.352]  Step 153364  [3.375 sec/step, loss=0.09597, avg_loss=0.08959, mel_loss=0.04329, linear_loss=0.05267]
[2020-05-12 05:05:48.133]  Step 153365  [3.368 sec/step, loss=0.08862, avg_loss=0.08957, mel_loss=0.03878, linear_loss=0.04984]
[2020-05-12 05:05:49.097]  Step 153366  [3.367 sec/step, loss=0.08120, avg_loss=0.08955, mel_loss=0.03432, linear_loss=0.04688]
[2020-05-12 05:05:51.653]  Step 153367  [3.380 sec/step, loss=0.09110, avg_loss=0.08963, mel_loss=0.04034, linear_loss=0.05076]
[2020-05-12 05:06:00.461]  Step 153368  [3.451 sec/step, loss=0.09661, avg_loss=0.08971, mel_loss=0.04453, linear_loss=0.05208]
[2020-05-12 05:06:03.716]  Step 153369  [3.449 sec/step, loss=0.09565, avg_loss=0.08972, mel_loss=0.04258, linear_loss=0.05307]
[2020-05-12 05:06:05.667]  Step 153370  [3.426 sec/step, loss=0.08929, avg_loss=0.08964, mel_loss=0.03951, linear_loss=0.04978]
[2020-05-12 05:06:08.508]  Step 153371  [3.365 sec/step, loss=0.09130, avg_loss=0.08960, mel_loss=0.04068, linear_loss=0.05062]
[2020-05-12 05:06:22.764]  Step 153372  [3.493 sec/step, loss=0.07678, avg_loss=0.08949, mel_loss=0.03634, linear_loss=0.04044]
[2020-05-12 05:06:23.534]  Step 153373  [3.381 sec/step, loss=0.08113, avg_loss=0.08942, mel_loss=0.03462, linear_loss=0.04650]
[2020-05-12 05:06:24.563]  Step 153374  [3.375 sec/step, loss=0.08114, avg_loss=0.08936, mel_loss=0.03492, linear_loss=0.04623]
[2020-05-12 05:06:25.452]  Generated 32 batches of size 32 in 1.911 sec
[2020-05-12 05:06:30.286]  Step 153375  [3.422 sec/step, loss=0.09866, avg_loss=0.08955, mel_loss=0.04523, linear_loss=0.05342]
[2020-05-12 05:06:31.639]  Step 153376  [3.382 sec/step, loss=0.08354, avg_loss=0.08943, mel_loss=0.03648, linear_loss=0.04706]
[2020-05-12 05:06:35.338]  Step 153377  [3.373 sec/step, loss=0.09600, avg_loss=0.08942, mel_loss=0.04321, linear_loss=0.05280]
[2020-05-12 05:06:37.382]  Step 153378  [3.357 sec/step, loss=0.09272, avg_loss=0.08939, mel_loss=0.04092, linear_loss=0.05180]
[2020-05-12 05:06:38.478]  Step 153379  [3.359 sec/step, loss=0.08212, avg_loss=0.08945, mel_loss=0.03525, linear_loss=0.04687]
[2020-05-12 05:06:42.086]  Step 153380  [3.377 sec/step, loss=0.09369, avg_loss=0.08949, mel_loss=0.04163, linear_loss=0.05206]
[2020-05-12 05:06:45.846]  Step 153381  [3.394 sec/step, loss=0.09009, avg_loss=0.08950, mel_loss=0.03971, linear_loss=0.05038]
[2020-05-12 05:06:47.751]  Step 153382  [3.381 sec/step, loss=0.08218, avg_loss=0.08935, mel_loss=0.03554, linear_loss=0.04664]
[2020-05-12 05:06:50.294]  Step 153383  [3.398 sec/step, loss=0.08574, avg_loss=0.08943, mel_loss=0.03757, linear_loss=0.04817]
[2020-05-12 05:06:52.230]  Step 153384  [3.404 sec/step, loss=0.08130, avg_loss=0.08938, mel_loss=0.03525, linear_loss=0.04605]
[2020-05-12 05:06:53.980]  Step 153385  [3.358 sec/step, loss=0.08258, avg_loss=0.08923, mel_loss=0.03579, linear_loss=0.04679]
[2020-05-12 05:06:54.746]  Step 153386  [3.325 sec/step, loss=0.07760, avg_loss=0.08906, mel_loss=0.03398, linear_loss=0.04363]
[2020-05-12 05:06:59.515]  Step 153387  [3.316 sec/step, loss=0.09667, avg_loss=0.08904, mel_loss=0.04379, linear_loss=0.05289]
[2020-05-12 05:07:03.787]  Step 153388  [3.352 sec/step, loss=0.09486, avg_loss=0.08922, mel_loss=0.04264, linear_loss=0.05222]
[2020-05-12 05:07:05.498]  Step 153389  [3.340 sec/step, loss=0.09001, avg_loss=0.08920, mel_loss=0.03910, linear_loss=0.05092]
[2020-05-12 05:07:07.827]  Step 153390  [3.287 sec/step, loss=0.09405, avg_loss=0.08916, mel_loss=0.04184, linear_loss=0.05221]
[2020-05-12 05:07:08.696]  Step 153391  [3.284 sec/step, loss=0.08320, avg_loss=0.08918, mel_loss=0.03551, linear_loss=0.04769]
[2020-05-12 05:07:12.199]  Step 153392  [3.302 sec/step, loss=0.09422, avg_loss=0.08923, mel_loss=0.04204, linear_loss=0.05218]
[2020-05-12 05:07:15.197]  Step 153393  [3.302 sec/step, loss=0.09513, avg_loss=0.08924, mel_loss=0.04245, linear_loss=0.05268]
[2020-05-12 05:07:17.626]  Step 153394  [3.309 sec/step, loss=0.08999, avg_loss=0.08927, mel_loss=0.03931, linear_loss=0.05068]
[2020-05-12 05:07:21.055]  Step 153395  [3.289 sec/step, loss=0.09385, avg_loss=0.08923, mel_loss=0.04200, linear_loss=0.05185]
[2020-05-12 05:07:24.840]  Step 153396  [3.312 sec/step, loss=0.09727, avg_loss=0.08933, mel_loss=0.04366, linear_loss=0.05361]
[2020-05-12 05:07:39.346]  Step 153397  [3.412 sec/step, loss=0.07765, avg_loss=0.08914, mel_loss=0.03699, linear_loss=0.04066]
[2020-05-12 05:07:42.405]  Step 153398  [3.421 sec/step, loss=0.09174, avg_loss=0.08916, mel_loss=0.04073, linear_loss=0.05101]
[2020-05-12 05:07:43.288]  Step 153399  [3.422 sec/step, loss=0.07656, avg_loss=0.08916, mel_loss=0.03294, linear_loss=0.04362]
[2020-05-12 05:07:51.779]  Step 153400  [3.492 sec/step, loss=0.09230, avg_loss=0.08923, mel_loss=0.04252, linear_loss=0.04977]
[2020-05-12 05:07:51.779]  Writing summary at step: 153400
[2020-05-12 05:07:53.652]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153400
[2020-05-12 05:07:55.205]  Saving audio and alignment...
[2020-05-12 05:07:56.644]  Input: 그러나~_______
[2020-05-12 05:07:58.004]  Step 153401  [3.464 sec/step, loss=0.08799, avg_loss=0.08915, mel_loss=0.03788, linear_loss=0.05011]
[2020-05-12 05:08:00.191]  Step 153402  [3.458 sec/step, loss=0.09257, avg_loss=0.08915, mel_loss=0.04083, linear_loss=0.05174]
[2020-05-12 05:08:01.953]  Step 153403  [3.438 sec/step, loss=0.08694, avg_loss=0.08905, mel_loss=0.03820, linear_loss=0.04874]
[2020-05-12 05:08:03.769]  Generated 32 batches of size 32 in 1.810 sec
[2020-05-12 05:08:06.907]  Step 153404  [3.406 sec/step, loss=0.09485, avg_loss=0.08905, mel_loss=0.04281, linear_loss=0.05204]
[2020-05-12 05:08:13.245]  Step 153405  [3.461 sec/step, loss=0.09587, avg_loss=0.08931, mel_loss=0.04370, linear_loss=0.05217]
[2020-05-12 05:08:16.264]  Step 153406  [3.481 sec/step, loss=0.09379, avg_loss=0.08944, mel_loss=0.04158, linear_loss=0.05221]
[2020-05-12 05:08:18.316]  Step 153407  [3.494 sec/step, loss=0.09027, avg_loss=0.08958, mel_loss=0.03941, linear_loss=0.05087]
[2020-05-12 05:08:19.344]  Step 153408  [3.495 sec/step, loss=0.08145, avg_loss=0.08961, mel_loss=0.03526, linear_loss=0.04619]
[2020-05-12 05:08:26.408]  Step 153409  [3.423 sec/step, loss=0.09857, avg_loss=0.08987, mel_loss=0.04533, linear_loss=0.05325]
[2020-05-12 05:08:27.816]  Step 153410  [3.409 sec/step, loss=0.08617, avg_loss=0.08981, mel_loss=0.03738, linear_loss=0.04879]
[2020-05-12 05:08:30.609]  Step 153411  [3.418 sec/step, loss=0.09002, avg_loss=0.08982, mel_loss=0.03990, linear_loss=0.05013]
[2020-05-12 05:08:36.230]  Step 153412  [3.437 sec/step, loss=0.09581, avg_loss=0.08982, mel_loss=0.04348, linear_loss=0.05233]
[2020-05-12 05:08:38.416]  Step 153413  [3.428 sec/step, loss=0.08984, avg_loss=0.08975, mel_loss=0.03971, linear_loss=0.05014]
[2020-05-12 05:08:41.295]  Step 153414  [3.443 sec/step, loss=0.09291, avg_loss=0.08983, mel_loss=0.04153, linear_loss=0.05138]
[2020-05-12 05:08:42.205]  Step 153415  [3.403 sec/step, loss=0.07964, avg_loss=0.08968, mel_loss=0.03428, linear_loss=0.04537]
[2020-05-12 05:08:44.148]  Step 153416  [3.402 sec/step, loss=0.08922, avg_loss=0.08970, mel_loss=0.03894, linear_loss=0.05029]
[2020-05-12 05:08:49.530]  Step 153417  [3.421 sec/step, loss=0.09545, avg_loss=0.08972, mel_loss=0.04334, linear_loss=0.05211]
[2020-05-12 05:08:58.362]  Step 153418  [3.450 sec/step, loss=0.09629, avg_loss=0.08974, mel_loss=0.04441, linear_loss=0.05188]
[2020-05-12 05:09:01.898]  Step 153419  [3.463 sec/step, loss=0.09320, avg_loss=0.08974, mel_loss=0.04176, linear_loss=0.05145]
[2020-05-12 05:09:03.216]  Step 153420  [3.452 sec/step, loss=0.08516, avg_loss=0.08969, mel_loss=0.03699, linear_loss=0.04817]
[2020-05-12 05:09:07.956]  Step 153421  [3.465 sec/step, loss=0.09682, avg_loss=0.08970, mel_loss=0.04374, linear_loss=0.05308]
[2020-05-12 05:09:08.780]  Step 153422  [3.462 sec/step, loss=0.07676, avg_loss=0.08966, mel_loss=0.03312, linear_loss=0.04364]
[2020-05-12 05:09:15.668]  Step 153423  [3.524 sec/step, loss=0.09746, avg_loss=0.08988, mel_loss=0.04468, linear_loss=0.05278]
[2020-05-12 05:09:18.859]  Step 153424  [3.511 sec/step, loss=0.09608, avg_loss=0.08986, mel_loss=0.04292, linear_loss=0.05316]
[2020-05-12 05:09:19.935]  Step 153425  [3.462 sec/step, loss=0.07896, avg_loss=0.08967, mel_loss=0.03430, linear_loss=0.04467]
[2020-05-12 05:09:23.915]  Step 153426  [3.482 sec/step, loss=0.09617, avg_loss=0.08973, mel_loss=0.04332, linear_loss=0.05286]
[2020-05-12 05:09:37.206]  Step 153427  [3.566 sec/step, loss=0.07989, avg_loss=0.08958, mel_loss=0.03746, linear_loss=0.04243]
[2020-05-12 05:09:39.310]  Step 153428  [3.578 sec/step, loss=0.09015, avg_loss=0.08973, mel_loss=0.03949, linear_loss=0.05066]
[2020-05-12 05:09:41.142]  Step 153429  [3.591 sec/step, loss=0.08630, avg_loss=0.08989, mel_loss=0.03763, linear_loss=0.04867]
[2020-05-12 05:09:43.832]  Step 153430  [3.608 sec/step, loss=0.09393, avg_loss=0.09004, mel_loss=0.04188, linear_loss=0.05205]
[2020-05-12 05:09:46.331]  Step 153431  [3.612 sec/step, loss=0.08955, avg_loss=0.09002, mel_loss=0.03936, linear_loss=0.05019]
[2020-05-12 05:09:47.478]  Step 153432  [3.531 sec/step, loss=0.08144, avg_loss=0.08986, mel_loss=0.03505, linear_loss=0.04639]
[2020-05-12 05:09:48.319]  Step 153433  [3.462 sec/step, loss=0.07475, avg_loss=0.08962, mel_loss=0.03190, linear_loss=0.04285]
[2020-05-12 05:09:50.558]  Step 153434  [3.447 sec/step, loss=0.08895, avg_loss=0.08954, mel_loss=0.03917, linear_loss=0.04978]
[2020-05-12 05:09:58.287]  Step 153435  [3.508 sec/step, loss=0.09849, avg_loss=0.08965, mel_loss=0.04539, linear_loss=0.05310]
[2020-05-12 05:09:58.889]  Step 153436  [3.480 sec/step, loss=0.06926, avg_loss=0.08938, mel_loss=0.03066, linear_loss=0.03860]
[2020-05-12 05:10:00.065]  Generated 32 batches of size 32 in 1.773 sec
[2020-05-12 05:10:00.243]  Step 153437  [3.466 sec/step, loss=0.08419, avg_loss=0.08929, mel_loss=0.03644, linear_loss=0.04774]
[2020-05-12 05:10:01.754]  Step 153438  [3.468 sec/step, loss=0.08407, avg_loss=0.08926, mel_loss=0.03676, linear_loss=0.04732]
[2020-05-12 05:10:06.108]  Step 153439  [3.493 sec/step, loss=0.09510, avg_loss=0.08932, mel_loss=0.04279, linear_loss=0.05231]
[2020-05-12 05:10:09.543]  Step 153440  [3.507 sec/step, loss=0.09486, avg_loss=0.08937, mel_loss=0.04238, linear_loss=0.05248]
[2020-05-12 05:10:11.207]  Step 153441  [3.509 sec/step, loss=0.08941, avg_loss=0.08942, mel_loss=0.03910, linear_loss=0.05031]
[2020-05-12 05:10:16.933]  Step 153442  [3.556 sec/step, loss=0.09738, avg_loss=0.08958, mel_loss=0.04431, linear_loss=0.05307]
[2020-05-12 05:10:18.519]  Step 153443  [3.555 sec/step, loss=0.08816, avg_loss=0.08957, mel_loss=0.03866, linear_loss=0.04950]
[2020-05-12 05:10:22.185]  Step 153444  [3.561 sec/step, loss=0.09596, avg_loss=0.08957, mel_loss=0.04289, linear_loss=0.05307]
[2020-05-12 05:10:24.679]  Step 153445  [3.545 sec/step, loss=0.09129, avg_loss=0.08952, mel_loss=0.04029, linear_loss=0.05100]
[2020-05-12 05:10:26.518]  Step 153446  [3.539 sec/step, loss=0.08805, avg_loss=0.08948, mel_loss=0.03847, linear_loss=0.04958]
[2020-05-12 05:10:28.095]  Step 153447  [3.424 sec/step, loss=0.08725, avg_loss=0.08951, mel_loss=0.03796, linear_loss=0.04929]
[2020-05-12 05:10:31.811]  Step 153448  [3.425 sec/step, loss=0.09679, avg_loss=0.08952, mel_loss=0.04345, linear_loss=0.05335]
[2020-05-12 05:10:33.745]  Step 153449  [3.375 sec/step, loss=0.08963, avg_loss=0.08941, mel_loss=0.03918, linear_loss=0.05045]
[2020-05-12 05:10:40.819]  Step 153450  [3.392 sec/step, loss=0.09518, avg_loss=0.08938, mel_loss=0.04381, linear_loss=0.05137]
[2020-05-12 05:10:40.819]  Writing summary at step: 153450
[2020-05-12 05:10:43.279]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153450
[2020-05-12 05:10:44.777]  Saving audio and alignment...
[2020-05-12 05:10:47.146]  Input: 어쩌다아 한번쯤으은~______
[2020-05-12 05:10:50.585]  Step 153451  [3.412 sec/step, loss=0.09502, avg_loss=0.08947, mel_loss=0.04252, linear_loss=0.05250]
[2020-05-12 05:10:51.631]  Step 153452  [3.387 sec/step, loss=0.08046, avg_loss=0.08933, mel_loss=0.03463, linear_loss=0.04583]
[2020-05-12 05:10:52.430]  Step 153453  [3.318 sec/step, loss=0.06767, avg_loss=0.08904, mel_loss=0.02968, linear_loss=0.03800]
[2020-05-12 05:10:53.404]  Step 153454  [3.305 sec/step, loss=0.08106, avg_loss=0.08895, mel_loss=0.03422, linear_loss=0.04683]
[2020-05-12 05:11:06.626]  Step 153455  [3.421 sec/step, loss=0.08519, avg_loss=0.08895, mel_loss=0.04017, linear_loss=0.04502]
[2020-05-12 05:11:12.491]  Step 153456  [3.411 sec/step, loss=0.09864, avg_loss=0.08896, mel_loss=0.04518, linear_loss=0.05346]
[2020-05-12 05:11:15.973]  Step 153457  [3.423 sec/step, loss=0.09414, avg_loss=0.08902, mel_loss=0.04205, linear_loss=0.05209]
[2020-05-12 05:11:20.218]  Step 153458  [3.411 sec/step, loss=0.09643, avg_loss=0.08900, mel_loss=0.04338, linear_loss=0.05305]
[2020-05-12 05:11:29.037]  Step 153459  [3.494 sec/step, loss=0.09335, avg_loss=0.08924, mel_loss=0.04339, linear_loss=0.04996]
[2020-05-12 05:11:34.589]  Step 153460  [3.505 sec/step, loss=0.09722, avg_loss=0.08923, mel_loss=0.04438, linear_loss=0.05285]
[2020-05-12 05:11:37.252]  Step 153461  [3.489 sec/step, loss=0.09365, avg_loss=0.08921, mel_loss=0.04174, linear_loss=0.05190]
[2020-05-12 05:11:39.458]  Step 153462  [3.476 sec/step, loss=0.09057, avg_loss=0.08916, mel_loss=0.03980, linear_loss=0.05077]
[2020-05-12 05:11:40.698]  Step 153463  [3.479 sec/step, loss=0.08407, avg_loss=0.08928, mel_loss=0.03631, linear_loss=0.04776]
[2020-05-12 05:11:41.735]  Step 153464  [3.442 sec/step, loss=0.08318, avg_loss=0.08916, mel_loss=0.03608, linear_loss=0.04710]
[2020-05-12 05:11:46.659]  Step 153465  [3.473 sec/step, loss=0.09486, avg_loss=0.08922, mel_loss=0.04271, linear_loss=0.05215]
[2020-05-12 05:11:48.441]  Generated 32 batches of size 32 in 1.776 sec
[2020-05-12 05:11:49.888]  Step 153466  [3.496 sec/step, loss=0.09375, avg_loss=0.08934, mel_loss=0.04161, linear_loss=0.05214]
[2020-05-12 05:11:52.858]  Step 153467  [3.500 sec/step, loss=0.09687, avg_loss=0.08940, mel_loss=0.04320, linear_loss=0.05367]
[2020-05-12 05:11:53.627]  Step 153468  [3.419 sec/step, loss=0.07767, avg_loss=0.08921, mel_loss=0.03369, linear_loss=0.04398]
[2020-05-12 05:11:55.162]  Step 153469  [3.402 sec/step, loss=0.08571, avg_loss=0.08911, mel_loss=0.03707, linear_loss=0.04864]
[2020-05-12 05:11:57.347]  Step 153470  [3.405 sec/step, loss=0.09011, avg_loss=0.08912, mel_loss=0.03936, linear_loss=0.05075]
[2020-05-12 05:11:58.863]  Step 153471  [3.391 sec/step, loss=0.08685, avg_loss=0.08908, mel_loss=0.03786, linear_loss=0.04899]
[2020-05-12 05:12:03.081]  Step 153472  [3.291 sec/step, loss=0.09484, avg_loss=0.08926, mel_loss=0.04259, linear_loss=0.05225]
[2020-05-12 05:12:04.750]  Step 153473  [3.300 sec/step, loss=0.08957, avg_loss=0.08934, mel_loss=0.03936, linear_loss=0.05021]
[2020-05-12 05:12:05.552]  Step 153474  [3.298 sec/step, loss=0.07663, avg_loss=0.08930, mel_loss=0.03244, linear_loss=0.04419]
[2020-05-12 05:12:08.741]  Step 153475  [3.272 sec/step, loss=0.09339, avg_loss=0.08924, mel_loss=0.04177, linear_loss=0.05162]
[2020-05-12 05:12:11.465]  Step 153476  [3.286 sec/step, loss=0.09250, avg_loss=0.08933, mel_loss=0.04112, linear_loss=0.05138]
[2020-05-12 05:12:12.119]  Step 153477  [3.256 sec/step, loss=0.07357, avg_loss=0.08911, mel_loss=0.03238, linear_loss=0.04119]
[2020-05-12 05:12:13.735]  Step 153478  [3.251 sec/step, loss=0.08877, avg_loss=0.08907, mel_loss=0.03863, linear_loss=0.05014]
[2020-05-12 05:12:17.212]  Step 153479  [3.275 sec/step, loss=0.09418, avg_loss=0.08919, mel_loss=0.04208, linear_loss=0.05210]
[2020-05-12 05:12:18.109]  Step 153480  [3.248 sec/step, loss=0.07337, avg_loss=0.08899, mel_loss=0.03171, linear_loss=0.04166]
[2020-05-12 05:12:20.519]  Step 153481  [3.235 sec/step, loss=0.09079, avg_loss=0.08899, mel_loss=0.04011, linear_loss=0.05069]
[2020-05-12 05:12:24.280]  Step 153482  [3.253 sec/step, loss=0.09694, avg_loss=0.08914, mel_loss=0.04351, linear_loss=0.05343]
[2020-05-12 05:12:26.474]  Step 153483  [3.250 sec/step, loss=0.09199, avg_loss=0.08920, mel_loss=0.04073, linear_loss=0.05126]
[2020-05-12 05:12:29.941]  Step 153484  [3.265 sec/step, loss=0.09553, avg_loss=0.08935, mel_loss=0.04246, linear_loss=0.05307]
[2020-05-12 05:12:31.666]  Step 153485  [3.265 sec/step, loss=0.08601, avg_loss=0.08938, mel_loss=0.03757, linear_loss=0.04844]
[2020-05-12 05:12:45.857]  Step 153486  [3.399 sec/step, loss=0.07385, avg_loss=0.08934, mel_loss=0.03489, linear_loss=0.03896]
[2020-05-12 05:12:51.967]  Step 153487  [3.412 sec/step, loss=0.09836, avg_loss=0.08936, mel_loss=0.04518, linear_loss=0.05318]
[2020-05-12 05:12:53.177]  Step 153488  [3.382 sec/step, loss=0.08232, avg_loss=0.08923, mel_loss=0.03522, linear_loss=0.04710]
[2020-05-12 05:12:58.921]  Step 153489  [3.422 sec/step, loss=0.09665, avg_loss=0.08930, mel_loss=0.04409, linear_loss=0.05256]
[2020-05-12 05:13:01.761]  Step 153490  [3.427 sec/step, loss=0.08938, avg_loss=0.08925, mel_loss=0.03932, linear_loss=0.05006]
[2020-05-12 05:13:03.741]  Step 153491  [3.438 sec/step, loss=0.08873, avg_loss=0.08931, mel_loss=0.03835, linear_loss=0.05039]
[2020-05-12 05:13:04.304]  Step 153492  [3.409 sec/step, loss=0.07581, avg_loss=0.08912, mel_loss=0.03318, linear_loss=0.04264]
[2020-05-12 05:13:09.092]  Step 153493  [3.427 sec/step, loss=0.09624, avg_loss=0.08914, mel_loss=0.04385, linear_loss=0.05238]
[2020-05-12 05:13:10.445]  Step 153494  [3.416 sec/step, loss=0.08456, avg_loss=0.08908, mel_loss=0.03664, linear_loss=0.04792]
[2020-05-12 05:13:14.943]  Step 153495  [3.427 sec/step, loss=0.09427, avg_loss=0.08909, mel_loss=0.04227, linear_loss=0.05200]
[2020-05-12 05:13:16.350]  Step 153496  [3.403 sec/step, loss=0.08486, avg_loss=0.08896, mel_loss=0.03692, linear_loss=0.04794]
[2020-05-12 05:13:25.212]  Step 153497  [3.346 sec/step, loss=0.09706, avg_loss=0.08916, mel_loss=0.04495, linear_loss=0.05210]
[2020-05-12 05:13:27.047]  Generated 32 batches of size 32 in 1.829 sec
[2020-05-12 05:13:28.226]  Step 153498  [3.346 sec/step, loss=0.09322, avg_loss=0.08917, mel_loss=0.04157, linear_loss=0.05165]
[2020-05-12 05:13:30.308]  Step 153499  [3.358 sec/step, loss=0.08928, avg_loss=0.08930, mel_loss=0.03949, linear_loss=0.04979]
[2020-05-12 05:13:31.669]  Step 153500  [3.287 sec/step, loss=0.08312, avg_loss=0.08921, mel_loss=0.03630, linear_loss=0.04681]
[2020-05-12 05:13:31.669]  Writing summary at step: 153500
[2020-05-12 05:13:32.554]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153500
[2020-05-12 05:13:35.389]  Saving audio and alignment...
[2020-05-12 05:13:37.586]  Input: 저는 이미 알고 있습니다~
[2020-05-12 05:13:42.385]  Step 153501  [3.321 sec/step, loss=0.09743, avg_loss=0.08930, mel_loss=0.04380, linear_loss=0.05363]
[2020-05-12 05:13:50.110]  Step 153502  [3.376 sec/step, loss=0.09656, avg_loss=0.08934, mel_loss=0.04428, linear_loss=0.05229]
[2020-05-12 05:13:56.950]  Step 153503  [3.427 sec/step, loss=0.09780, avg_loss=0.08945, mel_loss=0.04460, linear_loss=0.05320]
[2020-05-12 05:13:58.898]  Step 153504  [3.397 sec/step, loss=0.08960, avg_loss=0.08940, mel_loss=0.03918, linear_loss=0.05042]
[2020-05-12 05:14:03.058]  Step 153505  [3.375 sec/step, loss=0.09477, avg_loss=0.08939, mel_loss=0.04250, linear_loss=0.05228]
[2020-05-12 05:14:06.049]  Step 153506  [3.375 sec/step, loss=0.09427, avg_loss=0.08939, mel_loss=0.04198, linear_loss=0.05229]
[2020-05-12 05:14:11.873]  Step 153507  [3.413 sec/step, loss=0.09718, avg_loss=0.08946, mel_loss=0.04447, linear_loss=0.05272]
[2020-05-12 05:14:13.706]  Step 153508  [3.421 sec/step, loss=0.08777, avg_loss=0.08952, mel_loss=0.03819, linear_loss=0.04958]
[2020-05-12 05:14:18.128]  Step 153509  [3.394 sec/step, loss=0.09689, avg_loss=0.08951, mel_loss=0.04371, linear_loss=0.05319]
[2020-05-12 05:14:20.859]  Step 153510  [3.408 sec/step, loss=0.08912, avg_loss=0.08954, mel_loss=0.03932, linear_loss=0.04980]
[2020-05-12 05:14:35.038]  Step 153511  [3.522 sec/step, loss=0.07473, avg_loss=0.08938, mel_loss=0.03530, linear_loss=0.03943]
[2020-05-12 05:14:38.179]  Step 153512  [3.497 sec/step, loss=0.09465, avg_loss=0.08937, mel_loss=0.04202, linear_loss=0.05263]
[2020-05-12 05:14:45.601]  Step 153513  [3.549 sec/step, loss=0.09806, avg_loss=0.08945, mel_loss=0.04494, linear_loss=0.05312]
[2020-05-12 05:14:46.572]  Step 153514  [3.530 sec/step, loss=0.07698, avg_loss=0.08929, mel_loss=0.03294, linear_loss=0.04404]
[2020-05-12 05:14:47.135]  Step 153515  [3.527 sec/step, loss=0.07058, avg_loss=0.08920, mel_loss=0.03102, linear_loss=0.03957]
[2020-05-12 05:14:48.680]  Step 153516  [3.523 sec/step, loss=0.08719, avg_loss=0.08918, mel_loss=0.03787, linear_loss=0.04932]
[2020-05-12 05:14:49.950]  Step 153517  [3.482 sec/step, loss=0.08254, avg_loss=0.08905, mel_loss=0.03570, linear_loss=0.04684]
[2020-05-12 05:14:50.804]  Step 153518  [3.402 sec/step, loss=0.07668, avg_loss=0.08886, mel_loss=0.03242, linear_loss=0.04426]
[2020-05-12 05:14:55.689]  Step 153519  [3.415 sec/step, loss=0.09631, avg_loss=0.08889, mel_loss=0.04348, linear_loss=0.05283]
[2020-05-12 05:14:59.300]  Step 153520  [3.438 sec/step, loss=0.09462, avg_loss=0.08898, mel_loss=0.04236, linear_loss=0.05226]
[2020-05-12 05:15:03.382]  Step 153521  [3.432 sec/step, loss=0.09497, avg_loss=0.08896, mel_loss=0.04260, linear_loss=0.05237]
[2020-05-12 05:15:05.805]  Step 153522  [3.448 sec/step, loss=0.09189, avg_loss=0.08912, mel_loss=0.04060, linear_loss=0.05129]
[2020-05-12 05:15:14.609]  Step 153523  [3.467 sec/step, loss=0.09554, avg_loss=0.08910, mel_loss=0.04414, linear_loss=0.05140]
[2020-05-12 05:15:16.623]  Step 153524  [3.455 sec/step, loss=0.08892, avg_loss=0.08903, mel_loss=0.03881, linear_loss=0.05011]
[2020-05-12 05:15:21.960]  Step 153525  [3.498 sec/step, loss=0.09619, avg_loss=0.08920, mel_loss=0.04350, linear_loss=0.05269]
[2020-05-12 05:15:23.566]  Step 153526  [3.474 sec/step, loss=0.08799, avg_loss=0.08912, mel_loss=0.03856, linear_loss=0.04943]
[2020-05-12 05:15:25.341]  Step 153527  [3.359 sec/step, loss=0.08765, avg_loss=0.08919, mel_loss=0.03803, linear_loss=0.04962]
[2020-05-12 05:15:27.152]  Generated 32 batches of size 32 in 1.805 sec
[2020-05-12 05:15:27.633]  Step 153528  [3.361 sec/step, loss=0.09061, avg_loss=0.08920, mel_loss=0.04005, linear_loss=0.05057]
[2020-05-12 05:15:28.759]  Step 153529  [3.353 sec/step, loss=0.08407, avg_loss=0.08918, mel_loss=0.03584, linear_loss=0.04823]
[2020-05-12 05:15:29.752]  Step 153530  [3.336 sec/step, loss=0.08177, avg_loss=0.08905, mel_loss=0.03527, linear_loss=0.04649]
[2020-05-12 05:15:31.845]  Step 153531  [3.332 sec/step, loss=0.09168, avg_loss=0.08908, mel_loss=0.04031, linear_loss=0.05137]
[2020-05-12 05:15:35.335]  Step 153532  [3.356 sec/step, loss=0.09320, avg_loss=0.08919, mel_loss=0.04154, linear_loss=0.05166]
[2020-05-12 05:15:38.184]  Step 153533  [3.376 sec/step, loss=0.09240, avg_loss=0.08937, mel_loss=0.04113, linear_loss=0.05126]
[2020-05-12 05:15:39.571]  Step 153534  [3.367 sec/step, loss=0.08386, avg_loss=0.08932, mel_loss=0.03628, linear_loss=0.04758]
[2020-05-12 05:15:40.381]  Step 153535  [3.298 sec/step, loss=0.07645, avg_loss=0.08910, mel_loss=0.03258, linear_loss=0.04387]
[2020-05-12 05:15:46.907]  Step 153536  [3.357 sec/step, loss=0.09838, avg_loss=0.08939, mel_loss=0.04501, linear_loss=0.05337]
[2020-05-12 05:15:51.323]  Step 153537  [3.388 sec/step, loss=0.09973, avg_loss=0.08954, mel_loss=0.04506, linear_loss=0.05467]
[2020-05-12 05:16:04.407]  Step 153538  [3.504 sec/step, loss=0.08367, avg_loss=0.08954, mel_loss=0.03945, linear_loss=0.04422]
[2020-05-12 05:16:05.379]  Step 153539  [3.470 sec/step, loss=0.08255, avg_loss=0.08942, mel_loss=0.03523, linear_loss=0.04732]
[2020-05-12 05:16:06.397]  Step 153540  [3.446 sec/step, loss=0.08001, avg_loss=0.08927, mel_loss=0.03440, linear_loss=0.04562]
[2020-05-12 05:16:07.751]  Step 153541  [3.443 sec/step, loss=0.08341, avg_loss=0.08921, mel_loss=0.03630, linear_loss=0.04711]
[2020-05-12 05:16:09.758]  Step 153542  [3.406 sec/step, loss=0.09077, avg_loss=0.08914, mel_loss=0.04018, linear_loss=0.05058]
[2020-05-12 05:16:10.318]  Step 153543  [3.395 sec/step, loss=0.06883, avg_loss=0.08895, mel_loss=0.02992, linear_loss=0.03890]
[2020-05-12 05:16:15.237]  Step 153544  [3.408 sec/step, loss=0.09595, avg_loss=0.08895, mel_loss=0.04315, linear_loss=0.05280]
[2020-05-12 05:16:17.032]  Step 153545  [3.401 sec/step, loss=0.08886, avg_loss=0.08892, mel_loss=0.03878, linear_loss=0.05008]
[2020-05-12 05:16:20.550]  Step 153546  [3.418 sec/step, loss=0.09627, avg_loss=0.08901, mel_loss=0.04303, linear_loss=0.05324]
[2020-05-12 05:16:24.056]  Step 153547  [3.437 sec/step, loss=0.09383, avg_loss=0.08907, mel_loss=0.04210, linear_loss=0.05173]
[2020-05-12 05:16:31.544]  Step 153548  [3.475 sec/step, loss=0.09799, avg_loss=0.08908, mel_loss=0.04530, linear_loss=0.05269]
[2020-05-12 05:16:33.818]  Step 153549  [3.478 sec/step, loss=0.08974, avg_loss=0.08908, mel_loss=0.03945, linear_loss=0.05029]
[2020-05-12 05:16:34.898]  Step 153550  [3.418 sec/step, loss=0.08410, avg_loss=0.08897, mel_loss=0.03616, linear_loss=0.04794]
[2020-05-12 05:16:34.898]  Writing summary at step: 153550
[2020-05-12 05:16:38.656]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153550
[2020-05-12 05:16:40.220]  Saving audio and alignment...
[2020-05-12 05:16:44.303]  Input: 가장 의미 있게 보낸 여덟시간이라~_________________
[2020-05-12 05:16:46.483]  Step 153551  [3.405 sec/step, loss=0.08838, avg_loss=0.08891, mel_loss=0.03898, linear_loss=0.04941]
[2020-05-12 05:16:52.009]  Step 153552  [3.450 sec/step, loss=0.09807, avg_loss=0.08908, mel_loss=0.04460, linear_loss=0.05346]
[2020-05-12 05:16:54.600]  Step 153553  [3.468 sec/step, loss=0.09235, avg_loss=0.08933, mel_loss=0.04097, linear_loss=0.05137]
[2020-05-12 05:16:59.725]  Step 153554  [3.510 sec/step, loss=0.09635, avg_loss=0.08948, mel_loss=0.04312, linear_loss=0.05323]
[2020-05-12 05:17:06.322]  Step 153555  [3.443 sec/step, loss=0.09569, avg_loss=0.08959, mel_loss=0.04320, linear_loss=0.05249]
[2020-05-12 05:17:07.574]  Step 153556  [3.397 sec/step, loss=0.07677, avg_loss=0.08937, mel_loss=0.03338, linear_loss=0.04338]
[2020-05-12 05:17:14.186]  Step 153557  [3.429 sec/step, loss=0.09397, avg_loss=0.08937, mel_loss=0.04294, linear_loss=0.05104]
[2020-05-12 05:17:15.850]  Generated 32 batches of size 32 in 1.658 sec
[2020-05-12 05:17:23.142]  Step 153558  [3.476 sec/step, loss=0.09327, avg_loss=0.08934, mel_loss=0.04282, linear_loss=0.05045]
[2020-05-12 05:17:24.755]  Step 153559  [3.404 sec/step, loss=0.08867, avg_loss=0.08929, mel_loss=0.03881, linear_loss=0.04986]
[2020-05-12 05:17:25.932]  Step 153560  [3.360 sec/step, loss=0.08404, avg_loss=0.08916, mel_loss=0.03651, linear_loss=0.04753]
[2020-05-12 05:17:27.313]  Step 153561  [3.347 sec/step, loss=0.08581, avg_loss=0.08908, mel_loss=0.03737, linear_loss=0.04844]
[2020-05-12 05:17:30.178]  Step 153562  [3.354 sec/step, loss=0.09299, avg_loss=0.08910, mel_loss=0.04141, linear_loss=0.05158]
[2020-05-12 05:17:32.054]  Step 153563  [3.360 sec/step, loss=0.08710, avg_loss=0.08913, mel_loss=0.03805, linear_loss=0.04905]
[2020-05-12 05:17:32.888]  Step 153564  [3.358 sec/step, loss=0.07509, avg_loss=0.08905, mel_loss=0.03246, linear_loss=0.04263]
[2020-05-12 05:17:36.014]  Step 153565  [3.340 sec/step, loss=0.09528, avg_loss=0.08906, mel_loss=0.04249, linear_loss=0.05279]
[2020-05-12 05:17:37.509]  Step 153566  [3.323 sec/step, loss=0.08794, avg_loss=0.08900, mel_loss=0.03832, linear_loss=0.04962]
[2020-05-12 05:17:41.882]  Step 153567  [3.337 sec/step, loss=0.09581, avg_loss=0.08899, mel_loss=0.04314, linear_loss=0.05267]
[2020-05-12 05:17:42.459]  Step 153568  [3.335 sec/step, loss=0.06915, avg_loss=0.08890, mel_loss=0.03050, linear_loss=0.03865]
[2020-05-12 05:17:43.462]  Step 153569  [3.330 sec/step, loss=0.08320, avg_loss=0.08888, mel_loss=0.03598, linear_loss=0.04722]
[2020-05-12 05:17:46.585]  Step 153570  [3.339 sec/step, loss=0.09306, avg_loss=0.08891, mel_loss=0.04145, linear_loss=0.05161]
[2020-05-12 05:17:47.650]  Step 153571  [3.334 sec/step, loss=0.08496, avg_loss=0.08889, mel_loss=0.03632, linear_loss=0.04864]
[2020-05-12 05:17:48.649]  Step 153572  [3.302 sec/step, loss=0.07718, avg_loss=0.08871, mel_loss=0.03315, linear_loss=0.04403]
[2020-05-12 05:17:52.086]  Step 153573  [3.320 sec/step, loss=0.09320, avg_loss=0.08875, mel_loss=0.04155, linear_loss=0.05165]
[2020-05-12 05:17:54.097]  Step 153574  [3.332 sec/step, loss=0.08882, avg_loss=0.08887, mel_loss=0.03901, linear_loss=0.04981]
[2020-05-12 05:17:55.415]  Step 153575  [3.313 sec/step, loss=0.08515, avg_loss=0.08879, mel_loss=0.03699, linear_loss=0.04816]
[2020-05-12 05:17:57.000]  Step 153576  [3.302 sec/step, loss=0.08764, avg_loss=0.08874, mel_loss=0.03817, linear_loss=0.04947]
[2020-05-12 05:17:59.806]  Step 153577  [3.323 sec/step, loss=0.09192, avg_loss=0.08892, mel_loss=0.04074, linear_loss=0.05118]
[2020-05-12 05:18:04.145]  Step 153578  [3.351 sec/step, loss=0.09677, avg_loss=0.08900, mel_loss=0.04338, linear_loss=0.05340]
[2020-05-12 05:18:07.956]  Step 153579  [3.354 sec/step, loss=0.09481, avg_loss=0.08901, mel_loss=0.04246, linear_loss=0.05234]
[2020-05-12 05:18:12.627]  Step 153580  [3.392 sec/step, loss=0.09663, avg_loss=0.08924, mel_loss=0.04363, linear_loss=0.05300]
[2020-05-12 05:18:14.843]  Step 153581  [3.390 sec/step, loss=0.08927, avg_loss=0.08923, mel_loss=0.03935, linear_loss=0.04992]
[2020-05-12 05:18:21.089]  Step 153582  [3.415 sec/step, loss=0.09785, avg_loss=0.08923, mel_loss=0.04476, linear_loss=0.05309]
[2020-05-12 05:18:21.911]  Step 153583  [3.401 sec/step, loss=0.07569, avg_loss=0.08907, mel_loss=0.03268, linear_loss=0.04301]
[2020-05-12 05:18:30.834]  Step 153584  [3.455 sec/step, loss=0.09641, avg_loss=0.08908, mel_loss=0.04455, linear_loss=0.05186]
[2020-05-12 05:18:45.198]  Step 153585  [3.582 sec/step, loss=0.07626, avg_loss=0.08898, mel_loss=0.03612, linear_loss=0.04013]
[2020-05-12 05:18:50.894]  Step 153586  [3.497 sec/step, loss=0.09786, avg_loss=0.08922, mel_loss=0.04468, linear_loss=0.05319]
[2020-05-12 05:18:56.250]  Step 153587  [3.489 sec/step, loss=0.09500, avg_loss=0.08919, mel_loss=0.04310, linear_loss=0.05190]
[2020-05-12 05:18:59.660]  Step 153588  [3.511 sec/step, loss=0.09336, avg_loss=0.08930, mel_loss=0.04161, linear_loss=0.05175]
[2020-05-12 05:19:02.126]  Step 153589  [3.479 sec/step, loss=0.08854, avg_loss=0.08922, mel_loss=0.03917, linear_loss=0.04937]
[2020-05-12 05:19:03.905]  Generated 32 batches of size 32 in 1.774 sec
[2020-05-12 05:19:05.101]  Step 153590  [3.480 sec/step, loss=0.09179, avg_loss=0.08924, mel_loss=0.04070, linear_loss=0.05109]
[2020-05-12 05:19:07.254]  Step 153591  [3.482 sec/step, loss=0.09003, avg_loss=0.08926, mel_loss=0.03976, linear_loss=0.05027]
[2020-05-12 05:19:09.044]  Step 153592  [3.494 sec/step, loss=0.08752, avg_loss=0.08937, mel_loss=0.03812, linear_loss=0.04940]
[2020-05-12 05:19:09.687]  Step 153593  [3.452 sec/step, loss=0.07682, avg_loss=0.08918, mel_loss=0.03325, linear_loss=0.04357]
[2020-05-12 05:19:11.310]  Step 153594  [3.455 sec/step, loss=0.08861, avg_loss=0.08922, mel_loss=0.03858, linear_loss=0.05003]
[2020-05-12 05:19:18.833]  Step 153595  [3.485 sec/step, loss=0.09626, avg_loss=0.08924, mel_loss=0.04426, linear_loss=0.05200]
[2020-05-12 05:19:20.218]  Step 153596  [3.485 sec/step, loss=0.08652, avg_loss=0.08926, mel_loss=0.03760, linear_loss=0.04893]
[2020-05-12 05:19:21.419]  Step 153597  [3.409 sec/step, loss=0.08218, avg_loss=0.08911, mel_loss=0.03547, linear_loss=0.04671]
[2020-05-12 05:19:23.274]  Step 153598  [3.397 sec/step, loss=0.08882, avg_loss=0.08906, mel_loss=0.03877, linear_loss=0.05005]
[2020-05-12 05:19:25.270]  Step 153599  [3.396 sec/step, loss=0.08847, avg_loss=0.08906, mel_loss=0.03875, linear_loss=0.04972]
[2020-05-12 05:19:26.410]  Step 153600  [3.394 sec/step, loss=0.08346, avg_loss=0.08906, mel_loss=0.03615, linear_loss=0.04731]
[2020-05-12 05:19:26.410]  Writing summary at step: 153600
[2020-05-12 05:19:29.252]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153600
[2020-05-12 05:19:30.817]  Saving audio and alignment...
[2020-05-12 05:19:38.949]  Input: 그 시험 보는 회사에 옴부즈맨 프로그램은 꼭 챙겨 보세요 옴부즈맨 프로란~_______________________________
[2020-05-12 05:19:42.144]  Step 153601  [3.378 sec/step, loss=0.09650, avg_loss=0.08905, mel_loss=0.04308, linear_loss=0.05342]
[2020-05-12 05:19:44.568]  Step 153602  [3.325 sec/step, loss=0.09218, avg_loss=0.08901, mel_loss=0.04041, linear_loss=0.05178]
[2020-05-12 05:19:53.119]  Step 153603  [3.342 sec/step, loss=0.09262, avg_loss=0.08895, mel_loss=0.04296, linear_loss=0.04966]
[2020-05-12 05:19:58.437]  Step 153604  [3.376 sec/step, loss=0.09723, avg_loss=0.08903, mel_loss=0.04449, linear_loss=0.05274]
[2020-05-12 05:20:00.625]  Step 153605  [3.356 sec/step, loss=0.09116, avg_loss=0.08899, mel_loss=0.04045, linear_loss=0.05071]
[2020-05-12 05:20:02.380]  Step 153606  [3.344 sec/step, loss=0.09006, avg_loss=0.08895, mel_loss=0.03890, linear_loss=0.05117]
[2020-05-12 05:20:04.828]  Step 153607  [3.310 sec/step, loss=0.09135, avg_loss=0.08889, mel_loss=0.04014, linear_loss=0.05121]
[2020-05-12 05:20:06.334]  Step 153608  [3.307 sec/step, loss=0.08609, avg_loss=0.08888, mel_loss=0.03745, linear_loss=0.04864]
[2020-05-12 05:20:09.845]  Step 153609  [3.297 sec/step, loss=0.09518, avg_loss=0.08886, mel_loss=0.04260, linear_loss=0.05258]
[2020-05-12 05:20:11.911]  Step 153610  [3.291 sec/step, loss=0.09147, avg_loss=0.08888, mel_loss=0.04032, linear_loss=0.05115]
[2020-05-12 05:20:14.856]  Step 153611  [3.178 sec/step, loss=0.09480, avg_loss=0.08908, mel_loss=0.04227, linear_loss=0.05254]
[2020-05-12 05:20:16.661]  Step 153612  [3.165 sec/step, loss=0.08909, avg_loss=0.08903, mel_loss=0.03882, linear_loss=0.05027]
[2020-05-12 05:20:17.644]  Step 153613  [3.101 sec/step, loss=0.07979, avg_loss=0.08885, mel_loss=0.03418, linear_loss=0.04561]
[2020-05-12 05:20:21.339]  Step 153614  [3.128 sec/step, loss=0.09644, avg_loss=0.08904, mel_loss=0.04341, linear_loss=0.05303]
[2020-05-12 05:20:22.173]  Step 153615  [3.131 sec/step, loss=0.07762, avg_loss=0.08911, mel_loss=0.03303, linear_loss=0.04460]
[2020-05-12 05:20:29.551]  Step 153616  [3.189 sec/step, loss=0.09931, avg_loss=0.08923, mel_loss=0.04559, linear_loss=0.05373]
[2020-05-12 05:20:30.809]  Step 153617  [3.189 sec/step, loss=0.08701, avg_loss=0.08928, mel_loss=0.03771, linear_loss=0.04930]
[2020-05-12 05:20:35.637]  Step 153618  [3.229 sec/step, loss=0.09578, avg_loss=0.08947, mel_loss=0.04334, linear_loss=0.05244]
[2020-05-12 05:20:41.990]  Step 153619  [3.243 sec/step, loss=0.09626, avg_loss=0.08947, mel_loss=0.04412, linear_loss=0.05214]
[2020-05-12 05:20:43.715]  Generated 32 batches of size 32 in 1.719 sec
[2020-05-12 05:20:46.447]  Step 153620  [3.252 sec/step, loss=0.09588, avg_loss=0.08948, mel_loss=0.04331, linear_loss=0.05257]
[2020-05-12 05:20:50.324]  Step 153621  [3.250 sec/step, loss=0.09375, avg_loss=0.08947, mel_loss=0.04199, linear_loss=0.05175]
[2020-05-12 05:20:53.195]  Step 153622  [3.254 sec/step, loss=0.09651, avg_loss=0.08951, mel_loss=0.04281, linear_loss=0.05370]
[2020-05-12 05:20:54.548]  Step 153623  [3.180 sec/step, loss=0.08479, avg_loss=0.08941, mel_loss=0.03715, linear_loss=0.04764]
[2020-05-12 05:20:56.230]  Step 153624  [3.176 sec/step, loss=0.08939, avg_loss=0.08941, mel_loss=0.03937, linear_loss=0.05002]
[2020-05-12 05:20:56.798]  Step 153625  [3.129 sec/step, loss=0.07175, avg_loss=0.08917, mel_loss=0.03120, linear_loss=0.04055]
[2020-05-12 05:20:57.853]  Step 153626  [3.123 sec/step, loss=0.07922, avg_loss=0.08908, mel_loss=0.03417, linear_loss=0.04505]
[2020-05-12 05:20:58.656]  Step 153627  [3.113 sec/step, loss=0.07115, avg_loss=0.08891, mel_loss=0.03061, linear_loss=0.04054]
[2020-05-12 05:21:10.944]  Step 153628  [3.213 sec/step, loss=0.08450, avg_loss=0.08885, mel_loss=0.03978, linear_loss=0.04472]
[2020-05-12 05:21:18.398]  Step 153629  [3.277 sec/step, loss=0.09745, avg_loss=0.08899, mel_loss=0.04493, linear_loss=0.05252]
[2020-05-12 05:21:19.398]  Step 153630  [3.277 sec/step, loss=0.07834, avg_loss=0.08895, mel_loss=0.03347, linear_loss=0.04487]
[2020-05-12 05:21:20.224]  Step 153631  [3.264 sec/step, loss=0.07629, avg_loss=0.08880, mel_loss=0.03255, linear_loss=0.04374]
[2020-05-12 05:21:22.912]  Step 153632  [3.256 sec/step, loss=0.09145, avg_loss=0.08878, mel_loss=0.04062, linear_loss=0.05083]
[2020-05-12 05:21:26.962]  Step 153633  [3.268 sec/step, loss=0.09620, avg_loss=0.08882, mel_loss=0.04319, linear_loss=0.05301]
[2020-05-12 05:21:32.217]  Step 153634  [3.307 sec/step, loss=0.09809, avg_loss=0.08896, mel_loss=0.04477, linear_loss=0.05332]
[2020-05-12 05:21:33.030]  Step 153635  [3.307 sec/step, loss=0.07579, avg_loss=0.08895, mel_loss=0.03298, linear_loss=0.04280]
[2020-05-12 05:21:34.384]  Step 153636  [3.255 sec/step, loss=0.08611, avg_loss=0.08883, mel_loss=0.03740, linear_loss=0.04872]
[2020-05-12 05:21:37.447]  Step 153637  [3.242 sec/step, loss=0.09526, avg_loss=0.08879, mel_loss=0.04247, linear_loss=0.05280]
[2020-05-12 05:21:44.100]  Step 153638  [3.177 sec/step, loss=0.09515, avg_loss=0.08890, mel_loss=0.04349, linear_loss=0.05167]
[2020-05-12 05:21:45.876]  Step 153639  [3.185 sec/step, loss=0.08714, avg_loss=0.08895, mel_loss=0.03812, linear_loss=0.04902]
[2020-05-12 05:21:48.355]  Step 153640  [3.200 sec/step, loss=0.09078, avg_loss=0.08906, mel_loss=0.04004, linear_loss=0.05074]
[2020-05-12 05:21:52.907]  Step 153641  [3.232 sec/step, loss=0.09528, avg_loss=0.08917, mel_loss=0.04296, linear_loss=0.05232]
[2020-05-12 05:21:54.216]  Step 153642  [3.225 sec/step, loss=0.08554, avg_loss=0.08912, mel_loss=0.03737, linear_loss=0.04817]
[2020-05-12 05:21:55.331]  Step 153643  [3.230 sec/step, loss=0.08448, avg_loss=0.08928, mel_loss=0.03665, linear_loss=0.04783]
[2020-05-12 05:22:00.458]  Step 153644  [3.233 sec/step, loss=0.09709, avg_loss=0.08929, mel_loss=0.04401, linear_loss=0.05308]
[2020-05-12 05:22:02.142]  Step 153645  [3.231 sec/step, loss=0.08668, avg_loss=0.08927, mel_loss=0.03778, linear_loss=0.04890]
[2020-05-12 05:22:03.297]  Step 153646  [3.208 sec/step, loss=0.08123, avg_loss=0.08912, mel_loss=0.03517, linear_loss=0.04607]
[2020-05-12 05:22:07.636]  Step 153647  [3.216 sec/step, loss=0.09732, avg_loss=0.08915, mel_loss=0.04389, linear_loss=0.05343]
[2020-05-12 05:22:09.749]  Step 153648  [3.162 sec/step, loss=0.08927, avg_loss=0.08906, mel_loss=0.03923, linear_loss=0.05004]
[2020-05-12 05:22:10.346]  Step 153649  [3.146 sec/step, loss=0.07235, avg_loss=0.08889, mel_loss=0.03162, linear_loss=0.04073]
[2020-05-12 05:22:11.818]  Step 153650  [3.150 sec/step, loss=0.08658, avg_loss=0.08892, mel_loss=0.03776, linear_loss=0.04882]
[2020-05-12 05:22:11.818]  Writing summary at step: 153650
[2020-05-12 05:22:12.852]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153650
[2020-05-12 05:22:14.371]  Saving audio and alignment...
[2020-05-12 05:22:16.527]  Generated 32 batches of size 32 in 1.555 sec
[2020-05-12 05:22:18.211]  Input: 이 두 가지 만큼은 절대 잊으시면 안되~
[2020-05-12 05:22:21.825]  Step 153651  [3.164 sec/step, loss=0.09582, avg_loss=0.08899, mel_loss=0.04286, linear_loss=0.05297]
[2020-05-12 05:22:36.197]  Step 153652  [3.252 sec/step, loss=0.07447, avg_loss=0.08875, mel_loss=0.03535, linear_loss=0.03912]
[2020-05-12 05:22:39.067]  Step 153653  [3.255 sec/step, loss=0.09405, avg_loss=0.08877, mel_loss=0.04164, linear_loss=0.05241]
[2020-05-12 05:22:42.397]  Step 153654  [3.237 sec/step, loss=0.09696, avg_loss=0.08878, mel_loss=0.04352, linear_loss=0.05344]
[2020-05-12 05:22:45.867]  Step 153655  [3.206 sec/step, loss=0.09311, avg_loss=0.08875, mel_loss=0.04164, linear_loss=0.05147]
[2020-05-12 05:22:48.008]  Step 153656  [3.215 sec/step, loss=0.09079, avg_loss=0.08889, mel_loss=0.04004, linear_loss=0.05076]
[2020-05-12 05:22:56.351]  Step 153657  [3.232 sec/step, loss=0.09694, avg_loss=0.08892, mel_loss=0.04466, linear_loss=0.05227]
[2020-05-12 05:22:58.738]  Step 153658  [3.166 sec/step, loss=0.08954, avg_loss=0.08888, mel_loss=0.03967, linear_loss=0.04987]
[2020-05-12 05:22:59.878]  Step 153659  [3.162 sec/step, loss=0.08259, avg_loss=0.08882, mel_loss=0.03560, linear_loss=0.04700]
[2020-05-12 05:23:00.410]  Step 153660  [3.155 sec/step, loss=0.07378, avg_loss=0.08872, mel_loss=0.03225, linear_loss=0.04153]
[2020-05-12 05:23:05.200]  Step 153661  [3.189 sec/step, loss=0.09700, avg_loss=0.08883, mel_loss=0.04399, linear_loss=0.05302]
[2020-05-12 05:23:07.773]  Step 153662  [3.186 sec/step, loss=0.09093, avg_loss=0.08881, mel_loss=0.04026, linear_loss=0.05067]
[2020-05-12 05:23:13.922]  Step 153663  [3.229 sec/step, loss=0.09770, avg_loss=0.08892, mel_loss=0.04469, linear_loss=0.05301]
[2020-05-12 05:23:23.062]  Step 153664  [3.312 sec/step, loss=0.09475, avg_loss=0.08911, mel_loss=0.04370, linear_loss=0.05105]
[2020-05-12 05:23:24.126]  Step 153665  [3.292 sec/step, loss=0.08283, avg_loss=0.08899, mel_loss=0.03585, linear_loss=0.04698]
[2020-05-12 05:23:31.906]  Step 153666  [3.354 sec/step, loss=0.09774, avg_loss=0.08909, mel_loss=0.04506, linear_loss=0.05268]
[2020-05-12 05:23:32.549]  Step 153667  [3.317 sec/step, loss=0.07482, avg_loss=0.08888, mel_loss=0.03298, linear_loss=0.04184]
[2020-05-12 05:23:34.462]  Step 153668  [3.330 sec/step, loss=0.09013, avg_loss=0.08909, mel_loss=0.03954, linear_loss=0.05059]
[2020-05-12 05:23:36.200]  Step 153669  [3.338 sec/step, loss=0.08796, avg_loss=0.08914, mel_loss=0.03827, linear_loss=0.04969]
[2020-05-12 05:23:38.252]  Step 153670  [3.327 sec/step, loss=0.09000, avg_loss=0.08911, mel_loss=0.03955, linear_loss=0.05045]
[2020-05-12 05:23:41.384]  Step 153671  [3.348 sec/step, loss=0.09608, avg_loss=0.08922, mel_loss=0.04285, linear_loss=0.05323]
[2020-05-12 05:23:43.511]  Step 153672  [3.359 sec/step, loss=0.09206, avg_loss=0.08936, mel_loss=0.04042, linear_loss=0.05164]
[2020-05-12 05:23:46.162]  Step 153673  [3.351 sec/step, loss=0.09328, avg_loss=0.08937, mel_loss=0.04157, linear_loss=0.05171]
[2020-05-12 05:23:52.615]  Step 153674  [3.396 sec/step, loss=0.09867, avg_loss=0.08946, mel_loss=0.04535, linear_loss=0.05332]
[2020-05-12 05:23:56.115]  Step 153675  [3.417 sec/step, loss=0.09395, avg_loss=0.08955, mel_loss=0.04190, linear_loss=0.05206]
[2020-05-12 05:23:59.895]  Step 153676  [3.439 sec/step, loss=0.09665, avg_loss=0.08964, mel_loss=0.04340, linear_loss=0.05325]
[2020-05-12 05:24:02.926]  Step 153677  [3.442 sec/step, loss=0.09360, avg_loss=0.08966, mel_loss=0.04156, linear_loss=0.05204]
[2020-05-12 05:24:06.395]  Step 153678  [3.433 sec/step, loss=0.09532, avg_loss=0.08964, mel_loss=0.04252, linear_loss=0.05280]
[2020-05-12 05:24:07.236]  Step 153679  [3.403 sec/step, loss=0.07805, avg_loss=0.08948, mel_loss=0.03351, linear_loss=0.04454]
[2020-05-12 05:24:11.407]  Step 153680  [3.398 sec/step, loss=0.09577, avg_loss=0.08947, mel_loss=0.04307, linear_loss=0.05269]
[2020-05-12 05:24:12.464]  Step 153681  [3.387 sec/step, loss=0.08213, avg_loss=0.08940, mel_loss=0.03542, linear_loss=0.04671]
[2020-05-12 05:24:14.213]  Generated 32 batches of size 32 in 1.742 sec
[2020-05-12 05:24:14.791]  Step 153682  [3.347 sec/step, loss=0.09239, avg_loss=0.08934, mel_loss=0.04095, linear_loss=0.05144]
[2020-05-12 05:24:18.891]  Step 153683  [3.380 sec/step, loss=0.09600, avg_loss=0.08955, mel_loss=0.04287, linear_loss=0.05313]
[2020-05-12 05:24:19.748]  Step 153684  [3.300 sec/step, loss=0.08044, avg_loss=0.08939, mel_loss=0.03440, linear_loss=0.04604]
[2020-05-12 05:24:24.879]  Step 153685  [3.207 sec/step, loss=0.09658, avg_loss=0.08959, mel_loss=0.04383, linear_loss=0.05275]
[2020-05-12 05:24:26.522]  Step 153686  [3.167 sec/step, loss=0.08942, avg_loss=0.08950, mel_loss=0.03924, linear_loss=0.05018]
[2020-05-12 05:24:27.935]  Step 153687  [3.127 sec/step, loss=0.08620, avg_loss=0.08942, mel_loss=0.03766, linear_loss=0.04855]
[2020-05-12 05:24:41.202]  Step 153688  [3.226 sec/step, loss=0.08346, avg_loss=0.08932, mel_loss=0.03923, linear_loss=0.04422]
[2020-05-12 05:24:42.473]  Step 153689  [3.214 sec/step, loss=0.08175, avg_loss=0.08925, mel_loss=0.03538, linear_loss=0.04637]
[2020-05-12 05:24:43.955]  Step 153690  [3.199 sec/step, loss=0.08618, avg_loss=0.08919, mel_loss=0.03762, linear_loss=0.04856]
[2020-05-12 05:24:45.426]  Step 153691  [3.192 sec/step, loss=0.08631, avg_loss=0.08916, mel_loss=0.03752, linear_loss=0.04879]
[2020-05-12 05:24:52.651]  Step 153692  [3.247 sec/step, loss=0.09649, avg_loss=0.08925, mel_loss=0.04418, linear_loss=0.05230]
[2020-05-12 05:24:54.875]  Step 153693  [3.262 sec/step, loss=0.08962, avg_loss=0.08937, mel_loss=0.03949, linear_loss=0.05012]
[2020-05-12 05:24:59.770]  Step 153694  [3.295 sec/step, loss=0.09634, avg_loss=0.08945, mel_loss=0.04342, linear_loss=0.05292]
[2020-05-12 05:25:03.192]  Step 153695  [3.254 sec/step, loss=0.09308, avg_loss=0.08942, mel_loss=0.04202, linear_loss=0.05107]
[2020-05-12 05:25:05.834]  Step 153696  [3.267 sec/step, loss=0.09231, avg_loss=0.08948, mel_loss=0.04098, linear_loss=0.05133]
[2020-05-12 05:25:08.707]  Step 153697  [3.283 sec/step, loss=0.09291, avg_loss=0.08958, mel_loss=0.04150, linear_loss=0.05141]
[2020-05-12 05:25:09.629]  Step 153698  [3.274 sec/step, loss=0.07920, avg_loss=0.08949, mel_loss=0.03382, linear_loss=0.04538]
[2020-05-12 05:25:13.274]  Step 153699  [3.290 sec/step, loss=0.09495, avg_loss=0.08955, mel_loss=0.04258, linear_loss=0.05237]
[2020-05-12 05:25:14.089]  Step 153700  [3.287 sec/step, loss=0.07540, avg_loss=0.08947, mel_loss=0.03229, linear_loss=0.04311]
[2020-05-12 05:25:14.089]  Writing summary at step: 153700
[2020-05-12 05:25:14.939]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153700
[2020-05-12 05:25:16.434]  Saving audio and alignment...
[2020-05-12 05:25:20.030]  Input: 저느은 속도를 변화시키겠습~______________
[2020-05-12 05:25:22.507]  Step 153701  [3.280 sec/step, loss=0.09166, avg_loss=0.08942, mel_loss=0.04003, linear_loss=0.05162]
[2020-05-12 05:25:24.435]  Step 153702  [3.275 sec/step, loss=0.08374, avg_loss=0.08934, mel_loss=0.03628, linear_loss=0.04746]
[2020-05-12 05:25:26.739]  Step 153703  [3.213 sec/step, loss=0.08845, avg_loss=0.08930, mel_loss=0.03876, linear_loss=0.04969]
[2020-05-12 05:25:27.746]  Step 153704  [3.170 sec/step, loss=0.08099, avg_loss=0.08914, mel_loss=0.03503, linear_loss=0.04596]
[2020-05-12 05:25:41.658]  Step 153705  [3.287 sec/step, loss=0.07524, avg_loss=0.08898, mel_loss=0.03557, linear_loss=0.03966]
[2020-05-12 05:25:42.831]  Step 153706  [3.281 sec/step, loss=0.08057, avg_loss=0.08888, mel_loss=0.03471, linear_loss=0.04586]
[2020-05-12 05:25:45.957]  Step 153707  [3.288 sec/step, loss=0.09557, avg_loss=0.08892, mel_loss=0.04267, linear_loss=0.05290]
[2020-05-12 05:25:52.029]  Step 153708  [3.333 sec/step, loss=0.09479, avg_loss=0.08901, mel_loss=0.04319, linear_loss=0.05160]
[2020-05-12 05:25:54.450]  Step 153709  [3.322 sec/step, loss=0.09113, avg_loss=0.08897, mel_loss=0.04029, linear_loss=0.05084]
[2020-05-12 05:26:03.197]  Step 153710  [3.389 sec/step, loss=0.09582, avg_loss=0.08901, mel_loss=0.04433, linear_loss=0.05149]
[2020-05-12 05:26:07.487]  Step 153711  [3.403 sec/step, loss=0.09514, avg_loss=0.08902, mel_loss=0.04267, linear_loss=0.05247]
[2020-05-12 05:26:08.981]  Step 153712  [3.400 sec/step, loss=0.08427, avg_loss=0.08897, mel_loss=0.03644, linear_loss=0.04783]
[2020-05-12 05:26:09.775]  Generated 32 batches of size 32 in 2.282 sec
[2020-05-12 05:26:13.140]  Step 153713  [3.431 sec/step, loss=0.09561, avg_loss=0.08913, mel_loss=0.04298, linear_loss=0.05263]
[2020-05-12 05:26:16.237]  Step 153714  [3.425 sec/step, loss=0.09456, avg_loss=0.08911, mel_loss=0.04202, linear_loss=0.05255]
[2020-05-12 05:26:16.806]  Step 153715  [3.423 sec/step, loss=0.07200, avg_loss=0.08905, mel_loss=0.03200, linear_loss=0.04000]
[2020-05-12 05:26:21.411]  Step 153716  [3.395 sec/step, loss=0.09687, avg_loss=0.08903, mel_loss=0.04390, linear_loss=0.05298]
[2020-05-12 05:26:23.208]  Step 153717  [3.400 sec/step, loss=0.08856, avg_loss=0.08904, mel_loss=0.03875, linear_loss=0.04982]
[2020-05-12 05:26:28.828]  Step 153718  [3.408 sec/step, loss=0.09700, avg_loss=0.08906, mel_loss=0.04423, linear_loss=0.05277]
[2020-05-12 05:26:30.531]  Step 153719  [3.362 sec/step, loss=0.08665, avg_loss=0.08896, mel_loss=0.03792, linear_loss=0.04873]
[2020-05-12 05:26:32.287]  Step 153720  [3.335 sec/step, loss=0.08871, avg_loss=0.08889, mel_loss=0.03861, linear_loss=0.05010]
[2020-05-12 05:26:36.786]  Step 153721  [3.341 sec/step, loss=0.09530, avg_loss=0.08890, mel_loss=0.04304, linear_loss=0.05225]
[2020-05-12 05:26:42.109]  Step 153722  [3.366 sec/step, loss=0.09530, avg_loss=0.08889, mel_loss=0.04318, linear_loss=0.05212]
[2020-05-12 05:26:43.457]  Step 153723  [3.365 sec/step, loss=0.08525, avg_loss=0.08890, mel_loss=0.03705, linear_loss=0.04821]
[2020-05-12 05:26:45.231]  Step 153724  [3.366 sec/step, loss=0.08775, avg_loss=0.08888, mel_loss=0.03825, linear_loss=0.04950]
[2020-05-12 05:26:46.300]  Step 153725  [3.371 sec/step, loss=0.08353, avg_loss=0.08900, mel_loss=0.03591, linear_loss=0.04761]
[2020-05-12 05:26:48.510]  Step 153726  [3.383 sec/step, loss=0.09279, avg_loss=0.08913, mel_loss=0.04083, linear_loss=0.05196]
[2020-05-12 05:26:51.586]  Step 153727  [3.406 sec/step, loss=0.09320, avg_loss=0.08935, mel_loss=0.04131, linear_loss=0.05189]
[2020-05-12 05:26:53.948]  Step 153728  [3.306 sec/step, loss=0.09092, avg_loss=0.08942, mel_loss=0.04013, linear_loss=0.05079]
[2020-05-12 05:27:00.742]  Step 153729  [3.300 sec/step, loss=0.09689, avg_loss=0.08941, mel_loss=0.04432, linear_loss=0.05256]
[2020-05-12 05:27:18.692]  Step 153730  [3.469 sec/step, loss=0.07315, avg_loss=0.08936, mel_loss=0.03457, linear_loss=0.03858]
[2020-05-12 05:27:21.069]  Step 153731  [3.485 sec/step, loss=0.09007, avg_loss=0.08950, mel_loss=0.03950, linear_loss=0.05057]
[2020-05-12 05:27:22.091]  Step 153732  [3.468 sec/step, loss=0.07769, avg_loss=0.08936, mel_loss=0.03300, linear_loss=0.04469]
[2020-05-12 05:27:25.793]  Step 153733  [3.465 sec/step, loss=0.09604, avg_loss=0.08936, mel_loss=0.04294, linear_loss=0.05310]
[2020-05-12 05:27:26.772]  Step 153734  [3.422 sec/step, loss=0.08325, avg_loss=0.08921, mel_loss=0.03599, linear_loss=0.04726]
[2020-05-12 05:27:32.624]  Step 153735  [3.472 sec/step, loss=0.09637, avg_loss=0.08942, mel_loss=0.04366, linear_loss=0.05271]
[2020-05-12 05:27:33.775]  Step 153736  [3.470 sec/step, loss=0.08447, avg_loss=0.08940, mel_loss=0.03665, linear_loss=0.04782]
[2020-05-12 05:27:35.549]  Step 153737  [3.457 sec/step, loss=0.08996, avg_loss=0.08935, mel_loss=0.03926, linear_loss=0.05070]
[2020-05-12 05:27:36.112]  Step 153738  [3.397 sec/step, loss=0.07139, avg_loss=0.08911, mel_loss=0.03110, linear_loss=0.04028]
[2020-05-12 05:27:39.531]  Step 153739  [3.413 sec/step, loss=0.09382, avg_loss=0.08918, mel_loss=0.04187, linear_loss=0.05195]
[2020-05-12 05:27:42.199]  Step 153740  [3.415 sec/step, loss=0.09102, avg_loss=0.08918, mel_loss=0.03993, linear_loss=0.05109]
[2020-05-12 05:27:43.513]  Step 153741  [3.382 sec/step, loss=0.08422, avg_loss=0.08907, mel_loss=0.03678, linear_loss=0.04743]
[2020-05-12 05:27:44.346]  Step 153742  [3.378 sec/step, loss=0.07664, avg_loss=0.08898, mel_loss=0.03313, linear_loss=0.04351]
[2020-05-12 05:27:46.004]  Step 153743  [3.383 sec/step, loss=0.08792, avg_loss=0.08901, mel_loss=0.03862, linear_loss=0.04930]
[2020-05-12 05:27:48.204]  Generated 32 batches of size 32 in 2.195 sec
[2020-05-12 05:27:48.929]  Step 153744  [3.361 sec/step, loss=0.09289, avg_loss=0.08897, mel_loss=0.04149, linear_loss=0.05139]
[2020-05-12 05:27:56.625]  Step 153745  [3.421 sec/step, loss=0.09855, avg_loss=0.08909, mel_loss=0.04537, linear_loss=0.05318]
[2020-05-12 05:27:59.871]  Step 153746  [3.442 sec/step, loss=0.09514, avg_loss=0.08923, mel_loss=0.04255, linear_loss=0.05260]
[2020-05-12 05:28:01.927]  Step 153747  [3.419 sec/step, loss=0.09257, avg_loss=0.08918, mel_loss=0.04045, linear_loss=0.05212]
[2020-05-12 05:28:06.025]  Step 153748  [3.439 sec/step, loss=0.09573, avg_loss=0.08925, mel_loss=0.04306, linear_loss=0.05267]
[2020-05-12 05:28:07.524]  Step 153749  [3.448 sec/step, loss=0.08757, avg_loss=0.08940, mel_loss=0.03823, linear_loss=0.04934]
[2020-05-12 05:28:15.914]  Step 153750  [3.517 sec/step, loss=0.09607, avg_loss=0.08949, mel_loss=0.04449, linear_loss=0.05158]
[2020-05-12 05:28:15.914]  Writing summary at step: 153750
[2020-05-12 05:28:16.690]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153750
[2020-05-12 05:28:18.189]  Saving audio and alignment...
[2020-05-12 05:28:25.554]  Input: 아 그 밖에 제가 더 신경 써야 될 사항이 있을까요 그러니까 그 분의 대답이 이거였어요~_________
[2020-05-12 05:28:27.239]  Step 153751  [3.498 sec/step, loss=0.08647, avg_loss=0.08940, mel_loss=0.03760, linear_loss=0.04887]
[2020-05-12 05:28:28.874]  Step 153752  [3.371 sec/step, loss=0.08696, avg_loss=0.08952, mel_loss=0.03807, linear_loss=0.04889]
[2020-05-12 05:28:39.963]  Step 153753  [3.453 sec/step, loss=0.09463, avg_loss=0.08953, mel_loss=0.04374, linear_loss=0.05089]
[2020-05-12 05:28:41.881]  Step 153754  [3.439 sec/step, loss=0.09078, avg_loss=0.08947, mel_loss=0.03984, linear_loss=0.05095]
[2020-05-12 05:28:43.851]  Step 153755  [3.424 sec/step, loss=0.08965, avg_loss=0.08943, mel_loss=0.03947, linear_loss=0.05018]
[2020-05-12 05:28:46.327]  Step 153756  [3.427 sec/step, loss=0.09202, avg_loss=0.08945, mel_loss=0.04053, linear_loss=0.05149]
[2020-05-12 05:28:48.132]  Step 153757  [3.362 sec/step, loss=0.08725, avg_loss=0.08935, mel_loss=0.03774, linear_loss=0.04951]
[2020-05-12 05:28:53.734]  Step 153758  [3.394 sec/step, loss=0.09761, avg_loss=0.08943, mel_loss=0.04463, linear_loss=0.05298]
[2020-05-12 05:28:56.329]  Step 153759  [3.408 sec/step, loss=0.09204, avg_loss=0.08952, mel_loss=0.04087, linear_loss=0.05117]
[2020-05-12 05:28:59.197]  Step 153760  [3.432 sec/step, loss=0.09318, avg_loss=0.08972, mel_loss=0.04150, linear_loss=0.05167]
[2020-05-12 05:29:02.294]  Step 153761  [3.415 sec/step, loss=0.09576, avg_loss=0.08971, mel_loss=0.04275, linear_loss=0.05301]
[2020-05-12 05:29:15.792]  Step 153762  [3.524 sec/step, loss=0.08528, avg_loss=0.08965, mel_loss=0.04029, linear_loss=0.04499]
[2020-05-12 05:29:16.358]  Step 153763  [3.468 sec/step, loss=0.06738, avg_loss=0.08935, mel_loss=0.02964, linear_loss=0.03774]
[2020-05-12 05:29:17.381]  Step 153764  [3.387 sec/step, loss=0.07906, avg_loss=0.08919, mel_loss=0.03404, linear_loss=0.04501]
[2020-05-12 05:29:19.565]  Step 153765  [3.398 sec/step, loss=0.08988, avg_loss=0.08926, mel_loss=0.03971, linear_loss=0.05017]
[2020-05-12 05:29:24.508]  Step 153766  [3.370 sec/step, loss=0.09572, avg_loss=0.08924, mel_loss=0.04321, linear_loss=0.05251]
[2020-05-12 05:29:28.958]  Step 153767  [3.408 sec/step, loss=0.09778, avg_loss=0.08947, mel_loss=0.04415, linear_loss=0.05364]
[2020-05-12 05:29:36.518]  Step 153768  [3.464 sec/step, loss=0.09630, avg_loss=0.08953, mel_loss=0.04441, linear_loss=0.05189]
[2020-05-12 05:29:40.255]  Step 153769  [3.484 sec/step, loss=0.09741, avg_loss=0.08963, mel_loss=0.04349, linear_loss=0.05392]
[2020-05-12 05:29:41.427]  Step 153770  [3.476 sec/step, loss=0.08335, avg_loss=0.08956, mel_loss=0.03609, linear_loss=0.04726]
[2020-05-12 05:29:48.069]  Step 153771  [3.511 sec/step, loss=0.09510, avg_loss=0.08955, mel_loss=0.04343, linear_loss=0.05167]
[2020-05-12 05:29:49.750]  Step 153772  [3.506 sec/step, loss=0.08654, avg_loss=0.08949, mel_loss=0.03823, linear_loss=0.04831]
[2020-05-12 05:29:52.856]  Step 153773  [3.511 sec/step, loss=0.09480, avg_loss=0.08951, mel_loss=0.04205, linear_loss=0.05275]
[2020-05-12 05:29:53.702]  Step 153774  [3.455 sec/step, loss=0.07561, avg_loss=0.08928, mel_loss=0.03252, linear_loss=0.04309]
[2020-05-12 05:29:54.381]  Step 153775  [3.427 sec/step, loss=0.07639, avg_loss=0.08910, mel_loss=0.03365, linear_loss=0.04274]
[2020-05-12 05:29:54.735]  Generated 32 batches of size 32 in 1.873 sec
[2020-05-12 05:29:58.025]  Step 153776  [3.425 sec/step, loss=0.09417, avg_loss=0.08908, mel_loss=0.04228, linear_loss=0.05189]
[2020-05-12 05:30:02.270]  Step 153777  [3.437 sec/step, loss=0.09528, avg_loss=0.08909, mel_loss=0.04271, linear_loss=0.05257]
[2020-05-12 05:30:03.155]  Step 153778  [3.412 sec/step, loss=0.07915, avg_loss=0.08893, mel_loss=0.03405, linear_loss=0.04510]
[2020-05-12 05:30:06.678]  Step 153779  [3.438 sec/step, loss=0.09437, avg_loss=0.08910, mel_loss=0.04228, linear_loss=0.05209]
[2020-05-12 05:30:09.052]  Step 153780  [3.420 sec/step, loss=0.09156, avg_loss=0.08905, mel_loss=0.04033, linear_loss=0.05123]
[2020-05-12 05:30:10.412]  Step 153781  [3.423 sec/step, loss=0.08315, avg_loss=0.08906, mel_loss=0.03601, linear_loss=0.04714]
[2020-05-12 05:30:11.516]  Step 153782  [3.411 sec/step, loss=0.08494, avg_loss=0.08899, mel_loss=0.03652, linear_loss=0.04843]
[2020-05-12 05:30:16.872]  Step 153783  [3.424 sec/step, loss=0.09793, avg_loss=0.08901, mel_loss=0.04466, linear_loss=0.05327]
[2020-05-12 05:30:19.345]  Step 153784  [3.440 sec/step, loss=0.08936, avg_loss=0.08910, mel_loss=0.03919, linear_loss=0.05017]
[2020-05-12 05:30:20.958]  Step 153785  [3.405 sec/step, loss=0.08716, avg_loss=0.08900, mel_loss=0.03813, linear_loss=0.04903]
[2020-05-12 05:30:23.815]  Step 153786  [3.417 sec/step, loss=0.09431, avg_loss=0.08905, mel_loss=0.04206, linear_loss=0.05224]
[2020-05-12 05:30:24.964]  Step 153787  [3.414 sec/step, loss=0.08332, avg_loss=0.08902, mel_loss=0.03593, linear_loss=0.04739]
[2020-05-12 05:30:39.129]  Step 153788  [3.423 sec/step, loss=0.07536, avg_loss=0.08894, mel_loss=0.03554, linear_loss=0.03982]
[2020-05-12 05:30:41.339]  Step 153789  [3.433 sec/step, loss=0.09144, avg_loss=0.08904, mel_loss=0.04029, linear_loss=0.05115]
[2020-05-12 05:30:47.827]  Step 153790  [3.483 sec/step, loss=0.09856, avg_loss=0.08916, mel_loss=0.04500, linear_loss=0.05356]
[2020-05-12 05:30:51.597]  Step 153791  [3.506 sec/step, loss=0.09554, avg_loss=0.08926, mel_loss=0.04267, linear_loss=0.05287]
[2020-05-12 05:30:53.144]  Step 153792  [3.449 sec/step, loss=0.08801, avg_loss=0.08917, mel_loss=0.03817, linear_loss=0.04984]
[2020-05-12 05:30:54.094]  Step 153793  [3.436 sec/step, loss=0.07750, avg_loss=0.08905, mel_loss=0.03324, linear_loss=0.04426]
[2020-05-12 05:30:54.860]  Step 153794  [3.395 sec/step, loss=0.07201, avg_loss=0.08881, mel_loss=0.03184, linear_loss=0.04017]
[2020-05-12 05:30:56.851]  Step 153795  [3.381 sec/step, loss=0.08993, avg_loss=0.08878, mel_loss=0.03944, linear_loss=0.05049]
[2020-05-12 05:30:59.967]  Step 153796  [3.385 sec/step, loss=0.09342, avg_loss=0.08879, mel_loss=0.04135, linear_loss=0.05207]
[2020-05-12 05:31:02.508]  Step 153797  [3.382 sec/step, loss=0.09034, avg_loss=0.08876, mel_loss=0.03996, linear_loss=0.05038]
[2020-05-12 05:31:08.394]  Step 153798  [3.432 sec/step, loss=0.09648, avg_loss=0.08893, mel_loss=0.04403, linear_loss=0.05245]
[2020-05-12 05:31:09.409]  Step 153799  [3.405 sec/step, loss=0.08134, avg_loss=0.08880, mel_loss=0.03521, linear_loss=0.04614]
[2020-05-12 05:31:10.754]  Step 153800  [3.411 sec/step, loss=0.08666, avg_loss=0.08891, mel_loss=0.03760, linear_loss=0.04906]
[2020-05-12 05:31:10.754]  Writing summary at step: 153800
[2020-05-12 05:31:12.835]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153800
[2020-05-12 05:31:14.377]  Saving audio and alignment...
[2020-05-12 05:31:19.895]  Input: 아나운서 준비 기간 내내 저를 붙들어 준 한 한마디가 됐습니다~___
[2020-05-12 05:31:27.589]  Step 153801  [3.463 sec/step, loss=0.09713, avg_loss=0.08897, mel_loss=0.04458, linear_loss=0.05255]
[2020-05-12 05:31:31.644]  Step 153802  [3.484 sec/step, loss=0.09520, avg_loss=0.08908, mel_loss=0.04261, linear_loss=0.05259]
[2020-05-12 05:31:36.392]  Step 153803  [3.508 sec/step, loss=0.09576, avg_loss=0.08915, mel_loss=0.04326, linear_loss=0.05249]
[2020-05-12 05:31:37.731]  Step 153804  [3.512 sec/step, loss=0.08302, avg_loss=0.08917, mel_loss=0.03602, linear_loss=0.04700]
[2020-05-12 05:31:38.156]  Generated 32 batches of size 32 in 1.759 sec
[2020-05-12 05:31:41.341]  Step 153805  [3.409 sec/step, loss=0.09683, avg_loss=0.08939, mel_loss=0.04360, linear_loss=0.05322]
[2020-05-12 05:31:42.119]  Step 153806  [3.405 sec/step, loss=0.07516, avg_loss=0.08933, mel_loss=0.03255, linear_loss=0.04261]
[2020-05-12 05:31:43.840]  Step 153807  [3.391 sec/step, loss=0.08811, avg_loss=0.08926, mel_loss=0.03853, linear_loss=0.04957]
[2020-05-12 05:31:45.661]  Step 153808  [3.348 sec/step, loss=0.08733, avg_loss=0.08919, mel_loss=0.03806, linear_loss=0.04927]
[2020-05-12 05:31:48.831]  Step 153809  [3.356 sec/step, loss=0.09280, avg_loss=0.08920, mel_loss=0.04125, linear_loss=0.05155]
[2020-05-12 05:31:49.626]  Step 153810  [3.276 sec/step, loss=0.07917, avg_loss=0.08904, mel_loss=0.03381, linear_loss=0.04536]
[2020-05-12 05:31:54.035]  Step 153811  [3.277 sec/step, loss=0.09834, avg_loss=0.08907, mel_loss=0.04462, linear_loss=0.05372]
[2020-05-12 05:32:02.695]  Step 153812  [3.349 sec/step, loss=0.09771, avg_loss=0.08920, mel_loss=0.04509, linear_loss=0.05262]
[2020-05-12 05:32:04.386]  Step 153813  [3.324 sec/step, loss=0.08831, avg_loss=0.08913, mel_loss=0.03859, linear_loss=0.04972]
[2020-05-12 05:32:05.438]  Step 153814  [3.304 sec/step, loss=0.08294, avg_loss=0.08901, mel_loss=0.03573, linear_loss=0.04721]
[2020-05-12 05:32:06.068]  Step 153815  [3.305 sec/step, loss=0.07638, avg_loss=0.08906, mel_loss=0.03302, linear_loss=0.04336]
[2020-05-12 05:32:07.019]  Step 153816  [3.268 sec/step, loss=0.07972, avg_loss=0.08888, mel_loss=0.03386, linear_loss=0.04586]
[2020-05-12 05:32:08.381]  Step 153817  [3.264 sec/step, loss=0.08642, avg_loss=0.08886, mel_loss=0.03761, linear_loss=0.04882]
[2020-05-12 05:32:09.497]  Step 153818  [3.219 sec/step, loss=0.08268, avg_loss=0.08872, mel_loss=0.03556, linear_loss=0.04712]
[2020-05-12 05:32:13.139]  Step 153819  [3.238 sec/step, loss=0.09640, avg_loss=0.08882, mel_loss=0.04330, linear_loss=0.05309]
[2020-05-12 05:32:15.665]  Step 153820  [3.246 sec/step, loss=0.09049, avg_loss=0.08884, mel_loss=0.03983, linear_loss=0.05066]
[2020-05-12 05:32:19.151]  Step 153821  [3.236 sec/step, loss=0.09279, avg_loss=0.08881, mel_loss=0.04146, linear_loss=0.05133]
[2020-05-12 05:32:28.101]  Step 153822  [3.272 sec/step, loss=0.09636, avg_loss=0.08882, mel_loss=0.04471, linear_loss=0.05165]
[2020-05-12 05:32:41.017]  Step 153823  [3.388 sec/step, loss=0.08274, avg_loss=0.08880, mel_loss=0.03899, linear_loss=0.04375]
[2020-05-12 05:32:45.942]  Step 153824  [3.419 sec/step, loss=0.09583, avg_loss=0.08888, mel_loss=0.04334, linear_loss=0.05249]
[2020-05-12 05:32:47.718]  Step 153825  [3.426 sec/step, loss=0.08761, avg_loss=0.08892, mel_loss=0.03798, linear_loss=0.04963]
[2020-05-12 05:32:48.620]  Step 153826  [3.413 sec/step, loss=0.08306, avg_loss=0.08882, mel_loss=0.03587, linear_loss=0.04719]
[2020-05-12 05:32:50.219]  Step 153827  [3.398 sec/step, loss=0.08735, avg_loss=0.08876, mel_loss=0.03809, linear_loss=0.04926]
[2020-05-12 05:32:54.367]  Step 153828  [3.416 sec/step, loss=0.09554, avg_loss=0.08881, mel_loss=0.04306, linear_loss=0.05247]
[2020-05-12 05:32:55.126]  Step 153829  [3.356 sec/step, loss=0.07911, avg_loss=0.08863, mel_loss=0.03378, linear_loss=0.04533]
[2020-05-12 05:32:59.652]  Step 153830  [3.222 sec/step, loss=0.09656, avg_loss=0.08886, mel_loss=0.04347, linear_loss=0.05309]
[2020-05-12 05:33:00.204]  Step 153831  [3.203 sec/step, loss=0.07304, avg_loss=0.08869, mel_loss=0.03196, linear_loss=0.04107]
[2020-05-12 05:33:02.390]  Step 153832  [3.215 sec/step, loss=0.08958, avg_loss=0.08881, mel_loss=0.03976, linear_loss=0.04981]
[2020-05-12 05:33:04.321]  Step 153833  [3.197 sec/step, loss=0.09015, avg_loss=0.08875, mel_loss=0.03971, linear_loss=0.05044]
[2020-05-12 05:33:06.344]  Step 153834  [3.208 sec/step, loss=0.09017, avg_loss=0.08882, mel_loss=0.03943, linear_loss=0.05075]
[2020-05-12 05:33:13.396]  Step 153835  [3.220 sec/step, loss=0.09797, avg_loss=0.08884, mel_loss=0.04495, linear_loss=0.05303]
[2020-05-12 05:33:15.157]  Generated 32 batches of size 32 in 1.756 sec
[2020-05-12 05:33:16.212]  Step 153836  [3.236 sec/step, loss=0.09319, avg_loss=0.08893, mel_loss=0.04137, linear_loss=0.05181]
[2020-05-12 05:33:18.610]  Step 153837  [3.243 sec/step, loss=0.09228, avg_loss=0.08895, mel_loss=0.04091, linear_loss=0.05137]
[2020-05-12 05:33:21.699]  Step 153838  [3.268 sec/step, loss=0.09372, avg_loss=0.08917, mel_loss=0.04206, linear_loss=0.05166]
[2020-05-12 05:33:23.124]  Step 153839  [3.248 sec/step, loss=0.08444, avg_loss=0.08908, mel_loss=0.03679, linear_loss=0.04765]
[2020-05-12 05:33:26.029]  Step 153840  [3.250 sec/step, loss=0.09475, avg_loss=0.08912, mel_loss=0.04214, linear_loss=0.05261]
[2020-05-12 05:33:31.544]  Step 153841  [3.292 sec/step, loss=0.09751, avg_loss=0.08925, mel_loss=0.04433, linear_loss=0.05318]
[2020-05-12 05:33:35.139]  Step 153842  [3.320 sec/step, loss=0.09570, avg_loss=0.08944, mel_loss=0.04303, linear_loss=0.05266]
[2020-05-12 05:33:41.486]  Step 153843  [3.367 sec/step, loss=0.09563, avg_loss=0.08952, mel_loss=0.04368, linear_loss=0.05196]
[2020-05-12 05:33:42.780]  Step 153844  [3.350 sec/step, loss=0.08300, avg_loss=0.08942, mel_loss=0.03622, linear_loss=0.04678]
[2020-05-12 05:33:50.187]  Step 153845  [3.348 sec/step, loss=0.09717, avg_loss=0.08940, mel_loss=0.04456, linear_loss=0.05262]
[2020-05-12 05:33:51.532]  Step 153846  [3.329 sec/step, loss=0.08480, avg_loss=0.08930, mel_loss=0.03674, linear_loss=0.04806]
[2020-05-12 05:33:55.993]  Step 153847  [3.353 sec/step, loss=0.09785, avg_loss=0.08935, mel_loss=0.04421, linear_loss=0.05364]
[2020-05-12 05:33:57.639]  Step 153848  [3.328 sec/step, loss=0.08630, avg_loss=0.08926, mel_loss=0.03780, linear_loss=0.04849]
[2020-05-12 05:33:59.009]  Step 153849  [3.327 sec/step, loss=0.08575, avg_loss=0.08924, mel_loss=0.03724, linear_loss=0.04851]
[2020-05-12 05:34:03.302]  Step 153850  [3.286 sec/step, loss=0.09498, avg_loss=0.08923, mel_loss=0.04295, linear_loss=0.05203]
[2020-05-12 05:34:03.302]  Writing summary at step: 153850
[2020-05-12 05:34:06.205]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153850
[2020-05-12 05:34:07.704]  Saving audio and alignment...
[2020-05-12 05:34:15.752]  Input: 아 그럼이 두가지를 반드시 기억하면서 오늘의 뉴스 리딩으로 넘어가도록 하겠습니다~______________________
[2020-05-12 05:34:20.916]  Step 153851  [3.321 sec/step, loss=0.09597, avg_loss=0.08933, mel_loss=0.04344, linear_loss=0.05252]
[2020-05-12 05:34:21.927]  Step 153852  [3.314 sec/step, loss=0.07939, avg_loss=0.08925, mel_loss=0.03403, linear_loss=0.04536]
[2020-05-12 05:34:28.565]  Step 153853  [3.270 sec/step, loss=0.09729, avg_loss=0.08928, mel_loss=0.04443, linear_loss=0.05286]
[2020-05-12 05:34:41.673]  Step 153854  [3.382 sec/step, loss=0.08345, avg_loss=0.08920, mel_loss=0.03942, linear_loss=0.04403]
[2020-05-12 05:34:44.822]  Step 153855  [3.394 sec/step, loss=0.09566, avg_loss=0.08926, mel_loss=0.04279, linear_loss=0.05287]
[2020-05-12 05:34:45.713]  Step 153856  [3.378 sec/step, loss=0.07205, avg_loss=0.08906, mel_loss=0.03099, linear_loss=0.04106]
[2020-05-12 05:34:49.239]  Step 153857  [3.395 sec/step, loss=0.09370, avg_loss=0.08913, mel_loss=0.04196, linear_loss=0.05173]
[2020-05-12 05:34:50.059]  Step 153858  [3.347 sec/step, loss=0.07604, avg_loss=0.08891, mel_loss=0.03243, linear_loss=0.04362]
[2020-05-12 05:34:52.055]  Step 153859  [3.341 sec/step, loss=0.09107, avg_loss=0.08890, mel_loss=0.04017, linear_loss=0.05090]
[2020-05-12 05:34:54.824]  Step 153860  [3.340 sec/step, loss=0.09261, avg_loss=0.08890, mel_loss=0.04120, linear_loss=0.05142]
[2020-05-12 05:34:55.360]  Step 153861  [3.314 sec/step, loss=0.07074, avg_loss=0.08865, mel_loss=0.03123, linear_loss=0.03951]
[2020-05-12 05:35:03.913]  Step 153862  [3.265 sec/step, loss=0.09294, avg_loss=0.08872, mel_loss=0.04260, linear_loss=0.05034]
[2020-05-12 05:35:05.069]  Step 153863  [3.271 sec/step, loss=0.08443, avg_loss=0.08889, mel_loss=0.03653, linear_loss=0.04790]
[2020-05-12 05:35:06.880]  Step 153864  [3.279 sec/step, loss=0.08808, avg_loss=0.08898, mel_loss=0.03847, linear_loss=0.04961]
[2020-05-12 05:35:09.074]  Step 153865  [3.279 sec/step, loss=0.09061, avg_loss=0.08899, mel_loss=0.03981, linear_loss=0.05079]
[2020-05-12 05:35:10.754]  Step 153866  [3.246 sec/step, loss=0.08682, avg_loss=0.08890, mel_loss=0.03781, linear_loss=0.04901]
[2020-05-12 05:35:10.886]  Generated 32 batches of size 32 in 1.806 sec
[2020-05-12 05:35:12.760]  Step 153867  [3.222 sec/step, loss=0.08900, avg_loss=0.08881, mel_loss=0.03913, linear_loss=0.04987]
[2020-05-12 05:35:13.782]  Step 153868  [3.156 sec/step, loss=0.08053, avg_loss=0.08866, mel_loss=0.03467, linear_loss=0.04586]
[2020-05-12 05:35:17.195]  Step 153869  [3.153 sec/step, loss=0.09485, avg_loss=0.08863, mel_loss=0.04238, linear_loss=0.05247]
[2020-05-12 05:35:19.578]  Step 153870  [3.165 sec/step, loss=0.09270, avg_loss=0.08872, mel_loss=0.04078, linear_loss=0.05192]
[2020-05-12 05:35:20.682]  Step 153871  [3.110 sec/step, loss=0.08274, avg_loss=0.08860, mel_loss=0.03560, linear_loss=0.04713]
[2020-05-12 05:35:24.328]  Step 153872  [3.130 sec/step, loss=0.09628, avg_loss=0.08870, mel_loss=0.04301, linear_loss=0.05326]
[2020-05-12 05:35:28.177]  Step 153873  [3.137 sec/step, loss=0.09627, avg_loss=0.08871, mel_loss=0.04311, linear_loss=0.05316]
[2020-05-12 05:35:30.706]  Step 153874  [3.154 sec/step, loss=0.09167, avg_loss=0.08887, mel_loss=0.04060, linear_loss=0.05107]
[2020-05-12 05:35:33.417]  Step 153875  [3.174 sec/step, loss=0.09205, avg_loss=0.08903, mel_loss=0.04088, linear_loss=0.05117]
[2020-05-12 05:35:40.777]  Step 153876  [3.211 sec/step, loss=0.09749, avg_loss=0.08906, mel_loss=0.04489, linear_loss=0.05260]
[2020-05-12 05:35:44.442]  Step 153877  [3.206 sec/step, loss=0.09661, avg_loss=0.08908, mel_loss=0.04309, linear_loss=0.05352]
[2020-05-12 05:35:46.262]  Step 153878  [3.215 sec/step, loss=0.08724, avg_loss=0.08916, mel_loss=0.03810, linear_loss=0.04915]
[2020-05-12 05:35:48.011]  Step 153879  [3.197 sec/step, loss=0.08796, avg_loss=0.08909, mel_loss=0.03805, linear_loss=0.04991]
[2020-05-12 05:35:50.859]  Step 153880  [3.202 sec/step, loss=0.09208, avg_loss=0.08910, mel_loss=0.04091, linear_loss=0.05117]
[2020-05-12 05:35:52.828]  Step 153881  [3.208 sec/step, loss=0.09009, avg_loss=0.08917, mel_loss=0.03966, linear_loss=0.05043]
[2020-05-12 05:35:58.832]  Step 153882  [3.257 sec/step, loss=0.09629, avg_loss=0.08928, mel_loss=0.04387, linear_loss=0.05241]
[2020-05-12 05:35:59.800]  Step 153883  [3.213 sec/step, loss=0.07923, avg_loss=0.08909, mel_loss=0.03355, linear_loss=0.04568]
[2020-05-12 05:36:00.329]  Step 153884  [3.194 sec/step, loss=0.07228, avg_loss=0.08892, mel_loss=0.03159, linear_loss=0.04069]
[2020-05-12 05:36:01.645]  Step 153885  [3.191 sec/step, loss=0.08235, avg_loss=0.08888, mel_loss=0.03571, linear_loss=0.04663]
[2020-05-12 05:36:04.752]  Step 153886  [3.193 sec/step, loss=0.09436, avg_loss=0.08888, mel_loss=0.04172, linear_loss=0.05264]
[2020-05-12 05:36:05.770]  Step 153887  [3.192 sec/step, loss=0.08209, avg_loss=0.08886, mel_loss=0.03529, linear_loss=0.04680]
[2020-05-12 05:36:07.385]  Step 153888  [3.066 sec/step, loss=0.08843, avg_loss=0.08899, mel_loss=0.03862, linear_loss=0.04981]
[2020-05-12 05:36:08.534]  Step 153889  [3.056 sec/step, loss=0.08173, avg_loss=0.08890, mel_loss=0.03493, linear_loss=0.04679]
[2020-05-12 05:36:11.869]  Step 153890  [3.024 sec/step, loss=0.09476, avg_loss=0.08886, mel_loss=0.04229, linear_loss=0.05246]
[2020-05-12 05:36:17.015]  Step 153891  [3.038 sec/step, loss=0.09462, avg_loss=0.08885, mel_loss=0.04283, linear_loss=0.05179]
[2020-05-12 05:36:25.307]  Step 153892  [3.105 sec/step, loss=0.09491, avg_loss=0.08892, mel_loss=0.04372, linear_loss=0.05119]
[2020-05-12 05:36:26.171]  Step 153893  [3.105 sec/step, loss=0.07630, avg_loss=0.08891, mel_loss=0.03293, linear_loss=0.04336]
[2020-05-12 05:36:28.249]  Step 153894  [3.118 sec/step, loss=0.09179, avg_loss=0.08910, mel_loss=0.04009, linear_loss=0.05170]
[2020-05-12 05:36:32.878]  Step 153895  [3.144 sec/step, loss=0.09661, avg_loss=0.08917, mel_loss=0.04371, linear_loss=0.05290]
[2020-05-12 05:36:36.656]  Step 153896  [3.151 sec/step, loss=0.09660, avg_loss=0.08920, mel_loss=0.04327, linear_loss=0.05334]
[2020-05-12 05:36:38.212]  Step 153897  [3.141 sec/step, loss=0.08685, avg_loss=0.08917, mel_loss=0.03801, linear_loss=0.04884]
[2020-05-12 05:36:39.252]  Step 153898  [3.092 sec/step, loss=0.08021, avg_loss=0.08901, mel_loss=0.03442, linear_loss=0.04579]
[2020-05-12 05:36:39.975]  Generated 32 batches of size 32 in 1.758 sec
[2020-05-12 05:36:43.402]  Step 153899  [3.124 sec/step, loss=0.09358, avg_loss=0.08913, mel_loss=0.04195, linear_loss=0.05163]
[2020-05-12 05:36:45.872]  Step 153900  [3.135 sec/step, loss=0.08938, avg_loss=0.08916, mel_loss=0.03934, linear_loss=0.05004]
[2020-05-12 05:36:45.872]  Writing summary at step: 153900
[2020-05-12 05:36:49.324]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153900
[2020-05-12 05:36:50.818]  Saving audio and alignment...
[2020-05-12 05:37:08.992]  Input: 뭐 내 얼굴이 나가지도 않는 데 이렇게 할 필요는 없지만 씩씩거리면서 그런 표정 제스처가 목소리에 그대로 반영이 되기 때문에~____________________________________________
[2020-05-12 05:37:10.403]  Step 153901  [3.072 sec/step, loss=0.08329, avg_loss=0.08902, mel_loss=0.03625, linear_loss=0.04703]
[2020-05-12 05:37:12.631]  Step 153902  [3.054 sec/step, loss=0.08986, avg_loss=0.08896, mel_loss=0.03954, linear_loss=0.05032]
[2020-05-12 05:37:18.193]  Step 153903  [3.062 sec/step, loss=0.09805, avg_loss=0.08899, mel_loss=0.04463, linear_loss=0.05342]
[2020-05-12 05:37:19.039]  Step 153904  [3.057 sec/step, loss=0.07276, avg_loss=0.08888, mel_loss=0.03188, linear_loss=0.04088]
[2020-05-12 05:37:24.263]  Step 153905  [3.073 sec/step, loss=0.09649, avg_loss=0.08888, mel_loss=0.04337, linear_loss=0.05312]
[2020-05-12 05:37:27.444]  Step 153906  [3.097 sec/step, loss=0.09062, avg_loss=0.08904, mel_loss=0.03996, linear_loss=0.05065]
[2020-05-12 05:37:31.992]  Step 153907  [3.125 sec/step, loss=0.09597, avg_loss=0.08911, mel_loss=0.04278, linear_loss=0.05319]
[2020-05-12 05:37:36.495]  Step 153908  [3.152 sec/step, loss=0.09457, avg_loss=0.08919, mel_loss=0.04232, linear_loss=0.05225]
[2020-05-12 05:37:39.044]  Step 153909  [3.146 sec/step, loss=0.08972, avg_loss=0.08916, mel_loss=0.03915, linear_loss=0.05057]
[2020-05-12 05:37:43.781]  Step 153910  [3.186 sec/step, loss=0.09639, avg_loss=0.08933, mel_loss=0.04337, linear_loss=0.05303]
[2020-05-12 05:37:45.108]  Step 153911  [3.155 sec/step, loss=0.08411, avg_loss=0.08919, mel_loss=0.03628, linear_loss=0.04783]
[2020-05-12 05:37:57.421]  Step 153912  [3.191 sec/step, loss=0.08830, avg_loss=0.08909, mel_loss=0.04177, linear_loss=0.04653]
[2020-05-12 05:38:04.337]  Step 153913  [3.243 sec/step, loss=0.09607, avg_loss=0.08917, mel_loss=0.04402, linear_loss=0.05205]
[2020-05-12 05:38:05.694]  Step 153914  [3.247 sec/step, loss=0.08592, avg_loss=0.08920, mel_loss=0.03738, linear_loss=0.04854]
[2020-05-12 05:38:06.295]  Step 153915  [3.246 sec/step, loss=0.06858, avg_loss=0.08912, mel_loss=0.03035, linear_loss=0.03823]
[2020-05-12 05:38:09.761]  Step 153916  [3.271 sec/step, loss=0.09202, avg_loss=0.08924, mel_loss=0.04114, linear_loss=0.05089]
[2020-05-12 05:38:11.384]  Step 153917  [3.274 sec/step, loss=0.08968, avg_loss=0.08928, mel_loss=0.03894, linear_loss=0.05074]
[2020-05-12 05:38:12.150]  Step 153918  [3.270 sec/step, loss=0.07725, avg_loss=0.08922, mel_loss=0.03349, linear_loss=0.04376]
[2020-05-12 05:38:16.541]  Step 153919  [3.278 sec/step, loss=0.09517, avg_loss=0.08921, mel_loss=0.04288, linear_loss=0.05229]
[2020-05-12 05:38:17.708]  Step 153920  [3.264 sec/step, loss=0.08396, avg_loss=0.08914, mel_loss=0.03618, linear_loss=0.04778]
[2020-05-12 05:38:18.654]  Step 153921  [3.239 sec/step, loss=0.07933, avg_loss=0.08901, mel_loss=0.03418, linear_loss=0.04515]
[2020-05-12 05:38:21.330]  Step 153922  [3.176 sec/step, loss=0.09139, avg_loss=0.08896, mel_loss=0.04060, linear_loss=0.05080]
[2020-05-12 05:38:22.779]  Step 153923  [3.062 sec/step, loss=0.08713, avg_loss=0.08900, mel_loss=0.03791, linear_loss=0.04923]
[2020-05-12 05:38:25.180]  Step 153924  [3.036 sec/step, loss=0.09272, avg_loss=0.08897, mel_loss=0.04078, linear_loss=0.05193]
[2020-05-12 05:38:34.102]  Step 153925  [3.108 sec/step, loss=0.09425, avg_loss=0.08904, mel_loss=0.04349, linear_loss=0.05077]
[2020-05-12 05:38:37.163]  Step 153926  [3.129 sec/step, loss=0.09510, avg_loss=0.08916, mel_loss=0.04244, linear_loss=0.05266]
[2020-05-12 05:38:39.142]  Step 153927  [3.133 sec/step, loss=0.08942, avg_loss=0.08918, mel_loss=0.03896, linear_loss=0.05046]
[2020-05-12 05:38:40.941]  Generated 32 batches of size 32 in 1.793 sec
[2020-05-12 05:38:45.166]  Step 153928  [3.152 sec/step, loss=0.09642, avg_loss=0.08919, mel_loss=0.04368, linear_loss=0.05275]
[2020-05-12 05:38:46.099]  Step 153929  [3.154 sec/step, loss=0.07517, avg_loss=0.08915, mel_loss=0.03229, linear_loss=0.04288]
[2020-05-12 05:38:47.263]  Step 153930  [3.120 sec/step, loss=0.08299, avg_loss=0.08901, mel_loss=0.03602, linear_loss=0.04697]
[2020-05-12 05:38:49.571]  Step 153931  [3.138 sec/step, loss=0.09090, avg_loss=0.08919, mel_loss=0.04026, linear_loss=0.05065]
[2020-05-12 05:38:57.156]  Step 153932  [3.192 sec/step, loss=0.09656, avg_loss=0.08926, mel_loss=0.04436, linear_loss=0.05220]
[2020-05-12 05:39:02.486]  Step 153933  [3.226 sec/step, loss=0.09606, avg_loss=0.08932, mel_loss=0.04360, linear_loss=0.05246]
[2020-05-12 05:39:04.183]  Step 153934  [3.222 sec/step, loss=0.08998, avg_loss=0.08932, mel_loss=0.03954, linear_loss=0.05044]
[2020-05-12 05:39:07.582]  Step 153935  [3.186 sec/step, loss=0.09614, avg_loss=0.08930, mel_loss=0.04269, linear_loss=0.05345]
[2020-05-12 05:39:09.415]  Step 153936  [3.176 sec/step, loss=0.08953, avg_loss=0.08926, mel_loss=0.03909, linear_loss=0.05044]
[2020-05-12 05:39:11.350]  Step 153937  [3.171 sec/step, loss=0.09084, avg_loss=0.08925, mel_loss=0.04007, linear_loss=0.05077]
[2020-05-12 05:39:16.726]  Step 153938  [3.194 sec/step, loss=0.09546, avg_loss=0.08927, mel_loss=0.04346, linear_loss=0.05200]
[2020-05-12 05:39:17.268]  Step 153939  [3.185 sec/step, loss=0.07757, avg_loss=0.08920, mel_loss=0.03376, linear_loss=0.04380]
[2020-05-12 05:39:18.470]  Step 153940  [3.168 sec/step, loss=0.08024, avg_loss=0.08905, mel_loss=0.03466, linear_loss=0.04557]
[2020-05-12 05:39:19.225]  Step 153941  [3.121 sec/step, loss=0.07549, avg_loss=0.08883, mel_loss=0.03284, linear_loss=0.04265]
[2020-05-12 05:39:20.619]  Step 153942  [3.099 sec/step, loss=0.08581, avg_loss=0.08873, mel_loss=0.03746, linear_loss=0.04835]
[2020-05-12 05:39:21.539]  Step 153943  [3.044 sec/step, loss=0.08130, avg_loss=0.08859, mel_loss=0.03530, linear_loss=0.04600]
[2020-05-12 05:39:23.390]  Step 153944  [3.050 sec/step, loss=0.08768, avg_loss=0.08864, mel_loss=0.03828, linear_loss=0.04940]
[2020-05-12 05:39:24.962]  Step 153945  [2.992 sec/step, loss=0.08763, avg_loss=0.08854, mel_loss=0.03847, linear_loss=0.04916]
[2020-05-12 05:39:27.104]  Step 153946  [3.000 sec/step, loss=0.09043, avg_loss=0.08860, mel_loss=0.03969, linear_loss=0.05074]
[2020-05-12 05:39:35.807]  Step 153947  [3.042 sec/step, loss=0.09650, avg_loss=0.08859, mel_loss=0.04470, linear_loss=0.05180]
[2020-05-12 05:39:40.588]  Step 153948  [3.073 sec/step, loss=0.09601, avg_loss=0.08868, mel_loss=0.04344, linear_loss=0.05257]
[2020-05-12 05:39:44.567]  Step 153949  [3.100 sec/step, loss=0.09508, avg_loss=0.08878, mel_loss=0.04268, linear_loss=0.05239]
[2020-05-12 05:39:45.441]  Step 153950  [3.065 sec/step, loss=0.08290, avg_loss=0.08866, mel_loss=0.03521, linear_loss=0.04770]
[2020-05-12 05:39:45.441]  Writing summary at step: 153950
[2020-05-12 05:39:52.266]  Saving checkpoint to: ./logs-tacotron/model.ckpt-153950
[2020-05-12 05:39:53.818]  Saving audio and alignment...
[2020-05-12 05:40:00.359]  Input: 오늘 행사에 진행 규칙입니다 이렇게 간단명료하게 줄여주세요~_____________
[2020-05-12 05:40:04.066]  Step 153951  [3.051 sec/step, loss=0.09497, avg_loss=0.08865, mel_loss=0.04246, linear_loss=0.05251]
[2020-05-12 05:40:11.676]  Step 153952  [3.117 sec/step, loss=0.09715, avg_loss=0.08882, mel_loss=0.04472, linear_loss=0.05243]
[2020-05-12 05:40:14.156]  Step 153953  [3.075 sec/step, loss=0.09267, avg_loss=0.08878, mel_loss=0.04088, linear_loss=0.05179]
[2020-05-12 05:40:16.797]  Step 153954  [2.971 sec/step, loss=0.09199, avg_loss=0.08886, mel_loss=0.04059, linear_loss=0.05139]
[2020-05-12 05:40:22.583]  Step 153955  [2.997 sec/step, loss=0.09619, avg_loss=0.08887, mel_loss=0.04377, linear_loss=0.05242]
[2020-05-12 05:40:23.353]  Step 153956  [2.996 sec/step, loss=0.07891, avg_loss=0.08894, mel_loss=0.03391, linear_loss=0.04500]
[2020-05-12 05:40:24.668]  Step 153957  [2.974 sec/step, loss=0.08526, avg_loss=0.08885, mel_loss=0.03698, linear_loss=0.04828]
[2020-05-12 05:40:26.471]  Generated 32 batches of size 32 in 1.796 sec
[2020-05-12 05:40:26.530]  Step 153958  [2.984 sec/step, loss=0.08895, avg_loss=0.08898, mel_loss=0.03881, linear_loss=0.05014]
[2020-05-12 05:40:29.693]  Step 153959  [2.996 sec/step, loss=0.09530, avg_loss=0.08902, mel_loss=0.04268, linear_loss=0.05262]
[2020-05-12 05:40:33.028]  Step 153960  [3.001 sec/step, loss=0.09483, avg_loss=0.08905, mel_loss=0.04219, linear_loss=0.05263]
[2020-05-12 05:40:36.602]  Step 153961  [3.032 sec/step, loss=0.09361, avg_loss=0.08927, mel_loss=0.04166, linear_loss=0.05195]
[2020-05-12 05:40:37.683]  Step 153962  [2.957 sec/step, loss=0.08322, avg_loss=0.08918, mel_loss=0.03603, linear_loss=0.04719]
[2020-05-12 05:40:39.293]  Step 153963  [2.962 sec/step, loss=0.08793, avg_loss=0.08921, mel_loss=0.03824, linear_loss=0.04968]
[2020-05-12 05:40:53.552]  Step 153964  [3.086 sec/step, loss=0.07631, avg_loss=0.08909, mel_loss=0.03619, linear_loss=0.04013]
[2020-05-12 05:40:55.748]  Step 153965  [3.086 sec/step, loss=0.09111, avg_loss=0.08910, mel_loss=0.04027, linear_loss=0.05084]
[2020-05-12 05:40:58.678]  Step 153966  [3.099 sec/step, loss=0.09214, avg_loss=0.08915, mel_loss=0.04109, linear_loss=0.05106]
[2020-05-12 05:41:00.334]  Step 153967  [3.095 sec/step, loss=0.08680, avg_loss=0.08913, mel_loss=0.03792, linear_loss=0.04888]
[2020-05-12 05:41:04.037]  Step 153968  [3.122 sec/step, loss=0.09516, avg_loss=0.08928, mel_loss=0.04266, linear_loss=0.05250]
[2020-05-12 05:41:05.224]  Step 153969  [3.100 sec/step, loss=0.08371, avg_loss=0.08917, mel_loss=0.03647, linear_loss=0.04725]
[2020-05-12 05:41:06.091]  Step 153970  [3.084 sec/step, loss=0.07098, avg_loss=0.08895, mel_loss=0.03055, linear_loss=0.04043]
[2020-05-12 05:41:07.755]  Step 153971  [3.090 sec/step, loss=0.08868, avg_loss=0.08901, mel_loss=0.03870, linear_loss=0.04998]
[2020-05-12 05:41:22.135]  Step 153972  [3.197 sec/step, loss=0.07701, avg_loss=0.08882, mel_loss=0.03649, linear_loss=0.04052]
[2020-05-12 05:41:24.141]  Step 153973  [3.179 sec/step, loss=0.08925, avg_loss=0.08874, mel_loss=0.03912, linear_loss=0.05014]
[2020-05-12 05:41:27.240]  Step 153974  [3.185 sec/step, loss=0.09363, avg_loss=0.08876, mel_loss=0.04162, linear_loss=0.05201]
[2020-05-12 05:41:28.287]  Step 153975  [3.168 sec/step, loss=0.07852, avg_loss=0.08863, mel_loss=0.03377, linear_loss=0.04475]
[2020-05-12 05:41:31.270]  Step 153976  [3.124 sec/step, loss=0.09446, avg_loss=0.08860, mel_loss=0.04196, linear_loss=0.05250]
[2020-05-12 05:41:33.747]  Step 153977  [3.112 sec/step, loss=0.09067, avg_loss=0.08854, mel_loss=0.03987, linear_loss=0.05080]
[2020-05-12 05:41:34.823]  Step 153978  [3.105 sec/step, loss=0.08087, avg_loss=0.08848, mel_loss=0.03465, linear_loss=0.04623]
[2020-05-12 05:41:35.651]  Step 153979  [3.096 sec/step, loss=0.07896, avg_loss=0.08839, mel_loss=0.03376, linear_loss=0.04521]
[2020-05-12 05:41:42.003]  Step 153980  [3.131 sec/step, loss=0.09646, avg_loss=0.08843, mel_loss=0.04412, linear_loss=0.05234]
[2020-05-12 05:41:46.717]  Step 153981  [3.158 sec/step, loss=0.09527, avg_loss=0.08848, mel_loss=0.04286, linear_loss=0.05241]
[2020-05-12 05:41:55.634]  Step 153982  [3.187 sec/step, loss=0.09602, avg_loss=0.08848, mel_loss=0.04420, linear_loss=0.05182]
[2020-05-12 05:41:57.881]  Step 153983  [3.200 sec/step, loss=0.09007, avg_loss=0.08859, mel_loss=0.03989, linear_loss=0.05019]
[2020-05-12 05:42:00.573]  Step 153984  [3.222 sec/step, loss=0.09357, avg_loss=0.08880, mel_loss=0.04155, linear_loss=0.05202]
[2020-05-12 05:42:02.639]  Step 153985  [3.229 sec/step, loss=0.08914, avg_loss=0.08887, mel_loss=0.03933, linear_loss=0.04981]
[2020-05-12 05:42:03.168]  Step 153986  [3.203 sec/step, loss=0.06932, avg_loss=0.08862, mel_loss=0.03016, linear_loss=0.03916]
[2020-05-12 05:42:08.812]  Step 153987  [3.250 sec/step, loss=0.09711, avg_loss=0.08877, mel_loss=0.04424, linear_loss=0.05287]
[2020-05-12 05:42:13.926]  Step 153988  [3.285 sec/step, loss=0.09622, avg_loss=0.08885, mel_loss=0.04363, linear_loss=0.05259]
[2020-05-12 05:42:15.092]  Step 153989  [3.285 sec/step, loss=0.08243, avg_loss=0.08885, mel_loss=0.03523, linear_loss=0.04721]
[2020-05-12 05:42:16.729]  Generated 32 batches of size 32 in 1.631 sec
[2020-05-12 05:42:22.703]  Step 153990  [3.328 sec/step, loss=0.09799, avg_loss=0.08889, mel_loss=0.04494, linear_loss=0.05305]
[2020-05-12 05:42:25.430]  Step 153991  [3.304 sec/step, loss=0.09211, avg_loss=0.08886, mel_loss=0.04083, linear_loss=0.05128]
[2020-05-12 05:42:29.771]  Step 153992  [3.264 sec/step, loss=0.09576, avg_loss=0.08887, mel_loss=0.04294, linear_loss=0.05282]
[2020-05-12 05:42:31.289]  Step 153993  [3.271 sec/step, loss=0.08432, avg_loss=0.08895, mel_loss=0.03682, linear_loss=0.04750]
[2020-05-12 05:42:33.227]  Step 153994  [3.269 sec/step, loss=0.08802, avg_loss=0.08891, mel_loss=0.03823, linear_loss=0.04979]
[2020-05-12 05:42:37.402]  Step 153995  [3.265 sec/step, loss=0.09598, avg_loss=0.08890, mel_loss=0.04283, linear_loss=0.05316]
[2020-05-12 05:42:38.772]  Step 153996  [3.241 sec/step, loss=0.08566, avg_loss=0.08880, mel_loss=0.03720, linear_loss=0.04846]
[2020-05-12 05:42:42.371]  Step 153997  [3.261 sec/step, loss=0.09364, avg_loss=0.08886, mel_loss=0.04192, linear_loss=0.05172]
[2020-05-12 05:42:45.822]  Step 153998  [3.285 sec/step, loss=0.09394, avg_loss=0.08900, mel_loss=0.04185, linear_loss=0.05209]
[2020-05-12 05:42:49.524]  Step 153999  [3.281 sec/step, loss=0.09480, avg_loss=0.08901, mel_loss=0.04236, linear_loss=0.05244]
[2020-05-12 05:42:50.516]  Step 154000  [3.266 sec/step, loss=0.08112, avg_loss=0.08893, mel_loss=0.03485, linear_loss=0.04626]
[2020-05-12 05:42:50.516]  Writing summary at step: 154000
[2020-05-12 05:42:51.934]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154000
[2020-05-12 05:42:53.468]  Saving audio and alignment...
[2020-05-12 05:42:55.129]  Input: 예컨대~___________________________
[2020-05-12 05:42:56.189]  Step 154001  [3.262 sec/step, loss=0.08289, avg_loss=0.08893, mel_loss=0.03544, linear_loss=0.04746]
[2020-05-12 05:43:02.107]  Step 154002  [3.299 sec/step, loss=0.09921, avg_loss=0.08902, mel_loss=0.04536, linear_loss=0.05385]
[2020-05-12 05:43:03.923]  Step 154003  [3.262 sec/step, loss=0.08883, avg_loss=0.08893, mel_loss=0.03870, linear_loss=0.05013]
[2020-05-12 05:43:16.446]  Step 154004  [3.378 sec/step, loss=0.08436, avg_loss=0.08904, mel_loss=0.03954, linear_loss=0.04481]
[2020-05-12 05:43:19.310]  Step 154005  [3.355 sec/step, loss=0.09205, avg_loss=0.08900, mel_loss=0.04075, linear_loss=0.05130]
[2020-05-12 05:43:20.292]  Step 154006  [3.333 sec/step, loss=0.07785, avg_loss=0.08887, mel_loss=0.03294, linear_loss=0.04491]
[2020-05-12 05:43:25.767]  Step 154007  [3.342 sec/step, loss=0.09754, avg_loss=0.08889, mel_loss=0.04439, linear_loss=0.05314]
[2020-05-12 05:43:27.900]  Step 154008  [3.318 sec/step, loss=0.09090, avg_loss=0.08885, mel_loss=0.03995, linear_loss=0.05095]
[2020-05-12 05:43:36.221]  Step 154009  [3.376 sec/step, loss=0.09378, avg_loss=0.08889, mel_loss=0.04324, linear_loss=0.05054]
[2020-05-12 05:43:40.325]  Step 154010  [3.370 sec/step, loss=0.09602, avg_loss=0.08889, mel_loss=0.04317, linear_loss=0.05285]
[2020-05-12 05:43:43.683]  Step 154011  [3.390 sec/step, loss=0.09546, avg_loss=0.08900, mel_loss=0.04242, linear_loss=0.05304]
[2020-05-12 05:43:44.238]  Step 154012  [3.273 sec/step, loss=0.07022, avg_loss=0.08882, mel_loss=0.03056, linear_loss=0.03966]
[2020-05-12 05:43:46.278]  Step 154013  [3.224 sec/step, loss=0.08945, avg_loss=0.08875, mel_loss=0.03911, linear_loss=0.05034]
[2020-05-12 05:43:51.201]  Step 154014  [3.259 sec/step, loss=0.09610, avg_loss=0.08886, mel_loss=0.04354, linear_loss=0.05255]
[2020-05-12 05:43:52.527]  Step 154015  [3.267 sec/step, loss=0.08398, avg_loss=0.08901, mel_loss=0.03626, linear_loss=0.04772]
[2020-05-12 05:43:54.265]  Step 154016  [3.249 sec/step, loss=0.08682, avg_loss=0.08896, mel_loss=0.03787, linear_loss=0.04895]
[2020-05-12 05:43:55.494]  Step 154017  [3.246 sec/step, loss=0.08260, avg_loss=0.08889, mel_loss=0.03572, linear_loss=0.04688]
[2020-05-12 05:43:58.706]  Step 154018  [3.270 sec/step, loss=0.09358, avg_loss=0.08905, mel_loss=0.04130, linear_loss=0.05228]
[2020-05-12 05:44:00.802]  Step 154019  [3.247 sec/step, loss=0.08852, avg_loss=0.08898, mel_loss=0.03884, linear_loss=0.04967]
[2020-05-12 05:44:02.494]  Generated 32 batches of size 32 in 1.686 sec
[2020-05-12 05:44:05.063]  Step 154020  [3.278 sec/step, loss=0.09775, avg_loss=0.08912, mel_loss=0.04364, linear_loss=0.05411]
[2020-05-12 05:44:06.820]  Step 154021  [3.286 sec/step, loss=0.08746, avg_loss=0.08920, mel_loss=0.03823, linear_loss=0.04923]
[2020-05-12 05:44:07.552]  Step 154022  [3.267 sec/step, loss=0.07783, avg_loss=0.08907, mel_loss=0.03329, linear_loss=0.04454]
[2020-05-12 05:44:14.946]  Step 154023  [3.326 sec/step, loss=0.09680, avg_loss=0.08916, mel_loss=0.04426, linear_loss=0.05254]
[2020-05-12 05:44:17.627]  Step 154024  [3.329 sec/step, loss=0.09143, avg_loss=0.08915, mel_loss=0.04020, linear_loss=0.05122]
[2020-05-12 05:44:19.207]  Step 154025  [3.255 sec/step, loss=0.08573, avg_loss=0.08907, mel_loss=0.03722, linear_loss=0.04852]
[2020-05-12 05:44:22.836]  Step 154026  [3.261 sec/step, loss=0.09313, avg_loss=0.08905, mel_loss=0.04152, linear_loss=0.05161]
[2020-05-12 05:44:25.237]  Step 154027  [3.265 sec/step, loss=0.09056, avg_loss=0.08906, mel_loss=0.04010, linear_loss=0.05047]
[2020-05-12 05:44:30.131]  Step 154028  [3.254 sec/step, loss=0.09663, avg_loss=0.08906, mel_loss=0.04356, linear_loss=0.05308]
[2020-05-12 05:44:34.094]  Step 154029  [3.284 sec/step, loss=0.09500, avg_loss=0.08926, mel_loss=0.04259, linear_loss=0.05241]
[2020-05-12 05:44:40.656]  Step 154030  [3.338 sec/step, loss=0.09897, avg_loss=0.08942, mel_loss=0.04545, linear_loss=0.05351]
[2020-05-12 05:44:41.800]  Step 154031  [3.327 sec/step, loss=0.08536, avg_loss=0.08936, mel_loss=0.03643, linear_loss=0.04893]
[2020-05-12 05:44:46.532]  Step 154032  [3.298 sec/step, loss=0.09733, avg_loss=0.08937, mel_loss=0.04382, linear_loss=0.05351]
[2020-05-12 05:44:47.097]  Step 154033  [3.251 sec/step, loss=0.06898, avg_loss=0.08910, mel_loss=0.03008, linear_loss=0.03890]
[2020-05-12 05:44:48.137]  Step 154034  [3.244 sec/step, loss=0.08050, avg_loss=0.08900, mel_loss=0.03465, linear_loss=0.04584]
[2020-05-12 05:44:53.848]  Step 154035  [3.267 sec/step, loss=0.09459, avg_loss=0.08899, mel_loss=0.04294, linear_loss=0.05165]
[2020-05-12 05:44:54.564]  Step 154036  [3.256 sec/step, loss=0.07129, avg_loss=0.08881, mel_loss=0.03091, linear_loss=0.04039]
[2020-05-12 05:44:57.207]  Step 154037  [3.263 sec/step, loss=0.09252, avg_loss=0.08882, mel_loss=0.04115, linear_loss=0.05136]
[2020-05-12 05:45:00.160]  Step 154038  [3.239 sec/step, loss=0.09400, avg_loss=0.08881, mel_loss=0.04174, linear_loss=0.05226]
[2020-05-12 05:45:01.518]  Step 154039  [3.247 sec/step, loss=0.08571, avg_loss=0.08889, mel_loss=0.03726, linear_loss=0.04845]
[2020-05-12 05:45:03.074]  Step 154040  [3.250 sec/step, loss=0.08877, avg_loss=0.08898, mel_loss=0.03901, linear_loss=0.04976]
[2020-05-12 05:45:05.065]  Step 154041  [3.263 sec/step, loss=0.08887, avg_loss=0.08911, mel_loss=0.03894, linear_loss=0.04993]
[2020-05-12 05:45:08.262]  Step 154042  [3.281 sec/step, loss=0.09653, avg_loss=0.08922, mel_loss=0.04320, linear_loss=0.05333]
[2020-05-12 05:45:11.886]  Step 154043  [3.308 sec/step, loss=0.09667, avg_loss=0.08937, mel_loss=0.04327, linear_loss=0.05340]
[2020-05-12 05:45:17.154]  Step 154044  [3.342 sec/step, loss=0.09657, avg_loss=0.08946, mel_loss=0.04383, linear_loss=0.05274]
[2020-05-12 05:45:20.627]  Step 154045  [3.361 sec/step, loss=0.09430, avg_loss=0.08953, mel_loss=0.04239, linear_loss=0.05191]
[2020-05-12 05:45:28.277]  Step 154046  [3.416 sec/step, loss=0.09917, avg_loss=0.08961, mel_loss=0.04558, linear_loss=0.05359]
[2020-05-12 05:45:32.609]  Step 154047  [3.372 sec/step, loss=0.09489, avg_loss=0.08960, mel_loss=0.04263, linear_loss=0.05226]
[2020-05-12 05:45:35.286]  Step 154048  [3.351 sec/step, loss=0.09025, avg_loss=0.08954, mel_loss=0.03965, linear_loss=0.05060]
[2020-05-12 05:45:44.217]  Step 154049  [3.401 sec/step, loss=0.09578, avg_loss=0.08955, mel_loss=0.04436, linear_loss=0.05143]
[2020-05-12 05:45:45.138]  Step 154050  [3.401 sec/step, loss=0.08203, avg_loss=0.08954, mel_loss=0.03509, linear_loss=0.04694]
[2020-05-12 05:45:45.138]  Writing summary at step: 154050
[2020-05-12 05:45:46.966]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154050
[2020-05-12 05:45:48.522]  Saving audio and alignment...
[2020-05-12 05:45:50.775]  Generated 32 batches of size 32 in 1.654 sec
[2020-05-12 05:46:05.313]  Input: 삼성전자에는 그보다 더 많은 지원자들이 몰리지만 아무도 그걸 비효율적이라고 하지는 않지 않습니까 라고 했더니 면접관님이~___________________________________________
[2020-05-12 05:46:08.601]  Step 154051  [3.397 sec/step, loss=0.09565, avg_loss=0.08954, mel_loss=0.04287, linear_loss=0.05279]
[2020-05-12 05:46:10.038]  Step 154052  [3.335 sec/step, loss=0.08475, avg_loss=0.08942, mel_loss=0.03676, linear_loss=0.04799]
[2020-05-12 05:46:11.755]  Step 154053  [3.328 sec/step, loss=0.08878, avg_loss=0.08938, mel_loss=0.03848, linear_loss=0.05029]
[2020-05-12 05:46:13.968]  Step 154054  [3.324 sec/step, loss=0.09097, avg_loss=0.08937, mel_loss=0.04033, linear_loss=0.05065]
[2020-05-12 05:46:16.423]  Step 154055  [3.290 sec/step, loss=0.09142, avg_loss=0.08932, mel_loss=0.04011, linear_loss=0.05131]
[2020-05-12 05:46:17.267]  Step 154056  [3.291 sec/step, loss=0.07771, avg_loss=0.08931, mel_loss=0.03321, linear_loss=0.04450]
[2020-05-12 05:46:18.463]  Step 154057  [3.290 sec/step, loss=0.08591, avg_loss=0.08932, mel_loss=0.03722, linear_loss=0.04869]
[2020-05-12 05:46:20.585]  Step 154058  [3.292 sec/step, loss=0.09033, avg_loss=0.08933, mel_loss=0.03984, linear_loss=0.05048]
[2020-05-12 05:46:27.321]  Step 154059  [3.328 sec/step, loss=0.09653, avg_loss=0.08934, mel_loss=0.04405, linear_loss=0.05248]
[2020-05-12 05:46:29.747]  Step 154060  [3.319 sec/step, loss=0.09005, avg_loss=0.08930, mel_loss=0.03974, linear_loss=0.05032]
[2020-05-12 05:46:31.396]  Step 154061  [3.300 sec/step, loss=0.08638, avg_loss=0.08922, mel_loss=0.03750, linear_loss=0.04888]
[2020-05-12 05:46:34.073]  Step 154062  [3.316 sec/step, loss=0.08996, avg_loss=0.08929, mel_loss=0.03982, linear_loss=0.05014]
[2020-05-12 05:46:34.841]  Step 154063  [3.307 sec/step, loss=0.07538, avg_loss=0.08917, mel_loss=0.03252, linear_loss=0.04286]
[2020-05-12 05:46:40.070]  Step 154064  [3.217 sec/step, loss=0.09399, avg_loss=0.08934, mel_loss=0.04256, linear_loss=0.05143]
[2020-05-12 05:46:42.294]  Step 154065  [3.217 sec/step, loss=0.08870, avg_loss=0.08932, mel_loss=0.03900, linear_loss=0.04970]
[2020-05-12 05:46:44.102]  Step 154066  [3.206 sec/step, loss=0.08705, avg_loss=0.08927, mel_loss=0.03796, linear_loss=0.04910]
[2020-05-12 05:46:46.641]  Step 154067  [3.215 sec/step, loss=0.09025, avg_loss=0.08930, mel_loss=0.03969, linear_loss=0.05056]
[2020-05-12 05:46:48.755]  Step 154068  [3.199 sec/step, loss=0.08833, avg_loss=0.08923, mel_loss=0.03873, linear_loss=0.04961]
[2020-05-12 05:46:51.895]  Step 154069  [3.219 sec/step, loss=0.09430, avg_loss=0.08934, mel_loss=0.04187, linear_loss=0.05243]
[2020-05-12 05:46:53.303]  Step 154070  [3.224 sec/step, loss=0.08498, avg_loss=0.08948, mel_loss=0.03661, linear_loss=0.04836]
[2020-05-12 05:46:54.728]  Step 154071  [3.222 sec/step, loss=0.08555, avg_loss=0.08945, mel_loss=0.03726, linear_loss=0.04829]
[2020-05-12 05:46:55.969]  Step 154072  [3.090 sec/step, loss=0.08300, avg_loss=0.08951, mel_loss=0.03598, linear_loss=0.04702]
[2020-05-12 05:46:57.908]  Step 154073  [3.090 sec/step, loss=0.09049, avg_loss=0.08952, mel_loss=0.03958, linear_loss=0.05090]
[2020-05-12 05:47:06.806]  Step 154074  [3.148 sec/step, loss=0.09460, avg_loss=0.08953, mel_loss=0.04347, linear_loss=0.05113]
[2020-05-12 05:47:10.503]  Step 154075  [3.174 sec/step, loss=0.09616, avg_loss=0.08971, mel_loss=0.04305, linear_loss=0.05310]
[2020-05-12 05:47:11.623]  Step 154076  [3.155 sec/step, loss=0.08271, avg_loss=0.08959, mel_loss=0.03555, linear_loss=0.04716]
[2020-05-12 05:47:18.836]  Step 154077  [3.203 sec/step, loss=0.09669, avg_loss=0.08965, mel_loss=0.04432, linear_loss=0.05237]
[2020-05-12 05:47:19.367]  Step 154078  [3.197 sec/step, loss=0.06859, avg_loss=0.08953, mel_loss=0.03009, linear_loss=0.03850]
[2020-05-12 05:47:34.135]  Step 154079  [3.337 sec/step, loss=0.07446, avg_loss=0.08948, mel_loss=0.03529, linear_loss=0.03917]
[2020-05-12 05:47:36.787]  Step 154080  [3.300 sec/step, loss=0.08916, avg_loss=0.08941, mel_loss=0.03893, linear_loss=0.05023]
[2020-05-12 05:47:44.122]  Step 154081  [3.326 sec/step, loss=0.09537, avg_loss=0.08941, mel_loss=0.04302, linear_loss=0.05236]
[2020-05-12 05:47:45.751]  Step 154082  [3.253 sec/step, loss=0.08036, avg_loss=0.08925, mel_loss=0.03468, linear_loss=0.04569]
[2020-05-12 05:47:46.981]  Generated 32 batches of size 32 in 2.849 sec
[2020-05-12 05:47:50.421]  Step 154083  [3.277 sec/step, loss=0.09594, avg_loss=0.08931, mel_loss=0.04315, linear_loss=0.05279]
[2020-05-12 05:47:53.462]  Step 154084  [3.281 sec/step, loss=0.09527, avg_loss=0.08933, mel_loss=0.04234, linear_loss=0.05292]
[2020-05-12 05:47:59.355]  Step 154085  [3.319 sec/step, loss=0.09670, avg_loss=0.08940, mel_loss=0.04401, linear_loss=0.05269]
[2020-05-12 05:48:00.163]  Step 154086  [3.322 sec/step, loss=0.07866, avg_loss=0.08950, mel_loss=0.03372, linear_loss=0.04494]
[2020-05-12 05:48:03.754]  Step 154087  [3.301 sec/step, loss=0.09300, avg_loss=0.08946, mel_loss=0.04167, linear_loss=0.05133]
[2020-05-12 05:48:07.937]  Step 154088  [3.292 sec/step, loss=0.09552, avg_loss=0.08945, mel_loss=0.04273, linear_loss=0.05279]
[2020-05-12 05:48:08.961]  Step 154089  [3.291 sec/step, loss=0.07707, avg_loss=0.08940, mel_loss=0.03259, linear_loss=0.04448]
[2020-05-12 05:48:12.504]  Step 154090  [3.250 sec/step, loss=0.09435, avg_loss=0.08936, mel_loss=0.04207, linear_loss=0.05227]
[2020-05-12 05:48:13.977]  Step 154091  [3.237 sec/step, loss=0.08447, avg_loss=0.08928, mel_loss=0.03688, linear_loss=0.04759]
[2020-05-12 05:48:15.156]  Step 154092  [3.206 sec/step, loss=0.08396, avg_loss=0.08917, mel_loss=0.03639, linear_loss=0.04756]
[2020-05-12 05:48:16.485]  Step 154093  [3.204 sec/step, loss=0.08463, avg_loss=0.08917, mel_loss=0.03684, linear_loss=0.04779]
[2020-05-12 05:48:18.298]  Step 154094  [3.203 sec/step, loss=0.08775, avg_loss=0.08917, mel_loss=0.03800, linear_loss=0.04974]
[2020-05-12 05:48:19.061]  Step 154095  [3.168 sec/step, loss=0.07529, avg_loss=0.08896, mel_loss=0.03354, linear_loss=0.04174]
[2020-05-12 05:48:28.249]  Step 154096  [3.247 sec/step, loss=0.09682, avg_loss=0.08907, mel_loss=0.04470, linear_loss=0.05212]
[2020-05-12 05:48:35.868]  Step 154097  [3.287 sec/step, loss=0.09849, avg_loss=0.08912, mel_loss=0.04534, linear_loss=0.05316]
[2020-05-12 05:48:38.338]  Step 154098  [3.277 sec/step, loss=0.08992, avg_loss=0.08908, mel_loss=0.03966, linear_loss=0.05027]
[2020-05-12 05:48:43.720]  Step 154099  [3.294 sec/step, loss=0.09730, avg_loss=0.08910, mel_loss=0.04422, linear_loss=0.05308]
[2020-05-12 05:48:47.435]  Step 154100  [3.321 sec/step, loss=0.09560, avg_loss=0.08925, mel_loss=0.04275, linear_loss=0.05285]
[2020-05-12 05:48:47.435]  Writing summary at step: 154100
[2020-05-12 05:48:48.991]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154100
[2020-05-12 05:48:50.521]  Saving audio and alignment...
[2020-05-12 05:48:52.852]  Input: 뭐 뭐라고 밝혔습니다~_____
[2020-05-12 05:48:57.347]  Step 154101  [3.355 sec/step, loss=0.09920, avg_loss=0.08941, mel_loss=0.04505, linear_loss=0.05415]
[2020-05-12 05:48:58.365]  Step 154102  [3.306 sec/step, loss=0.08007, avg_loss=0.08922, mel_loss=0.03443, linear_loss=0.04564]
[2020-05-12 05:49:04.892]  Step 154103  [3.354 sec/step, loss=0.09651, avg_loss=0.08930, mel_loss=0.04412, linear_loss=0.05238]
[2020-05-12 05:49:06.006]  Step 154104  [3.239 sec/step, loss=0.07962, avg_loss=0.08925, mel_loss=0.03434, linear_loss=0.04528]
[2020-05-12 05:49:09.107]  Step 154105  [3.242 sec/step, loss=0.09507, avg_loss=0.08928, mel_loss=0.04239, linear_loss=0.05268]
[2020-05-12 05:49:12.011]  Step 154106  [3.261 sec/step, loss=0.08992, avg_loss=0.08940, mel_loss=0.03958, linear_loss=0.05034]
[2020-05-12 05:49:15.658]  Step 154107  [3.243 sec/step, loss=0.09311, avg_loss=0.08936, mel_loss=0.04164, linear_loss=0.05147]
[2020-05-12 05:49:17.897]  Step 154108  [3.244 sec/step, loss=0.09050, avg_loss=0.08935, mel_loss=0.03970, linear_loss=0.05081]
[2020-05-12 05:49:23.658]  Step 154109  [3.218 sec/step, loss=0.09684, avg_loss=0.08938, mel_loss=0.04398, linear_loss=0.05286]
[2020-05-12 05:49:28.043]  Step 154110  [3.221 sec/step, loss=0.09444, avg_loss=0.08937, mel_loss=0.04206, linear_loss=0.05238]
[2020-05-12 05:49:28.854]  Step 154111  [3.196 sec/step, loss=0.07391, avg_loss=0.08915, mel_loss=0.03187, linear_loss=0.04204]
[2020-05-12 05:49:30.834]  Generated 32 batches of size 32 in 1.973 sec
[2020-05-12 05:49:31.685]  Step 154112  [3.218 sec/step, loss=0.09310, avg_loss=0.08938, mel_loss=0.04147, linear_loss=0.05162]
[2020-05-12 05:49:33.384]  Step 154113  [3.215 sec/step, loss=0.08664, avg_loss=0.08935, mel_loss=0.03799, linear_loss=0.04865]
[2020-05-12 05:49:35.485]  Step 154114  [3.187 sec/step, loss=0.08974, avg_loss=0.08929, mel_loss=0.03944, linear_loss=0.05030]
[2020-05-12 05:49:38.898]  Step 154115  [3.208 sec/step, loss=0.09479, avg_loss=0.08940, mel_loss=0.04221, linear_loss=0.05258]
[2020-05-12 05:49:40.881]  Step 154116  [3.210 sec/step, loss=0.08877, avg_loss=0.08942, mel_loss=0.03898, linear_loss=0.04978]
[2020-05-12 05:49:41.711]  Step 154117  [3.206 sec/step, loss=0.07827, avg_loss=0.08937, mel_loss=0.03355, linear_loss=0.04472]
[2020-05-12 05:49:46.632]  Step 154118  [3.223 sec/step, loss=0.09558, avg_loss=0.08939, mel_loss=0.04291, linear_loss=0.05268]
[2020-05-12 05:50:00.033]  Step 154119  [3.336 sec/step, loss=0.08174, avg_loss=0.08932, mel_loss=0.03828, linear_loss=0.04346]
[2020-05-12 05:50:03.147]  Step 154120  [3.325 sec/step, loss=0.09467, avg_loss=0.08929, mel_loss=0.04230, linear_loss=0.05236]
[2020-05-12 05:50:04.186]  Step 154121  [3.317 sec/step, loss=0.07991, avg_loss=0.08922, mel_loss=0.03448, linear_loss=0.04543]
[2020-05-12 05:50:05.613]  Step 154122  [3.324 sec/step, loss=0.08596, avg_loss=0.08930, mel_loss=0.03741, linear_loss=0.04854]
[2020-05-12 05:50:09.793]  Step 154123  [3.292 sec/step, loss=0.09501, avg_loss=0.08928, mel_loss=0.04273, linear_loss=0.05228]
[2020-05-12 05:50:11.979]  Step 154124  [3.287 sec/step, loss=0.09057, avg_loss=0.08927, mel_loss=0.03991, linear_loss=0.05066]
[2020-05-12 05:50:13.215]  Step 154125  [3.284 sec/step, loss=0.08378, avg_loss=0.08925, mel_loss=0.03616, linear_loss=0.04762]
[2020-05-12 05:50:13.793]  Step 154126  [3.253 sec/step, loss=0.07027, avg_loss=0.08903, mel_loss=0.03106, linear_loss=0.03920]
[2020-05-12 05:50:14.527]  Step 154127  [3.237 sec/step, loss=0.07581, avg_loss=0.08888, mel_loss=0.03266, linear_loss=0.04315]
[2020-05-12 05:50:16.313]  Step 154128  [3.206 sec/step, loss=0.08902, avg_loss=0.08880, mel_loss=0.03880, linear_loss=0.05022]
[2020-05-12 05:50:17.948]  Step 154129  [3.182 sec/step, loss=0.08975, avg_loss=0.08875, mel_loss=0.03902, linear_loss=0.05073]
[2020-05-12 05:50:19.983]  Step 154130  [3.137 sec/step, loss=0.09054, avg_loss=0.08866, mel_loss=0.03989, linear_loss=0.05065]
[2020-05-12 05:50:23.995]  Step 154131  [3.166 sec/step, loss=0.09525, avg_loss=0.08876, mel_loss=0.04261, linear_loss=0.05265]
[2020-05-12 05:50:27.130]  Step 154132  [3.150 sec/step, loss=0.09431, avg_loss=0.08873, mel_loss=0.04185, linear_loss=0.05246]
[2020-05-12 05:50:30.553]  Step 154133  [3.178 sec/step, loss=0.09446, avg_loss=0.08899, mel_loss=0.04231, linear_loss=0.05215]
[2020-05-12 05:50:32.991]  Step 154134  [3.192 sec/step, loss=0.09212, avg_loss=0.08910, mel_loss=0.04042, linear_loss=0.05170]
[2020-05-12 05:50:35.171]  Step 154135  [3.157 sec/step, loss=0.09009, avg_loss=0.08906, mel_loss=0.03995, linear_loss=0.05015]
[2020-05-12 05:50:37.884]  Step 154136  [3.177 sec/step, loss=0.09265, avg_loss=0.08927, mel_loss=0.04086, linear_loss=0.05179]
[2020-05-12 05:50:40.774]  Step 154137  [3.179 sec/step, loss=0.09337, avg_loss=0.08928, mel_loss=0.04159, linear_loss=0.05177]
[2020-05-12 05:50:41.521]  Step 154138  [3.157 sec/step, loss=0.07935, avg_loss=0.08914, mel_loss=0.03420, linear_loss=0.04515]
[2020-05-12 05:50:42.427]  Step 154139  [3.153 sec/step, loss=0.08004, avg_loss=0.08908, mel_loss=0.03428, linear_loss=0.04577]
[2020-05-12 05:50:44.288]  Step 154140  [3.156 sec/step, loss=0.08769, avg_loss=0.08907, mel_loss=0.03841, linear_loss=0.04928]
[2020-05-12 05:50:58.751]  Step 154141  [3.281 sec/step, loss=0.07771, avg_loss=0.08896, mel_loss=0.03672, linear_loss=0.04099]
[2020-05-12 05:51:07.307]  Step 154142  [3.334 sec/step, loss=0.09606, avg_loss=0.08895, mel_loss=0.04446, linear_loss=0.05159]
[2020-05-12 05:51:12.449]  Step 154143  [3.349 sec/step, loss=0.09524, avg_loss=0.08894, mel_loss=0.04324, linear_loss=0.05200]
[2020-05-12 05:51:13.903]  Step 154144  [3.311 sec/step, loss=0.08486, avg_loss=0.08882, mel_loss=0.03665, linear_loss=0.04822]
[2020-05-12 05:51:14.342]  Generated 32 batches of size 32 in 1.887 sec
[2020-05-12 05:51:18.485]  Step 154145  [3.322 sec/step, loss=0.09637, avg_loss=0.08884, mel_loss=0.04350, linear_loss=0.05287]
[2020-05-12 05:51:21.730]  Step 154146  [3.278 sec/step, loss=0.09553, avg_loss=0.08880, mel_loss=0.04259, linear_loss=0.05294]
[2020-05-12 05:51:29.394]  Step 154147  [3.312 sec/step, loss=0.09578, avg_loss=0.08881, mel_loss=0.04409, linear_loss=0.05169]
[2020-05-12 05:51:36.114]  Step 154148  [3.352 sec/step, loss=0.09789, avg_loss=0.08889, mel_loss=0.04482, linear_loss=0.05307]
[2020-05-12 05:51:39.788]  Step 154149  [3.300 sec/step, loss=0.09632, avg_loss=0.08890, mel_loss=0.04322, linear_loss=0.05311]
[2020-05-12 05:51:40.927]  Step 154150  [3.302 sec/step, loss=0.08235, avg_loss=0.08890, mel_loss=0.03564, linear_loss=0.04671]
[2020-05-12 05:51:40.927]  Writing summary at step: 154150
[2020-05-12 05:51:42.538]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154150
[2020-05-12 05:51:44.030]  Saving audio and alignment...
[2020-05-12 05:51:52.172]  Input: 자 목소리가 가장 중요한 역할을 하는 것 중 하나가 바로 콜센터일텐데요~_____________________________
[2020-05-12 05:51:54.220]  Step 154151  [3.289 sec/step, loss=0.08902, avg_loss=0.08883, mel_loss=0.03898, linear_loss=0.05003]
[2020-05-12 05:51:59.036]  Step 154152  [3.323 sec/step, loss=0.09540, avg_loss=0.08894, mel_loss=0.04300, linear_loss=0.05240]
[2020-05-12 05:52:05.651]  Step 154153  [3.372 sec/step, loss=0.09705, avg_loss=0.08902, mel_loss=0.04422, linear_loss=0.05283]
[2020-05-12 05:52:07.574]  Step 154154  [3.369 sec/step, loss=0.08825, avg_loss=0.08899, mel_loss=0.03840, linear_loss=0.04985]
[2020-05-12 05:52:20.768]  Step 154155  [3.477 sec/step, loss=0.07836, avg_loss=0.08886, mel_loss=0.03682, linear_loss=0.04154]
[2020-05-12 05:52:21.832]  Step 154156  [3.479 sec/step, loss=0.07499, avg_loss=0.08884, mel_loss=0.03209, linear_loss=0.04290]
[2020-05-12 05:52:25.585]  Step 154157  [3.504 sec/step, loss=0.09648, avg_loss=0.08894, mel_loss=0.04307, linear_loss=0.05341]
[2020-05-12 05:52:28.128]  Step 154158  [3.509 sec/step, loss=0.08959, avg_loss=0.08893, mel_loss=0.03944, linear_loss=0.05015]
[2020-05-12 05:52:29.623]  Step 154159  [3.456 sec/step, loss=0.08700, avg_loss=0.08884, mel_loss=0.03813, linear_loss=0.04887]
[2020-05-12 05:52:30.859]  Step 154160  [3.444 sec/step, loss=0.08180, avg_loss=0.08876, mel_loss=0.03526, linear_loss=0.04653]
[2020-05-12 05:52:31.891]  Step 154161  [3.438 sec/step, loss=0.08181, avg_loss=0.08871, mel_loss=0.03520, linear_loss=0.04662]
[2020-05-12 05:52:36.068]  Step 154162  [3.453 sec/step, loss=0.09491, avg_loss=0.08876, mel_loss=0.04275, linear_loss=0.05217]
[2020-05-12 05:52:36.917]  Step 154163  [3.454 sec/step, loss=0.07638, avg_loss=0.08877, mel_loss=0.03328, linear_loss=0.04310]
[2020-05-12 05:52:39.681]  Step 154164  [3.429 sec/step, loss=0.09166, avg_loss=0.08875, mel_loss=0.04044, linear_loss=0.05122]
[2020-05-12 05:52:42.681]  Step 154165  [3.437 sec/step, loss=0.09204, avg_loss=0.08878, mel_loss=0.04058, linear_loss=0.05146]
[2020-05-12 05:52:48.680]  Step 154166  [3.479 sec/step, loss=0.09794, avg_loss=0.08889, mel_loss=0.04470, linear_loss=0.05324]
[2020-05-12 05:52:50.115]  Step 154167  [3.468 sec/step, loss=0.08478, avg_loss=0.08883, mel_loss=0.03686, linear_loss=0.04791]
[2020-05-12 05:52:53.585]  Step 154168  [3.481 sec/step, loss=0.09308, avg_loss=0.08888, mel_loss=0.04159, linear_loss=0.05148]
[2020-05-12 05:52:56.941]  Step 154169  [3.484 sec/step, loss=0.09499, avg_loss=0.08889, mel_loss=0.04216, linear_loss=0.05282]
[2020-05-12 05:52:57.768]  Step 154170  [3.478 sec/step, loss=0.07574, avg_loss=0.08880, mel_loss=0.03269, linear_loss=0.04305]
[2020-05-12 05:53:01.008]  Step 154171  [3.496 sec/step, loss=0.09467, avg_loss=0.08889, mel_loss=0.04221, linear_loss=0.05246]
[2020-05-12 05:53:05.162]  Step 154172  [3.525 sec/step, loss=0.09569, avg_loss=0.08901, mel_loss=0.04287, linear_loss=0.05282]
[2020-05-12 05:53:12.649]  Step 154173  [3.581 sec/step, loss=0.09895, avg_loss=0.08910, mel_loss=0.04535, linear_loss=0.05360]
[2020-05-12 05:53:14.501]  Generated 32 batches of size 32 in 1.846 sec
[2020-05-12 05:53:14.555]  Step 154174  [3.511 sec/step, loss=0.08725, avg_loss=0.08903, mel_loss=0.03789, linear_loss=0.04936]
[2020-05-12 05:53:16.952]  Step 154175  [3.498 sec/step, loss=0.09184, avg_loss=0.08898, mel_loss=0.04054, linear_loss=0.05130]
[2020-05-12 05:53:19.117]  Step 154176  [3.508 sec/step, loss=0.09066, avg_loss=0.08906, mel_loss=0.03987, linear_loss=0.05079]
[2020-05-12 05:53:19.646]  Step 154177  [3.441 sec/step, loss=0.06921, avg_loss=0.08879, mel_loss=0.03032, linear_loss=0.03889]
[2020-05-12 05:53:21.321]  Step 154178  [3.453 sec/step, loss=0.08954, avg_loss=0.08900, mel_loss=0.03928, linear_loss=0.05026]
[2020-05-12 05:53:22.441]  Step 154179  [3.316 sec/step, loss=0.08413, avg_loss=0.08909, mel_loss=0.03631, linear_loss=0.04783]
[2020-05-12 05:53:30.685]  Step 154180  [3.372 sec/step, loss=0.09499, avg_loss=0.08915, mel_loss=0.04376, linear_loss=0.05123]
[2020-05-12 05:53:32.061]  Step 154181  [3.313 sec/step, loss=0.08665, avg_loss=0.08906, mel_loss=0.03773, linear_loss=0.04892]
[2020-05-12 05:53:37.496]  Step 154182  [3.351 sec/step, loss=0.09713, avg_loss=0.08923, mel_loss=0.04391, linear_loss=0.05322]
[2020-05-12 05:53:41.054]  Step 154183  [3.339 sec/step, loss=0.09459, avg_loss=0.08922, mel_loss=0.04228, linear_loss=0.05231]
[2020-05-12 05:53:44.709]  Step 154184  [3.346 sec/step, loss=0.09576, avg_loss=0.08922, mel_loss=0.04282, linear_loss=0.05294]
[2020-05-12 05:53:45.918]  Step 154185  [3.299 sec/step, loss=0.08512, avg_loss=0.08911, mel_loss=0.03674, linear_loss=0.04837]
[2020-05-12 05:53:47.290]  Step 154186  [3.304 sec/step, loss=0.08448, avg_loss=0.08917, mel_loss=0.03664, linear_loss=0.04784]
[2020-05-12 05:53:50.710]  Step 154187  [3.303 sec/step, loss=0.09549, avg_loss=0.08919, mel_loss=0.04271, linear_loss=0.05277]
[2020-05-12 05:53:57.080]  Step 154188  [3.325 sec/step, loss=0.09431, avg_loss=0.08918, mel_loss=0.04323, linear_loss=0.05108]
[2020-05-12 05:53:58.742]  Step 154189  [3.331 sec/step, loss=0.09000, avg_loss=0.08931, mel_loss=0.03930, linear_loss=0.05069]
[2020-05-12 05:54:00.145]  Step 154190  [3.310 sec/step, loss=0.08669, avg_loss=0.08923, mel_loss=0.03796, linear_loss=0.04873]
[2020-05-12 05:54:00.978]  Step 154191  [3.303 sec/step, loss=0.07207, avg_loss=0.08911, mel_loss=0.03090, linear_loss=0.04117]
[2020-05-12 05:54:05.597]  Step 154192  [3.338 sec/step, loss=0.09722, avg_loss=0.08924, mel_loss=0.04376, linear_loss=0.05347]
[2020-05-12 05:54:08.494]  Step 154193  [3.353 sec/step, loss=0.09339, avg_loss=0.08933, mel_loss=0.04165, linear_loss=0.05174]
[2020-05-12 05:54:10.924]  Step 154194  [3.359 sec/step, loss=0.09251, avg_loss=0.08938, mel_loss=0.04076, linear_loss=0.05175]
[2020-05-12 05:54:12.960]  Step 154195  [3.372 sec/step, loss=0.08916, avg_loss=0.08951, mel_loss=0.03919, linear_loss=0.04997]
[2020-05-12 05:54:14.124]  Step 154196  [3.292 sec/step, loss=0.08126, avg_loss=0.08936, mel_loss=0.03486, linear_loss=0.04640]
[2020-05-12 05:54:14.719]  Step 154197  [3.222 sec/step, loss=0.07005, avg_loss=0.08907, mel_loss=0.03094, linear_loss=0.03912]
[2020-05-12 05:54:15.603]  Step 154198  [3.206 sec/step, loss=0.07669, avg_loss=0.08894, mel_loss=0.03301, linear_loss=0.04368]
[2020-05-12 05:54:17.984]  Step 154199  [3.176 sec/step, loss=0.09061, avg_loss=0.08888, mel_loss=0.03994, linear_loss=0.05067]
[2020-05-12 05:54:20.339]  Step 154200  [3.162 sec/step, loss=0.09030, avg_loss=0.08882, mel_loss=0.03992, linear_loss=0.05038]
[2020-05-12 05:54:20.339]  Writing summary at step: 154200
[2020-05-12 05:54:23.143]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154200
[2020-05-12 05:54:24.679]  Saving audio and alignment...
[2020-05-12 05:54:35.030]  Input: 어 저도 이제 온라인 강의 좀 들어보려고 하는데 저처럼 이렇게 제주도 같은 지역에서 지방에서도 많이 들으시나요~________
[2020-05-12 05:54:36.949]  Step 154201  [3.136 sec/step, loss=0.08901, avg_loss=0.08872, mel_loss=0.03899, linear_loss=0.05002]
[2020-05-12 05:54:42.545]  Step 154202  [3.182 sec/step, loss=0.09587, avg_loss=0.08888, mel_loss=0.04351, linear_loss=0.05236]
[2020-05-12 05:54:56.784]  Step 154203  [3.259 sec/step, loss=0.07675, avg_loss=0.08868, mel_loss=0.03636, linear_loss=0.04039]
[2020-05-12 05:54:58.690]  Generated 32 batches of size 32 in 1.899 sec
[2020-05-12 05:54:58.714]  Step 154204  [3.267 sec/step, loss=0.08877, avg_loss=0.08877, mel_loss=0.03867, linear_loss=0.05011]
[2020-05-12 05:55:03.152]  Step 154205  [3.281 sec/step, loss=0.09468, avg_loss=0.08877, mel_loss=0.04265, linear_loss=0.05204]
[2020-05-12 05:55:12.205]  Step 154206  [3.342 sec/step, loss=0.09692, avg_loss=0.08884, mel_loss=0.04489, linear_loss=0.05203]
[2020-05-12 05:55:17.204]  Step 154207  [3.356 sec/step, loss=0.09609, avg_loss=0.08887, mel_loss=0.04351, linear_loss=0.05258]
[2020-05-12 05:55:18.168]  Step 154208  [3.343 sec/step, loss=0.08379, avg_loss=0.08880, mel_loss=0.03614, linear_loss=0.04764]
[2020-05-12 05:55:22.269]  Step 154209  [3.326 sec/step, loss=0.09537, avg_loss=0.08879, mel_loss=0.04274, linear_loss=0.05263]
[2020-05-12 05:55:25.278]  Step 154210  [3.313 sec/step, loss=0.09511, avg_loss=0.08879, mel_loss=0.04232, linear_loss=0.05279]
[2020-05-12 05:55:26.190]  Step 154211  [3.314 sec/step, loss=0.07774, avg_loss=0.08883, mel_loss=0.03352, linear_loss=0.04422]
[2020-05-12 05:55:27.782]  Step 154212  [3.301 sec/step, loss=0.08782, avg_loss=0.08878, mel_loss=0.03842, linear_loss=0.04940]
[2020-05-12 05:55:30.954]  Step 154213  [3.316 sec/step, loss=0.09530, avg_loss=0.08886, mel_loss=0.04268, linear_loss=0.05262]
[2020-05-12 05:55:34.576]  Step 154214  [3.331 sec/step, loss=0.09747, avg_loss=0.08894, mel_loss=0.04377, linear_loss=0.05370]
[2020-05-12 05:55:36.215]  Step 154215  [3.314 sec/step, loss=0.08582, avg_loss=0.08885, mel_loss=0.03751, linear_loss=0.04831]
[2020-05-12 05:55:43.882]  Step 154216  [3.370 sec/step, loss=0.09778, avg_loss=0.08894, mel_loss=0.04505, linear_loss=0.05273]
[2020-05-12 05:55:49.528]  Step 154217  [3.419 sec/step, loss=0.09661, avg_loss=0.08913, mel_loss=0.04395, linear_loss=0.05266]
[2020-05-12 05:55:54.244]  Step 154218  [3.417 sec/step, loss=0.09508, avg_loss=0.08912, mel_loss=0.04282, linear_loss=0.05226]
[2020-05-12 05:55:56.305]  Step 154219  [3.303 sec/step, loss=0.08964, avg_loss=0.08920, mel_loss=0.03945, linear_loss=0.05019]
[2020-05-12 05:55:58.072]  Step 154220  [3.290 sec/step, loss=0.08993, avg_loss=0.08915, mel_loss=0.03895, linear_loss=0.05097]
[2020-05-12 05:56:01.462]  Step 154221  [3.313 sec/step, loss=0.09324, avg_loss=0.08929, mel_loss=0.04167, linear_loss=0.05157]
[2020-05-12 05:56:03.563]  Step 154222  [3.320 sec/step, loss=0.09020, avg_loss=0.08933, mel_loss=0.03980, linear_loss=0.05040]
[2020-05-12 05:56:06.527]  Step 154223  [3.308 sec/step, loss=0.09365, avg_loss=0.08931, mel_loss=0.04165, linear_loss=0.05201]
[2020-05-12 05:56:08.406]  Step 154224  [3.305 sec/step, loss=0.08939, avg_loss=0.08930, mel_loss=0.03909, linear_loss=0.05030]
[2020-05-12 05:56:10.788]  Step 154225  [3.316 sec/step, loss=0.09079, avg_loss=0.08937, mel_loss=0.04003, linear_loss=0.05076]
[2020-05-12 05:56:17.282]  Step 154226  [3.375 sec/step, loss=0.09428, avg_loss=0.08961, mel_loss=0.04316, linear_loss=0.05112]
[2020-05-12 05:56:22.471]  Step 154227  [3.420 sec/step, loss=0.09523, avg_loss=0.08981, mel_loss=0.04319, linear_loss=0.05205]
[2020-05-12 05:56:23.285]  Step 154228  [3.410 sec/step, loss=0.07524, avg_loss=0.08967, mel_loss=0.03205, linear_loss=0.04319]
[2020-05-12 05:56:31.803]  Step 154229  [3.479 sec/step, loss=0.09429, avg_loss=0.08972, mel_loss=0.04360, linear_loss=0.05068]
[2020-05-12 05:56:33.030]  Step 154230  [3.471 sec/step, loss=0.08421, avg_loss=0.08965, mel_loss=0.03660, linear_loss=0.04761]
[2020-05-12 05:56:37.127]  Step 154231  [3.472 sec/step, loss=0.09490, avg_loss=0.08965, mel_loss=0.04256, linear_loss=0.05234]
[2020-05-12 05:56:38.006]  Step 154232  [3.449 sec/step, loss=0.07122, avg_loss=0.08942, mel_loss=0.03086, linear_loss=0.04036]
[2020-05-12 05:56:52.373]  Step 154233  [3.559 sec/step, loss=0.07469, avg_loss=0.08922, mel_loss=0.03513, linear_loss=0.03956]
[2020-05-12 05:56:53.847]  Step 154234  [3.549 sec/step, loss=0.08380, avg_loss=0.08914, mel_loss=0.03671, linear_loss=0.04709]
[2020-05-12 05:56:56.616]  Step 154235  [3.555 sec/step, loss=0.09225, avg_loss=0.08916, mel_loss=0.04090, linear_loss=0.05136]
[2020-05-12 05:56:57.703]  Step 154236  [3.539 sec/step, loss=0.07764, avg_loss=0.08901, mel_loss=0.03351, linear_loss=0.04413]
[2020-05-12 05:56:58.370]  Generated 32 batches of size 32 in 1.748 sec
[2020-05-12 05:57:02.127]  Step 154237  [3.554 sec/step, loss=0.09529, avg_loss=0.08903, mel_loss=0.04271, linear_loss=0.05258]
[2020-05-12 05:57:04.709]  Step 154238  [3.572 sec/step, loss=0.08989, avg_loss=0.08913, mel_loss=0.03974, linear_loss=0.05015]
[2020-05-12 05:57:08.150]  Step 154239  [3.598 sec/step, loss=0.09525, avg_loss=0.08928, mel_loss=0.04276, linear_loss=0.05248]
[2020-05-12 05:57:09.504]  Step 154240  [3.593 sec/step, loss=0.08490, avg_loss=0.08926, mel_loss=0.03669, linear_loss=0.04820]
[2020-05-12 05:57:10.513]  Step 154241  [3.458 sec/step, loss=0.07818, avg_loss=0.08926, mel_loss=0.03357, linear_loss=0.04461]
[2020-05-12 05:57:12.207]  Step 154242  [3.389 sec/step, loss=0.08961, avg_loss=0.08920, mel_loss=0.03917, linear_loss=0.05044]
[2020-05-12 05:57:13.307]  Step 154243  [3.349 sec/step, loss=0.08244, avg_loss=0.08907, mel_loss=0.03548, linear_loss=0.04697]
[2020-05-12 05:57:13.874]  Step 154244  [3.340 sec/step, loss=0.06962, avg_loss=0.08892, mel_loss=0.03091, linear_loss=0.03870]
[2020-05-12 05:57:16.899]  Step 154245  [3.325 sec/step, loss=0.09265, avg_loss=0.08888, mel_loss=0.04086, linear_loss=0.05179]
[2020-05-12 05:57:24.180]  Step 154246  [3.365 sec/step, loss=0.09710, avg_loss=0.08890, mel_loss=0.04456, linear_loss=0.05254]
[2020-05-12 05:57:26.136]  Step 154247  [3.308 sec/step, loss=0.08845, avg_loss=0.08882, mel_loss=0.03861, linear_loss=0.04985]
[2020-05-12 05:57:28.181]  Step 154248  [3.261 sec/step, loss=0.08862, avg_loss=0.08873, mel_loss=0.03859, linear_loss=0.05003]
[2020-05-12 05:57:29.062]  Step 154249  [3.233 sec/step, loss=0.08218, avg_loss=0.08859, mel_loss=0.03495, linear_loss=0.04723]
[2020-05-12 05:57:32.575]  Step 154250  [3.257 sec/step, loss=0.09342, avg_loss=0.08870, mel_loss=0.04183, linear_loss=0.05159]
[2020-05-12 05:57:32.575]  Writing summary at step: 154250
[2020-05-12 05:57:44.914]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154250
[2020-05-12 05:57:47.493]  Saving audio and alignment...
[2020-05-12 05:57:54.238]  Input: 오늘따라 송식씨가 순영씨에 속을 긁는다~__________
[2020-05-12 05:58:00.473]  Step 154251  [3.299 sec/step, loss=0.09859, avg_loss=0.08879, mel_loss=0.04514, linear_loss=0.05344]
[2020-05-12 05:58:01.494]  Step 154252  [3.261 sec/step, loss=0.08175, avg_loss=0.08866, mel_loss=0.03515, linear_loss=0.04660]
[2020-05-12 05:58:02.316]  Step 154253  [3.203 sec/step, loss=0.07216, avg_loss=0.08841, mel_loss=0.03104, linear_loss=0.04111]
[2020-05-12 05:58:03.926]  Step 154254  [3.200 sec/step, loss=0.08643, avg_loss=0.08839, mel_loss=0.03775, linear_loss=0.04868]
[2020-05-12 05:58:04.738]  Step 154255  [3.076 sec/step, loss=0.07723, avg_loss=0.08838, mel_loss=0.03308, linear_loss=0.04415]
[2020-05-12 05:58:08.071]  Step 154256  [3.099 sec/step, loss=0.09524, avg_loss=0.08858, mel_loss=0.04222, linear_loss=0.05303]
[2020-05-12 05:58:13.528]  Step 154257  [3.116 sec/step, loss=0.09679, avg_loss=0.08858, mel_loss=0.04384, linear_loss=0.05295]
[2020-05-12 05:58:17.989]  Step 154258  [3.135 sec/step, loss=0.09662, avg_loss=0.08866, mel_loss=0.04377, linear_loss=0.05285]
[2020-05-12 05:58:22.798]  Step 154259  [3.168 sec/step, loss=0.09670, avg_loss=0.08875, mel_loss=0.04348, linear_loss=0.05322]
[2020-05-12 05:58:26.968]  Step 154260  [3.197 sec/step, loss=0.09670, avg_loss=0.08890, mel_loss=0.04325, linear_loss=0.05345]
[2020-05-12 05:58:28.345]  Step 154261  [3.201 sec/step, loss=0.08526, avg_loss=0.08894, mel_loss=0.03696, linear_loss=0.04830]
[2020-05-12 05:58:37.782]  Step 154262  [3.253 sec/step, loss=0.09579, avg_loss=0.08894, mel_loss=0.04422, linear_loss=0.05156]
[2020-05-12 05:58:41.505]  Step 154263  [3.282 sec/step, loss=0.09516, avg_loss=0.08913, mel_loss=0.04256, linear_loss=0.05260]
[2020-05-12 05:58:42.694]  Step 154264  [3.266 sec/step, loss=0.08456, avg_loss=0.08906, mel_loss=0.03656, linear_loss=0.04800]
[2020-05-12 05:58:44.077]  Step 154265  [3.250 sec/step, loss=0.08661, avg_loss=0.08901, mel_loss=0.03791, linear_loss=0.04869]
[2020-05-12 05:58:45.825]  Generated 32 batches of size 32 in 1.741 sec
[2020-05-12 05:58:46.802]  Step 154266  [3.217 sec/step, loss=0.08961, avg_loss=0.08892, mel_loss=0.03988, linear_loss=0.04974]
[2020-05-12 05:58:48.976]  Step 154267  [3.225 sec/step, loss=0.09161, avg_loss=0.08899, mel_loss=0.04030, linear_loss=0.05131]
[2020-05-12 05:58:51.377]  Step 154268  [3.214 sec/step, loss=0.08903, avg_loss=0.08895, mel_loss=0.03905, linear_loss=0.04998]
[2020-05-12 05:58:58.194]  Step 154269  [3.249 sec/step, loss=0.09679, avg_loss=0.08897, mel_loss=0.04412, linear_loss=0.05267]
[2020-05-12 05:58:59.857]  Step 154270  [3.257 sec/step, loss=0.08616, avg_loss=0.08907, mel_loss=0.03780, linear_loss=0.04836]
[2020-05-12 05:59:00.391]  Step 154271  [3.230 sec/step, loss=0.07286, avg_loss=0.08886, mel_loss=0.03175, linear_loss=0.04111]
[2020-05-12 05:59:02.191]  Step 154272  [3.206 sec/step, loss=0.08720, avg_loss=0.08877, mel_loss=0.03790, linear_loss=0.04930]
[2020-05-12 05:59:03.307]  Step 154273  [3.143 sec/step, loss=0.08317, avg_loss=0.08861, mel_loss=0.03567, linear_loss=0.04750]
[2020-05-12 05:59:06.132]  Step 154274  [3.152 sec/step, loss=0.09395, avg_loss=0.08868, mel_loss=0.04177, linear_loss=0.05218]
[2020-05-12 05:59:14.389]  Step 154275  [3.211 sec/step, loss=0.09315, avg_loss=0.08869, mel_loss=0.04311, linear_loss=0.05005]
[2020-05-12 05:59:21.549]  Step 154276  [3.261 sec/step, loss=0.09836, avg_loss=0.08877, mel_loss=0.04508, linear_loss=0.05328]
[2020-05-12 05:59:23.171]  Step 154277  [3.271 sec/step, loss=0.09036, avg_loss=0.08898, mel_loss=0.03920, linear_loss=0.05116]
[2020-05-12 05:59:23.734]  Step 154278  [3.260 sec/step, loss=0.06902, avg_loss=0.08878, mel_loss=0.03003, linear_loss=0.03899]
[2020-05-12 05:59:24.731]  Step 154279  [3.259 sec/step, loss=0.08234, avg_loss=0.08876, mel_loss=0.03557, linear_loss=0.04677]
[2020-05-12 05:59:29.924]  Step 154280  [3.229 sec/step, loss=0.09572, avg_loss=0.08877, mel_loss=0.04319, linear_loss=0.05253]
[2020-05-12 05:59:32.639]  Step 154281  [3.242 sec/step, loss=0.08946, avg_loss=0.08879, mel_loss=0.03941, linear_loss=0.05005]
[2020-05-12 05:59:36.288]  Step 154282  [3.224 sec/step, loss=0.09227, avg_loss=0.08875, mel_loss=0.04121, linear_loss=0.05106]
[2020-05-12 05:59:40.605]  Step 154283  [3.232 sec/step, loss=0.09366, avg_loss=0.08874, mel_loss=0.04214, linear_loss=0.05151]
[2020-05-12 05:59:41.489]  Step 154284  [3.204 sec/step, loss=0.07891, avg_loss=0.08857, mel_loss=0.03353, linear_loss=0.04538]
[2020-05-12 05:59:44.872]  Step 154285  [3.226 sec/step, loss=0.09510, avg_loss=0.08867, mel_loss=0.04232, linear_loss=0.05278]
[2020-05-12 05:59:46.627]  Step 154286  [3.230 sec/step, loss=0.08768, avg_loss=0.08870, mel_loss=0.03821, linear_loss=0.04948]
[2020-05-12 05:59:49.747]  Step 154287  [3.227 sec/step, loss=0.09537, avg_loss=0.08870, mel_loss=0.04267, linear_loss=0.05270]
[2020-05-12 05:59:53.464]  Step 154288  [3.200 sec/step, loss=0.09639, avg_loss=0.08872, mel_loss=0.04341, linear_loss=0.05297]
[2020-05-12 05:59:56.333]  Step 154289  [3.212 sec/step, loss=0.09436, avg_loss=0.08876, mel_loss=0.04210, linear_loss=0.05227]
[2020-05-12 05:59:57.655]  Step 154290  [3.211 sec/step, loss=0.08554, avg_loss=0.08875, mel_loss=0.03696, linear_loss=0.04858]
[2020-05-12 06:00:02.231]  Step 154291  [3.249 sec/step, loss=0.09747, avg_loss=0.08900, mel_loss=0.04398, linear_loss=0.05349]
[2020-05-12 06:00:16.745]  Step 154292  [3.348 sec/step, loss=0.07447, avg_loss=0.08878, mel_loss=0.03505, linear_loss=0.03942]
[2020-05-12 06:00:18.349]  Step 154293  [3.335 sec/step, loss=0.08518, avg_loss=0.08870, mel_loss=0.03691, linear_loss=0.04827]
[2020-05-12 06:00:23.716]  Step 154294  [3.364 sec/step, loss=0.09657, avg_loss=0.08874, mel_loss=0.04371, linear_loss=0.05286]
[2020-05-12 06:00:25.638]  Step 154295  [3.363 sec/step, loss=0.08911, avg_loss=0.08874, mel_loss=0.03928, linear_loss=0.04983]
[2020-05-12 06:00:31.599]  Step 154296  [3.411 sec/step, loss=0.09533, avg_loss=0.08888, mel_loss=0.04342, linear_loss=0.05191]
[2020-05-12 06:00:32.773]  Step 154297  [3.417 sec/step, loss=0.08174, avg_loss=0.08899, mel_loss=0.03524, linear_loss=0.04649]
[2020-05-12 06:00:34.477]  Generated 32 batches of size 32 in 1.698 sec
[2020-05-12 06:00:36.458]  Step 154298  [3.445 sec/step, loss=0.09483, avg_loss=0.08917, mel_loss=0.04232, linear_loss=0.05251]
[2020-05-12 06:00:38.713]  Step 154299  [3.444 sec/step, loss=0.09126, avg_loss=0.08918, mel_loss=0.04030, linear_loss=0.05097]
[2020-05-12 06:00:39.553]  Step 154300  [3.428 sec/step, loss=0.07604, avg_loss=0.08904, mel_loss=0.03305, linear_loss=0.04299]
[2020-05-12 06:00:39.553]  Writing summary at step: 154300
[2020-05-12 06:00:41.530]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154300
[2020-05-12 06:00:43.011]  Saving audio and alignment...
[2020-05-12 06:00:45.589]  Input: 살짝 포즈를 드시고~___________
[2020-05-12 06:00:46.341]  Step 154301  [3.417 sec/step, loss=0.07914, avg_loss=0.08894, mel_loss=0.03394, linear_loss=0.04519]
[2020-05-12 06:00:48.417]  Step 154302  [3.381 sec/step, loss=0.09109, avg_loss=0.08889, mel_loss=0.03998, linear_loss=0.05111]
[2020-05-12 06:00:49.487]  Step 154303  [3.250 sec/step, loss=0.08408, avg_loss=0.08896, mel_loss=0.03593, linear_loss=0.04815]
[2020-05-12 06:00:52.180]  Step 154304  [3.257 sec/step, loss=0.09322, avg_loss=0.08901, mel_loss=0.04148, linear_loss=0.05174]
[2020-05-12 06:01:00.397]  Step 154305  [3.295 sec/step, loss=0.09412, avg_loss=0.08900, mel_loss=0.04322, linear_loss=0.05089]
[2020-05-12 06:01:06.622]  Step 154306  [3.267 sec/step, loss=0.09677, avg_loss=0.08900, mel_loss=0.04414, linear_loss=0.05263]
[2020-05-12 06:01:12.051]  Step 154307  [3.271 sec/step, loss=0.09817, avg_loss=0.08902, mel_loss=0.04498, linear_loss=0.05320]
[2020-05-12 06:01:13.113]  Step 154308  [3.272 sec/step, loss=0.08097, avg_loss=0.08900, mel_loss=0.03518, linear_loss=0.04579]
[2020-05-12 06:01:15.123]  Step 154309  [3.251 sec/step, loss=0.08797, avg_loss=0.08892, mel_loss=0.03866, linear_loss=0.04931]
[2020-05-12 06:01:19.674]  Step 154310  [3.267 sec/step, loss=0.09629, avg_loss=0.08893, mel_loss=0.04349, linear_loss=0.05279]
[2020-05-12 06:01:22.137]  Step 154311  [3.282 sec/step, loss=0.09188, avg_loss=0.08907, mel_loss=0.04023, linear_loss=0.05165]
[2020-05-12 06:01:26.236]  Step 154312  [3.307 sec/step, loss=0.09537, avg_loss=0.08915, mel_loss=0.04284, linear_loss=0.05253]
[2020-05-12 06:01:27.990]  Step 154313  [3.293 sec/step, loss=0.08676, avg_loss=0.08906, mel_loss=0.03789, linear_loss=0.04887]
[2020-05-12 06:01:28.790]  Step 154314  [3.265 sec/step, loss=0.07127, avg_loss=0.08880, mel_loss=0.03050, linear_loss=0.04077]
[2020-05-12 06:01:30.141]  Step 154315  [3.262 sec/step, loss=0.08586, avg_loss=0.08880, mel_loss=0.03733, linear_loss=0.04853]
[2020-05-12 06:01:30.982]  Step 154316  [3.194 sec/step, loss=0.07455, avg_loss=0.08857, mel_loss=0.03198, linear_loss=0.04257]
[2020-05-12 06:01:34.230]  Step 154317  [3.170 sec/step, loss=0.09603, avg_loss=0.08856, mel_loss=0.04289, linear_loss=0.05314]
[2020-05-12 06:01:41.250]  Step 154318  [3.193 sec/step, loss=0.09794, avg_loss=0.08859, mel_loss=0.04501, linear_loss=0.05293]
[2020-05-12 06:01:42.978]  Step 154319  [3.189 sec/step, loss=0.08891, avg_loss=0.08859, mel_loss=0.03884, linear_loss=0.05007]
[2020-05-12 06:01:48.230]  Step 154320  [3.224 sec/step, loss=0.09582, avg_loss=0.08864, mel_loss=0.04356, linear_loss=0.05225]
[2020-05-12 06:01:49.426]  Step 154321  [3.202 sec/step, loss=0.08503, avg_loss=0.08856, mel_loss=0.03686, linear_loss=0.04816]
[2020-05-12 06:01:52.064]  Step 154322  [3.208 sec/step, loss=0.09181, avg_loss=0.08858, mel_loss=0.04050, linear_loss=0.05131]
[2020-05-12 06:01:54.453]  Step 154323  [3.202 sec/step, loss=0.09005, avg_loss=0.08854, mel_loss=0.03977, linear_loss=0.05028]
[2020-05-12 06:01:57.458]  Step 154324  [3.213 sec/step, loss=0.09302, avg_loss=0.08858, mel_loss=0.04144, linear_loss=0.05158]
[2020-05-12 06:01:59.279]  Step 154325  [3.208 sec/step, loss=0.08724, avg_loss=0.08854, mel_loss=0.03793, linear_loss=0.04931]
[2020-05-12 06:02:00.745]  Step 154326  [3.157 sec/step, loss=0.08508, avg_loss=0.08845, mel_loss=0.03716, linear_loss=0.04792]
[2020-05-12 06:02:02.716]  Step 154327  [3.125 sec/step, loss=0.08850, avg_loss=0.08838, mel_loss=0.03865, linear_loss=0.04984]
[2020-05-12 06:02:04.532]  Generated 32 batches of size 32 in 1.811 sec
[2020-05-12 06:02:05.001]  Step 154328  [3.140 sec/step, loss=0.09191, avg_loss=0.08855, mel_loss=0.04048, linear_loss=0.05143]
[2020-05-12 06:02:08.780]  Step 154329  [3.093 sec/step, loss=0.09400, avg_loss=0.08855, mel_loss=0.04196, linear_loss=0.05204]
[2020-05-12 06:02:09.845]  Step 154330  [3.091 sec/step, loss=0.07912, avg_loss=0.08850, mel_loss=0.03392, linear_loss=0.04521]
[2020-05-12 06:02:10.421]  Step 154331  [3.056 sec/step, loss=0.07156, avg_loss=0.08826, mel_loss=0.03147, linear_loss=0.04010]
[2020-05-12 06:02:14.653]  Step 154332  [3.089 sec/step, loss=0.09500, avg_loss=0.08850, mel_loss=0.04232, linear_loss=0.05268]
[2020-05-12 06:02:18.132]  Step 154333  [2.980 sec/step, loss=0.09390, avg_loss=0.08869, mel_loss=0.04187, linear_loss=0.05203]
[2020-05-12 06:02:19.258]  Step 154334  [2.977 sec/step, loss=0.08463, avg_loss=0.08870, mel_loss=0.03612, linear_loss=0.04851]
[2020-05-12 06:02:22.160]  Step 154335  [2.978 sec/step, loss=0.09424, avg_loss=0.08872, mel_loss=0.04202, linear_loss=0.05223]
[2020-05-12 06:02:35.449]  Step 154336  [3.100 sec/step, loss=0.08056, avg_loss=0.08875, mel_loss=0.03802, linear_loss=0.04254]
[2020-05-12 06:02:39.727]  Step 154337  [3.099 sec/step, loss=0.09513, avg_loss=0.08875, mel_loss=0.04280, linear_loss=0.05233]
[2020-05-12 06:02:43.356]  Step 154338  [3.109 sec/step, loss=0.09515, avg_loss=0.08880, mel_loss=0.04252, linear_loss=0.05263]
[2020-05-12 06:02:45.596]  Step 154339  [3.097 sec/step, loss=0.08956, avg_loss=0.08875, mel_loss=0.03953, linear_loss=0.05003]
[2020-05-12 06:02:47.582]  Step 154340  [3.104 sec/step, loss=0.09072, avg_loss=0.08880, mel_loss=0.03977, linear_loss=0.05094]
[2020-05-12 06:02:52.094]  Step 154341  [3.139 sec/step, loss=0.09717, avg_loss=0.08899, mel_loss=0.04387, linear_loss=0.05330]
[2020-05-12 06:03:06.658]  Step 154342  [3.267 sec/step, loss=0.07611, avg_loss=0.08886, mel_loss=0.03600, linear_loss=0.04010]
[2020-05-12 06:03:08.336]  Step 154343  [3.273 sec/step, loss=0.08849, avg_loss=0.08892, mel_loss=0.03858, linear_loss=0.04992]
[2020-05-12 06:03:09.537]  Step 154344  [3.279 sec/step, loss=0.07985, avg_loss=0.08902, mel_loss=0.03419, linear_loss=0.04566]
[2020-05-12 06:03:11.335]  Step 154345  [3.267 sec/step, loss=0.08820, avg_loss=0.08898, mel_loss=0.03846, linear_loss=0.04973]
[2020-05-12 06:03:12.162]  Step 154346  [3.203 sec/step, loss=0.07408, avg_loss=0.08875, mel_loss=0.03178, linear_loss=0.04230]
[2020-05-12 06:03:13.209]  Step 154347  [3.193 sec/step, loss=0.08217, avg_loss=0.08868, mel_loss=0.03536, linear_loss=0.04681]
[2020-05-12 06:03:18.838]  Step 154348  [3.229 sec/step, loss=0.09766, avg_loss=0.08877, mel_loss=0.04424, linear_loss=0.05341]
[2020-05-12 06:03:21.970]  Step 154349  [3.252 sec/step, loss=0.09415, avg_loss=0.08889, mel_loss=0.04167, linear_loss=0.05248]
[2020-05-12 06:03:24.124]  Step 154350  [3.238 sec/step, loss=0.09016, avg_loss=0.08886, mel_loss=0.03965, linear_loss=0.05051]
[2020-05-12 06:03:24.124]  Writing summary at step: 154350
[2020-05-12 06:03:25.142]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154350
[2020-05-12 06:03:26.667]  Saving audio and alignment...
[2020-05-12 06:03:29.494]  Input: 기회는 놓치지말아야 한~_________
[2020-05-12 06:03:30.779]  Step 154351  [3.189 sec/step, loss=0.08392, avg_loss=0.08871, mel_loss=0.03652, linear_loss=0.04741]
[2020-05-12 06:03:35.754]  Step 154352  [3.228 sec/step, loss=0.09584, avg_loss=0.08886, mel_loss=0.04313, linear_loss=0.05271]
[2020-05-12 06:03:42.732]  Step 154353  [3.290 sec/step, loss=0.09825, avg_loss=0.08912, mel_loss=0.04490, linear_loss=0.05335]
[2020-05-12 06:03:46.503]  Step 154354  [3.311 sec/step, loss=0.09606, avg_loss=0.08921, mel_loss=0.04304, linear_loss=0.05301]
[2020-05-12 06:03:49.993]  Step 154355  [3.338 sec/step, loss=0.09447, avg_loss=0.08938, mel_loss=0.04186, linear_loss=0.05261]
[2020-05-12 06:03:52.658]  Step 154356  [3.332 sec/step, loss=0.09246, avg_loss=0.08936, mel_loss=0.04079, linear_loss=0.05168]
[2020-05-12 06:04:01.936]  Step 154357  [3.370 sec/step, loss=0.09656, avg_loss=0.08935, mel_loss=0.04458, linear_loss=0.05198]
[2020-05-12 06:04:02.804]  Step 154358  [3.334 sec/step, loss=0.07814, avg_loss=0.08917, mel_loss=0.03351, linear_loss=0.04463]
[2020-05-12 06:04:03.412]  Step 154359  [3.292 sec/step, loss=0.07238, avg_loss=0.08893, mel_loss=0.03218, linear_loss=0.04020]
[2020-05-12 06:04:03.738]  Generated 32 batches of size 32 in 1.796 sec
[2020-05-12 06:04:09.417]  Step 154360  [3.310 sec/step, loss=0.09740, avg_loss=0.08893, mel_loss=0.04439, linear_loss=0.05301]
[2020-05-12 06:04:12.383]  Step 154361  [3.326 sec/step, loss=0.09100, avg_loss=0.08899, mel_loss=0.04056, linear_loss=0.05043]
[2020-05-12 06:04:14.229]  Step 154362  [3.250 sec/step, loss=0.08883, avg_loss=0.08892, mel_loss=0.03860, linear_loss=0.05023]
[2020-05-12 06:04:15.654]  Step 154363  [3.227 sec/step, loss=0.08572, avg_loss=0.08883, mel_loss=0.03736, linear_loss=0.04835]
[2020-05-12 06:04:18.162]  Step 154364  [3.240 sec/step, loss=0.09068, avg_loss=0.08889, mel_loss=0.03984, linear_loss=0.05084]
[2020-05-12 06:04:25.976]  Step 154365  [3.305 sec/step, loss=0.09561, avg_loss=0.08898, mel_loss=0.04392, linear_loss=0.05169]
[2020-05-12 06:04:29.401]  Step 154366  [3.312 sec/step, loss=0.09341, avg_loss=0.08902, mel_loss=0.04161, linear_loss=0.05179]
[2020-05-12 06:04:33.011]  Step 154367  [3.326 sec/step, loss=0.09484, avg_loss=0.08905, mel_loss=0.04231, linear_loss=0.05253]
[2020-05-12 06:04:37.064]  Step 154368  [3.343 sec/step, loss=0.09431, avg_loss=0.08910, mel_loss=0.04222, linear_loss=0.05209]
[2020-05-12 06:04:38.988]  Step 154369  [3.294 sec/step, loss=0.08727, avg_loss=0.08901, mel_loss=0.03819, linear_loss=0.04908]
[2020-05-12 06:04:40.407]  Step 154370  [3.291 sec/step, loss=0.08578, avg_loss=0.08900, mel_loss=0.03689, linear_loss=0.04889]
[2020-05-12 06:04:49.312]  Step 154371  [3.375 sec/step, loss=0.09652, avg_loss=0.08924, mel_loss=0.04442, linear_loss=0.05210]
[2020-05-12 06:04:51.803]  Step 154372  [3.382 sec/step, loss=0.09118, avg_loss=0.08928, mel_loss=0.04051, linear_loss=0.05067]
[2020-05-12 06:04:53.109]  Step 154373  [3.384 sec/step, loss=0.08482, avg_loss=0.08930, mel_loss=0.03663, linear_loss=0.04819]
[2020-05-12 06:04:55.277]  Step 154374  [3.377 sec/step, loss=0.08968, avg_loss=0.08925, mel_loss=0.03940, linear_loss=0.05028]
[2020-05-12 06:04:55.785]  Step 154375  [3.300 sec/step, loss=0.07665, avg_loss=0.08909, mel_loss=0.03354, linear_loss=0.04311]
[2020-05-12 06:04:56.673]  Step 154376  [3.237 sec/step, loss=0.07867, avg_loss=0.08889, mel_loss=0.03344, linear_loss=0.04523]
[2020-05-12 06:05:01.524]  Step 154377  [3.269 sec/step, loss=0.09460, avg_loss=0.08893, mel_loss=0.04262, linear_loss=0.05198]
[2020-05-12 06:05:02.367]  Step 154378  [3.272 sec/step, loss=0.07326, avg_loss=0.08898, mel_loss=0.03224, linear_loss=0.04102]
[2020-05-12 06:05:04.154]  Step 154379  [3.280 sec/step, loss=0.08870, avg_loss=0.08904, mel_loss=0.03855, linear_loss=0.05015]
[2020-05-12 06:05:07.389]  Step 154380  [3.260 sec/step, loss=0.09431, avg_loss=0.08902, mel_loss=0.04213, linear_loss=0.05218]
[2020-05-12 06:05:21.800]  Step 154381  [3.377 sec/step, loss=0.07391, avg_loss=0.08887, mel_loss=0.03482, linear_loss=0.03909]
[2020-05-12 06:05:28.786]  Step 154382  [3.411 sec/step, loss=0.09541, avg_loss=0.08890, mel_loss=0.04352, linear_loss=0.05189]
[2020-05-12 06:05:29.913]  Step 154383  [3.379 sec/step, loss=0.08184, avg_loss=0.08878, mel_loss=0.03545, linear_loss=0.04638]
[2020-05-12 06:05:30.903]  Step 154384  [3.380 sec/step, loss=0.07978, avg_loss=0.08879, mel_loss=0.03426, linear_loss=0.04552]
[2020-05-12 06:05:31.934]  Step 154385  [3.356 sec/step, loss=0.08017, avg_loss=0.08864, mel_loss=0.03454, linear_loss=0.04563]
[2020-05-12 06:05:33.584]  Step 154386  [3.355 sec/step, loss=0.08684, avg_loss=0.08863, mel_loss=0.03807, linear_loss=0.04876]
[2020-05-12 06:05:35.634]  Step 154387  [3.345 sec/step, loss=0.08901, avg_loss=0.08857, mel_loss=0.03931, linear_loss=0.04970]
[2020-05-12 06:05:40.180]  Step 154388  [3.353 sec/step, loss=0.09688, avg_loss=0.08857, mel_loss=0.04377, linear_loss=0.05310]
[2020-05-12 06:05:43.266]  Step 154389  [3.355 sec/step, loss=0.09369, avg_loss=0.08857, mel_loss=0.04176, linear_loss=0.05193]
[2020-05-12 06:05:45.034]  Generated 32 batches of size 32 in 1.762 sec
[2020-05-12 06:05:45.222]  Step 154390  [3.361 sec/step, loss=0.08758, avg_loss=0.08859, mel_loss=0.03812, linear_loss=0.04946]
[2020-05-12 06:05:48.951]  Step 154391  [3.353 sec/step, loss=0.09781, avg_loss=0.08859, mel_loss=0.04385, linear_loss=0.05397]
[2020-05-12 06:05:51.708]  Step 154392  [3.235 sec/step, loss=0.09153, avg_loss=0.08876, mel_loss=0.04042, linear_loss=0.05111]
[2020-05-12 06:05:57.667]  Step 154393  [3.279 sec/step, loss=0.09727, avg_loss=0.08888, mel_loss=0.04433, linear_loss=0.05294]
[2020-05-12 06:05:58.477]  Step 154394  [3.233 sec/step, loss=0.07768, avg_loss=0.08869, mel_loss=0.03327, linear_loss=0.04441]
[2020-05-12 06:06:01.418]  Step 154395  [3.243 sec/step, loss=0.09147, avg_loss=0.08872, mel_loss=0.04060, linear_loss=0.05087]
[2020-05-12 06:06:05.025]  Step 154396  [3.220 sec/step, loss=0.09462, avg_loss=0.08871, mel_loss=0.04235, linear_loss=0.05227]
[2020-05-12 06:06:06.493]  Step 154397  [3.223 sec/step, loss=0.08482, avg_loss=0.08874, mel_loss=0.03714, linear_loss=0.04768]
[2020-05-12 06:06:12.021]  Step 154398  [3.241 sec/step, loss=0.09627, avg_loss=0.08876, mel_loss=0.04362, linear_loss=0.05265]
[2020-05-12 06:06:14.472]  Step 154399  [3.243 sec/step, loss=0.09295, avg_loss=0.08877, mel_loss=0.04081, linear_loss=0.05213]
[2020-05-12 06:06:16.632]  Step 154400  [3.256 sec/step, loss=0.09077, avg_loss=0.08892, mel_loss=0.03995, linear_loss=0.05082]
[2020-05-12 06:06:16.632]  Writing summary at step: 154400
[2020-05-12 06:06:17.984]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154400
[2020-05-12 06:06:19.563]  Saving audio and alignment...
[2020-05-12 06:06:31.444]  Input: 호흡을 섞어주세요 오늘 아주 이런 소리 넣으면 아주 분위기가 밝아집니다 오늘 아주 기분 좋습니다~______________________________________________
[2020-05-12 06:06:33.658]  Step 154401  [3.271 sec/step, loss=0.09178, avg_loss=0.08905, mel_loss=0.04025, linear_loss=0.05154]
[2020-05-12 06:06:35.369]  Step 154402  [3.267 sec/step, loss=0.08794, avg_loss=0.08902, mel_loss=0.03842, linear_loss=0.04952]
[2020-05-12 06:06:39.157]  Step 154403  [3.295 sec/step, loss=0.09460, avg_loss=0.08912, mel_loss=0.04237, linear_loss=0.05224]
[2020-05-12 06:06:40.001]  Step 154404  [3.276 sec/step, loss=0.07594, avg_loss=0.08895, mel_loss=0.03257, linear_loss=0.04337]
[2020-05-12 06:06:43.534]  Step 154405  [3.229 sec/step, loss=0.09448, avg_loss=0.08895, mel_loss=0.04197, linear_loss=0.05251]
[2020-05-12 06:06:47.008]  Step 154406  [3.202 sec/step, loss=0.09440, avg_loss=0.08893, mel_loss=0.04193, linear_loss=0.05246]
[2020-05-12 06:06:52.505]  Step 154407  [3.202 sec/step, loss=0.09641, avg_loss=0.08891, mel_loss=0.04365, linear_loss=0.05276]
[2020-05-12 06:07:00.287]  Step 154408  [3.270 sec/step, loss=0.09778, avg_loss=0.08908, mel_loss=0.04492, linear_loss=0.05287]
[2020-05-12 06:07:01.830]  Step 154409  [3.265 sec/step, loss=0.08488, avg_loss=0.08905, mel_loss=0.03684, linear_loss=0.04804]
[2020-05-12 06:07:02.875]  Step 154410  [3.230 sec/step, loss=0.07933, avg_loss=0.08888, mel_loss=0.03389, linear_loss=0.04544]
[2020-05-12 06:07:04.785]  Step 154411  [3.224 sec/step, loss=0.08904, avg_loss=0.08885, mel_loss=0.03882, linear_loss=0.05022]
[2020-05-12 06:07:05.352]  Step 154412  [3.189 sec/step, loss=0.06976, avg_loss=0.08859, mel_loss=0.03061, linear_loss=0.03915]
[2020-05-12 06:07:10.153]  Step 154413  [3.220 sec/step, loss=0.09739, avg_loss=0.08870, mel_loss=0.04394, linear_loss=0.05345]
[2020-05-12 06:07:14.682]  Step 154414  [3.257 sec/step, loss=0.09619, avg_loss=0.08895, mel_loss=0.04341, linear_loss=0.05278]
[2020-05-12 06:07:20.622]  Step 154415  [3.303 sec/step, loss=0.09872, avg_loss=0.08908, mel_loss=0.04512, linear_loss=0.05360]
[2020-05-12 06:07:24.839]  Step 154416  [3.336 sec/step, loss=0.09542, avg_loss=0.08929, mel_loss=0.04265, linear_loss=0.05277]
[2020-05-12 06:07:31.750]  Step 154417  [3.373 sec/step, loss=0.09823, avg_loss=0.08931, mel_loss=0.04505, linear_loss=0.05318]
[2020-05-12 06:07:33.129]  Step 154418  [3.317 sec/step, loss=0.08673, avg_loss=0.08920, mel_loss=0.03780, linear_loss=0.04893]
[2020-05-12 06:07:34.215]  Step 154419  [3.310 sec/step, loss=0.08101, avg_loss=0.08912, mel_loss=0.03511, linear_loss=0.04590]
[2020-05-12 06:07:36.508]  Generated 32 batches of size 32 in 2.287 sec
[2020-05-12 06:07:37.143]  Step 154420  [3.287 sec/step, loss=0.09274, avg_loss=0.08909, mel_loss=0.04123, linear_loss=0.05150]
[2020-05-12 06:07:37.961]  Step 154421  [3.283 sec/step, loss=0.07041, avg_loss=0.08894, mel_loss=0.03010, linear_loss=0.04032]
[2020-05-12 06:07:51.461]  Step 154422  [3.392 sec/step, loss=0.08460, avg_loss=0.08887, mel_loss=0.03999, linear_loss=0.04461]
[2020-05-12 06:07:52.620]  Step 154423  [3.380 sec/step, loss=0.08144, avg_loss=0.08878, mel_loss=0.03488, linear_loss=0.04656]
[2020-05-12 06:07:55.594]  Step 154424  [3.379 sec/step, loss=0.09350, avg_loss=0.08879, mel_loss=0.04148, linear_loss=0.05202]
[2020-05-12 06:07:58.646]  Step 154425  [3.392 sec/step, loss=0.08948, avg_loss=0.08881, mel_loss=0.03930, linear_loss=0.05018]
[2020-05-12 06:08:03.401]  Step 154426  [3.424 sec/step, loss=0.09552, avg_loss=0.08891, mel_loss=0.04253, linear_loss=0.05299]
[2020-05-12 06:08:05.846]  Step 154427  [3.429 sec/step, loss=0.08650, avg_loss=0.08889, mel_loss=0.03758, linear_loss=0.04891]
[2020-05-12 06:08:09.632]  Step 154428  [3.444 sec/step, loss=0.08942, avg_loss=0.08887, mel_loss=0.03919, linear_loss=0.05024]
[2020-05-12 06:08:14.461]  Step 154429  [3.455 sec/step, loss=0.09571, avg_loss=0.08889, mel_loss=0.04298, linear_loss=0.05273]
[2020-05-12 06:08:15.018]  Step 154430  [3.450 sec/step, loss=0.06962, avg_loss=0.08879, mel_loss=0.03011, linear_loss=0.03951]
[2020-05-12 06:08:16.223]  Step 154431  [3.456 sec/step, loss=0.08396, avg_loss=0.08891, mel_loss=0.03620, linear_loss=0.04777]
[2020-05-12 06:08:21.328]  Step 154432  [3.465 sec/step, loss=0.09667, avg_loss=0.08893, mel_loss=0.04356, linear_loss=0.05311]
[2020-05-12 06:08:24.053]  Step 154433  [3.457 sec/step, loss=0.09017, avg_loss=0.08889, mel_loss=0.03981, linear_loss=0.05037]
[2020-05-12 06:08:24.883]  Step 154434  [3.454 sec/step, loss=0.07554, avg_loss=0.08880, mel_loss=0.03226, linear_loss=0.04328]
[2020-05-12 06:08:28.515]  Step 154435  [3.461 sec/step, loss=0.09385, avg_loss=0.08880, mel_loss=0.04187, linear_loss=0.05199]
[2020-05-12 06:08:29.445]  Step 154436  [3.338 sec/step, loss=0.07782, avg_loss=0.08877, mel_loss=0.03313, linear_loss=0.04469]
[2020-05-12 06:08:32.934]  Step 154437  [3.330 sec/step, loss=0.09395, avg_loss=0.08876, mel_loss=0.04190, linear_loss=0.05205]
[2020-05-12 06:08:34.081]  Step 154438  [3.305 sec/step, loss=0.08186, avg_loss=0.08863, mel_loss=0.03515, linear_loss=0.04672]
[2020-05-12 06:08:49.117]  Step 154439  [3.433 sec/step, loss=0.07758, avg_loss=0.08851, mel_loss=0.03645, linear_loss=0.04113]
[2020-05-12 06:08:50.455]  Step 154440  [3.427 sec/step, loss=0.08638, avg_loss=0.08846, mel_loss=0.03713, linear_loss=0.04925]
[2020-05-12 06:08:52.228]  Step 154441  [3.399 sec/step, loss=0.08848, avg_loss=0.08838, mel_loss=0.03856, linear_loss=0.04992]
[2020-05-12 06:08:54.096]  Step 154442  [3.272 sec/step, loss=0.08652, avg_loss=0.08848, mel_loss=0.03766, linear_loss=0.04885]
[2020-05-12 06:08:59.851]  Step 154443  [3.313 sec/step, loss=0.09741, avg_loss=0.08857, mel_loss=0.04447, linear_loss=0.05294]
[2020-05-12 06:09:08.648]  Step 154444  [3.389 sec/step, loss=0.09658, avg_loss=0.08874, mel_loss=0.04457, linear_loss=0.05201]
[2020-05-12 06:09:15.308]  Step 154445  [3.438 sec/step, loss=0.09526, avg_loss=0.08881, mel_loss=0.04354, linear_loss=0.05172]
[2020-05-12 06:09:20.746]  Step 154446  [3.484 sec/step, loss=0.09737, avg_loss=0.08904, mel_loss=0.04411, linear_loss=0.05326]
[2020-05-12 06:09:22.436]  Step 154447  [3.490 sec/step, loss=0.08760, avg_loss=0.08910, mel_loss=0.03809, linear_loss=0.04951]
[2020-05-12 06:09:24.931]  Step 154448  [3.459 sec/step, loss=0.09175, avg_loss=0.08904, mel_loss=0.04050, linear_loss=0.05124]
[2020-05-12 06:09:26.417]  Step 154449  [3.442 sec/step, loss=0.08560, avg_loss=0.08895, mel_loss=0.03709, linear_loss=0.04852]
[2020-05-12 06:09:27.291]  Step 154450  [3.430 sec/step, loss=0.07231, avg_loss=0.08877, mel_loss=0.03115, linear_loss=0.04116]
[2020-05-12 06:09:27.292]  Writing summary at step: 154450
[2020-05-12 06:09:35.102]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154450
[2020-05-12 06:09:36.631]  Saving audio and alignment...
[2020-05-12 06:09:38.816]  Generated 32 batches of size 32 in 1.566 sec
[2020-05-12 06:09:40.486]  Input: 이벤트를 작성하면서~________________________
[2020-05-12 06:09:44.609]  Step 154451  [3.458 sec/step, loss=0.09576, avg_loss=0.08889, mel_loss=0.04289, linear_loss=0.05287]
[2020-05-12 06:09:47.887]  Step 154452  [3.441 sec/step, loss=0.09458, avg_loss=0.08888, mel_loss=0.04225, linear_loss=0.05233]
[2020-05-12 06:09:51.959]  Step 154453  [3.412 sec/step, loss=0.09619, avg_loss=0.08886, mel_loss=0.04316, linear_loss=0.05303]
[2020-05-12 06:09:54.416]  Step 154454  [3.399 sec/step, loss=0.08967, avg_loss=0.08879, mel_loss=0.03948, linear_loss=0.05019]
[2020-05-12 06:09:55.563]  Step 154455  [3.375 sec/step, loss=0.07946, avg_loss=0.08864, mel_loss=0.03435, linear_loss=0.04511]
[2020-05-12 06:09:58.641]  Step 154456  [3.379 sec/step, loss=0.09095, avg_loss=0.08863, mel_loss=0.04028, linear_loss=0.05067]
[2020-05-12 06:10:00.683]  Step 154457  [3.307 sec/step, loss=0.09143, avg_loss=0.08858, mel_loss=0.04013, linear_loss=0.05130]
[2020-05-12 06:10:03.735]  Step 154458  [3.329 sec/step, loss=0.09352, avg_loss=0.08873, mel_loss=0.04167, linear_loss=0.05185]
[2020-05-12 06:10:04.763]  Step 154459  [3.333 sec/step, loss=0.08143, avg_loss=0.08882, mel_loss=0.03475, linear_loss=0.04668]
[2020-05-12 06:10:06.644]  Step 154460  [3.292 sec/step, loss=0.08782, avg_loss=0.08873, mel_loss=0.03856, linear_loss=0.04926]
[2020-05-12 06:10:07.771]  Step 154461  [3.274 sec/step, loss=0.08379, avg_loss=0.08865, mel_loss=0.03588, linear_loss=0.04792]
[2020-05-12 06:10:08.584]  Step 154462  [3.263 sec/step, loss=0.07570, avg_loss=0.08852, mel_loss=0.03255, linear_loss=0.04315]
[2020-05-12 06:10:11.527]  Step 154463  [3.278 sec/step, loss=0.09230, avg_loss=0.08859, mel_loss=0.04070, linear_loss=0.05160]
[2020-05-12 06:10:16.442]  Step 154464  [3.302 sec/step, loss=0.09543, avg_loss=0.08864, mel_loss=0.04306, linear_loss=0.05237]
[2020-05-12 06:10:25.256]  Step 154465  [3.312 sec/step, loss=0.09371, avg_loss=0.08862, mel_loss=0.04328, linear_loss=0.05042]
[2020-05-12 06:10:27.052]  Step 154466  [3.296 sec/step, loss=0.08598, avg_loss=0.08854, mel_loss=0.03735, linear_loss=0.04863]
[2020-05-12 06:10:30.608]  Step 154467  [3.296 sec/step, loss=0.09384, avg_loss=0.08853, mel_loss=0.04198, linear_loss=0.05186]
[2020-05-12 06:10:35.252]  Step 154468  [3.302 sec/step, loss=0.09696, avg_loss=0.08856, mel_loss=0.04377, linear_loss=0.05319]
[2020-05-12 06:10:37.900]  Step 154469  [3.309 sec/step, loss=0.09070, avg_loss=0.08859, mel_loss=0.04001, linear_loss=0.05069]
[2020-05-12 06:10:44.100]  Step 154470  [3.357 sec/step, loss=0.09591, avg_loss=0.08869, mel_loss=0.04380, linear_loss=0.05211]
[2020-05-12 06:10:51.350]  Step 154471  [3.340 sec/step, loss=0.09807, avg_loss=0.08871, mel_loss=0.04492, linear_loss=0.05316]
[2020-05-12 06:11:04.599]  Step 154472  [3.448 sec/step, loss=0.08000, avg_loss=0.08860, mel_loss=0.03762, linear_loss=0.04238]
[2020-05-12 06:11:05.230]  Step 154473  [3.441 sec/step, loss=0.07610, avg_loss=0.08851, mel_loss=0.03325, linear_loss=0.04285]
[2020-05-12 06:11:07.396]  Step 154474  [3.441 sec/step, loss=0.09197, avg_loss=0.08853, mel_loss=0.04046, linear_loss=0.05152]
[2020-05-12 06:11:09.658]  Step 154475  [3.458 sec/step, loss=0.08955, avg_loss=0.08866, mel_loss=0.03958, linear_loss=0.04997]
[2020-05-12 06:11:12.526]  Step 154476  [3.478 sec/step, loss=0.09217, avg_loss=0.08880, mel_loss=0.04106, linear_loss=0.05111]
[2020-05-12 06:11:13.099]  Step 154477  [3.435 sec/step, loss=0.06935, avg_loss=0.08855, mel_loss=0.03085, linear_loss=0.03850]
[2020-05-12 06:11:15.132]  Step 154478  [3.447 sec/step, loss=0.08835, avg_loss=0.08870, mel_loss=0.03852, linear_loss=0.04983]
[2020-05-12 06:11:19.381]  Step 154479  [3.472 sec/step, loss=0.09486, avg_loss=0.08876, mel_loss=0.04274, linear_loss=0.05212]
[2020-05-12 06:11:20.827]  Step 154480  [3.454 sec/step, loss=0.08704, avg_loss=0.08869, mel_loss=0.03775, linear_loss=0.04929]
[2020-05-12 06:11:23.928]  Step 154481  [3.341 sec/step, loss=0.09560, avg_loss=0.08890, mel_loss=0.04242, linear_loss=0.05319]
[2020-05-12 06:11:25.006]  Step 154482  [3.282 sec/step, loss=0.07991, avg_loss=0.08875, mel_loss=0.03398, linear_loss=0.04593]
[2020-05-12 06:11:25.724]  Generated 32 batches of size 32 in 1.789 sec
[2020-05-12 06:11:26.398]  Step 154483  [3.285 sec/step, loss=0.08568, avg_loss=0.08879, mel_loss=0.03724, linear_loss=0.04844]
[2020-05-12 06:11:28.059]  Step 154484  [3.291 sec/step, loss=0.08696, avg_loss=0.08886, mel_loss=0.03806, linear_loss=0.04890]
[2020-05-12 06:11:31.816]  Step 154485  [3.318 sec/step, loss=0.09430, avg_loss=0.08900, mel_loss=0.04216, linear_loss=0.05214]
[2020-05-12 06:11:33.112]  Step 154486  [3.315 sec/step, loss=0.08367, avg_loss=0.08897, mel_loss=0.03613, linear_loss=0.04754]
[2020-05-12 06:11:35.729]  Step 154487  [3.321 sec/step, loss=0.08922, avg_loss=0.08897, mel_loss=0.03923, linear_loss=0.04999]
[2020-05-12 06:11:39.957]  Step 154488  [3.317 sec/step, loss=0.09519, avg_loss=0.08895, mel_loss=0.04256, linear_loss=0.05262]
[2020-05-12 06:11:41.414]  Step 154489  [3.301 sec/step, loss=0.08834, avg_loss=0.08890, mel_loss=0.03858, linear_loss=0.04976]
[2020-05-12 06:11:47.029]  Step 154490  [3.338 sec/step, loss=0.09451, avg_loss=0.08897, mel_loss=0.04259, linear_loss=0.05192]
[2020-05-12 06:11:52.447]  Step 154491  [3.355 sec/step, loss=0.09487, avg_loss=0.08894, mel_loss=0.04299, linear_loss=0.05188]
[2020-05-12 06:11:53.259]  Step 154492  [3.335 sec/step, loss=0.07651, avg_loss=0.08879, mel_loss=0.03277, linear_loss=0.04374]
[2020-05-12 06:11:56.093]  Step 154493  [3.304 sec/step, loss=0.09152, avg_loss=0.08873, mel_loss=0.04060, linear_loss=0.05092]
[2020-05-12 06:11:57.114]  Step 154494  [3.306 sec/step, loss=0.08003, avg_loss=0.08875, mel_loss=0.03442, linear_loss=0.04561]
[2020-05-12 06:11:59.103]  Step 154495  [3.297 sec/step, loss=0.08977, avg_loss=0.08874, mel_loss=0.03923, linear_loss=0.05053]
[2020-05-12 06:12:01.552]  Step 154496  [3.285 sec/step, loss=0.09098, avg_loss=0.08870, mel_loss=0.04004, linear_loss=0.05094]
[2020-05-12 06:12:02.781]  Step 154497  [3.283 sec/step, loss=0.08298, avg_loss=0.08868, mel_loss=0.03550, linear_loss=0.04748]
[2020-05-12 06:12:04.091]  Step 154498  [3.240 sec/step, loss=0.08636, avg_loss=0.08858, mel_loss=0.03753, linear_loss=0.04883]
[2020-05-12 06:12:07.582]  Step 154499  [3.251 sec/step, loss=0.09276, avg_loss=0.08858, mel_loss=0.04138, linear_loss=0.05138]
[2020-05-12 06:12:12.325]  Step 154500  [3.277 sec/step, loss=0.09615, avg_loss=0.08864, mel_loss=0.04333, linear_loss=0.05282]
[2020-05-12 06:12:12.325]  Writing summary at step: 154500
[2020-05-12 06:12:18.026]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154500
[2020-05-12 06:12:19.547]  Saving audio and alignment...
[2020-05-12 06:12:23.357]  Input: 멘트 작성이 그리 어렵지 않습니다~___________
[2020-05-12 06:12:26.047]  Step 154501  [3.281 sec/step, loss=0.09013, avg_loss=0.08862, mel_loss=0.03963, linear_loss=0.05050]
[2020-05-12 06:12:27.873]  Step 154502  [3.283 sec/step, loss=0.08746, avg_loss=0.08861, mel_loss=0.03793, linear_loss=0.04953]
[2020-05-12 06:12:41.971]  Step 154503  [3.386 sec/step, loss=0.07607, avg_loss=0.08843, mel_loss=0.03597, linear_loss=0.04010]
[2020-05-12 06:12:45.149]  Step 154504  [3.409 sec/step, loss=0.09326, avg_loss=0.08860, mel_loss=0.04148, linear_loss=0.05177]
[2020-05-12 06:12:46.723]  Step 154505  [3.389 sec/step, loss=0.08663, avg_loss=0.08852, mel_loss=0.03768, linear_loss=0.04895]
[2020-05-12 06:12:47.513]  Step 154506  [3.363 sec/step, loss=0.07004, avg_loss=0.08828, mel_loss=0.03006, linear_loss=0.03998]
[2020-05-12 06:12:55.152]  Step 154507  [3.384 sec/step, loss=0.09634, avg_loss=0.08828, mel_loss=0.04405, linear_loss=0.05229]
[2020-05-12 06:12:56.260]  Step 154508  [3.317 sec/step, loss=0.08116, avg_loss=0.08811, mel_loss=0.03488, linear_loss=0.04628]
[2020-05-12 06:12:57.272]  Step 154509  [3.312 sec/step, loss=0.07963, avg_loss=0.08806, mel_loss=0.03407, linear_loss=0.04556]
[2020-05-12 06:13:01.635]  Step 154510  [3.345 sec/step, loss=0.09637, avg_loss=0.08823, mel_loss=0.04320, linear_loss=0.05318]
[2020-05-12 06:13:08.463]  Step 154511  [3.394 sec/step, loss=0.09764, avg_loss=0.08832, mel_loss=0.04453, linear_loss=0.05311]
[2020-05-12 06:13:10.237]  Generated 32 batches of size 32 in 1.769 sec
[2020-05-12 06:13:10.382]  Step 154512  [3.408 sec/step, loss=0.09072, avg_loss=0.08853, mel_loss=0.03917, linear_loss=0.05155]
[2020-05-12 06:13:13.353]  Step 154513  [3.389 sec/step, loss=0.09632, avg_loss=0.08852, mel_loss=0.04289, linear_loss=0.05343]
[2020-05-12 06:13:17.026]  Step 154514  [3.381 sec/step, loss=0.09421, avg_loss=0.08850, mel_loss=0.04228, linear_loss=0.05192]
[2020-05-12 06:13:18.381]  Step 154515  [3.335 sec/step, loss=0.08739, avg_loss=0.08838, mel_loss=0.03796, linear_loss=0.04942]
[2020-05-12 06:13:20.504]  Step 154516  [3.314 sec/step, loss=0.08990, avg_loss=0.08833, mel_loss=0.03969, linear_loss=0.05021]
[2020-05-12 06:13:21.066]  Step 154517  [3.251 sec/step, loss=0.06969, avg_loss=0.08804, mel_loss=0.03064, linear_loss=0.03906]
[2020-05-12 06:13:25.145]  Step 154518  [3.278 sec/step, loss=0.09578, avg_loss=0.08813, mel_loss=0.04270, linear_loss=0.05308]
[2020-05-12 06:13:34.503]  Step 154519  [3.360 sec/step, loss=0.09550, avg_loss=0.08828, mel_loss=0.04403, linear_loss=0.05146]
[2020-05-12 06:13:36.111]  Step 154520  [3.347 sec/step, loss=0.08816, avg_loss=0.08823, mel_loss=0.03859, linear_loss=0.04957]
[2020-05-12 06:13:43.479]  Step 154521  [3.413 sec/step, loss=0.09831, avg_loss=0.08851, mel_loss=0.04514, linear_loss=0.05318]
[2020-05-12 06:13:48.094]  Step 154522  [3.324 sec/step, loss=0.09533, avg_loss=0.08862, mel_loss=0.04283, linear_loss=0.05249]
[2020-05-12 06:13:48.861]  Step 154523  [3.320 sec/step, loss=0.07339, avg_loss=0.08854, mel_loss=0.03259, linear_loss=0.04080]
[2020-05-12 06:13:50.881]  Step 154524  [3.310 sec/step, loss=0.09053, avg_loss=0.08851, mel_loss=0.03991, linear_loss=0.05062]
[2020-05-12 06:13:54.534]  Step 154525  [3.316 sec/step, loss=0.09556, avg_loss=0.08857, mel_loss=0.04259, linear_loss=0.05298]
[2020-05-12 06:13:57.473]  Step 154526  [3.298 sec/step, loss=0.09373, avg_loss=0.08855, mel_loss=0.04162, linear_loss=0.05211]
[2020-05-12 06:14:03.088]  Step 154527  [3.330 sec/step, loss=0.09639, avg_loss=0.08865, mel_loss=0.04408, linear_loss=0.05230]
[2020-05-12 06:14:06.547]  Step 154528  [3.327 sec/step, loss=0.09432, avg_loss=0.08870, mel_loss=0.04217, linear_loss=0.05216]
[2020-05-12 06:14:10.695]  Step 154529  [3.320 sec/step, loss=0.09401, avg_loss=0.08868, mel_loss=0.04224, linear_loss=0.05177]
[2020-05-12 06:14:11.834]  Step 154530  [3.326 sec/step, loss=0.08282, avg_loss=0.08881, mel_loss=0.03564, linear_loss=0.04717]
[2020-05-12 06:14:13.853]  Step 154531  [3.334 sec/step, loss=0.09057, avg_loss=0.08888, mel_loss=0.03977, linear_loss=0.05080]
[2020-05-12 06:14:20.180]  Step 154532  [3.346 sec/step, loss=0.09607, avg_loss=0.08887, mel_loss=0.04389, linear_loss=0.05218]
[2020-05-12 06:14:21.382]  Step 154533  [3.331 sec/step, loss=0.08124, avg_loss=0.08878, mel_loss=0.03523, linear_loss=0.04600]
[2020-05-12 06:14:24.026]  Step 154534  [3.349 sec/step, loss=0.09154, avg_loss=0.08894, mel_loss=0.04058, linear_loss=0.05095]
[2020-05-12 06:14:29.406]  Step 154535  [3.366 sec/step, loss=0.09545, avg_loss=0.08896, mel_loss=0.04332, linear_loss=0.05213]
[2020-05-12 06:14:30.425]  Step 154536  [3.367 sec/step, loss=0.07867, avg_loss=0.08897, mel_loss=0.03362, linear_loss=0.04504]
[2020-05-12 06:14:31.422]  Step 154537  [3.342 sec/step, loss=0.08183, avg_loss=0.08885, mel_loss=0.03504, linear_loss=0.04679]
[2020-05-12 06:14:33.151]  Step 154538  [3.348 sec/step, loss=0.08830, avg_loss=0.08891, mel_loss=0.03865, linear_loss=0.04965]
[2020-05-12 06:14:34.661]  Step 154539  [3.213 sec/step, loss=0.08668, avg_loss=0.08900, mel_loss=0.03770, linear_loss=0.04898]
[2020-05-12 06:14:35.975]  Step 154540  [3.213 sec/step, loss=0.08414, avg_loss=0.08898, mel_loss=0.03620, linear_loss=0.04794]
[2020-05-12 06:14:44.853]  Step 154541  [3.284 sec/step, loss=0.09398, avg_loss=0.08904, mel_loss=0.04336, linear_loss=0.05062]
[2020-05-12 06:14:47.281]  Step 154542  [3.289 sec/step, loss=0.09042, avg_loss=0.08907, mel_loss=0.03970, linear_loss=0.05072]
[2020-05-12 06:14:49.429]  Step 154543  [3.253 sec/step, loss=0.09245, avg_loss=0.08903, mel_loss=0.04062, linear_loss=0.05182]
[2020-05-12 06:14:51.373]  Generated 32 batches of size 32 in 1.938 sec
[2020-05-12 06:14:52.947]  Step 154544  [3.200 sec/step, loss=0.09370, avg_loss=0.08900, mel_loss=0.04190, linear_loss=0.05180]
[2020-05-12 06:14:53.795]  Step 154545  [3.142 sec/step, loss=0.07767, avg_loss=0.08882, mel_loss=0.03330, linear_loss=0.04437]
[2020-05-12 06:14:55.631]  Step 154546  [3.106 sec/step, loss=0.08837, avg_loss=0.08873, mel_loss=0.03850, linear_loss=0.04987]
[2020-05-12 06:14:57.245]  Step 154547  [3.106 sec/step, loss=0.08778, avg_loss=0.08873, mel_loss=0.03861, linear_loss=0.04917]
[2020-05-12 06:15:09.726]  Step 154548  [3.205 sec/step, loss=0.08683, avg_loss=0.08868, mel_loss=0.04094, linear_loss=0.04589]
[2020-05-12 06:15:12.237]  Step 154549  [3.216 sec/step, loss=0.08925, avg_loss=0.08872, mel_loss=0.03902, linear_loss=0.05023]
[2020-05-12 06:15:16.328]  Step 154550  [3.248 sec/step, loss=0.09784, avg_loss=0.08897, mel_loss=0.04392, linear_loss=0.05392]
[2020-05-12 06:15:16.328]  Writing summary at step: 154550
[2020-05-12 06:15:19.522]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154550
[2020-05-12 06:15:22.725]  Saving audio and alignment...
[2020-05-12 06:15:24.397]  Input: 행복을~_________
[2020-05-12 06:15:25.987]  Step 154551  [3.223 sec/step, loss=0.08604, avg_loss=0.08888, mel_loss=0.03751, linear_loss=0.04853]
[2020-05-12 06:15:34.929]  Step 154552  [3.279 sec/step, loss=0.09539, avg_loss=0.08889, mel_loss=0.04394, linear_loss=0.05145]
[2020-05-12 06:15:35.871]  Step 154553  [3.248 sec/step, loss=0.07568, avg_loss=0.08868, mel_loss=0.03218, linear_loss=0.04350]
[2020-05-12 06:15:38.913]  Step 154554  [3.254 sec/step, loss=0.09095, avg_loss=0.08869, mel_loss=0.04045, linear_loss=0.05050]
[2020-05-12 06:15:40.574]  Step 154555  [3.259 sec/step, loss=0.08889, avg_loss=0.08879, mel_loss=0.03889, linear_loss=0.05000]
[2020-05-12 06:15:42.600]  Step 154556  [3.248 sec/step, loss=0.09161, avg_loss=0.08879, mel_loss=0.04031, linear_loss=0.05130]
[2020-05-12 06:15:43.951]  Step 154557  [3.241 sec/step, loss=0.08518, avg_loss=0.08873, mel_loss=0.03704, linear_loss=0.04814]
[2020-05-12 06:15:51.457]  Step 154558  [3.286 sec/step, loss=0.09657, avg_loss=0.08876, mel_loss=0.04430, linear_loss=0.05227]
[2020-05-12 06:15:57.063]  Step 154559  [3.332 sec/step, loss=0.09662, avg_loss=0.08891, mel_loss=0.04368, linear_loss=0.05294]
[2020-05-12 06:15:59.205]  Step 154560  [3.334 sec/step, loss=0.09087, avg_loss=0.08894, mel_loss=0.03980, linear_loss=0.05108]
[2020-05-12 06:16:02.105]  Step 154561  [3.352 sec/step, loss=0.09358, avg_loss=0.08904, mel_loss=0.04146, linear_loss=0.05211]
[2020-05-12 06:16:03.016]  Step 154562  [3.353 sec/step, loss=0.07769, avg_loss=0.08906, mel_loss=0.03336, linear_loss=0.04433]
[2020-05-12 06:16:05.467]  Step 154563  [3.348 sec/step, loss=0.09100, avg_loss=0.08905, mel_loss=0.04002, linear_loss=0.05098]
[2020-05-12 06:16:08.682]  Step 154564  [3.331 sec/step, loss=0.09476, avg_loss=0.08904, mel_loss=0.04205, linear_loss=0.05271]
[2020-05-12 06:16:09.909]  Step 154565  [3.255 sec/step, loss=0.08110, avg_loss=0.08892, mel_loss=0.03485, linear_loss=0.04625]
[2020-05-12 06:16:15.123]  Step 154566  [3.289 sec/step, loss=0.09535, avg_loss=0.08901, mel_loss=0.04317, linear_loss=0.05218]
[2020-05-12 06:16:18.739]  Step 154567  [3.290 sec/step, loss=0.09561, avg_loss=0.08903, mel_loss=0.04282, linear_loss=0.05279]
[2020-05-12 06:16:19.835]  Step 154568  [3.255 sec/step, loss=0.08180, avg_loss=0.08888, mel_loss=0.03514, linear_loss=0.04666]
[2020-05-12 06:16:26.155]  Step 154569  [3.291 sec/step, loss=0.09575, avg_loss=0.08893, mel_loss=0.04359, linear_loss=0.05215]
[2020-05-12 06:16:27.549]  Step 154570  [3.243 sec/step, loss=0.08551, avg_loss=0.08882, mel_loss=0.03717, linear_loss=0.04834]
[2020-05-12 06:16:28.333]  Step 154571  [3.179 sec/step, loss=0.07167, avg_loss=0.08856, mel_loss=0.03091, linear_loss=0.04076]
[2020-05-12 06:16:42.518]  Step 154572  [3.188 sec/step, loss=0.07633, avg_loss=0.08852, mel_loss=0.03591, linear_loss=0.04043]
[2020-05-12 06:16:45.929]  Step 154573  [3.216 sec/step, loss=0.09347, avg_loss=0.08870, mel_loss=0.04173, linear_loss=0.05174]
[2020-05-12 06:16:47.744]  Generated 32 batches of size 32 in 1.809 sec
[2020-05-12 06:16:47.958]  Step 154574  [3.214 sec/step, loss=0.08752, avg_loss=0.08865, mel_loss=0.03813, linear_loss=0.04938]
[2020-05-12 06:16:48.515]  Step 154575  [3.197 sec/step, loss=0.07100, avg_loss=0.08847, mel_loss=0.03073, linear_loss=0.04027]
[2020-05-12 06:16:50.883]  Step 154576  [3.192 sec/step, loss=0.08908, avg_loss=0.08843, mel_loss=0.03918, linear_loss=0.04989]
[2020-05-12 06:16:54.987]  Step 154577  [3.228 sec/step, loss=0.09452, avg_loss=0.08869, mel_loss=0.04225, linear_loss=0.05227]
[2020-05-12 06:16:58.025]  Step 154578  [3.238 sec/step, loss=0.09477, avg_loss=0.08875, mel_loss=0.04225, linear_loss=0.05252]
[2020-05-12 06:17:02.356]  Step 154579  [3.238 sec/step, loss=0.09587, avg_loss=0.08876, mel_loss=0.04312, linear_loss=0.05275]
[2020-05-12 06:17:04.095]  Step 154580  [3.241 sec/step, loss=0.08812, avg_loss=0.08877, mel_loss=0.03828, linear_loss=0.04984]
[2020-05-12 06:17:08.775]  Step 154581  [3.257 sec/step, loss=0.09523, avg_loss=0.08877, mel_loss=0.04301, linear_loss=0.05223]
[2020-05-12 06:17:09.792]  Step 154582  [3.257 sec/step, loss=0.07842, avg_loss=0.08875, mel_loss=0.03377, linear_loss=0.04465]
[2020-05-12 06:17:22.933]  Step 154583  [3.374 sec/step, loss=0.07894, avg_loss=0.08869, mel_loss=0.03713, linear_loss=0.04182]
[2020-05-12 06:17:26.084]  Step 154584  [3.389 sec/step, loss=0.09330, avg_loss=0.08875, mel_loss=0.04167, linear_loss=0.05163]
[2020-05-12 06:17:27.155]  Step 154585  [3.362 sec/step, loss=0.08113, avg_loss=0.08862, mel_loss=0.03490, linear_loss=0.04623]
[2020-05-12 06:17:28.474]  Step 154586  [3.362 sec/step, loss=0.08312, avg_loss=0.08861, mel_loss=0.03632, linear_loss=0.04680]
[2020-05-12 06:17:30.200]  Step 154587  [3.353 sec/step, loss=0.08908, avg_loss=0.08861, mel_loss=0.03853, linear_loss=0.05055]
[2020-05-12 06:17:37.134]  Step 154588  [3.381 sec/step, loss=0.09973, avg_loss=0.08866, mel_loss=0.04576, linear_loss=0.05396]
[2020-05-12 06:17:41.260]  Step 154589  [3.407 sec/step, loss=0.09366, avg_loss=0.08871, mel_loss=0.04199, linear_loss=0.05167]
[2020-05-12 06:17:42.735]  Step 154590  [3.366 sec/step, loss=0.08594, avg_loss=0.08862, mel_loss=0.03737, linear_loss=0.04857]
[2020-05-12 06:17:50.922]  Step 154591  [3.393 sec/step, loss=0.09502, avg_loss=0.08862, mel_loss=0.04364, linear_loss=0.05138]
[2020-05-12 06:17:52.102]  Step 154592  [3.397 sec/step, loss=0.08000, avg_loss=0.08866, mel_loss=0.03426, linear_loss=0.04574]
[2020-05-12 06:17:54.135]  Step 154593  [3.389 sec/step, loss=0.09017, avg_loss=0.08865, mel_loss=0.03973, linear_loss=0.05044]
[2020-05-12 06:17:58.513]  Step 154594  [3.423 sec/step, loss=0.09715, avg_loss=0.08882, mel_loss=0.04366, linear_loss=0.05349]
[2020-05-12 06:18:00.491]  Step 154595  [3.423 sec/step, loss=0.08869, avg_loss=0.08881, mel_loss=0.03888, linear_loss=0.04980]
[2020-05-12 06:18:03.345]  Step 154596  [3.427 sec/step, loss=0.09122, avg_loss=0.08881, mel_loss=0.04075, linear_loss=0.05048]
[2020-05-12 06:18:06.905]  Step 154597  [3.450 sec/step, loss=0.09473, avg_loss=0.08893, mel_loss=0.04223, linear_loss=0.05250]
[2020-05-12 06:18:10.684]  Step 154598  [3.475 sec/step, loss=0.09644, avg_loss=0.08903, mel_loss=0.04311, linear_loss=0.05333]
[2020-05-12 06:18:12.273]  Step 154599  [3.456 sec/step, loss=0.08081, avg_loss=0.08891, mel_loss=0.03470, linear_loss=0.04611]
[2020-05-12 06:18:20.688]  Step 154600  [3.492 sec/step, loss=0.09825, avg_loss=0.08893, mel_loss=0.04490, linear_loss=0.05336]
[2020-05-12 06:18:20.688]  Writing summary at step: 154600
[2020-05-12 06:18:22.618]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154600
[2020-05-12 06:18:24.201]  Saving audio and alignment...
[2020-05-12 06:18:25.523]  Input: 다음~________
[2020-05-12 06:18:26.420]  Step 154601  [3.474 sec/step, loss=0.07840, avg_loss=0.08881, mel_loss=0.03347, linear_loss=0.04493]
[2020-05-12 06:18:28.679]  Step 154602  [3.479 sec/step, loss=0.09033, avg_loss=0.08884, mel_loss=0.03980, linear_loss=0.05053]
[2020-05-12 06:18:29.494]  Step 154603  [3.346 sec/step, loss=0.07754, avg_loss=0.08885, mel_loss=0.03306, linear_loss=0.04448]
[2020-05-12 06:18:31.246]  Generated 32 batches of size 32 in 1.747 sec
[2020-05-12 06:18:32.599]  Step 154604  [3.345 sec/step, loss=0.09144, avg_loss=0.08884, mel_loss=0.04064, linear_loss=0.05080]
[2020-05-12 06:18:35.261]  Step 154605  [3.356 sec/step, loss=0.09224, avg_loss=0.08889, mel_loss=0.04081, linear_loss=0.05142]
[2020-05-12 06:18:41.481]  Step 154606  [3.410 sec/step, loss=0.09408, avg_loss=0.08913, mel_loss=0.04284, linear_loss=0.05124]
[2020-05-12 06:18:43.267]  Step 154607  [3.352 sec/step, loss=0.08812, avg_loss=0.08905, mel_loss=0.03868, linear_loss=0.04944]
[2020-05-12 06:18:43.885]  Step 154608  [3.347 sec/step, loss=0.07143, avg_loss=0.08895, mel_loss=0.03105, linear_loss=0.04038]
[2020-05-12 06:18:47.253]  Step 154609  [3.371 sec/step, loss=0.09576, avg_loss=0.08911, mel_loss=0.04284, linear_loss=0.05292]
[2020-05-12 06:18:52.033]  Step 154610  [3.375 sec/step, loss=0.09647, avg_loss=0.08912, mel_loss=0.04362, linear_loss=0.05286]
[2020-05-12 06:18:54.462]  Step 154611  [3.331 sec/step, loss=0.09145, avg_loss=0.08905, mel_loss=0.04033, linear_loss=0.05112]
[2020-05-12 06:18:56.125]  Step 154612  [3.328 sec/step, loss=0.08667, avg_loss=0.08901, mel_loss=0.03783, linear_loss=0.04884]
[2020-05-12 06:18:56.888]  Step 154613  [3.306 sec/step, loss=0.07495, avg_loss=0.08880, mel_loss=0.03223, linear_loss=0.04272]
[2020-05-12 06:18:57.662]  Step 154614  [3.277 sec/step, loss=0.07395, avg_loss=0.08860, mel_loss=0.03263, linear_loss=0.04132]
[2020-05-12 06:18:59.055]  Step 154615  [3.277 sec/step, loss=0.08666, avg_loss=0.08859, mel_loss=0.03757, linear_loss=0.04909]
[2020-05-12 06:19:02.673]  Step 154616  [3.292 sec/step, loss=0.09610, avg_loss=0.08865, mel_loss=0.04279, linear_loss=0.05332]
[2020-05-12 06:19:03.742]  Step 154617  [3.297 sec/step, loss=0.08308, avg_loss=0.08879, mel_loss=0.03574, linear_loss=0.04734]
[2020-05-12 06:19:07.160]  Step 154618  [3.291 sec/step, loss=0.09601, avg_loss=0.08879, mel_loss=0.04275, linear_loss=0.05326]
[2020-05-12 06:19:08.748]  Step 154619  [3.213 sec/step, loss=0.08929, avg_loss=0.08873, mel_loss=0.03888, linear_loss=0.05042]
[2020-05-12 06:19:10.254]  Step 154620  [3.212 sec/step, loss=0.08731, avg_loss=0.08872, mel_loss=0.03785, linear_loss=0.04947]
[2020-05-12 06:19:11.240]  Step 154621  [3.148 sec/step, loss=0.07832, avg_loss=0.08852, mel_loss=0.03364, linear_loss=0.04468]
[2020-05-12 06:19:12.119]  Step 154622  [3.111 sec/step, loss=0.07565, avg_loss=0.08832, mel_loss=0.03239, linear_loss=0.04326]
[2020-05-12 06:19:21.586]  Step 154623  [3.198 sec/step, loss=0.09755, avg_loss=0.08856, mel_loss=0.04520, linear_loss=0.05235]
[2020-05-12 06:19:25.392]  Step 154624  [3.216 sec/step, loss=0.09762, avg_loss=0.08863, mel_loss=0.04367, linear_loss=0.05395]
[2020-05-12 06:19:27.681]  Step 154625  [3.202 sec/step, loss=0.09005, avg_loss=0.08858, mel_loss=0.03963, linear_loss=0.05042]
[2020-05-12 06:19:28.841]  Step 154626  [3.184 sec/step, loss=0.08183, avg_loss=0.08846, mel_loss=0.03496, linear_loss=0.04687]
[2020-05-12 06:19:35.419]  Step 154627  [3.194 sec/step, loss=0.09636, avg_loss=0.08846, mel_loss=0.04421, linear_loss=0.05215]
[2020-05-12 06:19:39.625]  Step 154628  [3.201 sec/step, loss=0.09534, avg_loss=0.08847, mel_loss=0.04262, linear_loss=0.05272]
[2020-05-12 06:19:42.273]  Step 154629  [3.186 sec/step, loss=0.08926, avg_loss=0.08842, mel_loss=0.03930, linear_loss=0.04996]
[2020-05-12 06:19:43.543]  Step 154630  [3.188 sec/step, loss=0.08329, avg_loss=0.08843, mel_loss=0.03622, linear_loss=0.04707]
[2020-05-12 06:19:48.043]  Step 154631  [3.213 sec/step, loss=0.09673, avg_loss=0.08849, mel_loss=0.04368, linear_loss=0.05305]
[2020-05-12 06:19:52.897]  Step 154632  [3.198 sec/step, loss=0.09408, avg_loss=0.08847, mel_loss=0.04238, linear_loss=0.05170]
[2020-05-12 06:19:55.306]  Step 154633  [3.210 sec/step, loss=0.09145, avg_loss=0.08857, mel_loss=0.04014, linear_loss=0.05131]
[2020-05-12 06:20:09.249]  Step 154634  [3.323 sec/step, loss=0.07635, avg_loss=0.08842, mel_loss=0.03612, linear_loss=0.04023]
[2020-05-12 06:20:15.206]  Step 154635  [3.329 sec/step, loss=0.09826, avg_loss=0.08845, mel_loss=0.04467, linear_loss=0.05359]
[2020-05-12 06:20:16.955]  Generated 32 batches of size 32 in 1.742 sec
[2020-05-12 06:20:18.340]  Step 154636  [3.350 sec/step, loss=0.09445, avg_loss=0.08860, mel_loss=0.04186, linear_loss=0.05259]
[2020-05-12 06:20:20.226]  Step 154637  [3.359 sec/step, loss=0.08942, avg_loss=0.08868, mel_loss=0.03897, linear_loss=0.05045]
[2020-05-12 06:20:22.431]  Step 154638  [3.364 sec/step, loss=0.09137, avg_loss=0.08871, mel_loss=0.04028, linear_loss=0.05109]
[2020-05-12 06:20:27.752]  Step 154639  [3.402 sec/step, loss=0.09605, avg_loss=0.08880, mel_loss=0.04329, linear_loss=0.05276]
[2020-05-12 06:20:35.460]  Step 154640  [3.466 sec/step, loss=0.09796, avg_loss=0.08894, mel_loss=0.04506, linear_loss=0.05289]
[2020-05-12 06:20:37.205]  Step 154641  [3.394 sec/step, loss=0.08712, avg_loss=0.08887, mel_loss=0.03793, linear_loss=0.04918]
[2020-05-12 06:20:39.148]  Step 154642  [3.389 sec/step, loss=0.08853, avg_loss=0.08886, mel_loss=0.03888, linear_loss=0.04965]
[2020-05-12 06:20:42.607]  Step 154643  [3.402 sec/step, loss=0.09203, avg_loss=0.08885, mel_loss=0.04118, linear_loss=0.05085]
[2020-05-12 06:20:45.714]  Step 154644  [3.398 sec/step, loss=0.09385, avg_loss=0.08885, mel_loss=0.04155, linear_loss=0.05231]
[2020-05-12 06:20:53.098]  Step 154645  [3.464 sec/step, loss=0.09756, avg_loss=0.08905, mel_loss=0.04483, linear_loss=0.05273]
[2020-05-12 06:20:56.576]  Step 154646  [3.480 sec/step, loss=0.09675, avg_loss=0.08914, mel_loss=0.04323, linear_loss=0.05352]
[2020-05-12 06:20:58.360]  Step 154647  [3.482 sec/step, loss=0.08831, avg_loss=0.08914, mel_loss=0.03844, linear_loss=0.04986]
[2020-05-12 06:21:07.111]  Step 154648  [3.445 sec/step, loss=0.09716, avg_loss=0.08924, mel_loss=0.04494, linear_loss=0.05223]
[2020-05-12 06:21:21.104]  Step 154649  [3.559 sec/step, loss=0.07499, avg_loss=0.08910, mel_loss=0.03542, linear_loss=0.03957]
[2020-05-12 06:21:22.538]  Step 154650  [3.533 sec/step, loss=0.08559, avg_loss=0.08898, mel_loss=0.03733, linear_loss=0.04826]
[2020-05-12 06:21:22.538]  Writing summary at step: 154650
[2020-05-12 06:21:25.010]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154650
[2020-05-12 06:21:26.547]  Saving audio and alignment...
[2020-05-12 06:21:31.842]  Input: 빨간색 계열을 입으시는 것이 훨씬 센스있 선택입니다~________________
[2020-05-12 06:21:32.598]  Step 154651  [3.524 sec/step, loss=0.07956, avg_loss=0.08891, mel_loss=0.03407, linear_loss=0.04550]
[2020-05-12 06:21:33.436]  Step 154652  [3.443 sec/step, loss=0.07623, avg_loss=0.08872, mel_loss=0.03333, linear_loss=0.04290]
[2020-05-12 06:21:38.289]  Step 154653  [3.483 sec/step, loss=0.09518, avg_loss=0.08892, mel_loss=0.04296, linear_loss=0.05223]
[2020-05-12 06:21:45.049]  Step 154654  [3.520 sec/step, loss=0.09690, avg_loss=0.08898, mel_loss=0.04431, linear_loss=0.05259]
[2020-05-12 06:21:47.272]  Step 154655  [3.525 sec/step, loss=0.08928, avg_loss=0.08898, mel_loss=0.03958, linear_loss=0.04970]
[2020-05-12 06:21:48.191]  Step 154656  [3.514 sec/step, loss=0.07743, avg_loss=0.08884, mel_loss=0.03329, linear_loss=0.04414]
[2020-05-12 06:21:51.071]  Step 154657  [3.530 sec/step, loss=0.09571, avg_loss=0.08894, mel_loss=0.04265, linear_loss=0.05306]
[2020-05-12 06:21:52.386]  Step 154658  [3.468 sec/step, loss=0.08435, avg_loss=0.08882, mel_loss=0.03618, linear_loss=0.04816]
[2020-05-12 06:21:57.839]  Step 154659  [3.466 sec/step, loss=0.09789, avg_loss=0.08883, mel_loss=0.04450, linear_loss=0.05339]
[2020-05-12 06:22:03.593]  Step 154660  [3.502 sec/step, loss=0.09776, avg_loss=0.08890, mel_loss=0.04466, linear_loss=0.05310]
[2020-05-12 06:22:05.611]  Step 154661  [3.493 sec/step, loss=0.08982, avg_loss=0.08887, mel_loss=0.03948, linear_loss=0.05034]
[2020-05-12 06:22:07.570]  Step 154662  [3.504 sec/step, loss=0.08883, avg_loss=0.08898, mel_loss=0.03874, linear_loss=0.05009]
[2020-05-12 06:22:11.045]  Step 154663  [3.514 sec/step, loss=0.09261, avg_loss=0.08899, mel_loss=0.04152, linear_loss=0.05109]
[2020-05-12 06:22:12.210]  Step 154664  [3.494 sec/step, loss=0.08172, avg_loss=0.08886, mel_loss=0.03514, linear_loss=0.04658]
[2020-05-12 06:22:16.633]  Step 154665  [3.526 sec/step, loss=0.09726, avg_loss=0.08902, mel_loss=0.04408, linear_loss=0.05318]
[2020-05-12 06:22:18.360]  Generated 32 batches of size 32 in 1.720 sec
[2020-05-12 06:22:20.957]  Step 154666  [3.517 sec/step, loss=0.09591, avg_loss=0.08903, mel_loss=0.04309, linear_loss=0.05282]
[2020-05-12 06:22:21.940]  Step 154667  [3.490 sec/step, loss=0.08220, avg_loss=0.08890, mel_loss=0.03512, linear_loss=0.04708]
[2020-05-12 06:22:23.579]  Step 154668  [3.496 sec/step, loss=0.08711, avg_loss=0.08895, mel_loss=0.03805, linear_loss=0.04906]
[2020-05-12 06:22:24.691]  Step 154669  [3.444 sec/step, loss=0.08079, avg_loss=0.08880, mel_loss=0.03465, linear_loss=0.04614]
[2020-05-12 06:22:25.248]  Step 154670  [3.435 sec/step, loss=0.06789, avg_loss=0.08862, mel_loss=0.02986, linear_loss=0.03804]
[2020-05-12 06:22:27.906]  Step 154671  [3.454 sec/step, loss=0.09260, avg_loss=0.08883, mel_loss=0.04117, linear_loss=0.05142]
[2020-05-12 06:22:29.461]  Step 154672  [3.328 sec/step, loss=0.08539, avg_loss=0.08892, mel_loss=0.03693, linear_loss=0.04846]
[2020-05-12 06:22:32.057]  Step 154673  [3.320 sec/step, loss=0.08948, avg_loss=0.08888, mel_loss=0.03944, linear_loss=0.05004]
[2020-05-12 06:22:35.791]  Step 154674  [3.337 sec/step, loss=0.09598, avg_loss=0.08897, mel_loss=0.04288, linear_loss=0.05310]
[2020-05-12 06:22:37.561]  Step 154675  [3.349 sec/step, loss=0.08800, avg_loss=0.08914, mel_loss=0.03840, linear_loss=0.04960]
[2020-05-12 06:22:39.624]  Step 154676  [3.346 sec/step, loss=0.09192, avg_loss=0.08917, mel_loss=0.04043, linear_loss=0.05149]
[2020-05-12 06:22:42.773]  Step 154677  [3.336 sec/step, loss=0.09619, avg_loss=0.08918, mel_loss=0.04298, linear_loss=0.05321]
[2020-05-12 06:22:44.972]  Step 154678  [3.328 sec/step, loss=0.08955, avg_loss=0.08913, mel_loss=0.03930, linear_loss=0.05025]
[2020-05-12 06:22:46.369]  Step 154679  [3.298 sec/step, loss=0.08700, avg_loss=0.08904, mel_loss=0.03798, linear_loss=0.04902]
[2020-05-12 06:22:47.952]  Step 154680  [3.297 sec/step, loss=0.08718, avg_loss=0.08903, mel_loss=0.03835, linear_loss=0.04883]
[2020-05-12 06:22:48.942]  Step 154681  [3.260 sec/step, loss=0.08219, avg_loss=0.08890, mel_loss=0.03557, linear_loss=0.04662]
[2020-05-12 06:22:49.937]  Step 154682  [3.260 sec/step, loss=0.08100, avg_loss=0.08893, mel_loss=0.03449, linear_loss=0.04650]
[2020-05-12 06:22:52.445]  Step 154683  [3.153 sec/step, loss=0.09353, avg_loss=0.08907, mel_loss=0.04126, linear_loss=0.05227]
[2020-05-12 06:22:55.260]  Step 154684  [3.150 sec/step, loss=0.08981, avg_loss=0.08904, mel_loss=0.03989, linear_loss=0.04991]
[2020-05-12 06:22:55.815]  Step 154685  [3.145 sec/step, loss=0.07134, avg_loss=0.08894, mel_loss=0.03106, linear_loss=0.04027]
[2020-05-12 06:22:57.830]  Step 154686  [3.152 sec/step, loss=0.09165, avg_loss=0.08903, mel_loss=0.04012, linear_loss=0.05153]
[2020-05-12 06:23:03.597]  Step 154687  [3.192 sec/step, loss=0.09823, avg_loss=0.08912, mel_loss=0.04486, linear_loss=0.05337]
[2020-05-12 06:23:10.735]  Step 154688  [3.194 sec/step, loss=0.09730, avg_loss=0.08909, mel_loss=0.04436, linear_loss=0.05294]
[2020-05-12 06:23:15.035]  Step 154689  [3.196 sec/step, loss=0.09702, avg_loss=0.08913, mel_loss=0.04366, linear_loss=0.05336]
[2020-05-12 06:23:18.065]  Step 154690  [3.212 sec/step, loss=0.09242, avg_loss=0.08919, mel_loss=0.04085, linear_loss=0.05157]
[2020-05-12 06:23:21.529]  Step 154691  [3.164 sec/step, loss=0.09589, avg_loss=0.08920, mel_loss=0.04281, linear_loss=0.05308]
[2020-05-12 06:23:25.647]  Step 154692  [3.194 sec/step, loss=0.09684, avg_loss=0.08937, mel_loss=0.04334, linear_loss=0.05350]
[2020-05-12 06:23:26.454]  Step 154693  [3.182 sec/step, loss=0.07640, avg_loss=0.08923, mel_loss=0.03241, linear_loss=0.04399]
[2020-05-12 06:23:28.368]  Step 154694  [3.157 sec/step, loss=0.08890, avg_loss=0.08915, mel_loss=0.03880, linear_loss=0.05009]
[2020-05-12 06:23:31.986]  Step 154695  [3.173 sec/step, loss=0.09578, avg_loss=0.08922, mel_loss=0.04286, linear_loss=0.05292]
[2020-05-12 06:23:36.930]  Step 154696  [3.194 sec/step, loss=0.09501, avg_loss=0.08926, mel_loss=0.04304, linear_loss=0.05196]
[2020-05-12 06:23:49.924]  Step 154697  [3.289 sec/step, loss=0.08124, avg_loss=0.08912, mel_loss=0.03831, linear_loss=0.04293]
[2020-05-12 06:23:51.586]  Generated 32 batches of size 32 in 1.657 sec
[2020-05-12 06:23:52.402]  Step 154698  [3.276 sec/step, loss=0.09316, avg_loss=0.08909, mel_loss=0.04098, linear_loss=0.05218]
[2020-05-12 06:23:53.502]  Step 154699  [3.271 sec/step, loss=0.08379, avg_loss=0.08912, mel_loss=0.03581, linear_loss=0.04797]
[2020-05-12 06:24:01.464]  Step 154700  [3.266 sec/step, loss=0.09585, avg_loss=0.08910, mel_loss=0.04393, linear_loss=0.05192]
[2020-05-12 06:24:01.464]  Writing summary at step: 154700
[2020-05-12 06:24:06.216]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154700
[2020-05-12 06:24:07.773]  Saving audio and alignment...
[2020-05-12 06:24:10.310]  Input: 예문으로 연습해 보죠~___________
[2020-05-12 06:24:11.069]  Step 154701  [3.265 sec/step, loss=0.07531, avg_loss=0.08907, mel_loss=0.03214, linear_loss=0.04317]
[2020-05-12 06:24:12.778]  Step 154702  [3.259 sec/step, loss=0.08768, avg_loss=0.08904, mel_loss=0.03828, linear_loss=0.04940]
[2020-05-12 06:24:14.008]  Step 154703  [3.263 sec/step, loss=0.08298, avg_loss=0.08909, mel_loss=0.03639, linear_loss=0.04659]
[2020-05-12 06:24:17.424]  Step 154704  [3.267 sec/step, loss=0.09341, avg_loss=0.08911, mel_loss=0.04156, linear_loss=0.05184]
[2020-05-12 06:24:21.390]  Step 154705  [3.280 sec/step, loss=0.09326, avg_loss=0.08912, mel_loss=0.04158, linear_loss=0.05169]
[2020-05-12 06:24:35.696]  Step 154706  [3.360 sec/step, loss=0.07746, avg_loss=0.08896, mel_loss=0.03669, linear_loss=0.04077]
[2020-05-12 06:24:38.860]  Step 154707  [3.374 sec/step, loss=0.09355, avg_loss=0.08901, mel_loss=0.04163, linear_loss=0.05192]
[2020-05-12 06:24:40.103]  Step 154708  [3.380 sec/step, loss=0.08527, avg_loss=0.08915, mel_loss=0.03692, linear_loss=0.04835]
[2020-05-12 06:24:42.043]  Step 154709  [3.366 sec/step, loss=0.08946, avg_loss=0.08909, mel_loss=0.03911, linear_loss=0.05035]
[2020-05-12 06:24:43.384]  Step 154710  [3.332 sec/step, loss=0.08459, avg_loss=0.08897, mel_loss=0.03685, linear_loss=0.04774]
[2020-05-12 06:24:45.001]  Step 154711  [3.324 sec/step, loss=0.08611, avg_loss=0.08891, mel_loss=0.03747, linear_loss=0.04864]
[2020-05-12 06:24:46.794]  Step 154712  [3.325 sec/step, loss=0.08753, avg_loss=0.08892, mel_loss=0.03808, linear_loss=0.04945]
[2020-05-12 06:24:47.601]  Step 154713  [3.325 sec/step, loss=0.07368, avg_loss=0.08891, mel_loss=0.03145, linear_loss=0.04224]
[2020-05-12 06:24:49.028]  Step 154714  [3.332 sec/step, loss=0.08259, avg_loss=0.08900, mel_loss=0.03581, linear_loss=0.04678]
[2020-05-12 06:24:49.589]  Step 154715  [3.324 sec/step, loss=0.06952, avg_loss=0.08883, mel_loss=0.03045, linear_loss=0.03907]
[2020-05-12 06:24:53.980]  Step 154716  [3.331 sec/step, loss=0.09583, avg_loss=0.08882, mel_loss=0.04304, linear_loss=0.05278]
[2020-05-12 06:24:56.523]  Step 154717  [3.346 sec/step, loss=0.09026, avg_loss=0.08889, mel_loss=0.03960, linear_loss=0.05066]
[2020-05-12 06:25:05.584]  Step 154718  [3.402 sec/step, loss=0.09576, avg_loss=0.08889, mel_loss=0.04442, linear_loss=0.05134]
[2020-05-12 06:25:07.759]  Step 154719  [3.408 sec/step, loss=0.09167, avg_loss=0.08892, mel_loss=0.04047, linear_loss=0.05120]
[2020-05-12 06:25:08.873]  Step 154720  [3.404 sec/step, loss=0.08472, avg_loss=0.08889, mel_loss=0.03668, linear_loss=0.04804]
[2020-05-12 06:25:09.893]  Step 154721  [3.405 sec/step, loss=0.08014, avg_loss=0.08891, mel_loss=0.03464, linear_loss=0.04550]
[2020-05-12 06:25:12.677]  Step 154722  [3.424 sec/step, loss=0.09253, avg_loss=0.08908, mel_loss=0.04121, linear_loss=0.05133]
[2020-05-12 06:25:13.509]  Step 154723  [3.337 sec/step, loss=0.07534, avg_loss=0.08885, mel_loss=0.03209, linear_loss=0.04325]
[2020-05-12 06:25:18.351]  Step 154724  [3.348 sec/step, loss=0.09579, avg_loss=0.08884, mel_loss=0.04306, linear_loss=0.05273]
[2020-05-12 06:25:20.743]  Step 154725  [3.349 sec/step, loss=0.09049, avg_loss=0.08884, mel_loss=0.03991, linear_loss=0.05058]
[2020-05-12 06:25:22.436]  Step 154726  [3.354 sec/step, loss=0.08751, avg_loss=0.08890, mel_loss=0.03839, linear_loss=0.04912]
[2020-05-12 06:25:28.390]  Step 154727  [3.348 sec/step, loss=0.09640, avg_loss=0.08890, mel_loss=0.04396, linear_loss=0.05244]
[2020-05-12 06:25:30.191]  Generated 32 batches of size 32 in 1.795 sec
[2020-05-12 06:25:30.622]  Step 154728  [3.328 sec/step, loss=0.08873, avg_loss=0.08883, mel_loss=0.03894, linear_loss=0.04979]
[2020-05-12 06:25:33.641]  Step 154729  [3.332 sec/step, loss=0.09375, avg_loss=0.08888, mel_loss=0.04158, linear_loss=0.05217]
[2020-05-12 06:25:37.218]  Step 154730  [3.355 sec/step, loss=0.09342, avg_loss=0.08898, mel_loss=0.04187, linear_loss=0.05155]
[2020-05-12 06:25:40.621]  Step 154731  [3.344 sec/step, loss=0.09448, avg_loss=0.08896, mel_loss=0.04202, linear_loss=0.05246]
[2020-05-12 06:25:41.510]  Step 154732  [3.304 sec/step, loss=0.07911, avg_loss=0.08881, mel_loss=0.03384, linear_loss=0.04527]
[2020-05-12 06:25:48.294]  Step 154733  [3.348 sec/step, loss=0.09831, avg_loss=0.08887, mel_loss=0.04505, linear_loss=0.05326]
[2020-05-12 06:25:53.611]  Step 154734  [3.262 sec/step, loss=0.09781, avg_loss=0.08909, mel_loss=0.04435, linear_loss=0.05347]
[2020-05-12 06:26:01.318]  Step 154735  [3.279 sec/step, loss=0.09733, avg_loss=0.08908, mel_loss=0.04473, linear_loss=0.05260]
[2020-05-12 06:26:05.053]  Step 154736  [3.285 sec/step, loss=0.09703, avg_loss=0.08911, mel_loss=0.04344, linear_loss=0.05359]
[2020-05-12 06:26:07.031]  Step 154737  [3.286 sec/step, loss=0.08890, avg_loss=0.08910, mel_loss=0.03895, linear_loss=0.04995]
[2020-05-12 06:26:10.624]  Step 154738  [3.300 sec/step, loss=0.09446, avg_loss=0.08913, mel_loss=0.04212, linear_loss=0.05234]
[2020-05-12 06:26:14.386]  Step 154739  [3.285 sec/step, loss=0.09470, avg_loss=0.08912, mel_loss=0.04230, linear_loss=0.05240]
[2020-05-12 06:26:22.426]  Step 154740  [3.288 sec/step, loss=0.09378, avg_loss=0.08908, mel_loss=0.04315, linear_loss=0.05063]
[2020-05-12 06:26:24.896]  Step 154741  [3.295 sec/step, loss=0.09055, avg_loss=0.08911, mel_loss=0.03967, linear_loss=0.05088]
[2020-05-12 06:26:26.980]  Step 154742  [3.297 sec/step, loss=0.08877, avg_loss=0.08911, mel_loss=0.03898, linear_loss=0.04979]
[2020-05-12 06:26:27.618]  Step 154743  [3.268 sec/step, loss=0.07661, avg_loss=0.08896, mel_loss=0.03335, linear_loss=0.04326]
[2020-05-12 06:26:28.150]  Step 154744  [3.243 sec/step, loss=0.07155, avg_loss=0.08874, mel_loss=0.03153, linear_loss=0.04002]
[2020-05-12 06:26:29.210]  Step 154745  [3.179 sec/step, loss=0.08223, avg_loss=0.08858, mel_loss=0.03514, linear_loss=0.04710]
[2020-05-12 06:26:35.807]  Step 154746  [3.211 sec/step, loss=0.09413, avg_loss=0.08856, mel_loss=0.04277, linear_loss=0.05136]
[2020-05-12 06:26:36.778]  Step 154747  [3.202 sec/step, loss=0.08173, avg_loss=0.08849, mel_loss=0.03473, linear_loss=0.04700]
[2020-05-12 06:26:38.220]  Step 154748  [3.129 sec/step, loss=0.08674, avg_loss=0.08839, mel_loss=0.03792, linear_loss=0.04882]
[2020-05-12 06:26:39.782]  Step 154749  [3.005 sec/step, loss=0.08720, avg_loss=0.08851, mel_loss=0.03818, linear_loss=0.04902]
[2020-05-12 06:26:40.568]  Step 154750  [2.999 sec/step, loss=0.07668, avg_loss=0.08842, mel_loss=0.03304, linear_loss=0.04364]
[2020-05-12 06:26:40.568]  Writing summary at step: 154750
[2020-05-12 06:26:44.855]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154750
[2020-05-12 06:26:46.394]  Saving audio and alignment...
[2020-05-12 06:26:49.484]  Input: 시청자 여러분 안녕하십니까~____________
[2020-05-12 06:26:54.163]  Step 154751  [3.038 sec/step, loss=0.09701, avg_loss=0.08859, mel_loss=0.04409, linear_loss=0.05292]
[2020-05-12 06:27:00.983]  Step 154752  [3.098 sec/step, loss=0.09940, avg_loss=0.08882, mel_loss=0.04550, linear_loss=0.05390]
[2020-05-12 06:27:06.471]  Step 154753  [3.104 sec/step, loss=0.09763, avg_loss=0.08885, mel_loss=0.04462, linear_loss=0.05301]
[2020-05-12 06:27:07.638]  Step 154754  [3.048 sec/step, loss=0.08174, avg_loss=0.08870, mel_loss=0.03508, linear_loss=0.04666]
[2020-05-12 06:27:19.911]  Step 154755  [3.149 sec/step, loss=0.08324, avg_loss=0.08864, mel_loss=0.03901, linear_loss=0.04423]
[2020-05-12 06:27:23.170]  Step 154756  [3.172 sec/step, loss=0.09594, avg_loss=0.08882, mel_loss=0.04296, linear_loss=0.05298]
[2020-05-12 06:27:26.211]  Step 154757  [3.174 sec/step, loss=0.09518, avg_loss=0.08882, mel_loss=0.04243, linear_loss=0.05275]
[2020-05-12 06:27:27.252]  Step 154758  [3.171 sec/step, loss=0.07943, avg_loss=0.08877, mel_loss=0.03381, linear_loss=0.04563]
[2020-05-12 06:27:27.993]  Generated 32 batches of size 32 in 1.775 sec
[2020-05-12 06:27:28.694]  Step 154759  [3.131 sec/step, loss=0.08537, avg_loss=0.08864, mel_loss=0.03679, linear_loss=0.04857]
[2020-05-12 06:27:30.500]  Step 154760  [3.091 sec/step, loss=0.08874, avg_loss=0.08855, mel_loss=0.03850, linear_loss=0.05025]
[2020-05-12 06:27:33.008]  Step 154761  [3.096 sec/step, loss=0.09281, avg_loss=0.08858, mel_loss=0.04068, linear_loss=0.05213]
[2020-05-12 06:27:38.100]  Step 154762  [3.127 sec/step, loss=0.09661, avg_loss=0.08866, mel_loss=0.04369, linear_loss=0.05292]
[2020-05-12 06:27:40.933]  Step 154763  [3.121 sec/step, loss=0.09175, avg_loss=0.08865, mel_loss=0.04078, linear_loss=0.05097]
[2020-05-12 06:27:44.373]  Step 154764  [3.144 sec/step, loss=0.09345, avg_loss=0.08877, mel_loss=0.04175, linear_loss=0.05169]
[2020-05-12 06:27:45.618]  Step 154765  [3.112 sec/step, loss=0.08523, avg_loss=0.08865, mel_loss=0.03699, linear_loss=0.04825]
[2020-05-12 06:27:47.839]  Step 154766  [3.091 sec/step, loss=0.08972, avg_loss=0.08859, mel_loss=0.03952, linear_loss=0.05020]
[2020-05-12 06:27:48.872]  Step 154767  [3.091 sec/step, loss=0.08006, avg_loss=0.08857, mel_loss=0.03480, linear_loss=0.04526]
[2020-05-12 06:27:55.156]  Step 154768  [3.138 sec/step, loss=0.09571, avg_loss=0.08865, mel_loss=0.04385, linear_loss=0.05186]
[2020-05-12 06:27:58.332]  Step 154769  [3.159 sec/step, loss=0.09348, avg_loss=0.08878, mel_loss=0.04170, linear_loss=0.05178]
[2020-05-12 06:28:00.331]  Step 154770  [3.173 sec/step, loss=0.09188, avg_loss=0.08902, mel_loss=0.04055, linear_loss=0.05133]
[2020-05-12 06:28:01.747]  Step 154771  [3.161 sec/step, loss=0.08756, avg_loss=0.08897, mel_loss=0.03807, linear_loss=0.04950]
[2020-05-12 06:28:02.960]  Step 154772  [3.157 sec/step, loss=0.08457, avg_loss=0.08896, mel_loss=0.03643, linear_loss=0.04814]
[2020-05-12 06:28:08.290]  Step 154773  [3.184 sec/step, loss=0.09647, avg_loss=0.08903, mel_loss=0.04385, linear_loss=0.05262]
[2020-05-12 06:28:13.031]  Step 154774  [3.195 sec/step, loss=0.09638, avg_loss=0.08903, mel_loss=0.04343, linear_loss=0.05295]
[2020-05-12 06:28:15.470]  Step 154775  [3.201 sec/step, loss=0.09076, avg_loss=0.08906, mel_loss=0.03988, linear_loss=0.05087]
[2020-05-12 06:28:17.135]  Step 154776  [3.197 sec/step, loss=0.08606, avg_loss=0.08900, mel_loss=0.03771, linear_loss=0.04835]
[2020-05-12 06:28:20.047]  Step 154777  [3.195 sec/step, loss=0.09440, avg_loss=0.08898, mel_loss=0.04184, linear_loss=0.05256]
[2020-05-12 06:28:21.746]  Step 154778  [3.190 sec/step, loss=0.08997, avg_loss=0.08899, mel_loss=0.03911, linear_loss=0.05087]
[2020-05-12 06:28:25.268]  Step 154779  [3.211 sec/step, loss=0.09256, avg_loss=0.08904, mel_loss=0.04120, linear_loss=0.05136]
[2020-05-12 06:28:27.007]  Step 154780  [3.213 sec/step, loss=0.08148, avg_loss=0.08899, mel_loss=0.03493, linear_loss=0.04655]
[2020-05-12 06:28:32.784]  Step 154781  [3.261 sec/step, loss=0.09659, avg_loss=0.08913, mel_loss=0.04316, linear_loss=0.05343]
[2020-05-12 06:28:37.925]  Step 154782  [3.302 sec/step, loss=0.09439, avg_loss=0.08927, mel_loss=0.04264, linear_loss=0.05175]
[2020-05-12 06:28:38.948]  Step 154783  [3.287 sec/step, loss=0.08114, avg_loss=0.08914, mel_loss=0.03471, linear_loss=0.04643]
[2020-05-12 06:28:39.518]  Step 154784  [3.265 sec/step, loss=0.06856, avg_loss=0.08893, mel_loss=0.03033, linear_loss=0.03823]
[2020-05-12 06:28:43.129]  Step 154785  [3.295 sec/step, loss=0.09502, avg_loss=0.08917, mel_loss=0.04222, linear_loss=0.05281]
[2020-05-12 06:28:45.514]  Step 154786  [3.299 sec/step, loss=0.09025, avg_loss=0.08915, mel_loss=0.04004, linear_loss=0.05021]
[2020-05-12 06:28:46.381]  Step 154787  [3.250 sec/step, loss=0.07106, avg_loss=0.08888, mel_loss=0.03073, linear_loss=0.04033]
[2020-05-12 06:28:47.193]  Step 154788  [3.187 sec/step, loss=0.07677, avg_loss=0.08868, mel_loss=0.03282, linear_loss=0.04395]
[2020-05-12 06:28:48.582]  Step 154789  [3.158 sec/step, loss=0.08429, avg_loss=0.08855, mel_loss=0.03667, linear_loss=0.04761]
[2020-05-12 06:28:50.362]  Generated 32 batches of size 32 in 1.774 sec
[2020-05-12 06:28:52.612]  Step 154790  [3.168 sec/step, loss=0.09406, avg_loss=0.08856, mel_loss=0.04198, linear_loss=0.05208]
[2020-05-12 06:29:00.517]  Step 154791  [3.212 sec/step, loss=0.09710, avg_loss=0.08858, mel_loss=0.04461, linear_loss=0.05249]
[2020-05-12 06:29:06.165]  Step 154792  [3.227 sec/step, loss=0.09714, avg_loss=0.08858, mel_loss=0.04421, linear_loss=0.05293]
[2020-05-12 06:29:08.125]  Step 154793  [3.239 sec/step, loss=0.08931, avg_loss=0.08871, mel_loss=0.03908, linear_loss=0.05023]
[2020-05-12 06:29:22.710]  Step 154794  [3.366 sec/step, loss=0.07713, avg_loss=0.08859, mel_loss=0.03644, linear_loss=0.04069]
[2020-05-12 06:29:24.911]  Step 154795  [3.351 sec/step, loss=0.09223, avg_loss=0.08856, mel_loss=0.04054, linear_loss=0.05169]
[2020-05-12 06:29:26.744]  Step 154796  [3.320 sec/step, loss=0.08864, avg_loss=0.08849, mel_loss=0.03872, linear_loss=0.04993]
[2020-05-12 06:29:36.760]  Step 154797  [3.290 sec/step, loss=0.09767, avg_loss=0.08866, mel_loss=0.04513, linear_loss=0.05254]
[2020-05-12 06:29:40.308]  Step 154798  [3.301 sec/step, loss=0.09336, avg_loss=0.08866, mel_loss=0.04177, linear_loss=0.05159]
[2020-05-12 06:29:45.760]  Step 154799  [3.345 sec/step, loss=0.09602, avg_loss=0.08878, mel_loss=0.04328, linear_loss=0.05273]
[2020-05-12 06:29:46.592]  Step 154800  [3.273 sec/step, loss=0.07838, avg_loss=0.08861, mel_loss=0.03366, linear_loss=0.04471]
[2020-05-12 06:29:46.593]  Writing summary at step: 154800
[2020-05-12 06:29:48.007]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154800
[2020-05-12 06:29:49.638]  Saving audio and alignment...
[2020-05-12 06:29:55.263]  Input: 대본에도 기호로 적용해서 그걸 잘 지키기만 한다면~____________________
[2020-05-12 06:30:09.194]  Step 154801  [3.405 sec/step, loss=0.07510, avg_loss=0.08860, mel_loss=0.03574, linear_loss=0.03936]
[2020-05-12 06:30:10.211]  Step 154802  [3.398 sec/step, loss=0.07902, avg_loss=0.08852, mel_loss=0.03370, linear_loss=0.04532]
[2020-05-12 06:30:11.498]  Step 154803  [3.399 sec/step, loss=0.08180, avg_loss=0.08850, mel_loss=0.03553, linear_loss=0.04627]
[2020-05-12 06:30:18.246]  Step 154804  [3.432 sec/step, loss=0.09728, avg_loss=0.08854, mel_loss=0.04435, linear_loss=0.05293]
[2020-05-12 06:30:22.381]  Step 154805  [3.434 sec/step, loss=0.09594, avg_loss=0.08857, mel_loss=0.04290, linear_loss=0.05304]
[2020-05-12 06:30:25.648]  Step 154806  [3.323 sec/step, loss=0.09673, avg_loss=0.08876, mel_loss=0.04315, linear_loss=0.05359]
[2020-05-12 06:30:28.346]  Step 154807  [3.319 sec/step, loss=0.09326, avg_loss=0.08876, mel_loss=0.04116, linear_loss=0.05211]
[2020-05-12 06:30:29.825]  Step 154808  [3.321 sec/step, loss=0.08370, avg_loss=0.08874, mel_loss=0.03659, linear_loss=0.04710]
[2020-05-12 06:30:37.600]  Step 154809  [3.379 sec/step, loss=0.09672, avg_loss=0.08882, mel_loss=0.04441, linear_loss=0.05231]
[2020-05-12 06:30:40.757]  Step 154810  [3.398 sec/step, loss=0.09392, avg_loss=0.08891, mel_loss=0.04151, linear_loss=0.05241]
[2020-05-12 06:30:42.685]  Step 154811  [3.401 sec/step, loss=0.08733, avg_loss=0.08892, mel_loss=0.03790, linear_loss=0.04942]
[2020-05-12 06:30:44.783]  Step 154812  [3.404 sec/step, loss=0.08950, avg_loss=0.08894, mel_loss=0.03939, linear_loss=0.05011]
[2020-05-12 06:30:45.354]  Step 154813  [3.401 sec/step, loss=0.07092, avg_loss=0.08891, mel_loss=0.03094, linear_loss=0.03998]
[2020-05-12 06:30:48.036]  Step 154814  [3.414 sec/step, loss=0.09172, avg_loss=0.08901, mel_loss=0.04070, linear_loss=0.05102]
[2020-05-12 06:30:52.372]  Step 154815  [3.452 sec/step, loss=0.09635, avg_loss=0.08927, mel_loss=0.04333, linear_loss=0.05302]
[2020-05-12 06:30:54.312]  Step 154816  [3.427 sec/step, loss=0.08929, avg_loss=0.08921, mel_loss=0.03906, linear_loss=0.05023]
[2020-05-12 06:30:59.513]  Step 154817  [3.454 sec/step, loss=0.09619, avg_loss=0.08927, mel_loss=0.04345, linear_loss=0.05273]
[2020-05-12 06:31:03.568]  Step 154818  [3.404 sec/step, loss=0.09239, avg_loss=0.08923, mel_loss=0.04110, linear_loss=0.05129]
[2020-05-12 06:31:04.486]  Step 154819  [3.391 sec/step, loss=0.07483, avg_loss=0.08907, mel_loss=0.03252, linear_loss=0.04231]
[2020-05-12 06:31:05.733]  Step 154820  [3.392 sec/step, loss=0.08283, avg_loss=0.08905, mel_loss=0.03554, linear_loss=0.04729]
[2020-05-12 06:31:06.958]  Step 154821  [3.395 sec/step, loss=0.08236, avg_loss=0.08907, mel_loss=0.03572, linear_loss=0.04664]
[2020-05-12 06:31:10.187]  Step 154822  [3.399 sec/step, loss=0.09404, avg_loss=0.08908, mel_loss=0.04169, linear_loss=0.05235]
[2020-05-12 06:31:14.879]  Step 154823  [3.438 sec/step, loss=0.09675, avg_loss=0.08930, mel_loss=0.04344, linear_loss=0.05332]
[2020-05-12 06:31:16.553]  Step 154824  [3.406 sec/step, loss=0.08836, avg_loss=0.08922, mel_loss=0.03854, linear_loss=0.04982]
[2020-05-12 06:31:18.222]  Step 154825  [3.399 sec/step, loss=0.08601, avg_loss=0.08918, mel_loss=0.03732, linear_loss=0.04869]
[2020-05-12 06:31:19.827]  Generated 32 batches of size 32 in 15.334 sec
[2020-05-12 06:31:20.729]  Step 154826  [3.407 sec/step, loss=0.08928, avg_loss=0.08920, mel_loss=0.03924, linear_loss=0.05004]
[2020-05-12 06:31:22.838]  Step 154827  [3.368 sec/step, loss=0.09088, avg_loss=0.08914, mel_loss=0.04028, linear_loss=0.05060]
[2020-05-12 06:31:31.264]  Step 154828  [3.430 sec/step, loss=0.09448, avg_loss=0.08920, mel_loss=0.04374, linear_loss=0.05074]
[2020-05-12 06:31:36.610]  Step 154829  [3.454 sec/step, loss=0.09686, avg_loss=0.08923, mel_loss=0.04375, linear_loss=0.05311]
[2020-05-12 06:31:38.632]  Step 154830  [3.438 sec/step, loss=0.08753, avg_loss=0.08917, mel_loss=0.03839, linear_loss=0.04914]
[2020-05-12 06:31:42.073]  Step 154831  [3.438 sec/step, loss=0.09393, avg_loss=0.08917, mel_loss=0.04184, linear_loss=0.05209]
[2020-05-12 06:31:43.982]  Step 154832  [3.449 sec/step, loss=0.08813, avg_loss=0.08926, mel_loss=0.03826, linear_loss=0.04987]
[2020-05-12 06:31:44.744]  Step 154833  [3.388 sec/step, loss=0.07251, avg_loss=0.08900, mel_loss=0.03217, linear_loss=0.04034]
[2020-05-12 06:31:47.152]  Step 154834  [3.359 sec/step, loss=0.09074, avg_loss=0.08893, mel_loss=0.03964, linear_loss=0.05110]
[2020-05-12 06:31:47.909]  Step 154835  [3.290 sec/step, loss=0.07554, avg_loss=0.08871, mel_loss=0.03206, linear_loss=0.04348]
[2020-05-12 06:31:54.971]  Step 154836  [3.323 sec/step, loss=0.09784, avg_loss=0.08872, mel_loss=0.04468, linear_loss=0.05316]
[2020-05-12 06:31:55.786]  Step 154837  [3.311 sec/step, loss=0.07660, avg_loss=0.08859, mel_loss=0.03305, linear_loss=0.04354]
[2020-05-12 06:31:59.981]  Step 154838  [3.317 sec/step, loss=0.09452, avg_loss=0.08860, mel_loss=0.04216, linear_loss=0.05236]
[2020-05-12 06:32:03.687]  Step 154839  [3.317 sec/step, loss=0.09644, avg_loss=0.08861, mel_loss=0.04318, linear_loss=0.05326]
[2020-05-12 06:32:05.326]  Step 154840  [3.253 sec/step, loss=0.08701, avg_loss=0.08855, mel_loss=0.03802, linear_loss=0.04899]
[2020-05-12 06:32:11.082]  Step 154841  [3.286 sec/step, loss=0.09670, avg_loss=0.08861, mel_loss=0.04391, linear_loss=0.05279]
[2020-05-12 06:32:24.156]  Step 154842  [3.396 sec/step, loss=0.08073, avg_loss=0.08853, mel_loss=0.03775, linear_loss=0.04298]
[2020-05-12 06:32:25.076]  Step 154843  [3.398 sec/step, loss=0.07912, avg_loss=0.08855, mel_loss=0.03375, linear_loss=0.04537]
[2020-05-12 06:32:26.444]  Step 154844  [3.407 sec/step, loss=0.08528, avg_loss=0.08869, mel_loss=0.03702, linear_loss=0.04827]
[2020-05-12 06:32:27.647]  Step 154845  [3.408 sec/step, loss=0.08181, avg_loss=0.08868, mel_loss=0.03540, linear_loss=0.04641]
[2020-05-12 06:32:28.718]  Step 154846  [3.353 sec/step, loss=0.08417, avg_loss=0.08858, mel_loss=0.03615, linear_loss=0.04802]
[2020-05-12 06:32:33.078]  Step 154847  [3.387 sec/step, loss=0.09683, avg_loss=0.08874, mel_loss=0.04374, linear_loss=0.05309]
[2020-05-12 06:32:36.564]  Step 154848  [3.407 sec/step, loss=0.09328, avg_loss=0.08880, mel_loss=0.04169, linear_loss=0.05158]
[2020-05-12 06:32:42.981]  Step 154849  [3.456 sec/step, loss=0.09571, avg_loss=0.08889, mel_loss=0.04376, linear_loss=0.05195]
[2020-05-12 06:32:45.149]  Step 154850  [3.470 sec/step, loss=0.09060, avg_loss=0.08903, mel_loss=0.03975, linear_loss=0.05085]
[2020-05-12 06:32:45.149]  Writing summary at step: 154850
[2020-05-12 06:32:50.002]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154850
[2020-05-12 06:32:51.558]  Saving audio and alignment...
[2020-05-12 06:32:54.287]  Input: 예시 하나 더 볼게요~______________
[2020-05-12 06:32:55.292]  Step 154851  [3.433 sec/step, loss=0.08243, avg_loss=0.08888, mel_loss=0.03538, linear_loss=0.04705]
[2020-05-12 06:32:57.058]  Step 154852  [3.382 sec/step, loss=0.08828, avg_loss=0.08877, mel_loss=0.03842, linear_loss=0.04986]
[2020-05-12 06:32:58.728]  Generated 32 batches of size 32 in 6.584 sec
[2020-05-12 06:32:59.924]  Step 154853  [3.356 sec/step, loss=0.09290, avg_loss=0.08872, mel_loss=0.04138, linear_loss=0.05152]
[2020-05-12 06:33:01.368]  Step 154854  [3.359 sec/step, loss=0.08752, avg_loss=0.08878, mel_loss=0.03807, linear_loss=0.04945]
[2020-05-12 06:33:04.466]  Step 154855  [3.267 sec/step, loss=0.09581, avg_loss=0.08890, mel_loss=0.04296, linear_loss=0.05285]
[2020-05-12 06:33:06.670]  Step 154856  [3.257 sec/step, loss=0.09018, avg_loss=0.08885, mel_loss=0.03996, linear_loss=0.05022]
[2020-05-12 06:33:15.369]  Step 154857  [3.313 sec/step, loss=0.09577, avg_loss=0.08885, mel_loss=0.04391, linear_loss=0.05186]
[2020-05-12 06:33:17.918]  Step 154858  [3.328 sec/step, loss=0.08987, avg_loss=0.08896, mel_loss=0.03986, linear_loss=0.05000]
[2020-05-12 06:33:18.808]  Step 154859  [3.323 sec/step, loss=0.08135, avg_loss=0.08892, mel_loss=0.03466, linear_loss=0.04669]
[2020-05-12 06:33:20.209]  Step 154860  [3.319 sec/step, loss=0.08503, avg_loss=0.08888, mel_loss=0.03714, linear_loss=0.04789]
[2020-05-12 06:33:27.602]  Step 154861  [3.368 sec/step, loss=0.09768, avg_loss=0.08893, mel_loss=0.04484, linear_loss=0.05284]
[2020-05-12 06:33:30.770]  Step 154862  [3.348 sec/step, loss=0.09370, avg_loss=0.08890, mel_loss=0.04173, linear_loss=0.05197]
[2020-05-12 06:33:43.224]  Step 154863  [3.445 sec/step, loss=0.08455, avg_loss=0.08883, mel_loss=0.03975, linear_loss=0.04481]
[2020-05-12 06:33:44.977]  Step 154864  [3.428 sec/step, loss=0.08938, avg_loss=0.08879, mel_loss=0.03876, linear_loss=0.05062]
[2020-05-12 06:33:45.511]  Step 154865  [3.421 sec/step, loss=0.07397, avg_loss=0.08867, mel_loss=0.03221, linear_loss=0.04176]
[2020-05-12 06:33:47.241]  Step 154866  [3.416 sec/step, loss=0.08801, avg_loss=0.08866, mel_loss=0.03834, linear_loss=0.04968]
[2020-05-12 06:33:53.471]  Step 154867  [3.468 sec/step, loss=0.09690, avg_loss=0.08883, mel_loss=0.04415, linear_loss=0.05275]
[2020-05-12 06:33:58.081]  Step 154868  [3.451 sec/step, loss=0.09531, avg_loss=0.08882, mel_loss=0.04283, linear_loss=0.05248]
[2020-05-12 06:34:00.529]  Step 154869  [3.444 sec/step, loss=0.08993, avg_loss=0.08879, mel_loss=0.03943, linear_loss=0.05050]
[2020-05-12 06:34:02.902]  Step 154870  [3.447 sec/step, loss=0.09144, avg_loss=0.08878, mel_loss=0.04037, linear_loss=0.05107]
[2020-05-12 06:34:04.122]  Step 154871  [3.445 sec/step, loss=0.08326, avg_loss=0.08874, mel_loss=0.03594, linear_loss=0.04732]
[2020-05-12 06:34:07.945]  Step 154872  [3.471 sec/step, loss=0.09528, avg_loss=0.08885, mel_loss=0.04250, linear_loss=0.05278]
[2020-05-12 06:34:09.402]  Step 154873  [3.433 sec/step, loss=0.08414, avg_loss=0.08872, mel_loss=0.03689, linear_loss=0.04725]
[2020-05-12 06:34:17.821]  Step 154874  [3.470 sec/step, loss=0.09331, avg_loss=0.08869, mel_loss=0.04293, linear_loss=0.05037]
[2020-05-12 06:34:19.946]  Step 154875  [3.466 sec/step, loss=0.09003, avg_loss=0.08868, mel_loss=0.03957, linear_loss=0.05047]
[2020-05-12 06:34:22.863]  Step 154876  [3.479 sec/step, loss=0.09341, avg_loss=0.08876, mel_loss=0.04139, linear_loss=0.05202]
[2020-05-12 06:34:23.683]  Step 154877  [3.458 sec/step, loss=0.07600, avg_loss=0.08857, mel_loss=0.03234, linear_loss=0.04366]
[2020-05-12 06:34:26.444]  Step 154878  [3.469 sec/step, loss=0.09065, avg_loss=0.08858, mel_loss=0.04010, linear_loss=0.05055]
[2020-05-12 06:34:28.502]  Step 154879  [3.454 sec/step, loss=0.08964, avg_loss=0.08855, mel_loss=0.03927, linear_loss=0.05037]
[2020-05-12 06:34:29.371]  Step 154880  [3.445 sec/step, loss=0.06835, avg_loss=0.08842, mel_loss=0.02992, linear_loss=0.03843]
[2020-05-12 06:34:33.697]  Step 154881  [3.431 sec/step, loss=0.09515, avg_loss=0.08841, mel_loss=0.04296, linear_loss=0.05219]
[2020-05-12 06:34:34.718]  Step 154882  [3.390 sec/step, loss=0.08107, avg_loss=0.08827, mel_loss=0.03470, linear_loss=0.04636]
[2020-05-12 06:34:36.671]  Step 154883  [3.399 sec/step, loss=0.08922, avg_loss=0.08835, mel_loss=0.03913, linear_loss=0.05009]
[2020-05-12 06:34:39.121]  Generated 32 batches of size 32 in 5.417 sec
[2020-05-12 06:34:40.191]  Step 154884  [3.428 sec/step, loss=0.09407, avg_loss=0.08861, mel_loss=0.04174, linear_loss=0.05233]
[2020-05-12 06:34:41.754]  Step 154885  [3.408 sec/step, loss=0.08764, avg_loss=0.08854, mel_loss=0.03809, linear_loss=0.04954]
[2020-05-12 06:34:42.865]  Step 154886  [3.395 sec/step, loss=0.08351, avg_loss=0.08847, mel_loss=0.03570, linear_loss=0.04781]
[2020-05-12 06:34:48.159]  Step 154887  [3.439 sec/step, loss=0.09433, avg_loss=0.08870, mel_loss=0.04267, linear_loss=0.05166]
[2020-05-12 06:34:51.571]  Step 154888  [3.465 sec/step, loss=0.09314, avg_loss=0.08886, mel_loss=0.04139, linear_loss=0.05175]
[2020-05-12 06:34:55.285]  Step 154889  [3.489 sec/step, loss=0.09584, avg_loss=0.08898, mel_loss=0.04288, linear_loss=0.05297]
[2020-05-12 06:35:00.932]  Step 154890  [3.505 sec/step, loss=0.09706, avg_loss=0.08901, mel_loss=0.04434, linear_loss=0.05272]
[2020-05-12 06:35:04.727]  Step 154891  [3.464 sec/step, loss=0.09531, avg_loss=0.08899, mel_loss=0.04261, linear_loss=0.05270]
[2020-05-12 06:35:07.627]  Step 154892  [3.436 sec/step, loss=0.09262, avg_loss=0.08895, mel_loss=0.04118, linear_loss=0.05144]
[2020-05-12 06:35:09.645]  Step 154893  [3.437 sec/step, loss=0.08931, avg_loss=0.08895, mel_loss=0.03916, linear_loss=0.05015]
[2020-05-12 06:35:11.434]  Step 154894  [3.309 sec/step, loss=0.08611, avg_loss=0.08904, mel_loss=0.03730, linear_loss=0.04881]
[2020-05-12 06:35:13.352]  Step 154895  [3.306 sec/step, loss=0.08757, avg_loss=0.08899, mel_loss=0.03807, linear_loss=0.04950]
[2020-05-12 06:35:15.015]  Step 154896  [3.304 sec/step, loss=0.08693, avg_loss=0.08897, mel_loss=0.03798, linear_loss=0.04895]
[2020-05-12 06:35:15.649]  Step 154897  [3.211 sec/step, loss=0.07799, avg_loss=0.08878, mel_loss=0.03359, linear_loss=0.04439]
[2020-05-12 06:35:18.660]  Step 154898  [3.205 sec/step, loss=0.09359, avg_loss=0.08878, mel_loss=0.04143, linear_loss=0.05216]
[2020-05-12 06:35:20.865]  Step 154899  [3.173 sec/step, loss=0.09041, avg_loss=0.08872, mel_loss=0.03972, linear_loss=0.05070]
[2020-05-12 06:35:21.425]  Step 154900  [3.170 sec/step, loss=0.07123, avg_loss=0.08865, mel_loss=0.03090, linear_loss=0.04033]
[2020-05-12 06:35:21.426]  Writing summary at step: 154900
[2020-05-12 06:35:22.756]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154900
[2020-05-12 06:35:24.304]  Saving audio and alignment...
[2020-05-12 06:35:34.480]  Input: 으음 이럴 때요 뭐 어떤 어떤 점이 장점이고 내가 특히 뭘 잘 한다고 하더라 라는 나열보다~________________________________________________
[2020-05-12 06:35:35.242]  Step 154901  [3.038 sec/step, loss=0.07801, avg_loss=0.08868, mel_loss=0.03326, linear_loss=0.04475]
[2020-05-12 06:35:36.585]  Step 154902  [3.042 sec/step, loss=0.08508, avg_loss=0.08874, mel_loss=0.03660, linear_loss=0.04848]
[2020-05-12 06:35:37.750]  Step 154903  [3.040 sec/step, loss=0.08080, avg_loss=0.08873, mel_loss=0.03480, linear_loss=0.04600]
[2020-05-12 06:35:39.862]  Step 154904  [2.994 sec/step, loss=0.09172, avg_loss=0.08867, mel_loss=0.04040, linear_loss=0.05133]
[2020-05-12 06:35:48.831]  Step 154905  [3.042 sec/step, loss=0.09735, avg_loss=0.08869, mel_loss=0.04504, linear_loss=0.05231]
[2020-05-12 06:35:53.635]  Step 154906  [3.058 sec/step, loss=0.09672, avg_loss=0.08869, mel_loss=0.04365, linear_loss=0.05306]
[2020-05-12 06:35:57.293]  Step 154907  [3.067 sec/step, loss=0.09634, avg_loss=0.08872, mel_loss=0.04297, linear_loss=0.05337]
[2020-05-12 06:36:02.462]  Step 154908  [3.104 sec/step, loss=0.09613, avg_loss=0.08884, mel_loss=0.04358, linear_loss=0.05255]
[2020-05-12 06:36:05.838]  Step 154909  [3.060 sec/step, loss=0.09300, avg_loss=0.08881, mel_loss=0.04157, linear_loss=0.05143]
[2020-05-12 06:36:06.818]  Step 154910  [3.038 sec/step, loss=0.07899, avg_loss=0.08866, mel_loss=0.03402, linear_loss=0.04498]
[2020-05-12 06:36:07.918]  Step 154911  [3.030 sec/step, loss=0.08088, avg_loss=0.08859, mel_loss=0.03464, linear_loss=0.04625]
[2020-05-12 06:36:09.564]  Generated 32 batches of size 32 in 1.640 sec
[2020-05-12 06:36:14.641]  Step 154912  [3.076 sec/step, loss=0.09578, avg_loss=0.08866, mel_loss=0.04354, linear_loss=0.05224]
[2020-05-12 06:36:15.615]  Step 154913  [3.080 sec/step, loss=0.08010, avg_loss=0.08875, mel_loss=0.03411, linear_loss=0.04599]
[2020-05-12 06:36:29.987]  Step 154914  [3.197 sec/step, loss=0.07570, avg_loss=0.08859, mel_loss=0.03576, linear_loss=0.03994]
[2020-05-12 06:36:35.309]  Step 154915  [3.207 sec/step, loss=0.09681, avg_loss=0.08859, mel_loss=0.04409, linear_loss=0.05273]
[2020-05-12 06:36:36.753]  Step 154916  [3.202 sec/step, loss=0.08644, avg_loss=0.08856, mel_loss=0.03751, linear_loss=0.04893]
[2020-05-12 06:36:39.971]  Step 154917  [3.182 sec/step, loss=0.09521, avg_loss=0.08855, mel_loss=0.04253, linear_loss=0.05268]
[2020-05-12 06:36:42.575]  Step 154918  [3.168 sec/step, loss=0.09083, avg_loss=0.08854, mel_loss=0.04011, linear_loss=0.05073]
[2020-05-12 06:36:46.888]  Step 154919  [3.202 sec/step, loss=0.09353, avg_loss=0.08873, mel_loss=0.04176, linear_loss=0.05177]
[2020-05-12 06:36:49.340]  Step 154920  [3.214 sec/step, loss=0.09160, avg_loss=0.08881, mel_loss=0.04012, linear_loss=0.05148]
[2020-05-12 06:36:50.962]  Step 154921  [3.218 sec/step, loss=0.08799, avg_loss=0.08887, mel_loss=0.03836, linear_loss=0.04963]
[2020-05-12 06:36:53.859]  Step 154922  [3.215 sec/step, loss=0.09397, avg_loss=0.08887, mel_loss=0.04159, linear_loss=0.05238]
[2020-05-12 06:36:55.606]  Step 154923  [3.185 sec/step, loss=0.08800, avg_loss=0.08878, mel_loss=0.03819, linear_loss=0.04981]
[2020-05-12 06:36:56.835]  Step 154924  [3.181 sec/step, loss=0.08279, avg_loss=0.08873, mel_loss=0.03553, linear_loss=0.04726]
[2020-05-12 06:36:58.227]  Step 154925  [3.178 sec/step, loss=0.08353, avg_loss=0.08870, mel_loss=0.03615, linear_loss=0.04738]
[2020-05-12 06:36:59.036]  Step 154926  [3.161 sec/step, loss=0.07522, avg_loss=0.08856, mel_loss=0.03197, linear_loss=0.04325]
[2020-05-12 06:37:13.017]  Step 154927  [3.280 sec/step, loss=0.07516, avg_loss=0.08840, mel_loss=0.03547, linear_loss=0.03969]
[2020-05-12 06:37:17.622]  Step 154928  [3.241 sec/step, loss=0.09680, avg_loss=0.08843, mel_loss=0.04366, linear_loss=0.05314]
[2020-05-12 06:37:18.475]  Step 154929  [3.196 sec/step, loss=0.07657, avg_loss=0.08822, mel_loss=0.03306, linear_loss=0.04351]
[2020-05-12 06:37:25.704]  Step 154930  [3.249 sec/step, loss=0.09580, avg_loss=0.08831, mel_loss=0.04406, linear_loss=0.05174]
[2020-05-12 06:37:27.020]  Step 154931  [3.227 sec/step, loss=0.08600, avg_loss=0.08823, mel_loss=0.03738, linear_loss=0.04862]
[2020-05-12 06:37:29.059]  Step 154932  [3.229 sec/step, loss=0.08890, avg_loss=0.08823, mel_loss=0.03893, linear_loss=0.04997]
[2020-05-12 06:37:34.842]  Step 154933  [3.279 sec/step, loss=0.09607, avg_loss=0.08847, mel_loss=0.04362, linear_loss=0.05245]
[2020-05-12 06:37:36.972]  Step 154934  [3.276 sec/step, loss=0.09106, avg_loss=0.08847, mel_loss=0.04011, linear_loss=0.05095]
[2020-05-12 06:37:41.252]  Step 154935  [3.311 sec/step, loss=0.09568, avg_loss=0.08867, mel_loss=0.04294, linear_loss=0.05274]
[2020-05-12 06:37:43.771]  Step 154936  [3.266 sec/step, loss=0.09012, avg_loss=0.08860, mel_loss=0.03952, linear_loss=0.05061]
[2020-05-12 06:37:47.767]  Step 154937  [3.298 sec/step, loss=0.09578, avg_loss=0.08879, mel_loss=0.04283, linear_loss=0.05295]
[2020-05-12 06:37:56.573]  Step 154938  [3.344 sec/step, loss=0.09807, avg_loss=0.08882, mel_loss=0.04534, linear_loss=0.05273]
[2020-05-12 06:38:03.252]  Step 154939  [3.373 sec/step, loss=0.09729, avg_loss=0.08883, mel_loss=0.04440, linear_loss=0.05289]
[2020-05-12 06:38:05.909]  Step 154940  [3.384 sec/step, loss=0.09177, avg_loss=0.08888, mel_loss=0.04068, linear_loss=0.05110]
[2020-05-12 06:38:06.955]  Step 154941  [3.337 sec/step, loss=0.07958, avg_loss=0.08871, mel_loss=0.03432, linear_loss=0.04526]
[2020-05-12 06:38:10.131]  Step 154942  [3.238 sec/step, loss=0.09632, avg_loss=0.08887, mel_loss=0.04277, linear_loss=0.05355]
[2020-05-12 06:38:13.558]  Step 154943  [3.263 sec/step, loss=0.09298, avg_loss=0.08900, mel_loss=0.04147, linear_loss=0.05151]
[2020-05-12 06:38:15.159]  Step 154944  [3.265 sec/step, loss=0.08719, avg_loss=0.08902, mel_loss=0.03793, linear_loss=0.04927]
[2020-05-12 06:38:15.328]  Generated 32 batches of size 32 in 1.764 sec
[2020-05-12 06:38:16.173]  Step 154945  [3.263 sec/step, loss=0.08094, avg_loss=0.08901, mel_loss=0.03469, linear_loss=0.04625]
[2020-05-12 06:38:19.759]  Step 154946  [3.288 sec/step, loss=0.09680, avg_loss=0.08914, mel_loss=0.04327, linear_loss=0.05354]
[2020-05-12 06:38:20.849]  Step 154947  [3.256 sec/step, loss=0.08118, avg_loss=0.08898, mel_loss=0.03474, linear_loss=0.04643]
[2020-05-12 06:38:22.749]  Step 154948  [3.240 sec/step, loss=0.08787, avg_loss=0.08893, mel_loss=0.03812, linear_loss=0.04976]
[2020-05-12 06:38:25.025]  Step 154949  [3.198 sec/step, loss=0.08985, avg_loss=0.08887, mel_loss=0.03966, linear_loss=0.05019]
[2020-05-12 06:38:30.319]  Step 154950  [3.230 sec/step, loss=0.09509, avg_loss=0.08892, mel_loss=0.04309, linear_loss=0.05200]
[2020-05-12 06:38:30.319]  Writing summary at step: 154950
[2020-05-12 06:38:30.891]  Saving checkpoint to: ./logs-tacotron/model.ckpt-154950
[2020-05-12 06:38:32.452]  Saving audio and alignment...
[2020-05-12 06:38:41.045]  Input: 음악에 허공은 그 끝을 가능하기 힘든 것 같습니다~______________________
[2020-05-12 06:38:45.645]  Step 154951  [3.265 sec/step, loss=0.09409, avg_loss=0.08903, mel_loss=0.04224, linear_loss=0.05184]
[2020-05-12 06:38:50.211]  Step 154952  [3.293 sec/step, loss=0.09652, avg_loss=0.08912, mel_loss=0.04328, linear_loss=0.05324]
[2020-05-12 06:38:52.932]  Step 154953  [3.292 sec/step, loss=0.08972, avg_loss=0.08908, mel_loss=0.03957, linear_loss=0.05015]
[2020-05-12 06:38:55.782]  Step 154954  [3.306 sec/step, loss=0.09119, avg_loss=0.08912, mel_loss=0.04047, linear_loss=0.05071]
[2020-05-12 06:38:56.601]  Step 154955  [3.283 sec/step, loss=0.07598, avg_loss=0.08892, mel_loss=0.03286, linear_loss=0.04312]
[2020-05-12 06:38:58.346]  Step 154956  [3.279 sec/step, loss=0.08913, avg_loss=0.08891, mel_loss=0.03857, linear_loss=0.05056]
[2020-05-12 06:39:02.110]  Step 154957  [3.229 sec/step, loss=0.09538, avg_loss=0.08891, mel_loss=0.04245, linear_loss=0.05293]
[2020-05-12 06:39:04.088]  Step 154958  [3.224 sec/step, loss=0.08881, avg_loss=0.08890, mel_loss=0.03871, linear_loss=0.05009]
[2020-05-12 06:39:07.080]  Step 154959  [3.245 sec/step, loss=0.09315, avg_loss=0.08901, mel_loss=0.04167, linear_loss=0.05149]
[2020-05-12 06:39:13.291]  Step 154960  [3.293 sec/step, loss=0.09442, avg_loss=0.08911, mel_loss=0.04323, linear_loss=0.05119]
[2020-05-12 06:39:15.505]  Step 154961  [3.241 sec/step, loss=0.09096, avg_loss=0.08904, mel_loss=0.03997, linear_loss=0.05099]
[2020-05-12 06:39:16.063]  Step 154962  [3.215 sec/step, loss=0.07059, avg_loss=0.08881, mel_loss=0.03120, linear_loss=0.03939]
[2020-05-12 06:39:20.969]  Step 154963  [3.139 sec/step, loss=0.09685, avg_loss=0.08893, mel_loss=0.04370, linear_loss=0.05315]
[2020-05-12 06:39:22.597]  Step 154964  [3.138 sec/step, loss=0.08643, avg_loss=0.08890, mel_loss=0.03771, linear_loss=0.04872]
[2020-05-12 06:39:23.427]  Step 154965  [3.141 sec/step, loss=0.07512, avg_loss=0.08892, mel_loss=0.03187, linear_loss=0.04325]
[2020-05-12 06:39:26.760]  Step 154966  [3.157 sec/step, loss=0.09498, avg_loss=0.08899, mel_loss=0.04251, linear_loss=0.05247]
[2020-05-12 06:39:32.301]  Step 154967  [3.150 sec/step, loss=0.09852, avg_loss=0.08900, mel_loss=0.04510, linear_loss=0.05343]
[2020-05-12 06:39:33.717]  Step 154968  [3.118 sec/step, loss=0.08722, avg_loss=0.08892, mel_loss=0.03807, linear_loss=0.04915]
[2020-05-12 06:39:37.334]  Step 154969  [3.130 sec/step, loss=0.09710, avg_loss=0.08899, mel_loss=0.04333, linear_loss=0.05376]
[2020-05-12 06:39:40.847]  Step 154970  [3.141 sec/step, loss=0.09362, avg_loss=0.08901, mel_loss=0.04186, linear_loss=0.05175]
[2020-05-12 06:39:41.892]  Step 154971  [3.140 sec/step, loss=0.07941, avg_loss=0.08898, mel_loss=0.03416, linear_loss=0.04525]
[2020-05-12 06:39:43.672]  Step 154972  [3.119 sec/step, loss=0.08782, avg_loss=0.08890, mel_loss=0.03809, linear_loss=0.04973]
[2020-05-12 06:39:46.130]  Step 154973  [3.129 sec/step, loss=0.09185, avg_loss=0.08898, mel_loss=0.04035, linear_loss=0.05150]
[2020-05-12 06:39:47.348]  Step 154974  [3.057 sec/step, loss=0.08192, avg_loss=0.08886, mel_loss=0.03520, linear_loss=0.04672]
[2020-05-12 06:39:47.832]  Generated 32 batches of size 32 in 1.696 sec
[2020-05-12 06:39:49.381]  Step 154975  [3.056 sec/step, loss=0.09158, avg_loss=0.08888, mel_loss=0.03995, linear_loss=0.05163]
[2020-05-12 06:39:56.781]  Step 154976  [3.101 sec/step, loss=0.09819, avg_loss=0.08893, mel_loss=0.04500, linear_loss=0.05318]
[2020-05-12 06:39:58.204]  Step 154977  [3.107 sec/step, loss=0.08670, avg_loss=0.08903, mel_loss=0.03774, linear_loss=0.04896]
[2020-05-12 06:40:00.413]  Step 154978  [3.102 sec/step, loss=0.09005, avg_loss=0.08903, mel_loss=0.03993, linear_loss=0.05012]
[2020-05-12 06:40:13.744]  Step 154979  [3.214 sec/step, loss=0.08207, avg_loss=0.08895, mel_loss=0.03872, linear_loss=0.04335]
[2020-05-12 06:40:15.081]  Step 154980  [3.219 sec/step, loss=0.08234, avg_loss=0.08909, mel_loss=0.03576, linear_loss=0.04658]
[2020-05-12 06:40:16.024]  Step 154981  [3.185 sec/step, loss=0.07781, avg_loss=0.08892, mel_loss=0.03312, linear_loss=0.04469]
[2020-05-12 06:40:24.741]  Step 154982  [3.262 sec/step, loss=0.09407, avg_loss=0.08905, mel_loss=0.04342, linear_loss=0.05064]
[2020-05-12 06:40:25.697]  Step 154983  [3.252 sec/step, loss=0.08248, avg_loss=0.08898, mel_loss=0.03530, linear_loss=0.04718]
[2020-05-12 06:40:30.174]  Step 154984  [3.262 sec/step, loss=0.09755, avg_loss=0.08902, mel_loss=0.04400, linear_loss=0.05356]
[2020-05-12 06:40:32.614]  Step 154985  [3.271 sec/step, loss=0.09009, avg_loss=0.08904, mel_loss=0.03951, linear_loss=0.05057]
[2020-05-12 06:40:33.681]  Step 154986  [3.270 sec/step, loss=0.08474, avg_loss=0.08905, mel_loss=0.03639, linear_loss=0.04835]
[2020-05-12 06:40:34.435]  Step 154987  [3.225 sec/step, loss=0.07443, avg_loss=0.08885, mel_loss=0.03228, linear_loss=0.04214]
[2020-05-12 06:40:36.039]  Step 154988  [3.207 sec/step, loss=0.08830, avg_loss=0.08881, mel_loss=0.03870, linear_loss=0.04960]
[2020-05-12 06:40:42.428]  Step 154989  [3.233 sec/step, loss=0.09677, avg_loss=0.08881, mel_loss=0.04416, linear_loss=0.05260]
[2020-05-12 06:40:55.607]  Step 154990  [3.309 sec/step, loss=0.08139, avg_loss=0.08866, mel_loss=0.03819, linear_loss=0.04320]
[2020-05-12 06:40:59.224]  Step 154991  [3.307 sec/step, loss=0.09402, avg_loss=0.08865, mel_loss=0.04191, linear_loss=0.05212]
[2020-05-12 06:41:00.534]  Step 154992  [3.291 sec/step, loss=0.08259, avg_loss=0.08854, mel_loss=0.03552, linear_loss=0.04707]
[2020-05-12 06:41:09.405]  Step 154993  [3.360 sec/step, loss=0.09500, avg_loss=0.08860, mel_loss=0.04353, linear_loss=0.05147]
[2020-05-12 06:41:12.856]  Step 154994  [3.376 sec/step, loss=0.09268, avg_loss=0.08867, mel_loss=0.04130, linear_loss=0.05138]
[2020-05-12 06:41:15.023]  Step 154995  [3.379 sec/step, loss=0.08976, avg_loss=0.08869, mel_loss=0.03969, linear_loss=0.05007]
[2020-05-12 06:41:16.615]  Step 154996  [3.378 sec/step, loss=0.08905, avg_loss=0.08871, mel_loss=0.03893, linear_loss=0.05012]
[2020-05-12 06:41:18.007]  Step 154997  [3.386 sec/step, loss=0.08417, avg_loss=0.08877, mel_loss=0.03652, linear_loss=0.04765]
[2020-05-12 06:41:23.282]  Step 154998  [3.408 sec/step, loss=0.09687, avg_loss=0.08881, mel_loss=0.04398, linear_loss=0.05288]
[2020-05-12 06:41:24.049]  Step 154999  [3.394 sec/step, loss=0.07953, avg_loss=0.08870, mel_loss=0.03397, linear_loss=0.04556]
[2020-05-12 06:41:25.059]  Step 155000  [3.398 sec/step, loss=0.07624, avg_loss=0.08875, mel_loss=0.03274, linear_loss=0.04350]
[2020-05-12 06:41:25.059]  Writing summary at step: 155000
[2020-05-12 06:41:27.509]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155000
[2020-05-12 06:41:29.062]  Saving audio and alignment...
[2020-05-12 06:41:31.521]  Input: 그거 밑에 줄에 하락~____________
[2020-05-12 06:41:35.731]  Step 155001  [3.433 sec/step, loss=0.09319, avg_loss=0.08890, mel_loss=0.04186, linear_loss=0.05134]
[2020-05-12 06:41:40.476]  Step 155002  [3.467 sec/step, loss=0.09581, avg_loss=0.08901, mel_loss=0.04317, linear_loss=0.05263]
[2020-05-12 06:41:42.537]  Step 155003  [3.476 sec/step, loss=0.08744, avg_loss=0.08907, mel_loss=0.03825, linear_loss=0.04918]
[2020-05-12 06:41:44.286]  Generated 32 batches of size 32 in 1.743 sec
[2020-05-12 06:41:50.152]  Step 155004  [3.531 sec/step, loss=0.09725, avg_loss=0.08913, mel_loss=0.04468, linear_loss=0.05257]
[2020-05-12 06:41:50.714]  Step 155005  [3.447 sec/step, loss=0.06802, avg_loss=0.08883, mel_loss=0.02983, linear_loss=0.03819]
[2020-05-12 06:41:53.603]  Step 155006  [3.428 sec/step, loss=0.09396, avg_loss=0.08881, mel_loss=0.04133, linear_loss=0.05264]
[2020-05-12 06:41:55.393]  Step 155007  [3.409 sec/step, loss=0.08853, avg_loss=0.08873, mel_loss=0.03843, linear_loss=0.05010]
[2020-05-12 06:42:01.138]  Step 155008  [3.415 sec/step, loss=0.09662, avg_loss=0.08873, mel_loss=0.04380, linear_loss=0.05282]
[2020-05-12 06:42:04.304]  Step 155009  [3.413 sec/step, loss=0.09461, avg_loss=0.08875, mel_loss=0.04214, linear_loss=0.05247]
[2020-05-12 06:42:07.939]  Step 155010  [3.439 sec/step, loss=0.09650, avg_loss=0.08892, mel_loss=0.04316, linear_loss=0.05334]
[2020-05-12 06:42:10.557]  Step 155011  [3.454 sec/step, loss=0.09275, avg_loss=0.08904, mel_loss=0.04110, linear_loss=0.05166]
[2020-05-12 06:42:12.458]  Step 155012  [3.406 sec/step, loss=0.08858, avg_loss=0.08897, mel_loss=0.03897, linear_loss=0.04961]
[2020-05-12 06:42:15.347]  Step 155013  [3.425 sec/step, loss=0.09147, avg_loss=0.08908, mel_loss=0.04066, linear_loss=0.05081]
[2020-05-12 06:42:16.444]  Step 155014  [3.292 sec/step, loss=0.08478, avg_loss=0.08918, mel_loss=0.03663, linear_loss=0.04815]
[2020-05-12 06:42:18.873]  Step 155015  [3.264 sec/step, loss=0.09054, avg_loss=0.08911, mel_loss=0.03979, linear_loss=0.05075]
[2020-05-12 06:42:21.587]  Step 155016  [3.276 sec/step, loss=0.09144, avg_loss=0.08916, mel_loss=0.04024, linear_loss=0.05120]
[2020-05-12 06:42:23.243]  Step 155017  [3.261 sec/step, loss=0.08720, avg_loss=0.08908, mel_loss=0.03809, linear_loss=0.04911]
[2020-05-12 06:42:24.001]  Step 155018  [3.242 sec/step, loss=0.07180, avg_loss=0.08889, mel_loss=0.03147, linear_loss=0.04033]
[2020-05-12 06:42:27.349]  Step 155019  [3.232 sec/step, loss=0.09454, avg_loss=0.08890, mel_loss=0.04245, linear_loss=0.05209]
[2020-05-12 06:42:30.341]  Step 155020  [3.238 sec/step, loss=0.09354, avg_loss=0.08892, mel_loss=0.04173, linear_loss=0.05180]
[2020-05-12 06:42:35.779]  Step 155021  [3.276 sec/step, loss=0.09658, avg_loss=0.08901, mel_loss=0.04358, linear_loss=0.05300]
[2020-05-12 06:42:40.339]  Step 155022  [3.293 sec/step, loss=0.09610, avg_loss=0.08903, mel_loss=0.04321, linear_loss=0.05289]
[2020-05-12 06:42:47.695]  Step 155023  [3.349 sec/step, loss=0.09738, avg_loss=0.08912, mel_loss=0.04457, linear_loss=0.05281]
[2020-05-12 06:42:50.039]  Step 155024  [3.360 sec/step, loss=0.09255, avg_loss=0.08922, mel_loss=0.04075, linear_loss=0.05180]
[2020-05-12 06:42:54.396]  Step 155025  [3.390 sec/step, loss=0.09576, avg_loss=0.08934, mel_loss=0.04307, linear_loss=0.05268]
[2020-05-12 06:42:57.758]  Step 155026  [3.415 sec/step, loss=0.09485, avg_loss=0.08954, mel_loss=0.04226, linear_loss=0.05259]
[2020-05-12 06:43:01.578]  Step 155027  [3.313 sec/step, loss=0.09579, avg_loss=0.08975, mel_loss=0.04279, linear_loss=0.05300]
[2020-05-12 06:43:02.800]  Step 155028  [3.280 sec/step, loss=0.08261, avg_loss=0.08960, mel_loss=0.03581, linear_loss=0.04680]
[2020-05-12 06:43:04.267]  Step 155029  [3.286 sec/step, loss=0.08511, avg_loss=0.08969, mel_loss=0.03702, linear_loss=0.04810]
[2020-05-12 06:43:05.572]  Step 155030  [3.227 sec/step, loss=0.08263, avg_loss=0.08956, mel_loss=0.03560, linear_loss=0.04703]
[2020-05-12 06:43:11.660]  Step 155031  [3.274 sec/step, loss=0.09631, avg_loss=0.08966, mel_loss=0.04398, linear_loss=0.05232]
[2020-05-12 06:43:13.049]  Step 155032  [3.268 sec/step, loss=0.08524, avg_loss=0.08962, mel_loss=0.03691, linear_loss=0.04833]
[2020-05-12 06:43:13.956]  Step 155033  [3.219 sec/step, loss=0.08008, avg_loss=0.08946, mel_loss=0.03415, linear_loss=0.04593]
[2020-05-12 06:43:15.975]  Step 155034  [3.218 sec/step, loss=0.08889, avg_loss=0.08944, mel_loss=0.03878, linear_loss=0.05011]
[2020-05-12 06:43:17.746]  Step 155035  [3.193 sec/step, loss=0.09015, avg_loss=0.08939, mel_loss=0.03906, linear_loss=0.05109]
[2020-05-12 06:43:19.502]  Generated 32 batches of size 32 in 1.751 sec
[2020-05-12 06:43:19.997]  Step 155036  [3.190 sec/step, loss=0.09105, avg_loss=0.08940, mel_loss=0.04010, linear_loss=0.05095]
[2020-05-12 06:43:20.753]  Step 155037  [3.158 sec/step, loss=0.07233, avg_loss=0.08916, mel_loss=0.03120, linear_loss=0.04113]
[2020-05-12 06:43:25.656]  Step 155038  [3.119 sec/step, loss=0.09530, avg_loss=0.08913, mel_loss=0.04284, linear_loss=0.05246]
[2020-05-12 06:43:26.674]  Step 155039  [3.062 sec/step, loss=0.08011, avg_loss=0.08896, mel_loss=0.03451, linear_loss=0.04560]
[2020-05-12 06:43:30.322]  Step 155040  [3.072 sec/step, loss=0.09541, avg_loss=0.08900, mel_loss=0.04269, linear_loss=0.05272]
[2020-05-12 06:43:31.156]  Step 155041  [3.070 sec/step, loss=0.07551, avg_loss=0.08896, mel_loss=0.03223, linear_loss=0.04328]
[2020-05-12 06:43:39.929]  Step 155042  [3.126 sec/step, loss=0.09311, avg_loss=0.08893, mel_loss=0.04291, linear_loss=0.05020]
[2020-05-12 06:43:41.906]  Step 155043  [3.111 sec/step, loss=0.08857, avg_loss=0.08888, mel_loss=0.03855, linear_loss=0.05001]
[2020-05-12 06:43:56.441]  Step 155044  [3.241 sec/step, loss=0.07825, avg_loss=0.08879, mel_loss=0.03713, linear_loss=0.04112]
[2020-05-12 06:44:03.538]  Step 155045  [3.302 sec/step, loss=0.09654, avg_loss=0.08895, mel_loss=0.04410, linear_loss=0.05245]
[2020-05-12 06:44:07.174]  Step 155046  [3.302 sec/step, loss=0.09719, avg_loss=0.08895, mel_loss=0.04352, linear_loss=0.05367]
[2020-05-12 06:44:10.364]  Step 155047  [3.323 sec/step, loss=0.09526, avg_loss=0.08909, mel_loss=0.04231, linear_loss=0.05295]
[2020-05-12 06:44:11.155]  Step 155048  [3.312 sec/step, loss=0.07290, avg_loss=0.08894, mel_loss=0.03127, linear_loss=0.04163]
[2020-05-12 06:44:14.487]  Step 155049  [3.322 sec/step, loss=0.09506, avg_loss=0.08899, mel_loss=0.04234, linear_loss=0.05272]
[2020-05-12 06:44:28.594]  Step 155050  [3.411 sec/step, loss=0.07476, avg_loss=0.08879, mel_loss=0.03531, linear_loss=0.03945]
[2020-05-12 06:44:28.594]  Writing summary at step: 155050
[2020-05-12 06:44:29.601]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155050
[2020-05-12 06:44:31.174]  Saving audio and alignment...
[2020-05-12 06:44:33.313]  Input: 파랑은 곧~______________
[2020-05-12 06:44:36.328]  Step 155051  [3.395 sec/step, loss=0.09298, avg_loss=0.08878, mel_loss=0.04102, linear_loss=0.05196]
[2020-05-12 06:44:41.684]  Step 155052  [3.403 sec/step, loss=0.09626, avg_loss=0.08878, mel_loss=0.04353, linear_loss=0.05273]
[2020-05-12 06:44:47.338]  Step 155053  [3.432 sec/step, loss=0.09658, avg_loss=0.08885, mel_loss=0.04411, linear_loss=0.05247]
[2020-05-12 06:44:50.813]  Step 155054  [3.438 sec/step, loss=0.09334, avg_loss=0.08887, mel_loss=0.04152, linear_loss=0.05183]
[2020-05-12 06:44:53.655]  Step 155055  [3.458 sec/step, loss=0.09094, avg_loss=0.08902, mel_loss=0.04058, linear_loss=0.05036]
[2020-05-12 06:44:55.836]  Step 155056  [3.463 sec/step, loss=0.09047, avg_loss=0.08903, mel_loss=0.03969, linear_loss=0.05077]
[2020-05-12 06:44:58.262]  Step 155057  [3.449 sec/step, loss=0.09071, avg_loss=0.08898, mel_loss=0.03969, linear_loss=0.05102]
[2020-05-12 06:44:58.829]  Step 155058  [3.435 sec/step, loss=0.07129, avg_loss=0.08881, mel_loss=0.03184, linear_loss=0.03945]
[2020-05-12 06:44:59.639]  Step 155059  [3.414 sec/step, loss=0.07850, avg_loss=0.08866, mel_loss=0.03346, linear_loss=0.04504]
[2020-05-12 06:45:01.288]  Step 155060  [3.368 sec/step, loss=0.08689, avg_loss=0.08859, mel_loss=0.03790, linear_loss=0.04899]
[2020-05-12 06:45:03.030]  Step 155061  [3.363 sec/step, loss=0.08836, avg_loss=0.08856, mel_loss=0.03850, linear_loss=0.04986]
[2020-05-12 06:45:04.379]  Step 155062  [3.371 sec/step, loss=0.08557, avg_loss=0.08871, mel_loss=0.03710, linear_loss=0.04848]
[2020-05-12 06:45:09.012]  Step 155063  [3.368 sec/step, loss=0.09612, avg_loss=0.08870, mel_loss=0.04359, linear_loss=0.05252]
[2020-05-12 06:45:10.816]  Step 155064  [3.370 sec/step, loss=0.08677, avg_loss=0.08871, mel_loss=0.03765, linear_loss=0.04913]
[2020-05-12 06:45:12.314]  Step 155065  [3.377 sec/step, loss=0.08436, avg_loss=0.08880, mel_loss=0.03656, linear_loss=0.04780]
[2020-05-12 06:45:14.024]  Generated 32 batches of size 32 in 1.703 sec
[2020-05-12 06:45:16.506]  Step 155066  [3.385 sec/step, loss=0.09467, avg_loss=0.08880, mel_loss=0.04222, linear_loss=0.05244]
[2020-05-12 06:45:19.133]  Step 155067  [3.356 sec/step, loss=0.09069, avg_loss=0.08872, mel_loss=0.04023, linear_loss=0.05047]
[2020-05-12 06:45:20.345]  Step 155068  [3.354 sec/step, loss=0.08619, avg_loss=0.08871, mel_loss=0.03727, linear_loss=0.04891]
[2020-05-12 06:45:22.446]  Step 155069  [3.339 sec/step, loss=0.08856, avg_loss=0.08862, mel_loss=0.03894, linear_loss=0.04962]
[2020-05-12 06:45:28.944]  Step 155070  [3.369 sec/step, loss=0.09628, avg_loss=0.08865, mel_loss=0.04405, linear_loss=0.05223]
[2020-05-12 06:45:30.918]  Step 155071  [3.378 sec/step, loss=0.08982, avg_loss=0.08875, mel_loss=0.03948, linear_loss=0.05033]
[2020-05-12 06:45:39.702]  Step 155072  [3.448 sec/step, loss=0.09529, avg_loss=0.08883, mel_loss=0.04367, linear_loss=0.05162]
[2020-05-12 06:45:40.808]  Step 155073  [3.435 sec/step, loss=0.08295, avg_loss=0.08874, mel_loss=0.03522, linear_loss=0.04773]
[2020-05-12 06:45:44.916]  Step 155074  [3.464 sec/step, loss=0.09511, avg_loss=0.08887, mel_loss=0.04266, linear_loss=0.05245]
[2020-05-12 06:45:48.947]  Step 155075  [3.484 sec/step, loss=0.09560, avg_loss=0.08891, mel_loss=0.04274, linear_loss=0.05285]
[2020-05-12 06:45:57.173]  Step 155076  [3.492 sec/step, loss=0.09610, avg_loss=0.08889, mel_loss=0.04429, linear_loss=0.05181]
[2020-05-12 06:46:02.887]  Step 155077  [3.535 sec/step, loss=0.09609, avg_loss=0.08898, mel_loss=0.04337, linear_loss=0.05273]
[2020-05-12 06:46:04.377]  Step 155078  [3.528 sec/step, loss=0.08590, avg_loss=0.08894, mel_loss=0.03727, linear_loss=0.04863]
[2020-05-12 06:46:06.574]  Step 155079  [3.416 sec/step, loss=0.09047, avg_loss=0.08903, mel_loss=0.03964, linear_loss=0.05082]
[2020-05-12 06:46:07.429]  Step 155080  [3.411 sec/step, loss=0.07558, avg_loss=0.08896, mel_loss=0.03226, linear_loss=0.04332]
[2020-05-12 06:46:09.482]  Step 155081  [3.423 sec/step, loss=0.08837, avg_loss=0.08906, mel_loss=0.03821, linear_loss=0.05016]
[2020-05-12 06:46:10.101]  Step 155082  [3.342 sec/step, loss=0.06858, avg_loss=0.08881, mel_loss=0.02953, linear_loss=0.03905]
[2020-05-12 06:46:11.462]  Step 155083  [3.346 sec/step, loss=0.08365, avg_loss=0.08882, mel_loss=0.03601, linear_loss=0.04764]
[2020-05-12 06:46:15.229]  Step 155084  [3.338 sec/step, loss=0.09277, avg_loss=0.08877, mel_loss=0.04139, linear_loss=0.05138]
[2020-05-12 06:46:16.322]  Step 155085  [3.325 sec/step, loss=0.07949, avg_loss=0.08867, mel_loss=0.03412, linear_loss=0.04537]
[2020-05-12 06:46:18.452]  Step 155086  [3.336 sec/step, loss=0.08930, avg_loss=0.08871, mel_loss=0.03914, linear_loss=0.05016]
[2020-05-12 06:46:22.758]  Step 155087  [3.371 sec/step, loss=0.09626, avg_loss=0.08893, mel_loss=0.04300, linear_loss=0.05325]
[2020-05-12 06:46:25.694]  Step 155088  [3.384 sec/step, loss=0.09012, avg_loss=0.08895, mel_loss=0.03997, linear_loss=0.05015]
[2020-05-12 06:46:26.760]  Step 155089  [3.331 sec/step, loss=0.08194, avg_loss=0.08880, mel_loss=0.03527, linear_loss=0.04666]
[2020-05-12 06:46:29.562]  Step 155090  [3.227 sec/step, loss=0.09288, avg_loss=0.08892, mel_loss=0.04122, linear_loss=0.05166]
[2020-05-12 06:46:37.401]  Step 155091  [3.270 sec/step, loss=0.09792, avg_loss=0.08896, mel_loss=0.04497, linear_loss=0.05296]
[2020-05-12 06:46:41.007]  Step 155092  [3.293 sec/step, loss=0.09497, avg_loss=0.08908, mel_loss=0.04248, linear_loss=0.05249]
[2020-05-12 06:46:44.125]  Step 155093  [3.235 sec/step, loss=0.09280, avg_loss=0.08906, mel_loss=0.04105, linear_loss=0.05175]
[2020-05-12 06:46:45.261]  Step 155094  [3.212 sec/step, loss=0.08071, avg_loss=0.08894, mel_loss=0.03464, linear_loss=0.04608]
[2020-05-12 06:46:49.915]  Step 155095  [3.237 sec/step, loss=0.09650, avg_loss=0.08901, mel_loss=0.04334, linear_loss=0.05316]
[2020-05-12 06:46:55.090]  Step 155096  [3.273 sec/step, loss=0.09543, avg_loss=0.08907, mel_loss=0.04332, linear_loss=0.05211]
[2020-05-12 06:46:56.889]  Step 155097  [3.277 sec/step, loss=0.08744, avg_loss=0.08910, mel_loss=0.03820, linear_loss=0.04925]
[2020-05-12 06:46:58.566]  Generated 32 batches of size 32 in 1.672 sec
[2020-05-12 06:47:10.131]  Step 155098  [3.356 sec/step, loss=0.08048, avg_loss=0.08894, mel_loss=0.03773, linear_loss=0.04275]
[2020-05-12 06:47:16.880]  Step 155099  [3.416 sec/step, loss=0.09597, avg_loss=0.08910, mel_loss=0.04376, linear_loss=0.05221]
[2020-05-12 06:47:17.733]  Step 155100  [3.415 sec/step, loss=0.07474, avg_loss=0.08909, mel_loss=0.03247, linear_loss=0.04227]
[2020-05-12 06:47:17.733]  Writing summary at step: 155100
[2020-05-12 06:47:18.628]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155100
[2020-05-12 06:47:20.164]  Saving audio and alignment...
[2020-05-12 06:47:24.540]  Input: 수많은  상처를 안고 살아가는 거리에 여자지만~__
[2020-05-12 06:47:26.156]  Step 155101  [3.389 sec/step, loss=0.08504, avg_loss=0.08901, mel_loss=0.03721, linear_loss=0.04783]
[2020-05-12 06:47:27.884]  Step 155102  [3.359 sec/step, loss=0.08769, avg_loss=0.08892, mel_loss=0.03820, linear_loss=0.04950]
[2020-05-12 06:47:30.278]  Step 155103  [3.362 sec/step, loss=0.08850, avg_loss=0.08894, mel_loss=0.03908, linear_loss=0.04943]
[2020-05-12 06:47:31.663]  Step 155104  [3.300 sec/step, loss=0.08536, avg_loss=0.08882, mel_loss=0.03718, linear_loss=0.04817]
[2020-05-12 06:47:34.092]  Step 155105  [3.318 sec/step, loss=0.09008, avg_loss=0.08904, mel_loss=0.03963, linear_loss=0.05045]
[2020-05-12 06:47:36.955]  Step 155106  [3.318 sec/step, loss=0.09015, avg_loss=0.08900, mel_loss=0.04010, linear_loss=0.05005]
[2020-05-12 06:47:42.585]  Step 155107  [3.356 sec/step, loss=0.09676, avg_loss=0.08908, mel_loss=0.04415, linear_loss=0.05261]
[2020-05-12 06:47:49.742]  Step 155108  [3.371 sec/step, loss=0.09636, avg_loss=0.08908, mel_loss=0.04403, linear_loss=0.05232]
[2020-05-12 06:48:03.931]  Step 155109  [3.481 sec/step, loss=0.07579, avg_loss=0.08889, mel_loss=0.03577, linear_loss=0.04003]
[2020-05-12 06:48:12.784]  Step 155110  [3.533 sec/step, loss=0.09394, avg_loss=0.08886, mel_loss=0.04319, linear_loss=0.05075]
[2020-05-12 06:48:16.327]  Step 155111  [3.542 sec/step, loss=0.09272, avg_loss=0.08886, mel_loss=0.04118, linear_loss=0.05155]
[2020-05-12 06:48:17.530]  Step 155112  [3.535 sec/step, loss=0.08446, avg_loss=0.08882, mel_loss=0.03664, linear_loss=0.04783]
[2020-05-12 06:48:18.097]  Step 155113  [3.512 sec/step, loss=0.06728, avg_loss=0.08858, mel_loss=0.02965, linear_loss=0.03764]
[2020-05-12 06:48:19.904]  Step 155114  [3.519 sec/step, loss=0.08852, avg_loss=0.08862, mel_loss=0.03830, linear_loss=0.05022]
[2020-05-12 06:48:22.139]  Step 155115  [3.517 sec/step, loss=0.08910, avg_loss=0.08860, mel_loss=0.03918, linear_loss=0.04993]
[2020-05-12 06:48:23.146]  Step 155116  [3.500 sec/step, loss=0.08016, avg_loss=0.08849, mel_loss=0.03471, linear_loss=0.04545]
[2020-05-12 06:48:23.781]  Step 155117  [3.490 sec/step, loss=0.07417, avg_loss=0.08836, mel_loss=0.03228, linear_loss=0.04189]
[2020-05-12 06:48:25.167]  Step 155118  [3.496 sec/step, loss=0.08624, avg_loss=0.08851, mel_loss=0.03761, linear_loss=0.04863]
[2020-05-12 06:48:28.866]  Step 155119  [3.500 sec/step, loss=0.09572, avg_loss=0.08852, mel_loss=0.04270, linear_loss=0.05302]
[2020-05-12 06:48:33.028]  Step 155120  [3.511 sec/step, loss=0.09410, avg_loss=0.08852, mel_loss=0.04200, linear_loss=0.05209]
[2020-05-12 06:48:34.686]  Step 155121  [3.474 sec/step, loss=0.08796, avg_loss=0.08844, mel_loss=0.03842, linear_loss=0.04953]
[2020-05-12 06:48:38.096]  Step 155122  [3.462 sec/step, loss=0.09445, avg_loss=0.08842, mel_loss=0.04228, linear_loss=0.05217]
[2020-05-12 06:48:41.127]  Step 155123  [3.419 sec/step, loss=0.09400, avg_loss=0.08839, mel_loss=0.04168, linear_loss=0.05232]
[2020-05-12 06:48:42.726]  Step 155124  [3.411 sec/step, loss=0.08851, avg_loss=0.08835, mel_loss=0.03835, linear_loss=0.05016]
[2020-05-12 06:48:46.390]  Step 155125  [3.404 sec/step, loss=0.09459, avg_loss=0.08833, mel_loss=0.04217, linear_loss=0.05242]
[2020-05-12 06:48:53.675]  Step 155126  [3.444 sec/step, loss=0.09725, avg_loss=0.08836, mel_loss=0.04373, linear_loss=0.05353]
[2020-05-12 06:48:57.267]  Step 155127  [3.441 sec/step, loss=0.09040, avg_loss=0.08830, mel_loss=0.03967, linear_loss=0.05074]
[2020-05-12 06:48:58.482]  Step 155128  [3.441 sec/step, loss=0.08288, avg_loss=0.08831, mel_loss=0.03537, linear_loss=0.04751]
[2020-05-12 06:48:59.002]  Generated 32 batches of size 32 in 1.730 sec
[2020-05-12 06:48:59.532]  Step 155129  [3.437 sec/step, loss=0.08050, avg_loss=0.08826, mel_loss=0.03436, linear_loss=0.04614]
[2020-05-12 06:49:01.677]  Step 155130  [3.446 sec/step, loss=0.08979, avg_loss=0.08833, mel_loss=0.03951, linear_loss=0.05028]
[2020-05-12 06:49:03.043]  Step 155131  [3.398 sec/step, loss=0.08470, avg_loss=0.08822, mel_loss=0.03648, linear_loss=0.04822]
[2020-05-12 06:49:03.859]  Step 155132  [3.393 sec/step, loss=0.07728, avg_loss=0.08814, mel_loss=0.03291, linear_loss=0.04437]
[2020-05-12 06:49:08.297]  Step 155133  [3.428 sec/step, loss=0.09450, avg_loss=0.08828, mel_loss=0.04264, linear_loss=0.05186]
[2020-05-12 06:49:14.846]  Step 155134  [3.473 sec/step, loss=0.09693, avg_loss=0.08836, mel_loss=0.04424, linear_loss=0.05269]
[2020-05-12 06:49:19.968]  Step 155135  [3.507 sec/step, loss=0.09619, avg_loss=0.08842, mel_loss=0.04345, linear_loss=0.05274]
[2020-05-12 06:49:21.971]  Step 155136  [3.504 sec/step, loss=0.08970, avg_loss=0.08841, mel_loss=0.03922, linear_loss=0.05048]
[2020-05-12 06:49:24.064]  Step 155137  [3.518 sec/step, loss=0.09058, avg_loss=0.08859, mel_loss=0.03977, linear_loss=0.05081]
[2020-05-12 06:49:37.510]  Step 155138  [3.603 sec/step, loss=0.07985, avg_loss=0.08844, mel_loss=0.03764, linear_loss=0.04221]
[2020-05-12 06:49:38.515]  Step 155139  [3.603 sec/step, loss=0.08123, avg_loss=0.08845, mel_loss=0.03483, linear_loss=0.04640]
[2020-05-12 06:49:46.909]  Step 155140  [3.650 sec/step, loss=0.09675, avg_loss=0.08846, mel_loss=0.04456, linear_loss=0.05219]
[2020-05-12 06:49:48.927]  Step 155141  [3.662 sec/step, loss=0.08828, avg_loss=0.08859, mel_loss=0.03859, linear_loss=0.04969]
[2020-05-12 06:49:56.299]  Step 155142  [3.648 sec/step, loss=0.09567, avg_loss=0.08861, mel_loss=0.04370, linear_loss=0.05197]
[2020-05-12 06:49:57.693]  Step 155143  [3.642 sec/step, loss=0.08619, avg_loss=0.08859, mel_loss=0.03734, linear_loss=0.04886]
[2020-05-12 06:50:03.920]  Step 155144  [3.559 sec/step, loss=0.09391, avg_loss=0.08875, mel_loss=0.04273, linear_loss=0.05118]
[2020-05-12 06:50:07.483]  Step 155145  [3.524 sec/step, loss=0.09373, avg_loss=0.08872, mel_loss=0.04191, linear_loss=0.05182]
[2020-05-12 06:50:08.983]  Step 155146  [3.503 sec/step, loss=0.08562, avg_loss=0.08860, mel_loss=0.03709, linear_loss=0.04853]
[2020-05-12 06:50:09.797]  Step 155147  [3.479 sec/step, loss=0.07604, avg_loss=0.08841, mel_loss=0.03266, linear_loss=0.04338]
[2020-05-12 06:50:12.035]  Step 155148  [3.493 sec/step, loss=0.09033, avg_loss=0.08859, mel_loss=0.03951, linear_loss=0.05083]
[2020-05-12 06:50:14.555]  Step 155149  [3.485 sec/step, loss=0.09126, avg_loss=0.08855, mel_loss=0.04026, linear_loss=0.05100]
[2020-05-12 06:50:17.737]  Step 155150  [3.376 sec/step, loss=0.09358, avg_loss=0.08874, mel_loss=0.04148, linear_loss=0.05210]
[2020-05-12 06:50:17.737]  Writing summary at step: 155150
[2020-05-12 06:50:21.422]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155150
[2020-05-12 06:50:23.019]  Saving audio and alignment...
[2020-05-12 06:50:24.750]  Input: 동요제~___________________
[2020-05-12 06:50:26.135]  Step 155151  [3.360 sec/step, loss=0.08280, avg_loss=0.08863, mel_loss=0.03576, linear_loss=0.04705]
[2020-05-12 06:50:28.917]  Step 155152  [3.334 sec/step, loss=0.09139, avg_loss=0.08859, mel_loss=0.04027, linear_loss=0.05112]
[2020-05-12 06:50:30.697]  Step 155153  [3.295 sec/step, loss=0.08629, avg_loss=0.08848, mel_loss=0.03750, linear_loss=0.04879]
[2020-05-12 06:50:35.080]  Step 155154  [3.304 sec/step, loss=0.09462, avg_loss=0.08850, mel_loss=0.04237, linear_loss=0.05225]
[2020-05-12 06:50:38.042]  Step 155155  [3.305 sec/step, loss=0.09110, avg_loss=0.08850, mel_loss=0.04009, linear_loss=0.05100]
[2020-05-12 06:50:43.779]  Step 155156  [3.341 sec/step, loss=0.09611, avg_loss=0.08855, mel_loss=0.04356, linear_loss=0.05255]
[2020-05-12 06:50:48.400]  Step 155157  [3.363 sec/step, loss=0.09644, avg_loss=0.08861, mel_loss=0.04323, linear_loss=0.05321]
[2020-05-12 06:50:50.286]  Generated 32 batches of size 32 in 1.879 sec
[2020-05-12 06:50:52.336]  Step 155158  [3.397 sec/step, loss=0.09676, avg_loss=0.08887, mel_loss=0.04338, linear_loss=0.05339]
[2020-05-12 06:50:53.447]  Step 155159  [3.400 sec/step, loss=0.08305, avg_loss=0.08891, mel_loss=0.03536, linear_loss=0.04769]
[2020-05-12 06:50:58.518]  Step 155160  [3.434 sec/step, loss=0.09527, avg_loss=0.08899, mel_loss=0.04294, linear_loss=0.05233]
[2020-05-12 06:50:59.140]  Step 155161  [3.423 sec/step, loss=0.06967, avg_loss=0.08881, mel_loss=0.03082, linear_loss=0.03885]
[2020-05-12 06:51:01.110]  Step 155162  [3.429 sec/step, loss=0.08746, avg_loss=0.08883, mel_loss=0.03793, linear_loss=0.04952]
[2020-05-12 06:51:04.224]  Step 155163  [3.414 sec/step, loss=0.09427, avg_loss=0.08881, mel_loss=0.04179, linear_loss=0.05248]
[2020-05-12 06:51:05.860]  Step 155164  [3.412 sec/step, loss=0.08711, avg_loss=0.08881, mel_loss=0.03806, linear_loss=0.04905]
[2020-05-12 06:51:06.742]  Step 155165  [3.406 sec/step, loss=0.07966, avg_loss=0.08876, mel_loss=0.03377, linear_loss=0.04589]
[2020-05-12 06:51:07.939]  Step 155166  [3.376 sec/step, loss=0.08398, avg_loss=0.08866, mel_loss=0.03613, linear_loss=0.04785]
[2020-05-12 06:51:14.545]  Step 155167  [3.416 sec/step, loss=0.09763, avg_loss=0.08873, mel_loss=0.04469, linear_loss=0.05295]
[2020-05-12 06:51:16.946]  Step 155168  [3.428 sec/step, loss=0.09028, avg_loss=0.08877, mel_loss=0.03948, linear_loss=0.05080]
[2020-05-12 06:51:19.751]  Step 155169  [3.435 sec/step, loss=0.09254, avg_loss=0.08881, mel_loss=0.04101, linear_loss=0.05153]
[2020-05-12 06:51:35.549]  Step 155170  [3.528 sec/step, loss=0.07785, avg_loss=0.08862, mel_loss=0.03663, linear_loss=0.04122]
[2020-05-12 06:51:36.637]  Step 155171  [3.519 sec/step, loss=0.07964, avg_loss=0.08852, mel_loss=0.03395, linear_loss=0.04569]
[2020-05-12 06:51:37.447]  Step 155172  [3.439 sec/step, loss=0.07457, avg_loss=0.08831, mel_loss=0.03255, linear_loss=0.04201]
[2020-05-12 06:51:39.101]  Step 155173  [3.444 sec/step, loss=0.08745, avg_loss=0.08836, mel_loss=0.03819, linear_loss=0.04926]
[2020-05-12 06:51:42.217]  Step 155174  [3.435 sec/step, loss=0.09223, avg_loss=0.08833, mel_loss=0.04103, linear_loss=0.05120]
[2020-05-12 06:51:51.568]  Step 155175  [3.488 sec/step, loss=0.09417, avg_loss=0.08832, mel_loss=0.04331, linear_loss=0.05086]
[2020-05-12 06:51:52.596]  Step 155176  [3.416 sec/step, loss=0.07983, avg_loss=0.08815, mel_loss=0.03475, linear_loss=0.04508]
[2020-05-12 06:51:55.199]  Step 155177  [3.385 sec/step, loss=0.09042, avg_loss=0.08810, mel_loss=0.03968, linear_loss=0.05073]
[2020-05-12 06:51:56.537]  Step 155178  [3.383 sec/step, loss=0.08251, avg_loss=0.08806, mel_loss=0.03583, linear_loss=0.04668]
[2020-05-12 06:52:01.218]  Step 155179  [3.408 sec/step, loss=0.09678, avg_loss=0.08813, mel_loss=0.04370, linear_loss=0.05308]
[2020-05-12 06:52:03.230]  Step 155180  [3.420 sec/step, loss=0.09025, avg_loss=0.08827, mel_loss=0.03944, linear_loss=0.05081]
[2020-05-12 06:52:07.745]  Step 155181  [3.444 sec/step, loss=0.09484, avg_loss=0.08834, mel_loss=0.04284, linear_loss=0.05200]
[2020-05-12 06:52:09.317]  Step 155182  [3.454 sec/step, loss=0.08515, avg_loss=0.08850, mel_loss=0.03685, linear_loss=0.04830]
[2020-05-12 06:52:14.716]  Step 155183  [3.494 sec/step, loss=0.09724, avg_loss=0.08864, mel_loss=0.04389, linear_loss=0.05335]
[2020-05-12 06:52:15.839]  Step 155184  [3.468 sec/step, loss=0.08120, avg_loss=0.08852, mel_loss=0.03482, linear_loss=0.04637]
[2020-05-12 06:52:17.613]  Step 155185  [3.474 sec/step, loss=0.08784, avg_loss=0.08861, mel_loss=0.03830, linear_loss=0.04954]
[2020-05-12 06:52:18.429]  Step 155186  [3.461 sec/step, loss=0.07654, avg_loss=0.08848, mel_loss=0.03245, linear_loss=0.04409]
[2020-05-12 06:52:20.693]  Step 155187  [3.441 sec/step, loss=0.09018, avg_loss=0.08842, mel_loss=0.03973, linear_loss=0.05045]
[2020-05-12 06:52:22.734]  Step 155188  [3.432 sec/step, loss=0.08892, avg_loss=0.08841, mel_loss=0.03902, linear_loss=0.04990]
[2020-05-12 06:52:28.545]  Step 155189  [3.479 sec/step, loss=0.09651, avg_loss=0.08855, mel_loss=0.04382, linear_loss=0.05269]
[2020-05-12 06:52:29.340]  Step 155190  [3.459 sec/step, loss=0.07062, avg_loss=0.08833, mel_loss=0.03033, linear_loss=0.04030]
[2020-05-12 06:52:33.423]  Step 155191  [3.422 sec/step, loss=0.09333, avg_loss=0.08828, mel_loss=0.04149, linear_loss=0.05185]
[2020-05-12 06:52:37.212]  Step 155192  [3.424 sec/step, loss=0.09575, avg_loss=0.08829, mel_loss=0.04270, linear_loss=0.05305]
[2020-05-12 06:52:40.715]  Step 155193  [3.427 sec/step, loss=0.09334, avg_loss=0.08830, mel_loss=0.04148, linear_loss=0.05185]
[2020-05-12 06:52:43.964]  Step 155194  [3.449 sec/step, loss=0.09525, avg_loss=0.08844, mel_loss=0.04227, linear_loss=0.05299]
[2020-05-12 06:52:47.484]  Step 155195  [3.437 sec/step, loss=0.09511, avg_loss=0.08843, mel_loss=0.04252, linear_loss=0.05259]
[2020-05-12 06:52:55.319]  Step 155196  [3.464 sec/step, loss=0.09808, avg_loss=0.08845, mel_loss=0.04501, linear_loss=0.05307]
[2020-05-12 06:52:56.770]  Step 155197  [3.460 sec/step, loss=0.08510, avg_loss=0.08843, mel_loss=0.03698, linear_loss=0.04813]
[2020-05-12 06:52:58.667]  Step 155198  [3.347 sec/step, loss=0.08623, avg_loss=0.08849, mel_loss=0.03745, linear_loss=0.04878]
[2020-05-12 06:53:19.168]  Generated 32 batches of size 32 in 50.617 sec
[2020-05-12 06:53:20.351]  Step 155199  [3.496 sec/step, loss=0.08333, avg_loss=0.08836, mel_loss=0.03537, linear_loss=0.04796]
[2020-05-12 06:53:22.875]  Step 155200  [3.513 sec/step, loss=0.09100, avg_loss=0.08852, mel_loss=0.03981, linear_loss=0.05119]
[2020-05-12 06:53:22.876]  Writing summary at step: 155200
[2020-05-12 06:53:24.183]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155200
[2020-05-12 06:53:25.695]  Saving audio and alignment...
[2020-05-12 06:53:29.239]  Input: 아무리 제가 여기서 말의 내용은~______________
[2020-05-12 06:53:29.800]  Step 155201  [3.502 sec/step, loss=0.06781, avg_loss=0.08835, mel_loss=0.02978, linear_loss=0.03802]
[2020-05-12 06:53:32.027]  Step 155202  [3.507 sec/step, loss=0.08834, avg_loss=0.08836, mel_loss=0.03878, linear_loss=0.04956]
[2020-05-12 06:53:35.326]  Step 155203  [3.516 sec/step, loss=0.09458, avg_loss=0.08842, mel_loss=0.04177, linear_loss=0.05281]
[2020-05-12 06:53:40.128]  Step 155204  [3.551 sec/step, loss=0.09510, avg_loss=0.08852, mel_loss=0.04259, linear_loss=0.05251]
[2020-05-12 06:53:49.193]  Step 155205  [3.617 sec/step, loss=0.09679, avg_loss=0.08858, mel_loss=0.04465, linear_loss=0.05214]
[2020-05-12 06:53:57.202]  Step 155206  [3.668 sec/step, loss=0.09760, avg_loss=0.08866, mel_loss=0.04481, linear_loss=0.05279]
[2020-05-12 06:53:58.664]  Step 155207  [3.627 sec/step, loss=0.08588, avg_loss=0.08855, mel_loss=0.03700, linear_loss=0.04888]
[2020-05-12 06:54:00.340]  Step 155208  [3.572 sec/step, loss=0.08610, avg_loss=0.08845, mel_loss=0.03761, linear_loss=0.04849]
[2020-05-12 06:54:04.845]  Step 155209  [3.475 sec/step, loss=0.09681, avg_loss=0.08866, mel_loss=0.04356, linear_loss=0.05324]
[2020-05-12 06:54:19.247]  Step 155210  [3.531 sec/step, loss=0.07660, avg_loss=0.08848, mel_loss=0.03612, linear_loss=0.04048]
[2020-05-12 06:54:22.214]  Step 155211  [3.525 sec/step, loss=0.09195, avg_loss=0.08848, mel_loss=0.04092, linear_loss=0.05103]
[2020-05-12 06:54:25.792]  Step 155212  [3.549 sec/step, loss=0.09325, avg_loss=0.08856, mel_loss=0.04156, linear_loss=0.05169]
[2020-05-12 06:54:29.318]  Step 155213  [3.578 sec/step, loss=0.09359, avg_loss=0.08883, mel_loss=0.04166, linear_loss=0.05194]
[2020-05-12 06:54:30.203]  Step 155214  [3.569 sec/step, loss=0.07058, avg_loss=0.08865, mel_loss=0.03027, linear_loss=0.04031]
[2020-05-12 06:54:36.113]  Step 155215  [3.606 sec/step, loss=0.09716, avg_loss=0.08873, mel_loss=0.04407, linear_loss=0.05309]
[2020-05-12 06:54:37.151]  Step 155216  [3.606 sec/step, loss=0.07892, avg_loss=0.08872, mel_loss=0.03352, linear_loss=0.04540]
[2020-05-12 06:54:41.485]  Step 155217  [3.643 sec/step, loss=0.09514, avg_loss=0.08893, mel_loss=0.04244, linear_loss=0.05270]
[2020-05-12 06:54:48.546]  Step 155218  [3.700 sec/step, loss=0.09629, avg_loss=0.08903, mel_loss=0.04389, linear_loss=0.05240]
[2020-05-12 06:54:49.578]  Step 155219  [3.673 sec/step, loss=0.08000, avg_loss=0.08887, mel_loss=0.03402, linear_loss=0.04598]
[2020-05-12 06:54:52.302]  Step 155220  [3.659 sec/step, loss=0.09099, avg_loss=0.08884, mel_loss=0.04004, linear_loss=0.05095]
[2020-05-12 06:54:55.556]  Step 155221  [3.675 sec/step, loss=0.09411, avg_loss=0.08890, mel_loss=0.04173, linear_loss=0.05237]
[2020-05-12 06:54:57.295]  Step 155222  [3.658 sec/step, loss=0.08700, avg_loss=0.08883, mel_loss=0.03794, linear_loss=0.04906]
[2020-05-12 06:54:58.771]  Step 155223  [3.642 sec/step, loss=0.08346, avg_loss=0.08872, mel_loss=0.03629, linear_loss=0.04717]
[2020-05-12 06:55:00.924]  Step 155224  [3.648 sec/step, loss=0.09056, avg_loss=0.08874, mel_loss=0.03959, linear_loss=0.05097]
[2020-05-12 06:55:04.703]  Step 155225  [3.649 sec/step, loss=0.09503, avg_loss=0.08874, mel_loss=0.04231, linear_loss=0.05272]
[2020-05-12 06:55:06.568]  Step 155226  [3.595 sec/step, loss=0.08604, avg_loss=0.08863, mel_loss=0.03751, linear_loss=0.04854]
[2020-05-12 06:55:12.028]  Step 155227  [3.614 sec/step, loss=0.09501, avg_loss=0.08868, mel_loss=0.04296, linear_loss=0.05205]
[2020-05-12 06:55:12.842]  Step 155228  [3.610 sec/step, loss=0.07684, avg_loss=0.08862, mel_loss=0.03290, linear_loss=0.04394]
[2020-05-12 06:55:53.009]  Generated 32 batches of size 32 in 63.424 sec
[2020-05-12 06:55:55.523]  Step 155229  [4.026 sec/step, loss=0.08918, avg_loss=0.08871, mel_loss=0.03914, linear_loss=0.05005]
[2020-05-12 06:55:58.457]  Step 155230  [4.034 sec/step, loss=0.09320, avg_loss=0.08874, mel_loss=0.04137, linear_loss=0.05183]
[2020-05-12 06:55:59.590]  Step 155231  [4.031 sec/step, loss=0.08172, avg_loss=0.08871, mel_loss=0.03522, linear_loss=0.04650]
[2020-05-12 06:56:00.976]  Step 155232  [4.037 sec/step, loss=0.08397, avg_loss=0.08878, mel_loss=0.03611, linear_loss=0.04786]
[2020-05-12 06:56:03.142]  Step 155233  [4.014 sec/step, loss=0.09002, avg_loss=0.08873, mel_loss=0.03991, linear_loss=0.05011]
[2020-05-12 06:56:05.790]  Step 155234  [3.975 sec/step, loss=0.09136, avg_loss=0.08868, mel_loss=0.04047, linear_loss=0.05089]
[2020-05-12 06:56:06.992]  Step 155235  [3.936 sec/step, loss=0.08304, avg_loss=0.08854, mel_loss=0.03559, linear_loss=0.04745]
[2020-05-12 06:56:11.238]  Step 155236  [3.959 sec/step, loss=0.09252, avg_loss=0.08857, mel_loss=0.04146, linear_loss=0.05106]
[2020-05-12 06:56:14.884]  Step 155237  [3.974 sec/step, loss=0.09283, avg_loss=0.08859, mel_loss=0.04135, linear_loss=0.05148]
[2020-05-12 06:56:16.408]  Step 155238  [3.855 sec/step, loss=0.08434, avg_loss=0.08864, mel_loss=0.03653, linear_loss=0.04781]
[2020-05-12 06:56:18.466]  Step 155239  [3.865 sec/step, loss=0.08927, avg_loss=0.08872, mel_loss=0.03919, linear_loss=0.05007]
[2020-05-12 06:56:24.286]  Step 155240  [3.840 sec/step, loss=0.09724, avg_loss=0.08873, mel_loss=0.04439, linear_loss=0.05285]
[2020-05-12 06:56:26.042]  Step 155241  [3.837 sec/step, loss=0.08854, avg_loss=0.08873, mel_loss=0.03839, linear_loss=0.05015]
[2020-05-12 06:56:39.008]  Step 155242  [3.893 sec/step, loss=0.08044, avg_loss=0.08858, mel_loss=0.03767, linear_loss=0.04277]
[2020-05-12 06:56:43.375]  Step 155243  [3.923 sec/step, loss=0.09476, avg_loss=0.08866, mel_loss=0.04284, linear_loss=0.05193]
[2020-05-12 06:56:45.351]  Step 155244  [3.880 sec/step, loss=0.08815, avg_loss=0.08860, mel_loss=0.03852, linear_loss=0.04963]
[2020-05-12 06:56:50.857]  Step 155245  [3.900 sec/step, loss=0.09772, avg_loss=0.08864, mel_loss=0.04433, linear_loss=0.05339]
[2020-05-12 06:56:53.960]  Step 155246  [3.916 sec/step, loss=0.09223, avg_loss=0.08871, mel_loss=0.04107, linear_loss=0.05115]
[2020-05-12 06:56:58.865]  Step 155247  [3.957 sec/step, loss=0.09471, avg_loss=0.08890, mel_loss=0.04241, linear_loss=0.05230]
[2020-05-12 06:57:02.293]  Step 155248  [3.969 sec/step, loss=0.09200, avg_loss=0.08891, mel_loss=0.04114, linear_loss=0.05086]
[2020-05-12 06:57:03.052]  Step 155249  [3.951 sec/step, loss=0.07918, avg_loss=0.08879, mel_loss=0.03380, linear_loss=0.04538]
[2020-05-12 06:57:04.691]  Step 155250  [3.935 sec/step, loss=0.08754, avg_loss=0.08873, mel_loss=0.03799, linear_loss=0.04955]
[2020-05-12 06:57:04.691]  Writing summary at step: 155250
[2020-05-12 06:57:06.528]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155250
[2020-05-12 06:57:08.069]  Saving audio and alignment...
[2020-05-12 06:57:17.755]  Input: 올렸는데 이번에는 저축에 주는 날이라 생각이 들어요 이렇게 어미처리 여도 다르게 주고 있습니다~_________________
[2020-05-12 06:57:18.276]  Step 155251  [3.927 sec/step, loss=0.07465, avg_loss=0.08865, mel_loss=0.03269, linear_loss=0.04196]
[2020-05-12 06:57:26.576]  Step 155252  [3.982 sec/step, loss=0.09345, avg_loss=0.08867, mel_loss=0.04298, linear_loss=0.05047]
[2020-05-12 06:57:27.341]  Step 155253  [3.972 sec/step, loss=0.07467, avg_loss=0.08855, mel_loss=0.03192, linear_loss=0.04276]
[2020-05-12 06:57:28.227]  Step 155254  [3.937 sec/step, loss=0.07965, avg_loss=0.08840, mel_loss=0.03399, linear_loss=0.04566]
[2020-05-12 06:57:30.756]  Step 155255  [3.933 sec/step, loss=0.09206, avg_loss=0.08841, mel_loss=0.04065, linear_loss=0.05141]
[2020-05-12 06:57:31.133]  Generated 32 batches of size 32 in 22.443 sec
[2020-05-12 06:57:34.491]  Step 155256  [3.913 sec/step, loss=0.09506, avg_loss=0.08840, mel_loss=0.04266, linear_loss=0.05240]
[2020-05-12 06:57:35.825]  Step 155257  [3.880 sec/step, loss=0.08327, avg_loss=0.08827, mel_loss=0.03601, linear_loss=0.04727]
[2020-05-12 06:57:36.844]  Step 155258  [3.851 sec/step, loss=0.08182, avg_loss=0.08812, mel_loss=0.03503, linear_loss=0.04680]
[2020-05-12 06:57:38.519]  Step 155259  [3.856 sec/step, loss=0.08638, avg_loss=0.08816, mel_loss=0.03781, linear_loss=0.04858]
[2020-05-12 06:57:39.409]  Step 155260  [3.814 sec/step, loss=0.07262, avg_loss=0.08793, mel_loss=0.03134, linear_loss=0.04128]
[2020-05-12 06:57:40.850]  Step 155261  [3.823 sec/step, loss=0.08613, avg_loss=0.08809, mel_loss=0.03725, linear_loss=0.04888]
[2020-05-12 06:57:43.680]  Step 155262  [3.831 sec/step, loss=0.09045, avg_loss=0.08812, mel_loss=0.03999, linear_loss=0.05045]
[2020-05-12 06:57:44.930]  Step 155263  [3.813 sec/step, loss=0.08181, avg_loss=0.08800, mel_loss=0.03540, linear_loss=0.04641]
[2020-05-12 06:57:49.622]  Step 155264  [3.843 sec/step, loss=0.09604, avg_loss=0.08809, mel_loss=0.04327, linear_loss=0.05277]
[2020-05-12 06:57:52.821]  Step 155265  [3.866 sec/step, loss=0.09330, avg_loss=0.08823, mel_loss=0.04154, linear_loss=0.05177]
[2020-05-12 06:58:06.940]  Step 155266  [3.995 sec/step, loss=0.07551, avg_loss=0.08814, mel_loss=0.03550, linear_loss=0.04001]
[2020-05-12 06:58:08.318]  Step 155267  [3.943 sec/step, loss=0.08517, avg_loss=0.08802, mel_loss=0.03685, linear_loss=0.04832]
[2020-05-12 06:58:11.832]  Step 155268  [3.954 sec/step, loss=0.09477, avg_loss=0.08806, mel_loss=0.04230, linear_loss=0.05247]
[2020-05-12 06:58:14.781]  Step 155269  [3.956 sec/step, loss=0.09337, avg_loss=0.08807, mel_loss=0.04152, linear_loss=0.05185]
[2020-05-12 06:58:21.535]  Step 155270  [3.865 sec/step, loss=0.09556, avg_loss=0.08825, mel_loss=0.04350, linear_loss=0.05206]
[2020-05-12 06:58:23.748]  Step 155271  [3.877 sec/step, loss=0.08945, avg_loss=0.08834, mel_loss=0.03916, linear_loss=0.05029]
[2020-05-12 06:58:24.756]  Step 155272  [3.879 sec/step, loss=0.07932, avg_loss=0.08839, mel_loss=0.03373, linear_loss=0.04559]
[2020-05-12 06:58:26.459]  Step 155273  [3.879 sec/step, loss=0.08825, avg_loss=0.08840, mel_loss=0.03829, linear_loss=0.04997]
[2020-05-12 06:58:27.516]  Step 155274  [3.858 sec/step, loss=0.07634, avg_loss=0.08824, mel_loss=0.03295, linear_loss=0.04340]
[2020-05-12 06:58:29.939]  Step 155275  [3.789 sec/step, loss=0.09204, avg_loss=0.08822, mel_loss=0.04051, linear_loss=0.05153]
[2020-05-12 06:58:30.509]  Step 155276  [3.785 sec/step, loss=0.07168, avg_loss=0.08814, mel_loss=0.03120, linear_loss=0.04048]
[2020-05-12 06:58:32.647]  Step 155277  [3.780 sec/step, loss=0.09119, avg_loss=0.08815, mel_loss=0.04024, linear_loss=0.05095]
[2020-05-12 06:58:41.706]  Step 155278  [3.857 sec/step, loss=0.09340, avg_loss=0.08826, mel_loss=0.04300, linear_loss=0.05041]
[2020-05-12 06:58:45.201]  Step 155279  [3.845 sec/step, loss=0.09377, avg_loss=0.08822, mel_loss=0.04156, linear_loss=0.05221]
[2020-05-12 06:58:47.187]  Step 155280  [3.845 sec/step, loss=0.08850, avg_loss=0.08821, mel_loss=0.03851, linear_loss=0.04999]
[2020-05-12 06:58:51.510]  Step 155281  [3.843 sec/step, loss=0.09591, avg_loss=0.08822, mel_loss=0.04314, linear_loss=0.05277]
[2020-05-12 06:58:57.028]  Step 155282  [3.883 sec/step, loss=0.09574, avg_loss=0.08832, mel_loss=0.04325, linear_loss=0.05249]
[2020-05-12 06:58:58.002]  Generated 32 batches of size 32 in 6.487 sec
[2020-05-12 06:58:58.801]  Step 155283  [3.846 sec/step, loss=0.08324, avg_loss=0.08818, mel_loss=0.03560, linear_loss=0.04765]
[2020-05-12 06:59:00.093]  Step 155284  [3.848 sec/step, loss=0.07703, avg_loss=0.08814, mel_loss=0.03309, linear_loss=0.04395]
[2020-05-12 06:59:08.647]  Step 155285  [3.916 sec/step, loss=0.09718, avg_loss=0.08824, mel_loss=0.04435, linear_loss=0.05283]
[2020-05-12 06:59:12.441]  Step 155286  [3.946 sec/step, loss=0.09641, avg_loss=0.08843, mel_loss=0.04322, linear_loss=0.05319]
[2020-05-12 06:59:19.587]  Step 155287  [3.994 sec/step, loss=0.09769, avg_loss=0.08851, mel_loss=0.04461, linear_loss=0.05308]
[2020-05-12 06:59:22.076]  Step 155288  [3.999 sec/step, loss=0.08868, avg_loss=0.08851, mel_loss=0.03896, linear_loss=0.04972]
[2020-05-12 06:59:23.859]  Step 155289  [3.959 sec/step, loss=0.08905, avg_loss=0.08843, mel_loss=0.03884, linear_loss=0.05021]
[2020-05-12 06:59:27.926]  Step 155290  [3.991 sec/step, loss=0.09570, avg_loss=0.08868, mel_loss=0.04272, linear_loss=0.05298]
[2020-05-12 06:59:28.650]  Step 155291  [3.958 sec/step, loss=0.07559, avg_loss=0.08851, mel_loss=0.03176, linear_loss=0.04382]
[2020-05-12 06:59:29.564]  Step 155292  [3.929 sec/step, loss=0.08351, avg_loss=0.08838, mel_loss=0.03615, linear_loss=0.04736]
[2020-05-12 06:59:43.046]  Step 155293  [4.029 sec/step, loss=0.08276, avg_loss=0.08828, mel_loss=0.03889, linear_loss=0.04387]
[2020-05-12 06:59:45.287]  Step 155294  [4.019 sec/step, loss=0.08825, avg_loss=0.08821, mel_loss=0.03874, linear_loss=0.04951]
[2020-05-12 06:59:47.273]  Step 155295  [4.003 sec/step, loss=0.08690, avg_loss=0.08813, mel_loss=0.03792, linear_loss=0.04898]
[2020-05-12 06:59:49.750]  Step 155296  [3.950 sec/step, loss=0.09045, avg_loss=0.08805, mel_loss=0.03971, linear_loss=0.05074]
[2020-05-12 06:59:56.480]  Step 155297  [4.003 sec/step, loss=0.09681, avg_loss=0.08817, mel_loss=0.04425, linear_loss=0.05256]
[2020-05-12 06:59:59.760]  Step 155298  [4.016 sec/step, loss=0.09489, avg_loss=0.08825, mel_loss=0.04210, linear_loss=0.05280]
[2020-05-12 07:00:02.691]  Step 155299  [3.829 sec/step, loss=0.09190, avg_loss=0.08834, mel_loss=0.04062, linear_loss=0.05128]
[2020-05-12 07:00:04.284]  Step 155300  [3.820 sec/step, loss=0.08661, avg_loss=0.08829, mel_loss=0.03774, linear_loss=0.04888]
[2020-05-12 07:00:04.284]  Writing summary at step: 155300
[2020-05-12 07:00:05.347]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155300
[2020-05-12 07:00:06.887]  Saving audio and alignment...
[2020-05-12 07:00:11.858]  Input: 그래서 하루 종일 입가에 미소가 떠나지 않는 그런 날~__________
[2020-05-12 07:00:13.003]  Step 155301  [3.825 sec/step, loss=0.08352, avg_loss=0.08845, mel_loss=0.03558, linear_loss=0.04794]
[2020-05-12 07:00:18.666]  Step 155302  [3.860 sec/step, loss=0.09654, avg_loss=0.08853, mel_loss=0.04394, linear_loss=0.05260]
[2020-05-12 07:00:19.497]  Step 155303  [3.835 sec/step, loss=0.07517, avg_loss=0.08834, mel_loss=0.03188, linear_loss=0.04329]
[2020-05-12 07:00:27.171]  Step 155304  [3.864 sec/step, loss=0.09612, avg_loss=0.08835, mel_loss=0.04425, linear_loss=0.05188]
[2020-05-12 07:00:31.560]  Step 155305  [3.817 sec/step, loss=0.09618, avg_loss=0.08834, mel_loss=0.04311, linear_loss=0.05307]
[2020-05-12 07:00:32.133]  Step 155306  [3.743 sec/step, loss=0.07064, avg_loss=0.08807, mel_loss=0.03064, linear_loss=0.04000]
[2020-05-12 07:00:41.114]  Step 155307  [3.818 sec/step, loss=0.09459, avg_loss=0.08816, mel_loss=0.04339, linear_loss=0.05120]
[2020-05-12 07:00:43.874]  Step 155308  [3.829 sec/step, loss=0.09030, avg_loss=0.08820, mel_loss=0.03967, linear_loss=0.05062]
[2020-05-12 07:00:45.309]  Step 155309  [3.798 sec/step, loss=0.08524, avg_loss=0.08809, mel_loss=0.03713, linear_loss=0.04811]
[2020-05-12 07:00:46.989]  Step 155310  [3.671 sec/step, loss=0.08752, avg_loss=0.08820, mel_loss=0.03821, linear_loss=0.04931]
[2020-05-12 07:00:47.960]  Step 155311  [3.651 sec/step, loss=0.08008, avg_loss=0.08808, mel_loss=0.03391, linear_loss=0.04617]
[2020-05-12 07:00:49.704]  Generated 32 batches of size 32 in 1.739 sec
[2020-05-12 07:00:51.911]  Step 155312  [3.655 sec/step, loss=0.09483, avg_loss=0.08809, mel_loss=0.04213, linear_loss=0.05270]
[2020-05-12 07:00:53.320]  Step 155313  [3.633 sec/step, loss=0.08462, avg_loss=0.08800, mel_loss=0.03646, linear_loss=0.04815]
[2020-05-12 07:00:54.580]  Step 155314  [3.637 sec/step, loss=0.08663, avg_loss=0.08816, mel_loss=0.03721, linear_loss=0.04941]
[2020-05-12 07:00:59.959]  Step 155315  [3.632 sec/step, loss=0.09427, avg_loss=0.08814, mel_loss=0.04250, linear_loss=0.05177]
[2020-05-12 07:01:01.816]  Step 155316  [3.640 sec/step, loss=0.08638, avg_loss=0.08821, mel_loss=0.03744, linear_loss=0.04894]
[2020-05-12 07:01:05.277]  Step 155317  [3.631 sec/step, loss=0.09318, avg_loss=0.08819, mel_loss=0.04163, linear_loss=0.05155]
[2020-05-12 07:01:09.962]  Step 155318  [3.608 sec/step, loss=0.09599, avg_loss=0.08819, mel_loss=0.04314, linear_loss=0.05285]
[2020-05-12 07:01:11.986]  Step 155319  [3.617 sec/step, loss=0.09006, avg_loss=0.08829, mel_loss=0.03968, linear_loss=0.05038]
[2020-05-12 07:01:15.698]  Step 155320  [3.627 sec/step, loss=0.09528, avg_loss=0.08833, mel_loss=0.04252, linear_loss=0.05276]
[2020-05-12 07:01:17.503]  Step 155321  [3.613 sec/step, loss=0.08729, avg_loss=0.08826, mel_loss=0.03784, linear_loss=0.04945]
[2020-05-12 07:01:18.989]  Step 155322  [3.610 sec/step, loss=0.08466, avg_loss=0.08824, mel_loss=0.03665, linear_loss=0.04801]
[2020-05-12 07:01:20.393]  Step 155323  [3.610 sec/step, loss=0.08264, avg_loss=0.08823, mel_loss=0.03590, linear_loss=0.04674]
[2020-05-12 07:01:21.209]  Step 155324  [3.596 sec/step, loss=0.07523, avg_loss=0.08808, mel_loss=0.03221, linear_loss=0.04302]
[2020-05-12 07:01:26.009]  Step 155325  [3.606 sec/step, loss=0.09714, avg_loss=0.08810, mel_loss=0.04369, linear_loss=0.05346]
[2020-05-12 07:01:28.080]  Step 155326  [3.608 sec/step, loss=0.08950, avg_loss=0.08813, mel_loss=0.03932, linear_loss=0.05018]
[2020-05-12 07:01:29.008]  Step 155327  [3.563 sec/step, loss=0.08078, avg_loss=0.08799, mel_loss=0.03449, linear_loss=0.04629]
[2020-05-12 07:01:34.718]  Step 155328  [3.612 sec/step, loss=0.09529, avg_loss=0.08818, mel_loss=0.04309, linear_loss=0.05220]
[2020-05-12 07:01:37.397]  Step 155329  [3.212 sec/step, loss=0.09274, avg_loss=0.08821, mel_loss=0.04108, linear_loss=0.05166]
[2020-05-12 07:01:41.650]  Step 155330  [3.225 sec/step, loss=0.09387, avg_loss=0.08822, mel_loss=0.04192, linear_loss=0.05195]
[2020-05-12 07:01:50.655]  Step 155331  [3.304 sec/step, loss=0.09459, avg_loss=0.08835, mel_loss=0.04358, linear_loss=0.05101]
[2020-05-12 07:01:54.171]  Step 155332  [3.325 sec/step, loss=0.09368, avg_loss=0.08844, mel_loss=0.04166, linear_loss=0.05202]
[2020-05-12 07:01:58.295]  Step 155333  [3.345 sec/step, loss=0.09578, avg_loss=0.08850, mel_loss=0.04295, linear_loss=0.05283]
[2020-05-12 07:02:00.882]  Step 155334  [3.344 sec/step, loss=0.09064, avg_loss=0.08850, mel_loss=0.03993, linear_loss=0.05071]
[2020-05-12 07:02:03.039]  Step 155335  [3.354 sec/step, loss=0.09122, avg_loss=0.08858, mel_loss=0.03984, linear_loss=0.05138]
[2020-05-12 07:02:04.770]  Step 155336  [3.329 sec/step, loss=0.08656, avg_loss=0.08852, mel_loss=0.03776, linear_loss=0.04880]
[2020-05-12 07:02:05.647]  Step 155337  [3.301 sec/step, loss=0.07591, avg_loss=0.08835, mel_loss=0.03262, linear_loss=0.04329]
[2020-05-12 07:02:20.465]  Step 155338  [3.434 sec/step, loss=0.07513, avg_loss=0.08826, mel_loss=0.03542, linear_loss=0.03971]
[2020-05-12 07:02:22.703]  Step 155339  [3.436 sec/step, loss=0.09050, avg_loss=0.08827, mel_loss=0.03994, linear_loss=0.05056]
[2020-05-12 07:02:23.287]  Step 155340  [3.383 sec/step, loss=0.06791, avg_loss=0.08798, mel_loss=0.02970, linear_loss=0.03821]
[2020-05-12 07:02:26.796]  Step 155341  [3.401 sec/step, loss=0.09280, avg_loss=0.08802, mel_loss=0.04118, linear_loss=0.05161]
[2020-05-12 07:02:27.846]  Step 155342  [3.282 sec/step, loss=0.07950, avg_loss=0.08801, mel_loss=0.03398, linear_loss=0.04551]
[2020-05-12 07:02:29.751]  Step 155343  [3.257 sec/step, loss=0.08668, avg_loss=0.08793, mel_loss=0.03775, linear_loss=0.04893]
[2020-05-12 07:02:33.274]  Step 155344  [3.273 sec/step, loss=0.09423, avg_loss=0.08799, mel_loss=0.04188, linear_loss=0.05235]
[2020-05-12 07:02:40.890]  Step 155345  [3.294 sec/step, loss=0.09691, avg_loss=0.08798, mel_loss=0.04421, linear_loss=0.05270]
[2020-05-12 07:02:42.239]  Generated 32 batches of size 32 in 12.482 sec
[2020-05-12 07:02:46.302]  Step 155346  [3.317 sec/step, loss=0.09583, avg_loss=0.08802, mel_loss=0.04333, linear_loss=0.05250]
[2020-05-12 07:02:47.448]  Step 155347  [3.279 sec/step, loss=0.08358, avg_loss=0.08790, mel_loss=0.03584, linear_loss=0.04774]
[2020-05-12 07:02:49.935]  Step 155348  [3.270 sec/step, loss=0.08904, avg_loss=0.08788, mel_loss=0.03896, linear_loss=0.05008]
[2020-05-12 07:02:56.472]  Step 155349  [3.328 sec/step, loss=0.09458, avg_loss=0.08803, mel_loss=0.04313, linear_loss=0.05146]
[2020-05-12 07:03:00.785]  Step 155350  [3.354 sec/step, loss=0.09547, avg_loss=0.08811, mel_loss=0.04301, linear_loss=0.05246]
[2020-05-12 07:03:00.785]  Writing summary at step: 155350
[2020-05-12 07:03:02.091]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155350
[2020-05-12 07:03:03.649]  Saving audio and alignment...
[2020-05-12 07:03:08.229]  Input: 게 끌어 주시고 한번 붙어 봅시다~______________________________
[2020-05-12 07:03:09.460]  Step 155351  [3.361 sec/step, loss=0.08389, avg_loss=0.08820, mel_loss=0.03627, linear_loss=0.04762]
[2020-05-12 07:03:14.618]  Step 155352  [3.330 sec/step, loss=0.09556, avg_loss=0.08822, mel_loss=0.04312, linear_loss=0.05245]
[2020-05-12 07:03:18.130]  Step 155353  [3.357 sec/step, loss=0.09289, avg_loss=0.08840, mel_loss=0.04129, linear_loss=0.05159]
[2020-05-12 07:03:19.297]  Step 155354  [3.360 sec/step, loss=0.08016, avg_loss=0.08841, mel_loss=0.03446, linear_loss=0.04570]
[2020-05-12 07:03:20.112]  Step 155355  [3.343 sec/step, loss=0.07173, avg_loss=0.08821, mel_loss=0.03091, linear_loss=0.04082]
[2020-05-12 07:03:25.678]  Step 155356  [3.361 sec/step, loss=0.09558, avg_loss=0.08821, mel_loss=0.04325, linear_loss=0.05233]
[2020-05-12 07:03:28.261]  Step 155357  [3.374 sec/step, loss=0.08903, avg_loss=0.08827, mel_loss=0.03917, linear_loss=0.04986]
[2020-05-12 07:03:30.039]  Step 155358  [3.382 sec/step, loss=0.08862, avg_loss=0.08834, mel_loss=0.03823, linear_loss=0.05039]
[2020-05-12 07:03:31.109]  Step 155359  [3.375 sec/step, loss=0.07864, avg_loss=0.08826, mel_loss=0.03392, linear_loss=0.04473]
[2020-05-12 07:03:33.746]  Step 155360  [3.393 sec/step, loss=0.09204, avg_loss=0.08845, mel_loss=0.04089, linear_loss=0.05115]
[2020-05-12 07:03:37.966]  Step 155361  [3.421 sec/step, loss=0.09437, avg_loss=0.08854, mel_loss=0.04238, linear_loss=0.05199]
[2020-05-12 07:03:40.122]  Step 155362  [3.414 sec/step, loss=0.09005, avg_loss=0.08853, mel_loss=0.03963, linear_loss=0.05041]
[2020-05-12 07:03:40.924]  Step 155363  [3.410 sec/step, loss=0.07820, avg_loss=0.08850, mel_loss=0.03337, linear_loss=0.04483]
[2020-05-12 07:03:43.877]  Step 155364  [3.392 sec/step, loss=0.09469, avg_loss=0.08848, mel_loss=0.04193, linear_loss=0.05276]
[2020-05-12 07:03:45.785]  Step 155365  [3.379 sec/step, loss=0.08655, avg_loss=0.08841, mel_loss=0.03771, linear_loss=0.04884]
[2020-05-12 07:03:49.309]  Step 155366  [3.273 sec/step, loss=0.09380, avg_loss=0.08860, mel_loss=0.04173, linear_loss=0.05207]
[2020-05-12 07:03:50.074]  Step 155367  [3.267 sec/step, loss=0.07210, avg_loss=0.08847, mel_loss=0.03174, linear_loss=0.04037]
[2020-05-12 07:03:53.782]  Step 155368  [3.269 sec/step, loss=0.09505, avg_loss=0.08847, mel_loss=0.04238, linear_loss=0.05267]
[2020-05-12 07:03:54.836]  Step 155369  [3.250 sec/step, loss=0.07777, avg_loss=0.08831, mel_loss=0.03322, linear_loss=0.04455]
[2020-05-12 07:04:03.443]  Step 155370  [3.269 sec/step, loss=0.09489, avg_loss=0.08831, mel_loss=0.04371, linear_loss=0.05118]
[2020-05-12 07:04:04.832]  Step 155371  [3.260 sec/step, loss=0.08682, avg_loss=0.08828, mel_loss=0.03752, linear_loss=0.04931]
[2020-05-12 07:04:12.365]  Step 155372  [3.326 sec/step, loss=0.09632, avg_loss=0.08845, mel_loss=0.04404, linear_loss=0.05228]
[2020-05-12 07:04:13.945]  Step 155373  [3.324 sec/step, loss=0.08787, avg_loss=0.08845, mel_loss=0.03832, linear_loss=0.04955]
[2020-05-12 07:04:15.430]  Step 155374  [3.329 sec/step, loss=0.08423, avg_loss=0.08853, mel_loss=0.03669, linear_loss=0.04753]
[2020-05-12 07:04:17.496]  Step 155375  [3.325 sec/step, loss=0.08987, avg_loss=0.08850, mel_loss=0.03947, linear_loss=0.05040]
[2020-05-12 07:04:23.736]  Step 155376  [3.382 sec/step, loss=0.09610, avg_loss=0.08875, mel_loss=0.04376, linear_loss=0.05234]
[2020-05-12 07:04:23.920]  Generated 32 batches of size 32 in 9.970 sec
[2020-05-12 07:04:26.801]  Step 155377  [3.391 sec/step, loss=0.09542, avg_loss=0.08879, mel_loss=0.04245, linear_loss=0.05297]
[2020-05-12 07:04:28.525]  Step 155378  [3.318 sec/step, loss=0.08752, avg_loss=0.08873, mel_loss=0.03800, linear_loss=0.04952]
[2020-05-12 07:04:30.981]  Step 155379  [3.307 sec/step, loss=0.09085, avg_loss=0.08870, mel_loss=0.03978, linear_loss=0.05107]
[2020-05-12 07:04:45.508]  Step 155380  [3.433 sec/step, loss=0.07697, avg_loss=0.08859, mel_loss=0.03636, linear_loss=0.04061]
[2020-05-12 07:04:50.185]  Step 155381  [3.436 sec/step, loss=0.09538, avg_loss=0.08858, mel_loss=0.04275, linear_loss=0.05264]
[2020-05-12 07:04:54.316]  Step 155382  [3.422 sec/step, loss=0.09461, avg_loss=0.08857, mel_loss=0.04232, linear_loss=0.05229]
[2020-05-12 07:04:59.049]  Step 155383  [3.452 sec/step, loss=0.09555, avg_loss=0.08869, mel_loss=0.04300, linear_loss=0.05255]
[2020-05-12 07:05:00.894]  Step 155384  [3.458 sec/step, loss=0.08825, avg_loss=0.08881, mel_loss=0.03862, linear_loss=0.04963]
[2020-05-12 07:05:01.774]  Step 155385  [3.381 sec/step, loss=0.07785, avg_loss=0.08861, mel_loss=0.03320, linear_loss=0.04466]
[2020-05-12 07:05:09.343]  Step 155386  [3.419 sec/step, loss=0.09756, avg_loss=0.08862, mel_loss=0.04486, linear_loss=0.05270]
[2020-05-12 07:05:11.367]  Step 155387  [3.367 sec/step, loss=0.09119, avg_loss=0.08856, mel_loss=0.03989, linear_loss=0.05130]
[2020-05-12 07:05:14.906]  Step 155388  [3.378 sec/step, loss=0.09558, avg_loss=0.08863, mel_loss=0.04287, linear_loss=0.05272]
[2020-05-12 07:05:15.708]  Step 155389  [3.368 sec/step, loss=0.07652, avg_loss=0.08850, mel_loss=0.03266, linear_loss=0.04386]
[2020-05-12 07:05:16.263]  Step 155390  [3.333 sec/step, loss=0.07445, avg_loss=0.08829, mel_loss=0.03235, linear_loss=0.04211]
[2020-05-12 07:05:18.941]  Step 155391  [3.352 sec/step, loss=0.09019, avg_loss=0.08844, mel_loss=0.03967, linear_loss=0.05052]
[2020-05-12 07:05:22.368]  Step 155392  [3.378 sec/step, loss=0.09345, avg_loss=0.08854, mel_loss=0.04185, linear_loss=0.05160]
[2020-05-12 07:05:24.335]  Step 155393  [3.262 sec/step, loss=0.08948, avg_loss=0.08860, mel_loss=0.03919, linear_loss=0.05029]
[2020-05-12 07:05:28.644]  Step 155394  [3.283 sec/step, loss=0.09567, avg_loss=0.08868, mel_loss=0.04281, linear_loss=0.05287]
[2020-05-12 07:05:30.008]  Step 155395  [3.277 sec/step, loss=0.08617, avg_loss=0.08867, mel_loss=0.03720, linear_loss=0.04897]
[2020-05-12 07:05:31.284]  Step 155396  [3.265 sec/step, loss=0.08246, avg_loss=0.08859, mel_loss=0.03564, linear_loss=0.04682]
[2020-05-12 07:05:32.345]  Step 155397  [3.208 sec/step, loss=0.08035, avg_loss=0.08843, mel_loss=0.03477, linear_loss=0.04558]
[2020-05-12 07:05:34.730]  Step 155398  [3.199 sec/step, loss=0.08957, avg_loss=0.08837, mel_loss=0.03939, linear_loss=0.05018]
[2020-05-12 07:05:45.746]  Step 155399  [3.280 sec/step, loss=0.09535, avg_loss=0.08841, mel_loss=0.04465, linear_loss=0.05070]
[2020-05-12 07:05:48.115]  Step 155400  [3.288 sec/step, loss=0.09010, avg_loss=0.08844, mel_loss=0.03972, linear_loss=0.05038]
[2020-05-12 07:05:48.115]  Writing summary at step: 155400
[2020-05-12 07:05:49.874]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155400
[2020-05-12 07:05:51.438]  Saving audio and alignment...
[2020-05-12 07:05:56.256]  Input: 자 오일에 납입이 안 되면 육일 날 빠져나가나요~______________
[2020-05-12 07:05:56.867]  Step 155401  [3.283 sec/step, loss=0.07466, avg_loss=0.08835, mel_loss=0.03277, linear_loss=0.04189]
[2020-05-12 07:06:02.264]  Step 155402  [3.280 sec/step, loss=0.09442, avg_loss=0.08833, mel_loss=0.04251, linear_loss=0.05190]
[2020-05-12 07:06:05.596]  Step 155403  [3.305 sec/step, loss=0.09351, avg_loss=0.08852, mel_loss=0.04174, linear_loss=0.05177]
[2020-05-12 07:06:09.778]  Step 155404  [3.270 sec/step, loss=0.09620, avg_loss=0.08852, mel_loss=0.04310, linear_loss=0.05310]
[2020-05-12 07:06:10.928]  Step 155405  [3.238 sec/step, loss=0.08502, avg_loss=0.08840, mel_loss=0.03583, linear_loss=0.04919]
[2020-05-12 07:06:10.950]  Generated 32 batches of size 32 in 5.348 sec
[2020-05-12 07:06:11.913]  Step 155406  [3.242 sec/step, loss=0.08100, avg_loss=0.08851, mel_loss=0.03478, linear_loss=0.04622]
[2020-05-12 07:06:14.737]  Step 155407  [3.180 sec/step, loss=0.09169, avg_loss=0.08848, mel_loss=0.04077, linear_loss=0.05092]
[2020-05-12 07:06:20.443]  Step 155408  [3.210 sec/step, loss=0.09791, avg_loss=0.08856, mel_loss=0.04487, linear_loss=0.05304]
[2020-05-12 07:06:27.133]  Step 155409  [3.262 sec/step, loss=0.09797, avg_loss=0.08868, mel_loss=0.04462, linear_loss=0.05336]
[2020-05-12 07:06:28.803]  Step 155410  [3.262 sec/step, loss=0.08664, avg_loss=0.08867, mel_loss=0.03794, linear_loss=0.04870]
[2020-05-12 07:06:30.294]  Step 155411  [3.267 sec/step, loss=0.08618, avg_loss=0.08874, mel_loss=0.03740, linear_loss=0.04878]
[2020-05-12 07:06:39.200]  Step 155412  [3.317 sec/step, loss=0.09447, avg_loss=0.08873, mel_loss=0.04348, linear_loss=0.05098]
[2020-05-12 07:06:41.139]  Step 155413  [3.322 sec/step, loss=0.08893, avg_loss=0.08877, mel_loss=0.03899, linear_loss=0.04994]
[2020-05-12 07:06:55.649]  Step 155414  [3.455 sec/step, loss=0.07509, avg_loss=0.08866, mel_loss=0.03560, linear_loss=0.03949]
[2020-05-12 07:06:58.732]  Step 155415  [3.432 sec/step, loss=0.09374, avg_loss=0.08865, mel_loss=0.04150, linear_loss=0.05224]
[2020-05-12 07:07:03.508]  Step 155416  [3.461 sec/step, loss=0.09684, avg_loss=0.08876, mel_loss=0.04358, linear_loss=0.05327]
[2020-05-12 07:07:04.573]  Step 155417  [3.437 sec/step, loss=0.07915, avg_loss=0.08862, mel_loss=0.03432, linear_loss=0.04483]
[2020-05-12 07:07:06.364]  Step 155418  [3.408 sec/step, loss=0.08799, avg_loss=0.08854, mel_loss=0.03827, linear_loss=0.04972]
[2020-05-12 07:07:07.764]  Step 155419  [3.402 sec/step, loss=0.08534, avg_loss=0.08849, mel_loss=0.03702, linear_loss=0.04831]
[2020-05-12 07:07:11.775]  Step 155420  [3.405 sec/step, loss=0.09342, avg_loss=0.08847, mel_loss=0.04169, linear_loss=0.05173]
[2020-05-12 07:07:16.168]  Step 155421  [3.431 sec/step, loss=0.09586, avg_loss=0.08856, mel_loss=0.04316, linear_loss=0.05270]
[2020-05-12 07:07:19.626]  Step 155422  [3.450 sec/step, loss=0.09408, avg_loss=0.08865, mel_loss=0.04190, linear_loss=0.05218]
[2020-05-12 07:07:21.243]  Step 155423  [3.452 sec/step, loss=0.08684, avg_loss=0.08869, mel_loss=0.03776, linear_loss=0.04908]
[2020-05-12 07:07:23.758]  Step 155424  [3.469 sec/step, loss=0.08984, avg_loss=0.08884, mel_loss=0.03943, linear_loss=0.05040]
[2020-05-12 07:07:25.635]  Step 155425  [3.440 sec/step, loss=0.08637, avg_loss=0.08873, mel_loss=0.03752, linear_loss=0.04885]
[2020-05-12 07:07:26.901]  Step 155426  [3.432 sec/step, loss=0.08423, avg_loss=0.08868, mel_loss=0.03644, linear_loss=0.04779]
[2020-05-12 07:07:30.599]  Step 155427  [3.460 sec/step, loss=0.09584, avg_loss=0.08883, mel_loss=0.04269, linear_loss=0.05315]
[2020-05-12 07:07:36.452]  Step 155428  [3.461 sec/step, loss=0.09449, avg_loss=0.08882, mel_loss=0.04266, linear_loss=0.05183]
[2020-05-12 07:07:43.992]  Step 155429  [3.510 sec/step, loss=0.09711, avg_loss=0.08887, mel_loss=0.04446, linear_loss=0.05264]
[2020-05-12 07:07:44.849]  Step 155430  [3.476 sec/step, loss=0.07446, avg_loss=0.08867, mel_loss=0.03248, linear_loss=0.04198]
[2020-05-12 07:07:45.426]  Step 155431  [3.392 sec/step, loss=0.06807, avg_loss=0.08841, mel_loss=0.02946, linear_loss=0.03861]
[2020-05-12 07:07:46.599]  Step 155432  [3.368 sec/step, loss=0.08156, avg_loss=0.08829, mel_loss=0.03480, linear_loss=0.04675]
[2020-05-12 07:07:55.527]  Step 155433  [3.416 sec/step, loss=0.09433, avg_loss=0.08827, mel_loss=0.04359, linear_loss=0.05074]
[2020-05-12 07:07:57.617]  Step 155434  [3.411 sec/step, loss=0.09042, avg_loss=0.08827, mel_loss=0.03956, linear_loss=0.05085]
[2020-05-12 07:07:59.841]  Step 155435  [3.412 sec/step, loss=0.08917, avg_loss=0.08825, mel_loss=0.03905, linear_loss=0.05012]
[2020-05-12 07:08:02.683]  Generated 32 batches of size 32 in 2.835 sec
[2020-05-12 07:08:02.720]  Step 155436  [3.423 sec/step, loss=0.09125, avg_loss=0.08830, mel_loss=0.04062, linear_loss=0.05063]
[2020-05-12 07:08:07.967]  Step 155437  [3.467 sec/step, loss=0.09503, avg_loss=0.08849, mel_loss=0.04299, linear_loss=0.05204]
[2020-05-12 07:08:08.784]  Step 155438  [3.327 sec/step, loss=0.07592, avg_loss=0.08849, mel_loss=0.03267, linear_loss=0.04325]
[2020-05-12 07:08:11.927]  Step 155439  [3.336 sec/step, loss=0.09425, avg_loss=0.08853, mel_loss=0.04197, linear_loss=0.05228]
[2020-05-12 07:08:15.457]  Step 155440  [3.366 sec/step, loss=0.09422, avg_loss=0.08879, mel_loss=0.04186, linear_loss=0.05236]
[2020-05-12 07:08:21.909]  Step 155441  [3.395 sec/step, loss=0.09687, avg_loss=0.08884, mel_loss=0.04393, linear_loss=0.05294]
[2020-05-12 07:08:23.420]  Step 155442  [3.400 sec/step, loss=0.08623, avg_loss=0.08890, mel_loss=0.03745, linear_loss=0.04879]
[2020-05-12 07:08:25.861]  Step 155443  [3.405 sec/step, loss=0.09281, avg_loss=0.08896, mel_loss=0.04096, linear_loss=0.05185]
[2020-05-12 07:08:26.782]  Step 155444  [3.379 sec/step, loss=0.07991, avg_loss=0.08882, mel_loss=0.03412, linear_loss=0.04580]
[2020-05-12 07:08:39.410]  Step 155445  [3.429 sec/step, loss=0.08463, avg_loss=0.08870, mel_loss=0.03986, linear_loss=0.04478]
[2020-05-12 07:08:42.025]  Step 155446  [3.401 sec/step, loss=0.09171, avg_loss=0.08866, mel_loss=0.04025, linear_loss=0.05147]
[2020-05-12 07:08:50.278]  Step 155447  [3.472 sec/step, loss=0.09669, avg_loss=0.08879, mel_loss=0.04453, linear_loss=0.05216]
[2020-05-12 07:08:53.504]  Step 155448  [3.480 sec/step, loss=0.09586, avg_loss=0.08886, mel_loss=0.04274, linear_loss=0.05312]
[2020-05-12 07:08:56.701]  Step 155449  [3.446 sec/step, loss=0.09452, avg_loss=0.08886, mel_loss=0.04192, linear_loss=0.05260]
[2020-05-12 07:08:59.205]  Step 155450  [3.428 sec/step, loss=0.08874, avg_loss=0.08879, mel_loss=0.03897, linear_loss=0.04977]
[2020-05-12 07:08:59.205]  Writing summary at step: 155450
[2020-05-12 07:09:00.059]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155450
[2020-05-12 07:09:01.644]  Saving audio and alignment...
[2020-05-12 07:09:03.331]  Input: 바누~____________
[2020-05-12 07:09:09.459]  Step 155451  [3.477 sec/step, loss=0.09771, avg_loss=0.08893, mel_loss=0.04450, linear_loss=0.05321]
[2020-05-12 07:09:11.033]  Step 155452  [3.441 sec/step, loss=0.07977, avg_loss=0.08877, mel_loss=0.03438, linear_loss=0.04539]
[2020-05-12 07:09:13.368]  Step 155453  [3.429 sec/step, loss=0.08659, avg_loss=0.08871, mel_loss=0.03765, linear_loss=0.04894]
[2020-05-12 07:09:19.690]  Step 155454  [3.481 sec/step, loss=0.09475, avg_loss=0.08885, mel_loss=0.04242, linear_loss=0.05233]
[2020-05-12 07:09:21.615]  Step 155455  [3.492 sec/step, loss=0.08705, avg_loss=0.08901, mel_loss=0.03769, linear_loss=0.04937]
[2020-05-12 07:09:23.718]  Step 155456  [3.457 sec/step, loss=0.08838, avg_loss=0.08893, mel_loss=0.03886, linear_loss=0.04952]
[2020-05-12 07:09:31.447]  Step 155457  [3.509 sec/step, loss=0.09756, avg_loss=0.08902, mel_loss=0.04465, linear_loss=0.05291]
[2020-05-12 07:09:32.796]  Step 155458  [3.505 sec/step, loss=0.08591, avg_loss=0.08899, mel_loss=0.03734, linear_loss=0.04857]
[2020-05-12 07:09:37.645]  Step 155459  [3.542 sec/step, loss=0.09520, avg_loss=0.08916, mel_loss=0.04263, linear_loss=0.05257]
[2020-05-12 07:09:39.863]  Step 155460  [3.538 sec/step, loss=0.09160, avg_loss=0.08915, mel_loss=0.04021, linear_loss=0.05139]
[2020-05-12 07:09:40.893]  Step 155461  [3.506 sec/step, loss=0.07832, avg_loss=0.08899, mel_loss=0.03343, linear_loss=0.04489]
[2020-05-12 07:09:42.242]  Step 155462  [3.498 sec/step, loss=0.08732, avg_loss=0.08896, mel_loss=0.03789, linear_loss=0.04943]
[2020-05-12 07:09:45.155]  Step 155463  [3.519 sec/step, loss=0.09217, avg_loss=0.08910, mel_loss=0.04064, linear_loss=0.05153]
[2020-05-12 07:09:48.857]  Step 155464  [3.527 sec/step, loss=0.09435, avg_loss=0.08910, mel_loss=0.04224, linear_loss=0.05211]
[2020-05-12 07:09:50.042]  Step 155465  [3.520 sec/step, loss=0.08296, avg_loss=0.08907, mel_loss=0.03578, linear_loss=0.04718]
[2020-05-12 07:09:51.217]  Step 155466  [3.496 sec/step, loss=0.08331, avg_loss=0.08896, mel_loss=0.03591, linear_loss=0.04740]
[2020-05-12 07:09:51.867]  Generated 32 batches of size 32 in 1.819 sec
[2020-05-12 07:09:54.077]  Step 155467  [3.517 sec/step, loss=0.09252, avg_loss=0.08916, mel_loss=0.04090, linear_loss=0.05161]
[2020-05-12 07:09:59.439]  Step 155468  [3.534 sec/step, loss=0.09586, avg_loss=0.08917, mel_loss=0.04323, linear_loss=0.05263]
[2020-05-12 07:10:01.114]  Step 155469  [3.540 sec/step, loss=0.08737, avg_loss=0.08927, mel_loss=0.03813, linear_loss=0.04924]
[2020-05-12 07:10:05.277]  Step 155470  [3.495 sec/step, loss=0.09530, avg_loss=0.08927, mel_loss=0.04257, linear_loss=0.05273]
[2020-05-12 07:10:07.218]  Step 155471  [3.501 sec/step, loss=0.08958, avg_loss=0.08930, mel_loss=0.03919, linear_loss=0.05039]
[2020-05-12 07:10:07.797]  Step 155472  [3.431 sec/step, loss=0.07129, avg_loss=0.08905, mel_loss=0.03153, linear_loss=0.03976]
[2020-05-12 07:10:14.594]  Step 155473  [3.484 sec/step, loss=0.09470, avg_loss=0.08912, mel_loss=0.04336, linear_loss=0.05134]
[2020-05-12 07:10:18.040]  Step 155474  [3.503 sec/step, loss=0.09142, avg_loss=0.08919, mel_loss=0.04071, linear_loss=0.05072]
[2020-05-12 07:10:25.609]  Step 155475  [3.558 sec/step, loss=0.09669, avg_loss=0.08926, mel_loss=0.04427, linear_loss=0.05242]
[2020-05-12 07:10:27.796]  Step 155476  [3.518 sec/step, loss=0.09030, avg_loss=0.08920, mel_loss=0.03952, linear_loss=0.05078]
[2020-05-12 07:10:33.265]  Step 155477  [3.542 sec/step, loss=0.09686, avg_loss=0.08921, mel_loss=0.04401, linear_loss=0.05285]
[2020-05-12 07:10:38.256]  Step 155478  [3.574 sec/step, loss=0.09629, avg_loss=0.08930, mel_loss=0.04351, linear_loss=0.05279]
[2020-05-12 07:10:42.896]  Step 155479  [3.596 sec/step, loss=0.09540, avg_loss=0.08935, mel_loss=0.04283, linear_loss=0.05258]
[2020-05-12 07:10:44.364]  Step 155480  [3.466 sec/step, loss=0.08532, avg_loss=0.08943, mel_loss=0.03690, linear_loss=0.04842]
[2020-05-12 07:10:50.581]  Step 155481  [3.481 sec/step, loss=0.09515, avg_loss=0.08943, mel_loss=0.04323, linear_loss=0.05192]
[2020-05-12 07:10:51.907]  Step 155482  [3.453 sec/step, loss=0.08339, avg_loss=0.08932, mel_loss=0.03604, linear_loss=0.04735]
[2020-05-12 07:10:53.621]  Step 155483  [3.423 sec/step, loss=0.08773, avg_loss=0.08924, mel_loss=0.03843, linear_loss=0.04930]
[2020-05-12 07:10:56.077]  Step 155484  [3.429 sec/step, loss=0.09143, avg_loss=0.08927, mel_loss=0.04028, linear_loss=0.05114]
[2020-05-12 07:11:00.356]  Step 155485  [3.463 sec/step, loss=0.09511, avg_loss=0.08944, mel_loss=0.04260, linear_loss=0.05251]
[2020-05-12 07:11:01.369]  Step 155486  [3.397 sec/step, loss=0.07750, avg_loss=0.08924, mel_loss=0.03303, linear_loss=0.04447]
[2020-05-12 07:11:05.032]  Step 155487  [3.414 sec/step, loss=0.09457, avg_loss=0.08928, mel_loss=0.04196, linear_loss=0.05261]
[2020-05-12 07:11:08.341]  Step 155488  [3.411 sec/step, loss=0.09420, avg_loss=0.08926, mel_loss=0.04179, linear_loss=0.05241]
[2020-05-12 07:11:09.690]  Step 155489  [3.417 sec/step, loss=0.08588, avg_loss=0.08936, mel_loss=0.03703, linear_loss=0.04884]
[2020-05-12 07:11:13.222]  Step 155490  [3.447 sec/step, loss=0.09271, avg_loss=0.08954, mel_loss=0.04130, linear_loss=0.05141]
[2020-05-12 07:11:14.299]  Step 155491  [3.431 sec/step, loss=0.08357, avg_loss=0.08947, mel_loss=0.03578, linear_loss=0.04780]
[2020-05-12 07:11:17.491]  Step 155492  [3.428 sec/step, loss=0.09294, avg_loss=0.08947, mel_loss=0.04144, linear_loss=0.05151]
[2020-05-12 07:11:32.066]  Step 155493  [3.554 sec/step, loss=0.07572, avg_loss=0.08933, mel_loss=0.03559, linear_loss=0.04013]
[2020-05-12 07:11:32.897]  Step 155494  [3.520 sec/step, loss=0.07325, avg_loss=0.08911, mel_loss=0.03135, linear_loss=0.04190]
[2020-05-12 07:11:41.850]  Step 155495  [3.595 sec/step, loss=0.09384, avg_loss=0.08918, mel_loss=0.04321, linear_loss=0.05063]
[2020-05-12 07:11:43.911]  Step 155496  [3.603 sec/step, loss=0.08749, avg_loss=0.08923, mel_loss=0.03801, linear_loss=0.04949]
[2020-05-12 07:11:44.577]  Step 155497  [3.599 sec/step, loss=0.07454, avg_loss=0.08917, mel_loss=0.03267, linear_loss=0.04187]
[2020-05-12 07:11:46.428]  Generated 32 batches of size 32 in 1.845 sec
[2020-05-12 07:11:46.867]  Step 155498  [3.598 sec/step, loss=0.08931, avg_loss=0.08917, mel_loss=0.03909, linear_loss=0.05021]
[2020-05-12 07:11:48.714]  Step 155499  [3.507 sec/step, loss=0.08878, avg_loss=0.08911, mel_loss=0.03866, linear_loss=0.05012]
[2020-05-12 07:11:51.670]  Step 155500  [3.513 sec/step, loss=0.09208, avg_loss=0.08913, mel_loss=0.04078, linear_loss=0.05130]
[2020-05-12 07:11:51.670]  Writing summary at step: 155500
[2020-05-12 07:11:52.185]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155500
[2020-05-12 07:11:53.773]  Saving audio and alignment...
[2020-05-12 07:11:55.896]  Input: 가장 크고~_________________
[2020-05-12 07:11:57.578]  Step 155501  [3.523 sec/step, loss=0.08899, avg_loss=0.08927, mel_loss=0.03895, linear_loss=0.05004]
[2020-05-12 07:12:00.265]  Step 155502  [3.496 sec/step, loss=0.08999, avg_loss=0.08922, mel_loss=0.03986, linear_loss=0.05013]
[2020-05-12 07:12:04.273]  Step 155503  [3.503 sec/step, loss=0.09453, avg_loss=0.08923, mel_loss=0.04221, linear_loss=0.05233]
[2020-05-12 07:12:05.542]  Step 155504  [3.474 sec/step, loss=0.08333, avg_loss=0.08911, mel_loss=0.03575, linear_loss=0.04758]
[2020-05-12 07:12:11.702]  Step 155505  [3.524 sec/step, loss=0.09576, avg_loss=0.08921, mel_loss=0.04335, linear_loss=0.05241]
[2020-05-12 07:12:12.585]  Step 155506  [3.523 sec/step, loss=0.07661, avg_loss=0.08917, mel_loss=0.03276, linear_loss=0.04385]
[2020-05-12 07:12:14.297]  Step 155507  [3.512 sec/step, loss=0.08709, avg_loss=0.08912, mel_loss=0.03815, linear_loss=0.04893]
[2020-05-12 07:12:17.226]  Step 155508  [3.484 sec/step, loss=0.09323, avg_loss=0.08908, mel_loss=0.04132, linear_loss=0.05191]
[2020-05-12 07:12:23.690]  Step 155509  [3.482 sec/step, loss=0.09470, avg_loss=0.08904, mel_loss=0.04312, linear_loss=0.05159]
[2020-05-12 07:12:24.853]  Step 155510  [3.477 sec/step, loss=0.08124, avg_loss=0.08899, mel_loss=0.03503, linear_loss=0.04621]
[2020-05-12 07:12:26.414]  Step 155511  [3.477 sec/step, loss=0.08658, avg_loss=0.08899, mel_loss=0.03772, linear_loss=0.04886]
[2020-05-12 07:12:29.165]  Step 155512  [3.416 sec/step, loss=0.09040, avg_loss=0.08895, mel_loss=0.03996, linear_loss=0.05044]
[2020-05-12 07:12:29.921]  Step 155513  [3.404 sec/step, loss=0.07512, avg_loss=0.08882, mel_loss=0.03198, linear_loss=0.04314]
[2020-05-12 07:12:31.031]  Step 155514  [3.270 sec/step, loss=0.07924, avg_loss=0.08886, mel_loss=0.03372, linear_loss=0.04552]
[2020-05-12 07:12:32.996]  Step 155515  [3.259 sec/step, loss=0.08793, avg_loss=0.08880, mel_loss=0.03853, linear_loss=0.04940]
[2020-05-12 07:12:33.975]  Step 155516  [3.221 sec/step, loss=0.08171, avg_loss=0.08865, mel_loss=0.03513, linear_loss=0.04659]
[2020-05-12 07:12:36.445]  Step 155517  [3.235 sec/step, loss=0.08921, avg_loss=0.08875, mel_loss=0.03915, linear_loss=0.05006]
[2020-05-12 07:12:50.431]  Step 155518  [3.357 sec/step, loss=0.07579, avg_loss=0.08863, mel_loss=0.03595, linear_loss=0.03984]
[2020-05-12 07:12:51.902]  Step 155519  [3.358 sec/step, loss=0.08272, avg_loss=0.08860, mel_loss=0.03594, linear_loss=0.04678]
[2020-05-12 07:12:59.554]  Step 155520  [3.394 sec/step, loss=0.09682, avg_loss=0.08863, mel_loss=0.04429, linear_loss=0.05253]
[2020-05-12 07:13:01.731]  Step 155521  [3.372 sec/step, loss=0.08986, avg_loss=0.08857, mel_loss=0.03952, linear_loss=0.05034]
[2020-05-12 07:13:04.818]  Step 155522  [3.368 sec/step, loss=0.09500, avg_loss=0.08858, mel_loss=0.04236, linear_loss=0.05264]
[2020-05-12 07:13:13.748]  Step 155523  [3.441 sec/step, loss=0.09539, avg_loss=0.08867, mel_loss=0.04394, linear_loss=0.05145]
[2020-05-12 07:13:17.944]  Step 155524  [3.458 sec/step, loss=0.09384, avg_loss=0.08871, mel_loss=0.04169, linear_loss=0.05215]
[2020-05-12 07:13:23.070]  Step 155525  [3.491 sec/step, loss=0.09634, avg_loss=0.08881, mel_loss=0.04348, linear_loss=0.05286]
[2020-05-12 07:13:27.461]  Step 155526  [3.522 sec/step, loss=0.09534, avg_loss=0.08892, mel_loss=0.04311, linear_loss=0.05223]
[2020-05-12 07:13:28.219]  Step 155527  [3.492 sec/step, loss=0.06902, avg_loss=0.08865, mel_loss=0.02992, linear_loss=0.03911]
[2020-05-12 07:13:29.583]  Step 155528  [3.448 sec/step, loss=0.08413, avg_loss=0.08855, mel_loss=0.03663, linear_loss=0.04750]
[2020-05-12 07:13:31.396]  Step 155529  [3.390 sec/step, loss=0.08679, avg_loss=0.08844, mel_loss=0.03767, linear_loss=0.04912]
[2020-05-12 07:13:34.898]  Step 155530  [3.417 sec/step, loss=0.09313, avg_loss=0.08863, mel_loss=0.04132, linear_loss=0.05181]
[2020-05-12 07:13:38.730]  Step 155531  [3.449 sec/step, loss=0.09572, avg_loss=0.08891, mel_loss=0.04284, linear_loss=0.05288]
[2020-05-12 07:13:39.504]  Generated 32 batches of size 32 in 11.279 sec
[2020-05-12 07:13:40.766]  Step 155532  [3.458 sec/step, loss=0.08982, avg_loss=0.08899, mel_loss=0.03926, linear_loss=0.05056]
[2020-05-12 07:13:44.357]  Step 155533  [3.405 sec/step, loss=0.09296, avg_loss=0.08898, mel_loss=0.04150, linear_loss=0.05146]
[2020-05-12 07:13:46.703]  Step 155534  [3.407 sec/step, loss=0.09113, avg_loss=0.08898, mel_loss=0.04008, linear_loss=0.05105]
[2020-05-12 07:13:51.400]  Step 155535  [3.432 sec/step, loss=0.09550, avg_loss=0.08905, mel_loss=0.04294, linear_loss=0.05255]
[2020-05-12 07:13:52.432]  Step 155536  [3.413 sec/step, loss=0.07764, avg_loss=0.08891, mel_loss=0.03294, linear_loss=0.04469]
[2020-05-12 07:13:55.099]  Step 155537  [3.388 sec/step, loss=0.09182, avg_loss=0.08888, mel_loss=0.04060, linear_loss=0.05121]
[2020-05-12 07:14:00.509]  Step 155538  [3.433 sec/step, loss=0.09339, avg_loss=0.08905, mel_loss=0.04218, linear_loss=0.05122]
[2020-05-12 07:14:02.287]  Step 155539  [3.420 sec/step, loss=0.08829, avg_loss=0.08899, mel_loss=0.03814, linear_loss=0.05015]
[2020-05-12 07:14:06.374]  Step 155540  [3.425 sec/step, loss=0.09508, avg_loss=0.08900, mel_loss=0.04226, linear_loss=0.05282]
[2020-05-12 07:14:08.872]  Step 155541  [3.386 sec/step, loss=0.09021, avg_loss=0.08894, mel_loss=0.03955, linear_loss=0.05066]
[2020-05-12 07:14:13.195]  Step 155542  [3.414 sec/step, loss=0.09555, avg_loss=0.08903, mel_loss=0.04286, linear_loss=0.05269]
[2020-05-12 07:14:14.452]  Step 155543  [3.402 sec/step, loss=0.08570, avg_loss=0.08896, mel_loss=0.03692, linear_loss=0.04877]
[2020-05-12 07:14:17.380]  Step 155544  [3.422 sec/step, loss=0.09186, avg_loss=0.08908, mel_loss=0.04063, linear_loss=0.05123]
[2020-05-12 07:14:19.890]  Step 155545  [3.321 sec/step, loss=0.08952, avg_loss=0.08913, mel_loss=0.03932, linear_loss=0.05020]
[2020-05-12 07:14:33.213]  Step 155546  [3.428 sec/step, loss=0.08161, avg_loss=0.08903, mel_loss=0.03833, linear_loss=0.04328]
[2020-05-12 07:14:39.949]  Step 155547  [3.413 sec/step, loss=0.09625, avg_loss=0.08902, mel_loss=0.04382, linear_loss=0.05243]
[2020-05-12 07:14:44.670]  Step 155548  [3.428 sec/step, loss=0.09548, avg_loss=0.08902, mel_loss=0.04301, linear_loss=0.05247]
[2020-05-12 07:14:45.819]  Step 155549  [3.407 sec/step, loss=0.08398, avg_loss=0.08891, mel_loss=0.03588, linear_loss=0.04810]
[2020-05-12 07:14:48.000]  Step 155550  [3.404 sec/step, loss=0.08902, avg_loss=0.08891, mel_loss=0.03907, linear_loss=0.04994]
[2020-05-12 07:14:48.000]  Writing summary at step: 155550
[2020-05-12 07:14:48.934]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155550
[2020-05-12 07:14:50.486]  Saving audio and alignment...
[2020-05-12 07:14:53.049]  Input: 교재를 보겠습니다~______________
[2020-05-12 07:14:53.872]  Step 155551  [3.351 sec/step, loss=0.07727, avg_loss=0.08871, mel_loss=0.03306, linear_loss=0.04421]
[2020-05-12 07:14:57.203]  Step 155552  [3.369 sec/step, loss=0.09423, avg_loss=0.08885, mel_loss=0.04198, linear_loss=0.05225]
[2020-05-12 07:14:58.023]  Step 155553  [3.354 sec/step, loss=0.07266, avg_loss=0.08872, mel_loss=0.03119, linear_loss=0.04147]
[2020-05-12 07:15:01.700]  Step 155554  [3.327 sec/step, loss=0.09594, avg_loss=0.08873, mel_loss=0.04285, linear_loss=0.05309]
[2020-05-12 07:15:03.439]  Step 155555  [3.325 sec/step, loss=0.08714, avg_loss=0.08873, mel_loss=0.03796, linear_loss=0.04918]
[2020-05-12 07:15:06.975]  Step 155556  [3.340 sec/step, loss=0.09238, avg_loss=0.08877, mel_loss=0.04111, linear_loss=0.05126]
[2020-05-12 07:15:07.739]  Step 155557  [3.270 sec/step, loss=0.07247, avg_loss=0.08852, mel_loss=0.03235, linear_loss=0.04012]
[2020-05-12 07:15:10.853]  Step 155558  [3.288 sec/step, loss=0.09358, avg_loss=0.08859, mel_loss=0.04173, linear_loss=0.05185]
[2020-05-12 07:15:12.902]  Step 155559  [3.260 sec/step, loss=0.08960, avg_loss=0.08854, mel_loss=0.03932, linear_loss=0.05029]
[2020-05-12 07:15:15.164]  Generated 32 batches of size 32 in 7.419 sec
[2020-05-12 07:15:19.970]  Step 155560  [3.308 sec/step, loss=0.09652, avg_loss=0.08859, mel_loss=0.04430, linear_loss=0.05222]
[2020-05-12 07:15:21.572]  Step 155561  [3.314 sec/step, loss=0.08622, avg_loss=0.08867, mel_loss=0.03759, linear_loss=0.04863]
[2020-05-12 07:15:30.114]  Step 155562  [3.386 sec/step, loss=0.09386, avg_loss=0.08873, mel_loss=0.04315, linear_loss=0.05071]
[2020-05-12 07:15:31.992]  Step 155563  [3.375 sec/step, loss=0.08881, avg_loss=0.08870, mel_loss=0.03844, linear_loss=0.05037]
[2020-05-12 07:15:37.690]  Step 155564  [3.395 sec/step, loss=0.09702, avg_loss=0.08872, mel_loss=0.04402, linear_loss=0.05299]
[2020-05-12 07:15:39.118]  Step 155565  [3.398 sec/step, loss=0.08629, avg_loss=0.08876, mel_loss=0.03756, linear_loss=0.04873]
[2020-05-12 07:15:40.146]  Step 155566  [3.396 sec/step, loss=0.08154, avg_loss=0.08874, mel_loss=0.03510, linear_loss=0.04645]
[2020-05-12 07:15:44.715]  Step 155567  [3.413 sec/step, loss=0.09746, avg_loss=0.08879, mel_loss=0.04391, linear_loss=0.05355]
[2020-05-12 07:15:46.104]  Step 155568  [3.374 sec/step, loss=0.08494, avg_loss=0.08868, mel_loss=0.03694, linear_loss=0.04799]
[2020-05-12 07:15:49.411]  Step 155569  [3.390 sec/step, loss=0.09398, avg_loss=0.08875, mel_loss=0.04172, linear_loss=0.05226]
[2020-05-12 07:15:50.655]  Step 155570  [3.361 sec/step, loss=0.08085, avg_loss=0.08860, mel_loss=0.03455, linear_loss=0.04630]
[2020-05-12 07:15:51.470]  Step 155571  [3.350 sec/step, loss=0.07566, avg_loss=0.08846, mel_loss=0.03227, linear_loss=0.04339]
[2020-05-12 07:15:54.000]  Step 155572  [3.369 sec/step, loss=0.09211, avg_loss=0.08867, mel_loss=0.04046, linear_loss=0.05165]
[2020-05-12 07:16:00.812]  Step 155573  [3.369 sec/step, loss=0.09626, avg_loss=0.08869, mel_loss=0.04380, linear_loss=0.05246]
[2020-05-12 07:16:13.350]  Step 155574  [3.460 sec/step, loss=0.08479, avg_loss=0.08862, mel_loss=0.03986, linear_loss=0.04494]
[2020-05-12 07:16:16.887]  Step 155575  [3.420 sec/step, loss=0.09381, avg_loss=0.08859, mel_loss=0.04192, linear_loss=0.05189]
[2020-05-12 07:16:18.417]  Step 155576  [3.413 sec/step, loss=0.08471, avg_loss=0.08854, mel_loss=0.03673, linear_loss=0.04798]
[2020-05-12 07:16:22.573]  Step 155577  [3.400 sec/step, loss=0.09503, avg_loss=0.08852, mel_loss=0.04279, linear_loss=0.05223]
[2020-05-12 07:16:25.245]  Step 155578  [3.377 sec/step, loss=0.09093, avg_loss=0.08846, mel_loss=0.04016, linear_loss=0.05077]
[2020-05-12 07:16:26.893]  Step 155579  [3.347 sec/step, loss=0.08816, avg_loss=0.08839, mel_loss=0.03831, linear_loss=0.04985]
[2020-05-12 07:16:34.533]  Step 155580  [3.409 sec/step, loss=0.09749, avg_loss=0.08851, mel_loss=0.04468, linear_loss=0.05281]
[2020-05-12 07:16:39.890]  Step 155581  [3.400 sec/step, loss=0.09450, avg_loss=0.08851, mel_loss=0.04283, linear_loss=0.05167]
[2020-05-12 07:16:40.914]  Step 155582  [3.397 sec/step, loss=0.08076, avg_loss=0.08848, mel_loss=0.03453, linear_loss=0.04623]
[2020-05-12 07:16:46.668]  Step 155583  [3.437 sec/step, loss=0.09711, avg_loss=0.08857, mel_loss=0.04427, linear_loss=0.05284]
[2020-05-12 07:16:47.955]  Step 155584  [3.426 sec/step, loss=0.08453, avg_loss=0.08850, mel_loss=0.03675, linear_loss=0.04777]
[2020-05-12 07:16:50.131]  Step 155585  [3.405 sec/step, loss=0.09115, avg_loss=0.08847, mel_loss=0.03972, linear_loss=0.05142]
[2020-05-12 07:16:54.206]  Step 155586  [3.435 sec/step, loss=0.09524, avg_loss=0.08864, mel_loss=0.04240, linear_loss=0.05284]
[2020-05-12 07:16:55.289]  Step 155587  [3.410 sec/step, loss=0.08172, avg_loss=0.08851, mel_loss=0.03514, linear_loss=0.04658]
[2020-05-12 07:16:58.459]  Step 155588  [3.408 sec/step, loss=0.09372, avg_loss=0.08851, mel_loss=0.04172, linear_loss=0.05200]
[2020-05-12 07:17:00.525]  Step 155589  [3.415 sec/step, loss=0.08841, avg_loss=0.08853, mel_loss=0.03890, linear_loss=0.04951]
[2020-05-12 07:17:03.487]  Step 155590  [3.410 sec/step, loss=0.09447, avg_loss=0.08855, mel_loss=0.04171, linear_loss=0.05275]
[2020-05-12 07:17:05.258]  Step 155591  [3.417 sec/step, loss=0.08920, avg_loss=0.08861, mel_loss=0.03872, linear_loss=0.05048]
[2020-05-12 07:17:06.841]  Generated 32 batches of size 32 in 6.310 sec
[2020-05-12 07:17:13.840]  Step 155592  [3.470 sec/step, loss=0.09434, avg_loss=0.08862, mel_loss=0.04310, linear_loss=0.05124]
[2020-05-12 07:17:14.682]  Step 155593  [3.333 sec/step, loss=0.07032, avg_loss=0.08857, mel_loss=0.03082, linear_loss=0.03950]
[2020-05-12 07:17:15.544]  Step 155594  [3.333 sec/step, loss=0.07187, avg_loss=0.08855, mel_loss=0.03070, linear_loss=0.04117]
[2020-05-12 07:17:17.592]  Step 155595  [3.264 sec/step, loss=0.08782, avg_loss=0.08849, mel_loss=0.03827, linear_loss=0.04955]
[2020-05-12 07:17:20.081]  Step 155596  [3.269 sec/step, loss=0.08921, avg_loss=0.08851, mel_loss=0.03942, linear_loss=0.04980]
[2020-05-12 07:17:24.018]  Step 155597  [3.301 sec/step, loss=0.09312, avg_loss=0.08870, mel_loss=0.04154, linear_loss=0.05159]
[2020-05-12 07:17:25.046]  Step 155598  [3.289 sec/step, loss=0.08139, avg_loss=0.08862, mel_loss=0.03494, linear_loss=0.04645]
[2020-05-12 07:17:26.558]  Step 155599  [3.285 sec/step, loss=0.08465, avg_loss=0.08858, mel_loss=0.03663, linear_loss=0.04802]
[2020-05-12 07:17:28.771]  Step 155600  [3.278 sec/step, loss=0.09008, avg_loss=0.08856, mel_loss=0.04007, linear_loss=0.05001]
[2020-05-12 07:17:28.771]  Writing summary at step: 155600
[2020-05-12 07:17:30.527]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155600
[2020-05-12 07:17:32.080]  Saving audio and alignment...
[2020-05-12 07:17:33.646]  Input: 바누~________
[2020-05-12 07:17:36.103]  Step 155601  [3.286 sec/step, loss=0.08857, avg_loss=0.08855, mel_loss=0.03873, linear_loss=0.04985]
[2020-05-12 07:17:36.605]  Step 155602  [3.264 sec/step, loss=0.07289, avg_loss=0.08838, mel_loss=0.03146, linear_loss=0.04142]
[2020-05-12 07:17:37.717]  Step 155603  [3.235 sec/step, loss=0.08106, avg_loss=0.08825, mel_loss=0.03479, linear_loss=0.04627]
[2020-05-12 07:17:41.358]  Step 155604  [3.259 sec/step, loss=0.09704, avg_loss=0.08838, mel_loss=0.04356, linear_loss=0.05348]
[2020-05-12 07:17:42.239]  Step 155605  [3.206 sec/step, loss=0.08037, avg_loss=0.08823, mel_loss=0.03430, linear_loss=0.04607]
[2020-05-12 07:17:51.264]  Step 155606  [3.287 sec/step, loss=0.09654, avg_loss=0.08843, mel_loss=0.04493, linear_loss=0.05161]
[2020-05-12 07:17:57.394]  Step 155607  [3.331 sec/step, loss=0.09594, avg_loss=0.08852, mel_loss=0.04383, linear_loss=0.05211]
[2020-05-12 07:18:02.819]  Step 155608  [3.356 sec/step, loss=0.09678, avg_loss=0.08855, mel_loss=0.04353, linear_loss=0.05325]
[2020-05-12 07:18:04.495]  Step 155609  [3.309 sec/step, loss=0.08582, avg_loss=0.08846, mel_loss=0.03760, linear_loss=0.04822]
[2020-05-12 07:18:05.436]  Step 155610  [3.306 sec/step, loss=0.08002, avg_loss=0.08845, mel_loss=0.03434, linear_loss=0.04568]
[2020-05-12 07:18:08.443]  Step 155611  [3.321 sec/step, loss=0.09621, avg_loss=0.08855, mel_loss=0.04284, linear_loss=0.05336]
[2020-05-12 07:18:12.764]  Step 155612  [3.336 sec/step, loss=0.09611, avg_loss=0.08861, mel_loss=0.04296, linear_loss=0.05316]
[2020-05-12 07:18:14.554]  Step 155613  [3.347 sec/step, loss=0.08770, avg_loss=0.08873, mel_loss=0.03807, linear_loss=0.04963]
[2020-05-12 07:18:15.391]  Step 155614  [3.344 sec/step, loss=0.07851, avg_loss=0.08872, mel_loss=0.03407, linear_loss=0.04443]
[2020-05-12 07:18:16.597]  Step 155615  [3.337 sec/step, loss=0.08148, avg_loss=0.08866, mel_loss=0.03527, linear_loss=0.04621]
[2020-05-12 07:18:18.005]  Step 155616  [3.341 sec/step, loss=0.08582, avg_loss=0.08870, mel_loss=0.03713, linear_loss=0.04869]
[2020-05-12 07:18:25.273]  Step 155617  [3.389 sec/step, loss=0.09707, avg_loss=0.08878, mel_loss=0.04450, linear_loss=0.05257]
[2020-05-12 07:18:29.949]  Step 155618  [3.296 sec/step, loss=0.09507, avg_loss=0.08897, mel_loss=0.04281, linear_loss=0.05225]
[2020-05-12 07:18:31.988]  Step 155619  [3.301 sec/step, loss=0.08955, avg_loss=0.08904, mel_loss=0.03920, linear_loss=0.05035]
[2020-05-12 07:18:33.897]  Generated 32 batches of size 32 in 1.903 sec
[2020-05-12 07:18:36.173]  Step 155620  [3.267 sec/step, loss=0.09533, avg_loss=0.08903, mel_loss=0.04244, linear_loss=0.05290]
[2020-05-12 07:18:39.652]  Step 155621  [3.280 sec/step, loss=0.09227, avg_loss=0.08905, mel_loss=0.04124, linear_loss=0.05103]
[2020-05-12 07:18:42.032]  Step 155622  [3.273 sec/step, loss=0.09333, avg_loss=0.08903, mel_loss=0.04111, linear_loss=0.05222]
[2020-05-12 07:18:45.445]  Step 155623  [3.217 sec/step, loss=0.09523, avg_loss=0.08903, mel_loss=0.04236, linear_loss=0.05287]
[2020-05-12 07:18:47.916]  Step 155624  [3.200 sec/step, loss=0.09124, avg_loss=0.08901, mel_loss=0.04009, linear_loss=0.05114]
[2020-05-12 07:18:50.711]  Step 155625  [3.177 sec/step, loss=0.09166, avg_loss=0.08896, mel_loss=0.04063, linear_loss=0.05102]
[2020-05-12 07:18:53.696]  Step 155626  [3.163 sec/step, loss=0.09086, avg_loss=0.08891, mel_loss=0.04043, linear_loss=0.05043]
[2020-05-12 07:19:08.401]  Step 155627  [3.302 sec/step, loss=0.07770, avg_loss=0.08900, mel_loss=0.03678, linear_loss=0.04092]
[2020-05-12 07:19:13.498]  Step 155628  [3.340 sec/step, loss=0.09448, avg_loss=0.08910, mel_loss=0.04261, linear_loss=0.05187]
[2020-05-12 07:19:14.535]  Step 155629  [3.332 sec/step, loss=0.08167, avg_loss=0.08905, mel_loss=0.03515, linear_loss=0.04652]
[2020-05-12 07:19:16.305]  Step 155630  [3.315 sec/step, loss=0.08729, avg_loss=0.08899, mel_loss=0.03811, linear_loss=0.04919]
[2020-05-12 07:19:25.999]  Step 155631  [3.373 sec/step, loss=0.09878, avg_loss=0.08902, mel_loss=0.04530, linear_loss=0.05348]
[2020-05-12 07:19:31.096]  Step 155632  [3.404 sec/step, loss=0.09413, avg_loss=0.08907, mel_loss=0.04199, linear_loss=0.05214]
[2020-05-12 07:19:33.287]  Step 155633  [3.390 sec/step, loss=0.08948, avg_loss=0.08903, mel_loss=0.03919, linear_loss=0.05029]
[2020-05-12 07:19:35.213]  Step 155634  [3.386 sec/step, loss=0.08672, avg_loss=0.08899, mel_loss=0.03746, linear_loss=0.04926]
[2020-05-12 07:19:40.813]  Step 155635  [3.395 sec/step, loss=0.09621, avg_loss=0.08900, mel_loss=0.04346, linear_loss=0.05275]
[2020-05-12 07:19:41.830]  Step 155636  [3.394 sec/step, loss=0.08138, avg_loss=0.08903, mel_loss=0.03447, linear_loss=0.04691]
[2020-05-12 07:19:43.163]  Step 155637  [3.381 sec/step, loss=0.08530, avg_loss=0.08897, mel_loss=0.03698, linear_loss=0.04832]
[2020-05-12 07:19:43.977]  Step 155638  [3.335 sec/step, loss=0.07845, avg_loss=0.08882, mel_loss=0.03332, linear_loss=0.04513]
[2020-05-12 07:19:46.550]  Step 155639  [3.343 sec/step, loss=0.09017, avg_loss=0.08884, mel_loss=0.03967, linear_loss=0.05050]
[2020-05-12 07:19:47.269]  Step 155640  [3.309 sec/step, loss=0.07632, avg_loss=0.08865, mel_loss=0.03270, linear_loss=0.04362]
[2020-05-12 07:19:48.603]  Step 155641  [3.298 sec/step, loss=0.08467, avg_loss=0.08859, mel_loss=0.03680, linear_loss=0.04787]
[2020-05-12 07:19:52.119]  Step 155642  [3.290 sec/step, loss=0.09279, avg_loss=0.08857, mel_loss=0.04153, linear_loss=0.05126]
[2020-05-12 07:19:53.359]  Step 155643  [3.290 sec/step, loss=0.08248, avg_loss=0.08854, mel_loss=0.03556, linear_loss=0.04692]
[2020-05-12 07:19:58.274]  Step 155644  [3.309 sec/step, loss=0.09555, avg_loss=0.08857, mel_loss=0.04293, linear_loss=0.05262]
[2020-05-12 07:20:01.978]  Step 155645  [3.321 sec/step, loss=0.09481, avg_loss=0.08862, mel_loss=0.04236, linear_loss=0.05245]
[2020-05-12 07:20:08.884]  Step 155646  [3.257 sec/step, loss=0.09650, avg_loss=0.08877, mel_loss=0.04383, linear_loss=0.05267]
[2020-05-12 07:20:10.506]  Step 155647  [3.206 sec/step, loss=0.08879, avg_loss=0.08870, mel_loss=0.03852, linear_loss=0.05027]
[2020-05-12 07:20:12.600]  Step 155648  [3.180 sec/step, loss=0.08960, avg_loss=0.08864, mel_loss=0.03914, linear_loss=0.05046]
[2020-05-12 07:20:21.200]  Step 155649  [3.254 sec/step, loss=0.09371, avg_loss=0.08874, mel_loss=0.04296, linear_loss=0.05075]
[2020-05-12 07:20:25.692]  Step 155650  [3.277 sec/step, loss=0.09627, avg_loss=0.08881, mel_loss=0.04341, linear_loss=0.05286]
[2020-05-12 07:20:25.692]  Writing summary at step: 155650
[2020-05-12 07:20:26.844]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155650
[2020-05-12 07:20:30.181]  Saving audio and alignment...
[2020-05-12 07:20:34.105]  Input: 첫 번째 기술은 한수 더 뜨기에요~_____________
[2020-05-12 07:20:35.594]  Step 155651  [3.284 sec/step, loss=0.08667, avg_loss=0.08890, mel_loss=0.03750, linear_loss=0.04917]
[2020-05-12 07:20:36.358]  Step 155652  [3.258 sec/step, loss=0.07248, avg_loss=0.08869, mel_loss=0.03173, linear_loss=0.04074]
[2020-05-12 07:20:42.201]  Step 155653  [3.309 sec/step, loss=0.09691, avg_loss=0.08893, mel_loss=0.04416, linear_loss=0.05275]
[2020-05-12 07:20:46.461]  Step 155654  [3.314 sec/step, loss=0.09366, avg_loss=0.08891, mel_loss=0.04198, linear_loss=0.05169]
[2020-05-12 07:20:49.366]  Step 155655  [3.326 sec/step, loss=0.09111, avg_loss=0.08895, mel_loss=0.04031, linear_loss=0.05080]
[2020-05-12 07:20:52.483]  Step 155656  [3.322 sec/step, loss=0.09368, avg_loss=0.08896, mel_loss=0.04148, linear_loss=0.05220]
[2020-05-12 07:21:07.204]  Step 155657  [3.462 sec/step, loss=0.07192, avg_loss=0.08895, mel_loss=0.03382, linear_loss=0.03810]
[2020-05-12 07:21:09.763]  Step 155658  [3.456 sec/step, loss=0.09039, avg_loss=0.08892, mel_loss=0.03971, linear_loss=0.05068]
[2020-05-12 07:21:20.483]  Generated 32 batches of size 32 in 49.670 sec
[2020-05-12 07:21:21.671]  Step 155659  [3.555 sec/step, loss=0.08170, avg_loss=0.08884, mel_loss=0.03539, linear_loss=0.04631]
[2020-05-12 07:21:24.815]  Step 155660  [3.515 sec/step, loss=0.09366, avg_loss=0.08881, mel_loss=0.04128, linear_loss=0.05238]
[2020-05-12 07:21:25.460]  Step 155661  [3.506 sec/step, loss=0.07545, avg_loss=0.08871, mel_loss=0.03297, linear_loss=0.04248]
[2020-05-12 07:21:28.992]  Step 155662  [3.456 sec/step, loss=0.09478, avg_loss=0.08872, mel_loss=0.04261, linear_loss=0.05217]
[2020-05-12 07:21:34.753]  Step 155663  [3.494 sec/step, loss=0.09588, avg_loss=0.08879, mel_loss=0.04330, linear_loss=0.05258]
[2020-05-12 07:21:39.925]  Step 155664  [3.489 sec/step, loss=0.09451, avg_loss=0.08876, mel_loss=0.04264, linear_loss=0.05187]
[2020-05-12 07:21:41.839]  Step 155665  [3.494 sec/step, loss=0.08764, avg_loss=0.08877, mel_loss=0.03834, linear_loss=0.04930]
[2020-05-12 07:21:45.407]  Step 155666  [3.519 sec/step, loss=0.09322, avg_loss=0.08889, mel_loss=0.04148, linear_loss=0.05174]
[2020-05-12 07:21:46.786]  Step 155667  [3.488 sec/step, loss=0.08592, avg_loss=0.08878, mel_loss=0.03701, linear_loss=0.04891]
[2020-05-12 07:21:48.273]  Step 155668  [3.489 sec/step, loss=0.08579, avg_loss=0.08878, mel_loss=0.03733, linear_loss=0.04846]
[2020-05-12 07:21:49.118]  Step 155669  [3.464 sec/step, loss=0.07244, avg_loss=0.08857, mel_loss=0.03086, linear_loss=0.04159]
[2020-05-12 07:21:51.740]  Step 155670  [3.478 sec/step, loss=0.09144, avg_loss=0.08868, mel_loss=0.04041, linear_loss=0.05103]
[2020-05-12 07:21:54.185]  Step 155671  [3.494 sec/step, loss=0.09020, avg_loss=0.08882, mel_loss=0.03953, linear_loss=0.05068]
[2020-05-12 07:21:56.446]  Step 155672  [3.491 sec/step, loss=0.09023, avg_loss=0.08880, mel_loss=0.03985, linear_loss=0.05038]
[2020-05-12 07:22:02.735]  Step 155673  [3.486 sec/step, loss=0.09475, avg_loss=0.08879, mel_loss=0.04339, linear_loss=0.05136]
[2020-05-12 07:22:15.514]  Step 155674  [3.489 sec/step, loss=0.08751, avg_loss=0.08881, mel_loss=0.04100, linear_loss=0.04651]
[2020-05-12 07:22:19.314]  Step 155675  [3.491 sec/step, loss=0.09680, avg_loss=0.08884, mel_loss=0.04334, linear_loss=0.05346]
[2020-05-12 07:22:27.078]  Step 155676  [3.553 sec/step, loss=0.09560, avg_loss=0.08895, mel_loss=0.04368, linear_loss=0.05192]
[2020-05-12 07:22:31.288]  Step 155677  [3.554 sec/step, loss=0.09452, avg_loss=0.08895, mel_loss=0.04218, linear_loss=0.05234]
[2020-05-12 07:22:33.467]  Step 155678  [3.549 sec/step, loss=0.08826, avg_loss=0.08892, mel_loss=0.03862, linear_loss=0.04964]
[2020-05-12 07:22:34.903]  Step 155679  [3.547 sec/step, loss=0.08472, avg_loss=0.08889, mel_loss=0.03664, linear_loss=0.04808]
[2020-05-12 07:22:39.188]  Step 155680  [3.513 sec/step, loss=0.09542, avg_loss=0.08887, mel_loss=0.04290, linear_loss=0.05252]
[2020-05-12 07:22:39.757]  Step 155681  [3.466 sec/step, loss=0.06910, avg_loss=0.08861, mel_loss=0.03086, linear_loss=0.03823]
[2020-05-12 07:22:41.453]  Step 155682  [3.472 sec/step, loss=0.08652, avg_loss=0.08867, mel_loss=0.03793, linear_loss=0.04858]
[2020-05-12 07:22:50.877]  Step 155683  [3.509 sec/step, loss=0.09452, avg_loss=0.08864, mel_loss=0.04374, linear_loss=0.05078]
[2020-05-12 07:22:55.629]  Step 155684  [3.544 sec/step, loss=0.09555, avg_loss=0.08875, mel_loss=0.04279, linear_loss=0.05276]
[2020-05-12 07:22:57.471]  Step 155685  [3.540 sec/step, loss=0.08771, avg_loss=0.08872, mel_loss=0.03822, linear_loss=0.04949]
[2020-05-12 07:22:59.672]  Step 155686  [3.522 sec/step, loss=0.09046, avg_loss=0.08867, mel_loss=0.03995, linear_loss=0.05051]
[2020-05-12 07:23:02.910]  Step 155687  [3.543 sec/step, loss=0.09541, avg_loss=0.08881, mel_loss=0.04230, linear_loss=0.05311]
[2020-05-12 07:23:05.890]  Step 155688  [3.541 sec/step, loss=0.09078, avg_loss=0.08878, mel_loss=0.04028, linear_loss=0.05050]
[2020-05-12 07:23:06.983]  Step 155689  [3.531 sec/step, loss=0.07916, avg_loss=0.08869, mel_loss=0.03428, linear_loss=0.04488]
[2020-05-12 07:23:07.891]  Step 155690  [3.511 sec/step, loss=0.07736, avg_loss=0.08852, mel_loss=0.03317, linear_loss=0.04419]
[2020-05-12 07:23:11.781]  Generated 32 batches of size 32 in 32.019 sec
[2020-05-12 07:23:15.135]  Step 155691  [3.566 sec/step, loss=0.09405, avg_loss=0.08856, mel_loss=0.04169, linear_loss=0.05236]
[2020-05-12 07:23:20.906]  Step 155692  [3.538 sec/step, loss=0.09679, avg_loss=0.08859, mel_loss=0.04401, linear_loss=0.05278]
[2020-05-12 07:23:22.660]  Step 155693  [3.547 sec/step, loss=0.08824, avg_loss=0.08877, mel_loss=0.03822, linear_loss=0.05002]
[2020-05-12 07:23:37.259]  Step 155694  [3.684 sec/step, loss=0.07409, avg_loss=0.08879, mel_loss=0.03497, linear_loss=0.03912]
[2020-05-12 07:23:38.181]  Step 155695  [3.673 sec/step, loss=0.07894, avg_loss=0.08870, mel_loss=0.03370, linear_loss=0.04524]
[2020-05-12 07:23:41.054]  Step 155696  [3.677 sec/step, loss=0.09189, avg_loss=0.08873, mel_loss=0.04084, linear_loss=0.05105]
[2020-05-12 07:23:42.225]  Step 155697  [3.649 sec/step, loss=0.08302, avg_loss=0.08863, mel_loss=0.03531, linear_loss=0.04771]
[2020-05-12 07:23:44.756]  Step 155698  [3.664 sec/step, loss=0.08888, avg_loss=0.08870, mel_loss=0.03891, linear_loss=0.04997]
[2020-05-12 07:23:46.165]  Step 155699  [3.663 sec/step, loss=0.08461, avg_loss=0.08870, mel_loss=0.03676, linear_loss=0.04785]
[2020-05-12 07:23:48.060]  Step 155700  [3.660 sec/step, loss=0.08830, avg_loss=0.08868, mel_loss=0.03838, linear_loss=0.04992]
[2020-05-12 07:23:48.060]  Writing summary at step: 155700
[2020-05-12 07:23:49.154]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155700
[2020-05-12 07:23:50.717]  Saving audio and alignment...
[2020-05-12 07:23:52.274]  Input: 다음으로~_________________________
[2020-05-12 07:23:54.428]  Step 155701  [3.657 sec/step, loss=0.08919, avg_loss=0.08869, mel_loss=0.03906, linear_loss=0.05013]
[2020-05-12 07:23:56.058]  Step 155702  [3.668 sec/step, loss=0.08839, avg_loss=0.08884, mel_loss=0.03863, linear_loss=0.04976]
[2020-05-12 07:23:59.566]  Step 155703  [3.692 sec/step, loss=0.09612, avg_loss=0.08900, mel_loss=0.04305, linear_loss=0.05307]
[2020-05-12 07:24:01.611]  Step 155704  [3.676 sec/step, loss=0.08982, avg_loss=0.08892, mel_loss=0.03926, linear_loss=0.05056]
[2020-05-12 07:24:02.966]  Step 155705  [3.681 sec/step, loss=0.08333, avg_loss=0.08895, mel_loss=0.03633, linear_loss=0.04701]
[2020-05-12 07:24:08.256]  Step 155706  [3.643 sec/step, loss=0.09550, avg_loss=0.08894, mel_loss=0.04323, linear_loss=0.05227]
[2020-05-12 07:24:12.075]  Step 155707  [3.620 sec/step, loss=0.09522, avg_loss=0.08894, mel_loss=0.04259, linear_loss=0.05264]
[2020-05-12 07:24:13.666]  Step 155708  [3.582 sec/step, loss=0.08554, avg_loss=0.08882, mel_loss=0.03726, linear_loss=0.04828]
[2020-05-12 07:24:15.908]  Step 155709  [3.588 sec/step, loss=0.09133, avg_loss=0.08888, mel_loss=0.04045, linear_loss=0.05089]
[2020-05-12 07:24:20.197]  Step 155710  [3.621 sec/step, loss=0.09450, avg_loss=0.08902, mel_loss=0.04241, linear_loss=0.05209]
[2020-05-12 07:24:26.736]  Step 155711  [3.656 sec/step, loss=0.09634, avg_loss=0.08902, mel_loss=0.04396, linear_loss=0.05239]
[2020-05-12 07:24:29.888]  Step 155712  [3.645 sec/step, loss=0.09366, avg_loss=0.08900, mel_loss=0.04150, linear_loss=0.05216]
[2020-05-12 07:24:32.674]  Step 155713  [3.655 sec/step, loss=0.09078, avg_loss=0.08903, mel_loss=0.04026, linear_loss=0.05053]
[2020-05-12 07:24:33.711]  Step 155714  [3.657 sec/step, loss=0.08226, avg_loss=0.08907, mel_loss=0.03537, linear_loss=0.04689]
[2020-05-12 07:24:36.391]  Generated 32 batches of size 32 in 9.649 sec
[2020-05-12 07:24:41.536]  Step 155715  [3.723 sec/step, loss=0.09618, avg_loss=0.08922, mel_loss=0.04415, linear_loss=0.05203]
[2020-05-12 07:24:46.218]  Step 155716  [3.756 sec/step, loss=0.09514, avg_loss=0.08931, mel_loss=0.04280, linear_loss=0.05234]
[2020-05-12 07:24:47.015]  Step 155717  [3.691 sec/step, loss=0.07221, avg_loss=0.08906, mel_loss=0.03102, linear_loss=0.04119]
[2020-05-12 07:24:55.823]  Step 155718  [3.732 sec/step, loss=0.09534, avg_loss=0.08906, mel_loss=0.04378, linear_loss=0.05156]
[2020-05-12 07:24:59.297]  Step 155719  [3.747 sec/step, loss=0.09185, avg_loss=0.08909, mel_loss=0.04063, linear_loss=0.05122]
[2020-05-12 07:25:00.088]  Step 155720  [3.713 sec/step, loss=0.07651, avg_loss=0.08890, mel_loss=0.03285, linear_loss=0.04366]
[2020-05-12 07:25:06.834]  Step 155721  [3.745 sec/step, loss=0.09702, avg_loss=0.08894, mel_loss=0.04413, linear_loss=0.05289]
[2020-05-12 07:25:07.884]  Step 155722  [3.732 sec/step, loss=0.07678, avg_loss=0.08878, mel_loss=0.03304, linear_loss=0.04374]
[2020-05-12 07:25:21.905]  Step 155723  [3.838 sec/step, loss=0.07724, avg_loss=0.08860, mel_loss=0.03655, linear_loss=0.04069]
[2020-05-12 07:25:23.529]  Step 155724  [3.830 sec/step, loss=0.08636, avg_loss=0.08855, mel_loss=0.03756, linear_loss=0.04880]
[2020-05-12 07:25:32.369]  Step 155725  [3.890 sec/step, loss=0.09453, avg_loss=0.08858, mel_loss=0.04350, linear_loss=0.05103]
[2020-05-12 07:25:36.513]  Step 155726  [3.902 sec/step, loss=0.09317, avg_loss=0.08860, mel_loss=0.04162, linear_loss=0.05155]
[2020-05-12 07:25:40.011]  Step 155727  [3.790 sec/step, loss=0.09327, avg_loss=0.08876, mel_loss=0.04177, linear_loss=0.05151]
[2020-05-12 07:25:40.823]  Step 155728  [3.747 sec/step, loss=0.07783, avg_loss=0.08859, mel_loss=0.03306, linear_loss=0.04478]
[2020-05-12 07:25:41.957]  Step 155729  [3.748 sec/step, loss=0.08120, avg_loss=0.08859, mel_loss=0.03465, linear_loss=0.04655]
[2020-05-12 07:25:43.671]  Step 155730  [3.747 sec/step, loss=0.08921, avg_loss=0.08861, mel_loss=0.03863, linear_loss=0.05058]
[2020-05-12 07:25:46.096]  Step 155731  [3.674 sec/step, loss=0.09032, avg_loss=0.08852, mel_loss=0.03940, linear_loss=0.05093]
[2020-05-12 07:25:47.345]  Step 155732  [3.636 sec/step, loss=0.08385, avg_loss=0.08842, mel_loss=0.03612, linear_loss=0.04773]
[2020-05-12 07:25:49.377]  Step 155733  [3.634 sec/step, loss=0.09032, avg_loss=0.08843, mel_loss=0.03940, linear_loss=0.05092]
[2020-05-12 07:25:50.773]  Step 155734  [3.629 sec/step, loss=0.08414, avg_loss=0.08840, mel_loss=0.03655, linear_loss=0.04759]
[2020-05-12 07:25:53.776]  Step 155735  [3.603 sec/step, loss=0.09359, avg_loss=0.08838, mel_loss=0.04171, linear_loss=0.05188]
[2020-05-12 07:25:57.360]  Step 155736  [3.629 sec/step, loss=0.09317, avg_loss=0.08849, mel_loss=0.04148, linear_loss=0.05169]
[2020-05-12 07:26:02.048]  Step 155737  [3.662 sec/step, loss=0.09581, avg_loss=0.08860, mel_loss=0.04255, linear_loss=0.05325]
[2020-05-12 07:26:04.072]  Step 155738  [3.674 sec/step, loss=0.08607, avg_loss=0.08867, mel_loss=0.03767, linear_loss=0.04840]
[2020-05-12 07:26:06.293]  Step 155739  [3.671 sec/step, loss=0.08987, avg_loss=0.08867, mel_loss=0.03927, linear_loss=0.05060]
[2020-05-12 07:26:09.378]  Step 155740  [3.695 sec/step, loss=0.09462, avg_loss=0.08885, mel_loss=0.04198, linear_loss=0.05264]
[2020-05-12 07:26:10.143]  Step 155741  [3.689 sec/step, loss=0.07371, avg_loss=0.08874, mel_loss=0.03237, linear_loss=0.04134]
[2020-05-12 07:26:12.977]  Step 155742  [3.682 sec/step, loss=0.09046, avg_loss=0.08872, mel_loss=0.03978, linear_loss=0.05068]
[2020-05-12 07:26:18.198]  Step 155743  [3.722 sec/step, loss=0.09486, avg_loss=0.08885, mel_loss=0.04279, linear_loss=0.05207]
[2020-05-12 07:26:19.967]  Generated 32 batches of size 32 in 1.764 sec
[2020-05-12 07:26:20.108]  Step 155744  [3.692 sec/step, loss=0.08631, avg_loss=0.08875, mel_loss=0.03774, linear_loss=0.04858]
[2020-05-12 07:26:24.277]  Step 155745  [3.696 sec/step, loss=0.09637, avg_loss=0.08877, mel_loss=0.04354, linear_loss=0.05283]
[2020-05-12 07:26:31.357]  Step 155746  [3.698 sec/step, loss=0.09781, avg_loss=0.08878, mel_loss=0.04456, linear_loss=0.05325]
[2020-05-12 07:26:32.359]  Step 155747  [3.692 sec/step, loss=0.08079, avg_loss=0.08870, mel_loss=0.03447, linear_loss=0.04632]
[2020-05-12 07:26:35.031]  Step 155748  [3.698 sec/step, loss=0.09100, avg_loss=0.08872, mel_loss=0.04021, linear_loss=0.05079]
[2020-05-12 07:26:35.791]  Step 155749  [3.619 sec/step, loss=0.07205, avg_loss=0.08850, mel_loss=0.03115, linear_loss=0.04090]
[2020-05-12 07:26:37.207]  Step 155750  [3.589 sec/step, loss=0.08526, avg_loss=0.08839, mel_loss=0.03697, linear_loss=0.04829]
[2020-05-12 07:26:37.207]  Writing summary at step: 155750
[2020-05-12 07:26:43.033]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155750
[2020-05-12 07:26:44.563]  Saving audio and alignment...
[2020-05-12 07:26:50.357]  Input: 그럼 지금부터 향기로운 목소리 꽃 같은 발음을 위해~_________________
[2020-05-12 07:26:56.666]  Step 155751  [3.637 sec/step, loss=0.09464, avg_loss=0.08847, mel_loss=0.04299, linear_loss=0.05165]
[2020-05-12 07:26:57.526]  Step 155752  [3.638 sec/step, loss=0.08026, avg_loss=0.08855, mel_loss=0.03400, linear_loss=0.04625]
[2020-05-12 07:26:58.048]  Step 155753  [3.585 sec/step, loss=0.07430, avg_loss=0.08832, mel_loss=0.03187, linear_loss=0.04244]
[2020-05-12 07:27:01.029]  Step 155754  [3.572 sec/step, loss=0.09352, avg_loss=0.08832, mel_loss=0.04148, linear_loss=0.05204]
[2020-05-12 07:27:14.211]  Step 155755  [3.675 sec/step, loss=0.08023, avg_loss=0.08821, mel_loss=0.03770, linear_loss=0.04253]
[2020-05-12 07:27:16.015]  Step 155756  [3.661 sec/step, loss=0.08885, avg_loss=0.08816, mel_loss=0.03846, linear_loss=0.05039]
[2020-05-12 07:27:17.293]  Step 155757  [3.527 sec/step, loss=0.08513, avg_loss=0.08829, mel_loss=0.03686, linear_loss=0.04828]
[2020-05-12 07:27:19.839]  Step 155758  [3.527 sec/step, loss=0.09010, avg_loss=0.08829, mel_loss=0.03976, linear_loss=0.05034]
[2020-05-12 07:27:23.633]  Step 155759  [3.446 sec/step, loss=0.09552, avg_loss=0.08843, mel_loss=0.04260, linear_loss=0.05292]
[2020-05-12 07:27:25.948]  Step 155760  [3.437 sec/step, loss=0.09192, avg_loss=0.08841, mel_loss=0.04059, linear_loss=0.05134]
[2020-05-12 07:27:27.316]  Step 155761  [3.445 sec/step, loss=0.08727, avg_loss=0.08853, mel_loss=0.03783, linear_loss=0.04944]
[2020-05-12 07:27:28.793]  Step 155762  [3.424 sec/step, loss=0.08543, avg_loss=0.08844, mel_loss=0.03699, linear_loss=0.04844]
[2020-05-12 07:27:34.474]  Step 155763  [3.423 sec/step, loss=0.09533, avg_loss=0.08843, mel_loss=0.04318, linear_loss=0.05215]
[2020-05-12 07:27:37.979]  Step 155764  [3.407 sec/step, loss=0.09242, avg_loss=0.08841, mel_loss=0.04092, linear_loss=0.05150]
[2020-05-12 07:27:39.025]  Step 155765  [3.398 sec/step, loss=0.08189, avg_loss=0.08835, mel_loss=0.03519, linear_loss=0.04670]
[2020-05-12 07:27:43.851]  Step 155766  [3.411 sec/step, loss=0.09656, avg_loss=0.08839, mel_loss=0.04349, linear_loss=0.05307]
[2020-05-12 07:27:45.079]  Step 155767  [3.409 sec/step, loss=0.07946, avg_loss=0.08832, mel_loss=0.03420, linear_loss=0.04526]
[2020-05-12 07:27:52.578]  Step 155768  [3.469 sec/step, loss=0.09677, avg_loss=0.08843, mel_loss=0.04422, linear_loss=0.05255]
[2020-05-12 07:27:54.221]  Step 155769  [3.477 sec/step, loss=0.08679, avg_loss=0.08857, mel_loss=0.03799, linear_loss=0.04881]
[2020-05-12 07:27:55.971]  Step 155770  [3.468 sec/step, loss=0.08905, avg_loss=0.08855, mel_loss=0.03884, linear_loss=0.05021]
[2020-05-12 07:27:56.742]  Step 155771  [3.452 sec/step, loss=0.07834, avg_loss=0.08843, mel_loss=0.03332, linear_loss=0.04502]
[2020-05-12 07:27:59.949]  Step 155772  [3.461 sec/step, loss=0.09568, avg_loss=0.08849, mel_loss=0.04279, linear_loss=0.05289]
[2020-05-12 07:28:02.195]  Step 155773  [3.421 sec/step, loss=0.08893, avg_loss=0.08843, mel_loss=0.03942, linear_loss=0.04950]
[2020-05-12 07:28:02.990]  Step 155774  [3.301 sec/step, loss=0.07608, avg_loss=0.08831, mel_loss=0.03329, linear_loss=0.04279]
[2020-05-12 07:28:03.874]  Generated 32 batches of size 32 in 1.674 sec
[2020-05-12 07:28:06.667]  Step 155775  [3.300 sec/step, loss=0.09633, avg_loss=0.08831, mel_loss=0.04291, linear_loss=0.05342]
[2020-05-12 07:28:11.588]  Step 155776  [3.271 sec/step, loss=0.09440, avg_loss=0.08830, mel_loss=0.04274, linear_loss=0.05165]
[2020-05-12 07:28:12.664]  Step 155777  [3.240 sec/step, loss=0.08369, avg_loss=0.08819, mel_loss=0.03614, linear_loss=0.04755]
[2020-05-12 07:28:21.110]  Step 155778  [3.303 sec/step, loss=0.09386, avg_loss=0.08825, mel_loss=0.04309, linear_loss=0.05078]
[2020-05-12 07:28:23.168]  Step 155779  [3.309 sec/step, loss=0.08936, avg_loss=0.08829, mel_loss=0.03929, linear_loss=0.05007]
[2020-05-12 07:28:27.305]  Step 155780  [3.307 sec/step, loss=0.09489, avg_loss=0.08829, mel_loss=0.04245, linear_loss=0.05245]
[2020-05-12 07:28:30.017]  Step 155781  [3.329 sec/step, loss=0.09211, avg_loss=0.08852, mel_loss=0.04110, linear_loss=0.05101]
[2020-05-12 07:28:32.006]  Step 155782  [3.332 sec/step, loss=0.08916, avg_loss=0.08854, mel_loss=0.03893, linear_loss=0.05023]
[2020-05-12 07:28:38.172]  Step 155783  [3.299 sec/step, loss=0.09294, avg_loss=0.08853, mel_loss=0.04229, linear_loss=0.05065]
[2020-05-12 07:28:42.391]  Step 155784  [3.294 sec/step, loss=0.09416, avg_loss=0.08851, mel_loss=0.04214, linear_loss=0.05203]
[2020-05-12 07:28:43.487]  Step 155785  [3.286 sec/step, loss=0.08389, avg_loss=0.08847, mel_loss=0.03564, linear_loss=0.04826]
[2020-05-12 07:28:46.074]  Step 155786  [3.290 sec/step, loss=0.08842, avg_loss=0.08845, mel_loss=0.03881, linear_loss=0.04961]
[2020-05-12 07:28:50.885]  Step 155787  [3.306 sec/step, loss=0.09527, avg_loss=0.08845, mel_loss=0.04289, linear_loss=0.05238]
[2020-05-12 07:28:51.907]  Step 155788  [3.286 sec/step, loss=0.07880, avg_loss=0.08833, mel_loss=0.03402, linear_loss=0.04478]
[2020-05-12 07:28:53.467]  Step 155789  [3.291 sec/step, loss=0.08873, avg_loss=0.08843, mel_loss=0.03866, linear_loss=0.05007]
[2020-05-12 07:28:56.627]  Step 155790  [3.313 sec/step, loss=0.09414, avg_loss=0.08860, mel_loss=0.04195, linear_loss=0.05219]
[2020-05-12 07:28:57.654]  Step 155791  [3.251 sec/step, loss=0.08591, avg_loss=0.08852, mel_loss=0.03709, linear_loss=0.04883]
[2020-05-12 07:28:59.258]  Step 155792  [3.210 sec/step, loss=0.08618, avg_loss=0.08841, mel_loss=0.03775, linear_loss=0.04844]
[2020-05-12 07:29:02.519]  Step 155793  [3.225 sec/step, loss=0.09409, avg_loss=0.08847, mel_loss=0.04189, linear_loss=0.05220]
[2020-05-12 07:29:03.270]  Step 155794  [3.086 sec/step, loss=0.08036, avg_loss=0.08853, mel_loss=0.03425, linear_loss=0.04611]
[2020-05-12 07:29:04.620]  Step 155795  [3.091 sec/step, loss=0.08613, avg_loss=0.08860, mel_loss=0.03724, linear_loss=0.04889]
[2020-05-12 07:29:07.582]  Step 155796  [3.091 sec/step, loss=0.09414, avg_loss=0.08863, mel_loss=0.04198, linear_loss=0.05216]
[2020-05-12 07:29:09.349]  Step 155797  [3.097 sec/step, loss=0.08838, avg_loss=0.08868, mel_loss=0.03840, linear_loss=0.04998]
[2020-05-12 07:29:13.818]  Step 155798  [3.117 sec/step, loss=0.09634, avg_loss=0.08875, mel_loss=0.04328, linear_loss=0.05305]
[2020-05-12 07:29:15.527]  Step 155799  [3.120 sec/step, loss=0.09004, avg_loss=0.08881, mel_loss=0.03912, linear_loss=0.05093]
[2020-05-12 07:29:22.857]  Step 155800  [3.174 sec/step, loss=0.09814, avg_loss=0.08891, mel_loss=0.04484, linear_loss=0.05330]
[2020-05-12 07:29:22.857]  Writing summary at step: 155800
[2020-05-12 07:29:25.290]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155800
[2020-05-12 07:29:26.914]  Saving audio and alignment...
[2020-05-12 07:29:35.077]  Input: 지금부터는 정말 중요한 시간입니다 집중하셔야 돼요~______________
[2020-05-12 07:29:39.109]  Step 155801  [3.193 sec/step, loss=0.09205, avg_loss=0.08893, mel_loss=0.04055, linear_loss=0.05150]
[2020-05-12 07:29:41.358]  Step 155802  [3.199 sec/step, loss=0.08830, avg_loss=0.08893, mel_loss=0.03851, linear_loss=0.04979]
[2020-05-12 07:29:41.886]  Step 155803  [3.169 sec/step, loss=0.07407, avg_loss=0.08871, mel_loss=0.03205, linear_loss=0.04203]
[2020-05-12 07:29:43.640]  Generated 32 batches of size 32 in 1.748 sec
[2020-05-12 07:29:44.176]  Step 155804  [3.172 sec/step, loss=0.09181, avg_loss=0.08873, mel_loss=0.04044, linear_loss=0.05137]
[2020-05-12 07:29:44.930]  Step 155805  [3.166 sec/step, loss=0.07408, avg_loss=0.08864, mel_loss=0.03211, linear_loss=0.04197]
[2020-05-12 07:29:46.248]  Step 155806  [3.126 sec/step, loss=0.08451, avg_loss=0.08853, mel_loss=0.03647, linear_loss=0.04804]
[2020-05-12 07:29:54.629]  Step 155807  [3.172 sec/step, loss=0.09554, avg_loss=0.08853, mel_loss=0.04384, linear_loss=0.05170]
[2020-05-12 07:29:55.525]  Step 155808  [3.165 sec/step, loss=0.07921, avg_loss=0.08847, mel_loss=0.03428, linear_loss=0.04493]
[2020-05-12 07:29:59.239]  Step 155809  [3.179 sec/step, loss=0.09525, avg_loss=0.08851, mel_loss=0.04241, linear_loss=0.05284]
[2020-05-12 07:30:12.396]  Step 155810  [3.268 sec/step, loss=0.08149, avg_loss=0.08838, mel_loss=0.03821, linear_loss=0.04327]
[2020-05-12 07:30:14.342]  Step 155811  [3.222 sec/step, loss=0.08834, avg_loss=0.08830, mel_loss=0.03858, linear_loss=0.04976]
[2020-05-12 07:30:19.877]  Step 155812  [3.246 sec/step, loss=0.09616, avg_loss=0.08832, mel_loss=0.04376, linear_loss=0.05240]
[2020-05-12 07:30:24.776]  Step 155813  [3.267 sec/step, loss=0.09442, avg_loss=0.08836, mel_loss=0.04222, linear_loss=0.05221]
[2020-05-12 07:30:25.997]  Step 155814  [3.269 sec/step, loss=0.08564, avg_loss=0.08839, mel_loss=0.03716, linear_loss=0.04847]
[2020-05-12 07:30:27.815]  Step 155815  [3.209 sec/step, loss=0.08667, avg_loss=0.08830, mel_loss=0.03738, linear_loss=0.04929]
[2020-05-12 07:30:32.024]  Step 155816  [3.204 sec/step, loss=0.09527, avg_loss=0.08830, mel_loss=0.04259, linear_loss=0.05268]
[2020-05-12 07:30:37.814]  Step 155817  [3.254 sec/step, loss=0.09688, avg_loss=0.08855, mel_loss=0.04390, linear_loss=0.05298]
[2020-05-12 07:30:40.698]  Step 155818  [3.195 sec/step, loss=0.09108, avg_loss=0.08850, mel_loss=0.04037, linear_loss=0.05071]
[2020-05-12 07:30:45.145]  Step 155819  [3.205 sec/step, loss=0.09606, avg_loss=0.08855, mel_loss=0.04339, linear_loss=0.05266]
[2020-05-12 07:30:46.818]  Step 155820  [3.213 sec/step, loss=0.08591, avg_loss=0.08864, mel_loss=0.03711, linear_loss=0.04880]
[2020-05-12 07:30:47.786]  Step 155821  [3.156 sec/step, loss=0.08206, avg_loss=0.08849, mel_loss=0.03481, linear_loss=0.04724]
[2020-05-12 07:30:48.608]  Step 155822  [3.153 sec/step, loss=0.07476, avg_loss=0.08847, mel_loss=0.03192, linear_loss=0.04284]
[2020-05-12 07:30:49.460]  Step 155823  [3.022 sec/step, loss=0.07710, avg_loss=0.08847, mel_loss=0.03293, linear_loss=0.04417]
[2020-05-12 07:31:03.612]  Step 155824  [3.147 sec/step, loss=0.07438, avg_loss=0.08835, mel_loss=0.03499, linear_loss=0.03939]
[2020-05-12 07:31:05.572]  Step 155825  [3.078 sec/step, loss=0.08855, avg_loss=0.08829, mel_loss=0.03863, linear_loss=0.04992]
[2020-05-12 07:31:07.846]  Step 155826  [3.059 sec/step, loss=0.08912, avg_loss=0.08825, mel_loss=0.03928, linear_loss=0.04984]
[2020-05-12 07:31:14.539]  Step 155827  [3.091 sec/step, loss=0.09839, avg_loss=0.08830, mel_loss=0.04476, linear_loss=0.05364]
[2020-05-12 07:31:15.103]  Step 155828  [3.089 sec/step, loss=0.07010, avg_loss=0.08822, mel_loss=0.03057, linear_loss=0.03952]
[2020-05-12 07:31:17.653]  Step 155829  [3.103 sec/step, loss=0.09175, avg_loss=0.08833, mel_loss=0.04042, linear_loss=0.05133]
[2020-05-12 07:31:19.753]  Step 155830  [3.107 sec/step, loss=0.08987, avg_loss=0.08834, mel_loss=0.03924, linear_loss=0.05063]
[2020-05-12 07:31:20.736]  Step 155831  [3.092 sec/step, loss=0.07811, avg_loss=0.08821, mel_loss=0.03350, linear_loss=0.04461]
[2020-05-12 07:31:23.045]  Step 155832  [3.103 sec/step, loss=0.09182, avg_loss=0.08829, mel_loss=0.04006, linear_loss=0.05176]
[2020-05-12 07:31:26.030]  Step 155833  [3.113 sec/step, loss=0.09264, avg_loss=0.08832, mel_loss=0.04084, linear_loss=0.05180]
[2020-05-12 07:31:29.621]  Step 155834  [3.135 sec/step, loss=0.09514, avg_loss=0.08843, mel_loss=0.04237, linear_loss=0.05277]
[2020-05-12 07:31:33.394]  Step 155835  [3.142 sec/step, loss=0.09491, avg_loss=0.08844, mel_loss=0.04254, linear_loss=0.05237]
[2020-05-12 07:31:34.901]  Step 155836  [3.121 sec/step, loss=0.08482, avg_loss=0.08836, mel_loss=0.03687, linear_loss=0.04794]
[2020-05-12 07:31:35.204]  Generated 32 batches of size 32 in 1.805 sec
[2020-05-12 07:31:42.201]  Step 155837  [3.148 sec/step, loss=0.09817, avg_loss=0.08838, mel_loss=0.04496, linear_loss=0.05321]
[2020-05-12 07:31:43.332]  Step 155838  [3.139 sec/step, loss=0.08287, avg_loss=0.08835, mel_loss=0.03550, linear_loss=0.04737]
[2020-05-12 07:31:48.914]  Step 155839  [3.172 sec/step, loss=0.09523, avg_loss=0.08840, mel_loss=0.04302, linear_loss=0.05221]
[2020-05-12 07:31:57.864]  Step 155840  [3.231 sec/step, loss=0.09448, avg_loss=0.08840, mel_loss=0.04350, linear_loss=0.05098]
[2020-05-12 07:32:01.267]  Step 155841  [3.257 sec/step, loss=0.09554, avg_loss=0.08862, mel_loss=0.04264, linear_loss=0.05290]
[2020-05-12 07:32:02.603]  Step 155842  [3.242 sec/step, loss=0.08499, avg_loss=0.08856, mel_loss=0.03694, linear_loss=0.04805]
[2020-05-12 07:32:04.261]  Step 155843  [3.207 sec/step, loss=0.08806, avg_loss=0.08850, mel_loss=0.03810, linear_loss=0.04996]
[2020-05-12 07:32:07.793]  Step 155844  [3.223 sec/step, loss=0.09252, avg_loss=0.08856, mel_loss=0.04128, linear_loss=0.05124]
[2020-05-12 07:32:08.921]  Step 155845  [3.192 sec/step, loss=0.08421, avg_loss=0.08844, mel_loss=0.03575, linear_loss=0.04847]
[2020-05-12 07:32:09.853]  Step 155846  [3.131 sec/step, loss=0.07957, avg_loss=0.08825, mel_loss=0.03386, linear_loss=0.04571]
[2020-05-12 07:32:14.605]  Step 155847  [3.169 sec/step, loss=0.09593, avg_loss=0.08840, mel_loss=0.04308, linear_loss=0.05286]
[2020-05-12 07:32:16.592]  Step 155848  [3.162 sec/step, loss=0.08782, avg_loss=0.08837, mel_loss=0.03815, linear_loss=0.04967]
[2020-05-12 07:32:18.725]  Step 155849  [3.175 sec/step, loss=0.09049, avg_loss=0.08856, mel_loss=0.03949, linear_loss=0.05100]
[2020-05-12 07:32:23.093]  Step 155850  [3.205 sec/step, loss=0.09445, avg_loss=0.08865, mel_loss=0.04219, linear_loss=0.05227]
[2020-05-12 07:32:23.093]  Writing summary at step: 155850
[2020-05-12 07:32:25.662]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155850
[2020-05-12 07:32:27.234]  Saving audio and alignment...
[2020-05-12 07:32:32.187]  Input: 얼핏 보면 산골 집에 자상한 아버지와 어머니가~____________________
[2020-05-12 07:32:33.035]  Step 155851  [3.150 sec/step, loss=0.07357, avg_loss=0.08844, mel_loss=0.03138, linear_loss=0.04219]
[2020-05-12 07:32:34.767]  Step 155852  [3.159 sec/step, loss=0.08692, avg_loss=0.08851, mel_loss=0.03781, linear_loss=0.04911]
[2020-05-12 07:32:43.875]  Step 155853  [3.245 sec/step, loss=0.09673, avg_loss=0.08873, mel_loss=0.04471, linear_loss=0.05202]
[2020-05-12 07:32:44.893]  Step 155854  [3.225 sec/step, loss=0.08049, avg_loss=0.08860, mel_loss=0.03478, linear_loss=0.04571]
[2020-05-12 07:32:50.284]  Step 155855  [3.147 sec/step, loss=0.09458, avg_loss=0.08874, mel_loss=0.04259, linear_loss=0.05199]
[2020-05-12 07:32:59.226]  Step 155856  [3.219 sec/step, loss=0.09492, avg_loss=0.08880, mel_loss=0.04355, linear_loss=0.05137]
[2020-05-12 07:33:00.759]  Step 155857  [3.221 sec/step, loss=0.08411, avg_loss=0.08879, mel_loss=0.03619, linear_loss=0.04792]
[2020-05-12 07:33:02.859]  Step 155858  [3.217 sec/step, loss=0.08829, avg_loss=0.08878, mel_loss=0.03844, linear_loss=0.04985]
[2020-05-12 07:33:17.421]  Step 155859  [3.324 sec/step, loss=0.07632, avg_loss=0.08858, mel_loss=0.03591, linear_loss=0.04041]
[2020-05-12 07:33:18.623]  Step 155860  [3.313 sec/step, loss=0.08425, avg_loss=0.08851, mel_loss=0.03641, linear_loss=0.04784]
[2020-05-12 07:33:20.075]  Step 155861  [3.314 sec/step, loss=0.08678, avg_loss=0.08850, mel_loss=0.03793, linear_loss=0.04885]
[2020-05-12 07:33:23.024]  Step 155862  [3.329 sec/step, loss=0.09283, avg_loss=0.08858, mel_loss=0.04096, linear_loss=0.05187]
[2020-05-12 07:33:26.419]  Step 155863  [3.306 sec/step, loss=0.09514, avg_loss=0.08857, mel_loss=0.04229, linear_loss=0.05284]
[2020-05-12 07:33:30.534]  Step 155864  [3.312 sec/step, loss=0.09575, avg_loss=0.08861, mel_loss=0.04288, linear_loss=0.05287]
[2020-05-12 07:33:32.345]  Step 155865  [3.320 sec/step, loss=0.08704, avg_loss=0.08866, mel_loss=0.03768, linear_loss=0.04936]
[2020-05-12 07:33:32.914]  Step 155866  [3.277 sec/step, loss=0.06909, avg_loss=0.08838, mel_loss=0.02970, linear_loss=0.03940]
[2020-05-12 07:33:38.741]  Step 155867  [3.323 sec/step, loss=0.09572, avg_loss=0.08855, mel_loss=0.04359, linear_loss=0.05214]
[2020-05-12 07:33:42.474]  Step 155868  [3.286 sec/step, loss=0.09645, avg_loss=0.08854, mel_loss=0.04311, linear_loss=0.05334]
[2020-05-12 07:33:43.304]  Step 155869  [3.277 sec/step, loss=0.07607, avg_loss=0.08844, mel_loss=0.03263, linear_loss=0.04344]
[2020-05-12 07:33:46.821]  Step 155870  [3.295 sec/step, loss=0.09295, avg_loss=0.08847, mel_loss=0.04132, linear_loss=0.05163]
[2020-05-12 07:33:48.433]  Step 155871  [3.304 sec/step, loss=0.08485, avg_loss=0.08854, mel_loss=0.03677, linear_loss=0.04808]
[2020-05-12 07:33:50.747]  Step 155872  [3.295 sec/step, loss=0.08881, avg_loss=0.08847, mel_loss=0.03914, linear_loss=0.04967]
[2020-05-12 07:33:53.587]  Step 155873  [3.301 sec/step, loss=0.09126, avg_loss=0.08849, mel_loss=0.04049, linear_loss=0.05077]
[2020-05-12 07:33:55.693]  Generated 32 batches of size 32 in 23.343 sec
[2020-05-12 07:34:00.174]  Step 155874  [3.358 sec/step, loss=0.09520, avg_loss=0.08869, mel_loss=0.04339, linear_loss=0.05181]
[2020-05-12 07:34:02.003]  Step 155875  [3.340 sec/step, loss=0.08668, avg_loss=0.08859, mel_loss=0.03783, linear_loss=0.04886]
[2020-05-12 07:34:03.020]  Step 155876  [3.301 sec/step, loss=0.08085, avg_loss=0.08845, mel_loss=0.03462, linear_loss=0.04624]
[2020-05-12 07:34:05.191]  Step 155877  [3.312 sec/step, loss=0.09050, avg_loss=0.08852, mel_loss=0.03967, linear_loss=0.05083]
[2020-05-12 07:34:08.582]  Step 155878  [3.261 sec/step, loss=0.09540, avg_loss=0.08854, mel_loss=0.04226, linear_loss=0.05314]
[2020-05-12 07:34:12.045]  Step 155879  [3.275 sec/step, loss=0.09231, avg_loss=0.08857, mel_loss=0.04111, linear_loss=0.05121]
[2020-05-12 07:34:13.777]  Step 155880  [3.251 sec/step, loss=0.08825, avg_loss=0.08850, mel_loss=0.03845, linear_loss=0.04980]
[2020-05-12 07:34:22.056]  Step 155881  [3.307 sec/step, loss=0.09469, avg_loss=0.08853, mel_loss=0.04344, linear_loss=0.05125]
[2020-05-12 07:34:24.416]  Step 155882  [3.311 sec/step, loss=0.09064, avg_loss=0.08854, mel_loss=0.03977, linear_loss=0.05087]
[2020-05-12 07:34:30.600]  Step 155883  [3.311 sec/step, loss=0.09491, avg_loss=0.08856, mel_loss=0.04321, linear_loss=0.05170]
[2020-05-12 07:34:33.471]  Step 155884  [3.297 sec/step, loss=0.09218, avg_loss=0.08854, mel_loss=0.04063, linear_loss=0.05156]
[2020-05-12 07:34:36.998]  Step 155885  [3.322 sec/step, loss=0.09483, avg_loss=0.08865, mel_loss=0.04229, linear_loss=0.05255]
[2020-05-12 07:34:37.691]  Step 155886  [3.303 sec/step, loss=0.07442, avg_loss=0.08851, mel_loss=0.03203, linear_loss=0.04239]
[2020-05-12 07:34:40.699]  Step 155887  [3.285 sec/step, loss=0.09293, avg_loss=0.08849, mel_loss=0.04106, linear_loss=0.05187]
[2020-05-12 07:34:42.165]  Step 155888  [3.289 sec/step, loss=0.08602, avg_loss=0.08856, mel_loss=0.03727, linear_loss=0.04875]
[2020-05-12 07:34:54.745]  Step 155889  [3.399 sec/step, loss=0.08650, avg_loss=0.08854, mel_loss=0.04080, linear_loss=0.04570]
[2020-05-12 07:34:57.141]  Step 155890  [3.392 sec/step, loss=0.09107, avg_loss=0.08851, mel_loss=0.03991, linear_loss=0.05116]
[2020-05-12 07:34:57.951]  Step 155891  [3.390 sec/step, loss=0.07672, avg_loss=0.08841, mel_loss=0.03261, linear_loss=0.04411]
[2020-05-12 07:35:02.910]  Step 155892  [3.423 sec/step, loss=0.09576, avg_loss=0.08851, mel_loss=0.04316, linear_loss=0.05260]
[2020-05-12 07:35:07.143]  Step 155893  [3.433 sec/step, loss=0.09429, avg_loss=0.08851, mel_loss=0.04212, linear_loss=0.05216]
[2020-05-12 07:35:09.740]  Step 155894  [3.451 sec/step, loss=0.09055, avg_loss=0.08861, mel_loss=0.03974, linear_loss=0.05081]
[2020-05-12 07:35:14.181]  Step 155895  [3.482 sec/step, loss=0.09687, avg_loss=0.08872, mel_loss=0.04349, linear_loss=0.05338]
[2020-05-12 07:35:15.164]  Step 155896  [3.462 sec/step, loss=0.08413, avg_loss=0.08862, mel_loss=0.03618, linear_loss=0.04794]
[2020-05-12 07:35:15.754]  Step 155897  [3.451 sec/step, loss=0.07112, avg_loss=0.08845, mel_loss=0.03155, linear_loss=0.03958]
[2020-05-12 07:35:17.753]  Step 155898  [3.426 sec/step, loss=0.08931, avg_loss=0.08838, mel_loss=0.03921, linear_loss=0.05010]
[2020-05-12 07:35:19.031]  Step 155899  [3.422 sec/step, loss=0.08133, avg_loss=0.08829, mel_loss=0.03518, linear_loss=0.04615]
[2020-05-12 07:35:20.599]  Step 155900  [3.364 sec/step, loss=0.08665, avg_loss=0.08818, mel_loss=0.03767, linear_loss=0.04898]
[2020-05-12 07:35:20.599]  Writing summary at step: 155900
[2020-05-12 07:35:26.248]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155900
[2020-05-12 07:35:27.830]  Saving audio and alignment...
[2020-05-12 07:35:30.209]  Input: 자 처음부터 읽어보죠~_______
[2020-05-12 07:35:31.685]  Generated 32 batches of size 32 in 15.926 sec
[2020-05-12 07:35:33.968]  Step 155901  [3.361 sec/step, loss=0.09567, avg_loss=0.08821, mel_loss=0.04255, linear_loss=0.05312]
[2020-05-12 07:35:35.287]  Step 155902  [3.352 sec/step, loss=0.08649, avg_loss=0.08819, mel_loss=0.03741, linear_loss=0.04909]
[2020-05-12 07:35:37.303]  Step 155903  [3.367 sec/step, loss=0.09106, avg_loss=0.08836, mel_loss=0.03977, linear_loss=0.05129]
[2020-05-12 07:35:44.362]  Step 155904  [3.415 sec/step, loss=0.09714, avg_loss=0.08842, mel_loss=0.04429, linear_loss=0.05285]
[2020-05-12 07:35:52.084]  Step 155905  [3.484 sec/step, loss=0.09685, avg_loss=0.08865, mel_loss=0.04429, linear_loss=0.05256]
[2020-05-12 07:35:55.708]  Step 155906  [3.507 sec/step, loss=0.09492, avg_loss=0.08875, mel_loss=0.04224, linear_loss=0.05268]
[2020-05-12 07:35:58.830]  Step 155907  [3.455 sec/step, loss=0.09336, avg_loss=0.08873, mel_loss=0.04153, linear_loss=0.05183]
[2020-05-12 07:36:02.563]  Step 155908  [3.483 sec/step, loss=0.09498, avg_loss=0.08889, mel_loss=0.04238, linear_loss=0.05259]
[2020-05-12 07:36:04.621]  Step 155909  [3.467 sec/step, loss=0.08767, avg_loss=0.08881, mel_loss=0.03829, linear_loss=0.04938]
[2020-05-12 07:36:06.500]  Step 155910  [3.354 sec/step, loss=0.08650, avg_loss=0.08886, mel_loss=0.03738, linear_loss=0.04913]
[2020-05-12 07:36:09.208]  Step 155911  [3.361 sec/step, loss=0.08937, avg_loss=0.08887, mel_loss=0.03931, linear_loss=0.05006]
[2020-05-12 07:36:10.587]  Step 155912  [3.320 sec/step, loss=0.08306, avg_loss=0.08874, mel_loss=0.03607, linear_loss=0.04698]
[2020-05-12 07:36:11.583]  Step 155913  [3.281 sec/step, loss=0.07965, avg_loss=0.08859, mel_loss=0.03406, linear_loss=0.04559]
[2020-05-12 07:36:16.986]  Step 155914  [3.323 sec/step, loss=0.09642, avg_loss=0.08870, mel_loss=0.04352, linear_loss=0.05291]
[2020-05-12 07:36:21.802]  Step 155915  [3.353 sec/step, loss=0.09522, avg_loss=0.08878, mel_loss=0.04277, linear_loss=0.05245]
[2020-05-12 07:36:30.702]  Step 155916  [3.399 sec/step, loss=0.09532, avg_loss=0.08879, mel_loss=0.04381, linear_loss=0.05150]
[2020-05-12 07:36:33.559]  Step 155917  [3.370 sec/step, loss=0.09171, avg_loss=0.08873, mel_loss=0.04077, linear_loss=0.05094]
[2020-05-12 07:36:36.684]  Step 155918  [3.373 sec/step, loss=0.09513, avg_loss=0.08877, mel_loss=0.04214, linear_loss=0.05299]
[2020-05-12 07:36:38.311]  Step 155919  [3.344 sec/step, loss=0.08415, avg_loss=0.08865, mel_loss=0.03646, linear_loss=0.04768]
[2020-05-12 07:36:42.374]  Step 155920  [3.368 sec/step, loss=0.09442, avg_loss=0.08874, mel_loss=0.04201, linear_loss=0.05241]
[2020-05-12 07:36:49.206]  Step 155921  [3.427 sec/step, loss=0.09652, avg_loss=0.08888, mel_loss=0.04415, linear_loss=0.05237]
[2020-05-12 07:36:51.401]  Step 155922  [3.441 sec/step, loss=0.08874, avg_loss=0.08902, mel_loss=0.03921, linear_loss=0.04953]
[2020-05-12 07:36:52.533]  Step 155923  [3.443 sec/step, loss=0.08395, avg_loss=0.08909, mel_loss=0.03587, linear_loss=0.04808]
[2020-05-12 07:36:58.302]  Step 155924  [3.360 sec/step, loss=0.09677, avg_loss=0.08932, mel_loss=0.04406, linear_loss=0.05271]
[2020-05-12 07:36:59.208]  Step 155925  [3.349 sec/step, loss=0.07675, avg_loss=0.08920, mel_loss=0.03302, linear_loss=0.04373]
[2020-05-12 07:37:02.601]  Step 155926  [3.360 sec/step, loss=0.09348, avg_loss=0.08924, mel_loss=0.04163, linear_loss=0.05185]
[2020-05-12 07:37:04.241]  Step 155927  [3.310 sec/step, loss=0.08865, avg_loss=0.08914, mel_loss=0.03884, linear_loss=0.04981]
[2020-05-12 07:37:04.818]  Step 155928  [3.310 sec/step, loss=0.07068, avg_loss=0.08915, mel_loss=0.03118, linear_loss=0.03950]
[2020-05-12 07:37:06.239]  Step 155929  [3.299 sec/step, loss=0.08555, avg_loss=0.08909, mel_loss=0.03714, linear_loss=0.04840]
[2020-05-12 07:37:08.585]  Step 155930  [3.301 sec/step, loss=0.09050, avg_loss=0.08910, mel_loss=0.04003, linear_loss=0.05047]
[2020-05-12 07:37:09.350]  Step 155931  [3.299 sec/step, loss=0.07939, avg_loss=0.08911, mel_loss=0.03363, linear_loss=0.04577]
[2020-05-12 07:37:11.137]  Step 155932  [3.294 sec/step, loss=0.08789, avg_loss=0.08907, mel_loss=0.03791, linear_loss=0.04998]
[2020-05-12 07:37:12.429]  Step 155933  [3.277 sec/step, loss=0.08236, avg_loss=0.08897, mel_loss=0.03545, linear_loss=0.04691]
[2020-05-12 07:37:12.627]  Generated 32 batches of size 32 in 8.380 sec
[2020-05-12 07:37:27.093]  Step 155934  [3.387 sec/step, loss=0.07494, avg_loss=0.08876, mel_loss=0.03516, linear_loss=0.03978]
[2020-05-12 07:37:31.618]  Step 155935  [3.395 sec/step, loss=0.09614, avg_loss=0.08878, mel_loss=0.04330, linear_loss=0.05284]
[2020-05-12 07:37:32.349]  Step 155936  [3.387 sec/step, loss=0.07625, avg_loss=0.08869, mel_loss=0.03283, linear_loss=0.04341]
[2020-05-12 07:37:37.031]  Step 155937  [3.361 sec/step, loss=0.09723, avg_loss=0.08868, mel_loss=0.04380, linear_loss=0.05343]
[2020-05-12 07:37:39.063]  Step 155938  [3.370 sec/step, loss=0.08881, avg_loss=0.08874, mel_loss=0.03903, linear_loss=0.04978]
[2020-05-12 07:37:42.708]  Step 155939  [3.351 sec/step, loss=0.09303, avg_loss=0.08872, mel_loss=0.04157, linear_loss=0.05147]
[2020-05-12 07:37:47.934]  Step 155940  [3.313 sec/step, loss=0.09686, avg_loss=0.08874, mel_loss=0.04377, linear_loss=0.05309]
[2020-05-12 07:37:49.547]  Step 155941  [3.296 sec/step, loss=0.08866, avg_loss=0.08867, mel_loss=0.03861, linear_loss=0.05005]
[2020-05-12 07:37:52.152]  Step 155942  [3.308 sec/step, loss=0.09103, avg_loss=0.08873, mel_loss=0.04007, linear_loss=0.05096]
[2020-05-12 07:37:56.392]  Step 155943  [3.334 sec/step, loss=0.09346, avg_loss=0.08879, mel_loss=0.04182, linear_loss=0.05165]
[2020-05-12 07:38:04.204]  Step 155944  [3.377 sec/step, loss=0.09491, avg_loss=0.08881, mel_loss=0.04321, linear_loss=0.05171]
[2020-05-12 07:38:09.396]  Step 155945  [3.417 sec/step, loss=0.09528, avg_loss=0.08892, mel_loss=0.04299, linear_loss=0.05229]
[2020-05-12 07:38:12.667]  Step 155946  [3.441 sec/step, loss=0.09390, avg_loss=0.08907, mel_loss=0.04163, linear_loss=0.05228]
[2020-05-12 07:38:13.697]  Step 155947  [3.404 sec/step, loss=0.08021, avg_loss=0.08891, mel_loss=0.03455, linear_loss=0.04566]
[2020-05-12 07:38:15.475]  Step 155948  [3.402 sec/step, loss=0.08766, avg_loss=0.08891, mel_loss=0.03807, linear_loss=0.04958]
[2020-05-12 07:38:18.347]  Step 155949  [3.409 sec/step, loss=0.09029, avg_loss=0.08891, mel_loss=0.03994, linear_loss=0.05034]
[2020-05-12 07:38:19.694]  Step 155950  [3.379 sec/step, loss=0.08411, avg_loss=0.08880, mel_loss=0.03615, linear_loss=0.04796]
[2020-05-12 07:38:19.694]  Writing summary at step: 155950
[2020-05-12 07:38:20.789]  Saving checkpoint to: ./logs-tacotron/model.ckpt-155950
[2020-05-12 07:38:22.426]  Saving audio and alignment...
[2020-05-12 07:38:26.508]  Input: 너무 익숙해서 당연하다고 여게된 일들~_____________
[2020-05-12 07:38:27.325]  Step 155951  [3.378 sec/step, loss=0.07695, avg_loss=0.08884, mel_loss=0.03271, linear_loss=0.04424]
[2020-05-12 07:38:27.889]  Step 155952  [3.367 sec/step, loss=0.06859, avg_loss=0.08865, mel_loss=0.03022, linear_loss=0.03837]
[2020-05-12 07:38:29.039]  Step 155953  [3.287 sec/step, loss=0.08225, avg_loss=0.08851, mel_loss=0.03563, linear_loss=0.04663]
[2020-05-12 07:38:32.556]  Step 155954  [3.312 sec/step, loss=0.09287, avg_loss=0.08863, mel_loss=0.04152, linear_loss=0.05135]
[2020-05-12 07:38:33.565]  Step 155955  [3.268 sec/step, loss=0.08046, avg_loss=0.08849, mel_loss=0.03411, linear_loss=0.04635]
[2020-05-12 07:38:34.402]  Step 155956  [3.187 sec/step, loss=0.07650, avg_loss=0.08831, mel_loss=0.03291, linear_loss=0.04359]
[2020-05-12 07:38:37.351]  Step 155957  [3.201 sec/step, loss=0.09375, avg_loss=0.08840, mel_loss=0.04157, linear_loss=0.05218]
[2020-05-12 07:38:48.658]  Step 155958  [3.293 sec/step, loss=0.09058, avg_loss=0.08843, mel_loss=0.04233, linear_loss=0.04825]
[2020-05-12 07:38:50.091]  Step 155959  [3.162 sec/step, loss=0.08617, avg_loss=0.08852, mel_loss=0.03725, linear_loss=0.04892]
[2020-05-12 07:38:55.950]  Step 155960  [3.209 sec/step, loss=0.09655, avg_loss=0.08865, mel_loss=0.04383, linear_loss=0.05271]
[2020-05-12 07:39:04.299]  Step 155961  [3.278 sec/step, loss=0.09519, avg_loss=0.08873, mel_loss=0.04377, linear_loss=0.05142]
[2020-05-12 07:39:06.422]  Step 155962  [3.269 sec/step, loss=0.08968, avg_loss=0.08870, mel_loss=0.03927, linear_loss=0.05041]
[2020-05-12 07:39:08.339]  Step 155963  [3.255 sec/step, loss=0.08692, avg_loss=0.08862, mel_loss=0.03763, linear_loss=0.04929]
[2020-05-12 07:39:12.124]  Step 155964  [3.251 sec/step, loss=0.09611, avg_loss=0.08862, mel_loss=0.04278, linear_loss=0.05333]
[2020-05-12 07:39:13.608]  Step 155965  [3.248 sec/step, loss=0.08547, avg_loss=0.08860, mel_loss=0.03680, linear_loss=0.04867]
[2020-05-12 07:39:15.842]  Step 155966  [3.265 sec/step, loss=0.08884, avg_loss=0.08880, mel_loss=0.03876, linear_loss=0.05007]
[2020-05-12 07:39:56.745]  Generated 32 batches of size 32 in 79.388 sec
[2020-05-12 07:39:59.862]  Step 155967  [3.647 sec/step, loss=0.09021, avg_loss=0.08875, mel_loss=0.03977, linear_loss=0.05044]
[2020-05-12 07:40:08.750]  Step 155968  [3.698 sec/step, loss=0.09488, avg_loss=0.08873, mel_loss=0.04380, linear_loss=0.05108]
[2020-05-12 07:40:12.210]  Step 155969  [3.725 sec/step, loss=0.09274, avg_loss=0.08890, mel_loss=0.04116, linear_loss=0.05157]
[2020-05-12 07:40:13.859]  Step 155970  [3.706 sec/step, loss=0.08525, avg_loss=0.08882, mel_loss=0.03714, linear_loss=0.04811]
[2020-05-12 07:40:21.291]  Step 155971  [3.764 sec/step, loss=0.09636, avg_loss=0.08894, mel_loss=0.04410, linear_loss=0.05226]
[2020-05-12 07:40:22.522]  Step 155972  [3.753 sec/step, loss=0.08344, avg_loss=0.08888, mel_loss=0.03599, linear_loss=0.04745]
[2020-05-12 07:40:23.828]  Step 155973  [3.738 sec/step, loss=0.08573, avg_loss=0.08883, mel_loss=0.03726, linear_loss=0.04847]
[2020-05-12 07:40:24.944]  Step 155974  [3.683 sec/step, loss=0.08063, avg_loss=0.08868, mel_loss=0.03458, linear_loss=0.04605]
[2020-05-12 07:40:25.844]  Step 155975  [3.674 sec/step, loss=0.07635, avg_loss=0.08858, mel_loss=0.03255, linear_loss=0.04380]
[2020-05-12 07:40:27.873]  Step 155976  [3.684 sec/step, loss=0.09052, avg_loss=0.08868, mel_loss=0.03944, linear_loss=0.05108]
[2020-05-12 07:40:33.103]  Step 155977  [3.715 sec/step, loss=0.09470, avg_loss=0.08872, mel_loss=0.04262, linear_loss=0.05207]
[2020-05-12 07:40:33.864]  Step 155978  [3.688 sec/step, loss=0.07950, avg_loss=0.08856, mel_loss=0.03403, linear_loss=0.04547]
[2020-05-12 07:40:34.693]  Step 155979  [3.662 sec/step, loss=0.07442, avg_loss=0.08838, mel_loss=0.03187, linear_loss=0.04255]
[2020-05-12 07:40:36.773]  Step 155980  [3.665 sec/step, loss=0.09074, avg_loss=0.08840, mel_loss=0.04001, linear_loss=0.05072]
[2020-05-12 07:40:40.430]  Step 155981  [3.619 sec/step, loss=0.09652, avg_loss=0.08842, mel_loss=0.04326, linear_loss=0.05326]
[2020-05-12 07:40:42.909]  Step 155982  [3.620 sec/step, loss=0.09031, avg_loss=0.08842, mel_loss=0.03945, linear_loss=0.05085]
[2020-05-12 07:40:47.103]  Step 155983  [3.601 sec/step, loss=0.09406, avg_loss=0.08841, mel_loss=0.04200, linear_loss=0.05206]
[2020-05-12 07:40:50.537]  Step 155984  [3.606 sec/step, loss=0.09427, avg_loss=0.08843, mel_loss=0.04174, linear_loss=0.05253]
[2020-05-12 07:40:52.915]  Step 155985  [3.595 sec/step, loss=0.09053, avg_loss=0.08839, mel_loss=0.03959, linear_loss=0.05093]
[2020-05-12 07:40:57.064]  Step 155986  [3.629 sec/step, loss=0.09516, avg_loss=0.08860, mel_loss=0.04247, linear_loss=0.05269]
[2020-05-12 07:41:01.760]  Step 155987  [3.646 sec/step, loss=0.09463, avg_loss=0.08861, mel_loss=0.04240, linear_loss=0.05223]
[2020-05-12 07:41:02.743]  Step 155988  [3.641 sec/step, loss=0.08118, avg_loss=0.08856, mel_loss=0.03474, linear_loss=0.04644]
[2020-05-12 07:41:05.801]  Step 155989  [3.546 sec/step, loss=0.09468, avg_loss=0.08865, mel_loss=0.04207, linear_loss=0.05261]
[2020-05-12 07:41:11.514]  Step 155990  [3.579 sec/step, loss=0.09593, avg_loss=0.08869, mel_loss=0.04350, linear_loss=0.05242]
[2020-05-12 07:41:14.487]  Step 155991  [3.601 sec/step, loss=0.09324, avg_loss=0.08886, mel_loss=0.04130, linear_loss=0.05194]
[2020-05-12 07:41:16.223]  Step 155992  [3.569 sec/step, loss=0.08518, avg_loss=0.08875, mel_loss=0.03700, linear_loss=0.04818]
[2020-05-12 07:41:24.531]  Generated 32 batches of size 32 in 18.724 sec
[2020-05-12 07:41:30.798]  Step 155993  [3.672 sec/step, loss=0.07676, avg_loss=0.08858, mel_loss=0.03610, linear_loss=0.04067]
[2020-05-12 07:41:32.618]  Step 155994  [3.664 sec/step, loss=0.08899, avg_loss=0.08856, mel_loss=0.03844, linear_loss=0.05055]
[2020-05-12 07:41:34.563]  Step 155995  [3.639 sec/step, loss=0.08765, avg_loss=0.08847, mel_loss=0.03807, linear_loss=0.04958]
[2020-05-12 07:41:41.473]  Step 155996  [3.699 sec/step, loss=0.09599, avg_loss=0.08859, mel_loss=0.04364, linear_loss=0.05234]
[2020-05-12 07:41:42.913]  Step 155997  [3.707 sec/step, loss=0.08587, avg_loss=0.08874, mel_loss=0.03728, linear_loss=0.04859]
[2020-05-12 07:41:43.478]  Step 155998  [3.693 sec/step, loss=0.06925, avg_loss=0.08854, mel_loss=0.03012, linear_loss=0.03913]
[2020-05-12 07:41:44.913]  Step 155999  [3.694 sec/step, loss=0.08446, avg_loss=0.08857, mel_loss=0.03673, linear_loss=0.04773]
[2020-05-12 07:41:46.719]  Step 156000  [3.697 sec/step, loss=0.08796, avg_loss=0.08858, mel_loss=0.03793, linear_loss=0.05003]
[2020-05-12 07:41:46.720]  Writing summary at step: 156000
[2020-05-12 07:41:51.547]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156000
[2020-05-12 07:41:53.171]  Saving audio and alignment...
[2020-05-12 07:41:59.348]  Input: 박수 주시죠 박수 주시면 감사하겠습니다 알아서 이렇게 표현을~_________
[2020-05-12 07:42:11.273]  Step 156001  [3.778 sec/step, loss=0.09021, avg_loss=0.08853, mel_loss=0.04248, linear_loss=0.04773]
[2020-05-12 07:42:14.119]  Step 156002  [3.794 sec/step, loss=0.09121, avg_loss=0.08857, mel_loss=0.04033, linear_loss=0.05089]
[2020-05-12 07:42:22.987]  Step 156003  [3.862 sec/step, loss=0.09671, avg_loss=0.08863, mel_loss=0.04455, linear_loss=0.05216]
[2020-05-12 07:42:26.028]  Step 156004  [3.822 sec/step, loss=0.09120, avg_loss=0.08857, mel_loss=0.04029, linear_loss=0.05090]
[2020-05-12 07:42:27.664]  Step 156005  [3.761 sec/step, loss=0.08689, avg_loss=0.08847, mel_loss=0.03785, linear_loss=0.04904]
[2020-05-12 07:42:35.202]  Step 156006  [3.800 sec/step, loss=0.09487, avg_loss=0.08847, mel_loss=0.04321, linear_loss=0.05166]
[2020-05-12 07:42:36.018]  Step 156007  [3.777 sec/step, loss=0.07600, avg_loss=0.08830, mel_loss=0.03240, linear_loss=0.04360]
[2020-05-12 07:42:37.407]  Step 156008  [3.754 sec/step, loss=0.08519, avg_loss=0.08820, mel_loss=0.03679, linear_loss=0.04840]
[2020-05-12 07:42:39.884]  Step 156009  [3.758 sec/step, loss=0.09059, avg_loss=0.08823, mel_loss=0.03973, linear_loss=0.05086]
[2020-05-12 07:42:46.722]  Step 156010  [3.808 sec/step, loss=0.09705, avg_loss=0.08833, mel_loss=0.04420, linear_loss=0.05286]
[2020-05-12 07:42:52.481]  Step 156011  [3.838 sec/step, loss=0.09612, avg_loss=0.08840, mel_loss=0.04376, linear_loss=0.05236]
[2020-05-12 07:42:56.161]  Step 156012  [3.861 sec/step, loss=0.09282, avg_loss=0.08850, mel_loss=0.04137, linear_loss=0.05145]
[2020-05-12 07:42:58.346]  Step 156013  [3.873 sec/step, loss=0.09031, avg_loss=0.08861, mel_loss=0.03966, linear_loss=0.05065]
[2020-05-12 07:43:02.518]  Step 156014  [3.861 sec/step, loss=0.09609, avg_loss=0.08860, mel_loss=0.04308, linear_loss=0.05302]
[2020-05-12 07:43:05.655]  Step 156015  [3.844 sec/step, loss=0.09423, avg_loss=0.08859, mel_loss=0.04184, linear_loss=0.05239]
[2020-05-12 07:43:06.217]  Step 156016  [3.760 sec/step, loss=0.07103, avg_loss=0.08835, mel_loss=0.03130, linear_loss=0.03973]
[2020-05-12 07:43:07.131]  Step 156017  [3.741 sec/step, loss=0.07999, avg_loss=0.08823, mel_loss=0.03388, linear_loss=0.04611]
[2020-05-12 07:43:09.038]  Step 156018  [3.729 sec/step, loss=0.08937, avg_loss=0.08817, mel_loss=0.03938, linear_loss=0.04999]
[2020-05-12 07:43:12.680]  Step 156019  [3.749 sec/step, loss=0.09259, avg_loss=0.08826, mel_loss=0.04122, linear_loss=0.05137]
[2020-05-12 07:43:13.916]  Step 156020  [3.721 sec/step, loss=0.08175, avg_loss=0.08813, mel_loss=0.03509, linear_loss=0.04666]
[2020-05-12 07:43:19.653]  Step 156021  [3.710 sec/step, loss=0.09319, avg_loss=0.08810, mel_loss=0.04189, linear_loss=0.05131]
[2020-05-12 07:43:21.749]  Step 156022  [3.709 sec/step, loss=0.08838, avg_loss=0.08810, mel_loss=0.03836, linear_loss=0.05003]
[2020-05-12 07:43:22.638]  Step 156023  [3.706 sec/step, loss=0.07074, avg_loss=0.08796, mel_loss=0.03040, linear_loss=0.04034]
[2020-05-12 07:43:23.721]  Step 156024  [3.660 sec/step, loss=0.08088, avg_loss=0.08780, mel_loss=0.03476, linear_loss=0.04613]
[2020-05-12 07:43:25.030]  Generated 32 batches of size 32 in 12.345 sec
[2020-05-12 07:43:25.512]  Step 156025  [3.668 sec/step, loss=0.08871, avg_loss=0.08792, mel_loss=0.03836, linear_loss=0.05035]
[2020-05-12 07:43:28.286]  Step 156026  [3.662 sec/step, loss=0.09063, avg_loss=0.08790, mel_loss=0.03992, linear_loss=0.05072]
[2020-05-12 07:43:29.591]  Step 156027  [3.659 sec/step, loss=0.08190, avg_loss=0.08783, mel_loss=0.03536, linear_loss=0.04654]
[2020-05-12 07:43:31.961]  Step 156028  [3.677 sec/step, loss=0.08966, avg_loss=0.08802, mel_loss=0.03950, linear_loss=0.05016]
[2020-05-12 07:43:33.356]  Step 156029  [3.676 sec/step, loss=0.08237, avg_loss=0.08799, mel_loss=0.03544, linear_loss=0.04692]
[2020-05-12 07:43:34.980]  Step 156030  [3.669 sec/step, loss=0.08718, avg_loss=0.08795, mel_loss=0.03762, linear_loss=0.04956]
[2020-05-12 07:43:49.433]  Step 156031  [3.806 sec/step, loss=0.07395, avg_loss=0.08790, mel_loss=0.03460, linear_loss=0.03935]
[2020-05-12 07:43:55.121]  Step 156032  [3.845 sec/step, loss=0.09532, avg_loss=0.08797, mel_loss=0.04290, linear_loss=0.05242]
[2020-05-12 07:43:56.179]  Step 156033  [3.843 sec/step, loss=0.07972, avg_loss=0.08795, mel_loss=0.03425, linear_loss=0.04547]
[2020-05-12 07:43:57.112]  Step 156034  [3.706 sec/step, loss=0.07968, avg_loss=0.08799, mel_loss=0.03435, linear_loss=0.04533]
[2020-05-12 07:44:00.396]  Step 156035  [3.693 sec/step, loss=0.09443, avg_loss=0.08798, mel_loss=0.04212, linear_loss=0.05231]
[2020-05-12 07:44:02.752]  Step 156036  [3.709 sec/step, loss=0.08968, avg_loss=0.08811, mel_loss=0.03960, linear_loss=0.05008]
[2020-05-12 07:44:08.125]  Step 156037  [3.716 sec/step, loss=0.09618, avg_loss=0.08810, mel_loss=0.04366, linear_loss=0.05252]
[2020-05-12 07:44:10.969]  Step 156038  [3.724 sec/step, loss=0.09009, avg_loss=0.08811, mel_loss=0.03987, linear_loss=0.05022]
[2020-05-12 07:44:12.755]  Step 156039  [3.706 sec/step, loss=0.08626, avg_loss=0.08805, mel_loss=0.03752, linear_loss=0.04874]
[2020-05-12 07:44:14.765]  Step 156040  [3.674 sec/step, loss=0.08959, avg_loss=0.08797, mel_loss=0.03907, linear_loss=0.05053]
[2020-05-12 07:44:18.101]  Step 156041  [3.691 sec/step, loss=0.09565, avg_loss=0.08804, mel_loss=0.04240, linear_loss=0.05324]
[2020-05-12 07:44:18.622]  Step 156042  [3.670 sec/step, loss=0.07260, avg_loss=0.08786, mel_loss=0.03112, linear_loss=0.04148]
[2020-05-12 07:44:22.728]  Step 156043  [3.669 sec/step, loss=0.09506, avg_loss=0.08787, mel_loss=0.04239, linear_loss=0.05267]
[2020-05-12 07:44:24.229]  Step 156044  [3.606 sec/step, loss=0.08694, avg_loss=0.08779, mel_loss=0.03754, linear_loss=0.04940]
[2020-05-12 07:44:27.923]  Step 156045  [3.591 sec/step, loss=0.09676, avg_loss=0.08781, mel_loss=0.04325, linear_loss=0.05351]
[2020-05-12 07:44:32.510]  Step 156046  [3.604 sec/step, loss=0.09641, avg_loss=0.08783, mel_loss=0.04314, linear_loss=0.05326]
[2020-05-12 07:44:38.796]  Step 156047  [3.656 sec/step, loss=0.09463, avg_loss=0.08798, mel_loss=0.04314, linear_loss=0.05148]
[2020-05-12 07:44:39.568]  Step 156048  [3.646 sec/step, loss=0.07873, avg_loss=0.08789, mel_loss=0.03369, linear_loss=0.04504]
[2020-05-12 07:44:40.542]  Step 156049  [3.627 sec/step, loss=0.07652, avg_loss=0.08775, mel_loss=0.03232, linear_loss=0.04420]
[2020-05-12 07:44:41.696]  Step 156050  [3.625 sec/step, loss=0.08050, avg_loss=0.08772, mel_loss=0.03417, linear_loss=0.04632]
[2020-05-12 07:44:41.696]  Writing summary at step: 156050
[2020-05-12 07:44:44.278]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156050
[2020-05-12 07:44:45.819]  Saving audio and alignment...
[2020-05-12 07:44:48.001]  Generated 32 batches of size 32 in 1.569 sec
[2020-05-12 07:44:49.918]  Input: 나비처럼 날아서 벌처럼 쏴라~________________
[2020-05-12 07:44:53.434]  Step 156051  [3.652 sec/step, loss=0.09508, avg_loss=0.08790, mel_loss=0.04209, linear_loss=0.05299]
[2020-05-12 07:44:58.001]  Step 156052  [3.692 sec/step, loss=0.09427, avg_loss=0.08815, mel_loss=0.04231, linear_loss=0.05196]
[2020-05-12 07:44:58.791]  Step 156053  [3.689 sec/step, loss=0.07387, avg_loss=0.08807, mel_loss=0.03197, linear_loss=0.04190]
[2020-05-12 07:45:00.699]  Step 156054  [3.673 sec/step, loss=0.08498, avg_loss=0.08799, mel_loss=0.03698, linear_loss=0.04800]
[2020-05-12 07:45:01.930]  Step 156055  [3.675 sec/step, loss=0.08201, avg_loss=0.08801, mel_loss=0.03543, linear_loss=0.04658]
[2020-05-12 07:45:09.860]  Step 156056  [3.746 sec/step, loss=0.09668, avg_loss=0.08821, mel_loss=0.04457, linear_loss=0.05212]
[2020-05-12 07:45:12.787]  Step 156057  [3.746 sec/step, loss=0.09420, avg_loss=0.08821, mel_loss=0.04181, linear_loss=0.05240]
[2020-05-12 07:45:20.349]  Step 156058  [3.708 sec/step, loss=0.09787, avg_loss=0.08829, mel_loss=0.04475, linear_loss=0.05312]
[2020-05-12 07:45:26.115]  Step 156059  [3.751 sec/step, loss=0.09549, avg_loss=0.08838, mel_loss=0.04321, linear_loss=0.05228]
[2020-05-12 07:45:27.775]  Step 156060  [3.709 sec/step, loss=0.08817, avg_loss=0.08829, mel_loss=0.03833, linear_loss=0.04984]
[2020-05-12 07:45:32.567]  Step 156061  [3.674 sec/step, loss=0.09504, avg_loss=0.08829, mel_loss=0.04264, linear_loss=0.05240]
[2020-05-12 07:45:35.458]  Step 156062  [3.682 sec/step, loss=0.09156, avg_loss=0.08831, mel_loss=0.04066, linear_loss=0.05090]
[2020-05-12 07:45:38.081]  Step 156063  [3.689 sec/step, loss=0.09136, avg_loss=0.08836, mel_loss=0.04052, linear_loss=0.05084]
[2020-05-12 07:45:44.903]  Step 156064  [3.719 sec/step, loss=0.09522, avg_loss=0.08835, mel_loss=0.04339, linear_loss=0.05184]
[2020-05-12 07:45:53.859]  Step 156065  [3.794 sec/step, loss=0.09529, avg_loss=0.08845, mel_loss=0.04384, linear_loss=0.05145]
[2020-05-12 07:46:08.265]  Step 156066  [3.915 sec/step, loss=0.07705, avg_loss=0.08833, mel_loss=0.03625, linear_loss=0.04080]
[2020-05-12 07:46:09.297]  Step 156067  [3.486 sec/step, loss=0.08024, avg_loss=0.08823, mel_loss=0.03426, linear_loss=0.04598]
[2020-05-12 07:46:12.984]  Step 156068  [3.434 sec/step, loss=0.09523, avg_loss=0.08823, mel_loss=0.04251, linear_loss=0.05273]
[2020-05-12 07:46:14.001]  Step 156069  [3.409 sec/step, loss=0.07725, avg_loss=0.08808, mel_loss=0.03286, linear_loss=0.04439]
[2020-05-12 07:46:17.455]  Step 156070  [3.427 sec/step, loss=0.09289, avg_loss=0.08815, mel_loss=0.04137, linear_loss=0.05153]
[2020-05-12 07:46:19.255]  Step 156071  [3.371 sec/step, loss=0.08704, avg_loss=0.08806, mel_loss=0.03793, linear_loss=0.04911]
[2020-05-12 07:46:20.883]  Step 156072  [3.375 sec/step, loss=0.08668, avg_loss=0.08809, mel_loss=0.03761, linear_loss=0.04906]
[2020-05-12 07:46:26.018]  Step 156073  [3.413 sec/step, loss=0.09678, avg_loss=0.08820, mel_loss=0.04404, linear_loss=0.05274]
[2020-05-12 07:46:26.873]  Step 156074  [3.411 sec/step, loss=0.07564, avg_loss=0.08815, mel_loss=0.03223, linear_loss=0.04341]
[2020-05-12 07:46:29.342]  Step 156075  [3.426 sec/step, loss=0.09118, avg_loss=0.08830, mel_loss=0.03979, linear_loss=0.05139]
[2020-05-12 07:46:30.105]  Step 156076  [3.414 sec/step, loss=0.07831, avg_loss=0.08818, mel_loss=0.03322, linear_loss=0.04509]
[2020-05-12 07:46:34.016]  Step 156077  [3.400 sec/step, loss=0.09448, avg_loss=0.08818, mel_loss=0.04214, linear_loss=0.05234]
[2020-05-12 07:46:35.455]  Step 156078  [3.407 sec/step, loss=0.08401, avg_loss=0.08822, mel_loss=0.03663, linear_loss=0.04738]
[2020-05-12 07:46:37.870]  Step 156079  [3.423 sec/step, loss=0.09146, avg_loss=0.08839, mel_loss=0.04023, linear_loss=0.05123]
[2020-05-12 07:46:39.006]  Step 156080  [3.414 sec/step, loss=0.07971, avg_loss=0.08828, mel_loss=0.03407, linear_loss=0.04564]
[2020-05-12 07:46:42.138]  Step 156081  [3.408 sec/step, loss=0.09395, avg_loss=0.08826, mel_loss=0.04162, linear_loss=0.05232]
[2020-05-12 07:46:43.962]  Generated 32 batches of size 32 in 1.818 sec
[2020-05-12 07:46:44.253]  Step 156082  [3.405 sec/step, loss=0.08903, avg_loss=0.08824, mel_loss=0.03887, linear_loss=0.05016]
[2020-05-12 07:46:44.815]  Step 156083  [3.368 sec/step, loss=0.06843, avg_loss=0.08799, mel_loss=0.02983, linear_loss=0.03859]
[2020-05-12 07:46:46.809]  Step 156084  [3.354 sec/step, loss=0.08727, avg_loss=0.08792, mel_loss=0.03780, linear_loss=0.04946]
[2020-05-12 07:46:50.040]  Step 156085  [3.362 sec/step, loss=0.09342, avg_loss=0.08795, mel_loss=0.04158, linear_loss=0.05183]
[2020-05-12 07:46:57.498]  Step 156086  [3.396 sec/step, loss=0.09622, avg_loss=0.08796, mel_loss=0.04392, linear_loss=0.05230]
[2020-05-12 07:47:01.743]  Step 156087  [3.391 sec/step, loss=0.09436, avg_loss=0.08795, mel_loss=0.04238, linear_loss=0.05198]
[2020-05-12 07:47:02.945]  Step 156088  [3.393 sec/step, loss=0.08360, avg_loss=0.08798, mel_loss=0.03632, linear_loss=0.04727]
[2020-05-12 07:47:04.324]  Step 156089  [3.376 sec/step, loss=0.08388, avg_loss=0.08787, mel_loss=0.03616, linear_loss=0.04772]
[2020-05-12 07:47:06.472]  Step 156090  [3.341 sec/step, loss=0.09071, avg_loss=0.08782, mel_loss=0.03981, linear_loss=0.05091]
[2020-05-12 07:47:07.783]  Step 156091  [3.324 sec/step, loss=0.08502, avg_loss=0.08774, mel_loss=0.03687, linear_loss=0.04815]
[2020-05-12 07:47:08.812]  Step 156092  [3.317 sec/step, loss=0.08016, avg_loss=0.08769, mel_loss=0.03435, linear_loss=0.04580]
[2020-05-12 07:47:12.126]  Step 156093  [3.205 sec/step, loss=0.09386, avg_loss=0.08786, mel_loss=0.04187, linear_loss=0.05198]
[2020-05-12 07:47:17.784]  Step 156094  [3.243 sec/step, loss=0.09458, avg_loss=0.08791, mel_loss=0.04280, linear_loss=0.05177]
[2020-05-12 07:47:20.978]  Step 156095  [3.255 sec/step, loss=0.09383, avg_loss=0.08797, mel_loss=0.04170, linear_loss=0.05213]
[2020-05-12 07:47:21.645]  Step 156096  [3.193 sec/step, loss=0.07296, avg_loss=0.08774, mel_loss=0.03174, linear_loss=0.04122]
[2020-05-12 07:47:22.493]  Step 156097  [3.187 sec/step, loss=0.07563, avg_loss=0.08764, mel_loss=0.03233, linear_loss=0.04329]
[2020-05-12 07:47:23.829]  Step 156098  [3.195 sec/step, loss=0.08499, avg_loss=0.08780, mel_loss=0.03660, linear_loss=0.04839]
[2020-05-12 07:47:25.598]  Step 156099  [3.198 sec/step, loss=0.08757, avg_loss=0.08783, mel_loss=0.03807, linear_loss=0.04951]
[2020-05-12 07:47:27.734]  Step 156100  [3.201 sec/step, loss=0.09037, avg_loss=0.08785, mel_loss=0.03985, linear_loss=0.05052]
[2020-05-12 07:47:27.734]  Writing summary at step: 156100
[2020-05-12 07:47:32.968]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156100
[2020-05-12 07:47:34.508]  Saving audio and alignment...
[2020-05-12 07:47:45.849]  Input: 으음 이럴 때요 뭐 어떤 어떤 점이 장점이고 내가 특히 뭘 잘 한다고 하더라 라는 나열보다~_______________________________________________
[2020-05-12 07:47:48.309]  Step 156101  [3.107 sec/step, loss=0.09082, avg_loss=0.08786, mel_loss=0.03984, linear_loss=0.05099]
[2020-05-12 07:47:51.010]  Step 156102  [3.105 sec/step, loss=0.09299, avg_loss=0.08788, mel_loss=0.04102, linear_loss=0.05197]
[2020-05-12 07:47:55.173]  Step 156103  [3.058 sec/step, loss=0.09310, avg_loss=0.08784, mel_loss=0.04174, linear_loss=0.05137]
[2020-05-12 07:47:58.137]  Step 156104  [3.057 sec/step, loss=0.09330, avg_loss=0.08786, mel_loss=0.04133, linear_loss=0.05197]
[2020-05-12 07:47:59.364]  Step 156105  [3.053 sec/step, loss=0.08223, avg_loss=0.08782, mel_loss=0.03522, linear_loss=0.04701]
[2020-05-12 07:48:03.447]  Step 156106  [3.019 sec/step, loss=0.09517, avg_loss=0.08782, mel_loss=0.04235, linear_loss=0.05282]
[2020-05-12 07:48:05.715]  Step 156107  [3.033 sec/step, loss=0.08812, avg_loss=0.08794, mel_loss=0.03877, linear_loss=0.04936]
[2020-05-12 07:48:20.333]  Step 156108  [3.166 sec/step, loss=0.07381, avg_loss=0.08783, mel_loss=0.03477, linear_loss=0.03904]
[2020-05-12 07:48:21.337]  Step 156109  [3.151 sec/step, loss=0.07816, avg_loss=0.08770, mel_loss=0.03335, linear_loss=0.04481]
[2020-05-12 07:48:23.612]  Step 156110  [3.105 sec/step, loss=0.08943, avg_loss=0.08763, mel_loss=0.03913, linear_loss=0.05030]
[2020-05-12 07:48:28.755]  Step 156111  [3.099 sec/step, loss=0.09709, avg_loss=0.08764, mel_loss=0.04362, linear_loss=0.05347]
[2020-05-12 07:48:32.751]  Step 156112  [3.102 sec/step, loss=0.09540, avg_loss=0.08766, mel_loss=0.04250, linear_loss=0.05290]
[2020-05-12 07:48:34.375]  Step 156113  [3.097 sec/step, loss=0.08651, avg_loss=0.08762, mel_loss=0.03789, linear_loss=0.04862]
[2020-05-12 07:48:41.119]  Step 156114  [3.122 sec/step, loss=0.09730, avg_loss=0.08764, mel_loss=0.04441, linear_loss=0.05289]
[2020-05-12 07:48:43.019]  Step 156115  [3.110 sec/step, loss=0.08929, avg_loss=0.08759, mel_loss=0.03860, linear_loss=0.05068]
[2020-05-12 07:48:50.695]  Step 156116  [3.181 sec/step, loss=0.09729, avg_loss=0.08785, mel_loss=0.04451, linear_loss=0.05278]
[2020-05-12 07:48:52.198]  Step 156117  [3.187 sec/step, loss=0.08624, avg_loss=0.08791, mel_loss=0.03725, linear_loss=0.04899]
[2020-05-12 07:48:53.344]  Step 156118  [3.179 sec/step, loss=0.08127, avg_loss=0.08783, mel_loss=0.03502, linear_loss=0.04625]
[2020-05-12 07:48:56.956]  Step 156119  [3.179 sec/step, loss=0.09166, avg_loss=0.08782, mel_loss=0.04074, linear_loss=0.05093]
[2020-05-12 07:48:57.533]  Step 156120  [3.173 sec/step, loss=0.07100, avg_loss=0.08771, mel_loss=0.03127, linear_loss=0.03973]
[2020-05-12 07:49:05.051]  Generated 32 batches of size 32 in 36.289 sec
[2020-05-12 07:49:10.818]  Step 156121  [3.248 sec/step, loss=0.09637, avg_loss=0.08775, mel_loss=0.04371, linear_loss=0.05265]
[2020-05-12 07:49:17.212]  Step 156122  [3.291 sec/step, loss=0.09400, avg_loss=0.08780, mel_loss=0.04266, linear_loss=0.05133]
[2020-05-12 07:49:30.370]  Step 156123  [3.414 sec/step, loss=0.08161, avg_loss=0.08791, mel_loss=0.03835, linear_loss=0.04326]
[2020-05-12 07:49:37.855]  Step 156124  [3.478 sec/step, loss=0.09547, avg_loss=0.08806, mel_loss=0.04365, linear_loss=0.05182]
[2020-05-12 07:49:40.015]  Step 156125  [3.481 sec/step, loss=0.08934, avg_loss=0.08806, mel_loss=0.03896, linear_loss=0.05038]
[2020-05-12 07:49:44.373]  Step 156126  [3.497 sec/step, loss=0.09452, avg_loss=0.08810, mel_loss=0.04228, linear_loss=0.05224]
[2020-05-12 07:49:45.701]  Step 156127  [3.497 sec/step, loss=0.08433, avg_loss=0.08813, mel_loss=0.03624, linear_loss=0.04808]
[2020-05-12 07:49:47.472]  Step 156128  [3.491 sec/step, loss=0.08864, avg_loss=0.08812, mel_loss=0.03830, linear_loss=0.05034]
[2020-05-12 07:49:50.866]  Step 156129  [3.511 sec/step, loss=0.09452, avg_loss=0.08824, mel_loss=0.04182, linear_loss=0.05270]
[2020-05-12 07:49:54.845]  Step 156130  [3.535 sec/step, loss=0.08918, avg_loss=0.08826, mel_loss=0.03930, linear_loss=0.04988]
[2020-05-12 07:49:56.544]  Step 156131  [3.407 sec/step, loss=0.08342, avg_loss=0.08835, mel_loss=0.03553, linear_loss=0.04788]
[2020-05-12 07:49:59.485]  Step 156132  [3.380 sec/step, loss=0.08796, avg_loss=0.08828, mel_loss=0.03844, linear_loss=0.04952]
[2020-05-12 07:50:04.048]  Step 156133  [3.415 sec/step, loss=0.09277, avg_loss=0.08841, mel_loss=0.04122, linear_loss=0.05155]
[2020-05-12 07:50:13.288]  Step 156134  [3.498 sec/step, loss=0.09427, avg_loss=0.08855, mel_loss=0.04312, linear_loss=0.05115]
[2020-05-12 07:50:13.850]  Step 156135  [3.471 sec/step, loss=0.07080, avg_loss=0.08832, mel_loss=0.03125, linear_loss=0.03955]
[2020-05-12 07:50:18.483]  Step 156136  [3.494 sec/step, loss=0.09442, avg_loss=0.08837, mel_loss=0.04220, linear_loss=0.05221]
[2020-05-12 07:50:22.159]  Step 156137  [3.477 sec/step, loss=0.09331, avg_loss=0.08834, mel_loss=0.04166, linear_loss=0.05164]
[2020-05-12 07:50:25.200]  Step 156138  [3.479 sec/step, loss=0.09157, avg_loss=0.08835, mel_loss=0.04029, linear_loss=0.05129]
[2020-05-12 07:50:30.438]  Step 156139  [3.513 sec/step, loss=0.09508, avg_loss=0.08844, mel_loss=0.04294, linear_loss=0.05215]
[2020-05-12 07:50:31.691]  Step 156140  [3.506 sec/step, loss=0.08446, avg_loss=0.08839, mel_loss=0.03656, linear_loss=0.04790]
[2020-05-12 07:50:32.468]  Step 156141  [3.480 sec/step, loss=0.08060, avg_loss=0.08824, mel_loss=0.03446, linear_loss=0.04614]
[2020-05-12 07:50:33.945]  Step 156142  [3.490 sec/step, loss=0.08286, avg_loss=0.08834, mel_loss=0.03602, linear_loss=0.04684]
[2020-05-12 07:50:34.839]  Step 156143  [3.457 sec/step, loss=0.07968, avg_loss=0.08819, mel_loss=0.03375, linear_loss=0.04593]
[2020-05-12 07:50:38.709]  Step 156144  [3.481 sec/step, loss=0.09466, avg_loss=0.08826, mel_loss=0.04213, linear_loss=0.05252]
[2020-05-12 07:50:40.461]  Step 156145  [3.462 sec/step, loss=0.08837, avg_loss=0.08818, mel_loss=0.03848, linear_loss=0.04989]
[2020-05-12 07:50:42.917]  Step 156146  [3.440 sec/step, loss=0.08856, avg_loss=0.08810, mel_loss=0.03871, linear_loss=0.04985]
[2020-05-12 07:50:43.798]  Step 156147  [3.386 sec/step, loss=0.07280, avg_loss=0.08788, mel_loss=0.03101, linear_loss=0.04179]
[2020-05-12 07:50:44.815]  Step 156148  [3.389 sec/step, loss=0.08076, avg_loss=0.08790, mel_loss=0.03471, linear_loss=0.04605]
[2020-05-12 07:50:47.708]  Step 156149  [3.408 sec/step, loss=0.09238, avg_loss=0.08806, mel_loss=0.04099, linear_loss=0.05139]
[2020-05-12 07:50:49.709]  Step 156150  [3.417 sec/step, loss=0.08937, avg_loss=0.08815, mel_loss=0.03878, linear_loss=0.05060]
[2020-05-12 07:50:49.710]  Writing summary at step: 156150
[2020-05-12 07:50:52.172]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156150
[2020-05-12 07:50:53.749]  Saving audio and alignment...
[2020-05-12 07:50:56.840]  Input: 부용꽃 스물일곱송이~________________
[2020-05-12 07:50:58.906]  Generated 32 batches of size 32 in 24.062 sec
[2020-05-12 07:51:01.587]  Step 156151  [3.429 sec/step, loss=0.08990, avg_loss=0.08810, mel_loss=0.03954, linear_loss=0.05036]
[2020-05-12 07:51:02.615]  Step 156152  [3.393 sec/step, loss=0.08061, avg_loss=0.08796, mel_loss=0.03459, linear_loss=0.04602]
[2020-05-12 07:51:04.233]  Step 156153  [3.402 sec/step, loss=0.08713, avg_loss=0.08810, mel_loss=0.03783, linear_loss=0.04930]
[2020-05-12 07:51:06.258]  Step 156154  [3.403 sec/step, loss=0.08562, avg_loss=0.08810, mel_loss=0.03738, linear_loss=0.04824]
[2020-05-12 07:51:14.479]  Step 156155  [3.473 sec/step, loss=0.09508, avg_loss=0.08823, mel_loss=0.04372, linear_loss=0.05136]
[2020-05-12 07:51:16.675]  Step 156156  [3.415 sec/step, loss=0.08915, avg_loss=0.08816, mel_loss=0.03953, linear_loss=0.04962]
[2020-05-12 07:51:17.239]  Step 156157  [3.392 sec/step, loss=0.06960, avg_loss=0.08791, mel_loss=0.03055, linear_loss=0.03906]
[2020-05-12 07:51:19.399]  Step 156158  [3.338 sec/step, loss=0.08693, avg_loss=0.08780, mel_loss=0.03830, linear_loss=0.04864]
[2020-05-12 07:51:20.590]  Step 156159  [3.292 sec/step, loss=0.08174, avg_loss=0.08766, mel_loss=0.03518, linear_loss=0.04655]
[2020-05-12 07:51:24.872]  Step 156160  [3.318 sec/step, loss=0.09301, avg_loss=0.08771, mel_loss=0.04153, linear_loss=0.05149]
[2020-05-12 07:51:31.976]  Step 156161  [3.341 sec/step, loss=0.09725, avg_loss=0.08773, mel_loss=0.04450, linear_loss=0.05275]
[2020-05-12 07:51:35.140]  Step 156162  [3.344 sec/step, loss=0.09350, avg_loss=0.08775, mel_loss=0.04128, linear_loss=0.05222]
[2020-05-12 07:51:40.857]  Step 156163  [3.375 sec/step, loss=0.09646, avg_loss=0.08780, mel_loss=0.04361, linear_loss=0.05286]
[2020-05-12 07:51:42.339]  Step 156164  [3.322 sec/step, loss=0.08665, avg_loss=0.08772, mel_loss=0.03772, linear_loss=0.04893]
[2020-05-12 07:51:45.829]  Step 156165  [3.267 sec/step, loss=0.09249, avg_loss=0.08769, mel_loss=0.04126, linear_loss=0.05123]
[2020-05-12 07:51:48.840]  Step 156166  [3.153 sec/step, loss=0.09480, avg_loss=0.08787, mel_loss=0.04166, linear_loss=0.05314]
[2020-05-12 07:51:50.516]  Step 156167  [3.159 sec/step, loss=0.08629, avg_loss=0.08793, mel_loss=0.03750, linear_loss=0.04879]
[2020-05-12 07:51:54.145]  Step 156168  [3.159 sec/step, loss=0.09666, avg_loss=0.08794, mel_loss=0.04313, linear_loss=0.05353]
[2020-05-12 07:51:54.968]  Step 156169  [3.157 sec/step, loss=0.07499, avg_loss=0.08792, mel_loss=0.03206, linear_loss=0.04293]
[2020-05-12 07:51:59.904]  Step 156170  [3.172 sec/step, loss=0.09466, avg_loss=0.08794, mel_loss=0.04251, linear_loss=0.05215]
[2020-05-12 07:52:00.731]  Step 156171  [3.162 sec/step, loss=0.06949, avg_loss=0.08776, mel_loss=0.03029, linear_loss=0.03920]
[2020-05-12 07:52:07.463]  Step 156172  [3.213 sec/step, loss=0.09614, avg_loss=0.08786, mel_loss=0.04380, linear_loss=0.05234]
[2020-05-12 07:52:09.944]  Step 156173  [3.187 sec/step, loss=0.08890, avg_loss=0.08778, mel_loss=0.03909, linear_loss=0.04981]
[2020-05-12 07:52:12.893]  Step 156174  [3.207 sec/step, loss=0.09163, avg_loss=0.08794, mel_loss=0.04076, linear_loss=0.05087]
[2020-05-12 07:52:14.737]  Step 156175  [3.201 sec/step, loss=0.08825, avg_loss=0.08791, mel_loss=0.03817, linear_loss=0.05008]
[2020-05-12 07:52:15.869]  Step 156176  [3.205 sec/step, loss=0.08154, avg_loss=0.08794, mel_loss=0.03489, linear_loss=0.04664]
[2020-05-12 07:52:18.685]  Generated 32 batches of size 32 in 8.735 sec
[2020-05-12 07:52:19.664]  Step 156177  [3.204 sec/step, loss=0.09484, avg_loss=0.08795, mel_loss=0.04250, linear_loss=0.05234]
[2020-05-12 07:52:20.718]  Step 156178  [3.200 sec/step, loss=0.07593, avg_loss=0.08786, mel_loss=0.03250, linear_loss=0.04343]
[2020-05-12 07:52:26.199]  Step 156179  [3.231 sec/step, loss=0.09657, avg_loss=0.08792, mel_loss=0.04378, linear_loss=0.05279]
[2020-05-12 07:52:39.389]  Step 156180  [3.351 sec/step, loss=0.08101, avg_loss=0.08793, mel_loss=0.03785, linear_loss=0.04316]
[2020-05-12 07:52:40.784]  Step 156181  [3.334 sec/step, loss=0.08518, avg_loss=0.08784, mel_loss=0.03672, linear_loss=0.04845]
[2020-05-12 07:52:45.297]  Step 156182  [3.358 sec/step, loss=0.09612, avg_loss=0.08791, mel_loss=0.04338, linear_loss=0.05275]
[2020-05-12 07:52:47.294]  Step 156183  [3.372 sec/step, loss=0.08748, avg_loss=0.08810, mel_loss=0.03824, linear_loss=0.04924]
[2020-05-12 07:52:56.193]  Step 156184  [3.441 sec/step, loss=0.09489, avg_loss=0.08818, mel_loss=0.04366, linear_loss=0.05123]
[2020-05-12 07:52:59.481]  Step 156185  [3.442 sec/step, loss=0.09497, avg_loss=0.08819, mel_loss=0.04223, linear_loss=0.05273]
[2020-05-12 07:53:01.935]  Step 156186  [3.392 sec/step, loss=0.09094, avg_loss=0.08814, mel_loss=0.03970, linear_loss=0.05123]
[2020-05-12 07:53:05.725]  Step 156187  [3.387 sec/step, loss=0.09578, avg_loss=0.08816, mel_loss=0.04266, linear_loss=0.05312]
[2020-05-12 07:53:07.356]  Step 156188  [3.391 sec/step, loss=0.08613, avg_loss=0.08818, mel_loss=0.03759, linear_loss=0.04853]
[2020-05-12 07:53:09.515]  Step 156189  [3.399 sec/step, loss=0.08990, avg_loss=0.08824, mel_loss=0.03933, linear_loss=0.05057]
[2020-05-12 07:53:12.422]  Step 156190  [3.407 sec/step, loss=0.09068, avg_loss=0.08824, mel_loss=0.04006, linear_loss=0.05062]
[2020-05-12 07:53:13.396]  Step 156191  [3.403 sec/step, loss=0.08040, avg_loss=0.08819, mel_loss=0.03441, linear_loss=0.04599]
[2020-05-12 07:53:15.638]  Step 156192  [3.416 sec/step, loss=0.08903, avg_loss=0.08828, mel_loss=0.03887, linear_loss=0.05016]
[2020-05-12 07:53:16.971]  Step 156193  [3.396 sec/step, loss=0.08306, avg_loss=0.08818, mel_loss=0.03588, linear_loss=0.04718]
[2020-05-12 07:53:20.471]  Step 156194  [3.374 sec/step, loss=0.09448, avg_loss=0.08817, mel_loss=0.04214, linear_loss=0.05234]
[2020-05-12 07:53:21.849]  Step 156195  [3.356 sec/step, loss=0.08432, avg_loss=0.08808, mel_loss=0.03658, linear_loss=0.04774]
[2020-05-12 07:53:26.829]  Step 156196  [3.399 sec/step, loss=0.09580, avg_loss=0.08831, mel_loss=0.04315, linear_loss=0.05265]
[2020-05-12 07:53:31.357]  Step 156197  [3.436 sec/step, loss=0.09662, avg_loss=0.08852, mel_loss=0.04331, linear_loss=0.05331]
[2020-05-12 07:53:32.213]  Step 156198  [3.431 sec/step, loss=0.07586, avg_loss=0.08843, mel_loss=0.03219, linear_loss=0.04367]
[2020-05-12 07:53:33.056]  Step 156199  [3.422 sec/step, loss=0.07154, avg_loss=0.08827, mel_loss=0.03072, linear_loss=0.04083]
[2020-05-12 07:53:39.139]  Step 156200  [3.461 sec/step, loss=0.09518, avg_loss=0.08831, mel_loss=0.04318, linear_loss=0.05201]
[2020-05-12 07:53:39.139]  Writing summary at step: 156200
[2020-05-12 07:53:40.750]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156200
[2020-05-12 07:53:42.336]  Saving audio and alignment...
[2020-05-12 07:53:52.601]  Input: 여러분은 지금 현대자동차가 주최하는 현 뮤직 아틀리에 콘서트 와 함께하고 계십니다 이렇게 언급해 주면~_______________________
[2020-05-12 07:53:54.456]  Step 156201  [3.455 sec/step, loss=0.08585, avg_loss=0.08826, mel_loss=0.03735, linear_loss=0.04849]
[2020-05-12 07:54:06.237]  Step 156202  [3.546 sec/step, loss=0.09181, avg_loss=0.08825, mel_loss=0.04309, linear_loss=0.04872]
[2020-05-12 07:54:08.003]  Step 156203  [3.522 sec/step, loss=0.08860, avg_loss=0.08821, mel_loss=0.03838, linear_loss=0.05022]
[2020-05-12 07:54:11.238]  Step 156204  [3.525 sec/step, loss=0.09292, avg_loss=0.08820, mel_loss=0.04135, linear_loss=0.05157]
[2020-05-12 07:54:11.324]  Generated 32 batches of size 32 in 3.315 sec
[2020-05-12 07:54:17.399]  Step 156205  [3.574 sec/step, loss=0.09613, avg_loss=0.08834, mel_loss=0.04359, linear_loss=0.05254]
[2020-05-12 07:54:20.092]  Step 156206  [3.560 sec/step, loss=0.09110, avg_loss=0.08830, mel_loss=0.04008, linear_loss=0.05102]
[2020-05-12 07:54:21.011]  Step 156207  [3.547 sec/step, loss=0.07766, avg_loss=0.08820, mel_loss=0.03281, linear_loss=0.04485]
[2020-05-12 07:54:22.054]  Step 156208  [3.411 sec/step, loss=0.08258, avg_loss=0.08829, mel_loss=0.03526, linear_loss=0.04732]
[2020-05-12 07:54:22.617]  Step 156209  [3.407 sec/step, loss=0.06797, avg_loss=0.08818, mel_loss=0.02965, linear_loss=0.03832]
[2020-05-12 07:54:26.934]  Step 156210  [3.427 sec/step, loss=0.09433, avg_loss=0.08823, mel_loss=0.04226, linear_loss=0.05206]
[2020-05-12 07:54:28.088]  Step 156211  [3.387 sec/step, loss=0.08339, avg_loss=0.08810, mel_loss=0.03578, linear_loss=0.04761]
[2020-05-12 07:54:31.543]  Step 156212  [3.382 sec/step, loss=0.09322, avg_loss=0.08807, mel_loss=0.04162, linear_loss=0.05161]
[2020-05-12 07:54:32.873]  Step 156213  [3.379 sec/step, loss=0.08474, avg_loss=0.08806, mel_loss=0.03659, linear_loss=0.04815]
[2020-05-12 07:54:36.274]  Step 156214  [3.345 sec/step, loss=0.09336, avg_loss=0.08802, mel_loss=0.04136, linear_loss=0.05200]
[2020-05-12 07:54:39.349]  Step 156215  [3.357 sec/step, loss=0.09342, avg_loss=0.08806, mel_loss=0.04132, linear_loss=0.05210]
[2020-05-12 07:54:42.874]  Step 156216  [3.316 sec/step, loss=0.09134, avg_loss=0.08800, mel_loss=0.04061, linear_loss=0.05073]
[2020-05-12 07:54:45.821]  Step 156217  [3.330 sec/step, loss=0.09147, avg_loss=0.08805, mel_loss=0.04044, linear_loss=0.05103]
[2020-05-12 07:54:47.022]  Step 156218  [3.331 sec/step, loss=0.08473, avg_loss=0.08809, mel_loss=0.03654, linear_loss=0.04819]
[2020-05-12 07:54:47.575]  Step 156219  [3.300 sec/step, loss=0.06868, avg_loss=0.08786, mel_loss=0.03042, linear_loss=0.03827]
[2020-05-12 07:54:48.626]  Step 156220  [3.305 sec/step, loss=0.07800, avg_loss=0.08793, mel_loss=0.03361, linear_loss=0.04439]
[2020-05-12 07:54:49.746]  Step 156221  [3.183 sec/step, loss=0.08459, avg_loss=0.08781, mel_loss=0.03583, linear_loss=0.04876]
[2020-05-12 07:54:51.989]  Step 156222  [3.142 sec/step, loss=0.08922, avg_loss=0.08776, mel_loss=0.03925, linear_loss=0.04998]
[2020-05-12 07:54:53.944]  Step 156223  [3.030 sec/step, loss=0.08853, avg_loss=0.08783, mel_loss=0.03830, linear_loss=0.05023]
[2020-05-12 07:54:59.110]  Step 156224  [3.006 sec/step, loss=0.09256, avg_loss=0.08780, mel_loss=0.04176, linear_loss=0.05080]
[2020-05-12 07:55:13.432]  Step 156225  [3.128 sec/step, loss=0.07499, avg_loss=0.08766, mel_loss=0.03517, linear_loss=0.03982]
[2020-05-12 07:55:15.463]  Step 156226  [3.105 sec/step, loss=0.08811, avg_loss=0.08759, mel_loss=0.03840, linear_loss=0.04971]
[2020-05-12 07:55:19.819]  Step 156227  [3.135 sec/step, loss=0.09579, avg_loss=0.08771, mel_loss=0.04298, linear_loss=0.05282]
[2020-05-12 07:55:21.940]  Step 156228  [3.138 sec/step, loss=0.09105, avg_loss=0.08773, mel_loss=0.03977, linear_loss=0.05128]
[2020-05-12 07:55:22.749]  Step 156229  [3.113 sec/step, loss=0.07510, avg_loss=0.08754, mel_loss=0.03197, linear_loss=0.04312]
[2020-05-12 07:55:29.645]  Step 156230  [3.142 sec/step, loss=0.09559, avg_loss=0.08760, mel_loss=0.04356, linear_loss=0.05203]
[2020-05-12 07:55:33.334]  Step 156231  [3.162 sec/step, loss=0.09441, avg_loss=0.08771, mel_loss=0.04193, linear_loss=0.05248]
[2020-05-12 07:55:37.914]  Step 156232  [3.178 sec/step, loss=0.09452, avg_loss=0.08778, mel_loss=0.04238, linear_loss=0.05214]
[2020-05-12 07:55:40.364]  Step 156233  [3.157 sec/step, loss=0.09079, avg_loss=0.08776, mel_loss=0.03991, linear_loss=0.05088]
[2020-05-12 07:55:42.150]  Step 156234  [3.082 sec/step, loss=0.08639, avg_loss=0.08768, mel_loss=0.03734, linear_loss=0.04905]
[2020-05-12 07:55:42.998]  Step 156235  [3.085 sec/step, loss=0.07450, avg_loss=0.08772, mel_loss=0.03177, linear_loss=0.04274]
[2020-05-12 07:55:44.665]  Generated 32 batches of size 32 in 1.662 sec
[2020-05-12 07:55:50.787]  Step 156236  [3.117 sec/step, loss=0.09670, avg_loss=0.08774, mel_loss=0.04408, linear_loss=0.05262]
[2020-05-12 07:55:54.848]  Step 156237  [3.121 sec/step, loss=0.09556, avg_loss=0.08776, mel_loss=0.04267, linear_loss=0.05289]
[2020-05-12 07:55:56.508]  Step 156238  [3.107 sec/step, loss=0.08794, avg_loss=0.08772, mel_loss=0.03798, linear_loss=0.04996]
[2020-05-12 07:55:59.155]  Step 156239  [3.081 sec/step, loss=0.09192, avg_loss=0.08769, mel_loss=0.04056, linear_loss=0.05136]
[2020-05-12 07:56:00.096]  Step 156240  [3.078 sec/step, loss=0.07748, avg_loss=0.08762, mel_loss=0.03290, linear_loss=0.04458]
[2020-05-12 07:56:01.572]  Step 156241  [3.085 sec/step, loss=0.08588, avg_loss=0.08768, mel_loss=0.03734, linear_loss=0.04854]
[2020-05-12 07:56:10.500]  Step 156242  [3.159 sec/step, loss=0.09570, avg_loss=0.08780, mel_loss=0.04414, linear_loss=0.05156]
[2020-05-12 07:56:12.142]  Step 156243  [3.167 sec/step, loss=0.08604, avg_loss=0.08787, mel_loss=0.03736, linear_loss=0.04868]
[2020-05-12 07:56:17.886]  Step 156244  [3.186 sec/step, loss=0.09604, avg_loss=0.08788, mel_loss=0.04345, linear_loss=0.05259]
[2020-05-12 07:56:18.657]  Step 156245  [3.176 sec/step, loss=0.07501, avg_loss=0.08775, mel_loss=0.03235, linear_loss=0.04266]
[2020-05-12 07:56:20.117]  Step 156246  [3.166 sec/step, loss=0.08340, avg_loss=0.08770, mel_loss=0.03631, linear_loss=0.04709]
[2020-05-12 07:56:21.926]  Step 156247  [3.175 sec/step, loss=0.08615, avg_loss=0.08783, mel_loss=0.03722, linear_loss=0.04893]
[2020-05-12 07:56:29.434]  Step 156248  [3.240 sec/step, loss=0.09770, avg_loss=0.08800, mel_loss=0.04490, linear_loss=0.05280]
[2020-05-12 07:56:33.026]  Step 156249  [3.247 sec/step, loss=0.09250, avg_loss=0.08800, mel_loss=0.04096, linear_loss=0.05154]
[2020-05-12 07:56:37.226]  Step 156250  [3.269 sec/step, loss=0.09516, avg_loss=0.08806, mel_loss=0.04260, linear_loss=0.05256]
[2020-05-12 07:56:37.226]  Writing summary at step: 156250
[2020-05-12 07:56:38.595]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156250
[2020-05-12 07:56:40.172]  Saving audio and alignment...
[2020-05-12 07:56:43.241]  Input: 그리고 정말로 놀라운 사실은요~_______
[2020-05-12 07:56:46.956]  Step 156251  [3.259 sec/step, loss=0.09497, avg_loss=0.08811, mel_loss=0.04236, linear_loss=0.05261]
[2020-05-12 07:56:48.883]  Step 156252  [3.268 sec/step, loss=0.08948, avg_loss=0.08820, mel_loss=0.03909, linear_loss=0.05039]
[2020-05-12 07:56:55.394]  Step 156253  [3.317 sec/step, loss=0.09578, avg_loss=0.08828, mel_loss=0.04363, linear_loss=0.05215]
[2020-05-12 07:56:56.410]  Step 156254  [3.307 sec/step, loss=0.07800, avg_loss=0.08821, mel_loss=0.03315, linear_loss=0.04484]
[2020-05-12 07:57:02.121]  Step 156255  [3.281 sec/step, loss=0.09624, avg_loss=0.08822, mel_loss=0.04349, linear_loss=0.05275]
[2020-05-12 07:57:04.331]  Step 156256  [3.282 sec/step, loss=0.08916, avg_loss=0.08822, mel_loss=0.03897, linear_loss=0.05018]
[2020-05-12 07:57:05.145]  Step 156257  [3.284 sec/step, loss=0.06946, avg_loss=0.08822, mel_loss=0.03005, linear_loss=0.03940]
[2020-05-12 07:57:09.345]  Step 156258  [3.304 sec/step, loss=0.09335, avg_loss=0.08828, mel_loss=0.04154, linear_loss=0.05181]
[2020-05-12 07:57:11.606]  Step 156259  [3.315 sec/step, loss=0.08853, avg_loss=0.08835, mel_loss=0.03908, linear_loss=0.04946]
[2020-05-12 07:57:14.558]  Step 156260  [3.302 sec/step, loss=0.09268, avg_loss=0.08835, mel_loss=0.04102, linear_loss=0.05166]
[2020-05-12 07:57:18.093]  Step 156261  [3.266 sec/step, loss=0.09426, avg_loss=0.08832, mel_loss=0.04224, linear_loss=0.05202]
[2020-05-12 07:57:19.369]  Step 156262  [3.247 sec/step, loss=0.08122, avg_loss=0.08819, mel_loss=0.03512, linear_loss=0.04610]
[2020-05-12 07:57:24.098]  Step 156263  [3.237 sec/step, loss=0.09690, avg_loss=0.08820, mel_loss=0.04347, linear_loss=0.05344]
[2020-05-12 07:57:25.126]  Step 156264  [3.233 sec/step, loss=0.07791, avg_loss=0.08811, mel_loss=0.03345, linear_loss=0.04446]
[2020-05-12 07:57:26.726]  Step 156265  [3.214 sec/step, loss=0.08533, avg_loss=0.08804, mel_loss=0.03706, linear_loss=0.04827]
[2020-05-12 07:57:27.511]  Step 156266  [3.192 sec/step, loss=0.07834, avg_loss=0.08788, mel_loss=0.03319, linear_loss=0.04515]
[2020-05-12 07:57:28.494]  Generated 32 batches of size 32 in 1.762 sec
[2020-05-12 07:57:32.891]  Step 156267  [3.229 sec/step, loss=0.09550, avg_loss=0.08797, mel_loss=0.04316, linear_loss=0.05234]
[2020-05-12 07:57:36.077]  Step 156268  [3.224 sec/step, loss=0.09492, avg_loss=0.08795, mel_loss=0.04205, linear_loss=0.05286]
[2020-05-12 07:57:50.849]  Step 156269  [3.364 sec/step, loss=0.07655, avg_loss=0.08797, mel_loss=0.03624, linear_loss=0.04031]
[2020-05-12 07:57:53.302]  Step 156270  [3.339 sec/step, loss=0.09150, avg_loss=0.08793, mel_loss=0.03992, linear_loss=0.05158]
[2020-05-12 07:57:54.380]  Step 156271  [3.341 sec/step, loss=0.08139, avg_loss=0.08805, mel_loss=0.03495, linear_loss=0.04644]
[2020-05-12 07:57:56.965]  Step 156272  [3.300 sec/step, loss=0.08782, avg_loss=0.08797, mel_loss=0.03836, linear_loss=0.04946]
[2020-05-12 07:58:05.993]  Step 156273  [3.365 sec/step, loss=0.09523, avg_loss=0.08803, mel_loss=0.04373, linear_loss=0.05150]
[2020-05-12 07:58:08.809]  Step 156274  [3.364 sec/step, loss=0.09128, avg_loss=0.08803, mel_loss=0.04037, linear_loss=0.05091]
[2020-05-12 07:58:11.043]  Step 156275  [3.368 sec/step, loss=0.08948, avg_loss=0.08804, mel_loss=0.03933, linear_loss=0.05015]
[2020-05-12 07:58:14.548]  Step 156276  [3.392 sec/step, loss=0.09268, avg_loss=0.08815, mel_loss=0.04111, linear_loss=0.05157]
[2020-05-12 07:58:15.377]  Step 156277  [3.362 sec/step, loss=0.07463, avg_loss=0.08795, mel_loss=0.03174, linear_loss=0.04289]
[2020-05-12 07:58:17.448]  Step 156278  [3.372 sec/step, loss=0.08735, avg_loss=0.08807, mel_loss=0.03820, linear_loss=0.04915]
[2020-05-12 07:58:18.829]  Step 156279  [3.331 sec/step, loss=0.08541, avg_loss=0.08795, mel_loss=0.03684, linear_loss=0.04857]
[2020-05-12 07:58:22.052]  Step 156280  [3.232 sec/step, loss=0.09261, avg_loss=0.08807, mel_loss=0.04112, linear_loss=0.05149]
[2020-05-12 07:58:29.488]  Step 156281  [3.292 sec/step, loss=0.09596, avg_loss=0.08818, mel_loss=0.04370, linear_loss=0.05226]
[2020-05-12 07:58:34.937]  Step 156282  [3.301 sec/step, loss=0.09620, avg_loss=0.08818, mel_loss=0.04329, linear_loss=0.05291]
[2020-05-12 07:58:41.782]  Step 156283  [3.350 sec/step, loss=0.09609, avg_loss=0.08826, mel_loss=0.04374, linear_loss=0.05234]
[2020-05-12 07:58:47.775]  Step 156284  [3.321 sec/step, loss=0.09471, avg_loss=0.08826, mel_loss=0.04297, linear_loss=0.05174]
[2020-05-12 07:58:48.911]  Step 156285  [3.299 sec/step, loss=0.07860, avg_loss=0.08810, mel_loss=0.03344, linear_loss=0.04516]
[2020-05-12 07:58:51.557]  Step 156286  [3.301 sec/step, loss=0.09028, avg_loss=0.08809, mel_loss=0.03955, linear_loss=0.05073]
[2020-05-12 07:58:53.662]  Step 156287  [3.284 sec/step, loss=0.08767, avg_loss=0.08801, mel_loss=0.03801, linear_loss=0.04966]
[2020-05-12 07:58:56.480]  Step 156288  [3.296 sec/step, loss=0.09055, avg_loss=0.08806, mel_loss=0.04016, linear_loss=0.05039]
[2020-05-12 07:59:00.789]  Step 156289  [3.318 sec/step, loss=0.09368, avg_loss=0.08809, mel_loss=0.04205, linear_loss=0.05163]
[2020-05-12 07:59:04.134]  Step 156290  [3.322 sec/step, loss=0.09301, avg_loss=0.08812, mel_loss=0.04135, linear_loss=0.05166]
[2020-05-12 07:59:12.982]  Step 156291  [3.401 sec/step, loss=0.09457, avg_loss=0.08826, mel_loss=0.04359, linear_loss=0.05098]
[2020-05-12 07:59:16.933]  Step 156292  [3.418 sec/step, loss=0.09408, avg_loss=0.08831, mel_loss=0.04199, linear_loss=0.05209]
[2020-05-12 07:59:18.690]  Step 156293  [3.422 sec/step, loss=0.08599, avg_loss=0.08834, mel_loss=0.03739, linear_loss=0.04860]
[2020-05-12 07:59:19.743]  Step 156294  [3.398 sec/step, loss=0.07982, avg_loss=0.08819, mel_loss=0.03440, linear_loss=0.04542]
[2020-05-12 07:59:20.868]  Step 156295  [3.395 sec/step, loss=0.08228, avg_loss=0.08817, mel_loss=0.03485, linear_loss=0.04743]
[2020-05-12 07:59:22.712]  Step 156296  [3.364 sec/step, loss=0.08633, avg_loss=0.08808, mel_loss=0.03735, linear_loss=0.04898]
[2020-05-12 07:59:26.453]  Step 156297  [3.356 sec/step, loss=0.09463, avg_loss=0.08806, mel_loss=0.04222, linear_loss=0.05241]
[2020-05-12 07:59:28.048]  Step 156298  [3.363 sec/step, loss=0.08528, avg_loss=0.08815, mel_loss=0.03705, linear_loss=0.04824]
[2020-05-12 07:59:42.661]  Step 156299  [3.501 sec/step, loss=0.07648, avg_loss=0.08820, mel_loss=0.03587, linear_loss=0.04061]
[2020-05-12 07:59:45.662]  Step 156300  [3.470 sec/step, loss=0.09203, avg_loss=0.08817, mel_loss=0.04080, linear_loss=0.05123]
[2020-05-12 07:59:45.662]  Writing summary at step: 156300
[2020-05-12 07:59:48.268]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156300
[2020-05-12 07:59:49.846]  Saving audio and alignment...
[2020-05-12 07:59:57.209]  Input: 오늘 참석자가 이렇게 와서 아 오늘 서울 와서 정말 좋은 행사 잘 봤습니다~_________________
[2020-05-12 07:59:58.423]  Step 156301  [3.464 sec/step, loss=0.08168, avg_loss=0.08813, mel_loss=0.03547, linear_loss=0.04621]
[2020-05-12 07:59:58.998]  Step 156302  [3.352 sec/step, loss=0.07144, avg_loss=0.08792, mel_loss=0.03072, linear_loss=0.04072]
[2020-05-12 07:59:59.762]  Step 156303  [3.342 sec/step, loss=0.07726, avg_loss=0.08781, mel_loss=0.03277, linear_loss=0.04448]
[2020-05-12 08:00:01.170]  Step 156304  [3.323 sec/step, loss=0.08657, avg_loss=0.08775, mel_loss=0.03752, linear_loss=0.04905]
[2020-05-12 08:00:13.603]  Generated 32 batches of size 32 in 47.144 sec
[2020-05-12 08:00:22.853]  Step 156305  [3.479 sec/step, loss=0.09435, avg_loss=0.08773, mel_loss=0.04329, linear_loss=0.05106]
[2020-05-12 08:00:24.567]  Step 156306  [3.469 sec/step, loss=0.08822, avg_loss=0.08770, mel_loss=0.03836, linear_loss=0.04985]
[2020-05-12 08:00:26.498]  Step 156307  [3.479 sec/step, loss=0.08587, avg_loss=0.08778, mel_loss=0.03741, linear_loss=0.04845]
[2020-05-12 08:00:33.859]  Step 156308  [3.542 sec/step, loss=0.09689, avg_loss=0.08792, mel_loss=0.04428, linear_loss=0.05262]
[2020-05-12 08:00:35.358]  Step 156309  [3.552 sec/step, loss=0.08427, avg_loss=0.08809, mel_loss=0.03643, linear_loss=0.04784]
[2020-05-12 08:00:36.167]  Step 156310  [3.516 sec/step, loss=0.07557, avg_loss=0.08790, mel_loss=0.03219, linear_loss=0.04338]
[2020-05-12 08:00:41.027]  Step 156311  [3.554 sec/step, loss=0.09416, avg_loss=0.08801, mel_loss=0.04228, linear_loss=0.05188]
[2020-05-12 08:00:41.890]  Step 156312  [3.528 sec/step, loss=0.08084, avg_loss=0.08788, mel_loss=0.03432, linear_loss=0.04652]
[2020-05-12 08:00:47.892]  Step 156313  [3.574 sec/step, loss=0.09667, avg_loss=0.08800, mel_loss=0.04402, linear_loss=0.05265]
[2020-05-12 08:00:48.956]  Step 156314  [3.551 sec/step, loss=0.08305, avg_loss=0.08790, mel_loss=0.03547, linear_loss=0.04758]
[2020-05-12 08:00:50.215]  Step 156315  [3.533 sec/step, loss=0.08175, avg_loss=0.08778, mel_loss=0.03499, linear_loss=0.04676]
[2020-05-12 08:01:03.436]  Step 156316  [3.630 sec/step, loss=0.07871, avg_loss=0.08766, mel_loss=0.03683, linear_loss=0.04189]
[2020-05-12 08:01:04.610]  Step 156317  [3.612 sec/step, loss=0.08091, avg_loss=0.08755, mel_loss=0.03457, linear_loss=0.04634]
[2020-05-12 08:01:08.952]  Step 156318  [3.643 sec/step, loss=0.09655, avg_loss=0.08767, mel_loss=0.04321, linear_loss=0.05334]
[2020-05-12 08:01:12.418]  Step 156319  [3.673 sec/step, loss=0.09425, avg_loss=0.08793, mel_loss=0.04168, linear_loss=0.05257]
[2020-05-12 08:01:15.853]  Step 156320  [3.696 sec/step, loss=0.09213, avg_loss=0.08807, mel_loss=0.04095, linear_loss=0.05118]
[2020-05-12 08:01:16.704]  Step 156321  [3.694 sec/step, loss=0.07373, avg_loss=0.08796, mel_loss=0.03140, linear_loss=0.04232]
[2020-05-12 08:01:17.239]  Step 156322  [3.677 sec/step, loss=0.06999, avg_loss=0.08777, mel_loss=0.03131, linear_loss=0.03867]
[2020-05-12 08:01:18.590]  Step 156323  [3.671 sec/step, loss=0.08354, avg_loss=0.08772, mel_loss=0.03594, linear_loss=0.04760]
[2020-05-12 08:01:20.728]  Step 156324  [3.640 sec/step, loss=0.08938, avg_loss=0.08768, mel_loss=0.03910, linear_loss=0.05028]
[2020-05-12 08:01:22.961]  Step 156325  [3.519 sec/step, loss=0.08881, avg_loss=0.08782, mel_loss=0.03883, linear_loss=0.04998]
[2020-05-12 08:01:25.408]  Step 156326  [3.524 sec/step, loss=0.09109, avg_loss=0.08785, mel_loss=0.03990, linear_loss=0.05120]
[2020-05-12 08:01:29.096]  Step 156327  [3.517 sec/step, loss=0.09457, avg_loss=0.08784, mel_loss=0.04208, linear_loss=0.05250]
[2020-05-12 08:01:34.450]  Step 156328  [3.549 sec/step, loss=0.09754, avg_loss=0.08790, mel_loss=0.04396, linear_loss=0.05358]
[2020-05-12 08:01:35.432]  Step 156329  [3.551 sec/step, loss=0.08086, avg_loss=0.08796, mel_loss=0.03443, linear_loss=0.04644]
[2020-05-12 08:01:38.079]  Step 156330  [3.508 sec/step, loss=0.09137, avg_loss=0.08792, mel_loss=0.04013, linear_loss=0.05124]
[2020-05-12 08:01:43.207]  Step 156331  [3.523 sec/step, loss=0.09824, avg_loss=0.08796, mel_loss=0.04405, linear_loss=0.05419]
[2020-05-12 08:01:45.219]  Step 156332  [3.497 sec/step, loss=0.08979, avg_loss=0.08791, mel_loss=0.03923, linear_loss=0.05055]
[2020-05-12 08:01:48.108]  Step 156333  [3.502 sec/step, loss=0.09329, avg_loss=0.08794, mel_loss=0.04112, linear_loss=0.05217]
[2020-05-12 08:01:51.174]  Step 156334  [3.514 sec/step, loss=0.09359, avg_loss=0.08801, mel_loss=0.04148, linear_loss=0.05211]
[2020-05-12 08:01:52.875]  Step 156335  [3.523 sec/step, loss=0.08681, avg_loss=0.08813, mel_loss=0.03797, linear_loss=0.04884]
[2020-05-12 08:01:56.970]  Step 156336  [3.486 sec/step, loss=0.09603, avg_loss=0.08812, mel_loss=0.04249, linear_loss=0.05353]
[2020-05-12 08:02:04.878]  Generated 32 batches of size 32 in 35.777 sec
[2020-05-12 08:02:07.837]  Step 156337  [3.554 sec/step, loss=0.09238, avg_loss=0.08809, mel_loss=0.04065, linear_loss=0.05172]
[2020-05-12 08:02:10.310]  Step 156338  [3.562 sec/step, loss=0.09026, avg_loss=0.08812, mel_loss=0.03956, linear_loss=0.05070]
[2020-05-12 08:02:12.319]  Step 156339  [3.556 sec/step, loss=0.08827, avg_loss=0.08808, mel_loss=0.03845, linear_loss=0.04981]
[2020-05-12 08:02:15.514]  Step 156340  [3.578 sec/step, loss=0.09286, avg_loss=0.08823, mel_loss=0.04124, linear_loss=0.05162]
[2020-05-12 08:02:16.442]  Step 156341  [3.573 sec/step, loss=0.07902, avg_loss=0.08816, mel_loss=0.03342, linear_loss=0.04561]
[2020-05-12 08:02:18.601]  Step 156342  [3.505 sec/step, loss=0.08938, avg_loss=0.08810, mel_loss=0.03912, linear_loss=0.05025]
[2020-05-12 08:02:32.752]  Step 156343  [3.630 sec/step, loss=0.07392, avg_loss=0.08798, mel_loss=0.03471, linear_loss=0.03921]
[2020-05-12 08:02:33.438]  Step 156344  [3.580 sec/step, loss=0.07210, avg_loss=0.08774, mel_loss=0.03142, linear_loss=0.04068]
[2020-05-12 08:02:40.112]  Step 156345  [3.639 sec/step, loss=0.09474, avg_loss=0.08794, mel_loss=0.04291, linear_loss=0.05183]
[2020-05-12 08:02:42.562]  Step 156346  [3.649 sec/step, loss=0.08937, avg_loss=0.08800, mel_loss=0.03916, linear_loss=0.05021]
[2020-05-12 08:02:44.312]  Step 156347  [3.648 sec/step, loss=0.08783, avg_loss=0.08801, mel_loss=0.03786, linear_loss=0.04997]
[2020-05-12 08:02:47.066]  Step 156348  [3.600 sec/step, loss=0.09069, avg_loss=0.08794, mel_loss=0.04008, linear_loss=0.05061]
[2020-05-12 08:02:49.289]  Step 156349  [3.587 sec/step, loss=0.08804, avg_loss=0.08790, mel_loss=0.03874, linear_loss=0.04930]
[2020-05-12 08:02:51.125]  Step 156350  [3.563 sec/step, loss=0.08696, avg_loss=0.08782, mel_loss=0.03750, linear_loss=0.04946]
[2020-05-12 08:02:51.125]  Writing summary at step: 156350
[2020-05-12 08:02:55.575]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156350
[2020-05-12 08:02:57.200]  Saving audio and alignment...
[2020-05-12 08:03:05.208]  Input: 얼마 전에 제가 한 총장님이 진행하시는 대학생들과의 토크 콘서트~_______________________________________
[2020-05-12 08:03:06.326]  Step 156351  [3.537 sec/step, loss=0.08089, avg_loss=0.08768, mel_loss=0.03460, linear_loss=0.04629]
[2020-05-12 08:03:07.699]  Step 156352  [3.532 sec/step, loss=0.08479, avg_loss=0.08763, mel_loss=0.03687, linear_loss=0.04792]
[2020-05-12 08:03:09.220]  Step 156353  [3.482 sec/step, loss=0.08543, avg_loss=0.08753, mel_loss=0.03705, linear_loss=0.04838]
[2020-05-12 08:03:13.992]  Step 156354  [3.519 sec/step, loss=0.09483, avg_loss=0.08769, mel_loss=0.04253, linear_loss=0.05230]
[2020-05-12 08:03:14.988]  Step 156355  [3.472 sec/step, loss=0.08233, avg_loss=0.08756, mel_loss=0.03524, linear_loss=0.04709]
[2020-05-12 08:03:18.509]  Step 156356  [3.485 sec/step, loss=0.09355, avg_loss=0.08760, mel_loss=0.04167, linear_loss=0.05188]
[2020-05-12 08:03:21.999]  Step 156357  [3.512 sec/step, loss=0.09246, avg_loss=0.08783, mel_loss=0.04106, linear_loss=0.05140]
[2020-05-12 08:03:29.089]  Step 156358  [3.541 sec/step, loss=0.09657, avg_loss=0.08786, mel_loss=0.04401, linear_loss=0.05256]
[2020-05-12 08:03:30.446]  Step 156359  [3.532 sec/step, loss=0.08239, avg_loss=0.08780, mel_loss=0.03579, linear_loss=0.04660]
[2020-05-12 08:03:38.877]  Step 156360  [3.587 sec/step, loss=0.09505, avg_loss=0.08782, mel_loss=0.04358, linear_loss=0.05146]
[2020-05-12 08:03:39.874]  Generated 32 batches of size 32 in 17.869 sec
[2020-05-12 08:03:40.515]  Step 156361  [3.568 sec/step, loss=0.08748, avg_loss=0.08776, mel_loss=0.03821, linear_loss=0.04927]
[2020-05-12 08:03:41.734]  Step 156362  [3.567 sec/step, loss=0.08144, avg_loss=0.08776, mel_loss=0.03479, linear_loss=0.04666]
[2020-05-12 08:03:42.302]  Step 156363  [3.525 sec/step, loss=0.06796, avg_loss=0.08747, mel_loss=0.02977, linear_loss=0.03819]
[2020-05-12 08:03:43.189]  Step 156364  [3.524 sec/step, loss=0.07410, avg_loss=0.08743, mel_loss=0.03145, linear_loss=0.04265]
[2020-05-12 08:03:47.017]  Step 156365  [3.546 sec/step, loss=0.09529, avg_loss=0.08753, mel_loss=0.04263, linear_loss=0.05267]
[2020-05-12 08:03:51.185]  Step 156366  [3.580 sec/step, loss=0.09382, avg_loss=0.08769, mel_loss=0.04184, linear_loss=0.05198]
[2020-05-12 08:03:53.193]  Step 156367  [3.546 sec/step, loss=0.08850, avg_loss=0.08762, mel_loss=0.03880, linear_loss=0.04970]
[2020-05-12 08:03:54.205]  Step 156368  [3.525 sec/step, loss=0.07624, avg_loss=0.08743, mel_loss=0.03217, linear_loss=0.04407]
[2020-05-12 08:03:59.276]  Step 156369  [3.428 sec/step, loss=0.09596, avg_loss=0.08762, mel_loss=0.04300, linear_loss=0.05295]
[2020-05-12 08:04:04.879]  Step 156370  [3.459 sec/step, loss=0.09410, avg_loss=0.08765, mel_loss=0.04241, linear_loss=0.05169]
[2020-05-12 08:04:06.013]  Step 156371  [3.460 sec/step, loss=0.08268, avg_loss=0.08766, mel_loss=0.03493, linear_loss=0.04775]
[2020-05-12 08:04:20.246]  Step 156372  [3.576 sec/step, loss=0.07373, avg_loss=0.08752, mel_loss=0.03482, linear_loss=0.03891]
[2020-05-12 08:04:24.129]  Step 156373  [3.525 sec/step, loss=0.09479, avg_loss=0.08752, mel_loss=0.04234, linear_loss=0.05245]
[2020-05-12 08:04:27.636]  Step 156374  [3.532 sec/step, loss=0.09279, avg_loss=0.08753, mel_loss=0.04141, linear_loss=0.05138]
[2020-05-12 08:04:29.049]  Step 156375  [3.524 sec/step, loss=0.08609, avg_loss=0.08750, mel_loss=0.03728, linear_loss=0.04881]
[2020-05-12 08:04:36.025]  Step 156376  [3.558 sec/step, loss=0.09673, avg_loss=0.08754, mel_loss=0.04425, linear_loss=0.05247]
[2020-05-12 08:04:37.660]  Step 156377  [3.566 sec/step, loss=0.08922, avg_loss=0.08768, mel_loss=0.03888, linear_loss=0.05034]
[2020-05-12 08:04:38.225]  Step 156378  [3.551 sec/step, loss=0.06774, avg_loss=0.08749, mel_loss=0.02943, linear_loss=0.03831]
[2020-05-12 08:04:41.040]  Step 156379  [3.566 sec/step, loss=0.08962, avg_loss=0.08753, mel_loss=0.03961, linear_loss=0.05002]
[2020-05-12 08:04:43.589]  Step 156380  [3.559 sec/step, loss=0.09089, avg_loss=0.08751, mel_loss=0.03950, linear_loss=0.05139]
[2020-05-12 08:04:45.915]  Step 156381  [3.508 sec/step, loss=0.08979, avg_loss=0.08745, mel_loss=0.03969, linear_loss=0.05010]
[2020-05-12 08:04:47.851]  Step 156382  [3.473 sec/step, loss=0.08823, avg_loss=0.08737, mel_loss=0.03839, linear_loss=0.04984]
[2020-05-12 08:04:49.208]  Step 156383  [3.418 sec/step, loss=0.08258, avg_loss=0.08724, mel_loss=0.03563, linear_loss=0.04695]
[2020-05-12 08:04:50.018]  Step 156384  [3.366 sec/step, loss=0.07558, avg_loss=0.08705, mel_loss=0.03229, linear_loss=0.04329]
[2020-05-12 08:04:51.795]  Step 156385  [3.372 sec/step, loss=0.08737, avg_loss=0.08713, mel_loss=0.03769, linear_loss=0.04968]
[2020-05-12 08:04:53.982]  Step 156386  [3.368 sec/step, loss=0.09015, avg_loss=0.08713, mel_loss=0.03958, linear_loss=0.05057]
[2020-05-12 08:04:59.628]  Step 156387  [3.403 sec/step, loss=0.09621, avg_loss=0.08722, mel_loss=0.04380, linear_loss=0.05241]
[2020-05-12 08:05:00.784]  Step 156388  [3.386 sec/step, loss=0.08581, avg_loss=0.08717, mel_loss=0.03725, linear_loss=0.04856]
[2020-05-12 08:05:02.355]  Step 156389  [3.359 sec/step, loss=0.08531, avg_loss=0.08709, mel_loss=0.03706, linear_loss=0.04825]
[2020-05-12 08:05:04.059]  Generated 32 batches of size 32 in 1.698 sec
[2020-05-12 08:05:11.254]  Step 156390  [3.415 sec/step, loss=0.09282, avg_loss=0.08708, mel_loss=0.04257, linear_loss=0.05025]
[2020-05-12 08:05:12.126]  Step 156391  [3.335 sec/step, loss=0.07095, avg_loss=0.08685, mel_loss=0.03038, linear_loss=0.04058]
[2020-05-12 08:05:16.313]  Step 156392  [3.337 sec/step, loss=0.09518, avg_loss=0.08686, mel_loss=0.04277, linear_loss=0.05241]
[2020-05-12 08:05:17.365]  Step 156393  [3.330 sec/step, loss=0.08171, avg_loss=0.08682, mel_loss=0.03480, linear_loss=0.04691]
[2020-05-12 08:05:21.170]  Step 156394  [3.358 sec/step, loss=0.09562, avg_loss=0.08697, mel_loss=0.04254, linear_loss=0.05309]
[2020-05-12 08:05:27.636]  Step 156395  [3.411 sec/step, loss=0.09432, avg_loss=0.08709, mel_loss=0.04284, linear_loss=0.05148]
[2020-05-12 08:05:31.014]  Step 156396  [3.426 sec/step, loss=0.09370, avg_loss=0.08717, mel_loss=0.04167, linear_loss=0.05202]
[2020-05-12 08:05:34.137]  Step 156397  [3.420 sec/step, loss=0.09528, avg_loss=0.08717, mel_loss=0.04219, linear_loss=0.05310]
[2020-05-12 08:05:37.159]  Step 156398  [3.435 sec/step, loss=0.09210, avg_loss=0.08724, mel_loss=0.04061, linear_loss=0.05149]
[2020-05-12 08:05:39.264]  Step 156399  [3.309 sec/step, loss=0.08772, avg_loss=0.08736, mel_loss=0.03829, linear_loss=0.04944]
[2020-05-12 08:05:41.018]  Step 156400  [3.297 sec/step, loss=0.08757, avg_loss=0.08731, mel_loss=0.03800, linear_loss=0.04957]
[2020-05-12 08:05:41.018]  Writing summary at step: 156400
[2020-05-12 08:05:46.771]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156400
[2020-05-12 08:05:48.369]  Saving audio and alignment...
[2020-05-12 08:05:55.466]  Input: 머지 않아 아나운서 부럽지 않은 훌륭한 목소리도 완성할수~________________________________
[2020-05-12 08:05:58.985]  Step 156401  [3.320 sec/step, loss=0.09240, avg_loss=0.08742, mel_loss=0.04095, linear_loss=0.05145]
[2020-05-12 08:06:01.209]  Step 156402  [3.337 sec/step, loss=0.08987, avg_loss=0.08760, mel_loss=0.03921, linear_loss=0.05067]
[2020-05-12 08:06:03.026]  Step 156403  [3.347 sec/step, loss=0.08899, avg_loss=0.08772, mel_loss=0.03859, linear_loss=0.05040]
[2020-05-12 08:06:06.000]  Step 156404  [3.363 sec/step, loss=0.09404, avg_loss=0.08779, mel_loss=0.04171, linear_loss=0.05232]
[2020-05-12 08:06:09.551]  Step 156405  [3.181 sec/step, loss=0.09264, avg_loss=0.08778, mel_loss=0.04108, linear_loss=0.05156]
[2020-05-12 08:06:11.232]  Step 156406  [3.181 sec/step, loss=0.08538, avg_loss=0.08775, mel_loss=0.03722, linear_loss=0.04816]
[2020-05-12 08:06:14.923]  Step 156407  [3.199 sec/step, loss=0.09426, avg_loss=0.08783, mel_loss=0.04214, linear_loss=0.05211]
[2020-05-12 08:06:17.468]  Step 156408  [3.151 sec/step, loss=0.09136, avg_loss=0.08778, mel_loss=0.04031, linear_loss=0.05105]
[2020-05-12 08:06:18.734]  Step 156409  [3.148 sec/step, loss=0.08129, avg_loss=0.08775, mel_loss=0.03494, linear_loss=0.04636]
[2020-05-12 08:06:32.036]  Step 156410  [3.273 sec/step, loss=0.08112, avg_loss=0.08780, mel_loss=0.03781, linear_loss=0.04331]
[2020-05-12 08:06:33.123]  Step 156411  [3.235 sec/step, loss=0.08306, avg_loss=0.08769, mel_loss=0.03561, linear_loss=0.04744]
[2020-05-12 08:06:34.139]  Step 156412  [3.237 sec/step, loss=0.07915, avg_loss=0.08767, mel_loss=0.03360, linear_loss=0.04555]
[2020-05-12 08:06:34.877]  Step 156413  [3.184 sec/step, loss=0.07431, avg_loss=0.08745, mel_loss=0.03194, linear_loss=0.04237]
[2020-05-12 08:06:36.345]  Step 156414  [3.188 sec/step, loss=0.08410, avg_loss=0.08746, mel_loss=0.03643, linear_loss=0.04767]
[2020-05-12 08:06:44.036]  Step 156415  [3.253 sec/step, loss=0.09591, avg_loss=0.08760, mel_loss=0.04391, linear_loss=0.05201]
[2020-05-12 08:06:48.461]  Step 156416  [3.165 sec/step, loss=0.09465, avg_loss=0.08776, mel_loss=0.04238, linear_loss=0.05227]
[2020-05-12 08:06:49.502]  Step 156417  [3.163 sec/step, loss=0.07777, avg_loss=0.08773, mel_loss=0.03349, linear_loss=0.04428]
[2020-05-12 08:06:50.075]  Step 156418  [3.126 sec/step, loss=0.06908, avg_loss=0.08746, mel_loss=0.02994, linear_loss=0.03914]
[2020-05-12 08:06:56.387]  Step 156419  [3.154 sec/step, loss=0.09439, avg_loss=0.08746, mel_loss=0.04297, linear_loss=0.05143]
[2020-05-12 08:06:58.177]  Generated 32 batches of size 32 in 1.784 sec
[2020-05-12 08:06:58.524]  Step 156420  [3.141 sec/step, loss=0.08629, avg_loss=0.08740, mel_loss=0.03785, linear_loss=0.04844]
[2020-05-12 08:07:01.684]  Step 156421  [3.164 sec/step, loss=0.09556, avg_loss=0.08762, mel_loss=0.04251, linear_loss=0.05304]
[2020-05-12 08:07:10.254]  Step 156422  [3.245 sec/step, loss=0.09296, avg_loss=0.08785, mel_loss=0.04258, linear_loss=0.05038]
[2020-05-12 08:07:15.596]  Step 156423  [3.285 sec/step, loss=0.09479, avg_loss=0.08796, mel_loss=0.04273, linear_loss=0.05206]
[2020-05-12 08:07:18.028]  Step 156424  [3.287 sec/step, loss=0.08978, avg_loss=0.08796, mel_loss=0.03936, linear_loss=0.05042]
[2020-05-12 08:07:22.110]  Step 156425  [3.306 sec/step, loss=0.09536, avg_loss=0.08803, mel_loss=0.04249, linear_loss=0.05287]
[2020-05-12 08:07:23.504]  Step 156426  [3.295 sec/step, loss=0.08403, avg_loss=0.08796, mel_loss=0.03626, linear_loss=0.04777]
[2020-05-12 08:07:26.277]  Step 156427  [3.286 sec/step, loss=0.09183, avg_loss=0.08793, mel_loss=0.04057, linear_loss=0.05126]
[2020-05-12 08:07:27.079]  Step 156428  [3.241 sec/step, loss=0.07614, avg_loss=0.08772, mel_loss=0.03291, linear_loss=0.04322]
[2020-05-12 08:07:28.849]  Step 156429  [3.249 sec/step, loss=0.08692, avg_loss=0.08778, mel_loss=0.03752, linear_loss=0.04939]
[2020-05-12 08:07:31.514]  Step 156430  [3.249 sec/step, loss=0.09049, avg_loss=0.08777, mel_loss=0.03980, linear_loss=0.05069]
[2020-05-12 08:07:33.097]  Step 156431  [3.213 sec/step, loss=0.08817, avg_loss=0.08767, mel_loss=0.03815, linear_loss=0.05002]
[2020-05-12 08:07:34.076]  Step 156432  [3.203 sec/step, loss=0.07925, avg_loss=0.08756, mel_loss=0.03361, linear_loss=0.04565]
[2020-05-12 08:07:35.217]  Step 156433  [3.186 sec/step, loss=0.08298, avg_loss=0.08746, mel_loss=0.03563, linear_loss=0.04735]
[2020-05-12 08:07:36.292]  Step 156434  [3.166 sec/step, loss=0.08170, avg_loss=0.08734, mel_loss=0.03494, linear_loss=0.04677]
[2020-05-12 08:07:40.725]  Step 156435  [3.193 sec/step, loss=0.09623, avg_loss=0.08744, mel_loss=0.04344, linear_loss=0.05279]
[2020-05-12 08:07:48.196]  Step 156436  [3.227 sec/step, loss=0.09796, avg_loss=0.08745, mel_loss=0.04492, linear_loss=0.05304]
[2020-05-12 08:07:49.008]  Step 156437  [3.126 sec/step, loss=0.07469, avg_loss=0.08728, mel_loss=0.03177, linear_loss=0.04292]
[2020-05-12 08:07:53.739]  Step 156438  [3.149 sec/step, loss=0.09469, avg_loss=0.08732, mel_loss=0.04235, linear_loss=0.05235]
[2020-05-12 08:07:54.735]  Step 156439  [3.139 sec/step, loss=0.07970, avg_loss=0.08724, mel_loss=0.03399, linear_loss=0.04570]
[2020-05-12 08:07:56.712]  Step 156440  [3.126 sec/step, loss=0.08695, avg_loss=0.08718, mel_loss=0.03792, linear_loss=0.04903]
[2020-05-12 08:08:03.481]  Step 156441  [3.185 sec/step, loss=0.09611, avg_loss=0.08735, mel_loss=0.04367, linear_loss=0.05243]
[2020-05-12 08:08:05.708]  Step 156442  [3.186 sec/step, loss=0.08906, avg_loss=0.08735, mel_loss=0.03905, linear_loss=0.05001]
[2020-05-12 08:08:08.143]  Step 156443  [3.068 sec/step, loss=0.08853, avg_loss=0.08749, mel_loss=0.03874, linear_loss=0.04979]
[2020-05-12 08:08:17.153]  Step 156444  [3.152 sec/step, loss=0.09449, avg_loss=0.08772, mel_loss=0.04360, linear_loss=0.05089]
[2020-05-12 08:08:20.320]  Step 156445  [3.117 sec/step, loss=0.09597, avg_loss=0.08773, mel_loss=0.04242, linear_loss=0.05355]
[2020-05-12 08:08:22.376]  Step 156446  [3.113 sec/step, loss=0.08899, avg_loss=0.08772, mel_loss=0.03902, linear_loss=0.04997]
[2020-05-12 08:08:23.207]  Step 156447  [3.103 sec/step, loss=0.07626, avg_loss=0.08761, mel_loss=0.03212, linear_loss=0.04414]
[2020-05-12 08:08:26.196]  Step 156448  [3.106 sec/step, loss=0.09233, avg_loss=0.08762, mel_loss=0.04066, linear_loss=0.05167]
[2020-05-12 08:08:31.332]  Step 156449  [3.135 sec/step, loss=0.09507, avg_loss=0.08769, mel_loss=0.04282, linear_loss=0.05225]
[2020-05-12 08:08:32.712]  Step 156450  [3.130 sec/step, loss=0.08561, avg_loss=0.08768, mel_loss=0.03692, linear_loss=0.04869]
[2020-05-12 08:08:32.712]  Writing summary at step: 156450
[2020-05-12 08:08:36.173]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156450
[2020-05-12 08:08:37.777]  Saving audio and alignment...
[2020-05-12 08:08:39.915]  Generated 32 batches of size 32 in 1.545 sec
[2020-05-12 08:08:41.022]  Input: 눈부신 햇살과 함께~____________
[2020-05-12 08:08:43.836]  Step 156451  [3.147 sec/step, loss=0.09111, avg_loss=0.08778, mel_loss=0.04029, linear_loss=0.05081]
[2020-05-12 08:08:47.531]  Step 156452  [3.170 sec/step, loss=0.09465, avg_loss=0.08788, mel_loss=0.04225, linear_loss=0.05240]
[2020-05-12 08:08:51.690]  Step 156453  [3.197 sec/step, loss=0.09377, avg_loss=0.08797, mel_loss=0.04158, linear_loss=0.05219]
[2020-05-12 08:08:57.356]  Step 156454  [3.206 sec/step, loss=0.09626, avg_loss=0.08798, mel_loss=0.04350, linear_loss=0.05277]
[2020-05-12 08:08:58.672]  Step 156455  [3.209 sec/step, loss=0.08315, avg_loss=0.08799, mel_loss=0.03581, linear_loss=0.04734]
[2020-05-12 08:09:10.781]  Step 156456  [3.295 sec/step, loss=0.08859, avg_loss=0.08794, mel_loss=0.04169, linear_loss=0.04690]
[2020-05-12 08:09:14.540]  Step 156457  [3.298 sec/step, loss=0.09238, avg_loss=0.08794, mel_loss=0.04089, linear_loss=0.05149]
[2020-05-12 08:09:15.190]  Step 156458  [3.233 sec/step, loss=0.06945, avg_loss=0.08767, mel_loss=0.03081, linear_loss=0.03864]
[2020-05-12 08:09:22.952]  Step 156459  [3.297 sec/step, loss=0.09594, avg_loss=0.08780, mel_loss=0.04388, linear_loss=0.05206]
[2020-05-12 08:09:28.208]  Step 156460  [3.265 sec/step, loss=0.09494, avg_loss=0.08780, mel_loss=0.04266, linear_loss=0.05228]
[2020-05-12 08:09:30.994]  Step 156461  [3.277 sec/step, loss=0.08988, avg_loss=0.08782, mel_loss=0.03959, linear_loss=0.05029]
[2020-05-12 08:09:31.562]  Step 156462  [3.270 sec/step, loss=0.06967, avg_loss=0.08771, mel_loss=0.03012, linear_loss=0.03955]
[2020-05-12 08:09:38.331]  Step 156463  [3.332 sec/step, loss=0.09489, avg_loss=0.08798, mel_loss=0.04310, linear_loss=0.05179]
[2020-05-12 08:09:41.801]  Step 156464  [3.358 sec/step, loss=0.09276, avg_loss=0.08816, mel_loss=0.04163, linear_loss=0.05112]
[2020-05-12 08:09:43.225]  Step 156465  [3.334 sec/step, loss=0.08635, avg_loss=0.08807, mel_loss=0.03771, linear_loss=0.04865]
[2020-05-12 08:09:44.833]  Step 156466  [3.309 sec/step, loss=0.08796, avg_loss=0.08801, mel_loss=0.03806, linear_loss=0.04990]
[2020-05-12 08:09:59.455]  Step 156467  [3.435 sec/step, loss=0.07444, avg_loss=0.08787, mel_loss=0.03495, linear_loss=0.03949]
[2020-05-12 08:10:05.302]  Step 156468  [3.483 sec/step, loss=0.09591, avg_loss=0.08807, mel_loss=0.04344, linear_loss=0.05248]
[2020-05-12 08:10:08.743]  Step 156469  [3.467 sec/step, loss=0.09258, avg_loss=0.08804, mel_loss=0.04100, linear_loss=0.05157]
[2020-05-12 08:10:13.087]  Step 156470  [3.454 sec/step, loss=0.09397, avg_loss=0.08804, mel_loss=0.04194, linear_loss=0.05203]
[2020-05-12 08:10:19.306]  Step 156471  [3.505 sec/step, loss=0.09579, avg_loss=0.08817, mel_loss=0.04267, linear_loss=0.05313]
[2020-05-12 08:10:21.209]  Step 156472  [3.382 sec/step, loss=0.08103, avg_loss=0.08824, mel_loss=0.03488, linear_loss=0.04615]
[2020-05-12 08:10:22.436]  Step 156473  [3.355 sec/step, loss=0.07417, avg_loss=0.08803, mel_loss=0.03161, linear_loss=0.04256]
[2020-05-12 08:10:25.657]  Step 156474  [3.352 sec/step, loss=0.08951, avg_loss=0.08800, mel_loss=0.03926, linear_loss=0.05025]
[2020-05-12 08:10:27.145]  Step 156475  [3.353 sec/step, loss=0.08531, avg_loss=0.08799, mel_loss=0.03656, linear_loss=0.04875]
[2020-05-12 08:10:29.081]  Step 156476  [3.303 sec/step, loss=0.08750, avg_loss=0.08790, mel_loss=0.03797, linear_loss=0.04953]
[2020-05-12 08:10:31.140]  Step 156477  [3.307 sec/step, loss=0.08740, avg_loss=0.08788, mel_loss=0.03806, linear_loss=0.04934]
[2020-05-12 08:10:32.042]  Step 156478  [3.310 sec/step, loss=0.07741, avg_loss=0.08798, mel_loss=0.03287, linear_loss=0.04454]
[2020-05-12 08:10:41.420]  Step 156479  [3.376 sec/step, loss=0.09563, avg_loss=0.08804, mel_loss=0.04397, linear_loss=0.05167]
[2020-05-12 08:10:43.893]  Step 156480  [3.375 sec/step, loss=0.09044, avg_loss=0.08804, mel_loss=0.03948, linear_loss=0.05096]
[2020-05-12 08:10:45.976]  Step 156481  [3.373 sec/step, loss=0.08882, avg_loss=0.08803, mel_loss=0.03882, linear_loss=0.05000]
[2020-05-12 08:10:47.837]  Step 156482  [3.372 sec/step, loss=0.08730, avg_loss=0.08802, mel_loss=0.03773, linear_loss=0.04957]
[2020-05-12 08:10:50.895]  Step 156483  [3.389 sec/step, loss=0.09283, avg_loss=0.08812, mel_loss=0.04119, linear_loss=0.05164]
[2020-05-12 08:10:53.175]  Step 156484  [3.404 sec/step, loss=0.08990, avg_loss=0.08826, mel_loss=0.03929, linear_loss=0.05061]
[2020-05-12 08:10:53.915]  Step 156485  [3.393 sec/step, loss=0.07361, avg_loss=0.08812, mel_loss=0.03216, linear_loss=0.04145]
[2020-05-12 08:10:54.961]  Step 156486  [3.382 sec/step, loss=0.08062, avg_loss=0.08803, mel_loss=0.03452, linear_loss=0.04609]
[2020-05-12 08:10:58.652]  Step 156487  [3.362 sec/step, loss=0.09552, avg_loss=0.08802, mel_loss=0.04251, linear_loss=0.05302]
[2020-05-12 08:10:59.779]  Step 156488  [3.362 sec/step, loss=0.08146, avg_loss=0.08798, mel_loss=0.03475, linear_loss=0.04671]
[2020-05-12 08:11:04.478]  Step 156489  [3.393 sec/step, loss=0.09627, avg_loss=0.08809, mel_loss=0.04340, linear_loss=0.05287]
[2020-05-12 08:11:06.133]  Step 156490  [3.321 sec/step, loss=0.08740, avg_loss=0.08803, mel_loss=0.03804, linear_loss=0.04936]
[2020-05-12 08:11:25.420]  Generated 32 batches of size 32 in 39.438 sec
[2020-05-12 08:11:26.853]  Step 156491  [3.519 sec/step, loss=0.08477, avg_loss=0.08817, mel_loss=0.03671, linear_loss=0.04806]
[2020-05-12 08:11:32.528]  Step 156492  [3.534 sec/step, loss=0.09547, avg_loss=0.08818, mel_loss=0.04312, linear_loss=0.05235]
[2020-05-12 08:11:41.309]  Step 156493  [3.612 sec/step, loss=0.09470, avg_loss=0.08830, mel_loss=0.04351, linear_loss=0.05119]
[2020-05-12 08:11:42.652]  Step 156494  [3.587 sec/step, loss=0.08083, avg_loss=0.08816, mel_loss=0.03488, linear_loss=0.04594]
[2020-05-12 08:11:43.741]  Step 156495  [3.533 sec/step, loss=0.07876, avg_loss=0.08800, mel_loss=0.03375, linear_loss=0.04501]
[2020-05-12 08:11:44.580]  Step 156496  [3.508 sec/step, loss=0.07937, avg_loss=0.08786, mel_loss=0.03377, linear_loss=0.04560]
[2020-05-12 08:11:51.302]  Step 156497  [3.544 sec/step, loss=0.09670, avg_loss=0.08787, mel_loss=0.04402, linear_loss=0.05268]
[2020-05-12 08:11:53.334]  Step 156498  [3.534 sec/step, loss=0.08954, avg_loss=0.08785, mel_loss=0.03885, linear_loss=0.05069]
[2020-05-12 08:11:56.857]  Step 156499  [3.548 sec/step, loss=0.09262, avg_loss=0.08790, mel_loss=0.04121, linear_loss=0.05142]
[2020-05-12 08:11:58.036]  Step 156500  [3.542 sec/step, loss=0.08228, avg_loss=0.08784, mel_loss=0.03500, linear_loss=0.04728]
[2020-05-12 08:11:58.036]  Writing summary at step: 156500
[2020-05-12 08:11:59.773]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156500
[2020-05-12 08:12:01.347]  Saving audio and alignment...
[2020-05-12 08:12:04.352]  Input: 어 어미처리에 있어도요~__________________
[2020-05-12 08:12:06.168]  Step 156501  [3.525 sec/step, loss=0.08641, avg_loss=0.08778, mel_loss=0.03759, linear_loss=0.04882]
[2020-05-12 08:12:11.552]  Step 156502  [3.557 sec/step, loss=0.09556, avg_loss=0.08784, mel_loss=0.04311, linear_loss=0.05245]
[2020-05-12 08:12:14.035]  Step 156503  [3.564 sec/step, loss=0.08838, avg_loss=0.08783, mel_loss=0.03889, linear_loss=0.04949]
[2020-05-12 08:12:21.218]  Step 156504  [3.606 sec/step, loss=0.09541, avg_loss=0.08785, mel_loss=0.04346, linear_loss=0.05195]
[2020-05-12 08:12:23.458]  Step 156505  [3.593 sec/step, loss=0.08915, avg_loss=0.08781, mel_loss=0.03919, linear_loss=0.04996]
[2020-05-12 08:12:28.201]  Step 156506  [3.623 sec/step, loss=0.09509, avg_loss=0.08791, mel_loss=0.04262, linear_loss=0.05248]
[2020-05-12 08:12:31.571]  Step 156507  [3.620 sec/step, loss=0.09421, avg_loss=0.08791, mel_loss=0.04170, linear_loss=0.05251]
[2020-05-12 08:12:33.794]  Step 156508  [3.617 sec/step, loss=0.08824, avg_loss=0.08788, mel_loss=0.03882, linear_loss=0.04942]
[2020-05-12 08:12:37.929]  Step 156509  [3.645 sec/step, loss=0.09385, avg_loss=0.08800, mel_loss=0.04177, linear_loss=0.05208]
[2020-05-12 08:12:39.378]  Step 156510  [3.527 sec/step, loss=0.08545, avg_loss=0.08805, mel_loss=0.03693, linear_loss=0.04852]
[2020-05-12 08:12:42.332]  Step 156511  [3.546 sec/step, loss=0.09248, avg_loss=0.08814, mel_loss=0.04103, linear_loss=0.05145]
[2020-05-12 08:12:45.531]  Step 156512  [3.567 sec/step, loss=0.09330, avg_loss=0.08828, mel_loss=0.04147, linear_loss=0.05183]
[2020-05-12 08:12:47.454]  Step 156513  [3.579 sec/step, loss=0.08893, avg_loss=0.08843, mel_loss=0.03861, linear_loss=0.05031]
[2020-05-12 08:12:50.232]  Step 156514  [3.592 sec/step, loss=0.09235, avg_loss=0.08851, mel_loss=0.04084, linear_loss=0.05151]
[2020-05-12 08:12:50.776]  Step 156515  [3.521 sec/step, loss=0.07035, avg_loss=0.08826, mel_loss=0.03060, linear_loss=0.03975]
[2020-05-12 08:12:55.250]  Step 156516  [3.521 sec/step, loss=0.09418, avg_loss=0.08825, mel_loss=0.04221, linear_loss=0.05197]
[2020-05-12 08:13:08.537]  Step 156517  [3.644 sec/step, loss=0.08303, avg_loss=0.08830, mel_loss=0.03887, linear_loss=0.04416]
[2020-05-12 08:13:09.035]  Generated 32 batches of size 32 in 26.698 sec
[2020-05-12 08:13:09.344]  Step 156518  [3.646 sec/step, loss=0.07103, avg_loss=0.08832, mel_loss=0.03036, linear_loss=0.04067]
[2020-05-12 08:13:13.063]  Step 156519  [3.620 sec/step, loss=0.09470, avg_loss=0.08833, mel_loss=0.04214, linear_loss=0.05256]
[2020-05-12 08:13:13.955]  Step 156520  [3.608 sec/step, loss=0.08103, avg_loss=0.08827, mel_loss=0.03443, linear_loss=0.04661]
[2020-05-12 08:13:17.419]  Step 156521  [3.611 sec/step, loss=0.09214, avg_loss=0.08824, mel_loss=0.04100, linear_loss=0.05113]
[2020-05-12 08:13:31.452]  Step 156522  [3.665 sec/step, loss=0.07490, avg_loss=0.08806, mel_loss=0.03525, linear_loss=0.03965]
[2020-05-12 08:13:39.320]  Step 156523  [3.691 sec/step, loss=0.09710, avg_loss=0.08808, mel_loss=0.04447, linear_loss=0.05264]
[2020-05-12 08:13:42.786]  Step 156524  [3.701 sec/step, loss=0.09279, avg_loss=0.08811, mel_loss=0.04098, linear_loss=0.05181]
[2020-05-12 08:13:46.485]  Step 156525  [3.697 sec/step, loss=0.09559, avg_loss=0.08811, mel_loss=0.04262, linear_loss=0.05297]
[2020-05-12 08:13:47.485]  Step 156526  [3.693 sec/step, loss=0.07689, avg_loss=0.08804, mel_loss=0.03298, linear_loss=0.04392]
[2020-05-12 08:13:48.881]  Step 156527  [3.680 sec/step, loss=0.08300, avg_loss=0.08796, mel_loss=0.03590, linear_loss=0.04711]
[2020-05-12 08:13:50.656]  Step 156528  [3.689 sec/step, loss=0.08780, avg_loss=0.08807, mel_loss=0.03785, linear_loss=0.04994]
[2020-05-12 08:13:53.835]  Step 156529  [3.703 sec/step, loss=0.09531, avg_loss=0.08816, mel_loss=0.04236, linear_loss=0.05296]
[2020-05-12 08:13:54.949]  Step 156530  [3.688 sec/step, loss=0.08182, avg_loss=0.08807, mel_loss=0.03507, linear_loss=0.04676]
[2020-05-12 08:13:55.715]  Step 156531  [3.680 sec/step, loss=0.07491, avg_loss=0.08794, mel_loss=0.03216, linear_loss=0.04276]
[2020-05-12 08:14:00.732]  Step 156532  [3.720 sec/step, loss=0.09503, avg_loss=0.08809, mel_loss=0.04282, linear_loss=0.05221]
[2020-05-12 08:14:04.907]  Step 156533  [3.750 sec/step, loss=0.09626, avg_loss=0.08823, mel_loss=0.04321, linear_loss=0.05305]
[2020-05-12 08:14:07.113]  Step 156534  [3.762 sec/step, loss=0.08978, avg_loss=0.08831, mel_loss=0.03915, linear_loss=0.05063]
[2020-05-12 08:14:12.840]  Step 156535  [3.775 sec/step, loss=0.09592, avg_loss=0.08830, mel_loss=0.04359, linear_loss=0.05233]
[2020-05-12 08:14:14.465]  Step 156536  [3.716 sec/step, loss=0.08462, avg_loss=0.08817, mel_loss=0.03677, linear_loss=0.04785]
[2020-05-12 08:14:17.176]  Step 156537  [3.735 sec/step, loss=0.09007, avg_loss=0.08832, mel_loss=0.03994, linear_loss=0.05013]
[2020-05-12 08:14:18.009]  Step 156538  [3.696 sec/step, loss=0.07908, avg_loss=0.08817, mel_loss=0.03343, linear_loss=0.04565]
[2020-05-12 08:14:25.064]  Step 156539  [3.757 sec/step, loss=0.09482, avg_loss=0.08832, mel_loss=0.04318, linear_loss=0.05164]
[2020-05-12 08:14:30.095]  Step 156540  [3.787 sec/step, loss=0.09527, avg_loss=0.08840, mel_loss=0.04247, linear_loss=0.05280]
[2020-05-12 08:14:31.268]  Step 156541  [3.731 sec/step, loss=0.07939, avg_loss=0.08824, mel_loss=0.03419, linear_loss=0.04520]
[2020-05-12 08:14:32.949]  Step 156542  [3.726 sec/step, loss=0.08439, avg_loss=0.08819, mel_loss=0.03663, linear_loss=0.04776]
[2020-05-12 08:14:33.970]  Step 156543  [3.712 sec/step, loss=0.07978, avg_loss=0.08810, mel_loss=0.03416, linear_loss=0.04562]
[2020-05-12 08:14:34.748]  Step 156544  [3.629 sec/step, loss=0.07080, avg_loss=0.08786, mel_loss=0.03075, linear_loss=0.04004]
[2020-05-12 08:14:37.091]  Generated 32 batches of size 32 in 3.115 sec
[2020-05-12 08:14:38.972]  Step 156545  [3.640 sec/step, loss=0.09393, avg_loss=0.08784, mel_loss=0.04194, linear_loss=0.05199]
[2020-05-12 08:14:41.028]  Step 156546  [3.640 sec/step, loss=0.08861, avg_loss=0.08784, mel_loss=0.03859, linear_loss=0.05003]
[2020-05-12 08:14:43.552]  Step 156547  [3.657 sec/step, loss=0.09032, avg_loss=0.08798, mel_loss=0.03942, linear_loss=0.05090]
[2020-05-12 08:14:44.898]  Step 156548  [3.640 sec/step, loss=0.08239, avg_loss=0.08788, mel_loss=0.03562, linear_loss=0.04676]
[2020-05-12 08:14:53.733]  Step 156549  [3.677 sec/step, loss=0.09603, avg_loss=0.08789, mel_loss=0.04420, linear_loss=0.05183]
[2020-05-12 08:14:56.183]  Step 156550  [3.688 sec/step, loss=0.09019, avg_loss=0.08794, mel_loss=0.03954, linear_loss=0.05066]
[2020-05-12 08:14:56.184]  Writing summary at step: 156550
[2020-05-12 08:14:59.194]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156550
[2020-05-12 08:15:00.715]  Saving audio and alignment...
[2020-05-12 08:15:04.122]  Input: 행사 진행에 모든 것을~____________________
[2020-05-12 08:15:09.875]  Step 156551  [3.718 sec/step, loss=0.09414, avg_loss=0.08797, mel_loss=0.04284, linear_loss=0.05130]
[2020-05-12 08:15:11.257]  Step 156552  [3.694 sec/step, loss=0.08304, avg_loss=0.08785, mel_loss=0.03604, linear_loss=0.04700]
[2020-05-12 08:15:12.442]  Step 156553  [3.665 sec/step, loss=0.07966, avg_loss=0.08771, mel_loss=0.03388, linear_loss=0.04578]
[2020-05-12 08:15:13.205]  Step 156554  [3.616 sec/step, loss=0.07730, avg_loss=0.08752, mel_loss=0.03279, linear_loss=0.04451]
[2020-05-12 08:15:19.897]  Step 156555  [3.669 sec/step, loss=0.09620, avg_loss=0.08765, mel_loss=0.04366, linear_loss=0.05254]
[2020-05-12 08:15:20.757]  Step 156556  [3.557 sec/step, loss=0.07163, avg_loss=0.08748, mel_loss=0.03121, linear_loss=0.04042]
[2020-05-12 08:15:21.847]  Step 156557  [3.530 sec/step, loss=0.08102, avg_loss=0.08737, mel_loss=0.03459, linear_loss=0.04643]
[2020-05-12 08:15:22.832]  Step 156558  [3.534 sec/step, loss=0.08103, avg_loss=0.08748, mel_loss=0.03465, linear_loss=0.04639]
[2020-05-12 08:15:26.626]  Step 156559  [3.494 sec/step, loss=0.09457, avg_loss=0.08747, mel_loss=0.04221, linear_loss=0.05236]
[2020-05-12 08:15:28.187]  Step 156560  [3.457 sec/step, loss=0.08558, avg_loss=0.08738, mel_loss=0.03707, linear_loss=0.04851]
[2020-05-12 08:15:29.901]  Step 156561  [3.446 sec/step, loss=0.08891, avg_loss=0.08737, mel_loss=0.03842, linear_loss=0.05049]
[2020-05-12 08:15:32.597]  Step 156562  [3.468 sec/step, loss=0.09066, avg_loss=0.08758, mel_loss=0.03969, linear_loss=0.05097]
[2020-05-12 08:15:35.336]  Step 156563  [3.427 sec/step, loss=0.09095, avg_loss=0.08754, mel_loss=0.04015, linear_loss=0.05080]
[2020-05-12 08:15:37.828]  Step 156564  [3.417 sec/step, loss=0.08925, avg_loss=0.08750, mel_loss=0.03893, linear_loss=0.05032]
[2020-05-12 08:15:39.724]  Step 156565  [3.422 sec/step, loss=0.08665, avg_loss=0.08751, mel_loss=0.03762, linear_loss=0.04903]
[2020-05-12 08:15:41.457]  Step 156566  [3.423 sec/step, loss=0.08704, avg_loss=0.08750, mel_loss=0.03782, linear_loss=0.04922]
[2020-05-12 08:15:54.565]  Step 156567  [3.408 sec/step, loss=0.08370, avg_loss=0.08759, mel_loss=0.03928, linear_loss=0.04442]
[2020-05-12 08:15:58.090]  Step 156568  [3.385 sec/step, loss=0.09302, avg_loss=0.08756, mel_loss=0.04146, linear_loss=0.05156]
[2020-05-12 08:16:06.854]  Step 156569  [3.438 sec/step, loss=0.09396, avg_loss=0.08757, mel_loss=0.04322, linear_loss=0.05073]
[2020-05-12 08:16:11.091]  Step 156570  [3.437 sec/step, loss=0.09453, avg_loss=0.08758, mel_loss=0.04210, linear_loss=0.05243]
[2020-05-12 08:16:14.665]  Step 156571  [3.411 sec/step, loss=0.09345, avg_loss=0.08756, mel_loss=0.04163, linear_loss=0.05181]
[2020-05-12 08:16:19.539]  Step 156572  [3.441 sec/step, loss=0.09398, avg_loss=0.08769, mel_loss=0.04225, linear_loss=0.05173]
[2020-05-12 08:16:21.780]  Step 156573  [3.451 sec/step, loss=0.08826, avg_loss=0.08783, mel_loss=0.03889, linear_loss=0.04937]
[2020-05-12 08:16:23.153]  Step 156574  [3.432 sec/step, loss=0.08372, avg_loss=0.08777, mel_loss=0.03604, linear_loss=0.04768]
[2020-05-12 08:16:23.715]  Step 156575  [3.423 sec/step, loss=0.07206, avg_loss=0.08764, mel_loss=0.03119, linear_loss=0.04087]
[2020-05-12 08:16:23.918]  Generated 32 batches of size 32 in 2.133 sec
[2020-05-12 08:16:25.762]  Step 156576  [3.424 sec/step, loss=0.08866, avg_loss=0.08765, mel_loss=0.03881, linear_loss=0.04985]
[2020-05-12 08:16:28.702]  Step 156577  [3.433 sec/step, loss=0.09319, avg_loss=0.08771, mel_loss=0.04113, linear_loss=0.05206]
[2020-05-12 08:16:36.239]  Step 156578  [3.499 sec/step, loss=0.09599, avg_loss=0.08789, mel_loss=0.04398, linear_loss=0.05202]
[2020-05-12 08:16:39.297]  Step 156579  [3.436 sec/step, loss=0.09343, avg_loss=0.08787, mel_loss=0.04120, linear_loss=0.05223]
[2020-05-12 08:16:41.435]  Step 156580  [3.433 sec/step, loss=0.08952, avg_loss=0.08786, mel_loss=0.03943, linear_loss=0.05010]
[2020-05-12 08:16:45.853]  Step 156581  [3.456 sec/step, loss=0.09670, avg_loss=0.08794, mel_loss=0.04331, linear_loss=0.05339]
[2020-05-12 08:16:46.710]  Step 156582  [3.446 sec/step, loss=0.08037, avg_loss=0.08787, mel_loss=0.03384, linear_loss=0.04653]
[2020-05-12 08:16:47.564]  Step 156583  [3.424 sec/step, loss=0.07520, avg_loss=0.08769, mel_loss=0.03235, linear_loss=0.04284]
[2020-05-12 08:16:48.388]  Step 156584  [3.409 sec/step, loss=0.07171, avg_loss=0.08751, mel_loss=0.03057, linear_loss=0.04114]
[2020-05-12 08:16:50.048]  Step 156585  [3.419 sec/step, loss=0.08505, avg_loss=0.08763, mel_loss=0.03714, linear_loss=0.04791]
[2020-05-12 08:16:56.490]  Step 156586  [3.472 sec/step, loss=0.09603, avg_loss=0.08778, mel_loss=0.04386, linear_loss=0.05218]
[2020-05-12 08:16:57.925]  Step 156587  [3.450 sec/step, loss=0.08701, avg_loss=0.08769, mel_loss=0.03779, linear_loss=0.04922]
[2020-05-12 08:17:01.920]  Step 156588  [3.479 sec/step, loss=0.09377, avg_loss=0.08782, mel_loss=0.04171, linear_loss=0.05206]
[2020-05-12 08:17:03.229]  Step 156589  [3.445 sec/step, loss=0.08222, avg_loss=0.08768, mel_loss=0.03537, linear_loss=0.04685]
[2020-05-12 08:17:10.811]  Step 156590  [3.504 sec/step, loss=0.09725, avg_loss=0.08778, mel_loss=0.04426, linear_loss=0.05299]
[2020-05-12 08:17:15.719]  Step 156591  [3.346 sec/step, loss=0.09425, avg_loss=0.08787, mel_loss=0.04246, linear_loss=0.05179]
[2020-05-12 08:17:17.504]  Step 156592  [3.307 sec/step, loss=0.08570, avg_loss=0.08777, mel_loss=0.03716, linear_loss=0.04854]
[2020-05-12 08:17:21.089]  Step 156593  [3.255 sec/step, loss=0.09392, avg_loss=0.08777, mel_loss=0.04191, linear_loss=0.05201]
[2020-05-12 08:17:23.030]  Step 156594  [3.261 sec/step, loss=0.08627, avg_loss=0.08782, mel_loss=0.03733, linear_loss=0.04894]
[2020-05-12 08:17:25.918]  Step 156595  [3.279 sec/step, loss=0.09101, avg_loss=0.08794, mel_loss=0.04036, linear_loss=0.05065]
[2020-05-12 08:17:26.966]  Step 156596  [3.281 sec/step, loss=0.07767, avg_loss=0.08792, mel_loss=0.03323, linear_loss=0.04444]
[2020-05-12 08:17:28.021]  Step 156597  [3.224 sec/step, loss=0.08147, avg_loss=0.08777, mel_loss=0.03487, linear_loss=0.04660]
[2020-05-12 08:17:33.826]  Step 156598  [3.262 sec/step, loss=0.09725, avg_loss=0.08785, mel_loss=0.04402, linear_loss=0.05323]
[2020-05-12 08:17:36.318]  Step 156599  [3.252 sec/step, loss=0.09004, avg_loss=0.08782, mel_loss=0.03929, linear_loss=0.05075]
[2020-05-12 08:17:38.162]  Step 156600  [3.258 sec/step, loss=0.08694, avg_loss=0.08787, mel_loss=0.03775, linear_loss=0.04919]
[2020-05-12 08:17:38.163]  Writing summary at step: 156600
[2020-05-12 08:17:46.323]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156600
[2020-05-12 08:17:47.936]  Saving audio and alignment...
[2020-05-12 08:17:53.391]  Input: 습도가 조금만 높아도 잎사귀에 곰팡이가 생겼고요~_____________________
[2020-05-12 08:17:58.806]  Step 156601  [3.294 sec/step, loss=0.09636, avg_loss=0.08797, mel_loss=0.04323, linear_loss=0.05313]
[2020-05-12 08:17:59.957]  Step 156602  [3.252 sec/step, loss=0.08147, avg_loss=0.08783, mel_loss=0.03488, linear_loss=0.04659]
[2020-05-12 08:18:00.517]  Step 156603  [3.233 sec/step, loss=0.07220, avg_loss=0.08767, mel_loss=0.03203, linear_loss=0.04017]
[2020-05-12 08:18:02.230]  Generated 32 batches of size 32 in 1.708 sec
[2020-05-12 08:18:02.736]  Step 156604  [3.183 sec/step, loss=0.08952, avg_loss=0.08761, mel_loss=0.03908, linear_loss=0.05044]
[2020-05-12 08:18:05.743]  Step 156605  [3.191 sec/step, loss=0.09333, avg_loss=0.08765, mel_loss=0.04124, linear_loss=0.05209]
[2020-05-12 08:18:08.947]  Step 156606  [3.176 sec/step, loss=0.09316, avg_loss=0.08763, mel_loss=0.04123, linear_loss=0.05194]
[2020-05-12 08:18:21.345]  Step 156607  [3.266 sec/step, loss=0.08331, avg_loss=0.08752, mel_loss=0.03886, linear_loss=0.04445]
[2020-05-12 08:18:25.854]  Step 156608  [3.289 sec/step, loss=0.09584, avg_loss=0.08760, mel_loss=0.04300, linear_loss=0.05284]
[2020-05-12 08:18:29.619]  Step 156609  [3.285 sec/step, loss=0.09541, avg_loss=0.08761, mel_loss=0.04239, linear_loss=0.05301]
[2020-05-12 08:18:32.370]  Step 156610  [3.298 sec/step, loss=0.09186, avg_loss=0.08768, mel_loss=0.04051, linear_loss=0.05135]
[2020-05-12 08:18:33.725]  Step 156611  [3.282 sec/step, loss=0.08390, avg_loss=0.08759, mel_loss=0.03609, linear_loss=0.04781]
[2020-05-12 08:18:35.960]  Step 156612  [3.272 sec/step, loss=0.09086, avg_loss=0.08757, mel_loss=0.04000, linear_loss=0.05086]
[2020-05-12 08:18:36.987]  Step 156613  [3.263 sec/step, loss=0.08248, avg_loss=0.08750, mel_loss=0.03512, linear_loss=0.04736]
[2020-05-12 08:18:37.936]  Step 156614  [3.245 sec/step, loss=0.08175, avg_loss=0.08740, mel_loss=0.03495, linear_loss=0.04680]
[2020-05-12 08:18:38.762]  Step 156615  [3.248 sec/step, loss=0.07650, avg_loss=0.08746, mel_loss=0.03257, linear_loss=0.04393]
[2020-05-12 08:18:40.607]  Step 156616  [3.222 sec/step, loss=0.08509, avg_loss=0.08737, mel_loss=0.03661, linear_loss=0.04848]
[2020-05-12 08:18:42.297]  Step 156617  [3.106 sec/step, loss=0.08931, avg_loss=0.08743, mel_loss=0.03859, linear_loss=0.05072]
[2020-05-12 08:18:48.329]  Step 156618  [3.158 sec/step, loss=0.09484, avg_loss=0.08767, mel_loss=0.04317, linear_loss=0.05168]
[2020-05-12 08:18:50.539]  Step 156619  [3.143 sec/step, loss=0.08896, avg_loss=0.08761, mel_loss=0.03891, linear_loss=0.05004]
[2020-05-12 08:18:52.167]  Step 156620  [3.150 sec/step, loss=0.08790, avg_loss=0.08768, mel_loss=0.03816, linear_loss=0.04974]
[2020-05-12 08:18:57.047]  Step 156621  [3.164 sec/step, loss=0.09475, avg_loss=0.08771, mel_loss=0.04247, linear_loss=0.05228]
[2020-05-12 08:18:58.189]  Step 156622  [3.035 sec/step, loss=0.08215, avg_loss=0.08778, mel_loss=0.03505, linear_loss=0.04709]
[2020-05-12 08:19:06.573]  Step 156623  [3.041 sec/step, loss=0.09391, avg_loss=0.08775, mel_loss=0.04315, linear_loss=0.05077]
[2020-05-12 08:19:07.890]  Step 156624  [3.019 sec/step, loss=0.08153, avg_loss=0.08763, mel_loss=0.03493, linear_loss=0.04661]
[2020-05-12 08:19:10.337]  Step 156625  [3.007 sec/step, loss=0.09078, avg_loss=0.08759, mel_loss=0.03984, linear_loss=0.05094]
[2020-05-12 08:19:14.829]  Step 156626  [3.042 sec/step, loss=0.09575, avg_loss=0.08777, mel_loss=0.04304, linear_loss=0.05271]
[2020-05-12 08:19:22.128]  Step 156627  [3.101 sec/step, loss=0.09657, avg_loss=0.08791, mel_loss=0.04409, linear_loss=0.05248]
[2020-05-12 08:19:25.060]  Step 156628  [3.112 sec/step, loss=0.09156, avg_loss=0.08795, mel_loss=0.04058, linear_loss=0.05099]
[2020-05-12 08:19:27.826]  Step 156629  [3.108 sec/step, loss=0.08810, avg_loss=0.08788, mel_loss=0.03862, linear_loss=0.04948]
[2020-05-12 08:19:32.263]  Step 156630  [3.141 sec/step, loss=0.09465, avg_loss=0.08800, mel_loss=0.04221, linear_loss=0.05245]
[2020-05-12 08:19:37.979]  Step 156631  [3.191 sec/step, loss=0.09552, avg_loss=0.08821, mel_loss=0.04303, linear_loss=0.05249]
[2020-05-12 08:19:38.865]  Step 156632  [3.149 sec/step, loss=0.07233, avg_loss=0.08798, mel_loss=0.03130, linear_loss=0.04103]
[2020-05-12 08:19:41.852]  Step 156633  [3.138 sec/step, loss=0.09217, avg_loss=0.08794, mel_loss=0.04063, linear_loss=0.05154]
[2020-05-12 08:19:56.198]  Step 156634  [3.259 sec/step, loss=0.07197, avg_loss=0.08776, mel_loss=0.03378, linear_loss=0.03820]
[2020-05-12 08:19:59.835]  Step 156635  [3.238 sec/step, loss=0.09453, avg_loss=0.08775, mel_loss=0.04187, linear_loss=0.05266]
[2020-05-12 08:20:01.643]  Generated 32 batches of size 32 in 1.803 sec
[2020-05-12 08:20:02.033]  Step 156636  [3.244 sec/step, loss=0.08922, avg_loss=0.08780, mel_loss=0.03907, linear_loss=0.05015]
[2020-05-12 08:20:02.891]  Step 156637  [3.225 sec/step, loss=0.07943, avg_loss=0.08769, mel_loss=0.03357, linear_loss=0.04586]
[2020-05-12 08:20:04.216]  Step 156638  [3.230 sec/step, loss=0.08575, avg_loss=0.08776, mel_loss=0.03700, linear_loss=0.04875]
[2020-05-12 08:20:04.774]  Step 156639  [3.165 sec/step, loss=0.06740, avg_loss=0.08748, mel_loss=0.02909, linear_loss=0.03831]
[2020-05-12 08:20:08.767]  Step 156640  [3.155 sec/step, loss=0.09454, avg_loss=0.08747, mel_loss=0.04231, linear_loss=0.05223]
[2020-05-12 08:20:12.159]  Step 156641  [3.177 sec/step, loss=0.09224, avg_loss=0.08760, mel_loss=0.04106, linear_loss=0.05118]
[2020-05-12 08:20:13.639]  Step 156642  [3.175 sec/step, loss=0.08504, avg_loss=0.08761, mel_loss=0.03669, linear_loss=0.04835]
[2020-05-12 08:20:15.640]  Step 156643  [3.185 sec/step, loss=0.08820, avg_loss=0.08769, mel_loss=0.03860, linear_loss=0.04960]
[2020-05-12 08:20:18.970]  Step 156644  [3.210 sec/step, loss=0.09517, avg_loss=0.08794, mel_loss=0.04218, linear_loss=0.05299]
[2020-05-12 08:20:27.925]  Step 156645  [3.258 sec/step, loss=0.09553, avg_loss=0.08795, mel_loss=0.04347, linear_loss=0.05206]
[2020-05-12 08:20:31.899]  Step 156646  [3.277 sec/step, loss=0.08723, avg_loss=0.08794, mel_loss=0.03810, linear_loss=0.04913]
[2020-05-12 08:20:42.461]  Step 156647  [3.357 sec/step, loss=0.09451, avg_loss=0.08798, mel_loss=0.04354, linear_loss=0.05097]
[2020-05-12 08:20:45.648]  Step 156648  [3.376 sec/step, loss=0.09317, avg_loss=0.08809, mel_loss=0.04130, linear_loss=0.05186]
[2020-05-12 08:20:51.009]  Step 156649  [3.341 sec/step, loss=0.09632, avg_loss=0.08809, mel_loss=0.04341, linear_loss=0.05290]
[2020-05-12 08:20:53.132]  Step 156650  [3.338 sec/step, loss=0.08928, avg_loss=0.08808, mel_loss=0.03892, linear_loss=0.05035]
[2020-05-12 08:20:53.132]  Writing summary at step: 156650
[2020-05-12 08:21:00.036]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156650
[2020-05-12 08:21:01.645]  Saving audio and alignment...
[2020-05-12 08:21:03.883]  Input: 파랑은 곧~_________________
[2020-05-12 08:21:05.247]  Step 156651  [3.294 sec/step, loss=0.08491, avg_loss=0.08799, mel_loss=0.03671, linear_loss=0.04820]
[2020-05-12 08:21:10.974]  Step 156652  [3.337 sec/step, loss=0.09624, avg_loss=0.08812, mel_loss=0.04380, linear_loss=0.05244]
[2020-05-12 08:21:13.668]  Step 156653  [3.352 sec/step, loss=0.08967, avg_loss=0.08822, mel_loss=0.03968, linear_loss=0.04999]
[2020-05-12 08:21:15.149]  Step 156654  [3.359 sec/step, loss=0.08378, avg_loss=0.08829, mel_loss=0.03625, linear_loss=0.04753]
[2020-05-12 08:21:16.404]  Step 156655  [3.305 sec/step, loss=0.08030, avg_loss=0.08813, mel_loss=0.03483, linear_loss=0.04547]
[2020-05-12 08:21:18.683]  Step 156656  [3.319 sec/step, loss=0.08955, avg_loss=0.08831, mel_loss=0.03931, linear_loss=0.05024]
[2020-05-12 08:21:21.662]  Step 156657  [3.338 sec/step, loss=0.09409, avg_loss=0.08844, mel_loss=0.04177, linear_loss=0.05232]
[2020-05-12 08:21:23.458]  Step 156658  [3.346 sec/step, loss=0.08733, avg_loss=0.08850, mel_loss=0.03810, linear_loss=0.04923]
[2020-05-12 08:21:24.257]  Step 156659  [3.316 sec/step, loss=0.07476, avg_loss=0.08830, mel_loss=0.03178, linear_loss=0.04298]
[2020-05-12 08:21:28.715]  Step 156660  [3.345 sec/step, loss=0.09599, avg_loss=0.08841, mel_loss=0.04310, linear_loss=0.05288]
[2020-05-12 08:21:32.223]  Step 156661  [3.363 sec/step, loss=0.09334, avg_loss=0.08845, mel_loss=0.04179, linear_loss=0.05155]
[2020-05-12 08:21:34.146]  Step 156662  [3.355 sec/step, loss=0.08918, avg_loss=0.08844, mel_loss=0.03867, linear_loss=0.05051]
[2020-05-12 08:21:37.605]  Step 156663  [3.363 sec/step, loss=0.09290, avg_loss=0.08846, mel_loss=0.04136, linear_loss=0.05153]
[2020-05-12 08:21:38.610]  Step 156664  [3.348 sec/step, loss=0.07732, avg_loss=0.08834, mel_loss=0.03277, linear_loss=0.04455]
[2020-05-12 08:21:43.630]  Step 156665  [3.379 sec/step, loss=0.09452, avg_loss=0.08842, mel_loss=0.04242, linear_loss=0.05210]
[2020-05-12 08:21:45.371]  Generated 32 batches of size 32 in 1.736 sec
[2020-05-12 08:21:58.376]  Step 156666  [3.509 sec/step, loss=0.07875, avg_loss=0.08833, mel_loss=0.03716, linear_loss=0.04159]
[2020-05-12 08:21:58.954]  Step 156667  [3.384 sec/step, loss=0.07091, avg_loss=0.08821, mel_loss=0.03133, linear_loss=0.03958]
[2020-05-12 08:21:59.978]  Step 156668  [3.359 sec/step, loss=0.07885, avg_loss=0.08806, mel_loss=0.03373, linear_loss=0.04512]
[2020-05-12 08:22:03.717]  Step 156669  [3.309 sec/step, loss=0.09378, avg_loss=0.08806, mel_loss=0.04191, linear_loss=0.05187]
[2020-05-12 08:22:05.442]  Step 156670  [3.283 sec/step, loss=0.08798, avg_loss=0.08800, mel_loss=0.03827, linear_loss=0.04972]
[2020-05-12 08:22:09.660]  Step 156671  [3.290 sec/step, loss=0.09423, avg_loss=0.08800, mel_loss=0.04190, linear_loss=0.05233]
[2020-05-12 08:22:10.461]  Step 156672  [3.249 sec/step, loss=0.07224, avg_loss=0.08779, mel_loss=0.03126, linear_loss=0.04099]
[2020-05-12 08:22:12.091]  Step 156673  [3.243 sec/step, loss=0.08598, avg_loss=0.08776, mel_loss=0.03731, linear_loss=0.04866]
[2020-05-12 08:22:14.157]  Step 156674  [3.250 sec/step, loss=0.08832, avg_loss=0.08781, mel_loss=0.03851, linear_loss=0.04981]
[2020-05-12 08:22:17.213]  Step 156675  [3.275 sec/step, loss=0.09153, avg_loss=0.08800, mel_loss=0.04032, linear_loss=0.05120]
[2020-05-12 08:22:29.670]  Step 156676  [3.379 sec/step, loss=0.08356, avg_loss=0.08795, mel_loss=0.03908, linear_loss=0.04448]
[2020-05-12 08:22:31.452]  Step 156677  [3.367 sec/step, loss=0.08770, avg_loss=0.08790, mel_loss=0.03793, linear_loss=0.04977]
[2020-05-12 08:22:32.475]  Step 156678  [3.302 sec/step, loss=0.07841, avg_loss=0.08772, mel_loss=0.03377, linear_loss=0.04465]
[2020-05-12 08:22:35.945]  Step 156679  [3.306 sec/step, loss=0.09228, avg_loss=0.08771, mel_loss=0.04089, linear_loss=0.05140]
[2020-05-12 08:22:37.495]  Step 156680  [3.301 sec/step, loss=0.08374, avg_loss=0.08765, mel_loss=0.03623, linear_loss=0.04752]
[2020-05-12 08:22:40.365]  Step 156681  [3.285 sec/step, loss=0.09284, avg_loss=0.08761, mel_loss=0.04102, linear_loss=0.05182]
[2020-05-12 08:22:42.288]  Step 156682  [3.296 sec/step, loss=0.08727, avg_loss=0.08768, mel_loss=0.03798, linear_loss=0.04929]
[2020-05-12 08:22:47.378]  Step 156683  [3.338 sec/step, loss=0.09406, avg_loss=0.08787, mel_loss=0.04223, linear_loss=0.05183]
[2020-05-12 08:22:51.111]  Step 156684  [3.367 sec/step, loss=0.09451, avg_loss=0.08810, mel_loss=0.04196, linear_loss=0.05255]
[2020-05-12 08:22:58.486]  Step 156685  [3.424 sec/step, loss=0.09637, avg_loss=0.08821, mel_loss=0.04402, linear_loss=0.05235]
[2020-05-12 08:23:03.048]  Step 156686  [3.406 sec/step, loss=0.09566, avg_loss=0.08821, mel_loss=0.04288, linear_loss=0.05279]
[2020-05-12 08:23:05.377]  Step 156687  [3.414 sec/step, loss=0.08980, avg_loss=0.08824, mel_loss=0.03957, linear_loss=0.05022]
[2020-05-12 08:23:06.274]  Step 156688  [3.383 sec/step, loss=0.07719, avg_loss=0.08807, mel_loss=0.03260, linear_loss=0.04459]
[2020-05-12 08:23:14.811]  Step 156689  [3.456 sec/step, loss=0.09473, avg_loss=0.08820, mel_loss=0.04363, linear_loss=0.05110]
[2020-05-12 08:23:15.899]  Step 156690  [3.391 sec/step, loss=0.08160, avg_loss=0.08804, mel_loss=0.03472, linear_loss=0.04688]
[2020-05-12 08:23:17.259]  Step 156691  [3.355 sec/step, loss=0.08650, avg_loss=0.08796, mel_loss=0.03732, linear_loss=0.04918]
[2020-05-12 08:23:21.553]  Step 156692  [3.380 sec/step, loss=0.09329, avg_loss=0.08804, mel_loss=0.04160, linear_loss=0.05169]
[2020-05-12 08:23:22.877]  Step 156693  [3.358 sec/step, loss=0.08560, avg_loss=0.08796, mel_loss=0.03692, linear_loss=0.04869]
[2020-05-12 08:23:23.686]  Step 156694  [3.347 sec/step, loss=0.07515, avg_loss=0.08784, mel_loss=0.03213, linear_loss=0.04302]
[2020-05-12 08:23:25.720]  Step 156695  [3.338 sec/step, loss=0.08809, avg_loss=0.08782, mel_loss=0.03840, linear_loss=0.04968]
[2020-05-12 08:23:32.120]  Step 156696  [3.392 sec/step, loss=0.09612, avg_loss=0.08800, mel_loss=0.04369, linear_loss=0.05243]
[2020-05-12 08:23:35.481]  Step 156697  [3.415 sec/step, loss=0.09385, avg_loss=0.08812, mel_loss=0.04164, linear_loss=0.05222]
[2020-05-12 08:23:39.145]  Step 156698  [3.393 sec/step, loss=0.09372, avg_loss=0.08809, mel_loss=0.04162, linear_loss=0.05210]
[2020-05-12 08:23:39.714]  Step 156699  [3.374 sec/step, loss=0.06929, avg_loss=0.08788, mel_loss=0.03045, linear_loss=0.03884]
[2020-05-12 08:23:42.545]  Step 156700  [3.384 sec/step, loss=0.08955, avg_loss=0.08791, mel_loss=0.03947, linear_loss=0.05008]
[2020-05-12 08:23:42.545]  Writing summary at step: 156700
[2020-05-12 08:23:42.728]  Generated 32 batches of size 32 in 7.242 sec
[2020-05-12 08:23:44.237]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156700
[2020-05-12 08:23:45.829]  Saving audio and alignment...
[2020-05-12 08:23:49.899]  Input: 참 아까 성함이 뭐라고 하셨더라~____________________
[2020-05-12 08:23:50.739]  Step 156701  [3.338 sec/step, loss=0.07390, avg_loss=0.08768, mel_loss=0.03155, linear_loss=0.04234]
[2020-05-12 08:23:56.404]  Step 156702  [3.383 sec/step, loss=0.09608, avg_loss=0.08783, mel_loss=0.04350, linear_loss=0.05258]
[2020-05-12 08:23:57.580]  Step 156703  [3.389 sec/step, loss=0.08165, avg_loss=0.08792, mel_loss=0.03508, linear_loss=0.04657]
[2020-05-12 08:23:59.758]  Step 156704  [3.389 sec/step, loss=0.09065, avg_loss=0.08793, mel_loss=0.03962, linear_loss=0.05103]
[2020-05-12 08:24:01.714]  Step 156705  [3.378 sec/step, loss=0.08743, avg_loss=0.08788, mel_loss=0.03793, linear_loss=0.04950]
[2020-05-12 08:24:02.587]  Step 156706  [3.355 sec/step, loss=0.07087, avg_loss=0.08765, mel_loss=0.03065, linear_loss=0.04022]
[2020-05-12 08:24:03.585]  Step 156707  [3.241 sec/step, loss=0.07944, avg_loss=0.08761, mel_loss=0.03384, linear_loss=0.04560]
[2020-05-12 08:24:05.772]  Step 156708  [3.218 sec/step, loss=0.08976, avg_loss=0.08755, mel_loss=0.03951, linear_loss=0.05025]
[2020-05-12 08:24:09.918]  Step 156709  [3.222 sec/step, loss=0.09352, avg_loss=0.08753, mel_loss=0.04173, linear_loss=0.05178]
[2020-05-12 08:24:11.270]  Step 156710  [3.208 sec/step, loss=0.08435, avg_loss=0.08746, mel_loss=0.03632, linear_loss=0.04803]
[2020-05-12 08:24:24.375]  Step 156711  [3.325 sec/step, loss=0.08261, avg_loss=0.08745, mel_loss=0.03868, linear_loss=0.04393]
[2020-05-12 08:24:27.831]  Step 156712  [3.337 sec/step, loss=0.09299, avg_loss=0.08747, mel_loss=0.04139, linear_loss=0.05159]
[2020-05-12 08:24:34.658]  Step 156713  [3.395 sec/step, loss=0.09452, avg_loss=0.08759, mel_loss=0.04287, linear_loss=0.05165]
[2020-05-12 08:24:37.109]  Step 156714  [3.410 sec/step, loss=0.08968, avg_loss=0.08767, mel_loss=0.03957, linear_loss=0.05011]
[2020-05-12 08:24:38.655]  Step 156715  [3.418 sec/step, loss=0.08734, avg_loss=0.08778, mel_loss=0.03789, linear_loss=0.04945]
[2020-05-12 08:24:41.448]  Step 156716  [3.427 sec/step, loss=0.08920, avg_loss=0.08782, mel_loss=0.03906, linear_loss=0.05014]
[2020-05-12 08:24:42.433]  Step 156717  [3.420 sec/step, loss=0.08023, avg_loss=0.08773, mel_loss=0.03425, linear_loss=0.04598]
[2020-05-12 08:24:46.121]  Step 156718  [3.397 sec/step, loss=0.09204, avg_loss=0.08770, mel_loss=0.04077, linear_loss=0.05127]
[2020-05-12 08:24:50.972]  Step 156719  [3.423 sec/step, loss=0.09494, avg_loss=0.08776, mel_loss=0.04248, linear_loss=0.05246]
[2020-05-12 08:24:53.907]  Step 156720  [3.436 sec/step, loss=0.09289, avg_loss=0.08781, mel_loss=0.04117, linear_loss=0.05173]
[2020-05-12 08:24:54.720]  Step 156721  [3.395 sec/step, loss=0.07508, avg_loss=0.08761, mel_loss=0.03207, linear_loss=0.04301]
[2020-05-12 08:24:56.149]  Step 156722  [3.398 sec/step, loss=0.08247, avg_loss=0.08761, mel_loss=0.03579, linear_loss=0.04668]
[2020-05-12 08:24:58.801]  Step 156723  [3.341 sec/step, loss=0.09154, avg_loss=0.08759, mel_loss=0.04042, linear_loss=0.05111]
[2020-05-12 08:25:04.576]  Step 156724  [3.386 sec/step, loss=0.09547, avg_loss=0.08773, mel_loss=0.04329, linear_loss=0.05218]
[2020-05-12 08:25:05.701]  Step 156725  [3.372 sec/step, loss=0.08337, avg_loss=0.08766, mel_loss=0.03550, linear_loss=0.04787]
[2020-05-12 08:25:10.956]  Step 156726  [3.380 sec/step, loss=0.09402, avg_loss=0.08764, mel_loss=0.04229, linear_loss=0.05173]
[2020-05-12 08:25:14.096]  Step 156727  [3.338 sec/step, loss=0.09405, avg_loss=0.08761, mel_loss=0.04145, linear_loss=0.05260]
[2020-05-12 08:25:18.634]  Generated 32 batches of size 32 in 4.532 sec
[2020-05-12 08:25:21.813]  Step 156728  [3.386 sec/step, loss=0.09677, avg_loss=0.08766, mel_loss=0.04424, linear_loss=0.05253]
[2020-05-12 08:25:30.698]  Step 156729  [3.447 sec/step, loss=0.09487, avg_loss=0.08773, mel_loss=0.04363, linear_loss=0.05124]
[2020-05-12 08:25:32.709]  Step 156730  [3.423 sec/step, loss=0.08989, avg_loss=0.08768, mel_loss=0.03936, linear_loss=0.05053]
[2020-05-12 08:25:36.360]  Step 156731  [3.403 sec/step, loss=0.09536, avg_loss=0.08768, mel_loss=0.04236, linear_loss=0.05300]
[2020-05-12 08:25:38.150]  Step 156732  [3.412 sec/step, loss=0.08562, avg_loss=0.08782, mel_loss=0.03698, linear_loss=0.04864]
[2020-05-12 08:25:39.877]  Step 156733  [3.399 sec/step, loss=0.08887, avg_loss=0.08778, mel_loss=0.03852, linear_loss=0.05035]
[2020-05-12 08:25:44.002]  Step 156734  [3.297 sec/step, loss=0.09549, avg_loss=0.08802, mel_loss=0.04230, linear_loss=0.05319]
[2020-05-12 08:25:45.227]  Step 156735  [3.273 sec/step, loss=0.08283, avg_loss=0.08790, mel_loss=0.03554, linear_loss=0.04730]
[2020-05-12 08:25:45.820]  Step 156736  [3.257 sec/step, loss=0.06863, avg_loss=0.08770, mel_loss=0.03056, linear_loss=0.03807]
[2020-05-12 08:25:48.819]  Step 156737  [3.278 sec/step, loss=0.09376, avg_loss=0.08784, mel_loss=0.04150, linear_loss=0.05226]
[2020-05-12 08:25:52.933]  Step 156738  [3.306 sec/step, loss=0.09250, avg_loss=0.08791, mel_loss=0.04139, linear_loss=0.05111]
[2020-05-12 08:25:54.749]  Step 156739  [3.318 sec/step, loss=0.08737, avg_loss=0.08811, mel_loss=0.03809, linear_loss=0.04928]
[2020-05-12 08:25:56.364]  Step 156740  [3.295 sec/step, loss=0.08743, avg_loss=0.08803, mel_loss=0.03789, linear_loss=0.04955]
[2020-05-12 08:25:59.161]  Step 156741  [3.289 sec/step, loss=0.09119, avg_loss=0.08802, mel_loss=0.04029, linear_loss=0.05090]
[2020-05-12 08:26:13.490]  Step 156742  [3.417 sec/step, loss=0.07388, avg_loss=0.08791, mel_loss=0.03487, linear_loss=0.03901]
[2020-05-12 08:26:20.805]  Step 156743  [3.470 sec/step, loss=0.09568, avg_loss=0.08799, mel_loss=0.04365, linear_loss=0.05203]
[2020-05-12 08:26:26.902]  Step 156744  [3.498 sec/step, loss=0.09376, avg_loss=0.08797, mel_loss=0.04254, linear_loss=0.05122]
[2020-05-12 08:26:35.151]  Step 156745  [3.491 sec/step, loss=0.09283, avg_loss=0.08795, mel_loss=0.04249, linear_loss=0.05033]
[2020-05-12 08:26:35.924]  Step 156746  [3.459 sec/step, loss=0.07627, avg_loss=0.08784, mel_loss=0.03240, linear_loss=0.04387]
[2020-05-12 08:26:37.008]  Step 156747  [3.364 sec/step, loss=0.08288, avg_loss=0.08772, mel_loss=0.03526, linear_loss=0.04761]
[2020-05-12 08:26:37.633]  Step 156748  [3.339 sec/step, loss=0.07469, avg_loss=0.08754, mel_loss=0.03219, linear_loss=0.04250]
[2020-05-12 08:26:38.963]  Step 156749  [3.298 sec/step, loss=0.08427, avg_loss=0.08742, mel_loss=0.03626, linear_loss=0.04800]
[2020-05-12 08:26:41.205]  Step 156750  [3.299 sec/step, loss=0.08838, avg_loss=0.08741, mel_loss=0.03861, linear_loss=0.04977]
[2020-05-12 08:26:41.206]  Writing summary at step: 156750
[2020-05-12 08:26:43.818]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156750
[2020-05-12 08:26:47.368]  Saving audio and alignment...
[2020-05-12 08:26:54.056]  Input: 부산 해운대를 주름잡는 패셔니스타가 떳다 이러겠지만 성우들 어떻게 해요~___________
[2020-05-12 08:26:57.690]  Step 156751  [3.322 sec/step, loss=0.09452, avg_loss=0.08750, mel_loss=0.04213, linear_loss=0.05239]
[2020-05-12 08:27:02.724]  Step 156752  [3.315 sec/step, loss=0.09630, avg_loss=0.08750, mel_loss=0.04364, linear_loss=0.05266]
[2020-05-12 08:27:07.284]  Step 156753  [3.334 sec/step, loss=0.09596, avg_loss=0.08757, mel_loss=0.04312, linear_loss=0.05284]
[2020-05-12 08:27:09.376]  Step 156754  [3.340 sec/step, loss=0.08730, avg_loss=0.08760, mel_loss=0.03797, linear_loss=0.04933]
[2020-05-12 08:27:09.910]  Step 156755  [3.333 sec/step, loss=0.06881, avg_loss=0.08749, mel_loss=0.02946, linear_loss=0.03935]
[2020-05-12 08:27:11.274]  Step 156756  [3.324 sec/step, loss=0.08482, avg_loss=0.08744, mel_loss=0.03641, linear_loss=0.04842]
[2020-05-12 08:27:12.523]  Step 156757  [3.306 sec/step, loss=0.08316, avg_loss=0.08733, mel_loss=0.03589, linear_loss=0.04727]
[2020-05-12 08:27:14.548]  Step 156758  [3.309 sec/step, loss=0.08804, avg_loss=0.08734, mel_loss=0.03809, linear_loss=0.04995]
[2020-05-12 08:27:19.921]  Step 156759  [3.354 sec/step, loss=0.09732, avg_loss=0.08756, mel_loss=0.04409, linear_loss=0.05323]
[2020-05-12 08:27:23.305]  Step 156760  [3.344 sec/step, loss=0.09406, avg_loss=0.08754, mel_loss=0.04168, linear_loss=0.05237]
[2020-05-12 08:27:24.367]  Step 156761  [3.319 sec/step, loss=0.08058, avg_loss=0.08742, mel_loss=0.03443, linear_loss=0.04615]
[2020-05-12 08:27:25.236]  Step 156762  [3.309 sec/step, loss=0.07897, avg_loss=0.08731, mel_loss=0.03310, linear_loss=0.04587]
[2020-05-12 08:27:27.660]  Step 156763  [3.298 sec/step, loss=0.09154, avg_loss=0.08730, mel_loss=0.04010, linear_loss=0.05144]
[2020-05-12 08:27:27.913]  Generated 32 batches of size 32 in 15.384 sec
[2020-05-12 08:27:29.155]  Step 156764  [3.303 sec/step, loss=0.08593, avg_loss=0.08739, mel_loss=0.03730, linear_loss=0.04863]
[2020-05-12 08:27:30.856]  Step 156765  [3.270 sec/step, loss=0.08552, avg_loss=0.08730, mel_loss=0.03752, linear_loss=0.04800]
[2020-05-12 08:27:34.366]  Step 156766  [3.158 sec/step, loss=0.09280, avg_loss=0.08744, mel_loss=0.04127, linear_loss=0.05152]
[2020-05-12 08:27:35.737]  Step 156767  [3.166 sec/step, loss=0.08434, avg_loss=0.08757, mel_loss=0.03633, linear_loss=0.04801]
[2020-05-12 08:27:37.516]  Step 156768  [3.173 sec/step, loss=0.08771, avg_loss=0.08766, mel_loss=0.03767, linear_loss=0.05004]
[2020-05-12 08:27:38.650]  Step 156769  [3.147 sec/step, loss=0.08391, avg_loss=0.08756, mel_loss=0.03587, linear_loss=0.04804]
[2020-05-12 08:27:40.668]  Step 156770  [3.150 sec/step, loss=0.08949, avg_loss=0.08758, mel_loss=0.03912, linear_loss=0.05037]
[2020-05-12 08:27:46.865]  Step 156771  [3.170 sec/step, loss=0.09501, avg_loss=0.08758, mel_loss=0.04306, linear_loss=0.05194]
[2020-05-12 08:27:49.345]  Step 156772  [3.187 sec/step, loss=0.09116, avg_loss=0.08777, mel_loss=0.04004, linear_loss=0.05112]
[2020-05-12 08:27:50.354]  Step 156773  [3.180 sec/step, loss=0.07941, avg_loss=0.08771, mel_loss=0.03376, linear_loss=0.04565]
[2020-05-12 08:27:52.074]  Step 156774  [3.177 sec/step, loss=0.08707, avg_loss=0.08769, mel_loss=0.03779, linear_loss=0.04928]
[2020-05-12 08:27:53.990]  Step 156775  [3.165 sec/step, loss=0.08942, avg_loss=0.08767, mel_loss=0.03913, linear_loss=0.05030]
[2020-05-12 08:27:55.294]  Step 156776  [3.054 sec/step, loss=0.08395, avg_loss=0.08768, mel_loss=0.03623, linear_loss=0.04772]
[2020-05-12 08:27:58.906]  Step 156777  [3.072 sec/step, loss=0.09489, avg_loss=0.08775, mel_loss=0.04232, linear_loss=0.05258]
[2020-05-12 08:28:06.016]  Step 156778  [3.133 sec/step, loss=0.09561, avg_loss=0.08792, mel_loss=0.04356, linear_loss=0.05205]
[2020-05-12 08:28:07.504]  Step 156779  [3.113 sec/step, loss=0.08486, avg_loss=0.08785, mel_loss=0.03666, linear_loss=0.04819]
[2020-05-12 08:28:13.167]  Step 156780  [3.154 sec/step, loss=0.09472, avg_loss=0.08796, mel_loss=0.04288, linear_loss=0.05184]
[2020-05-12 08:28:16.662]  Step 156781  [3.161 sec/step, loss=0.09132, avg_loss=0.08794, mel_loss=0.04085, linear_loss=0.05047]
[2020-05-12 08:28:20.466]  Step 156782  [3.179 sec/step, loss=0.09421, avg_loss=0.08801, mel_loss=0.04186, linear_loss=0.05235]
[2020-05-12 08:28:23.600]  Step 156783  [3.160 sec/step, loss=0.09419, avg_loss=0.08801, mel_loss=0.04163, linear_loss=0.05256]
[2020-05-12 08:28:24.414]  Step 156784  [3.131 sec/step, loss=0.07706, avg_loss=0.08784, mel_loss=0.03283, linear_loss=0.04424]
[2020-05-12 08:28:29.677]  Step 156785  [3.110 sec/step, loss=0.09449, avg_loss=0.08782, mel_loss=0.04257, linear_loss=0.05192]
[2020-05-12 08:28:32.549]  Step 156786  [3.093 sec/step, loss=0.09155, avg_loss=0.08778, mel_loss=0.04068, linear_loss=0.05087]
[2020-05-12 08:28:40.830]  Step 156787  [3.152 sec/step, loss=0.09579, avg_loss=0.08784, mel_loss=0.04388, linear_loss=0.05191]
[2020-05-12 08:28:55.043]  Step 156788  [3.285 sec/step, loss=0.07150, avg_loss=0.08778, mel_loss=0.03356, linear_loss=0.03795]
[2020-05-12 08:28:57.414]  Step 156789  [3.224 sec/step, loss=0.09036, avg_loss=0.08774, mel_loss=0.03973, linear_loss=0.05063]
[2020-05-12 08:28:58.494]  Step 156790  [3.224 sec/step, loss=0.08275, avg_loss=0.08775, mel_loss=0.03565, linear_loss=0.04709]
[2020-05-12 08:29:01.680]  Step 156791  [3.242 sec/step, loss=0.09209, avg_loss=0.08780, mel_loss=0.04060, linear_loss=0.05149]
[2020-05-12 08:29:02.446]  Step 156792  [3.207 sec/step, loss=0.07321, avg_loss=0.08760, mel_loss=0.03223, linear_loss=0.04098]
[2020-05-12 08:29:04.649]  Step 156793  [3.215 sec/step, loss=0.08907, avg_loss=0.08764, mel_loss=0.03874, linear_loss=0.05033]
[2020-05-12 08:29:04.886]  Generated 32 batches of size 32 in 7.466 sec
[2020-05-12 08:29:08.954]  Step 156794  [3.250 sec/step, loss=0.09319, avg_loss=0.08782, mel_loss=0.04167, linear_loss=0.05152]
[2020-05-12 08:29:13.617]  Step 156795  [3.277 sec/step, loss=0.09646, avg_loss=0.08790, mel_loss=0.04337, linear_loss=0.05309]
[2020-05-12 08:29:16.242]  Step 156796  [3.239 sec/step, loss=0.09066, avg_loss=0.08785, mel_loss=0.03995, linear_loss=0.05071]
[2020-05-12 08:29:17.228]  Step 156797  [3.215 sec/step, loss=0.08220, avg_loss=0.08773, mel_loss=0.03522, linear_loss=0.04698]
[2020-05-12 08:29:18.022]  Step 156798  [3.186 sec/step, loss=0.07165, avg_loss=0.08751, mel_loss=0.03048, linear_loss=0.04117]
[2020-05-12 08:29:19.656]  Step 156799  [3.197 sec/step, loss=0.08676, avg_loss=0.08769, mel_loss=0.03775, linear_loss=0.04901]
[2020-05-12 08:29:21.413]  Step 156800  [3.186 sec/step, loss=0.08837, avg_loss=0.08767, mel_loss=0.03811, linear_loss=0.05026]
[2020-05-12 08:29:21.413]  Writing summary at step: 156800
[2020-05-12 08:29:22.815]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156800
[2020-05-12 08:29:24.375]  Saving audio and alignment...
[2020-05-12 08:29:27.442]  Input: 육십사 센트 할 때~_________________
[2020-05-12 08:29:30.352]  Step 156801  [3.207 sec/step, loss=0.09418, avg_loss=0.08788, mel_loss=0.04154, linear_loss=0.05265]
[2020-05-12 08:29:31.525]  Step 156802  [3.162 sec/step, loss=0.07875, avg_loss=0.08770, mel_loss=0.03347, linear_loss=0.04527]
[2020-05-12 08:29:32.801]  Step 156803  [3.163 sec/step, loss=0.08318, avg_loss=0.08772, mel_loss=0.03577, linear_loss=0.04741]
[2020-05-12 08:29:37.519]  Step 156804  [3.189 sec/step, loss=0.09356, avg_loss=0.08775, mel_loss=0.04181, linear_loss=0.05174]
[2020-05-12 08:29:40.923]  Step 156805  [3.203 sec/step, loss=0.09377, avg_loss=0.08781, mel_loss=0.04168, linear_loss=0.05209]
[2020-05-12 08:29:46.350]  Step 156806  [3.249 sec/step, loss=0.09448, avg_loss=0.08805, mel_loss=0.04244, linear_loss=0.05204]
[2020-05-12 08:29:55.811]  Step 156807  [3.333 sec/step, loss=0.09331, avg_loss=0.08819, mel_loss=0.04299, linear_loss=0.05032]
[2020-05-12 08:29:56.429]  Step 156808  [3.318 sec/step, loss=0.06706, avg_loss=0.08796, mel_loss=0.02930, linear_loss=0.03777]
[2020-05-12 08:30:01.044]  Step 156809  [3.322 sec/step, loss=0.09620, avg_loss=0.08799, mel_loss=0.04299, linear_loss=0.05321]
[2020-05-12 08:30:03.023]  Step 156810  [3.328 sec/step, loss=0.08607, avg_loss=0.08800, mel_loss=0.03748, linear_loss=0.04859]
[2020-05-12 08:30:16.105]  Step 156811  [3.328 sec/step, loss=0.08352, avg_loss=0.08801, mel_loss=0.03886, linear_loss=0.04466]
[2020-05-12 08:30:16.916]  Step 156812  [3.302 sec/step, loss=0.07514, avg_loss=0.08783, mel_loss=0.03199, linear_loss=0.04316]
[2020-05-12 08:30:23.331]  Step 156813  [3.298 sec/step, loss=0.09650, avg_loss=0.08785, mel_loss=0.04392, linear_loss=0.05258]
[2020-05-12 08:30:24.227]  Step 156814  [3.282 sec/step, loss=0.07038, avg_loss=0.08766, mel_loss=0.03045, linear_loss=0.03992]
[2020-05-12 08:30:27.295]  Step 156815  [3.297 sec/step, loss=0.09403, avg_loss=0.08773, mel_loss=0.04167, linear_loss=0.05236]
[2020-05-12 08:30:29.272]  Step 156816  [3.289 sec/step, loss=0.08785, avg_loss=0.08771, mel_loss=0.03820, linear_loss=0.04965]
[2020-05-12 08:30:31.519]  Step 156817  [3.302 sec/step, loss=0.08900, avg_loss=0.08780, mel_loss=0.03881, linear_loss=0.05019]
[2020-05-12 08:30:33.684]  Step 156818  [3.287 sec/step, loss=0.09109, avg_loss=0.08779, mel_loss=0.04038, linear_loss=0.05071]
[2020-05-12 08:30:42.267]  Step 156819  [3.324 sec/step, loss=0.09783, avg_loss=0.08782, mel_loss=0.04451, linear_loss=0.05332]
[2020-05-12 08:30:43.585]  Step 156820  [3.308 sec/step, loss=0.08040, avg_loss=0.08770, mel_loss=0.03430, linear_loss=0.04610]
[2020-05-12 08:30:44.416]  Generated 32 batches of size 32 in 2.139 sec
[2020-05-12 08:30:46.321]  Step 156821  [3.327 sec/step, loss=0.08926, avg_loss=0.08784, mel_loss=0.03895, linear_loss=0.05031]
[2020-05-12 08:30:47.441]  Step 156822  [3.324 sec/step, loss=0.07968, avg_loss=0.08781, mel_loss=0.03409, linear_loss=0.04559]
[2020-05-12 08:30:55.697]  Step 156823  [3.380 sec/step, loss=0.09577, avg_loss=0.08785, mel_loss=0.04373, linear_loss=0.05204]
[2020-05-12 08:30:59.388]  Step 156824  [3.359 sec/step, loss=0.09401, avg_loss=0.08784, mel_loss=0.04194, linear_loss=0.05207]
[2020-05-12 08:31:02.162]  Step 156825  [3.376 sec/step, loss=0.08965, avg_loss=0.08790, mel_loss=0.03944, linear_loss=0.05021]
[2020-05-12 08:31:03.658]  Step 156826  [3.338 sec/step, loss=0.08548, avg_loss=0.08781, mel_loss=0.03682, linear_loss=0.04866]
[2020-05-12 08:31:07.742]  Step 156827  [3.347 sec/step, loss=0.09391, avg_loss=0.08781, mel_loss=0.04157, linear_loss=0.05234]
[2020-05-12 08:31:11.220]  Step 156828  [3.305 sec/step, loss=0.09238, avg_loss=0.08777, mel_loss=0.04093, linear_loss=0.05145]
[2020-05-12 08:31:18.005]  Step 156829  [3.284 sec/step, loss=0.09453, avg_loss=0.08777, mel_loss=0.04308, linear_loss=0.05145]
[2020-05-12 08:31:19.157]  Step 156830  [3.275 sec/step, loss=0.08132, avg_loss=0.08768, mel_loss=0.03499, linear_loss=0.04633]
[2020-05-12 08:31:21.555]  Step 156831  [3.263 sec/step, loss=0.09002, avg_loss=0.08763, mel_loss=0.03958, linear_loss=0.05044]
[2020-05-12 08:31:26.251]  Step 156832  [3.292 sec/step, loss=0.09528, avg_loss=0.08772, mel_loss=0.04265, linear_loss=0.05263]
[2020-05-12 08:31:27.069]  Step 156833  [3.283 sec/step, loss=0.07121, avg_loss=0.08755, mel_loss=0.03053, linear_loss=0.04068]
[2020-05-12 08:31:27.885]  Step 156834  [3.250 sec/step, loss=0.07584, avg_loss=0.08735, mel_loss=0.03230, linear_loss=0.04353]
[2020-05-12 08:31:42.387]  Step 156835  [3.383 sec/step, loss=0.07450, avg_loss=0.08727, mel_loss=0.03518, linear_loss=0.03932]
[2020-05-12 08:31:47.366]  Step 156836  [3.426 sec/step, loss=0.09611, avg_loss=0.08754, mel_loss=0.04324, linear_loss=0.05287]
[2020-05-12 08:31:48.383]  Step 156837  [3.407 sec/step, loss=0.07683, avg_loss=0.08737, mel_loss=0.03261, linear_loss=0.04422]
[2020-05-12 08:31:50.554]  Step 156838  [3.387 sec/step, loss=0.09067, avg_loss=0.08735, mel_loss=0.03951, linear_loss=0.05115]
[2020-05-12 08:31:53.708]  Step 156839  [3.401 sec/step, loss=0.09387, avg_loss=0.08742, mel_loss=0.04166, linear_loss=0.05221]
[2020-05-12 08:31:54.749]  Step 156840  [3.395 sec/step, loss=0.08478, avg_loss=0.08739, mel_loss=0.03622, linear_loss=0.04856]
[2020-05-12 08:31:56.079]  Step 156841  [3.380 sec/step, loss=0.08469, avg_loss=0.08733, mel_loss=0.03655, linear_loss=0.04815]
[2020-05-12 08:32:03.660]  Step 156842  [3.313 sec/step, loss=0.09845, avg_loss=0.08757, mel_loss=0.04505, linear_loss=0.05341]
[2020-05-12 08:32:07.793]  Step 156843  [3.281 sec/step, loss=0.09543, avg_loss=0.08757, mel_loss=0.04253, linear_loss=0.05290]
[2020-05-12 08:32:09.886]  Step 156844  [3.241 sec/step, loss=0.08884, avg_loss=0.08752, mel_loss=0.03884, linear_loss=0.05000]
[2020-05-12 08:32:12.395]  Step 156845  [3.183 sec/step, loss=0.08834, avg_loss=0.08748, mel_loss=0.03892, linear_loss=0.04942]
[2020-05-12 08:32:14.344]  Step 156846  [3.195 sec/step, loss=0.08792, avg_loss=0.08759, mel_loss=0.03813, linear_loss=0.04979]
[2020-05-12 08:32:15.996]  Step 156847  [3.201 sec/step, loss=0.08859, avg_loss=0.08765, mel_loss=0.03857, linear_loss=0.05002]
[2020-05-12 08:32:18.949]  Step 156848  [3.224 sec/step, loss=0.09073, avg_loss=0.08781, mel_loss=0.04004, linear_loss=0.05070]
[2020-05-12 08:32:19.974]  Step 156849  [3.221 sec/step, loss=0.07827, avg_loss=0.08775, mel_loss=0.03370, linear_loss=0.04457]
[2020-05-12 08:32:22.678]  Step 156850  [3.226 sec/step, loss=0.09061, avg_loss=0.08777, mel_loss=0.04016, linear_loss=0.05045]
[2020-05-12 08:32:22.678]  Writing summary at step: 156850
[2020-05-12 08:32:24.215]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156850
[2020-05-12 08:32:25.791]  Saving audio and alignment...
[2020-05-12 08:32:27.958]  Generated 32 batches of size 32 in 1.538 sec
[2020-05-12 08:32:29.372]  Input: 반드시 첫 주어 뒤에서~___________________
[2020-05-12 08:32:30.720]  Step 156851  [3.203 sec/step, loss=0.08662, avg_loss=0.08769, mel_loss=0.03752, linear_loss=0.04909]
[2020-05-12 08:32:31.285]  Step 156852  [3.158 sec/step, loss=0.07071, avg_loss=0.08744, mel_loss=0.03063, linear_loss=0.04009]
[2020-05-12 08:32:40.197]  Step 156853  [3.202 sec/step, loss=0.09538, avg_loss=0.08743, mel_loss=0.04396, linear_loss=0.05142]
[2020-05-12 08:32:43.659]  Step 156854  [3.215 sec/step, loss=0.09324, avg_loss=0.08749, mel_loss=0.04129, linear_loss=0.05195]
[2020-05-12 08:32:49.293]  Step 156855  [3.266 sec/step, loss=0.09450, avg_loss=0.08775, mel_loss=0.04259, linear_loss=0.05191]
[2020-05-12 08:32:53.045]  Step 156856  [3.290 sec/step, loss=0.09398, avg_loss=0.08784, mel_loss=0.04197, linear_loss=0.05201]
[2020-05-12 08:32:57.238]  Step 156857  [3.320 sec/step, loss=0.09392, avg_loss=0.08795, mel_loss=0.04208, linear_loss=0.05184]
[2020-05-12 08:33:00.700]  Step 156858  [3.334 sec/step, loss=0.09333, avg_loss=0.08800, mel_loss=0.04144, linear_loss=0.05189]
[2020-05-12 08:33:01.267]  Step 156859  [3.286 sec/step, loss=0.06721, avg_loss=0.08770, mel_loss=0.02916, linear_loss=0.03805]
[2020-05-12 08:33:02.821]  Step 156860  [3.268 sec/step, loss=0.08382, avg_loss=0.08760, mel_loss=0.03607, linear_loss=0.04775]
[2020-05-12 08:33:06.507]  Step 156861  [3.294 sec/step, loss=0.09487, avg_loss=0.08774, mel_loss=0.04222, linear_loss=0.05265]
[2020-05-12 08:33:07.516]  Step 156862  [3.295 sec/step, loss=0.07815, avg_loss=0.08773, mel_loss=0.03297, linear_loss=0.04518]
[2020-05-12 08:33:08.642]  Step 156863  [3.282 sec/step, loss=0.08136, avg_loss=0.08763, mel_loss=0.03456, linear_loss=0.04680]
[2020-05-12 08:33:10.451]  Step 156864  [3.285 sec/step, loss=0.08657, avg_loss=0.08764, mel_loss=0.03733, linear_loss=0.04924]
[2020-05-12 08:33:11.855]  Step 156865  [3.283 sec/step, loss=0.08550, avg_loss=0.08764, mel_loss=0.03700, linear_loss=0.04850]
[2020-05-12 08:33:15.041]  Step 156866  [3.279 sec/step, loss=0.09385, avg_loss=0.08765, mel_loss=0.04153, linear_loss=0.05232]
[2020-05-12 08:33:16.316]  Step 156867  [3.278 sec/step, loss=0.07978, avg_loss=0.08760, mel_loss=0.03428, linear_loss=0.04550]
[2020-05-12 08:33:18.809]  Step 156868  [3.285 sec/step, loss=0.08933, avg_loss=0.08762, mel_loss=0.03893, linear_loss=0.05041]
[2020-05-12 08:33:24.407]  Step 156869  [3.330 sec/step, loss=0.09604, avg_loss=0.08774, mel_loss=0.04324, linear_loss=0.05280]
[2020-05-12 08:33:33.146]  Step 156870  [3.397 sec/step, loss=0.09644, avg_loss=0.08781, mel_loss=0.04410, linear_loss=0.05234]
[2020-05-12 08:33:35.486]  Step 156871  [3.359 sec/step, loss=0.08965, avg_loss=0.08775, mel_loss=0.03943, linear_loss=0.05022]
[2020-05-12 08:33:36.800]  Step 156872  [3.347 sec/step, loss=0.08406, avg_loss=0.08768, mel_loss=0.03601, linear_loss=0.04805]
[2020-05-12 08:33:40.200]  Step 156873  [3.371 sec/step, loss=0.09194, avg_loss=0.08781, mel_loss=0.04083, linear_loss=0.05111]
[2020-05-12 08:33:43.275]  Step 156874  [3.385 sec/step, loss=0.09246, avg_loss=0.08786, mel_loss=0.04086, linear_loss=0.05160]
[2020-05-12 08:33:47.895]  Step 156875  [3.412 sec/step, loss=0.09317, avg_loss=0.08790, mel_loss=0.04195, linear_loss=0.05122]
[2020-05-12 08:33:54.281]  Step 156876  [3.462 sec/step, loss=0.09391, avg_loss=0.08800, mel_loss=0.04260, linear_loss=0.05131]
[2020-05-12 08:34:01.785]  Step 156877  [3.501 sec/step, loss=0.09488, avg_loss=0.08800, mel_loss=0.04328, linear_loss=0.05160]
[2020-05-12 08:34:05.882]  Step 156878  [3.471 sec/step, loss=0.09498, avg_loss=0.08799, mel_loss=0.04211, linear_loss=0.05287]
[2020-05-12 08:34:09.306]  Step 156879  [3.491 sec/step, loss=0.09556, avg_loss=0.08810, mel_loss=0.04254, linear_loss=0.05301]
[2020-05-12 08:34:14.059]  Step 156880  [3.481 sec/step, loss=0.09523, avg_loss=0.08811, mel_loss=0.04267, linear_loss=0.05256]
[2020-05-12 08:34:16.008]  Step 156881  [3.466 sec/step, loss=0.08972, avg_loss=0.08809, mel_loss=0.03902, linear_loss=0.05070]
[2020-05-12 08:34:17.802]  Generated 32 batches of size 32 in 1.788 sec
[2020-05-12 08:34:21.428]  Step 156882  [3.482 sec/step, loss=0.09541, avg_loss=0.08810, mel_loss=0.04289, linear_loss=0.05252]
[2020-05-12 08:34:22.465]  Step 156883  [3.461 sec/step, loss=0.07853, avg_loss=0.08795, mel_loss=0.03382, linear_loss=0.04471]
[2020-05-12 08:34:24.649]  Step 156884  [3.475 sec/step, loss=0.08938, avg_loss=0.08807, mel_loss=0.03911, linear_loss=0.05028]
[2020-05-12 08:34:27.459]  Step 156885  [3.450 sec/step, loss=0.09117, avg_loss=0.08804, mel_loss=0.04012, linear_loss=0.05106]
[2020-05-12 08:34:28.244]  Step 156886  [3.429 sec/step, loss=0.07420, avg_loss=0.08786, mel_loss=0.03143, linear_loss=0.04278]
[2020-05-12 08:34:28.999]  Step 156887  [3.354 sec/step, loss=0.07414, avg_loss=0.08765, mel_loss=0.03139, linear_loss=0.04275]
[2020-05-12 08:34:40.989]  Step 156888  [3.332 sec/step, loss=0.08407, avg_loss=0.08777, mel_loss=0.03927, linear_loss=0.04480]
[2020-05-12 08:34:42.847]  Step 156889  [3.327 sec/step, loss=0.08849, avg_loss=0.08775, mel_loss=0.03820, linear_loss=0.05029]
[2020-05-12 08:34:45.008]  Step 156890  [3.338 sec/step, loss=0.08833, avg_loss=0.08781, mel_loss=0.03851, linear_loss=0.04982]
[2020-05-12 08:34:49.273]  Step 156891  [3.348 sec/step, loss=0.09602, avg_loss=0.08785, mel_loss=0.04310, linear_loss=0.05292]
[2020-05-12 08:34:54.488]  Step 156892  [3.393 sec/step, loss=0.09472, avg_loss=0.08806, mel_loss=0.04276, linear_loss=0.05197]
[2020-05-12 08:34:55.304]  Step 156893  [3.379 sec/step, loss=0.07489, avg_loss=0.08792, mel_loss=0.03204, linear_loss=0.04285]
[2020-05-12 08:35:02.098]  Step 156894  [3.404 sec/step, loss=0.09579, avg_loss=0.08795, mel_loss=0.04362, linear_loss=0.05217]
[2020-05-12 08:35:04.140]  Step 156895  [3.378 sec/step, loss=0.08725, avg_loss=0.08785, mel_loss=0.03791, linear_loss=0.04934]
[2020-05-12 08:35:10.191]  Step 156896  [3.412 sec/step, loss=0.09572, avg_loss=0.08791, mel_loss=0.04333, linear_loss=0.05239]
[2020-05-12 08:35:14.000]  Step 156897  [3.440 sec/step, loss=0.09438, avg_loss=0.08803, mel_loss=0.04200, linear_loss=0.05238]
[2020-05-12 08:35:16.084]  Step 156898  [3.453 sec/step, loss=0.08922, avg_loss=0.08820, mel_loss=0.03901, linear_loss=0.05021]
[2020-05-12 08:35:17.083]  Step 156899  [3.447 sec/step, loss=0.07795, avg_loss=0.08811, mel_loss=0.03343, linear_loss=0.04452]
[2020-05-12 08:35:19.940]  Step 156900  [3.458 sec/step, loss=0.09084, avg_loss=0.08814, mel_loss=0.04011, linear_loss=0.05073]
[2020-05-12 08:35:19.940]  Writing summary at step: 156900
[2020-05-12 08:35:23.481]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156900
[2020-05-12 08:35:25.017]  Saving audio and alignment...
[2020-05-12 08:35:36.452]  Input: 본인이 시험 보러 갈 방송사 멘트의 형식이나 분량 그 느낌을 미리알고 익히는 것은~_________________________________________________
[2020-05-12 08:35:37.292]  Step 156901  [3.437 sec/step, loss=0.07296, avg_loss=0.08793, mel_loss=0.03151, linear_loss=0.04144]
[2020-05-12 08:35:44.789]  Step 156902  [3.500 sec/step, loss=0.09694, avg_loss=0.08811, mel_loss=0.04427, linear_loss=0.05267]
[2020-05-12 08:35:45.666]  Step 156903  [3.496 sec/step, loss=0.07567, avg_loss=0.08803, mel_loss=0.03224, linear_loss=0.04344]
[2020-05-12 08:35:48.100]  Step 156904  [3.473 sec/step, loss=0.09103, avg_loss=0.08801, mel_loss=0.04007, linear_loss=0.05096]
[2020-05-12 08:35:49.203]  Step 156905  [3.450 sec/step, loss=0.08174, avg_loss=0.08789, mel_loss=0.03498, linear_loss=0.04676]
[2020-05-12 08:35:51.167]  Step 156906  [3.416 sec/step, loss=0.08993, avg_loss=0.08784, mel_loss=0.03918, linear_loss=0.05074]
[2020-05-12 08:35:52.924]  Step 156907  [3.339 sec/step, loss=0.08677, avg_loss=0.08778, mel_loss=0.03745, linear_loss=0.04932]
[2020-05-12 08:35:53.525]  Step 156908  [3.339 sec/step, loss=0.06803, avg_loss=0.08779, mel_loss=0.02978, linear_loss=0.03824]
[2020-05-12 08:35:55.194]  Step 156909  [3.309 sec/step, loss=0.08848, avg_loss=0.08771, mel_loss=0.03848, linear_loss=0.05000]
[2020-05-12 08:35:57.978]  Step 156910  [3.317 sec/step, loss=0.08988, avg_loss=0.08775, mel_loss=0.03946, linear_loss=0.05042]
[2020-05-12 08:35:59.352]  Step 156911  [3.200 sec/step, loss=0.08451, avg_loss=0.08776, mel_loss=0.03671, linear_loss=0.04780]
[2020-05-12 08:36:00.754]  Step 156912  [3.206 sec/step, loss=0.08358, avg_loss=0.08784, mel_loss=0.03626, linear_loss=0.04731]
[2020-05-12 08:36:01.066]  Generated 32 batches of size 32 in 1.709 sec
[2020-05-12 08:36:01.923]  Step 156913  [3.154 sec/step, loss=0.08141, avg_loss=0.08769, mel_loss=0.03504, linear_loss=0.04637]
[2020-05-12 08:36:06.581]  Step 156914  [3.191 sec/step, loss=0.09661, avg_loss=0.08795, mel_loss=0.04329, linear_loss=0.05332]
[2020-05-12 08:36:10.538]  Step 156915  [3.200 sec/step, loss=0.09404, avg_loss=0.08795, mel_loss=0.04188, linear_loss=0.05216]
[2020-05-12 08:36:12.114]  Step 156916  [3.196 sec/step, loss=0.08641, avg_loss=0.08794, mel_loss=0.03755, linear_loss=0.04885]
[2020-05-12 08:36:26.676]  Step 156917  [3.319 sec/step, loss=0.07703, avg_loss=0.08782, mel_loss=0.03623, linear_loss=0.04080]
[2020-05-12 08:36:29.742]  Step 156918  [3.328 sec/step, loss=0.09363, avg_loss=0.08784, mel_loss=0.04148, linear_loss=0.05215]
[2020-05-12 08:36:32.112]  Step 156919  [3.266 sec/step, loss=0.09046, avg_loss=0.08777, mel_loss=0.03950, linear_loss=0.05096]
[2020-05-12 08:36:35.339]  Step 156920  [3.285 sec/step, loss=0.09294, avg_loss=0.08790, mel_loss=0.04103, linear_loss=0.05191]
[2020-05-12 08:36:36.374]  Step 156921  [3.268 sec/step, loss=0.07841, avg_loss=0.08779, mel_loss=0.03342, linear_loss=0.04499]
[2020-05-12 08:36:36.942]  Step 156922  [3.263 sec/step, loss=0.06856, avg_loss=0.08768, mel_loss=0.03018, linear_loss=0.03838]
[2020-05-12 08:36:39.102]  Step 156923  [3.202 sec/step, loss=0.08970, avg_loss=0.08762, mel_loss=0.03941, linear_loss=0.05029]
[2020-05-12 08:36:41.145]  Step 156924  [3.185 sec/step, loss=0.08867, avg_loss=0.08756, mel_loss=0.03850, linear_loss=0.05017]
[2020-05-12 08:36:42.571]  Step 156925  [3.172 sec/step, loss=0.08357, avg_loss=0.08750, mel_loss=0.03622, linear_loss=0.04734]
[2020-05-12 08:36:46.478]  Step 156926  [3.196 sec/step, loss=0.09305, avg_loss=0.08758, mel_loss=0.04160, linear_loss=0.05145]
[2020-05-12 08:36:49.116]  Step 156927  [3.181 sec/step, loss=0.09099, avg_loss=0.08755, mel_loss=0.04016, linear_loss=0.05083]
[2020-05-12 08:36:50.017]  Step 156928  [3.156 sec/step, loss=0.07574, avg_loss=0.08738, mel_loss=0.03212, linear_loss=0.04362]
[2020-05-12 08:36:53.449]  Step 156929  [3.122 sec/step, loss=0.09302, avg_loss=0.08737, mel_loss=0.04120, linear_loss=0.05182]
[2020-05-12 08:36:57.079]  Step 156930  [3.147 sec/step, loss=0.09640, avg_loss=0.08752, mel_loss=0.04296, linear_loss=0.05343]
[2020-05-12 08:36:57.843]  Step 156931  [3.131 sec/step, loss=0.07756, avg_loss=0.08739, mel_loss=0.03306, linear_loss=0.04450]
[2020-05-12 08:36:59.777]  Step 156932  [3.103 sec/step, loss=0.08755, avg_loss=0.08732, mel_loss=0.03812, linear_loss=0.04943]
[2020-05-12 08:37:02.241]  Step 156933  [3.119 sec/step, loss=0.08884, avg_loss=0.08749, mel_loss=0.03872, linear_loss=0.05011]
[2020-05-12 08:37:03.353]  Step 156934  [3.122 sec/step, loss=0.08195, avg_loss=0.08755, mel_loss=0.03471, linear_loss=0.04724]
[2020-05-12 08:37:06.498]  Step 156935  [3.009 sec/step, loss=0.09394, avg_loss=0.08775, mel_loss=0.04163, linear_loss=0.05231]
[2020-05-12 08:37:12.141]  Step 156936  [3.015 sec/step, loss=0.09632, avg_loss=0.08775, mel_loss=0.04362, linear_loss=0.05270]
[2020-05-12 08:37:16.794]  Step 156937  [3.052 sec/step, loss=0.09445, avg_loss=0.08793, mel_loss=0.04226, linear_loss=0.05219]
[2020-05-12 08:37:18.347]  Step 156938  [3.046 sec/step, loss=0.08688, avg_loss=0.08789, mel_loss=0.03767, linear_loss=0.04921]
[2020-05-12 08:37:19.533]  Step 156939  [3.026 sec/step, loss=0.08183, avg_loss=0.08777, mel_loss=0.03506, linear_loss=0.04678]
[2020-05-12 08:37:28.243]  Step 156940  [3.103 sec/step, loss=0.09573, avg_loss=0.08788, mel_loss=0.04393, linear_loss=0.05179]
[2020-05-12 08:37:30.029]  Step 156941  [3.107 sec/step, loss=0.08774, avg_loss=0.08791, mel_loss=0.03779, linear_loss=0.04995]
[2020-05-12 08:37:32.383]  Step 156942  [3.055 sec/step, loss=0.09050, avg_loss=0.08783, mel_loss=0.03964, linear_loss=0.05086]
[2020-05-12 08:37:35.305]  Step 156943  [3.043 sec/step, loss=0.09289, avg_loss=0.08780, mel_loss=0.04096, linear_loss=0.05193]
[2020-05-12 08:37:42.751]  Step 156944  [3.096 sec/step, loss=0.09531, avg_loss=0.08787, mel_loss=0.04352, linear_loss=0.05180]
[2020-05-12 08:37:44.145]  Step 156945  [3.085 sec/step, loss=0.08358, avg_loss=0.08782, mel_loss=0.03611, linear_loss=0.04747]
[2020-05-12 08:37:48.300]  Step 156946  [3.107 sec/step, loss=0.09511, avg_loss=0.08789, mel_loss=0.04263, linear_loss=0.05248]
[2020-05-12 08:37:51.702]  Step 156947  [3.125 sec/step, loss=0.09240, avg_loss=0.08793, mel_loss=0.04096, linear_loss=0.05144]
[2020-05-12 08:37:53.402]  Step 156948  [3.112 sec/step, loss=0.08610, avg_loss=0.08788, mel_loss=0.03742, linear_loss=0.04868]
[2020-05-12 08:37:54.119]  Step 156949  [3.109 sec/step, loss=0.07565, avg_loss=0.08786, mel_loss=0.03254, linear_loss=0.04311]
[2020-05-12 08:37:59.447]  Step 156950  [3.135 sec/step, loss=0.09381, avg_loss=0.08789, mel_loss=0.04209, linear_loss=0.05172]
[2020-05-12 08:37:59.447]  Writing summary at step: 156950
[2020-05-12 08:38:04.932]  Generated 32 batches of size 32 in 29.622 sec
[2020-05-12 08:38:05.960]  Saving checkpoint to: ./logs-tacotron/model.ckpt-156950
[2020-05-12 08:38:07.502]  Saving audio and alignment...
[2020-05-12 08:38:25.345]  Input: 온도에서 습도까지 모든 것이 완벽해야 비로소 피어나게 됩니다 너무 익숙해서 당연하다고 여기는 일들~___________________________________________________________________
[2020-05-12 08:38:27.321]  Step 156951  [3.142 sec/step, loss=0.08788, avg_loss=0.08790, mel_loss=0.03840, linear_loss=0.04948]
[2020-05-12 08:38:30.915]  Step 156952  [3.172 sec/step, loss=0.09529, avg_loss=0.08815, mel_loss=0.04232, linear_loss=0.05297]
[2020-05-12 08:38:43.822]  Step 156953  [3.212 sec/step, loss=0.08167, avg_loss=0.08801, mel_loss=0.03827, linear_loss=0.04341]
[2020-05-12 08:38:45.533]  Step 156954  [3.194 sec/step, loss=0.08754, avg_loss=0.08795, mel_loss=0.03779, linear_loss=0.04975]
[2020-05-12 08:38:48.675]  Step 156955  [3.169 sec/step, loss=0.09380, avg_loss=0.08795, mel_loss=0.04154, linear_loss=0.05226]
[2020-05-12 08:38:49.805]  Step 156956  [3.143 sec/step, loss=0.08307, avg_loss=0.08784, mel_loss=0.03549, linear_loss=0.04758]
[2020-05-12 08:38:51.444]  Step 156957  [3.118 sec/step, loss=0.08572, avg_loss=0.08776, mel_loss=0.03729, linear_loss=0.04843]
[2020-05-12 08:38:58.829]  Step 156958  [3.157 sec/step, loss=0.09648, avg_loss=0.08779, mel_loss=0.04404, linear_loss=0.05243]
[2020-05-12 08:39:00.936]  Step 156959  [3.172 sec/step, loss=0.08839, avg_loss=0.08800, mel_loss=0.03848, linear_loss=0.04991]
[2020-05-12 08:39:05.167]  Step 156960  [3.199 sec/step, loss=0.09462, avg_loss=0.08811, mel_loss=0.04210, linear_loss=0.05251]
[2020-05-12 08:39:13.585]  Step 156961  [3.246 sec/step, loss=0.09393, avg_loss=0.08810, mel_loss=0.04303, linear_loss=0.05090]
[2020-05-12 08:39:17.581]  Step 156962  [3.276 sec/step, loss=0.09538, avg_loss=0.08827, mel_loss=0.04221, linear_loss=0.05317]
[2020-05-12 08:39:22.948]  Step 156963  [3.319 sec/step, loss=0.09672, avg_loss=0.08842, mel_loss=0.04377, linear_loss=0.05295]
[2020-05-12 08:39:24.421]  Step 156964  [3.315 sec/step, loss=0.08658, avg_loss=0.08842, mel_loss=0.03727, linear_loss=0.04931]
[2020-05-12 08:39:27.256]  Step 156965  [3.330 sec/step, loss=0.09094, avg_loss=0.08848, mel_loss=0.04029, linear_loss=0.05065]
[2020-05-12 08:39:28.347]  Step 156966  [3.309 sec/step, loss=0.07909, avg_loss=0.08833, mel_loss=0.03402, linear_loss=0.04506]
[2020-05-12 08:39:34.920]  Step 156967  [3.362 sec/step, loss=0.09363, avg_loss=0.08847, mel_loss=0.04252, linear_loss=0.05111]
[2020-05-12 08:39:35.908]  Step 156968  [3.347 sec/step, loss=0.08027, avg_loss=0.08838, mel_loss=0.03387, linear_loss=0.04641]
[2020-05-12 08:39:38.153]  Step 156969  [3.313 sec/step, loss=0.08958, avg_loss=0.08831, mel_loss=0.03954, linear_loss=0.05004]
[2020-05-12 08:39:43.021]  Step 156970  [3.274 sec/step, loss=0.09508, avg_loss=0.08830, mel_loss=0.04275, linear_loss=0.05233]
[2020-05-12 08:39:47.587]  Step 156971  [3.297 sec/step, loss=0.09595, avg_loss=0.08836, mel_loss=0.04296, linear_loss=0.05299]
[2020-05-12 08:39:48.896]  Step 156972  [3.297 sec/step, loss=0.08348, avg_loss=0.08836, mel_loss=0.03599, linear_loss=0.04750]
[2020-05-12 08:39:50.238]  Step 156973  [3.276 sec/step, loss=0.08427, avg_loss=0.08828, mel_loss=0.03654, linear_loss=0.04773]
[2020-05-12 08:39:51.003]  Step 156974  [3.253 sec/step, loss=0.07023, avg_loss=0.08806, mel_loss=0.03088, linear_loss=0.03935]
[2020-05-12 08:39:54.437]  Step 156975  [3.241 sec/step, loss=0.09257, avg_loss=0.08805, mel_loss=0.04135, linear_loss=0.05122]
[2020-05-12 08:39:55.411]  Step 156976  [3.187 sec/step, loss=0.08232, avg_loss=0.08794, mel_loss=0.03532, linear_loss=0.04699]
[2020-05-12 08:39:58.126]  Step 156977  [3.139 sec/step, loss=0.09039, avg_loss=0.08789, mel_loss=0.03987, linear_loss=0.05052]
[2020-05-12 08:40:00.007]  Step 156978  [3.117 sec/step, loss=0.08539, avg_loss=0.08780, mel_loss=0.03705, linear_loss=0.04835]
[2020-05-12 08:40:00.798]  Step 156979  [3.091 sec/step, loss=0.06971, avg_loss=0.08754, mel_loss=0.02952, linear_loss=0.04020]
[2020-05-12 08:40:03.930]  Step 156980  [3.074 sec/step, loss=0.09355, avg_loss=0.08752, mel_loss=0.04141, linear_loss=0.05214]
[2020-05-12 08:40:06.347]  Step 156981  [3.079 sec/step, loss=0.09049, avg_loss=0.08753, mel_loss=0.03954, linear_loss=0.05095]
[2020-05-12 08:40:07.194]  Step 156982  [3.033 sec/step, loss=0.07353, avg_loss=0.08731, mel_loss=0.03137, linear_loss=0.04216]
[2020-05-12 08:40:08.835]  Generated 32 batches of size 32 in 18.592 sec
[2020-05-12 08:40:11.026]  Step 156983  [3.061 sec/step, loss=0.08977, avg_loss=0.08742, mel_loss=0.03936, linear_loss=0.05041]
[2020-05-12 08:40:11.928]  Step 156984  [3.048 sec/step, loss=0.07526, avg_loss=0.08728, mel_loss=0.03193, linear_loss=0.04333]
[2020-05-12 08:40:12.672]  Step 156985  [3.028 sec/step, loss=0.07721, avg_loss=0.08714, mel_loss=0.03254, linear_loss=0.04467]
[2020-05-12 08:40:14.117]  Step 156986  [3.034 sec/step, loss=0.08623, avg_loss=0.08726, mel_loss=0.03731, linear_loss=0.04892]
[2020-05-12 08:40:17.523]  Step 156987  [3.061 sec/step, loss=0.09397, avg_loss=0.08746, mel_loss=0.04179, linear_loss=0.05218]
[2020-05-12 08:40:25.908]  Step 156988  [3.025 sec/step, loss=0.09354, avg_loss=0.08755, mel_loss=0.04281, linear_loss=0.05074]
[2020-05-12 08:40:27.261]  Step 156989  [3.020 sec/step, loss=0.08318, avg_loss=0.08750, mel_loss=0.03586, linear_loss=0.04731]
[2020-05-12 08:40:31.964]  Step 156990  [3.045 sec/step, loss=0.09453, avg_loss=0.08756, mel_loss=0.04237, linear_loss=0.05217]
[2020-05-12 08:40:38.578]  Step 156991  [3.069 sec/step, loss=0.09521, avg_loss=0.08755, mel_loss=0.04306, linear_loss=0.05216]
[2020-05-12 08:40:41.489]  Step 156992  [3.046 sec/step, loss=0.09151, avg_loss=0.08752, mel_loss=0.04030, linear_loss=0.05122]
[2020-05-12 08:40:42.607]  Step 156993  [3.049 sec/step, loss=0.08203, avg_loss=0.08759, mel_loss=0.03507, linear_loss=0.04696]
[2020-05-12 08:40:50.316]  Step 156994  [3.058 sec/step, loss=0.09620, avg_loss=0.08760, mel_loss=0.04361, linear_loss=0.05259]
[2020-05-12 08:40:56.100]  Step 156995  [3.095 sec/step, loss=0.09485, avg_loss=0.08767, mel_loss=0.04254, linear_loss=0.05231]
[2020-05-12 08:41:11.191]  Step 156996  [3.186 sec/step, loss=0.07219, avg_loss=0.08744, mel_loss=0.03378, linear_loss=0.03841]
[2020-05-12 08:41:13.745]  Step 156997  [3.173 sec/step, loss=0.08928, avg_loss=0.08739, mel_loss=0.03918, linear_loss=0.05010]
[2020-05-12 08:41:19.047]  Step 156998  [3.205 sec/step, loss=0.09448, avg_loss=0.08744, mel_loss=0.04275, linear_loss=0.05173]
[2020-05-12 08:41:21.128]  Step 156999  [3.216 sec/step, loss=0.08840, avg_loss=0.08754, mel_loss=0.03863, linear_loss=0.04977]
[2020-05-12 08:41:22.156]  Step 157000  [3.198 sec/step, loss=0.07871, avg_loss=0.08742, mel_loss=0.03358, linear_loss=0.04513]
[2020-05-12 08:41:22.156]  Writing summary at step: 157000
[2020-05-12 08:41:25.906]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157000
[2020-05-12 08:41:27.499]  Saving audio and alignment...
[2020-05-12 08:41:30.907]  Input: 다으음 대본에 이렇게 적혀 있어요~__________
[2020-05-12 08:41:34.410]  Step 157001  [3.224 sec/step, loss=0.09142, avg_loss=0.08761, mel_loss=0.04065, linear_loss=0.05077]
[2020-05-12 08:41:37.215]  Step 157002  [3.178 sec/step, loss=0.08972, avg_loss=0.08754, mel_loss=0.03957, linear_loss=0.05015]
[2020-05-12 08:41:38.995]  Step 157003  [3.187 sec/step, loss=0.08733, avg_loss=0.08765, mel_loss=0.03764, linear_loss=0.04969]
[2020-05-12 08:41:39.853]  Step 157004  [3.171 sec/step, loss=0.07411, avg_loss=0.08748, mel_loss=0.03164, linear_loss=0.04246]
[2020-05-12 08:41:41.605]  Step 157005  [3.177 sec/step, loss=0.08622, avg_loss=0.08753, mel_loss=0.03754, linear_loss=0.04868]
[2020-05-12 08:41:42.169]  Step 157006  [3.163 sec/step, loss=0.06886, avg_loss=0.08732, mel_loss=0.02984, linear_loss=0.03903]
[2020-05-12 08:41:43.742]  Step 157007  [3.161 sec/step, loss=0.08462, avg_loss=0.08730, mel_loss=0.03639, linear_loss=0.04823]
[2020-05-12 08:41:44.928]  Step 157008  [3.167 sec/step, loss=0.08263, avg_loss=0.08744, mel_loss=0.03532, linear_loss=0.04731]
[2020-05-12 08:41:47.254]  Step 157009  [3.174 sec/step, loss=0.08860, avg_loss=0.08744, mel_loss=0.03881, linear_loss=0.04979]
[2020-05-12 08:41:54.283]  Step 157010  [3.216 sec/step, loss=0.09697, avg_loss=0.08751, mel_loss=0.04436, linear_loss=0.05261]
[2020-05-12 08:41:57.422]  Step 157011  [3.234 sec/step, loss=0.09339, avg_loss=0.08760, mel_loss=0.04124, linear_loss=0.05216]
[2020-05-12 08:42:01.597]  Step 157012  [3.262 sec/step, loss=0.09323, avg_loss=0.08770, mel_loss=0.04148, linear_loss=0.05175]
[2020-05-12 08:42:13.756]  Generated 32 batches of size 32 in 34.756 sec
[2020-05-12 08:42:19.134]  Step 157013  [3.425 sec/step, loss=0.09580, avg_loss=0.08784, mel_loss=0.04327, linear_loss=0.05252]
[2020-05-12 08:42:20.169]  Step 157014  [3.389 sec/step, loss=0.07882, avg_loss=0.08767, mel_loss=0.03353, linear_loss=0.04530]
[2020-05-12 08:42:22.635]  Step 157015  [3.374 sec/step, loss=0.09077, avg_loss=0.08763, mel_loss=0.03991, linear_loss=0.05086]
[2020-05-12 08:42:23.969]  Step 157016  [3.372 sec/step, loss=0.08365, avg_loss=0.08761, mel_loss=0.03615, linear_loss=0.04750]
[2020-05-12 08:42:26.111]  Step 157017  [3.248 sec/step, loss=0.08863, avg_loss=0.08772, mel_loss=0.03893, linear_loss=0.04971]
[2020-05-12 08:42:27.749]  Step 157018  [3.233 sec/step, loss=0.08600, avg_loss=0.08765, mel_loss=0.03743, linear_loss=0.04857]
[2020-05-12 08:42:30.430]  Step 157019  [3.236 sec/step, loss=0.09204, avg_loss=0.08766, mel_loss=0.04090, linear_loss=0.05114]
[2020-05-12 08:42:34.101]  Step 157020  [3.241 sec/step, loss=0.09396, avg_loss=0.08767, mel_loss=0.04183, linear_loss=0.05213]
[2020-05-12 08:42:36.646]  Step 157021  [3.256 sec/step, loss=0.09000, avg_loss=0.08779, mel_loss=0.03961, linear_loss=0.05039]
[2020-05-12 08:42:42.205]  Step 157022  [3.306 sec/step, loss=0.09659, avg_loss=0.08807, mel_loss=0.04351, linear_loss=0.05308]
[2020-05-12 08:42:44.218]  Step 157023  [3.304 sec/step, loss=0.08750, avg_loss=0.08805, mel_loss=0.03832, linear_loss=0.04919]
[2020-05-12 08:42:47.722]  Step 157024  [3.319 sec/step, loss=0.09397, avg_loss=0.08810, mel_loss=0.04161, linear_loss=0.05236]
[2020-05-12 08:42:48.977]  Step 157025  [3.317 sec/step, loss=0.08140, avg_loss=0.08808, mel_loss=0.03520, linear_loss=0.04621]
[2020-05-12 08:42:55.119]  Step 157026  [3.340 sec/step, loss=0.09889, avg_loss=0.08813, mel_loss=0.04558, linear_loss=0.05332]
[2020-05-12 08:42:59.330]  Step 157027  [3.355 sec/step, loss=0.09520, avg_loss=0.08818, mel_loss=0.04268, linear_loss=0.05251]
[2020-05-12 08:43:02.756]  Step 157028  [3.381 sec/step, loss=0.09509, avg_loss=0.08837, mel_loss=0.04253, linear_loss=0.05256]
[2020-05-12 08:43:04.973]  Step 157029  [3.369 sec/step, loss=0.09275, avg_loss=0.08837, mel_loss=0.04131, linear_loss=0.05143]
[2020-05-12 08:43:07.916]  Step 157030  [3.362 sec/step, loss=0.10001, avg_loss=0.08840, mel_loss=0.04554, linear_loss=0.05448]
[2020-05-12 08:43:08.821]  Step 157031  [3.363 sec/step, loss=0.08285, avg_loss=0.08846, mel_loss=0.03537, linear_loss=0.04748]
[2020-05-12 08:43:09.356]  Step 157032  [3.349 sec/step, loss=0.06923, avg_loss=0.08827, mel_loss=0.03053, linear_loss=0.03870]
[2020-05-12 08:43:16.586]  Step 157033  [3.397 sec/step, loss=0.10943, avg_loss=0.08848, mel_loss=0.05342, linear_loss=0.05601]
[2020-05-12 08:43:17.377]  Step 157034  [3.394 sec/step, loss=0.07383, avg_loss=0.08840, mel_loss=0.03223, linear_loss=0.04160]
[2020-05-12 08:43:19.107]  Step 157035  [3.379 sec/step, loss=0.08953, avg_loss=0.08835, mel_loss=0.03982, linear_loss=0.04972]
[2020-05-12 08:43:20.902]  Generated 32 batches of size 32 in 1.790 sec
[2020-05-12 08:43:23.296]  Step 157036  [3.365 sec/step, loss=0.10202, avg_loss=0.08841, mel_loss=0.04711, linear_loss=0.05491]
[2020-05-12 08:43:26.326]  Step 157037  [3.349 sec/step, loss=0.10163, avg_loss=0.08848, mel_loss=0.04649, linear_loss=0.05513]
[2020-05-12 08:43:27.465]  Step 157038  [3.344 sec/step, loss=0.08139, avg_loss=0.08843, mel_loss=0.03486, linear_loss=0.04652]
[2020-05-12 08:43:29.301]  Step 157039  [3.351 sec/step, loss=0.08972, avg_loss=0.08851, mel_loss=0.03943, linear_loss=0.05030]
[2020-05-12 08:43:33.946]  Step 157040  [3.310 sec/step, loss=0.09993, avg_loss=0.08855, mel_loss=0.04559, linear_loss=0.05434]
[2020-05-12 08:43:34.759]  Step 157041  [3.301 sec/step, loss=0.07906, avg_loss=0.08846, mel_loss=0.03404, linear_loss=0.04502]
[2020-05-12 08:43:47.237]  Step 157042  [3.402 sec/step, loss=0.08977, avg_loss=0.08846, mel_loss=0.04311, linear_loss=0.04667]
[2020-05-12 08:43:48.653]  Step 157043  [3.387 sec/step, loss=0.08996, avg_loss=0.08843, mel_loss=0.03960, linear_loss=0.05036]
[2020-05-12 08:43:57.508]  Step 157044  [3.401 sec/step, loss=0.10082, avg_loss=0.08848, mel_loss=0.04787, linear_loss=0.05296]
[2020-05-12 08:43:59.238]  Step 157045  [3.404 sec/step, loss=0.09025, avg_loss=0.08855, mel_loss=0.03968, linear_loss=0.05056]
[2020-05-12 08:44:00.777]  Step 157046  [3.378 sec/step, loss=0.08943, avg_loss=0.08849, mel_loss=0.03931, linear_loss=0.05012]
[2020-05-12 08:44:01.592]  Step 157047  [3.352 sec/step, loss=0.07748, avg_loss=0.08834, mel_loss=0.03323, linear_loss=0.04425]
[2020-05-12 08:44:10.488]  Step 157048  [3.424 sec/step, loss=0.11312, avg_loss=0.08861, mel_loss=0.05585, linear_loss=0.05726]
[2020-05-12 08:44:12.695]  Step 157049  [3.439 sec/step, loss=0.09269, avg_loss=0.08878, mel_loss=0.04161, linear_loss=0.05108]
[2020-05-12 08:44:15.423]  Step 157050  [3.413 sec/step, loss=0.09262, avg_loss=0.08877, mel_loss=0.04131, linear_loss=0.05131]
[2020-05-12 08:44:15.423]  Writing summary at step: 157050
[2020-05-12 08:44:17.910]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157050
[2020-05-12 08:44:19.491]  Saving audio and alignment...
[2020-05-12 08:44:27.969]  Input: 아 그럼이 두가지를 반드시 기억하면서 오늘의 뉴스 리딩으로 넘어가도록 하겠습니다~______________________
[2020-05-12 08:44:32.025]  Step 157051  [3.434 sec/step, loss=0.10029, avg_loss=0.08889, mel_loss=0.04568, linear_loss=0.05461]
[2020-05-12 08:44:35.119]  Step 157052  [3.429 sec/step, loss=0.10023, avg_loss=0.08894, mel_loss=0.04574, linear_loss=0.05448]
[2020-05-12 08:44:36.354]  Step 157053  [3.312 sec/step, loss=0.08814, avg_loss=0.08901, mel_loss=0.03875, linear_loss=0.04939]
[2020-05-12 08:44:41.755]  Step 157054  [3.349 sec/step, loss=0.12128, avg_loss=0.08935, mel_loss=0.06089, linear_loss=0.06038]
[2020-05-12 08:44:46.465]  Step 157055  [3.365 sec/step, loss=0.11629, avg_loss=0.08957, mel_loss=0.05709, linear_loss=0.05921]
[2020-05-12 08:44:47.867]  Step 157056  [3.367 sec/step, loss=0.09016, avg_loss=0.08964, mel_loss=0.04014, linear_loss=0.05002]
[2020-05-12 08:44:49.903]  Step 157057  [3.371 sec/step, loss=0.09417, avg_loss=0.08973, mel_loss=0.04245, linear_loss=0.05173]
[2020-05-12 08:44:57.616]  Step 157058  [3.375 sec/step, loss=0.12060, avg_loss=0.08997, mel_loss=0.06088, linear_loss=0.05972]
[2020-05-12 08:45:01.119]  Step 157059  [3.389 sec/step, loss=0.10397, avg_loss=0.09012, mel_loss=0.04780, linear_loss=0.05617]
[2020-05-12 08:45:03.001]  Step 157060  [3.365 sec/step, loss=0.09260, avg_loss=0.09010, mel_loss=0.04107, linear_loss=0.05153]
[2020-05-12 08:45:03.639]  Step 157061  [3.287 sec/step, loss=0.07970, avg_loss=0.08996, mel_loss=0.03488, linear_loss=0.04482]
[2020-05-12 08:45:10.494]  Step 157062  [3.316 sec/step, loss=0.11004, avg_loss=0.09011, mel_loss=0.05310, linear_loss=0.05694]
[2020-05-12 08:45:12.121]  Step 157063  [3.279 sec/step, loss=0.09537, avg_loss=0.09009, mel_loss=0.04241, linear_loss=0.05297]
[2020-05-12 08:45:13.001]  Step 157064  [3.273 sec/step, loss=0.08154, avg_loss=0.09004, mel_loss=0.03537, linear_loss=0.04616]
[2020-05-12 08:45:14.119]  Step 157065  [3.255 sec/step, loss=0.08664, avg_loss=0.09000, mel_loss=0.03791, linear_loss=0.04873]
[2020-05-12 08:45:15.803]  Generated 32 batches of size 32 in 1.680 sec
[2020-05-12 08:45:27.381]  Step 157066  [3.377 sec/step, loss=0.09457, avg_loss=0.09016, mel_loss=0.04686, linear_loss=0.04771]
[2020-05-12 08:45:29.596]  Step 157067  [3.334 sec/step, loss=0.09538, avg_loss=0.09017, mel_loss=0.04276, linear_loss=0.05262]
[2020-05-12 08:45:33.313]  Step 157068  [3.361 sec/step, loss=0.10114, avg_loss=0.09038, mel_loss=0.04687, linear_loss=0.05427]
[2020-05-12 08:45:34.135]  Step 157069  [3.347 sec/step, loss=0.07516, avg_loss=0.09024, mel_loss=0.03374, linear_loss=0.04143]
[2020-05-12 08:45:35.492]  Step 157070  [3.311 sec/step, loss=0.08902, avg_loss=0.09018, mel_loss=0.03969, linear_loss=0.04932]
[2020-05-12 08:45:39.859]  Step 157071  [3.309 sec/step, loss=0.10512, avg_loss=0.09027, mel_loss=0.04965, linear_loss=0.05547]
[2020-05-12 08:45:42.744]  Step 157072  [3.325 sec/step, loss=0.09933, avg_loss=0.09043, mel_loss=0.04570, linear_loss=0.05364]
[2020-05-12 08:45:43.769]  Step 157073  [3.322 sec/step, loss=0.08439, avg_loss=0.09043, mel_loss=0.03705, linear_loss=0.04734]
[2020-05-12 08:45:47.584]  Step 157074  [3.353 sec/step, loss=0.10046, avg_loss=0.09073, mel_loss=0.04601, linear_loss=0.05445]
[2020-05-12 08:45:50.388]  Step 157075  [3.346 sec/step, loss=0.09926, avg_loss=0.09080, mel_loss=0.04556, linear_loss=0.05371]
[2020-05-12 08:45:51.389]  Step 157076  [3.347 sec/step, loss=0.08182, avg_loss=0.09079, mel_loss=0.03571, linear_loss=0.04611]
[2020-05-12 08:45:54.352]  Step 157077  [3.349 sec/step, loss=0.10106, avg_loss=0.09090, mel_loss=0.04582, linear_loss=0.05524]
[2020-05-12 08:45:57.568]  Step 157078  [3.362 sec/step, loss=0.09972, avg_loss=0.09104, mel_loss=0.04545, linear_loss=0.05427]
[2020-05-12 08:45:58.406]  Step 157079  [3.363 sec/step, loss=0.07706, avg_loss=0.09112, mel_loss=0.03342, linear_loss=0.04364]
[2020-05-12 08:46:00.124]  Step 157080  [3.349 sec/step, loss=0.09357, avg_loss=0.09112, mel_loss=0.04133, linear_loss=0.05224]
[2020-05-12 08:46:05.156]  Step 157081  [3.375 sec/step, loss=0.10204, avg_loss=0.09123, mel_loss=0.04738, linear_loss=0.05466]
[2020-05-12 08:46:11.422]  Step 157082  [3.429 sec/step, loss=0.10481, avg_loss=0.09154, mel_loss=0.04941, linear_loss=0.05539]
[2020-05-12 08:46:20.176]  Step 157083  [3.478 sec/step, loss=0.10603, avg_loss=0.09171, mel_loss=0.05128, linear_loss=0.05475]
[2020-05-12 08:46:27.447]  Step 157084  [3.542 sec/step, loss=0.10303, avg_loss=0.09198, mel_loss=0.04899, linear_loss=0.05404]
[2020-05-12 08:46:29.639]  Step 157085  [3.556 sec/step, loss=0.09420, avg_loss=0.09215, mel_loss=0.04224, linear_loss=0.05196]
[2020-05-12 08:46:30.754]  Step 157086  [3.553 sec/step, loss=0.08679, avg_loss=0.09216, mel_loss=0.03764, linear_loss=0.04915]
[2020-05-12 08:46:32.125]  Step 157087  [3.533 sec/step, loss=0.08893, avg_loss=0.09211, mel_loss=0.03948, linear_loss=0.04945]
[2020-05-12 08:46:33.349]  Step 157088  [3.461 sec/step, loss=0.08557, avg_loss=0.09203, mel_loss=0.03768, linear_loss=0.04790]
[2020-05-12 08:46:34.363]  Step 157089  [3.458 sec/step, loss=0.08357, avg_loss=0.09203, mel_loss=0.03670, linear_loss=0.04687]
[2020-05-12 08:46:38.504]  Step 157090  [3.452 sec/step, loss=0.09798, avg_loss=0.09207, mel_loss=0.04467, linear_loss=0.05331]
[2020-05-12 08:46:39.847]  Step 157091  [3.399 sec/step, loss=0.08742, avg_loss=0.09199, mel_loss=0.03842, linear_loss=0.04900]
[2020-05-12 08:46:40.407]  Step 157092  [3.376 sec/step, loss=0.07108, avg_loss=0.09179, mel_loss=0.03107, linear_loss=0.04001]
[2020-05-12 08:46:44.080]  Step 157093  [3.402 sec/step, loss=0.10083, avg_loss=0.09197, mel_loss=0.04631, linear_loss=0.05453]
[2020-05-12 08:46:57.974]  Step 157094  [3.463 sec/step, loss=0.07932, avg_loss=0.09181, mel_loss=0.03868, linear_loss=0.04064]
[2020-05-12 08:46:59.581]  Step 157095  [3.422 sec/step, loss=0.08825, avg_loss=0.09174, mel_loss=0.03856, linear_loss=0.04968]
[2020-05-12 08:47:01.534]  Step 157096  [3.290 sec/step, loss=0.09055, avg_loss=0.09192, mel_loss=0.04009, linear_loss=0.05046]
[2020-05-12 08:47:05.028]  Step 157097  [3.300 sec/step, loss=0.09771, avg_loss=0.09201, mel_loss=0.04423, linear_loss=0.05347]
[2020-05-12 08:47:06.738]  Generated 32 batches of size 32 in 1.705 sec
[2020-05-12 08:47:09.737]  Step 157098  [3.294 sec/step, loss=0.10027, avg_loss=0.09207, mel_loss=0.04585, linear_loss=0.05442]
[2020-05-12 08:47:11.751]  Step 157099  [3.293 sec/step, loss=0.09324, avg_loss=0.09211, mel_loss=0.04133, linear_loss=0.05191]
[2020-05-12 08:47:15.151]  Step 157100  [3.317 sec/step, loss=0.09809, avg_loss=0.09231, mel_loss=0.04422, linear_loss=0.05387]
[2020-05-12 08:47:15.151]  Writing summary at step: 157100
[2020-05-12 08:47:16.970]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157100
[2020-05-12 08:47:18.555]  Saving audio and alignment...
[2020-05-12 08:47:26.611]  Input: 여러분이 행사 사회를 보러 갔어요 그래서 관객중 한 분과의 인터뷰를 하게 되었습니다~____________________
[2020-05-12 08:47:30.767]  Step 157101  [3.323 sec/step, loss=0.10026, avg_loss=0.09240, mel_loss=0.04570, linear_loss=0.05456]
[2020-05-12 08:47:33.179]  Step 157102  [3.319 sec/step, loss=0.09530, avg_loss=0.09245, mel_loss=0.04245, linear_loss=0.05285]
[2020-05-12 08:47:35.749]  Step 157103  [3.327 sec/step, loss=0.09346, avg_loss=0.09251, mel_loss=0.04161, linear_loss=0.05186]
[2020-05-12 08:47:36.503]  Step 157104  [3.326 sec/step, loss=0.08166, avg_loss=0.09259, mel_loss=0.03491, linear_loss=0.04675]
[2020-05-12 08:47:39.809]  Step 157105  [3.342 sec/step, loss=0.09768, avg_loss=0.09270, mel_loss=0.04372, linear_loss=0.05396]
[2020-05-12 08:47:40.963]  Step 157106  [3.348 sec/step, loss=0.08463, avg_loss=0.09286, mel_loss=0.03668, linear_loss=0.04795]
[2020-05-12 08:47:43.115]  Step 157107  [3.353 sec/step, loss=0.09219, avg_loss=0.09294, mel_loss=0.04098, linear_loss=0.05121]
[2020-05-12 08:47:48.388]  Step 157108  [3.394 sec/step, loss=0.09889, avg_loss=0.09310, mel_loss=0.04543, linear_loss=0.05347]
[2020-05-12 08:47:49.202]  Step 157109  [3.379 sec/step, loss=0.07854, avg_loss=0.09300, mel_loss=0.03386, linear_loss=0.04469]
[2020-05-12 08:47:49.955]  Step 157110  [3.316 sec/step, loss=0.07463, avg_loss=0.09277, mel_loss=0.03233, linear_loss=0.04230]
[2020-05-12 08:47:52.909]  Step 157111  [3.315 sec/step, loss=0.09597, avg_loss=0.09280, mel_loss=0.04301, linear_loss=0.05296]
[2020-05-12 08:47:57.490]  Step 157112  [3.319 sec/step, loss=0.09735, avg_loss=0.09284, mel_loss=0.04434, linear_loss=0.05301]
[2020-05-12 08:47:58.018]  Step 157113  [3.149 sec/step, loss=0.07236, avg_loss=0.09261, mel_loss=0.03227, linear_loss=0.04009]
[2020-05-12 08:48:01.558]  Step 157114  [3.174 sec/step, loss=0.09748, avg_loss=0.09279, mel_loss=0.04392, linear_loss=0.05357]
[2020-05-12 08:48:03.465]  Step 157115  [3.168 sec/step, loss=0.09034, avg_loss=0.09279, mel_loss=0.03955, linear_loss=0.05079]
[2020-05-12 08:48:11.929]  Step 157116  [3.239 sec/step, loss=0.09843, avg_loss=0.09294, mel_loss=0.04585, linear_loss=0.05258]
[2020-05-12 08:48:13.283]  Step 157117  [3.231 sec/step, loss=0.08482, avg_loss=0.09290, mel_loss=0.03687, linear_loss=0.04795]
[2020-05-12 08:48:27.887]  Step 157118  [3.361 sec/step, loss=0.07978, avg_loss=0.09284, mel_loss=0.03846, linear_loss=0.04133]
[2020-05-12 08:48:31.323]  Step 157119  [3.369 sec/step, loss=0.09573, avg_loss=0.09287, mel_loss=0.04310, linear_loss=0.05263]
[2020-05-12 08:48:32.747]  Step 157120  [3.346 sec/step, loss=0.08773, avg_loss=0.09281, mel_loss=0.03852, linear_loss=0.04921]
[2020-05-12 08:48:33.833]  Step 157121  [3.332 sec/step, loss=0.08240, avg_loss=0.09274, mel_loss=0.03577, linear_loss=0.04663]
[2020-05-12 08:48:36.217]  Step 157122  [3.300 sec/step, loss=0.09005, avg_loss=0.09267, mel_loss=0.03976, linear_loss=0.05029]
[2020-05-12 08:48:38.247]  Step 157123  [3.300 sec/step, loss=0.09185, avg_loss=0.09271, mel_loss=0.04054, linear_loss=0.05131]
[2020-05-12 08:48:39.261]  Step 157124  [3.275 sec/step, loss=0.08098, avg_loss=0.09258, mel_loss=0.03498, linear_loss=0.04600]
[2020-05-12 08:48:42.143]  Step 157125  [3.291 sec/step, loss=0.09248, avg_loss=0.09269, mel_loss=0.04142, linear_loss=0.05106]
[2020-05-12 08:48:49.661]  Step 157126  [3.305 sec/step, loss=0.10101, avg_loss=0.09272, mel_loss=0.04678, linear_loss=0.05423]
[2020-05-12 08:48:53.909]  Step 157127  [3.305 sec/step, loss=0.09660, avg_loss=0.09273, mel_loss=0.04363, linear_loss=0.05297]
[2020-05-12 08:48:57.676]  Step 157128  [3.309 sec/step, loss=0.09737, avg_loss=0.09275, mel_loss=0.04361, linear_loss=0.05375]
[2020-05-12 08:48:58.702]  Step 157129  [3.297 sec/step, loss=0.07982, avg_loss=0.09262, mel_loss=0.03452, linear_loss=0.04531]
[2020-05-12 08:49:01.451]  Step 157130  [3.295 sec/step, loss=0.09167, avg_loss=0.09254, mel_loss=0.04076, linear_loss=0.05091]
[2020-05-12 08:49:07.867]  Step 157131  [3.350 sec/step, loss=0.09844, avg_loss=0.09270, mel_loss=0.04549, linear_loss=0.05295]
[2020-05-12 08:49:13.568]  Step 157132  [3.402 sec/step, loss=0.09835, avg_loss=0.09299, mel_loss=0.04511, linear_loss=0.05324]
[2020-05-12 08:49:15.354]  Step 157133  [3.347 sec/step, loss=0.08936, avg_loss=0.09279, mel_loss=0.03909, linear_loss=0.05027]
[2020-05-12 08:49:17.010]  Step 157134  [3.356 sec/step, loss=0.08615, avg_loss=0.09291, mel_loss=0.03793, linear_loss=0.04822]
[2020-05-12 08:49:17.703]  Generated 32 batches of size 32 in 23.788 sec
[2020-05-12 08:49:19.444]  Step 157135  [3.363 sec/step, loss=0.09213, avg_loss=0.09294, mel_loss=0.04068, linear_loss=0.05145]
[2020-05-12 08:49:21.078]  Step 157136  [3.338 sec/step, loss=0.08936, avg_loss=0.09281, mel_loss=0.03919, linear_loss=0.05017]
[2020-05-12 08:49:24.158]  Step 157137  [3.338 sec/step, loss=0.09634, avg_loss=0.09276, mel_loss=0.04288, linear_loss=0.05347]
[2020-05-12 08:49:27.659]  Step 157138  [3.362 sec/step, loss=0.09405, avg_loss=0.09288, mel_loss=0.04224, linear_loss=0.05181]
[2020-05-12 08:49:31.275]  Step 157139  [3.379 sec/step, loss=0.09565, avg_loss=0.09294, mel_loss=0.04313, linear_loss=0.05252]
[2020-05-12 08:49:33.415]  Step 157140  [3.354 sec/step, loss=0.09144, avg_loss=0.09286, mel_loss=0.04048, linear_loss=0.05096]
[2020-05-12 08:49:37.607]  Step 157141  [3.388 sec/step, loss=0.09479, avg_loss=0.09301, mel_loss=0.04261, linear_loss=0.05219]
[2020-05-12 08:49:40.621]  Step 157142  [3.294 sec/step, loss=0.09477, avg_loss=0.09306, mel_loss=0.04235, linear_loss=0.05242]
[2020-05-12 08:49:41.687]  Step 157143  [3.290 sec/step, loss=0.08420, avg_loss=0.09301, mel_loss=0.03633, linear_loss=0.04787]
[2020-05-12 08:49:42.696]  Step 157144  [3.212 sec/step, loss=0.07716, avg_loss=0.09277, mel_loss=0.03303, linear_loss=0.04413]
[2020-05-12 08:49:48.640]  Step 157145  [3.254 sec/step, loss=0.09893, avg_loss=0.09286, mel_loss=0.04557, linear_loss=0.05336]
[2020-05-12 08:49:54.174]  Step 157146  [3.294 sec/step, loss=0.09824, avg_loss=0.09295, mel_loss=0.04473, linear_loss=0.05351]
[2020-05-12 08:49:55.316]  Step 157147  [3.297 sec/step, loss=0.08197, avg_loss=0.09299, mel_loss=0.03519, linear_loss=0.04678]
[2020-05-12 08:49:56.719]  Step 157148  [3.222 sec/step, loss=0.08664, avg_loss=0.09273, mel_loss=0.03771, linear_loss=0.04892]
[2020-05-12 08:49:57.673]  Step 157149  [3.209 sec/step, loss=0.08080, avg_loss=0.09261, mel_loss=0.03471, linear_loss=0.04609]
[2020-05-12 08:49:58.206]  Step 157150  [3.188 sec/step, loss=0.06819, avg_loss=0.09236, mel_loss=0.02997, linear_loss=0.03822]
[2020-05-12 08:49:58.206]  Writing summary at step: 157150
[2020-05-12 08:50:00.672]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157150
[2020-05-12 08:50:02.241]  Saving audio and alignment...
[2020-05-12 08:50:12.928]  Input: 여러분은 지금 현대자동차가 주최하는 현 뮤직 아틀리에 콘서트 와 함께하고 계십니다 이렇게 언급해 주면~_______________________________
[2020-05-12 08:50:15.754]  Step 157151  [3.175 sec/step, loss=0.09184, avg_loss=0.09228, mel_loss=0.04092, linear_loss=0.05092]
[2020-05-12 08:50:20.628]  Step 157152  [3.193 sec/step, loss=0.09614, avg_loss=0.09224, mel_loss=0.04345, linear_loss=0.05269]
[2020-05-12 08:50:24.387]  Step 157153  [3.218 sec/step, loss=0.09750, avg_loss=0.09233, mel_loss=0.04376, linear_loss=0.05375]
[2020-05-12 08:50:26.157]  Step 157154  [3.182 sec/step, loss=0.08928, avg_loss=0.09201, mel_loss=0.03885, linear_loss=0.05043]
[2020-05-12 08:50:28.183]  Step 157155  [3.155 sec/step, loss=0.09018, avg_loss=0.09175, mel_loss=0.03983, linear_loss=0.05035]
[2020-05-12 08:50:32.622]  Step 157156  [3.185 sec/step, loss=0.09777, avg_loss=0.09183, mel_loss=0.04429, linear_loss=0.05348]
[2020-05-12 08:50:33.437]  Step 157157  [3.173 sec/step, loss=0.07507, avg_loss=0.09163, mel_loss=0.03202, linear_loss=0.04306]
[2020-05-12 08:50:36.082]  Step 157158  [3.123 sec/step, loss=0.09082, avg_loss=0.09134, mel_loss=0.04019, linear_loss=0.05063]
[2020-05-12 08:50:50.816]  Step 157159  [3.235 sec/step, loss=0.07941, avg_loss=0.09109, mel_loss=0.03818, linear_loss=0.04122]
[2020-05-12 08:50:51.667]  Step 157160  [3.225 sec/step, loss=0.07524, avg_loss=0.09092, mel_loss=0.03248, linear_loss=0.04276]
[2020-05-12 08:50:53.124]  Generated 32 batches of size 32 in 19.681 sec
[2020-05-12 08:50:53.176]  Step 157161  [3.233 sec/step, loss=0.08855, avg_loss=0.09101, mel_loss=0.03830, linear_loss=0.05024]
[2020-05-12 08:50:55.874]  Step 157162  [3.192 sec/step, loss=0.09052, avg_loss=0.09081, mel_loss=0.04010, linear_loss=0.05041]
[2020-05-12 08:50:58.496]  Step 157163  [3.202 sec/step, loss=0.08788, avg_loss=0.09074, mel_loss=0.03843, linear_loss=0.04945]
[2020-05-12 08:51:01.525]  Step 157164  [3.223 sec/step, loss=0.08704, avg_loss=0.09079, mel_loss=0.03800, linear_loss=0.04904]
[2020-05-12 08:51:11.421]  Step 157165  [3.311 sec/step, loss=0.09628, avg_loss=0.09089, mel_loss=0.04490, linear_loss=0.05137]
[2020-05-12 08:51:12.805]  Step 157166  [3.192 sec/step, loss=0.08183, avg_loss=0.09076, mel_loss=0.03573, linear_loss=0.04609]
[2020-05-12 08:51:14.023]  Step 157167  [3.182 sec/step, loss=0.08276, avg_loss=0.09063, mel_loss=0.03557, linear_loss=0.04720]
[2020-05-12 08:51:18.616]  Step 157168  [3.191 sec/step, loss=0.09652, avg_loss=0.09059, mel_loss=0.04362, linear_loss=0.05290]
[2020-05-12 08:51:23.970]  Step 157169  [3.236 sec/step, loss=0.09905, avg_loss=0.09083, mel_loss=0.04534, linear_loss=0.05371]
[2020-05-12 08:51:25.025]  Step 157170  [3.233 sec/step, loss=0.07843, avg_loss=0.09072, mel_loss=0.03384, linear_loss=0.04459]
[2020-05-12 08:51:26.656]  Step 157171  [3.206 sec/step, loss=0.08929, avg_loss=0.09056, mel_loss=0.03931, linear_loss=0.04998]
[2020-05-12 08:51:29.258]  Step 157172  [3.203 sec/step, loss=0.09077, avg_loss=0.09048, mel_loss=0.03997, linear_loss=0.05079]
[2020-05-12 08:51:34.119]  Step 157173  [3.241 sec/step, loss=0.09599, avg_loss=0.09059, mel_loss=0.04337, linear_loss=0.05262]
[2020-05-12 08:51:34.683]  Step 157174  [3.209 sec/step, loss=0.07253, avg_loss=0.09031, mel_loss=0.03180, linear_loss=0.04072]
[2020-05-12 08:51:36.155]  Step 157175  [3.196 sec/step, loss=0.08496, avg_loss=0.09017, mel_loss=0.03697, linear_loss=0.04799]
[2020-05-12 08:51:49.353]  Step 157176  [3.318 sec/step, loss=0.08115, avg_loss=0.09016, mel_loss=0.03836, linear_loss=0.04279]
[2020-05-12 08:51:52.964]  Step 157177  [3.324 sec/step, loss=0.09538, avg_loss=0.09011, mel_loss=0.04240, linear_loss=0.05297]
[2020-05-12 08:51:54.610]  Step 157178  [3.308 sec/step, loss=0.08831, avg_loss=0.08999, mel_loss=0.03864, linear_loss=0.04967]
[2020-05-12 08:51:57.816]  Step 157179  [3.332 sec/step, loss=0.09636, avg_loss=0.09019, mel_loss=0.04298, linear_loss=0.05338]
[2020-05-12 08:51:58.621]  Step 157180  [3.323 sec/step, loss=0.07694, avg_loss=0.09002, mel_loss=0.03320, linear_loss=0.04374]
[2020-05-12 08:52:02.051]  Step 157181  [3.307 sec/step, loss=0.09226, avg_loss=0.08992, mel_loss=0.04126, linear_loss=0.05099]
[2020-05-12 08:52:09.360]  Step 157182  [3.317 sec/step, loss=0.09928, avg_loss=0.08987, mel_loss=0.04544, linear_loss=0.05384]
[2020-05-12 08:52:10.636]  Step 157183  [3.243 sec/step, loss=0.08253, avg_loss=0.08963, mel_loss=0.03569, linear_loss=0.04684]
[2020-05-12 08:52:12.589]  Step 157184  [3.189 sec/step, loss=0.08870, avg_loss=0.08949, mel_loss=0.03872, linear_loss=0.04998]
[2020-05-12 08:52:20.913]  Step 157185  [3.251 sec/step, loss=0.09717, avg_loss=0.08952, mel_loss=0.04516, linear_loss=0.05201]
[2020-05-12 08:52:27.747]  Step 157186  [3.308 sec/step, loss=0.09787, avg_loss=0.08963, mel_loss=0.04478, linear_loss=0.05309]
[2020-05-12 08:52:29.542]  Step 157187  [3.312 sec/step, loss=0.08739, avg_loss=0.08961, mel_loss=0.03781, linear_loss=0.04958]
[2020-05-12 08:52:30.885]  Step 157188  [3.313 sec/step, loss=0.08518, avg_loss=0.08961, mel_loss=0.03691, linear_loss=0.04827]
[2020-05-12 08:52:36.676]  Step 157189  [3.361 sec/step, loss=0.09871, avg_loss=0.08976, mel_loss=0.04499, linear_loss=0.05372]
[2020-05-12 08:52:38.469]  Generated 32 batches of size 32 in 1.787 sec
[2020-05-12 08:52:38.829]  Step 157190  [3.341 sec/step, loss=0.08867, avg_loss=0.08967, mel_loss=0.03874, linear_loss=0.04992]
[2020-05-12 08:52:42.571]  Step 157191  [3.365 sec/step, loss=0.09565, avg_loss=0.08975, mel_loss=0.04287, linear_loss=0.05278]
[2020-05-12 08:52:45.740]  Step 157192  [3.391 sec/step, loss=0.09478, avg_loss=0.08999, mel_loss=0.04223, linear_loss=0.05255]
[2020-05-12 08:52:48.643]  Step 157193  [3.384 sec/step, loss=0.09228, avg_loss=0.08990, mel_loss=0.04121, linear_loss=0.05107]
[2020-05-12 08:52:49.546]  Step 157194  [3.254 sec/step, loss=0.08003, avg_loss=0.08991, mel_loss=0.03395, linear_loss=0.04608]
[2020-05-12 08:52:51.797]  Step 157195  [3.260 sec/step, loss=0.09069, avg_loss=0.08993, mel_loss=0.03985, linear_loss=0.05084]
[2020-05-12 08:52:54.246]  Step 157196  [3.265 sec/step, loss=0.09216, avg_loss=0.08995, mel_loss=0.04071, linear_loss=0.05146]
[2020-05-12 08:52:54.911]  Step 157197  [3.237 sec/step, loss=0.07332, avg_loss=0.08970, mel_loss=0.03170, linear_loss=0.04162]
[2020-05-12 08:52:59.140]  Step 157198  [3.232 sec/step, loss=0.09528, avg_loss=0.08965, mel_loss=0.04274, linear_loss=0.05254]
[2020-05-12 08:53:00.375]  Step 157199  [3.224 sec/step, loss=0.08154, avg_loss=0.08954, mel_loss=0.03488, linear_loss=0.04667]
[2020-05-12 08:53:03.085]  Step 157200  [3.217 sec/step, loss=0.09083, avg_loss=0.08947, mel_loss=0.04001, linear_loss=0.05082]
[2020-05-12 08:53:03.085]  Writing summary at step: 157200
[2020-05-12 08:53:06.181]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157200
[2020-05-12 08:53:07.738]  Saving audio and alignment...
[2020-05-12 08:53:17.533]  Input: 어 늘 합격을 잘하는 친구들을 보면 표정에도 좀 변화가 있어요 그 내용에 맞게~________________________________________________________
[2020-05-12 08:53:25.805]  Step 157201  [3.258 sec/step, loss=0.09557, avg_loss=0.08942, mel_loss=0.04416, linear_loss=0.05141]
[2020-05-12 08:53:27.210]  Step 157202  [3.248 sec/step, loss=0.08679, avg_loss=0.08933, mel_loss=0.03768, linear_loss=0.04911]
[2020-05-12 08:53:31.715]  Step 157203  [3.268 sec/step, loss=0.09673, avg_loss=0.08937, mel_loss=0.04353, linear_loss=0.05319]
[2020-05-12 08:53:38.435]  Step 157204  [3.327 sec/step, loss=0.09642, avg_loss=0.08951, mel_loss=0.04415, linear_loss=0.05228]
[2020-05-12 08:53:39.286]  Step 157205  [3.303 sec/step, loss=0.07423, avg_loss=0.08928, mel_loss=0.03185, linear_loss=0.04238]
[2020-05-12 08:53:40.826]  Step 157206  [3.307 sec/step, loss=0.08708, avg_loss=0.08930, mel_loss=0.03774, linear_loss=0.04934]
[2020-05-12 08:53:41.396]  Step 157207  [3.291 sec/step, loss=0.06828, avg_loss=0.08906, mel_loss=0.02969, linear_loss=0.03860]
[2020-05-12 08:53:45.049]  Step 157208  [3.275 sec/step, loss=0.09262, avg_loss=0.08900, mel_loss=0.04126, linear_loss=0.05137]
[2020-05-12 08:53:47.522]  Step 157209  [3.291 sec/step, loss=0.09150, avg_loss=0.08913, mel_loss=0.04041, linear_loss=0.05109]
[2020-05-12 08:53:48.885]  Step 157210  [3.297 sec/step, loss=0.08291, avg_loss=0.08921, mel_loss=0.03567, linear_loss=0.04724]
[2020-05-12 08:53:49.652]  Step 157211  [3.275 sec/step, loss=0.07845, avg_loss=0.08904, mel_loss=0.03323, linear_loss=0.04521]
[2020-05-12 08:53:51.671]  Step 157212  [3.250 sec/step, loss=0.08890, avg_loss=0.08895, mel_loss=0.03907, linear_loss=0.04983]
[2020-05-12 08:53:55.434]  Step 157213  [3.282 sec/step, loss=0.09593, avg_loss=0.08919, mel_loss=0.04288, linear_loss=0.05305]
[2020-05-12 08:53:56.513]  Step 157214  [3.258 sec/step, loss=0.08411, avg_loss=0.08906, mel_loss=0.03608, linear_loss=0.04803]
[2020-05-12 08:53:58.232]  Step 157215  [3.256 sec/step, loss=0.08707, avg_loss=0.08902, mel_loss=0.03785, linear_loss=0.04922]
[2020-05-12 08:53:59.237]  Step 157216  [3.181 sec/step, loss=0.07590, avg_loss=0.08880, mel_loss=0.03217, linear_loss=0.04373]
[2020-05-12 08:54:13.859]  Step 157217  [3.314 sec/step, loss=0.07452, avg_loss=0.08870, mel_loss=0.03524, linear_loss=0.03928]
[2020-05-12 08:54:15.959]  Step 157218  [3.189 sec/step, loss=0.09009, avg_loss=0.08880, mel_loss=0.03935, linear_loss=0.05074]
[2020-05-12 08:54:18.226]  Step 157219  [3.177 sec/step, loss=0.09021, avg_loss=0.08874, mel_loss=0.03946, linear_loss=0.05075]
[2020-05-12 08:54:23.946]  Step 157220  [3.220 sec/step, loss=0.09745, avg_loss=0.08884, mel_loss=0.04457, linear_loss=0.05288]
[2020-05-12 08:54:24.896]  Step 157221  [3.219 sec/step, loss=0.08141, avg_loss=0.08883, mel_loss=0.03510, linear_loss=0.04631]
[2020-05-12 08:54:29.166]  Step 157222  [3.238 sec/step, loss=0.09539, avg_loss=0.08888, mel_loss=0.04265, linear_loss=0.05274]
[2020-05-12 08:54:32.687]  Step 157223  [3.252 sec/step, loss=0.09419, avg_loss=0.08891, mel_loss=0.04198, linear_loss=0.05221]
[2020-05-12 08:54:35.386]  Step 157224  [3.269 sec/step, loss=0.09190, avg_loss=0.08902, mel_loss=0.04074, linear_loss=0.05116]
[2020-05-12 08:54:37.167]  Step 157225  [3.258 sec/step, loss=0.08799, avg_loss=0.08897, mel_loss=0.03814, linear_loss=0.04985]
[2020-05-12 08:54:42.155]  Step 157226  [3.233 sec/step, loss=0.09540, avg_loss=0.08892, mel_loss=0.04294, linear_loss=0.05247]
[2020-05-12 08:54:45.164]  Step 157227  [3.221 sec/step, loss=0.09360, avg_loss=0.08889, mel_loss=0.04163, linear_loss=0.05197]
[2020-05-12 08:54:47.052]  Step 157228  [3.202 sec/step, loss=0.08772, avg_loss=0.08879, mel_loss=0.03810, linear_loss=0.04962]
[2020-05-12 08:55:45.738]  Generated 32 batches of size 32 in 87.506 sec
[2020-05-12 08:55:46.703]  Step 157229  [3.788 sec/step, loss=0.07925, avg_loss=0.08878, mel_loss=0.03390, linear_loss=0.04535]
[2020-05-12 08:55:52.892]  Step 157230  [3.822 sec/step, loss=0.09530, avg_loss=0.08882, mel_loss=0.04327, linear_loss=0.05203]
[2020-05-12 08:55:56.814]  Step 157231  [3.798 sec/step, loss=0.09574, avg_loss=0.08879, mel_loss=0.04297, linear_loss=0.05276]
[2020-05-12 08:55:58.427]  Step 157232  [3.757 sec/step, loss=0.08701, avg_loss=0.08868, mel_loss=0.03804, linear_loss=0.04897]
[2020-05-12 08:56:00.799]  Step 157233  [3.762 sec/step, loss=0.09095, avg_loss=0.08870, mel_loss=0.04008, linear_loss=0.05087]
[2020-05-12 08:56:09.596]  Step 157234  [3.834 sec/step, loss=0.09778, avg_loss=0.08881, mel_loss=0.04535, linear_loss=0.05243]
[2020-05-12 08:56:14.573]  Step 157235  [3.859 sec/step, loss=0.09616, avg_loss=0.08885, mel_loss=0.04332, linear_loss=0.05285]
[2020-05-12 08:56:27.239]  Step 157236  [3.970 sec/step, loss=0.08685, avg_loss=0.08883, mel_loss=0.04091, linear_loss=0.04594]
[2020-05-12 08:56:29.100]  Step 157237  [3.957 sec/step, loss=0.08676, avg_loss=0.08873, mel_loss=0.03783, linear_loss=0.04894]
[2020-05-12 08:56:31.466]  Step 157238  [3.946 sec/step, loss=0.09043, avg_loss=0.08869, mel_loss=0.03950, linear_loss=0.05093]
[2020-05-12 08:56:32.258]  Step 157239  [3.918 sec/step, loss=0.07533, avg_loss=0.08849, mel_loss=0.03192, linear_loss=0.04341]
[2020-05-12 08:56:33.228]  Step 157240  [3.906 sec/step, loss=0.08293, avg_loss=0.08841, mel_loss=0.03516, linear_loss=0.04777]
[2020-05-12 08:56:34.540]  Step 157241  [3.877 sec/step, loss=0.08462, avg_loss=0.08830, mel_loss=0.03664, linear_loss=0.04798]
[2020-05-12 08:56:35.026]  Step 157242  [3.852 sec/step, loss=0.07550, avg_loss=0.08811, mel_loss=0.03294, linear_loss=0.04256]
[2020-05-12 08:56:37.967]  Step 157243  [3.871 sec/step, loss=0.09401, avg_loss=0.08821, mel_loss=0.04193, linear_loss=0.05208]
[2020-05-12 08:56:39.411]  Step 157244  [3.875 sec/step, loss=0.08490, avg_loss=0.08829, mel_loss=0.03678, linear_loss=0.04812]
[2020-05-12 08:56:40.550]  Step 157245  [3.827 sec/step, loss=0.08060, avg_loss=0.08810, mel_loss=0.03491, linear_loss=0.04569]
[2020-05-12 08:56:46.990]  Step 157246  [3.836 sec/step, loss=0.09772, avg_loss=0.08810, mel_loss=0.04470, linear_loss=0.05301]
[2020-05-12 08:56:47.598]  Step 157247  [3.831 sec/step, loss=0.07690, avg_loss=0.08805, mel_loss=0.03451, linear_loss=0.04238]
[2020-05-12 08:56:49.755]  Step 157248  [3.838 sec/step, loss=0.09032, avg_loss=0.08809, mel_loss=0.03996, linear_loss=0.05036]
[2020-05-12 08:56:51.105]  Step 157249  [3.842 sec/step, loss=0.08720, avg_loss=0.08815, mel_loss=0.03765, linear_loss=0.04956]
[2020-05-12 08:56:55.851]  Step 157250  [3.884 sec/step, loss=0.09590, avg_loss=0.08843, mel_loss=0.04344, linear_loss=0.05245]
[2020-05-12 08:56:55.851]  Writing summary at step: 157250
[2020-05-12 08:56:57.877]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157250
[2020-05-12 08:56:59.424]  Saving audio and alignment...
[2020-05-12 08:57:04.512]  Input: 다음으로 문어체와 동일어 반복을 피해 주셔야 돼요~_________________
[2020-05-12 08:57:05.613]  Step 157251  [3.867 sec/step, loss=0.07993, avg_loss=0.08831, mel_loss=0.03435, linear_loss=0.04559]
[2020-05-12 08:57:09.812]  Step 157252  [3.860 sec/step, loss=0.09525, avg_loss=0.08830, mel_loss=0.04299, linear_loss=0.05226]
[2020-05-12 08:57:17.560]  Step 157253  [3.900 sec/step, loss=0.09765, avg_loss=0.08830, mel_loss=0.04496, linear_loss=0.05269]
[2020-05-12 08:57:21.704]  Step 157254  [3.924 sec/step, loss=0.09294, avg_loss=0.08834, mel_loss=0.04142, linear_loss=0.05152]
[2020-05-12 08:57:25.107]  Step 157255  [3.938 sec/step, loss=0.09261, avg_loss=0.08836, mel_loss=0.04123, linear_loss=0.05138]
[2020-05-12 08:57:27.787]  Step 157256  [3.920 sec/step, loss=0.09003, avg_loss=0.08828, mel_loss=0.03981, linear_loss=0.05022]
[2020-05-12 08:57:29.554]  Step 157257  [3.930 sec/step, loss=0.08736, avg_loss=0.08841, mel_loss=0.03813, linear_loss=0.04923]
[2020-05-12 08:57:33.037]  Step 157258  [3.938 sec/step, loss=0.09371, avg_loss=0.08844, mel_loss=0.04171, linear_loss=0.05199]
[2020-05-12 08:57:47.747]  Generated 32 batches of size 32 in 47.740 sec
[2020-05-12 08:57:48.343]  Step 157259  [3.944 sec/step, loss=0.06729, avg_loss=0.08831, mel_loss=0.02929, linear_loss=0.03800]
[2020-05-12 08:57:51.709]  Step 157260  [3.969 sec/step, loss=0.09541, avg_loss=0.08852, mel_loss=0.04253, linear_loss=0.05289]
[2020-05-12 08:57:52.737]  Step 157261  [3.964 sec/step, loss=0.07932, avg_loss=0.08842, mel_loss=0.03416, linear_loss=0.04516]
[2020-05-12 08:57:54.929]  Step 157262  [3.959 sec/step, loss=0.09019, avg_loss=0.08842, mel_loss=0.03933, linear_loss=0.05086]
[2020-05-12 08:57:57.522]  Step 157263  [3.959 sec/step, loss=0.09017, avg_loss=0.08844, mel_loss=0.03977, linear_loss=0.05039]
[2020-05-12 08:57:58.629]  Step 157264  [3.940 sec/step, loss=0.08268, avg_loss=0.08840, mel_loss=0.03538, linear_loss=0.04730]
[2020-05-12 08:58:05.304]  Step 157265  [3.907 sec/step, loss=0.09879, avg_loss=0.08842, mel_loss=0.04511, linear_loss=0.05368]
[2020-05-12 08:58:06.309]  Step 157266  [3.904 sec/step, loss=0.07886, avg_loss=0.08839, mel_loss=0.03353, linear_loss=0.04533]
[2020-05-12 08:58:09.221]  Step 157267  [3.921 sec/step, loss=0.09083, avg_loss=0.08848, mel_loss=0.04041, linear_loss=0.05042]
[2020-05-12 08:58:10.837]  Step 157268  [3.891 sec/step, loss=0.08509, avg_loss=0.08836, mel_loss=0.03696, linear_loss=0.04813]
[2020-05-12 08:58:12.073]  Step 157269  [3.850 sec/step, loss=0.08177, avg_loss=0.08819, mel_loss=0.03507, linear_loss=0.04670]
[2020-05-12 08:58:16.262]  Step 157270  [3.881 sec/step, loss=0.09643, avg_loss=0.08837, mel_loss=0.04315, linear_loss=0.05328]
[2020-05-12 08:58:18.139]  Step 157271  [3.883 sec/step, loss=0.08732, avg_loss=0.08835, mel_loss=0.03795, linear_loss=0.04937]
[2020-05-12 08:58:19.743]  Step 157272  [3.874 sec/step, loss=0.08881, avg_loss=0.08833, mel_loss=0.03836, linear_loss=0.05045]
[2020-05-12 08:58:21.773]  Step 157273  [3.845 sec/step, loss=0.09075, avg_loss=0.08828, mel_loss=0.03993, linear_loss=0.05082]
[2020-05-12 08:58:22.643]  Step 157274  [3.848 sec/step, loss=0.06986, avg_loss=0.08825, mel_loss=0.02981, linear_loss=0.04006]
[2020-05-12 08:58:24.770]  Step 157275  [3.855 sec/step, loss=0.09091, avg_loss=0.08831, mel_loss=0.03969, linear_loss=0.05121]
[2020-05-12 08:58:27.838]  Step 157276  [3.754 sec/step, loss=0.09265, avg_loss=0.08842, mel_loss=0.04095, linear_loss=0.05170]
[2020-05-12 08:58:29.599]  Step 157277  [3.735 sec/step, loss=0.08842, avg_loss=0.08835, mel_loss=0.03845, linear_loss=0.04997]
[2020-05-12 08:58:33.255]  Step 157278  [3.755 sec/step, loss=0.09404, avg_loss=0.08841, mel_loss=0.04186, linear_loss=0.05218]
[2020-05-12 08:58:34.649]  Step 157279  [3.737 sec/step, loss=0.08281, avg_loss=0.08828, mel_loss=0.03589, linear_loss=0.04692]
[2020-05-12 08:58:39.877]  Step 157280  [3.781 sec/step, loss=0.09476, avg_loss=0.08845, mel_loss=0.04274, linear_loss=0.05202]
[2020-05-12 08:58:42.300]  Step 157281  [3.771 sec/step, loss=0.09097, avg_loss=0.08844, mel_loss=0.03976, linear_loss=0.05121]
[2020-05-12 08:58:56.724]  Step 157282  [3.842 sec/step, loss=0.07468, avg_loss=0.08820, mel_loss=0.03523, linear_loss=0.03945]
[2020-05-12 08:59:04.026]  Step 157283  [3.903 sec/step, loss=0.09697, avg_loss=0.08834, mel_loss=0.04455, linear_loss=0.05241]
[2020-05-12 08:59:05.344]  Step 157284  [3.896 sec/step, loss=0.08490, avg_loss=0.08830, mel_loss=0.03669, linear_loss=0.04822]
[2020-05-12 08:59:06.895]  Generated 32 batches of size 32 in 24.589 sec
[2020-05-12 08:59:10.012]  Step 157285  [3.860 sec/step, loss=0.09494, avg_loss=0.08828, mel_loss=0.04228, linear_loss=0.05266]
[2020-05-12 08:59:10.826]  Step 157286  [3.799 sec/step, loss=0.07647, avg_loss=0.08807, mel_loss=0.03254, linear_loss=0.04393]
[2020-05-12 08:59:16.263]  Step 157287  [3.836 sec/step, loss=0.09581, avg_loss=0.08815, mel_loss=0.04348, linear_loss=0.05233]
[2020-05-12 08:59:20.415]  Step 157288  [3.864 sec/step, loss=0.09274, avg_loss=0.08823, mel_loss=0.04124, linear_loss=0.05150]
[2020-05-12 08:59:23.750]  Step 157289  [3.839 sec/step, loss=0.09272, avg_loss=0.08817, mel_loss=0.04140, linear_loss=0.05132]
[2020-05-12 08:59:32.511]  Step 157290  [3.905 sec/step, loss=0.09361, avg_loss=0.08822, mel_loss=0.04306, linear_loss=0.05055]
[2020-05-12 08:59:33.360]  Step 157291  [3.877 sec/step, loss=0.07459, avg_loss=0.08800, mel_loss=0.03160, linear_loss=0.04299]
[2020-05-12 08:59:35.079]  Step 157292  [3.862 sec/step, loss=0.08672, avg_loss=0.08792, mel_loss=0.03760, linear_loss=0.04912]
[2020-05-12 08:59:38.811]  Step 157293  [3.870 sec/step, loss=0.09503, avg_loss=0.08795, mel_loss=0.04226, linear_loss=0.05277]
[2020-05-12 08:59:40.759]  Step 157294  [3.881 sec/step, loss=0.08778, avg_loss=0.08803, mel_loss=0.03805, linear_loss=0.04974]
[2020-05-12 08:59:45.013]  Step 157295  [3.901 sec/step, loss=0.09453, avg_loss=0.08807, mel_loss=0.04224, linear_loss=0.05228]
[2020-05-12 08:59:47.315]  Step 157296  [3.899 sec/step, loss=0.09121, avg_loss=0.08806, mel_loss=0.04017, linear_loss=0.05104]
[2020-05-12 08:59:50.475]  Step 157297  [3.924 sec/step, loss=0.09259, avg_loss=0.08825, mel_loss=0.04131, linear_loss=0.05128]
[2020-05-12 08:59:51.470]  Step 157298  [3.892 sec/step, loss=0.08091, avg_loss=0.08811, mel_loss=0.03435, linear_loss=0.04656]
[2020-05-12 08:59:55.078]  Step 157299  [3.916 sec/step, loss=0.09724, avg_loss=0.08826, mel_loss=0.04341, linear_loss=0.05383]
[2020-05-12 09:00:04.004]  Step 157300  [3.978 sec/step, loss=0.09523, avg_loss=0.08831, mel_loss=0.04390, linear_loss=0.05133]
[2020-05-12 09:00:04.004]  Writing summary at step: 157300
[2020-05-12 09:00:09.587]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157300
[2020-05-12 09:00:11.183]  Saving audio and alignment...
[2020-05-12 09:00:14.698]  Input: 고맙습니다 이렇게 좋은 자리에~_______
[2020-05-12 09:00:16.847]  Step 157301  [3.917 sec/step, loss=0.08808, avg_loss=0.08823, mel_loss=0.03860, linear_loss=0.04948]
[2020-05-12 09:00:23.753]  Step 157302  [3.972 sec/step, loss=0.09409, avg_loss=0.08831, mel_loss=0.04303, linear_loss=0.05107]
[2020-05-12 09:00:25.207]  Step 157303  [3.941 sec/step, loss=0.08492, avg_loss=0.08819, mel_loss=0.03680, linear_loss=0.04812]
[2020-05-12 09:00:37.610]  Step 157304  [3.998 sec/step, loss=0.08716, avg_loss=0.08810, mel_loss=0.04086, linear_loss=0.04630]
[2020-05-12 09:00:38.642]  Step 157305  [4.000 sec/step, loss=0.07789, avg_loss=0.08813, mel_loss=0.03338, linear_loss=0.04451]
[2020-05-12 09:00:42.079]  Step 157306  [4.019 sec/step, loss=0.09287, avg_loss=0.08819, mel_loss=0.04121, linear_loss=0.05166]
[2020-05-12 09:00:46.565]  Step 157307  [4.058 sec/step, loss=0.09675, avg_loss=0.08847, mel_loss=0.04383, linear_loss=0.05292]
[2020-05-12 09:00:47.388]  Step 157308  [4.030 sec/step, loss=0.07106, avg_loss=0.08826, mel_loss=0.03052, linear_loss=0.04054]
[2020-05-12 09:00:49.000]  Step 157309  [4.021 sec/step, loss=0.08743, avg_loss=0.08822, mel_loss=0.03790, linear_loss=0.04953]
[2020-05-12 09:00:50.258]  Step 157310  [4.020 sec/step, loss=0.08298, avg_loss=0.08822, mel_loss=0.03568, linear_loss=0.04730]
[2020-05-12 09:00:55.199]  Step 157311  [4.062 sec/step, loss=0.09606, avg_loss=0.08840, mel_loss=0.04324, linear_loss=0.05282]
[2020-05-12 09:00:57.051]  Generated 32 batches of size 32 in 1.845 sec
[2020-05-12 09:00:57.882]  Step 157312  [4.068 sec/step, loss=0.08871, avg_loss=0.08839, mel_loss=0.03893, linear_loss=0.04978]
[2020-05-12 09:00:59.092]  Step 157313  [4.043 sec/step, loss=0.08050, avg_loss=0.08824, mel_loss=0.03433, linear_loss=0.04617]
[2020-05-12 09:00:59.692]  Step 157314  [4.038 sec/step, loss=0.07154, avg_loss=0.08811, mel_loss=0.03107, linear_loss=0.04047]
[2020-05-12 09:01:06.372]  Step 157315  [4.088 sec/step, loss=0.09739, avg_loss=0.08822, mel_loss=0.04425, linear_loss=0.05313]
[2020-05-12 09:01:10.960]  Step 157316  [4.123 sec/step, loss=0.09338, avg_loss=0.08839, mel_loss=0.04111, linear_loss=0.05227]
[2020-05-12 09:01:15.428]  Step 157317  [4.022 sec/step, loss=0.09378, avg_loss=0.08858, mel_loss=0.04163, linear_loss=0.05216]
[2020-05-12 09:01:18.330]  Step 157318  [4.030 sec/step, loss=0.09095, avg_loss=0.08859, mel_loss=0.03991, linear_loss=0.05104]
[2020-05-12 09:01:20.119]  Step 157319  [4.025 sec/step, loss=0.08583, avg_loss=0.08855, mel_loss=0.03723, linear_loss=0.04860]
[2020-05-12 09:01:21.465]  Step 157320  [3.981 sec/step, loss=0.08442, avg_loss=0.08842, mel_loss=0.03652, linear_loss=0.04789]
[2020-05-12 09:01:23.995]  Step 157321  [3.997 sec/step, loss=0.09115, avg_loss=0.08852, mel_loss=0.03999, linear_loss=0.05116]
[2020-05-12 09:01:26.475]  Step 157322  [3.979 sec/step, loss=0.09061, avg_loss=0.08847, mel_loss=0.03982, linear_loss=0.05078]
[2020-05-12 09:01:30.297]  Step 157323  [3.982 sec/step, loss=0.09590, avg_loss=0.08849, mel_loss=0.04266, linear_loss=0.05325]
[2020-05-12 09:01:31.760]  Step 157324  [3.970 sec/step, loss=0.08685, avg_loss=0.08843, mel_loss=0.03754, linear_loss=0.04931]
[2020-05-12 09:01:38.657]  Step 157325  [4.021 sec/step, loss=0.09964, avg_loss=0.08855, mel_loss=0.04545, linear_loss=0.05420]
[2020-05-12 09:01:43.329]  Step 157326  [4.018 sec/step, loss=0.09492, avg_loss=0.08855, mel_loss=0.04244, linear_loss=0.05248]
[2020-05-12 09:01:52.170]  Step 157327  [4.076 sec/step, loss=0.09653, avg_loss=0.08858, mel_loss=0.04475, linear_loss=0.05178]
[2020-05-12 09:01:53.335]  Step 157328  [4.069 sec/step, loss=0.08016, avg_loss=0.08850, mel_loss=0.03432, linear_loss=0.04583]
[2020-05-12 09:01:54.159]  Step 157329  [3.481 sec/step, loss=0.07293, avg_loss=0.08844, mel_loss=0.03151, linear_loss=0.04142]
[2020-05-12 09:02:00.056]  Step 157330  [3.478 sec/step, loss=0.09579, avg_loss=0.08844, mel_loss=0.04355, linear_loss=0.05224]
[2020-05-12 09:02:03.537]  Step 157331  [3.473 sec/step, loss=0.09351, avg_loss=0.08842, mel_loss=0.04160, linear_loss=0.05191]
[2020-05-12 09:02:05.246]  Step 157332  [3.474 sec/step, loss=0.08615, avg_loss=0.08841, mel_loss=0.03749, linear_loss=0.04866]
[2020-05-12 09:02:08.458]  Step 157333  [3.483 sec/step, loss=0.09439, avg_loss=0.08845, mel_loss=0.04205, linear_loss=0.05234]
[2020-05-12 09:02:10.520]  Step 157334  [3.415 sec/step, loss=0.08806, avg_loss=0.08835, mel_loss=0.03857, linear_loss=0.04949]
[2020-05-12 09:02:18.243]  Step 157335  [3.443 sec/step, loss=0.09902, avg_loss=0.08838, mel_loss=0.04556, linear_loss=0.05345]
[2020-05-12 09:02:20.419]  Step 157336  [3.338 sec/step, loss=0.09031, avg_loss=0.08841, mel_loss=0.03960, linear_loss=0.05070]
[2020-05-12 09:02:21.799]  Step 157337  [3.333 sec/step, loss=0.08393, avg_loss=0.08838, mel_loss=0.03610, linear_loss=0.04783]
[2020-05-12 09:02:24.551]  Step 157338  [3.337 sec/step, loss=0.09178, avg_loss=0.08840, mel_loss=0.04066, linear_loss=0.05112]
[2020-05-12 09:02:26.469]  Step 157339  [3.348 sec/step, loss=0.08887, avg_loss=0.08853, mel_loss=0.03867, linear_loss=0.05020]
[2020-05-12 09:02:40.787]  Step 157340  [3.482 sec/step, loss=0.07612, avg_loss=0.08846, mel_loss=0.03587, linear_loss=0.04025]
[2020-05-12 09:02:41.695]  Step 157341  [3.478 sec/step, loss=0.07630, avg_loss=0.08838, mel_loss=0.03256, linear_loss=0.04375]
[2020-05-12 09:02:43.038]  Step 157342  [3.486 sec/step, loss=0.08197, avg_loss=0.08844, mel_loss=0.03543, linear_loss=0.04654]
[2020-05-12 09:02:43.599]  Step 157343  [3.463 sec/step, loss=0.06956, avg_loss=0.08820, mel_loss=0.03030, linear_loss=0.03926]
[2020-05-12 09:02:44.703]  Step 157344  [3.459 sec/step, loss=0.08481, avg_loss=0.08820, mel_loss=0.03632, linear_loss=0.04850]
[2020-05-12 09:02:45.327]  Generated 32 batches of size 32 in 1.723 sec
[2020-05-12 09:02:48.895]  Step 157345  [3.490 sec/step, loss=0.09394, avg_loss=0.08833, mel_loss=0.04187, linear_loss=0.05207]
[2020-05-12 09:02:53.025]  Step 157346  [3.467 sec/step, loss=0.09489, avg_loss=0.08830, mel_loss=0.04266, linear_loss=0.05223]
[2020-05-12 09:02:55.914]  Step 157347  [3.489 sec/step, loss=0.09194, avg_loss=0.08846, mel_loss=0.04062, linear_loss=0.05132]
[2020-05-12 09:03:01.356]  Step 157348  [3.522 sec/step, loss=0.09424, avg_loss=0.08849, mel_loss=0.04259, linear_loss=0.05165]
[2020-05-12 09:03:03.124]  Step 157349  [3.526 sec/step, loss=0.08649, avg_loss=0.08849, mel_loss=0.03734, linear_loss=0.04916]
[2020-05-12 09:03:04.138]  Step 157350  [3.489 sec/step, loss=0.07760, avg_loss=0.08830, mel_loss=0.03347, linear_loss=0.04414]
[2020-05-12 09:03:04.138]  Writing summary at step: 157350
[2020-05-12 09:03:07.221]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157350
[2020-05-12 09:03:08.820]  Saving audio and alignment...
[2020-05-12 09:03:10.619]  Input: 말을 했을까요~_________
[2020-05-12 09:03:13.994]  Step 157351  [3.512 sec/step, loss=0.09308, avg_loss=0.08844, mel_loss=0.04107, linear_loss=0.05201]
[2020-05-12 09:03:27.898]  Step 157352  [3.609 sec/step, loss=0.07345, avg_loss=0.08822, mel_loss=0.03468, linear_loss=0.03877]
[2020-05-12 09:03:29.538]  Step 157353  [3.548 sec/step, loss=0.08583, avg_loss=0.08810, mel_loss=0.03756, linear_loss=0.04827]
[2020-05-12 09:03:32.027]  Step 157354  [3.531 sec/step, loss=0.08952, avg_loss=0.08807, mel_loss=0.03897, linear_loss=0.05056]
[2020-05-12 09:03:33.290]  Step 157355  [3.510 sec/step, loss=0.08152, avg_loss=0.08795, mel_loss=0.03501, linear_loss=0.04651]
[2020-05-12 09:03:34.816]  Step 157356  [3.498 sec/step, loss=0.08722, avg_loss=0.08793, mel_loss=0.03759, linear_loss=0.04963]
[2020-05-12 09:03:38.898]  Step 157357  [3.521 sec/step, loss=0.09644, avg_loss=0.08802, mel_loss=0.04282, linear_loss=0.05362]
[2020-05-12 09:03:40.822]  Step 157358  [3.506 sec/step, loss=0.08802, avg_loss=0.08796, mel_loss=0.03813, linear_loss=0.04989]
[2020-05-12 09:03:45.113]  Step 157359  [3.396 sec/step, loss=0.09579, avg_loss=0.08825, mel_loss=0.04285, linear_loss=0.05294]
[2020-05-12 09:03:45.983]  Step 157360  [3.371 sec/step, loss=0.07751, avg_loss=0.08807, mel_loss=0.03303, linear_loss=0.04447]
[2020-05-12 09:03:51.101]  Step 157361  [3.412 sec/step, loss=0.09545, avg_loss=0.08823, mel_loss=0.04327, linear_loss=0.05218]
[2020-05-12 09:03:51.865]  Step 157362  [3.397 sec/step, loss=0.07918, avg_loss=0.08812, mel_loss=0.03381, linear_loss=0.04537]
[2020-05-12 09:03:52.845]  Step 157363  [3.381 sec/step, loss=0.08370, avg_loss=0.08805, mel_loss=0.03602, linear_loss=0.04767]
[2020-05-12 09:03:54.205]  Step 157364  [3.384 sec/step, loss=0.08426, avg_loss=0.08807, mel_loss=0.03623, linear_loss=0.04802]
[2020-05-12 09:03:58.776]  Step 157365  [3.363 sec/step, loss=0.09573, avg_loss=0.08804, mel_loss=0.04280, linear_loss=0.05294]
[2020-05-12 09:04:02.423]  Step 157366  [3.389 sec/step, loss=0.09583, avg_loss=0.08821, mel_loss=0.04267, linear_loss=0.05316]
[2020-05-12 09:04:09.866]  Step 157367  [3.434 sec/step, loss=0.09716, avg_loss=0.08827, mel_loss=0.04447, linear_loss=0.05269]
[2020-05-12 09:04:11.257]  Step 157368  [3.432 sec/step, loss=0.08569, avg_loss=0.08828, mel_loss=0.03738, linear_loss=0.04830]
[2020-05-12 09:04:12.366]  Step 157369  [3.431 sec/step, loss=0.08041, avg_loss=0.08826, mel_loss=0.03414, linear_loss=0.04627]
[2020-05-12 09:04:18.006]  Step 157370  [3.445 sec/step, loss=0.09467, avg_loss=0.08825, mel_loss=0.04297, linear_loss=0.05170]
[2020-05-12 09:04:20.114]  Step 157371  [3.448 sec/step, loss=0.09028, avg_loss=0.08828, mel_loss=0.03947, linear_loss=0.05081]
[2020-05-12 09:04:22.365]  Step 157372  [3.454 sec/step, loss=0.08930, avg_loss=0.08828, mel_loss=0.03927, linear_loss=0.05003]
[2020-05-12 09:04:28.503]  Step 157373  [3.495 sec/step, loss=0.09450, avg_loss=0.08832, mel_loss=0.04312, linear_loss=0.05138]
[2020-05-12 09:04:29.053]  Step 157374  [3.492 sec/step, loss=0.07269, avg_loss=0.08835, mel_loss=0.03158, linear_loss=0.04111]
[2020-05-12 09:04:30.218]  Generated 32 batches of size 32 in 1.709 sec
[2020-05-12 09:04:37.310]  Step 157375  [3.553 sec/step, loss=0.09580, avg_loss=0.08839, mel_loss=0.04396, linear_loss=0.05184]
[2020-05-12 09:04:39.041]  Step 157376  [3.540 sec/step, loss=0.08771, avg_loss=0.08835, mel_loss=0.03789, linear_loss=0.04983]
[2020-05-12 09:04:41.067]  Step 157377  [3.543 sec/step, loss=0.08957, avg_loss=0.08836, mel_loss=0.03905, linear_loss=0.05052]
[2020-05-12 09:04:44.589]  Step 157378  [3.541 sec/step, loss=0.09212, avg_loss=0.08834, mel_loss=0.04068, linear_loss=0.05143]
[2020-05-12 09:04:47.626]  Step 157379  [3.558 sec/step, loss=0.09473, avg_loss=0.08846, mel_loss=0.04205, linear_loss=0.05268]
[2020-05-12 09:04:50.532]  Step 157380  [3.535 sec/step, loss=0.09167, avg_loss=0.08843, mel_loss=0.04088, linear_loss=0.05079]
[2020-05-12 09:04:51.371]  Step 157381  [3.519 sec/step, loss=0.07186, avg_loss=0.08823, mel_loss=0.03090, linear_loss=0.04095]
[2020-05-12 09:04:53.999]  Step 157382  [3.401 sec/step, loss=0.08869, avg_loss=0.08837, mel_loss=0.03889, linear_loss=0.04980]
[2020-05-12 09:04:58.550]  Step 157383  [3.373 sec/step, loss=0.09690, avg_loss=0.08837, mel_loss=0.04342, linear_loss=0.05348]
[2020-05-12 09:05:00.844]  Step 157384  [3.383 sec/step, loss=0.08969, avg_loss=0.08842, mel_loss=0.03940, linear_loss=0.05030]
[2020-05-12 09:05:04.514]  Step 157385  [3.373 sec/step, loss=0.09334, avg_loss=0.08841, mel_loss=0.04158, linear_loss=0.05176]
[2020-05-12 09:05:05.313]  Step 157386  [3.373 sec/step, loss=0.07614, avg_loss=0.08840, mel_loss=0.03173, linear_loss=0.04441]
[2020-05-12 09:05:05.889]  Step 157387  [3.324 sec/step, loss=0.06686, avg_loss=0.08811, mel_loss=0.02907, linear_loss=0.03779]
[2020-05-12 09:05:11.472]  Step 157388  [3.339 sec/step, loss=0.09673, avg_loss=0.08815, mel_loss=0.04362, linear_loss=0.05310]
[2020-05-12 09:05:18.383]  Step 157389  [3.374 sec/step, loss=0.09581, avg_loss=0.08818, mel_loss=0.04387, linear_loss=0.05193]
[2020-05-12 09:05:20.147]  Step 157390  [3.304 sec/step, loss=0.08686, avg_loss=0.08812, mel_loss=0.03751, linear_loss=0.04935]
[2020-05-12 09:05:23.080]  Step 157391  [3.325 sec/step, loss=0.09222, avg_loss=0.08829, mel_loss=0.04070, linear_loss=0.05152]
[2020-05-12 09:05:25.575]  Step 157392  [3.333 sec/step, loss=0.09058, avg_loss=0.08833, mel_loss=0.03982, linear_loss=0.05076]
[2020-05-12 09:05:27.678]  Step 157393  [3.317 sec/step, loss=0.08975, avg_loss=0.08828, mel_loss=0.03937, linear_loss=0.05038]
[2020-05-12 09:05:31.120]  Step 157394  [3.332 sec/step, loss=0.09231, avg_loss=0.08832, mel_loss=0.04105, linear_loss=0.05126]
[2020-05-12 09:05:32.121]  Step 157395  [3.299 sec/step, loss=0.07868, avg_loss=0.08817, mel_loss=0.03333, linear_loss=0.04536]
[2020-05-12 09:05:42.109]  Step 157396  [3.376 sec/step, loss=0.09441, avg_loss=0.08820, mel_loss=0.04352, linear_loss=0.05089]
[2020-05-12 09:05:56.479]  Step 157397  [3.488 sec/step, loss=0.08253, avg_loss=0.08810, mel_loss=0.03853, linear_loss=0.04400]
[2020-05-12 09:05:57.601]  Step 157398  [3.489 sec/step, loss=0.08292, avg_loss=0.08812, mel_loss=0.03545, linear_loss=0.04747]
[2020-05-12 09:05:59.494]  Step 157399  [3.472 sec/step, loss=0.08665, avg_loss=0.08801, mel_loss=0.03749, linear_loss=0.04915]
[2020-05-12 09:06:03.912]  Step 157400  [3.427 sec/step, loss=0.09477, avg_loss=0.08801, mel_loss=0.04242, linear_loss=0.05234]
[2020-05-12 09:06:03.912]  Writing summary at step: 157400
[2020-05-12 09:06:04.600]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157400
[2020-05-12 09:06:06.178]  Saving audio and alignment...
[2020-05-12 09:06:09.835]  Input: 그리고 특별히 어떤 핵심을 담은~________
[2020-05-12 09:06:11.594]  Step 157401  [3.423 sec/step, loss=0.08448, avg_loss=0.08797, mel_loss=0.03655, linear_loss=0.04793]
[2020-05-12 09:06:13.384]  Step 157402  [3.372 sec/step, loss=0.08845, avg_loss=0.08791, mel_loss=0.03840, linear_loss=0.05005]
[2020-05-12 09:06:17.848]  Step 157403  [3.402 sec/step, loss=0.09269, avg_loss=0.08799, mel_loss=0.04137, linear_loss=0.05133]
[2020-05-12 09:06:19.783]  Generated 32 batches of size 32 in 1.929 sec
[2020-05-12 09:06:21.402]  Step 157404  [3.314 sec/step, loss=0.09369, avg_loss=0.08806, mel_loss=0.04196, linear_loss=0.05172]
[2020-05-12 09:06:24.601]  Step 157405  [3.335 sec/step, loss=0.09317, avg_loss=0.08821, mel_loss=0.04154, linear_loss=0.05163]
[2020-05-12 09:06:25.631]  Step 157406  [3.311 sec/step, loss=0.07941, avg_loss=0.08808, mel_loss=0.03390, linear_loss=0.04551]
[2020-05-12 09:06:30.876]  Step 157407  [3.319 sec/step, loss=0.09407, avg_loss=0.08805, mel_loss=0.04248, linear_loss=0.05159]
[2020-05-12 09:06:32.111]  Step 157408  [3.323 sec/step, loss=0.08026, avg_loss=0.08814, mel_loss=0.03457, linear_loss=0.04569]
[2020-05-12 09:06:34.958]  Step 157409  [3.335 sec/step, loss=0.09139, avg_loss=0.08818, mel_loss=0.04051, linear_loss=0.05087]
[2020-05-12 09:06:41.642]  Step 157410  [3.390 sec/step, loss=0.09580, avg_loss=0.08831, mel_loss=0.04354, linear_loss=0.05227]
[2020-05-12 09:06:42.974]  Step 157411  [3.353 sec/step, loss=0.08537, avg_loss=0.08820, mel_loss=0.03681, linear_loss=0.04857]
[2020-05-12 09:06:44.375]  Step 157412  [3.341 sec/step, loss=0.08319, avg_loss=0.08815, mel_loss=0.03585, linear_loss=0.04733]
[2020-05-12 09:06:48.589]  Step 157413  [3.371 sec/step, loss=0.09386, avg_loss=0.08828, mel_loss=0.04177, linear_loss=0.05209]
[2020-05-12 09:06:50.569]  Step 157414  [3.384 sec/step, loss=0.08879, avg_loss=0.08845, mel_loss=0.03866, linear_loss=0.05013]
[2020-05-12 09:06:55.927]  Step 157415  [3.371 sec/step, loss=0.09488, avg_loss=0.08843, mel_loss=0.04273, linear_loss=0.05216]
[2020-05-12 09:07:03.478]  Step 157416  [3.401 sec/step, loss=0.09725, avg_loss=0.08847, mel_loss=0.04453, linear_loss=0.05273]
[2020-05-12 09:07:12.393]  Step 157417  [3.445 sec/step, loss=0.09445, avg_loss=0.08847, mel_loss=0.04330, linear_loss=0.05115]
[2020-05-12 09:07:14.875]  Step 157418  [3.441 sec/step, loss=0.08892, avg_loss=0.08845, mel_loss=0.03885, linear_loss=0.05007]
[2020-05-12 09:07:16.281]  Step 157419  [3.437 sec/step, loss=0.08196, avg_loss=0.08841, mel_loss=0.03528, linear_loss=0.04668]
[2020-05-12 09:07:18.433]  Step 157420  [3.445 sec/step, loss=0.08851, avg_loss=0.08845, mel_loss=0.03886, linear_loss=0.04965]
[2020-05-12 09:07:22.195]  Step 157421  [3.458 sec/step, loss=0.09439, avg_loss=0.08849, mel_loss=0.04192, linear_loss=0.05247]
[2020-05-12 09:07:25.276]  Step 157422  [3.464 sec/step, loss=0.09250, avg_loss=0.08851, mel_loss=0.04112, linear_loss=0.05138]
[2020-05-12 09:07:30.002]  Step 157423  [3.473 sec/step, loss=0.09438, avg_loss=0.08849, mel_loss=0.04209, linear_loss=0.05229]
[2020-05-12 09:07:31.021]  Step 157424  [3.468 sec/step, loss=0.07922, avg_loss=0.08841, mel_loss=0.03390, linear_loss=0.04532]
[2020-05-12 09:07:31.588]  Step 157425  [3.405 sec/step, loss=0.06775, avg_loss=0.08810, mel_loss=0.02903, linear_loss=0.03872]
[2020-05-12 09:07:37.240]  Step 157426  [3.415 sec/step, loss=0.09704, avg_loss=0.08812, mel_loss=0.04421, linear_loss=0.05283]
[2020-05-12 09:07:41.672]  Step 157427  [3.371 sec/step, loss=0.09577, avg_loss=0.08811, mel_loss=0.04300, linear_loss=0.05278]
[2020-05-12 09:07:44.518]  Step 157428  [3.388 sec/step, loss=0.09100, avg_loss=0.08822, mel_loss=0.04012, linear_loss=0.05089]
[2020-05-12 09:07:47.895]  Step 157429  [3.413 sec/step, loss=0.09288, avg_loss=0.08842, mel_loss=0.04111, linear_loss=0.05177]
[2020-05-12 09:07:48.734]  Step 157430  [3.362 sec/step, loss=0.07444, avg_loss=0.08820, mel_loss=0.03172, linear_loss=0.04272]
[2020-05-12 09:07:52.183]  Step 157431  [3.362 sec/step, loss=0.09394, avg_loss=0.08821, mel_loss=0.04168, linear_loss=0.05226]
[2020-05-12 09:07:53.448]  Step 157432  [3.358 sec/step, loss=0.07999, avg_loss=0.08815, mel_loss=0.03436, linear_loss=0.04563]
[2020-05-12 09:07:55.157]  Step 157433  [3.343 sec/step, loss=0.08683, avg_loss=0.08807, mel_loss=0.03758, linear_loss=0.04926]
[2020-05-12 09:08:01.954]  Step 157434  [3.390 sec/step, loss=0.09579, avg_loss=0.08815, mel_loss=0.04361, linear_loss=0.05218]
[2020-05-12 09:08:04.640]  Step 157435  [3.340 sec/step, loss=0.09054, avg_loss=0.08806, mel_loss=0.03976, linear_loss=0.05079]
[2020-05-12 09:08:06.443]  Generated 32 batches of size 32 in 1.798 sec
[2020-05-12 09:08:07.863]  Step 157436  [3.350 sec/step, loss=0.09612, avg_loss=0.08812, mel_loss=0.04254, linear_loss=0.05357]
[2020-05-12 09:08:22.509]  Step 157437  [3.483 sec/step, loss=0.07513, avg_loss=0.08803, mel_loss=0.03534, linear_loss=0.03979]
[2020-05-12 09:08:23.334]  Step 157438  [3.464 sec/step, loss=0.07291, avg_loss=0.08784, mel_loss=0.03137, linear_loss=0.04154]
[2020-05-12 09:08:25.160]  Step 157439  [3.463 sec/step, loss=0.08657, avg_loss=0.08782, mel_loss=0.03728, linear_loss=0.04929]
[2020-05-12 09:08:26.176]  Step 157440  [3.330 sec/step, loss=0.07759, avg_loss=0.08784, mel_loss=0.03288, linear_loss=0.04471]
[2020-05-12 09:08:27.307]  Step 157441  [3.332 sec/step, loss=0.08250, avg_loss=0.08790, mel_loss=0.03511, linear_loss=0.04739]
[2020-05-12 09:08:28.959]  Step 157442  [3.335 sec/step, loss=0.08466, avg_loss=0.08793, mel_loss=0.03645, linear_loss=0.04821]
[2020-05-12 09:08:30.449]  Step 157443  [3.344 sec/step, loss=0.08448, avg_loss=0.08807, mel_loss=0.03669, linear_loss=0.04779]
[2020-05-12 09:08:32.684]  Step 157444  [3.356 sec/step, loss=0.08874, avg_loss=0.08811, mel_loss=0.03891, linear_loss=0.04984]
[2020-05-12 09:08:34.493]  Step 157445  [3.332 sec/step, loss=0.08546, avg_loss=0.08803, mel_loss=0.03704, linear_loss=0.04842]
[2020-05-12 09:08:35.310]  Step 157446  [3.299 sec/step, loss=0.07558, avg_loss=0.08784, mel_loss=0.03214, linear_loss=0.04344]
[2020-05-12 09:08:43.862]  Step 157447  [3.355 sec/step, loss=0.09183, avg_loss=0.08783, mel_loss=0.04217, linear_loss=0.04967]
[2020-05-12 09:08:46.164]  Step 157448  [3.324 sec/step, loss=0.08845, avg_loss=0.08778, mel_loss=0.03886, linear_loss=0.04959]
[2020-05-12 09:08:50.307]  Step 157449  [3.348 sec/step, loss=0.09346, avg_loss=0.08785, mel_loss=0.04189, linear_loss=0.05157]
[2020-05-12 09:08:51.069]  Step 157450  [3.345 sec/step, loss=0.07323, avg_loss=0.08780, mel_loss=0.03145, linear_loss=0.04178]
[2020-05-12 09:08:51.069]  Writing summary at step: 157450
[2020-05-12 09:08:54.875]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157450
[2020-05-12 09:08:56.460]  Saving audio and alignment...
[2020-05-12 09:09:06.344]  Input: 올렸는데 이번에는 저축에 주는 날이라 생각이 들어요 이렇게 어미처리 여도 다르게 주고 있습니다~_______________________
[2020-05-12 09:09:09.722]  Step 157451  [3.345 sec/step, loss=0.09152, avg_loss=0.08779, mel_loss=0.04076, linear_loss=0.05076]
[2020-05-12 09:09:12.300]  Step 157452  [3.232 sec/step, loss=0.08949, avg_loss=0.08795, mel_loss=0.03906, linear_loss=0.05043]
[2020-05-12 09:09:13.477]  Step 157453  [3.227 sec/step, loss=0.08025, avg_loss=0.08789, mel_loss=0.03429, linear_loss=0.04596]
[2020-05-12 09:09:14.757]  Step 157454  [3.215 sec/step, loss=0.08216, avg_loss=0.08782, mel_loss=0.03561, linear_loss=0.04655]
[2020-05-12 09:09:15.871]  Step 157455  [3.214 sec/step, loss=0.08147, avg_loss=0.08782, mel_loss=0.03480, linear_loss=0.04667]
[2020-05-12 09:09:16.794]  Step 157456  [3.208 sec/step, loss=0.07822, avg_loss=0.08773, mel_loss=0.03335, linear_loss=0.04487]
[2020-05-12 09:09:21.392]  Step 157457  [3.213 sec/step, loss=0.09680, avg_loss=0.08773, mel_loss=0.04347, linear_loss=0.05332]
[2020-05-12 09:09:33.103]  Step 157458  [3.311 sec/step, loss=0.08926, avg_loss=0.08774, mel_loss=0.04190, linear_loss=0.04737]
[2020-05-12 09:09:34.473]  Step 157459  [3.281 sec/step, loss=0.08500, avg_loss=0.08764, mel_loss=0.03666, linear_loss=0.04834]
[2020-05-12 09:09:36.887]  Step 157460  [3.297 sec/step, loss=0.09171, avg_loss=0.08778, mel_loss=0.04009, linear_loss=0.05162]
[2020-05-12 09:09:42.314]  Step 157461  [3.300 sec/step, loss=0.09469, avg_loss=0.08777, mel_loss=0.04246, linear_loss=0.05223]
[2020-05-12 09:09:43.977]  Step 157462  [3.309 sec/step, loss=0.08597, avg_loss=0.08784, mel_loss=0.03730, linear_loss=0.04867]
[2020-05-12 09:09:46.055]  Step 157463  [3.320 sec/step, loss=0.08783, avg_loss=0.08788, mel_loss=0.03822, linear_loss=0.04961]
[2020-05-12 09:09:49.696]  Step 157464  [3.343 sec/step, loss=0.09445, avg_loss=0.08798, mel_loss=0.04221, linear_loss=0.05223]
[2020-05-12 09:09:53.178]  Step 157465  [3.332 sec/step, loss=0.09294, avg_loss=0.08795, mel_loss=0.04149, linear_loss=0.05145]
[2020-05-12 09:09:56.218]  Step 157466  [3.326 sec/step, loss=0.09403, avg_loss=0.08794, mel_loss=0.04125, linear_loss=0.05278]
[2020-05-12 09:09:59.101]  Step 157467  [3.280 sec/step, loss=0.08979, avg_loss=0.08786, mel_loss=0.03967, linear_loss=0.05011]
[2020-05-12 09:10:00.692]  Step 157468  [3.282 sec/step, loss=0.08426, avg_loss=0.08785, mel_loss=0.03658, linear_loss=0.04769]
[2020-05-12 09:10:01.267]  Step 157469  [3.277 sec/step, loss=0.06938, avg_loss=0.08774, mel_loss=0.03056, linear_loss=0.03882]
[2020-05-12 09:10:06.359]  Step 157470  [3.271 sec/step, loss=0.09523, avg_loss=0.08774, mel_loss=0.04283, linear_loss=0.05241]
[2020-05-12 09:10:07.391]  Step 157471  [3.261 sec/step, loss=0.07797, avg_loss=0.08762, mel_loss=0.03342, linear_loss=0.04456]
[2020-05-12 09:10:09.533]  Step 157472  [3.259 sec/step, loss=0.08938, avg_loss=0.08762, mel_loss=0.03902, linear_loss=0.05036]
[2020-05-12 09:10:11.452]  Step 157473  [3.217 sec/step, loss=0.08825, avg_loss=0.08756, mel_loss=0.03837, linear_loss=0.04988]
[2020-05-12 09:10:17.612]  Step 157474  [3.273 sec/step, loss=0.09573, avg_loss=0.08779, mel_loss=0.04346, linear_loss=0.05227]
[2020-05-12 09:10:45.508]  Generated 32 batches of size 32 in 52.325 sec
[2020-05-12 09:10:46.944]  Step 157475  [3.484 sec/step, loss=0.08450, avg_loss=0.08768, mel_loss=0.03629, linear_loss=0.04821]
[2020-05-12 09:10:48.530]  Step 157476  [3.483 sec/step, loss=0.08425, avg_loss=0.08764, mel_loss=0.03633, linear_loss=0.04792]
[2020-05-12 09:10:49.239]  Step 157477  [3.469 sec/step, loss=0.07206, avg_loss=0.08747, mel_loss=0.03096, linear_loss=0.04109]
[2020-05-12 09:10:51.992]  Step 157478  [3.462 sec/step, loss=0.09059, avg_loss=0.08745, mel_loss=0.04012, linear_loss=0.05047]
[2020-05-12 09:10:54.531]  Step 157479  [3.457 sec/step, loss=0.08969, avg_loss=0.08740, mel_loss=0.03909, linear_loss=0.05060]
[2020-05-12 09:10:56.271]  Step 157480  [3.445 sec/step, loss=0.08689, avg_loss=0.08735, mel_loss=0.03753, linear_loss=0.04936]
[2020-05-12 09:11:01.957]  Step 157481  [3.494 sec/step, loss=0.09627, avg_loss=0.08760, mel_loss=0.04366, linear_loss=0.05261]
[2020-05-12 09:11:03.074]  Step 157482  [3.479 sec/step, loss=0.08067, avg_loss=0.08752, mel_loss=0.03462, linear_loss=0.04605]
[2020-05-12 09:11:06.013]  Step 157483  [3.462 sec/step, loss=0.09181, avg_loss=0.08747, mel_loss=0.04045, linear_loss=0.05137]
[2020-05-12 09:11:07.015]  Step 157484  [3.449 sec/step, loss=0.07543, avg_loss=0.08732, mel_loss=0.03202, linear_loss=0.04342]
[2020-05-12 09:11:14.638]  Step 157485  [3.489 sec/step, loss=0.09607, avg_loss=0.08735, mel_loss=0.04377, linear_loss=0.05230]
[2020-05-12 09:11:20.002]  Step 157486  [3.535 sec/step, loss=0.09282, avg_loss=0.08752, mel_loss=0.04133, linear_loss=0.05149]
[2020-05-12 09:11:24.944]  Step 157487  [3.578 sec/step, loss=0.09412, avg_loss=0.08779, mel_loss=0.04169, linear_loss=0.05244]
[2020-05-12 09:11:27.178]  Step 157488  [3.545 sec/step, loss=0.08676, avg_loss=0.08769, mel_loss=0.03764, linear_loss=0.04912]
[2020-05-12 09:11:31.011]  Step 157489  [3.514 sec/step, loss=0.09239, avg_loss=0.08766, mel_loss=0.04088, linear_loss=0.05151]
[2020-05-12 09:11:32.164]  Step 157490  [3.508 sec/step, loss=0.08370, avg_loss=0.08762, mel_loss=0.03583, linear_loss=0.04786]
[2020-05-12 09:11:36.687]  Step 157491  [3.524 sec/step, loss=0.09406, avg_loss=0.08764, mel_loss=0.04207, linear_loss=0.05199]
[2020-05-12 09:11:41.575]  Step 157492  [3.548 sec/step, loss=0.09392, avg_loss=0.08768, mel_loss=0.04208, linear_loss=0.05184]
[2020-05-12 09:11:43.561]  Step 157493  [3.547 sec/step, loss=0.08823, avg_loss=0.08766, mel_loss=0.03847, linear_loss=0.04976]
[2020-05-12 09:11:48.794]  Step 157494  [3.565 sec/step, loss=0.09467, avg_loss=0.08768, mel_loss=0.04257, linear_loss=0.05210]
[2020-05-12 09:11:52.480]  Step 157495  [3.591 sec/step, loss=0.09466, avg_loss=0.08784, mel_loss=0.04213, linear_loss=0.05254]
[2020-05-12 09:11:53.242]  Step 157496  [3.499 sec/step, loss=0.07664, avg_loss=0.08767, mel_loss=0.03247, linear_loss=0.04417]
[2020-05-12 09:11:54.944]  Step 157497  [3.372 sec/step, loss=0.08783, avg_loss=0.08772, mel_loss=0.03810, linear_loss=0.04973]
[2020-05-12 09:12:09.701]  Step 157498  [3.509 sec/step, loss=0.07497, avg_loss=0.08764, mel_loss=0.03527, linear_loss=0.03970]
[2020-05-12 09:12:11.080]  Step 157499  [3.504 sec/step, loss=0.08370, avg_loss=0.08761, mel_loss=0.03576, linear_loss=0.04794]
[2020-05-12 09:12:11.661]  Step 157500  [3.465 sec/step, loss=0.06682, avg_loss=0.08733, mel_loss=0.02887, linear_loss=0.03795]
[2020-05-12 09:12:11.661]  Writing summary at step: 157500
[2020-05-12 09:12:20.837]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157500
[2020-05-12 09:12:22.494]  Saving audio and alignment...
[2020-05-12 09:12:23.689]  Generated 32 batches of size 32 in 28.740 sec
[2020-05-12 09:12:26.349]  Input: 잘 키운 아들을 둔 평화로운 풍경이다~___
[2020-05-12 09:12:32.950]  Step 157501  [3.514 sec/step, loss=0.09437, avg_loss=0.08743, mel_loss=0.04287, linear_loss=0.05151]
[2020-05-12 09:12:37.108]  Step 157502  [3.537 sec/step, loss=0.09528, avg_loss=0.08750, mel_loss=0.04235, linear_loss=0.05293]
[2020-05-12 09:12:38.130]  Step 157503  [3.503 sec/step, loss=0.07895, avg_loss=0.08736, mel_loss=0.03368, linear_loss=0.04528]
[2020-05-12 09:12:40.556]  Step 157504  [3.492 sec/step, loss=0.08981, avg_loss=0.08732, mel_loss=0.03950, linear_loss=0.05031]
[2020-05-12 09:12:42.203]  Step 157505  [3.476 sec/step, loss=0.08561, avg_loss=0.08725, mel_loss=0.03752, linear_loss=0.04809]
[2020-05-12 09:12:44.915]  Step 157506  [3.493 sec/step, loss=0.09116, avg_loss=0.08736, mel_loss=0.03989, linear_loss=0.05126]
[2020-05-12 09:12:48.487]  Step 157507  [3.476 sec/step, loss=0.09173, avg_loss=0.08734, mel_loss=0.04063, linear_loss=0.05110]
[2020-05-12 09:12:50.990]  Step 157508  [3.489 sec/step, loss=0.08837, avg_loss=0.08742, mel_loss=0.03849, linear_loss=0.04988]
[2020-05-12 09:12:53.997]  Step 157509  [3.491 sec/step, loss=0.09293, avg_loss=0.08744, mel_loss=0.04101, linear_loss=0.05193]
[2020-05-12 09:12:55.068]  Step 157510  [3.434 sec/step, loss=0.08003, avg_loss=0.08728, mel_loss=0.03455, linear_loss=0.04548]
[2020-05-12 09:12:59.458]  Step 157511  [3.465 sec/step, loss=0.09311, avg_loss=0.08736, mel_loss=0.04155, linear_loss=0.05156]
[2020-05-12 09:13:00.465]  Step 157512  [3.461 sec/step, loss=0.08090, avg_loss=0.08733, mel_loss=0.03407, linear_loss=0.04683]
[2020-05-12 09:13:08.788]  Step 157513  [3.502 sec/step, loss=0.09390, avg_loss=0.08733, mel_loss=0.04290, linear_loss=0.05100]
[2020-05-12 09:13:12.306]  Step 157514  [3.517 sec/step, loss=0.09429, avg_loss=0.08739, mel_loss=0.04221, linear_loss=0.05208]
[2020-05-12 09:13:13.576]  Step 157515  [3.477 sec/step, loss=0.08326, avg_loss=0.08727, mel_loss=0.03576, linear_loss=0.04750]
[2020-05-12 09:13:15.146]  Step 157516  [3.417 sec/step, loss=0.08636, avg_loss=0.08716, mel_loss=0.03747, linear_loss=0.04888]
[2020-05-12 09:13:16.949]  Step 157517  [3.346 sec/step, loss=0.08915, avg_loss=0.08711, mel_loss=0.03812, linear_loss=0.05102]
[2020-05-12 09:13:22.559]  Step 157518  [3.377 sec/step, loss=0.09470, avg_loss=0.08717, mel_loss=0.04279, linear_loss=0.05191]
[2020-05-12 09:13:27.016]  Step 157519  [3.407 sec/step, loss=0.09745, avg_loss=0.08732, mel_loss=0.04368, linear_loss=0.05377]
[2020-05-12 09:13:33.002]  Step 157520  [3.446 sec/step, loss=0.09590, avg_loss=0.08740, mel_loss=0.04371, linear_loss=0.05219]
[2020-05-12 09:13:34.437]  Step 157521  [3.423 sec/step, loss=0.08226, avg_loss=0.08728, mel_loss=0.03581, linear_loss=0.04645]
[2020-05-12 09:13:35.289]  Step 157522  [3.400 sec/step, loss=0.07437, avg_loss=0.08709, mel_loss=0.03147, linear_loss=0.04290]
[2020-05-12 09:13:38.512]  Step 157523  [3.385 sec/step, loss=0.09511, avg_loss=0.08710, mel_loss=0.04205, linear_loss=0.05307]
[2020-05-12 09:13:39.250]  Step 157524  [3.382 sec/step, loss=0.07268, avg_loss=0.08704, mel_loss=0.03123, linear_loss=0.04146]
[2020-05-12 09:13:44.192]  Step 157525  [3.426 sec/step, loss=0.09497, avg_loss=0.08731, mel_loss=0.04285, linear_loss=0.05212]
[2020-05-12 09:13:45.317]  Step 157526  [3.381 sec/step, loss=0.08176, avg_loss=0.08716, mel_loss=0.03495, linear_loss=0.04681]
[2020-05-12 09:13:46.839]  Step 157527  [3.352 sec/step, loss=0.08741, avg_loss=0.08707, mel_loss=0.03795, linear_loss=0.04946]
[2020-05-12 09:13:49.703]  Step 157528  [3.352 sec/step, loss=0.09123, avg_loss=0.08707, mel_loss=0.04034, linear_loss=0.05089]
[2020-05-12 09:13:57.075]  Step 157529  [3.392 sec/step, loss=0.09832, avg_loss=0.08713, mel_loss=0.04508, linear_loss=0.05323]
[2020-05-12 09:13:57.705]  Generated 32 batches of size 32 in 10.861 sec
[2020-05-12 09:13:59.323]  Step 157530  [3.406 sec/step, loss=0.08897, avg_loss=0.08727, mel_loss=0.03925, linear_loss=0.04972]
[2020-05-12 09:14:01.381]  Step 157531  [3.392 sec/step, loss=0.08714, avg_loss=0.08721, mel_loss=0.03774, linear_loss=0.04940]
[2020-05-12 09:14:02.188]  Step 157532  [3.388 sec/step, loss=0.06843, avg_loss=0.08709, mel_loss=0.02944, linear_loss=0.03899]
[2020-05-12 09:14:05.900]  Step 157533  [3.408 sec/step, loss=0.09502, avg_loss=0.08717, mel_loss=0.04228, linear_loss=0.05274]
[2020-05-12 09:14:07.781]  Step 157534  [3.358 sec/step, loss=0.08986, avg_loss=0.08711, mel_loss=0.03883, linear_loss=0.05104]
[2020-05-12 09:14:09.969]  Step 157535  [3.353 sec/step, loss=0.08988, avg_loss=0.08711, mel_loss=0.03934, linear_loss=0.05054]
[2020-05-12 09:14:22.359]  Step 157536  [3.445 sec/step, loss=0.08509, avg_loss=0.08700, mel_loss=0.03961, linear_loss=0.04548]
[2020-05-12 09:14:23.004]  Step 157537  [3.305 sec/step, loss=0.07320, avg_loss=0.08698, mel_loss=0.03155, linear_loss=0.04165]
[2020-05-12 09:14:26.900]  Step 157538  [3.336 sec/step, loss=0.09480, avg_loss=0.08720, mel_loss=0.04217, linear_loss=0.05263]
[2020-05-12 09:14:30.338]  Step 157539  [3.352 sec/step, loss=0.09391, avg_loss=0.08727, mel_loss=0.04161, linear_loss=0.05231]
[2020-05-12 09:14:31.191]  Step 157540  [3.350 sec/step, loss=0.07808, avg_loss=0.08727, mel_loss=0.03293, linear_loss=0.04515]
[2020-05-12 09:14:32.024]  Step 157541  [3.347 sec/step, loss=0.07527, avg_loss=0.08720, mel_loss=0.03182, linear_loss=0.04345]
[2020-05-12 09:14:37.328]  Step 157542  [3.384 sec/step, loss=0.09430, avg_loss=0.08730, mel_loss=0.04258, linear_loss=0.05172]
[2020-05-12 09:14:46.180]  Step 157543  [3.457 sec/step, loss=0.09667, avg_loss=0.08742, mel_loss=0.04463, linear_loss=0.05204]
[2020-05-12 09:14:48.017]  Step 157544  [3.453 sec/step, loss=0.08688, avg_loss=0.08740, mel_loss=0.03769, linear_loss=0.04920]
[2020-05-12 09:14:50.611]  Step 157545  [3.461 sec/step, loss=0.09043, avg_loss=0.08745, mel_loss=0.03993, linear_loss=0.05050]
[2020-05-12 09:14:52.218]  Step 157546  [3.469 sec/step, loss=0.08856, avg_loss=0.08758, mel_loss=0.03826, linear_loss=0.05029]
[2020-05-12 09:14:56.565]  Step 157547  [3.427 sec/step, loss=0.09402, avg_loss=0.08760, mel_loss=0.04199, linear_loss=0.05203]
[2020-05-12 09:15:02.229]  Step 157548  [3.461 sec/step, loss=0.09682, avg_loss=0.08769, mel_loss=0.04385, linear_loss=0.05297]
[2020-05-12 09:15:04.001]  Step 157549  [3.437 sec/step, loss=0.08599, avg_loss=0.08761, mel_loss=0.03718, linear_loss=0.04881]
[2020-05-12 09:15:06.133]  Step 157550  [3.451 sec/step, loss=0.08881, avg_loss=0.08777, mel_loss=0.03868, linear_loss=0.05013]
[2020-05-12 09:15:06.133]  Writing summary at step: 157550
[2020-05-12 09:15:09.687]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157550
[2020-05-12 09:15:11.332]  Saving audio and alignment...
[2020-05-12 09:15:13.446]  Input: 두 가지가 있는데요~______
[2020-05-12 09:15:14.010]  Step 157551  [3.423 sec/step, loss=0.06746, avg_loss=0.08753, mel_loss=0.02948, linear_loss=0.03799]
[2020-05-12 09:15:17.067]  Step 157552  [3.427 sec/step, loss=0.09352, avg_loss=0.08757, mel_loss=0.04143, linear_loss=0.05209]
[2020-05-12 09:15:19.555]  Step 157553  [3.441 sec/step, loss=0.08968, avg_loss=0.08766, mel_loss=0.03929, linear_loss=0.05040]
[2020-05-12 09:15:21.836]  Step 157554  [3.451 sec/step, loss=0.08759, avg_loss=0.08772, mel_loss=0.03825, linear_loss=0.04934]
[2020-05-12 09:15:22.991]  Step 157555  [3.451 sec/step, loss=0.08042, avg_loss=0.08771, mel_loss=0.03425, linear_loss=0.04617]
[2020-05-12 09:15:24.027]  Step 157556  [3.452 sec/step, loss=0.08017, avg_loss=0.08773, mel_loss=0.03403, linear_loss=0.04614]
[2020-05-12 09:15:25.435]  Step 157557  [3.420 sec/step, loss=0.08280, avg_loss=0.08759, mel_loss=0.03550, linear_loss=0.04731]
[2020-05-12 09:15:27.495]  Step 157558  [3.324 sec/step, loss=0.08733, avg_loss=0.08757, mel_loss=0.03844, linear_loss=0.04889]
[2020-05-12 09:15:28.398]  Generated 32 batches of size 32 in 2.957 sec
[2020-05-12 09:15:42.201]  Step 157559  [3.457 sec/step, loss=0.07538, avg_loss=0.08747, mel_loss=0.03557, linear_loss=0.03981]
[2020-05-12 09:15:49.860]  Step 157560  [3.509 sec/step, loss=0.09660, avg_loss=0.08752, mel_loss=0.04411, linear_loss=0.05249]
[2020-05-12 09:15:51.444]  Step 157561  [3.471 sec/step, loss=0.08766, avg_loss=0.08745, mel_loss=0.03793, linear_loss=0.04973]
[2020-05-12 09:15:54.358]  Step 157562  [3.484 sec/step, loss=0.09212, avg_loss=0.08751, mel_loss=0.04086, linear_loss=0.05126]
[2020-05-12 09:15:58.103]  Step 157563  [3.500 sec/step, loss=0.09292, avg_loss=0.08756, mel_loss=0.04120, linear_loss=0.05172]
[2020-05-12 09:16:02.773]  Step 157564  [3.511 sec/step, loss=0.09464, avg_loss=0.08756, mel_loss=0.04237, linear_loss=0.05227]
[2020-05-12 09:16:04.112]  Step 157565  [3.489 sec/step, loss=0.08278, avg_loss=0.08746, mel_loss=0.03564, linear_loss=0.04714]
[2020-05-12 09:16:10.600]  Step 157566  [3.524 sec/step, loss=0.09545, avg_loss=0.08748, mel_loss=0.04341, linear_loss=0.05204]
[2020-05-12 09:16:13.116]  Step 157567  [3.520 sec/step, loss=0.08799, avg_loss=0.08746, mel_loss=0.03856, linear_loss=0.04943]
[2020-05-12 09:16:15.987]  Step 157568  [3.533 sec/step, loss=0.08935, avg_loss=0.08751, mel_loss=0.03945, linear_loss=0.04990]
[2020-05-12 09:16:30.451]  Step 157569  [3.672 sec/step, loss=0.07616, avg_loss=0.08758, mel_loss=0.03582, linear_loss=0.04034]
[2020-05-12 09:16:35.194]  Step 157570  [3.668 sec/step, loss=0.09423, avg_loss=0.08757, mel_loss=0.04214, linear_loss=0.05208]
[2020-05-12 09:16:44.716]  Step 157571  [3.753 sec/step, loss=0.09707, avg_loss=0.08776, mel_loss=0.04479, linear_loss=0.05228]
[2020-05-12 09:16:46.132]  Step 157572  [3.746 sec/step, loss=0.08187, avg_loss=0.08768, mel_loss=0.03523, linear_loss=0.04664]
[2020-05-12 09:16:47.013]  Step 157573  [3.735 sec/step, loss=0.07334, avg_loss=0.08753, mel_loss=0.03135, linear_loss=0.04199]
[2020-05-12 09:16:51.089]  Step 157574  [3.714 sec/step, loss=0.09424, avg_loss=0.08752, mel_loss=0.04171, linear_loss=0.05253]
[2020-05-12 09:16:51.855]  Step 157575  [3.429 sec/step, loss=0.07173, avg_loss=0.08739, mel_loss=0.03121, linear_loss=0.04052]
[2020-05-12 09:16:58.826]  Step 157576  [3.483 sec/step, loss=0.09792, avg_loss=0.08753, mel_loss=0.04453, linear_loss=0.05338]
[2020-05-12 09:17:01.553]  Step 157577  [3.503 sec/step, loss=0.09345, avg_loss=0.08774, mel_loss=0.04128, linear_loss=0.05217]
[2020-05-12 09:17:03.133]  Step 157578  [3.491 sec/step, loss=0.08638, avg_loss=0.08770, mel_loss=0.03717, linear_loss=0.04921]
[2020-05-12 09:17:06.760]  Step 157579  [3.502 sec/step, loss=0.09439, avg_loss=0.08775, mel_loss=0.04184, linear_loss=0.05255]
[2020-05-12 09:17:08.787]  Step 157580  [3.505 sec/step, loss=0.08843, avg_loss=0.08776, mel_loss=0.03842, linear_loss=0.05000]
[2020-05-12 09:17:11.836]  Step 157581  [3.479 sec/step, loss=0.09228, avg_loss=0.08772, mel_loss=0.04061, linear_loss=0.05168]
[2020-05-12 09:17:13.696]  Step 157582  [3.486 sec/step, loss=0.08759, avg_loss=0.08779, mel_loss=0.03791, linear_loss=0.04968]
[2020-05-12 09:17:18.599]  Step 157583  [3.506 sec/step, loss=0.09339, avg_loss=0.08781, mel_loss=0.04177, linear_loss=0.05163]
[2020-05-12 09:17:19.761]  Step 157584  [3.507 sec/step, loss=0.08051, avg_loss=0.08786, mel_loss=0.03438, linear_loss=0.04614]
[2020-05-12 09:17:25.324]  Step 157585  [3.487 sec/step, loss=0.09450, avg_loss=0.08784, mel_loss=0.04250, linear_loss=0.05200]
[2020-05-12 09:17:26.967]  Step 157586  [3.449 sec/step, loss=0.08624, avg_loss=0.08778, mel_loss=0.03748, linear_loss=0.04876]
[2020-05-12 09:17:34.773]  Step 157587  [3.478 sec/step, loss=0.09736, avg_loss=0.08781, mel_loss=0.04440, linear_loss=0.05295]
[2020-05-12 09:17:38.537]  Step 157588  [3.493 sec/step, loss=0.09494, avg_loss=0.08789, mel_loss=0.04221, linear_loss=0.05273]
[2020-05-12 09:17:40.688]  Step 157589  [3.477 sec/step, loss=0.09048, avg_loss=0.08787, mel_loss=0.03939, linear_loss=0.05109]
[2020-05-12 09:17:42.095]  Step 157590  [3.479 sec/step, loss=0.08183, avg_loss=0.08785, mel_loss=0.03545, linear_loss=0.04638]
[2020-05-12 09:17:45.355]  Step 157591  [3.466 sec/step, loss=0.09525, avg_loss=0.08786, mel_loss=0.04222, linear_loss=0.05303]
[2020-05-12 09:17:46.421]  Step 157592  [3.428 sec/step, loss=0.08272, avg_loss=0.08775, mel_loss=0.03567, linear_loss=0.04705]
[2020-05-12 09:17:49.850]  Step 157593  [3.443 sec/step, loss=0.09337, avg_loss=0.08780, mel_loss=0.04176, linear_loss=0.05161]
[2020-05-12 09:17:50.695]  Step 157594  [3.399 sec/step, loss=0.07119, avg_loss=0.08757, mel_loss=0.03050, linear_loss=0.04069]
[2020-05-12 09:17:52.497]  Step 157595  [3.380 sec/step, loss=0.08595, avg_loss=0.08748, mel_loss=0.03688, linear_loss=0.04907]
[2020-05-12 09:17:54.735]  Step 157596  [3.395 sec/step, loss=0.08940, avg_loss=0.08761, mel_loss=0.03918, linear_loss=0.05022]
[2020-05-12 09:17:55.686]  Step 157597  [3.387 sec/step, loss=0.07916, avg_loss=0.08752, mel_loss=0.03390, linear_loss=0.04526]
[2020-05-12 09:18:01.586]  Step 157598  [3.299 sec/step, loss=0.09571, avg_loss=0.08773, mel_loss=0.04333, linear_loss=0.05238]
[2020-05-12 09:18:26.056]  Generated 32 batches of size 32 in 45.362 sec
[2020-05-12 09:18:32.288]  Step 157599  [3.592 sec/step, loss=0.09652, avg_loss=0.08786, mel_loss=0.04387, linear_loss=0.05265]
[2020-05-12 09:18:39.330]  Step 157600  [3.656 sec/step, loss=0.09768, avg_loss=0.08817, mel_loss=0.04451, linear_loss=0.05317]
[2020-05-12 09:18:39.330]  Writing summary at step: 157600
[2020-05-12 09:18:42.763]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157600
[2020-05-12 09:18:44.381]  Saving audio and alignment...
[2020-05-12 09:18:49.132]  Input: 내가 이 중에서 최고로 말 잘하는 사람이야~___________________
[2020-05-12 09:18:51.158]  Step 157601  [3.611 sec/step, loss=0.08891, avg_loss=0.08811, mel_loss=0.03880, linear_loss=0.05011]
[2020-05-12 09:18:52.473]  Step 157602  [3.582 sec/step, loss=0.08157, avg_loss=0.08797, mel_loss=0.03505, linear_loss=0.04651]
[2020-05-12 09:18:54.168]  Step 157603  [3.589 sec/step, loss=0.08768, avg_loss=0.08806, mel_loss=0.03824, linear_loss=0.04944]
[2020-05-12 09:18:58.516]  Step 157604  [3.608 sec/step, loss=0.09249, avg_loss=0.08809, mel_loss=0.04139, linear_loss=0.05109]
[2020-05-12 09:18:59.307]  Step 157605  [3.600 sec/step, loss=0.07406, avg_loss=0.08797, mel_loss=0.03188, linear_loss=0.04218]
[2020-05-12 09:19:01.740]  Step 157606  [3.597 sec/step, loss=0.09051, avg_loss=0.08797, mel_loss=0.03941, linear_loss=0.05110]
[2020-05-12 09:19:13.748]  Step 157607  [3.681 sec/step, loss=0.08469, avg_loss=0.08790, mel_loss=0.03973, linear_loss=0.04496]
[2020-05-12 09:19:15.959]  Step 157608  [3.678 sec/step, loss=0.09011, avg_loss=0.08791, mel_loss=0.03962, linear_loss=0.05049]
[2020-05-12 09:19:19.699]  Step 157609  [3.686 sec/step, loss=0.09529, avg_loss=0.08794, mel_loss=0.04250, linear_loss=0.05280]
[2020-05-12 09:19:24.621]  Step 157610  [3.724 sec/step, loss=0.09669, avg_loss=0.08810, mel_loss=0.04355, linear_loss=0.05314]
[2020-05-12 09:19:25.764]  Step 157611  [3.692 sec/step, loss=0.08164, avg_loss=0.08799, mel_loss=0.03472, linear_loss=0.04692]
[2020-05-12 09:19:27.121]  Step 157612  [3.695 sec/step, loss=0.08487, avg_loss=0.08803, mel_loss=0.03652, linear_loss=0.04836]
[2020-05-12 09:19:32.671]  Step 157613  [3.667 sec/step, loss=0.09543, avg_loss=0.08804, mel_loss=0.04309, linear_loss=0.05234]
[2020-05-12 09:19:33.512]  Step 157614  [3.641 sec/step, loss=0.07359, avg_loss=0.08784, mel_loss=0.03222, linear_loss=0.04137]
[2020-05-12 09:19:35.132]  Step 157615  [3.644 sec/step, loss=0.08746, avg_loss=0.08788, mel_loss=0.03803, linear_loss=0.04943]
[2020-05-12 09:19:36.603]  Step 157616  [3.643 sec/step, loss=0.08454, avg_loss=0.08786, mel_loss=0.03658, linear_loss=0.04796]
[2020-05-12 09:19:40.228]  Step 157617  [3.661 sec/step, loss=0.09563, avg_loss=0.08793, mel_loss=0.04257, linear_loss=0.05307]
[2020-05-12 09:19:44.869]  Step 157618  [3.652 sec/step, loss=0.09604, avg_loss=0.08794, mel_loss=0.04313, linear_loss=0.05290]
[2020-05-12 09:19:47.770]  Step 157619  [3.636 sec/step, loss=0.09214, avg_loss=0.08789, mel_loss=0.04097, linear_loss=0.05117]
[2020-05-12 09:19:48.758]  Step 157620  [3.586 sec/step, loss=0.07911, avg_loss=0.08772, mel_loss=0.03373, linear_loss=0.04539]
[2020-05-12 09:19:50.685]  Step 157621  [3.591 sec/step, loss=0.08549, avg_loss=0.08775, mel_loss=0.03707, linear_loss=0.04842]
[2020-05-12 09:19:59.104]  Step 157622  [3.667 sec/step, loss=0.09390, avg_loss=0.08795, mel_loss=0.04299, linear_loss=0.05091]
[2020-05-12 09:20:00.085]  Step 157623  [3.644 sec/step, loss=0.07889, avg_loss=0.08778, mel_loss=0.03339, linear_loss=0.04550]
[2020-05-12 09:20:00.617]  Step 157624  [3.642 sec/step, loss=0.07317, avg_loss=0.08779, mel_loss=0.03150, linear_loss=0.04167]
[2020-05-12 09:20:04.166]  Step 157625  [3.628 sec/step, loss=0.09188, avg_loss=0.08776, mel_loss=0.04088, linear_loss=0.05100]
[2020-05-12 09:20:05.228]  Step 157626  [3.628 sec/step, loss=0.08047, avg_loss=0.08774, mel_loss=0.03433, linear_loss=0.04613]
[2020-05-12 09:20:05.919]  Generated 32 batches of size 32 in 18.143 sec
[2020-05-12 09:20:07.408]  Step 157627  [3.634 sec/step, loss=0.08924, avg_loss=0.08776, mel_loss=0.03925, linear_loss=0.04998]
[2020-05-12 09:20:09.959]  Step 157628  [3.631 sec/step, loss=0.08793, avg_loss=0.08773, mel_loss=0.03839, linear_loss=0.04954]
[2020-05-12 09:20:10.493]  Step 157629  [3.563 sec/step, loss=0.06826, avg_loss=0.08743, mel_loss=0.03009, linear_loss=0.03818]
[2020-05-12 09:20:23.537]  Step 157630  [3.671 sec/step, loss=0.07869, avg_loss=0.08733, mel_loss=0.03672, linear_loss=0.04197]
[2020-05-12 09:20:30.168]  Step 157631  [3.716 sec/step, loss=0.09548, avg_loss=0.08741, mel_loss=0.04331, linear_loss=0.05217]
[2020-05-12 09:20:31.959]  Step 157632  [3.726 sec/step, loss=0.08762, avg_loss=0.08760, mel_loss=0.03798, linear_loss=0.04964]
[2020-05-12 09:20:39.418]  Step 157633  [3.764 sec/step, loss=0.09648, avg_loss=0.08762, mel_loss=0.04400, linear_loss=0.05247]
[2020-05-12 09:20:40.572]  Step 157634  [3.757 sec/step, loss=0.08274, avg_loss=0.08755, mel_loss=0.03538, linear_loss=0.04736]
[2020-05-12 09:20:42.577]  Step 157635  [3.755 sec/step, loss=0.08949, avg_loss=0.08754, mel_loss=0.03906, linear_loss=0.05043]
[2020-05-12 09:20:43.384]  Step 157636  [3.639 sec/step, loss=0.07561, avg_loss=0.08745, mel_loss=0.03213, linear_loss=0.04348]
[2020-05-12 09:20:48.862]  Step 157637  [3.687 sec/step, loss=0.09757, avg_loss=0.08769, mel_loss=0.04424, linear_loss=0.05333]
[2020-05-12 09:20:53.413]  Step 157638  [3.694 sec/step, loss=0.09498, avg_loss=0.08769, mel_loss=0.04239, linear_loss=0.05259]
[2020-05-12 09:20:55.565]  Step 157639  [3.681 sec/step, loss=0.08881, avg_loss=0.08764, mel_loss=0.03861, linear_loss=0.05019]
[2020-05-12 09:21:03.924]  Step 157640  [3.756 sec/step, loss=0.09446, avg_loss=0.08780, mel_loss=0.04336, linear_loss=0.05110]
[2020-05-12 09:21:04.722]  Step 157641  [3.756 sec/step, loss=0.07381, avg_loss=0.08779, mel_loss=0.03151, linear_loss=0.04231]
[2020-05-12 09:21:08.733]  Step 157642  [3.743 sec/step, loss=0.09572, avg_loss=0.08780, mel_loss=0.04279, linear_loss=0.05293]
[2020-05-12 09:21:09.803]  Step 157643  [3.665 sec/step, loss=0.08169, avg_loss=0.08765, mel_loss=0.03489, linear_loss=0.04680]
[2020-05-12 09:21:11.302]  Step 157644  [3.661 sec/step, loss=0.08360, avg_loss=0.08762, mel_loss=0.03599, linear_loss=0.04760]
[2020-05-12 09:21:14.109]  Step 157645  [3.664 sec/step, loss=0.09002, avg_loss=0.08762, mel_loss=0.03959, linear_loss=0.05043]
[2020-05-12 09:21:17.098]  Step 157646  [3.677 sec/step, loss=0.09310, avg_loss=0.08766, mel_loss=0.04094, linear_loss=0.05216]
[2020-05-12 09:21:20.630]  Step 157647  [3.669 sec/step, loss=0.09313, avg_loss=0.08765, mel_loss=0.04131, linear_loss=0.05182]
[2020-05-12 09:21:25.030]  Step 157648  [3.657 sec/step, loss=0.09498, avg_loss=0.08764, mel_loss=0.04255, linear_loss=0.05243]
[2020-05-12 09:21:27.045]  Step 157649  [3.659 sec/step, loss=0.08462, avg_loss=0.08762, mel_loss=0.03658, linear_loss=0.04803]
[2020-05-12 09:21:28.638]  Step 157650  [3.654 sec/step, loss=0.07814, avg_loss=0.08752, mel_loss=0.03316, linear_loss=0.04498]
[2020-05-12 09:21:28.639]  Writing summary at step: 157650
[2020-05-12 09:21:31.775]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157650
[2020-05-12 09:21:34.243]  Saving audio and alignment...
[2020-05-12 09:21:36.483]  Input: 조금 더 어둡게~___________
[2020-05-12 09:21:40.952]  Step 157651  [3.693 sec/step, loss=0.09422, avg_loss=0.08778, mel_loss=0.04186, linear_loss=0.05236]
[2020-05-12 09:21:42.745]  Step 157652  [3.680 sec/step, loss=0.08874, avg_loss=0.08774, mel_loss=0.03837, linear_loss=0.05037]
[2020-05-12 09:21:46.188]  Generated 32 batches of size 32 in 11.295 sec
[2020-05-12 09:21:46.652]  Step 157653  [3.694 sec/step, loss=0.09296, avg_loss=0.08777, mel_loss=0.04113, linear_loss=0.05183]
[2020-05-12 09:21:53.374]  Step 157654  [3.739 sec/step, loss=0.09561, avg_loss=0.08785, mel_loss=0.04313, linear_loss=0.05248]
[2020-05-12 09:21:55.859]  Step 157655  [3.752 sec/step, loss=0.08946, avg_loss=0.08794, mel_loss=0.03935, linear_loss=0.05010]
[2020-05-12 09:21:58.569]  Step 157656  [3.769 sec/step, loss=0.08993, avg_loss=0.08804, mel_loss=0.03928, linear_loss=0.05065]
[2020-05-12 09:22:01.648]  Step 157657  [3.785 sec/step, loss=0.09445, avg_loss=0.08815, mel_loss=0.04178, linear_loss=0.05267]
[2020-05-12 09:22:03.231]  Step 157658  [3.781 sec/step, loss=0.08630, avg_loss=0.08814, mel_loss=0.03752, linear_loss=0.04879]
[2020-05-12 09:22:05.313]  Step 157659  [3.654 sec/step, loss=0.08784, avg_loss=0.08827, mel_loss=0.03819, linear_loss=0.04965]
[2020-05-12 09:22:09.101]  Step 157660  [3.616 sec/step, loss=0.09370, avg_loss=0.08824, mel_loss=0.04156, linear_loss=0.05214]
[2020-05-12 09:22:10.433]  Step 157661  [3.613 sec/step, loss=0.08341, avg_loss=0.08820, mel_loss=0.03575, linear_loss=0.04767]
[2020-05-12 09:22:12.184]  Step 157662  [3.602 sec/step, loss=0.08632, avg_loss=0.08814, mel_loss=0.03745, linear_loss=0.04887]
[2020-05-12 09:22:15.059]  Step 157663  [3.593 sec/step, loss=0.09385, avg_loss=0.08815, mel_loss=0.04167, linear_loss=0.05218]
[2020-05-12 09:22:18.548]  Step 157664  [3.581 sec/step, loss=0.09120, avg_loss=0.08811, mel_loss=0.04061, linear_loss=0.05059]
[2020-05-12 09:22:19.103]  Step 157665  [3.573 sec/step, loss=0.06957, avg_loss=0.08798, mel_loss=0.02999, linear_loss=0.03958]
[2020-05-12 09:22:23.325]  Step 157666  [3.551 sec/step, loss=0.09217, avg_loss=0.08795, mel_loss=0.04104, linear_loss=0.05113]
[2020-05-12 09:22:24.486]  Step 157667  [3.537 sec/step, loss=0.08082, avg_loss=0.08788, mel_loss=0.03449, linear_loss=0.04634]
[2020-05-12 09:22:25.365]  Step 157668  [3.517 sec/step, loss=0.07569, avg_loss=0.08774, mel_loss=0.03219, linear_loss=0.04350]
[2020-05-12 09:22:27.509]  Step 157669  [3.394 sec/step, loss=0.08996, avg_loss=0.08788, mel_loss=0.03931, linear_loss=0.05065]
[2020-05-12 09:22:28.621]  Step 157670  [3.358 sec/step, loss=0.07940, avg_loss=0.08773, mel_loss=0.03399, linear_loss=0.04541]
[2020-05-12 09:22:42.933]  Step 157671  [3.405 sec/step, loss=0.07705, avg_loss=0.08753, mel_loss=0.03647, linear_loss=0.04059]
[2020-05-12 09:22:51.916]  Step 157672  [3.481 sec/step, loss=0.09636, avg_loss=0.08767, mel_loss=0.04463, linear_loss=0.05173]
[2020-05-12 09:22:54.332]  Step 157673  [3.496 sec/step, loss=0.08976, avg_loss=0.08784, mel_loss=0.03928, linear_loss=0.05048]
[2020-05-12 09:22:55.678]  Step 157674  [3.469 sec/step, loss=0.08475, avg_loss=0.08774, mel_loss=0.03665, linear_loss=0.04809]
[2020-05-12 09:22:56.486]  Step 157675  [3.470 sec/step, loss=0.07554, avg_loss=0.08778, mel_loss=0.03206, linear_loss=0.04348]
[2020-05-12 09:23:00.780]  Step 157676  [3.443 sec/step, loss=0.09625, avg_loss=0.08776, mel_loss=0.04325, linear_loss=0.05300]
[2020-05-12 09:23:04.054]  Step 157677  [3.448 sec/step, loss=0.09282, avg_loss=0.08776, mel_loss=0.04111, linear_loss=0.05172]
[2020-05-12 09:23:05.018]  Step 157678  [3.442 sec/step, loss=0.08080, avg_loss=0.08770, mel_loss=0.03432, linear_loss=0.04648]
[2020-05-12 09:23:08.162]  Step 157679  [3.437 sec/step, loss=0.09375, avg_loss=0.08770, mel_loss=0.04197, linear_loss=0.05178]
[2020-05-12 09:23:09.947]  Step 157680  [3.435 sec/step, loss=0.08640, avg_loss=0.08768, mel_loss=0.03707, linear_loss=0.04933]
[2020-05-12 09:23:12.184]  Step 157681  [3.427 sec/step, loss=0.09070, avg_loss=0.08766, mel_loss=0.03957, linear_loss=0.05113]
[2020-05-12 09:23:13.650]  Step 157682  [3.423 sec/step, loss=0.08420, avg_loss=0.08763, mel_loss=0.03630, linear_loss=0.04790]
[2020-05-12 09:23:19.000]  Step 157683  [3.427 sec/step, loss=0.09249, avg_loss=0.08762, mel_loss=0.04170, linear_loss=0.05080]
[2020-05-12 09:23:19.683]  Step 157684  [3.422 sec/step, loss=0.07245, avg_loss=0.08754, mel_loss=0.03111, linear_loss=0.04134]
[2020-05-12 09:23:21.645]  Step 157685  [3.386 sec/step, loss=0.08677, avg_loss=0.08746, mel_loss=0.03769, linear_loss=0.04908]
[2020-05-12 09:23:27.352]  Step 157686  [3.427 sec/step, loss=0.09444, avg_loss=0.08754, mel_loss=0.04265, linear_loss=0.05179]
[2020-05-12 09:23:28.977]  Step 157687  [3.365 sec/step, loss=0.08718, avg_loss=0.08744, mel_loss=0.03785, linear_loss=0.04933]
[2020-05-12 09:23:31.743]  Generated 32 batches of size 32 in 19.555 sec
[2020-05-12 09:23:36.380]  Step 157688  [3.402 sec/step, loss=0.09540, avg_loss=0.08744, mel_loss=0.04359, linear_loss=0.05182]
[2020-05-12 09:23:42.737]  Step 157689  [3.444 sec/step, loss=0.09528, avg_loss=0.08749, mel_loss=0.04324, linear_loss=0.05204]
[2020-05-12 09:23:45.332]  Step 157690  [3.456 sec/step, loss=0.09021, avg_loss=0.08758, mel_loss=0.03961, linear_loss=0.05060]
[2020-05-12 09:23:48.760]  Step 157691  [3.457 sec/step, loss=0.09194, avg_loss=0.08754, mel_loss=0.04081, linear_loss=0.05113]
[2020-05-12 09:23:54.473]  Step 157692  [3.504 sec/step, loss=0.09549, avg_loss=0.08767, mel_loss=0.04327, linear_loss=0.05222]
[2020-05-12 09:24:03.192]  Step 157693  [3.557 sec/step, loss=0.09487, avg_loss=0.08769, mel_loss=0.04339, linear_loss=0.05148]
[2020-05-12 09:24:06.899]  Step 157694  [3.585 sec/step, loss=0.09279, avg_loss=0.08790, mel_loss=0.04124, linear_loss=0.05155]
[2020-05-12 09:24:07.895]  Step 157695  [3.577 sec/step, loss=0.07658, avg_loss=0.08781, mel_loss=0.03247, linear_loss=0.04411]
[2020-05-12 09:24:10.040]  Step 157696  [3.576 sec/step, loss=0.09061, avg_loss=0.08782, mel_loss=0.03969, linear_loss=0.05092]
[2020-05-12 09:24:17.563]  Step 157697  [3.642 sec/step, loss=0.09746, avg_loss=0.08800, mel_loss=0.04452, linear_loss=0.05294]
[2020-05-12 09:24:18.118]  Step 157698  [3.589 sec/step, loss=0.07043, avg_loss=0.08775, mel_loss=0.03102, linear_loss=0.03940]
[2020-05-12 09:24:19.222]  Step 157699  [3.293 sec/step, loss=0.08130, avg_loss=0.08760, mel_loss=0.03460, linear_loss=0.04670]
[2020-05-12 09:24:21.003]  Step 157700  [3.240 sec/step, loss=0.08649, avg_loss=0.08749, mel_loss=0.03738, linear_loss=0.04910]
[2020-05-12 09:24:21.003]  Writing summary at step: 157700
[2020-05-12 09:24:27.403]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157700
[2020-05-12 09:24:29.002]  Saving audio and alignment...
[2020-05-12 09:24:32.537]  Input: 일단 이 책과 인간의 내용은요~___________
[2020-05-12 09:24:37.785]  Step 157701  [3.272 sec/step, loss=0.09426, avg_loss=0.08754, mel_loss=0.04221, linear_loss=0.05205]
[2020-05-12 09:24:40.536]  Step 157702  [3.287 sec/step, loss=0.09193, avg_loss=0.08764, mel_loss=0.04072, linear_loss=0.05121]
[2020-05-12 09:24:43.023]  Step 157703  [3.295 sec/step, loss=0.08944, avg_loss=0.08766, mel_loss=0.03908, linear_loss=0.05036]
[2020-05-12 09:24:44.033]  Step 157704  [3.261 sec/step, loss=0.08030, avg_loss=0.08754, mel_loss=0.03417, linear_loss=0.04613]
[2020-05-12 09:24:48.010]  Step 157705  [3.293 sec/step, loss=0.09313, avg_loss=0.08773, mel_loss=0.04128, linear_loss=0.05185]
[2020-05-12 09:24:49.663]  Step 157706  [3.285 sec/step, loss=0.08610, avg_loss=0.08769, mel_loss=0.03732, linear_loss=0.04877]
[2020-05-12 09:24:54.521]  Step 157707  [3.214 sec/step, loss=0.09480, avg_loss=0.08779, mel_loss=0.04238, linear_loss=0.05242]
[2020-05-12 09:24:56.108]  Step 157708  [3.207 sec/step, loss=0.08570, avg_loss=0.08774, mel_loss=0.03700, linear_loss=0.04870]
[2020-05-12 09:25:10.690]  Step 157709  [3.316 sec/step, loss=0.07460, avg_loss=0.08754, mel_loss=0.03498, linear_loss=0.03963]
[2020-05-12 09:25:12.049]  Step 157710  [3.280 sec/step, loss=0.08117, avg_loss=0.08738, mel_loss=0.03491, linear_loss=0.04626]
[2020-05-12 09:25:12.861]  Step 157711  [3.277 sec/step, loss=0.07302, avg_loss=0.08729, mel_loss=0.03093, linear_loss=0.04209]
[2020-05-12 09:25:15.908]  Step 157712  [3.294 sec/step, loss=0.09529, avg_loss=0.08740, mel_loss=0.04210, linear_loss=0.05319]
[2020-05-12 09:25:19.459]  Step 157713  [3.274 sec/step, loss=0.09196, avg_loss=0.08736, mel_loss=0.04067, linear_loss=0.05128]
[2020-05-12 09:25:23.974]  Step 157714  [3.311 sec/step, loss=0.09310, avg_loss=0.08756, mel_loss=0.04178, linear_loss=0.05132]
[2020-05-12 09:25:26.398]  Step 157715  [3.319 sec/step, loss=0.09011, avg_loss=0.08759, mel_loss=0.03942, linear_loss=0.05070]
[2020-05-12 09:25:28.361]  Step 157716  [3.324 sec/step, loss=0.08840, avg_loss=0.08762, mel_loss=0.03827, linear_loss=0.05013]
[2020-05-12 09:25:29.560]  Step 157717  [3.299 sec/step, loss=0.08254, avg_loss=0.08749, mel_loss=0.03523, linear_loss=0.04731]
[2020-05-12 09:25:32.535]  Step 157718  [3.283 sec/step, loss=0.09302, avg_loss=0.08746, mel_loss=0.04100, linear_loss=0.05202]
[2020-05-12 09:25:34.002]  Step 157719  [3.268 sec/step, loss=0.08294, avg_loss=0.08737, mel_loss=0.03599, linear_loss=0.04695]
[2020-05-12 09:25:34.871]  Step 157720  [3.267 sec/step, loss=0.07435, avg_loss=0.08732, mel_loss=0.03167, linear_loss=0.04268]
[2020-05-12 09:25:35.395]  Generated 32 batches of size 32 in 22.528 sec
[2020-05-12 09:25:37.228]  Step 157721  [3.271 sec/step, loss=0.08733, avg_loss=0.08734, mel_loss=0.03789, linear_loss=0.04944]
[2020-05-12 09:25:44.505]  Step 157722  [3.260 sec/step, loss=0.09402, avg_loss=0.08734, mel_loss=0.04265, linear_loss=0.05137]
[2020-05-12 09:25:48.157]  Step 157723  [3.287 sec/step, loss=0.09580, avg_loss=0.08751, mel_loss=0.04260, linear_loss=0.05320]
[2020-05-12 09:25:50.374]  Step 157724  [3.304 sec/step, loss=0.08913, avg_loss=0.08767, mel_loss=0.03875, linear_loss=0.05038]
[2020-05-12 09:25:52.434]  Step 157725  [3.289 sec/step, loss=0.09052, avg_loss=0.08766, mel_loss=0.03958, linear_loss=0.05094]
[2020-05-12 09:25:54.723]  Step 157726  [3.301 sec/step, loss=0.08806, avg_loss=0.08773, mel_loss=0.03901, linear_loss=0.04906]
[2020-05-12 09:25:59.697]  Step 157727  [3.329 sec/step, loss=0.09496, avg_loss=0.08779, mel_loss=0.04273, linear_loss=0.05223]
[2020-05-12 09:26:01.039]  Step 157728  [3.317 sec/step, loss=0.08536, avg_loss=0.08776, mel_loss=0.03658, linear_loss=0.04878]
[2020-05-12 09:26:07.103]  Step 157729  [3.372 sec/step, loss=0.09484, avg_loss=0.08803, mel_loss=0.04323, linear_loss=0.05161]
[2020-05-12 09:26:10.034]  Step 157730  [3.271 sec/step, loss=0.09159, avg_loss=0.08816, mel_loss=0.04041, linear_loss=0.05118]
[2020-05-12 09:26:11.143]  Step 157731  [3.216 sec/step, loss=0.08231, avg_loss=0.08803, mel_loss=0.03529, linear_loss=0.04702]
[2020-05-12 09:26:14.318]  Step 157732  [3.230 sec/step, loss=0.09264, avg_loss=0.08808, mel_loss=0.04105, linear_loss=0.05158]
[2020-05-12 09:26:18.506]  Step 157733  [3.197 sec/step, loss=0.09508, avg_loss=0.08806, mel_loss=0.04240, linear_loss=0.05268]
[2020-05-12 09:26:22.583]  Step 157734  [3.226 sec/step, loss=0.09460, avg_loss=0.08818, mel_loss=0.04218, linear_loss=0.05242]
[2020-05-12 09:26:23.111]  Step 157735  [3.211 sec/step, loss=0.06959, avg_loss=0.08798, mel_loss=0.02957, linear_loss=0.04002]
[2020-05-12 09:26:24.028]  Step 157736  [3.212 sec/step, loss=0.07823, avg_loss=0.08801, mel_loss=0.03311, linear_loss=0.04513]
[2020-05-12 09:26:37.340]  Step 157737  [3.291 sec/step, loss=0.08135, avg_loss=0.08785, mel_loss=0.03824, linear_loss=0.04310]
[2020-05-12 09:26:42.948]  Step 157738  [3.301 sec/step, loss=0.09745, avg_loss=0.08787, mel_loss=0.04422, linear_loss=0.05323]
[2020-05-12 09:26:51.461]  Step 157739  [3.365 sec/step, loss=0.09182, avg_loss=0.08790, mel_loss=0.04187, linear_loss=0.04995]
[2020-05-12 09:26:53.350]  Step 157740  [3.300 sec/step, loss=0.08791, avg_loss=0.08784, mel_loss=0.03836, linear_loss=0.04955]
[2020-05-12 09:26:56.399]  Step 157741  [3.323 sec/step, loss=0.08974, avg_loss=0.08800, mel_loss=0.03956, linear_loss=0.05018]
[2020-05-12 09:26:58.046]  Step 157742  [3.299 sec/step, loss=0.08442, avg_loss=0.08788, mel_loss=0.03641, linear_loss=0.04802]
[2020-05-12 09:27:02.961]  Step 157743  [3.338 sec/step, loss=0.09720, avg_loss=0.08804, mel_loss=0.04342, linear_loss=0.05378]
[2020-05-12 09:27:06.705]  Step 157744  [3.360 sec/step, loss=0.09165, avg_loss=0.08812, mel_loss=0.04071, linear_loss=0.05094]
[2020-05-12 09:27:08.044]  Generated 32 batches of size 32 in 5.077 sec
[2020-05-12 09:27:09.301]  Step 157745  [3.358 sec/step, loss=0.08827, avg_loss=0.08810, mel_loss=0.03853, linear_loss=0.04974]
[2020-05-12 09:27:10.911]  Step 157746  [3.344 sec/step, loss=0.08571, avg_loss=0.08803, mel_loss=0.03691, linear_loss=0.04880]
[2020-05-12 09:27:12.168]  Step 157747  [3.321 sec/step, loss=0.08205, avg_loss=0.08792, mel_loss=0.03540, linear_loss=0.04665]
[2020-05-12 09:27:13.199]  Step 157748  [3.288 sec/step, loss=0.07968, avg_loss=0.08776, mel_loss=0.03413, linear_loss=0.04555]
[2020-05-12 09:27:14.855]  Step 157749  [3.284 sec/step, loss=0.08853, avg_loss=0.08780, mel_loss=0.03827, linear_loss=0.05026]
[2020-05-12 09:27:15.695]  Step 157750  [3.277 sec/step, loss=0.07140, avg_loss=0.08774, mel_loss=0.03025, linear_loss=0.04116]
[2020-05-12 09:27:15.695]  Writing summary at step: 157750
[2020-05-12 09:27:16.552]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157750
[2020-05-12 09:27:18.130]  Saving audio and alignment...
[2020-05-12 09:27:23.503]  Input: 퀴즈 프로그램에서 정말로 중요한 정답을 발표할 때 어떻게 하나요~
[2020-05-12 09:27:26.079]  Step 157751  [3.258 sec/step, loss=0.08868, avg_loss=0.08768, mel_loss=0.03852, linear_loss=0.05016]
[2020-05-12 09:27:33.813]  Step 157752  [3.317 sec/step, loss=0.09679, avg_loss=0.08776, mel_loss=0.04419, linear_loss=0.05260]
[2020-05-12 09:27:35.245]  Step 157753  [3.292 sec/step, loss=0.08525, avg_loss=0.08768, mel_loss=0.03678, linear_loss=0.04847]
[2020-05-12 09:27:38.330]  Step 157754  [3.256 sec/step, loss=0.09422, avg_loss=0.08767, mel_loss=0.04162, linear_loss=0.05260]
[2020-05-12 09:27:43.039]  Step 157755  [3.278 sec/step, loss=0.09460, avg_loss=0.08772, mel_loss=0.04223, linear_loss=0.05238]
[2020-05-12 09:27:47.445]  Step 157756  [3.295 sec/step, loss=0.09528, avg_loss=0.08777, mel_loss=0.04291, linear_loss=0.05237]
[2020-05-12 09:27:51.685]  Step 157757  [3.307 sec/step, loss=0.09236, avg_loss=0.08775, mel_loss=0.04088, linear_loss=0.05148]
[2020-05-12 09:27:53.273]  Step 157758  [3.307 sec/step, loss=0.08350, avg_loss=0.08773, mel_loss=0.03614, linear_loss=0.04736]
[2020-05-12 09:27:55.254]  Step 157759  [3.306 sec/step, loss=0.08533, avg_loss=0.08770, mel_loss=0.03696, linear_loss=0.04836]
[2020-05-12 09:27:58.748]  Step 157760  [3.303 sec/step, loss=0.09313, avg_loss=0.08770, mel_loss=0.04138, linear_loss=0.05175]
[2020-05-12 09:27:59.571]  Step 157761  [3.298 sec/step, loss=0.07709, avg_loss=0.08763, mel_loss=0.03282, linear_loss=0.04427]
[2020-05-12 09:28:13.933]  Step 157762  [3.424 sec/step, loss=0.07453, avg_loss=0.08751, mel_loss=0.03488, linear_loss=0.03965]
[2020-05-12 09:28:15.760]  Step 157763  [3.413 sec/step, loss=0.08512, avg_loss=0.08743, mel_loss=0.03630, linear_loss=0.04882]
[2020-05-12 09:28:17.826]  Step 157764  [3.399 sec/step, loss=0.08826, avg_loss=0.08740, mel_loss=0.03839, linear_loss=0.04987]
[2020-05-12 09:28:18.991]  Step 157765  [3.405 sec/step, loss=0.08327, avg_loss=0.08753, mel_loss=0.03576, linear_loss=0.04751]
[2020-05-12 09:28:22.768]  Step 157766  [3.401 sec/step, loss=0.09358, avg_loss=0.08755, mel_loss=0.04152, linear_loss=0.05207]
[2020-05-12 09:28:24.133]  Step 157767  [3.403 sec/step, loss=0.08233, avg_loss=0.08756, mel_loss=0.03557, linear_loss=0.04676]
[2020-05-12 09:28:27.100]  Step 157768  [3.424 sec/step, loss=0.09244, avg_loss=0.08773, mel_loss=0.04065, linear_loss=0.05179]
[2020-05-12 09:28:29.536]  Step 157769  [3.427 sec/step, loss=0.08991, avg_loss=0.08773, mel_loss=0.03940, linear_loss=0.05051]
[2020-05-12 09:28:30.658]  Step 157770  [3.427 sec/step, loss=0.08161, avg_loss=0.08775, mel_loss=0.03482, linear_loss=0.04679]
[2020-05-12 09:28:32.362]  Step 157771  [3.301 sec/step, loss=0.08786, avg_loss=0.08786, mel_loss=0.03786, linear_loss=0.05001]
[2020-05-12 09:28:33.374]  Step 157772  [3.221 sec/step, loss=0.07837, avg_loss=0.08768, mel_loss=0.03312, linear_loss=0.04525]
[2020-05-12 09:28:42.433]  Step 157773  [3.287 sec/step, loss=0.09588, avg_loss=0.08774, mel_loss=0.04421, linear_loss=0.05167]
[2020-05-12 09:28:44.685]  Step 157774  [3.296 sec/step, loss=0.08833, avg_loss=0.08778, mel_loss=0.03875, linear_loss=0.04958]
[2020-05-12 09:28:45.422]  Generated 32 batches of size 32 in 2.983 sec
[2020-05-12 09:28:45.530]  Step 157775  [3.297 sec/step, loss=0.07444, avg_loss=0.08777, mel_loss=0.03174, linear_loss=0.04270]
[2020-05-12 09:28:46.109]  Step 157776  [3.260 sec/step, loss=0.06998, avg_loss=0.08750, mel_loss=0.03078, linear_loss=0.03920]
[2020-05-12 09:28:47.149]  Step 157777  [3.237 sec/step, loss=0.07787, avg_loss=0.08735, mel_loss=0.03336, linear_loss=0.04451]
[2020-05-12 09:28:49.927]  Step 157778  [3.255 sec/step, loss=0.09063, avg_loss=0.08745, mel_loss=0.04006, linear_loss=0.05056]
[2020-05-12 09:28:53.418]  Step 157779  [3.259 sec/step, loss=0.09213, avg_loss=0.08744, mel_loss=0.04086, linear_loss=0.05127]
[2020-05-12 09:28:59.861]  Step 157780  [3.305 sec/step, loss=0.09541, avg_loss=0.08753, mel_loss=0.04325, linear_loss=0.05216]
[2020-05-12 09:29:05.670]  Step 157781  [3.341 sec/step, loss=0.09736, avg_loss=0.08759, mel_loss=0.04400, linear_loss=0.05336]
[2020-05-12 09:29:11.098]  Step 157782  [3.381 sec/step, loss=0.09323, avg_loss=0.08768, mel_loss=0.04184, linear_loss=0.05139]
[2020-05-12 09:29:18.108]  Step 157783  [3.397 sec/step, loss=0.09686, avg_loss=0.08773, mel_loss=0.04439, linear_loss=0.05247]
[2020-05-12 09:29:26.958]  Step 157784  [3.479 sec/step, loss=0.09233, avg_loss=0.08793, mel_loss=0.04236, linear_loss=0.04997]
[2020-05-12 09:29:29.632]  Step 157785  [3.486 sec/step, loss=0.09075, avg_loss=0.08797, mel_loss=0.04014, linear_loss=0.05061]
[2020-05-12 09:29:41.549]  Step 157786  [3.548 sec/step, loss=0.08741, avg_loss=0.08790, mel_loss=0.04098, linear_loss=0.04643]
[2020-05-12 09:29:43.239]  Step 157787  [3.549 sec/step, loss=0.08735, avg_loss=0.08790, mel_loss=0.03809, linear_loss=0.04927]
[2020-05-12 09:29:45.017]  Step 157788  [3.493 sec/step, loss=0.08569, avg_loss=0.08780, mel_loss=0.03716, linear_loss=0.04853]
[2020-05-12 09:29:47.491]  Step 157789  [3.454 sec/step, loss=0.09194, avg_loss=0.08777, mel_loss=0.04023, linear_loss=0.05171]
[2020-05-12 09:29:51.692]  Step 157790  [3.470 sec/step, loss=0.09316, avg_loss=0.08780, mel_loss=0.04134, linear_loss=0.05183]
[2020-05-12 09:29:57.392]  Step 157791  [3.493 sec/step, loss=0.09489, avg_loss=0.08783, mel_loss=0.04284, linear_loss=0.05205]
[2020-05-12 09:30:00.960]  Step 157792  [3.471 sec/step, loss=0.09148, avg_loss=0.08779, mel_loss=0.04041, linear_loss=0.05107]
[2020-05-12 09:30:05.805]  Step 157793  [3.432 sec/step, loss=0.09518, avg_loss=0.08779, mel_loss=0.04263, linear_loss=0.05255]
[2020-05-12 09:30:07.206]  Step 157794  [3.409 sec/step, loss=0.08305, avg_loss=0.08769, mel_loss=0.03567, linear_loss=0.04738]
[2020-05-12 09:30:10.162]  Step 157795  [3.429 sec/step, loss=0.09180, avg_loss=0.08784, mel_loss=0.04050, linear_loss=0.05129]
[2020-05-12 09:30:12.353]  Step 157796  [3.429 sec/step, loss=0.08856, avg_loss=0.08782, mel_loss=0.03860, linear_loss=0.04996]
[2020-05-12 09:30:13.640]  Step 157797  [3.367 sec/step, loss=0.08082, avg_loss=0.08766, mel_loss=0.03478, linear_loss=0.04604]
[2020-05-12 09:30:17.865]  Step 157798  [3.404 sec/step, loss=0.09307, avg_loss=0.08788, mel_loss=0.04165, linear_loss=0.05142]
[2020-05-12 09:30:19.342]  Step 157799  [3.408 sec/step, loss=0.08542, avg_loss=0.08792, mel_loss=0.03679, linear_loss=0.04863]
[2020-05-12 09:30:21.378]  Step 157800  [3.410 sec/step, loss=0.08831, avg_loss=0.08794, mel_loss=0.03830, linear_loss=0.05000]
[2020-05-12 09:30:21.378]  Writing summary at step: 157800
[2020-05-12 09:30:24.543]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157800
[2020-05-12 09:30:26.146]  Saving audio and alignment...
[2020-05-12 09:30:28.310]  Input: 다음것도 보시면요~____________
[2020-05-12 09:30:30.242]  Step 157801  [3.377 sec/step, loss=0.08455, avg_loss=0.08785, mel_loss=0.03693, linear_loss=0.04762]
[2020-05-12 09:30:31.007]  Step 157802  [3.357 sec/step, loss=0.07187, avg_loss=0.08765, mel_loss=0.03060, linear_loss=0.04127]
[2020-05-12 09:30:34.770]  Step 157803  [3.370 sec/step, loss=0.09572, avg_loss=0.08771, mel_loss=0.04262, linear_loss=0.05310]
[2020-05-12 09:30:35.675]  Step 157804  [3.369 sec/step, loss=0.07236, avg_loss=0.08763, mel_loss=0.03075, linear_loss=0.04161]
[2020-05-12 09:30:36.544]  Generated 32 batches of size 32 in 1.768 sec
[2020-05-12 09:30:36.875]  Step 157805  [3.341 sec/step, loss=0.08009, avg_loss=0.08750, mel_loss=0.03416, linear_loss=0.04593]
[2020-05-12 09:30:38.961]  Step 157806  [3.345 sec/step, loss=0.09031, avg_loss=0.08754, mel_loss=0.03936, linear_loss=0.05096]
[2020-05-12 09:30:45.258]  Step 157807  [3.360 sec/step, loss=0.09504, avg_loss=0.08754, mel_loss=0.04303, linear_loss=0.05201]
[2020-05-12 09:30:45.795]  Step 157808  [3.349 sec/step, loss=0.06884, avg_loss=0.08737, mel_loss=0.03019, linear_loss=0.03865]
[2020-05-12 09:30:49.298]  Step 157809  [3.238 sec/step, loss=0.09231, avg_loss=0.08755, mel_loss=0.04092, linear_loss=0.05140]
[2020-05-12 09:30:54.601]  Step 157810  [3.278 sec/step, loss=0.09570, avg_loss=0.08770, mel_loss=0.04324, linear_loss=0.05245]
[2020-05-12 09:30:55.673]  Step 157811  [3.280 sec/step, loss=0.07945, avg_loss=0.08776, mel_loss=0.03401, linear_loss=0.04544]
[2020-05-12 09:30:58.001]  Step 157812  [3.273 sec/step, loss=0.09105, avg_loss=0.08772, mel_loss=0.03988, linear_loss=0.05117]
[2020-05-12 09:30:58.845]  Step 157813  [3.246 sec/step, loss=0.07322, avg_loss=0.08753, mel_loss=0.03153, linear_loss=0.04169]
[2020-05-12 09:31:01.006]  Step 157814  [3.223 sec/step, loss=0.08780, avg_loss=0.08748, mel_loss=0.03826, linear_loss=0.04954]
[2020-05-12 09:31:02.381]  Step 157815  [3.212 sec/step, loss=0.08489, avg_loss=0.08743, mel_loss=0.03665, linear_loss=0.04824]
[2020-05-12 09:31:04.157]  Step 157816  [3.210 sec/step, loss=0.08582, avg_loss=0.08740, mel_loss=0.03694, linear_loss=0.04888]
[2020-05-12 09:31:07.790]  Step 157817  [3.235 sec/step, loss=0.09440, avg_loss=0.08752, mel_loss=0.04192, linear_loss=0.05248]
[2020-05-12 09:31:09.300]  Step 157818  [3.220 sec/step, loss=0.08476, avg_loss=0.08744, mel_loss=0.03673, linear_loss=0.04802]
[2020-05-12 09:31:11.582]  Step 157819  [3.228 sec/step, loss=0.08783, avg_loss=0.08748, mel_loss=0.03856, linear_loss=0.04927]
[2020-05-12 09:31:20.029]  Step 157820  [3.304 sec/step, loss=0.09491, avg_loss=0.08769, mel_loss=0.04356, linear_loss=0.05135]
[2020-05-12 09:31:22.782]  Step 157821  [3.308 sec/step, loss=0.09055, avg_loss=0.08772, mel_loss=0.03983, linear_loss=0.05073]
[2020-05-12 09:31:24.409]  Step 157822  [3.251 sec/step, loss=0.08543, avg_loss=0.08764, mel_loss=0.03705, linear_loss=0.04838]
[2020-05-12 09:31:25.395]  Step 157823  [3.225 sec/step, loss=0.08113, avg_loss=0.08749, mel_loss=0.03469, linear_loss=0.04644]
[2020-05-12 09:31:28.575]  Step 157824  [3.234 sec/step, loss=0.09329, avg_loss=0.08753, mel_loss=0.04127, linear_loss=0.05201]
[2020-05-12 09:31:35.309]  Step 157825  [3.281 sec/step, loss=0.09445, avg_loss=0.08757, mel_loss=0.04290, linear_loss=0.05155]
[2020-05-12 09:31:39.234]  Step 157826  [3.297 sec/step, loss=0.09047, avg_loss=0.08759, mel_loss=0.03941, linear_loss=0.05106]
[2020-05-12 09:31:44.103]  Step 157827  [3.296 sec/step, loss=0.09403, avg_loss=0.08759, mel_loss=0.04170, linear_loss=0.05233]
[2020-05-12 09:31:46.263]  Step 157828  [3.305 sec/step, loss=0.08824, avg_loss=0.08761, mel_loss=0.03858, linear_loss=0.04967]
[2020-05-12 09:31:48.104]  Step 157829  [3.262 sec/step, loss=0.08638, avg_loss=0.08753, mel_loss=0.03731, linear_loss=0.04907]
[2020-05-12 09:31:53.950]  Step 157830  [3.291 sec/step, loss=0.09527, avg_loss=0.08757, mel_loss=0.04299, linear_loss=0.05228]
[2020-05-12 09:31:58.861]  Step 157831  [3.330 sec/step, loss=0.09372, avg_loss=0.08768, mel_loss=0.04198, linear_loss=0.05174]
[2020-05-12 09:32:03.107]  Step 157832  [3.340 sec/step, loss=0.09462, avg_loss=0.08770, mel_loss=0.04211, linear_loss=0.05251]
[2020-05-12 09:32:07.871]  Step 157833  [3.346 sec/step, loss=0.09598, avg_loss=0.08771, mel_loss=0.04293, linear_loss=0.05305]
[2020-05-12 09:32:11.926]  Step 157834  [3.346 sec/step, loss=0.09441, avg_loss=0.08771, mel_loss=0.04218, linear_loss=0.05223]
[2020-05-12 09:32:12.885]  Step 157835  [3.350 sec/step, loss=0.08033, avg_loss=0.08782, mel_loss=0.03411, linear_loss=0.04622]
[2020-05-12 09:32:14.205]  Step 157836  [3.354 sec/step, loss=0.08164, avg_loss=0.08785, mel_loss=0.03471, linear_loss=0.04693]
[2020-05-12 09:32:14.659]  Generated 32 batches of size 32 in 1.768 sec
[2020-05-12 09:32:29.158]  Step 157837  [3.371 sec/step, loss=0.07562, avg_loss=0.08779, mel_loss=0.03543, linear_loss=0.04019]
[2020-05-12 09:32:29.729]  Step 157838  [3.320 sec/step, loss=0.06867, avg_loss=0.08750, mel_loss=0.02962, linear_loss=0.03906]
[2020-05-12 09:32:33.302]  Step 157839  [3.271 sec/step, loss=0.09241, avg_loss=0.08751, mel_loss=0.04120, linear_loss=0.05121]
[2020-05-12 09:32:36.227]  Step 157840  [3.281 sec/step, loss=0.09246, avg_loss=0.08756, mel_loss=0.04064, linear_loss=0.05183]
[2020-05-12 09:32:37.584]  Step 157841  [3.264 sec/step, loss=0.08252, avg_loss=0.08748, mel_loss=0.03542, linear_loss=0.04709]
[2020-05-12 09:32:38.664]  Step 157842  [3.259 sec/step, loss=0.08182, avg_loss=0.08746, mel_loss=0.03484, linear_loss=0.04697]
[2020-05-12 09:32:46.320]  Step 157843  [3.286 sec/step, loss=0.09614, avg_loss=0.08745, mel_loss=0.04396, linear_loss=0.05218]
[2020-05-12 09:32:47.097]  Step 157844  [3.256 sec/step, loss=0.07777, avg_loss=0.08731, mel_loss=0.03264, linear_loss=0.04513]
[2020-05-12 09:32:49.779]  Step 157845  [3.257 sec/step, loss=0.08892, avg_loss=0.08731, mel_loss=0.03883, linear_loss=0.05008]
[2020-05-12 09:32:51.574]  Step 157846  [3.259 sec/step, loss=0.08668, avg_loss=0.08732, mel_loss=0.03759, linear_loss=0.04909]
[2020-05-12 09:32:53.076]  Step 157847  [3.261 sec/step, loss=0.08386, avg_loss=0.08734, mel_loss=0.03619, linear_loss=0.04768]
[2020-05-12 09:32:54.010]  Step 157848  [3.260 sec/step, loss=0.07723, avg_loss=0.08732, mel_loss=0.03266, linear_loss=0.04457]
[2020-05-12 09:32:58.659]  Step 157849  [3.290 sec/step, loss=0.09455, avg_loss=0.08738, mel_loss=0.04232, linear_loss=0.05223]
[2020-05-12 09:33:06.415]  Step 157850  [3.360 sec/step, loss=0.09479, avg_loss=0.08761, mel_loss=0.04319, linear_loss=0.05160]
[2020-05-12 09:33:06.415]  Writing summary at step: 157850
[2020-05-12 09:33:09.501]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157850
[2020-05-12 09:33:11.110]  Saving audio and alignment...
[2020-05-12 09:33:15.054]  Input: 매력을 갖추게 될 거란 사실만큼은 제가~_
[2020-05-12 09:33:20.457]  Step 157851  [3.388 sec/step, loss=0.09447, avg_loss=0.08767, mel_loss=0.04226, linear_loss=0.05221]
[2020-05-12 09:33:29.351]  Step 157852  [3.399 sec/step, loss=0.09397, avg_loss=0.08764, mel_loss=0.04297, linear_loss=0.05100]
[2020-05-12 09:33:35.047]  Step 157853  [3.442 sec/step, loss=0.09416, avg_loss=0.08773, mel_loss=0.04227, linear_loss=0.05189]
[2020-05-12 09:33:37.462]  Step 157854  [3.435 sec/step, loss=0.09080, avg_loss=0.08770, mel_loss=0.03979, linear_loss=0.05101]
[2020-05-12 09:33:51.800]  Step 157855  [3.532 sec/step, loss=0.07463, avg_loss=0.08750, mel_loss=0.03525, linear_loss=0.03938]
[2020-05-12 09:33:53.453]  Step 157856  [3.504 sec/step, loss=0.08755, avg_loss=0.08742, mel_loss=0.03785, linear_loss=0.04970]
[2020-05-12 09:33:55.558]  Step 157857  [3.483 sec/step, loss=0.08951, avg_loss=0.08739, mel_loss=0.03923, linear_loss=0.05028]
[2020-05-12 09:33:58.492]  Step 157858  [3.496 sec/step, loss=0.09215, avg_loss=0.08748, mel_loss=0.04071, linear_loss=0.05143]
[2020-05-12 09:33:59.692]  Step 157859  [3.488 sec/step, loss=0.07912, avg_loss=0.08742, mel_loss=0.03372, linear_loss=0.04540]
[2020-05-12 09:34:03.139]  Step 157860  [3.488 sec/step, loss=0.09410, avg_loss=0.08743, mel_loss=0.04171, linear_loss=0.05239]
[2020-05-12 09:34:03.970]  Step 157861  [3.488 sec/step, loss=0.07266, avg_loss=0.08738, mel_loss=0.03081, linear_loss=0.04184]
[2020-05-12 09:34:10.356]  Step 157862  [3.408 sec/step, loss=0.09511, avg_loss=0.08759, mel_loss=0.04329, linear_loss=0.05181]
[2020-05-12 09:34:12.292]  Step 157863  [3.409 sec/step, loss=0.08575, avg_loss=0.08759, mel_loss=0.03712, linear_loss=0.04863]
[2020-05-12 09:34:13.620]  Step 157864  [3.402 sec/step, loss=0.08327, avg_loss=0.08754, mel_loss=0.03579, linear_loss=0.04748]
[2020-05-12 09:34:17.098]  Step 157865  [3.425 sec/step, loss=0.09106, avg_loss=0.08762, mel_loss=0.04048, linear_loss=0.05057]
[2020-05-12 09:34:18.189]  Step 157866  [3.398 sec/step, loss=0.08324, avg_loss=0.08752, mel_loss=0.03512, linear_loss=0.04812]
[2020-05-12 09:34:21.979]  Step 157867  [3.422 sec/step, loss=0.09343, avg_loss=0.08763, mel_loss=0.04148, linear_loss=0.05195]
[2020-05-12 09:34:24.048]  Step 157868  [3.414 sec/step, loss=0.08857, avg_loss=0.08759, mel_loss=0.03870, linear_loss=0.04987]
[2020-05-12 09:34:25.069]  Step 157869  [3.399 sec/step, loss=0.08132, avg_loss=0.08750, mel_loss=0.03475, linear_loss=0.04657]
[2020-05-12 09:34:25.965]  Generated 32 batches of size 32 in 8.861 sec
[2020-05-12 09:34:29.248]  Step 157870  [3.430 sec/step, loss=0.09438, avg_loss=0.08763, mel_loss=0.04186, linear_loss=0.05252]
[2020-05-12 09:34:33.639]  Step 157871  [3.457 sec/step, loss=0.09507, avg_loss=0.08770, mel_loss=0.04246, linear_loss=0.05261]
[2020-05-12 09:34:34.206]  Step 157872  [3.452 sec/step, loss=0.06957, avg_loss=0.08762, mel_loss=0.03011, linear_loss=0.03945]
[2020-05-12 09:34:35.060]  Step 157873  [3.370 sec/step, loss=0.07363, avg_loss=0.08739, mel_loss=0.03155, linear_loss=0.04208]
[2020-05-12 09:34:36.477]  Step 157874  [3.362 sec/step, loss=0.08268, avg_loss=0.08734, mel_loss=0.03571, linear_loss=0.04697]
[2020-05-12 09:34:37.489]  Step 157875  [3.364 sec/step, loss=0.07846, avg_loss=0.08738, mel_loss=0.03319, linear_loss=0.04527]
[2020-05-12 09:34:38.063]  Step 157876  [3.364 sec/step, loss=0.06688, avg_loss=0.08735, mel_loss=0.02878, linear_loss=0.03810]
[2020-05-12 09:34:39.432]  Step 157877  [3.367 sec/step, loss=0.08650, avg_loss=0.08743, mel_loss=0.03699, linear_loss=0.04951]
[2020-05-12 09:34:42.961]  Step 157878  [3.374 sec/step, loss=0.09182, avg_loss=0.08744, mel_loss=0.04067, linear_loss=0.05116]
[2020-05-12 09:34:44.897]  Step 157879  [3.359 sec/step, loss=0.08686, avg_loss=0.08739, mel_loss=0.03768, linear_loss=0.04917]
[2020-05-12 09:34:46.183]  Step 157880  [3.307 sec/step, loss=0.08350, avg_loss=0.08727, mel_loss=0.03588, linear_loss=0.04762]
[2020-05-12 09:34:50.413]  Step 157881  [3.291 sec/step, loss=0.09335, avg_loss=0.08723, mel_loss=0.04182, linear_loss=0.05154]
[2020-05-12 09:34:52.621]  Step 157882  [3.259 sec/step, loss=0.09170, avg_loss=0.08722, mel_loss=0.04000, linear_loss=0.05170]
[2020-05-12 09:34:55.985]  Step 157883  [3.223 sec/step, loss=0.09399, avg_loss=0.08719, mel_loss=0.04172, linear_loss=0.05227]
[2020-05-12 09:34:57.478]  Step 157884  [3.149 sec/step, loss=0.08351, avg_loss=0.08710, mel_loss=0.03616, linear_loss=0.04735]
[2020-05-12 09:34:59.935]  Step 157885  [3.147 sec/step, loss=0.09138, avg_loss=0.08711, mel_loss=0.03960, linear_loss=0.05177]
[2020-05-12 09:35:02.691]  Step 157886  [3.055 sec/step, loss=0.09104, avg_loss=0.08714, mel_loss=0.04018, linear_loss=0.05086]
[2020-05-12 09:35:06.560]  Step 157887  [3.077 sec/step, loss=0.09404, avg_loss=0.08721, mel_loss=0.04179, linear_loss=0.05225]
[2020-05-12 09:35:09.730]  Step 157888  [3.091 sec/step, loss=0.09428, avg_loss=0.08730, mel_loss=0.04182, linear_loss=0.05246]
[2020-05-12 09:35:17.118]  Step 157889  [3.140 sec/step, loss=0.09772, avg_loss=0.08735, mel_loss=0.04452, linear_loss=0.05320]
[2020-05-12 09:35:19.233]  Step 157890  [3.119 sec/step, loss=0.08800, avg_loss=0.08730, mel_loss=0.03826, linear_loss=0.04974]
[2020-05-12 09:35:20.052]  Step 157891  [3.071 sec/step, loss=0.07503, avg_loss=0.08710, mel_loss=0.03154, linear_loss=0.04349]
[2020-05-12 09:35:22.987]  Step 157892  [3.064 sec/step, loss=0.09048, avg_loss=0.08709, mel_loss=0.03997, linear_loss=0.05052]
[2020-05-12 09:35:24.046]  Step 157893  [3.026 sec/step, loss=0.07738, avg_loss=0.08691, mel_loss=0.03319, linear_loss=0.04420]
[2020-05-12 09:35:32.608]  Step 157894  [3.098 sec/step, loss=0.09253, avg_loss=0.08701, mel_loss=0.04246, linear_loss=0.05007]
[2020-05-12 09:35:35.027]  Step 157895  [3.093 sec/step, loss=0.08896, avg_loss=0.08698, mel_loss=0.03905, linear_loss=0.04992]
[2020-05-12 09:35:36.693]  Step 157896  [3.087 sec/step, loss=0.08684, avg_loss=0.08696, mel_loss=0.03777, linear_loss=0.04907]
[2020-05-12 09:35:37.815]  Step 157897  [3.086 sec/step, loss=0.08000, avg_loss=0.08696, mel_loss=0.03401, linear_loss=0.04600]
[2020-05-12 09:35:38.590]  Step 157898  [3.051 sec/step, loss=0.07101, avg_loss=0.08674, mel_loss=0.03028, linear_loss=0.04074]
[2020-05-12 09:35:43.325]  Step 157899  [3.084 sec/step, loss=0.09498, avg_loss=0.08683, mel_loss=0.04266, linear_loss=0.05232]
[2020-05-12 09:35:44.610]  Generated 32 batches of size 32 in 6.790 sec
[2020-05-12 09:35:50.164]  Step 157900  [3.132 sec/step, loss=0.09625, avg_loss=0.08691, mel_loss=0.04364, linear_loss=0.05261]
[2020-05-12 09:35:50.164]  Writing summary at step: 157900
[2020-05-12 09:35:55.915]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157900
[2020-05-12 09:35:57.517]  Saving audio and alignment...
[2020-05-12 09:36:07.200]  Input: 행사 참석자들에게 보이는 나의 첫 인상만큼이나 중요한 것이 또 없겠죠~___________________
[2020-05-12 09:36:10.888]  Step 157901  [3.149 sec/step, loss=0.09525, avg_loss=0.08702, mel_loss=0.04239, linear_loss=0.05286]
[2020-05-12 09:36:12.668]  Step 157902  [3.160 sec/step, loss=0.08842, avg_loss=0.08718, mel_loss=0.03793, linear_loss=0.05049]
[2020-05-12 09:36:25.894]  Step 157903  [3.254 sec/step, loss=0.08217, avg_loss=0.08705, mel_loss=0.03845, linear_loss=0.04372]
[2020-05-12 09:36:27.632]  Step 157904  [3.263 sec/step, loss=0.08713, avg_loss=0.08720, mel_loss=0.03747, linear_loss=0.04966]
[2020-05-12 09:36:29.861]  Step 157905  [3.273 sec/step, loss=0.08843, avg_loss=0.08728, mel_loss=0.03873, linear_loss=0.04971]
[2020-05-12 09:36:31.227]  Step 157906  [3.266 sec/step, loss=0.08444, avg_loss=0.08722, mel_loss=0.03635, linear_loss=0.04809]
[2020-05-12 09:36:34.674]  Step 157907  [3.237 sec/step, loss=0.09210, avg_loss=0.08719, mel_loss=0.04062, linear_loss=0.05147]
[2020-05-12 09:36:35.691]  Step 157908  [3.242 sec/step, loss=0.08001, avg_loss=0.08730, mel_loss=0.03405, linear_loss=0.04596]
[2020-05-12 09:36:48.828]  Step 157909  [3.338 sec/step, loss=0.08062, avg_loss=0.08718, mel_loss=0.03767, linear_loss=0.04295]
[2020-05-12 09:36:54.449]  Step 157910  [3.341 sec/step, loss=0.09430, avg_loss=0.08717, mel_loss=0.04224, linear_loss=0.05206]
[2020-05-12 09:36:59.689]  Step 157911  [3.383 sec/step, loss=0.09619, avg_loss=0.08734, mel_loss=0.04339, linear_loss=0.05280]
[2020-05-12 09:37:02.113]  Step 157912  [3.384 sec/step, loss=0.09055, avg_loss=0.08733, mel_loss=0.03957, linear_loss=0.05098]
[2020-05-12 09:37:09.460]  Step 157913  [3.449 sec/step, loss=0.09509, avg_loss=0.08755, mel_loss=0.04332, linear_loss=0.05178]
[2020-05-12 09:37:12.237]  Step 157914  [3.455 sec/step, loss=0.09173, avg_loss=0.08759, mel_loss=0.04040, linear_loss=0.05132]
[2020-05-12 09:37:14.210]  Step 157915  [3.461 sec/step, loss=0.08580, avg_loss=0.08760, mel_loss=0.03728, linear_loss=0.04852]
[2020-05-12 09:37:16.924]  Step 157916  [3.471 sec/step, loss=0.08718, avg_loss=0.08761, mel_loss=0.03802, linear_loss=0.04917]
[2020-05-12 09:37:18.114]  Step 157917  [3.446 sec/step, loss=0.08164, avg_loss=0.08749, mel_loss=0.03458, linear_loss=0.04706]
[2020-05-12 09:37:18.976]  Step 157918  [3.440 sec/step, loss=0.07499, avg_loss=0.08739, mel_loss=0.03214, linear_loss=0.04285]
[2020-05-12 09:37:22.612]  Step 157919  [3.453 sec/step, loss=0.09416, avg_loss=0.08745, mel_loss=0.04186, linear_loss=0.05229]
[2020-05-12 09:37:23.585]  Step 157920  [3.379 sec/step, loss=0.07756, avg_loss=0.08728, mel_loss=0.03289, linear_loss=0.04467]
[2020-05-12 09:37:24.186]  Step 157921  [3.357 sec/step, loss=0.06905, avg_loss=0.08706, mel_loss=0.03043, linear_loss=0.03862]
[2020-05-12 09:37:26.083]  Step 157922  [3.360 sec/step, loss=0.08534, avg_loss=0.08706, mel_loss=0.03655, linear_loss=0.04879]
[2020-05-12 09:37:27.269]  Step 157923  [3.362 sec/step, loss=0.08256, avg_loss=0.08708, mel_loss=0.03546, linear_loss=0.04710]
[2020-05-12 09:37:31.932]  Step 157924  [3.377 sec/step, loss=0.09515, avg_loss=0.08710, mel_loss=0.04233, linear_loss=0.05281]
[2020-05-12 09:37:36.034]  Step 157925  [3.350 sec/step, loss=0.09380, avg_loss=0.08709, mel_loss=0.04175, linear_loss=0.05205]
[2020-05-12 09:37:38.909]  Step 157926  [3.340 sec/step, loss=0.09325, avg_loss=0.08712, mel_loss=0.04119, linear_loss=0.05206]
[2020-05-12 09:37:39.734]  Step 157927  [3.299 sec/step, loss=0.07315, avg_loss=0.08691, mel_loss=0.03119, linear_loss=0.04195]
[2020-05-12 09:37:41.337]  Step 157928  [3.294 sec/step, loss=0.08556, avg_loss=0.08688, mel_loss=0.03699, linear_loss=0.04858]
[2020-05-12 09:37:45.183]  Generated 32 batches of size 32 in 5.443 sec
[2020-05-12 09:37:50.156]  Step 157929  [3.364 sec/step, loss=0.09544, avg_loss=0.08697, mel_loss=0.04374, linear_loss=0.05170]
[2020-05-12 09:37:53.288]  Step 157930  [3.336 sec/step, loss=0.09319, avg_loss=0.08695, mel_loss=0.04110, linear_loss=0.05210]
[2020-05-12 09:37:54.909]  Step 157931  [3.303 sec/step, loss=0.08526, avg_loss=0.08687, mel_loss=0.03722, linear_loss=0.04803]
[2020-05-12 09:37:56.296]  Step 157932  [3.275 sec/step, loss=0.08540, avg_loss=0.08677, mel_loss=0.03683, linear_loss=0.04856]
[2020-05-12 09:38:02.465]  Step 157933  [3.289 sec/step, loss=0.09529, avg_loss=0.08677, mel_loss=0.04329, linear_loss=0.05200]
[2020-05-12 09:38:04.461]  Step 157934  [3.268 sec/step, loss=0.08826, avg_loss=0.08671, mel_loss=0.03841, linear_loss=0.04985]
[2020-05-12 09:38:08.114]  Step 157935  [3.295 sec/step, loss=0.09387, avg_loss=0.08684, mel_loss=0.04173, linear_loss=0.05214]
[2020-05-12 09:38:12.434]  Step 157936  [3.325 sec/step, loss=0.09432, avg_loss=0.08697, mel_loss=0.04197, linear_loss=0.05235]
[2020-05-12 09:38:18.109]  Step 157937  [3.233 sec/step, loss=0.09527, avg_loss=0.08716, mel_loss=0.04347, linear_loss=0.05180]
[2020-05-12 09:38:22.735]  Step 157938  [3.273 sec/step, loss=0.09512, avg_loss=0.08743, mel_loss=0.04274, linear_loss=0.05239]
[2020-05-12 09:38:29.103]  Step 157939  [3.301 sec/step, loss=0.09648, avg_loss=0.08747, mel_loss=0.04388, linear_loss=0.05260]
[2020-05-12 09:38:31.323]  Step 157940  [3.294 sec/step, loss=0.08710, avg_loss=0.08742, mel_loss=0.03823, linear_loss=0.04887]
[2020-05-12 09:38:36.269]  Step 157941  [3.330 sec/step, loss=0.09442, avg_loss=0.08754, mel_loss=0.04238, linear_loss=0.05204]
[2020-05-12 09:38:37.731]  Step 157942  [3.334 sec/step, loss=0.08367, avg_loss=0.08755, mel_loss=0.03601, linear_loss=0.04766]
[2020-05-12 09:38:39.682]  Step 157943  [3.277 sec/step, loss=0.08819, avg_loss=0.08747, mel_loss=0.03833, linear_loss=0.04986]
[2020-05-12 09:38:41.383]  Step 157944  [3.286 sec/step, loss=0.08770, avg_loss=0.08757, mel_loss=0.03778, linear_loss=0.04992]
[2020-05-12 09:38:43.848]  Step 157945  [3.284 sec/step, loss=0.08957, avg_loss=0.08758, mel_loss=0.03900, linear_loss=0.05057]
[2020-05-12 09:38:44.814]  Step 157946  [3.275 sec/step, loss=0.08127, avg_loss=0.08753, mel_loss=0.03461, linear_loss=0.04666]
[2020-05-12 09:38:45.687]  Step 157947  [3.269 sec/step, loss=0.07045, avg_loss=0.08739, mel_loss=0.02994, linear_loss=0.04051]
[2020-05-12 09:38:48.264]  Step 157948  [3.286 sec/step, loss=0.09021, avg_loss=0.08752, mel_loss=0.03950, linear_loss=0.05071]
[2020-05-12 09:38:48.811]  Step 157949  [3.245 sec/step, loss=0.07178, avg_loss=0.08729, mel_loss=0.03076, linear_loss=0.04101]
[2020-05-12 09:38:51.946]  Step 157950  [3.198 sec/step, loss=0.09405, avg_loss=0.08729, mel_loss=0.04183, linear_loss=0.05222]
[2020-05-12 09:38:51.946]  Writing summary at step: 157950
[2020-05-12 09:38:55.347]  Saving checkpoint to: ./logs-tacotron/model.ckpt-157950
[2020-05-12 09:38:56.957]  Saving audio and alignment...
[2020-05-12 09:38:59.124]  Input: 자 여기서 중요한 거~_______
[2020-05-12 09:39:00.430]  Step 157951  [3.157 sec/step, loss=0.08081, avg_loss=0.08715, mel_loss=0.03484, linear_loss=0.04598]
[2020-05-12 09:39:02.464]  Step 157952  [3.089 sec/step, loss=0.08839, avg_loss=0.08709, mel_loss=0.03851, linear_loss=0.04989]
[2020-05-12 09:39:03.632]  Step 157953  [3.043 sec/step, loss=0.07893, avg_loss=0.08694, mel_loss=0.03366, linear_loss=0.04526]
[2020-05-12 09:39:04.957]  Step 157954  [3.033 sec/step, loss=0.08419, avg_loss=0.08688, mel_loss=0.03629, linear_loss=0.04790]
[2020-05-12 09:39:12.559]  Step 157955  [2.965 sec/step, loss=0.09743, avg_loss=0.08710, mel_loss=0.04458, linear_loss=0.05284]
[2020-05-12 09:39:26.556]  Step 157956  [3.089 sec/step, loss=0.07855, avg_loss=0.08701, mel_loss=0.03707, linear_loss=0.04148]
[2020-05-12 09:39:28.463]  Step 157957  [3.087 sec/step, loss=0.08697, avg_loss=0.08699, mel_loss=0.03752, linear_loss=0.04945]
[2020-05-12 09:39:30.070]  Step 157958  [3.073 sec/step, loss=0.08671, avg_loss=0.08693, mel_loss=0.03734, linear_loss=0.04936]
[2020-05-12 09:39:33.536]  Step 157959  [3.096 sec/step, loss=0.09176, avg_loss=0.08706, mel_loss=0.04068, linear_loss=0.05108]
[2020-05-12 09:39:37.864]  Step 157960  [3.105 sec/step, loss=0.09571, avg_loss=0.08708, mel_loss=0.04287, linear_loss=0.05284]
[2020-05-12 09:39:38.682]  Step 157961  [3.105 sec/step, loss=0.07343, avg_loss=0.08708, mel_loss=0.03082, linear_loss=0.04261]
[2020-05-12 09:39:39.696]  Step 157962  [3.051 sec/step, loss=0.07698, avg_loss=0.08690, mel_loss=0.03275, linear_loss=0.04423]
[2020-05-12 09:39:43.392]  Step 157963  [3.069 sec/step, loss=0.09512, avg_loss=0.08700, mel_loss=0.04241, linear_loss=0.05271]
[2020-05-12 09:39:45.629]  Generated 32 batches of size 32 in 17.160 sec
[2020-05-12 09:39:47.263]  Step 157964  [3.094 sec/step, loss=0.09312, avg_loss=0.08709, mel_loss=0.04114, linear_loss=0.05199]
[2020-05-12 09:39:50.145]  Step 157965  [3.088 sec/step, loss=0.09108, avg_loss=0.08710, mel_loss=0.04011, linear_loss=0.05097]
[2020-05-12 09:39:59.085]  Step 157966  [3.167 sec/step, loss=0.09504, avg_loss=0.08721, mel_loss=0.04379, linear_loss=0.05125]
[2020-05-12 09:40:01.115]  Step 157967  [3.149 sec/step, loss=0.08947, avg_loss=0.08717, mel_loss=0.03901, linear_loss=0.05046]
[2020-05-12 09:40:02.836]  Step 157968  [3.145 sec/step, loss=0.08624, avg_loss=0.08715, mel_loss=0.03742, linear_loss=0.04882]
[2020-05-12 09:40:04.598]  Step 157969  [3.153 sec/step, loss=0.08710, avg_loss=0.08721, mel_loss=0.03763, linear_loss=0.04947]
[2020-05-12 09:40:07.466]  Step 157970  [3.140 sec/step, loss=0.09067, avg_loss=0.08717, mel_loss=0.04010, linear_loss=0.05057]
[2020-05-12 09:40:09.050]  Step 157971  [3.112 sec/step, loss=0.08580, avg_loss=0.08708, mel_loss=0.03692, linear_loss=0.04888]
[2020-05-12 09:40:10.398]  Step 157972  [3.120 sec/step, loss=0.08388, avg_loss=0.08722, mel_loss=0.03598, linear_loss=0.04791]
[2020-05-12 09:40:21.626]  Step 157973  [3.223 sec/step, loss=0.08843, avg_loss=0.08737, mel_loss=0.04132, linear_loss=0.04711]
[2020-05-12 09:40:25.901]  Step 157974  [3.252 sec/step, loss=0.09285, avg_loss=0.08747, mel_loss=0.04152, linear_loss=0.05133]
[2020-05-12 09:40:33.954]  Step 157975  [3.322 sec/step, loss=0.09608, avg_loss=0.08765, mel_loss=0.04392, linear_loss=0.05216]
[2020-05-12 09:40:36.166]  Step 157976  [3.339 sec/step, loss=0.08966, avg_loss=0.08788, mel_loss=0.03921, linear_loss=0.05045]
[2020-05-12 09:40:36.980]  Step 157977  [3.333 sec/step, loss=0.07473, avg_loss=0.08776, mel_loss=0.03161, linear_loss=0.04312]
[2020-05-12 09:40:39.416]  Step 157978  [3.322 sec/step, loss=0.09057, avg_loss=0.08775, mel_loss=0.03960, linear_loss=0.05098]
[2020-05-12 09:40:42.864]  Step 157979  [3.337 sec/step, loss=0.09211, avg_loss=0.08780, mel_loss=0.04101, linear_loss=0.05109]
[2020-05-12 09:40:48.025]  Step 157980  [3.376 sec/step, loss=0.09436, avg_loss=0.08791, mel_loss=0.04263, linear_loss=0.05173]
[2020-05-12 09:40:48.789]  Step 157981  [3.341 sec/step, loss=0.07034, avg_loss=0.08768, mel_loss=0.02993, linear_loss=0.04041]
[2020-05-12 09:40:49.807]  Step 157982  [3.329 sec/step, loss=0.07986, avg_loss=0.08756, mel_loss=0.03406, linear_loss=0.04580]
[2020-05-12 09:40:50.721]  Step 157983  [3.305 sec/step, loss=0.07744, avg_loss=0.08739, mel_loss=0.03253, linear_loss=0.04491]
[2020-05-12 09:40:52.109]  Step 157984  [3.304 sec/step, loss=0.08591, avg_loss=0.08742, mel_loss=0.03702, linear_loss=0.04889]
[2020-05-12 09:40:55.072]  Step 157985  [3.309 sec/step, loss=0.09241, avg_loss=0.08743, mel_loss=0.04078, linear_loss=0.05163]
[2020-05-12 09:40:56.997]  Step 157986  [3.301 sec/step, loss=0.08658, avg_loss=0.08738, mel_loss=0.03720, linear_loss=0.04938]
[2020-05-12 09:41:01.551]  Step 157987  [3.308 sec/step, loss=0.09398, avg_loss=0.08738, mel_loss=0.04193, linear_loss=0.05205]
[2020-05-12 09:41:08.117]  Step 157988  [3.341 sec/step, loss=0.09484, avg_loss=0.08739, mel_loss=0.04312, linear_loss=0.05172]
[2020-05-12 09:41:09.339]  Step 157989  [3.280 sec/step, loss=0.08442, avg_loss=0.08725, mel_loss=0.03625, linear_loss=0.04817]
[2020-05-12 09:41:12.748]  Step 157990  [3.293 sec/step, loss=0.09329, avg_loss=0.08731, mel_loss=0.04128, linear_loss=0.05201]
[2020-05-12 09:41:15.600]  Generated 32 batches of size 32 in 6.255 sec
[2020-05-12 09:41:18.339]  Step 157991  [3.340 sec/step, loss=0.09579, avg_loss=0.08751, mel_loss=0.04302, linear_loss=0.05278]
[2020-05-12 09:41:19.416]  Step 157992  [3.322 sec/step, loss=0.08306, avg_loss=0.08744, mel_loss=0.03515, linear_loss=0.04792]
[2020-05-12 09:41:26.207]  Step 157993  [3.379 sec/step, loss=0.09744, avg_loss=0.08764, mel_loss=0.04423, linear_loss=0.05321]
[2020-05-12 09:41:30.007]  Step 157994  [3.332 sec/step, loss=0.09408, avg_loss=0.08766, mel_loss=0.04178, linear_loss=0.05230]
[2020-05-12 09:41:32.694]  Step 157995  [3.334 sec/step, loss=0.08876, avg_loss=0.08765, mel_loss=0.03881, linear_loss=0.04995]
[2020-05-12 09:41:34.825]  Step 157996  [3.339 sec/step, loss=0.09097, avg_loss=0.08770, mel_loss=0.03978, linear_loss=0.05120]
[2020-05-12 09:41:35.391]  Step 157997  [3.333 sec/step, loss=0.06968, avg_loss=0.08759, mel_loss=0.03030, linear_loss=0.03938]
[2020-05-12 09:41:38.881]  Step 157998  [3.361 sec/step, loss=0.09517, avg_loss=0.08783, mel_loss=0.04224, linear_loss=0.05293]
[2020-05-12 09:41:39.688]  Step 157999  [3.321 sec/step, loss=0.07390, avg_loss=0.08762, mel_loss=0.03174, linear_loss=0.04216]
[2020-05-12 09:41:45.353]  Step 158000  [3.309 sec/step, loss=0.09543, avg_loss=0.08761, mel_loss=0.04309, linear_loss=0.05235]
[2020-05-12 09:41:45.353]  Writing summary at step: 158000
[2020-05-12 09:41:46.932]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158000
[2020-05-12 09:41:51.278]  Saving audio and alignment...
[2020-05-12 09:41:54.551]  Input: 발음이 무너지는 친구들이 많거든요~___
[2020-05-12 09:41:56.689]  Step 158001  [3.294 sec/step, loss=0.08834, avg_loss=0.08755, mel_loss=0.03852, linear_loss=0.04982]
[2020-05-12 09:42:00.558]  Step 158002  [3.315 sec/step, loss=0.09604, avg_loss=0.08762, mel_loss=0.04291, linear_loss=0.05312]
[2020-05-12 09:42:02.425]  Step 158003  [3.201 sec/step, loss=0.08650, avg_loss=0.08767, mel_loss=0.03732, linear_loss=0.04918]
[2020-05-12 09:42:08.000]  Step 158004  [3.240 sec/step, loss=0.09387, avg_loss=0.08773, mel_loss=0.04220, linear_loss=0.05168]
[2020-05-12 09:42:11.025]  Step 158005  [3.248 sec/step, loss=0.09125, avg_loss=0.08776, mel_loss=0.04019, linear_loss=0.05105]
[2020-05-12 09:42:12.177]  Step 158006  [3.245 sec/step, loss=0.08191, avg_loss=0.08774, mel_loss=0.03491, linear_loss=0.04700]
[2020-05-12 09:42:13.657]  Step 158007  [3.226 sec/step, loss=0.08176, avg_loss=0.08763, mel_loss=0.03520, linear_loss=0.04656]
[2020-05-12 09:42:14.948]  Step 158008  [3.229 sec/step, loss=0.08023, avg_loss=0.08763, mel_loss=0.03457, linear_loss=0.04566]
[2020-05-12 09:42:17.151]  Step 158009  [3.119 sec/step, loss=0.08682, avg_loss=0.08770, mel_loss=0.03774, linear_loss=0.04908]
[2020-05-12 09:42:18.631]  Step 158010  [3.078 sec/step, loss=0.08402, avg_loss=0.08759, mel_loss=0.03624, linear_loss=0.04778]
[2020-05-12 09:42:21.727]  Step 158011  [3.056 sec/step, loss=0.09332, avg_loss=0.08756, mel_loss=0.04135, linear_loss=0.05197]
[2020-05-12 09:42:35.323]  Step 158012  [3.168 sec/step, loss=0.08067, avg_loss=0.08747, mel_loss=0.03739, linear_loss=0.04328]
[2020-05-12 09:42:44.342]  Step 158013  [3.185 sec/step, loss=0.09325, avg_loss=0.08745, mel_loss=0.04272, linear_loss=0.05052]
[2020-05-12 09:42:48.495]  Step 158014  [3.199 sec/step, loss=0.09290, avg_loss=0.08746, mel_loss=0.04117, linear_loss=0.05174]
[2020-05-12 09:42:49.517]  Step 158015  [3.189 sec/step, loss=0.07967, avg_loss=0.08740, mel_loss=0.03404, linear_loss=0.04563]
[2020-05-12 09:42:53.708]  Step 158016  [3.204 sec/step, loss=0.09406, avg_loss=0.08747, mel_loss=0.04192, linear_loss=0.05214]
[2020-05-12 09:42:56.307]  Step 158017  [3.218 sec/step, loss=0.09033, avg_loss=0.08755, mel_loss=0.03975, linear_loss=0.05058]
[2020-05-12 09:43:03.801]  Step 158018  [3.284 sec/step, loss=0.09678, avg_loss=0.08777, mel_loss=0.04432, linear_loss=0.05246]
[2020-05-12 09:43:05.425]  Step 158019  [3.264 sec/step, loss=0.08430, avg_loss=0.08767, mel_loss=0.03681, linear_loss=0.04750]
[2020-05-12 09:43:07.296]  Generated 32 batches of size 32 in 1.866 sec
[2020-05-12 09:43:09.042]  Step 158020  [3.291 sec/step, loss=0.09116, avg_loss=0.08781, mel_loss=0.04043, linear_loss=0.05072]
[2020-05-12 09:43:13.752]  Step 158021  [3.332 sec/step, loss=0.09453, avg_loss=0.08806, mel_loss=0.04207, linear_loss=0.05246]
[2020-05-12 09:43:15.981]  Step 158022  [3.335 sec/step, loss=0.08824, avg_loss=0.08809, mel_loss=0.03855, linear_loss=0.04968]
[2020-05-12 09:43:22.675]  Step 158023  [3.390 sec/step, loss=0.09589, avg_loss=0.08823, mel_loss=0.04347, linear_loss=0.05241]
[2020-05-12 09:43:26.160]  Step 158024  [3.378 sec/step, loss=0.09354, avg_loss=0.08821, mel_loss=0.04168, linear_loss=0.05186]
[2020-05-12 09:43:26.706]  Step 158025  [3.343 sec/step, loss=0.07043, avg_loss=0.08798, mel_loss=0.03127, linear_loss=0.03916]
[2020-05-12 09:43:29.516]  Step 158026  [3.342 sec/step, loss=0.09069, avg_loss=0.08795, mel_loss=0.04010, linear_loss=0.05059]
[2020-05-12 09:43:31.943]  Step 158027  [3.358 sec/step, loss=0.08788, avg_loss=0.08810, mel_loss=0.03837, linear_loss=0.04951]
[2020-05-12 09:43:32.778]  Step 158028  [3.350 sec/step, loss=0.07368, avg_loss=0.08798, mel_loss=0.03160, linear_loss=0.04208]
[2020-05-12 09:43:33.998]  Step 158029  [3.274 sec/step, loss=0.08095, avg_loss=0.08783, mel_loss=0.03466, linear_loss=0.04629]
[2020-05-12 09:43:34.868]  Step 158030  [3.252 sec/step, loss=0.07870, avg_loss=0.08769, mel_loss=0.03310, linear_loss=0.04560]
[2020-05-12 09:43:37.499]  Step 158031  [3.262 sec/step, loss=0.09045, avg_loss=0.08774, mel_loss=0.03961, linear_loss=0.05083]
[2020-05-12 09:43:41.547]  Step 158032  [3.288 sec/step, loss=0.09329, avg_loss=0.08782, mel_loss=0.04158, linear_loss=0.05171]
[2020-05-12 09:43:42.855]  Step 158033  [3.240 sec/step, loss=0.08448, avg_loss=0.08771, mel_loss=0.03628, linear_loss=0.04819]
[2020-05-12 09:43:49.650]  Step 158034  [3.288 sec/step, loss=0.09531, avg_loss=0.08778, mel_loss=0.04337, linear_loss=0.05194]
[2020-05-12 09:44:04.152]  Step 158035  [3.396 sec/step, loss=0.07525, avg_loss=0.08760, mel_loss=0.03541, linear_loss=0.03984]
[2020-05-12 09:44:09.087]  Step 158036  [3.403 sec/step, loss=0.09564, avg_loss=0.08761, mel_loss=0.04289, linear_loss=0.05275]
[2020-05-12 09:44:10.916]  Step 158037  [3.364 sec/step, loss=0.08680, avg_loss=0.08753, mel_loss=0.03771, linear_loss=0.04910]
[2020-05-12 09:44:12.903]  Step 158038  [3.338 sec/step, loss=0.08905, avg_loss=0.08746, mel_loss=0.03867, linear_loss=0.05038]
[2020-05-12 09:44:16.290]  Step 158039  [3.308 sec/step, loss=0.09089, avg_loss=0.08741, mel_loss=0.04016, linear_loss=0.05073]
[2020-05-12 09:44:17.082]  Step 158040  [3.294 sec/step, loss=0.07382, avg_loss=0.08728, mel_loss=0.03126, linear_loss=0.04257]
[2020-05-12 09:44:18.167]  Step 158041  [3.255 sec/step, loss=0.08034, avg_loss=0.08713, mel_loss=0.03419, linear_loss=0.04615]
[2020-05-12 09:44:19.788]  Step 158042  [3.257 sec/step, loss=0.08801, avg_loss=0.08718, mel_loss=0.03807, linear_loss=0.04994]
[2020-05-12 09:44:21.372]  Step 158043  [3.253 sec/step, loss=0.08402, avg_loss=0.08714, mel_loss=0.03627, linear_loss=0.04775]
[2020-05-12 09:44:25.840]  Step 158044  [3.281 sec/step, loss=0.09663, avg_loss=0.08723, mel_loss=0.04351, linear_loss=0.05313]
[2020-05-12 09:44:28.722]  Step 158045  [3.285 sec/step, loss=0.09028, avg_loss=0.08723, mel_loss=0.03986, linear_loss=0.05042]
[2020-05-12 09:44:31.815]  Step 158046  [3.306 sec/step, loss=0.09312, avg_loss=0.08735, mel_loss=0.04107, linear_loss=0.05206]
[2020-05-12 09:44:34.001]  Step 158047  [3.319 sec/step, loss=0.08911, avg_loss=0.08754, mel_loss=0.03898, linear_loss=0.05013]
[2020-05-12 09:44:36.437]  Step 158048  [3.318 sec/step, loss=0.09117, avg_loss=0.08755, mel_loss=0.03990, linear_loss=0.05127]
[2020-05-12 09:44:37.837]  Step 158049  [3.326 sec/step, loss=0.08309, avg_loss=0.08766, mel_loss=0.03597, linear_loss=0.04712]
[2020-05-12 09:44:46.430]  Step 158050  [3.381 sec/step, loss=0.09328, avg_loss=0.08765, mel_loss=0.04268, linear_loss=0.05060]
[2020-05-12 09:44:46.430]  Writing summary at step: 158050
[2020-05-12 09:44:50.084]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158050
[2020-05-12 09:44:51.650]  Saving audio and alignment...
[2020-05-12 09:44:55.490]  Input: 오늘따라 송식씨가 순영씨에 속을 긁는다~___
[2020-05-12 09:44:56.053]  Step 158051  [3.373 sec/step, loss=0.06774, avg_loss=0.08752, mel_loss=0.02959, linear_loss=0.03815]
[2020-05-12 09:44:59.240]  Step 158052  [3.385 sec/step, loss=0.09431, avg_loss=0.08758, mel_loss=0.04178, linear_loss=0.05253]
[2020-05-12 09:45:00.215]  Step 158053  [3.383 sec/step, loss=0.07954, avg_loss=0.08759, mel_loss=0.03391, linear_loss=0.04563]
[2020-05-12 09:45:01.977]  Step 158054  [3.387 sec/step, loss=0.08592, avg_loss=0.08760, mel_loss=0.03735, linear_loss=0.04856]
[2020-05-12 09:45:05.773]  Step 158055  [3.349 sec/step, loss=0.09401, avg_loss=0.08757, mel_loss=0.04181, linear_loss=0.05220]
[2020-05-12 09:45:11.753]  Step 158056  [3.269 sec/step, loss=0.09602, avg_loss=0.08775, mel_loss=0.04363, linear_loss=0.05239]
[2020-05-12 09:45:12.520]  Step 158057  [3.258 sec/step, loss=0.07564, avg_loss=0.08763, mel_loss=0.03219, linear_loss=0.04344]
[2020-05-12 09:45:17.837]  Step 158058  [3.295 sec/step, loss=0.09629, avg_loss=0.08773, mel_loss=0.04339, linear_loss=0.05290]
[2020-05-12 09:45:20.383]  Generated 32 batches of size 32 in 28.161 sec
[2020-05-12 09:45:22.982]  Step 158059  [3.312 sec/step, loss=0.09147, avg_loss=0.08772, mel_loss=0.04001, linear_loss=0.05146]
[2020-05-12 09:45:24.031]  Step 158060  [3.279 sec/step, loss=0.08410, avg_loss=0.08761, mel_loss=0.03596, linear_loss=0.04814]
[2020-05-12 09:45:24.591]  Step 158061  [3.276 sec/step, loss=0.07113, avg_loss=0.08759, mel_loss=0.03149, linear_loss=0.03965]
[2020-05-12 09:45:26.803]  Step 158062  [3.288 sec/step, loss=0.08876, avg_loss=0.08770, mel_loss=0.03886, linear_loss=0.04989]
[2020-05-12 09:45:28.747]  Step 158063  [3.271 sec/step, loss=0.08779, avg_loss=0.08763, mel_loss=0.03815, linear_loss=0.04964]
[2020-05-12 09:45:30.349]  Step 158064  [3.248 sec/step, loss=0.08657, avg_loss=0.08756, mel_loss=0.03756, linear_loss=0.04900]
[2020-05-12 09:45:32.107]  Step 158065  [3.237 sec/step, loss=0.08542, avg_loss=0.08751, mel_loss=0.03690, linear_loss=0.04852]
[2020-05-12 09:45:38.511]  Step 158066  [3.211 sec/step, loss=0.09390, avg_loss=0.08750, mel_loss=0.04256, linear_loss=0.05133]
[2020-05-12 09:45:41.477]  Step 158067  [3.221 sec/step, loss=0.09293, avg_loss=0.08753, mel_loss=0.04110, linear_loss=0.05182]
[2020-05-12 09:45:45.748]  Step 158068  [3.246 sec/step, loss=0.09364, avg_loss=0.08761, mel_loss=0.04181, linear_loss=0.05183]
[2020-05-12 09:45:47.203]  Step 158069  [3.243 sec/step, loss=0.08541, avg_loss=0.08759, mel_loss=0.03677, linear_loss=0.04863]
[2020-05-12 09:45:48.371]  Step 158070  [3.226 sec/step, loss=0.08117, avg_loss=0.08749, mel_loss=0.03477, linear_loss=0.04640]
[2020-05-12 09:45:54.007]  Step 158071  [3.267 sec/step, loss=0.09458, avg_loss=0.08758, mel_loss=0.04272, linear_loss=0.05186]
[2020-05-12 09:45:54.675]  Step 158072  [3.260 sec/step, loss=0.07282, avg_loss=0.08747, mel_loss=0.03160, linear_loss=0.04122]
[2020-05-12 09:45:58.006]  Step 158073  [3.181 sec/step, loss=0.09284, avg_loss=0.08751, mel_loss=0.04118, linear_loss=0.05166]
[2020-05-12 09:45:59.037]  Step 158074  [3.149 sec/step, loss=0.07859, avg_loss=0.08737, mel_loss=0.03390, linear_loss=0.04469]
[2020-05-12 09:46:02.426]  Step 158075  [3.102 sec/step, loss=0.09268, avg_loss=0.08734, mel_loss=0.04132, linear_loss=0.05136]
[2020-05-12 09:46:11.385]  Step 158076  [3.169 sec/step, loss=0.09491, avg_loss=0.08739, mel_loss=0.04380, linear_loss=0.05111]
[2020-05-12 09:46:13.828]  Step 158077  [3.186 sec/step, loss=0.09004, avg_loss=0.08754, mel_loss=0.03928, linear_loss=0.05077]
[2020-05-12 09:46:26.963]  Step 158078  [3.293 sec/step, loss=0.08256, avg_loss=0.08746, mel_loss=0.03861, linear_loss=0.04395]
[2020-05-12 09:46:27.983]  Step 158079  [3.268 sec/step, loss=0.07829, avg_loss=0.08733, mel_loss=0.03326, linear_loss=0.04503]
[2020-05-12 09:46:32.354]  Step 158080  [3.260 sec/step, loss=0.09581, avg_loss=0.08734, mel_loss=0.04288, linear_loss=0.05294]
[2020-05-12 09:46:34.423]  Step 158081  [3.274 sec/step, loss=0.08825, avg_loss=0.08752, mel_loss=0.03866, linear_loss=0.04958]
[2020-05-12 09:46:38.174]  Step 158082  [3.301 sec/step, loss=0.09488, avg_loss=0.08767, mel_loss=0.04195, linear_loss=0.05293]
[2020-05-12 09:46:45.517]  Step 158083  [3.365 sec/step, loss=0.09717, avg_loss=0.08787, mel_loss=0.04434, linear_loss=0.05283]
[2020-05-12 09:46:46.333]  Step 158084  [3.359 sec/step, loss=0.07725, avg_loss=0.08778, mel_loss=0.03300, linear_loss=0.04425]
[2020-05-12 09:46:49.935]  Step 158085  [3.366 sec/step, loss=0.09197, avg_loss=0.08778, mel_loss=0.04092, linear_loss=0.05105]
[2020-05-12 09:46:51.267]  Step 158086  [3.360 sec/step, loss=0.08472, avg_loss=0.08776, mel_loss=0.03624, linear_loss=0.04848]
[2020-05-12 09:46:52.611]  Step 158087  [3.328 sec/step, loss=0.08480, avg_loss=0.08766, mel_loss=0.03650, linear_loss=0.04830]
[2020-05-12 09:46:57.591]  Step 158088  [3.312 sec/step, loss=0.09403, avg_loss=0.08766, mel_loss=0.04235, linear_loss=0.05168]
[2020-05-12 09:46:57.845]  Generated 32 batches of size 32 in 23.416 sec
[2020-05-12 09:47:00.312]  Step 158089  [3.327 sec/step, loss=0.08990, avg_loss=0.08771, mel_loss=0.03975, linear_loss=0.05015]
[2020-05-12 09:47:02.146]  Step 158090  [3.311 sec/step, loss=0.08580, avg_loss=0.08764, mel_loss=0.03720, linear_loss=0.04860]
[2020-05-12 09:47:07.802]  Step 158091  [3.312 sec/step, loss=0.09506, avg_loss=0.08763, mel_loss=0.04296, linear_loss=0.05210]
[2020-05-12 09:47:10.037]  Step 158092  [3.323 sec/step, loss=0.08810, avg_loss=0.08768, mel_loss=0.03848, linear_loss=0.04963]
[2020-05-12 09:47:11.596]  Step 158093  [3.271 sec/step, loss=0.08649, avg_loss=0.08757, mel_loss=0.03721, linear_loss=0.04928]
[2020-05-12 09:47:14.448]  Step 158094  [3.262 sec/step, loss=0.09194, avg_loss=0.08755, mel_loss=0.04067, linear_loss=0.05127]
[2020-05-12 09:47:15.790]  Step 158095  [3.248 sec/step, loss=0.08555, avg_loss=0.08752, mel_loss=0.03680, linear_loss=0.04875]
[2020-05-12 09:47:17.596]  Step 158096  [3.245 sec/step, loss=0.08491, avg_loss=0.08746, mel_loss=0.03687, linear_loss=0.04804]
[2020-05-12 09:47:18.984]  Step 158097  [3.253 sec/step, loss=0.07988, avg_loss=0.08756, mel_loss=0.03444, linear_loss=0.04543]
[2020-05-12 09:47:22.760]  Step 158098  [3.256 sec/step, loss=0.09676, avg_loss=0.08757, mel_loss=0.04309, linear_loss=0.05367]
[2020-05-12 09:47:25.877]  Step 158099  [3.279 sec/step, loss=0.09429, avg_loss=0.08778, mel_loss=0.04168, linear_loss=0.05261]
[2020-05-12 09:47:30.258]  Step 158100  [3.266 sec/step, loss=0.09532, avg_loss=0.08778, mel_loss=0.04279, linear_loss=0.05253]
[2020-05-12 09:47:30.258]  Writing summary at step: 158100
[2020-05-12 09:47:31.077]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158100
[2020-05-12 09:47:32.675]  Saving audio and alignment...
[2020-05-12 09:47:39.576]  Input: 빨랐다 느렸다를 이야기 합니다 빠른 부분이 있는가하면~___________________________________
[2020-05-12 09:47:42.484]  Step 158101  [3.274 sec/step, loss=0.08805, avg_loss=0.08777, mel_loss=0.03855, linear_loss=0.04950]
[2020-05-12 09:47:44.651]  Step 158102  [3.257 sec/step, loss=0.08687, avg_loss=0.08768, mel_loss=0.03798, linear_loss=0.04889]
[2020-05-12 09:47:45.603]  Step 158103  [3.248 sec/step, loss=0.07856, avg_loss=0.08760, mel_loss=0.03318, linear_loss=0.04538]
[2020-05-12 09:47:48.190]  Step 158104  [3.218 sec/step, loss=0.08989, avg_loss=0.08756, mel_loss=0.03928, linear_loss=0.05061]
[2020-05-12 09:47:54.916]  Step 158105  [3.255 sec/step, loss=0.09568, avg_loss=0.08761, mel_loss=0.04359, linear_loss=0.05209]
[2020-05-12 09:47:56.942]  Step 158106  [3.264 sec/step, loss=0.09118, avg_loss=0.08770, mel_loss=0.03961, linear_loss=0.05157]
[2020-05-12 09:47:58.096]  Step 158107  [3.260 sec/step, loss=0.08004, avg_loss=0.08768, mel_loss=0.03400, linear_loss=0.04605]
[2020-05-12 09:48:03.431]  Step 158108  [3.301 sec/step, loss=0.09480, avg_loss=0.08783, mel_loss=0.04254, linear_loss=0.05227]
[2020-05-12 09:48:04.485]  Step 158109  [3.289 sec/step, loss=0.07755, avg_loss=0.08774, mel_loss=0.03301, linear_loss=0.04454]
[2020-05-12 09:48:07.512]  Step 158110  [3.305 sec/step, loss=0.09407, avg_loss=0.08784, mel_loss=0.04151, linear_loss=0.05256]
[2020-05-12 09:48:08.306]  Step 158111  [3.282 sec/step, loss=0.06998, avg_loss=0.08760, mel_loss=0.02955, linear_loss=0.04044]
[2020-05-12 09:48:09.105]  Step 158112  [3.154 sec/step, loss=0.06868, avg_loss=0.08748, mel_loss=0.02987, linear_loss=0.03881]
[2020-05-12 09:48:09.993]  Generated 32 batches of size 32 in 1.681 sec
[2020-05-12 09:48:13.335]  Step 158113  [3.106 sec/step, loss=0.09379, avg_loss=0.08749, mel_loss=0.04172, linear_loss=0.05206]
[2020-05-12 09:48:20.864]  Step 158114  [3.140 sec/step, loss=0.09607, avg_loss=0.08752, mel_loss=0.04369, linear_loss=0.05237]
[2020-05-12 09:48:22.549]  Step 158115  [3.146 sec/step, loss=0.08520, avg_loss=0.08758, mel_loss=0.03702, linear_loss=0.04818]
[2020-05-12 09:48:30.841]  Step 158116  [3.187 sec/step, loss=0.09501, avg_loss=0.08758, mel_loss=0.04351, linear_loss=0.05149]
[2020-05-12 09:48:32.542]  Step 158117  [3.178 sec/step, loss=0.08723, avg_loss=0.08755, mel_loss=0.03768, linear_loss=0.04954]
[2020-05-12 09:48:36.316]  Step 158118  [3.141 sec/step, loss=0.09299, avg_loss=0.08752, mel_loss=0.04155, linear_loss=0.05144]
[2020-05-12 09:48:50.431]  Step 158119  [3.266 sec/step, loss=0.07332, avg_loss=0.08741, mel_loss=0.03432, linear_loss=0.03900]
[2020-05-12 09:48:53.987]  Step 158120  [3.265 sec/step, loss=0.09161, avg_loss=0.08741, mel_loss=0.04080, linear_loss=0.05080]
[2020-05-12 09:48:55.314]  Step 158121  [3.232 sec/step, loss=0.08482, avg_loss=0.08731, mel_loss=0.03643, linear_loss=0.04839]
[2020-05-12 09:48:58.914]  Step 158122  [3.245 sec/step, loss=0.09464, avg_loss=0.08738, mel_loss=0.04203, linear_loss=0.05260]
[2020-05-12 09:49:01.268]  Step 158123  [3.202 sec/step, loss=0.08993, avg_loss=0.08732, mel_loss=0.03957, linear_loss=0.05036]
[2020-05-12 09:49:06.499]  Step 158124  [3.219 sec/step, loss=0.09447, avg_loss=0.08733, mel_loss=0.04243, linear_loss=0.05204]
[2020-05-12 09:49:07.609]  Step 158125  [3.225 sec/step, loss=0.08079, avg_loss=0.08743, mel_loss=0.03434, linear_loss=0.04645]
[2020-05-12 09:49:10.524]  Step 158126  [3.226 sec/step, loss=0.08987, avg_loss=0.08742, mel_loss=0.03962, linear_loss=0.05025]
[2020-05-12 09:49:12.296]  Step 158127  [3.219 sec/step, loss=0.08723, avg_loss=0.08742, mel_loss=0.03754, linear_loss=0.04968]
[2020-05-12 09:49:15.544]  Step 158128  [3.244 sec/step, loss=0.09468, avg_loss=0.08763, mel_loss=0.04177, linear_loss=0.05292]
[2020-05-12 09:49:17.136]  Step 158129  [3.247 sec/step, loss=0.08548, avg_loss=0.08767, mel_loss=0.03696, linear_loss=0.04853]
[2020-05-12 09:49:24.525]  Step 158130  [3.313 sec/step, loss=0.09711, avg_loss=0.08786, mel_loss=0.04429, linear_loss=0.05282]
[2020-05-12 09:49:26.691]  Step 158131  [3.308 sec/step, loss=0.08696, avg_loss=0.08782, mel_loss=0.03796, linear_loss=0.04900]
[2020-05-12 09:49:27.512]  Step 158132  [3.276 sec/step, loss=0.07355, avg_loss=0.08762, mel_loss=0.03153, linear_loss=0.04202]
[2020-05-12 09:49:28.365]  Step 158133  [3.271 sec/step, loss=0.07809, avg_loss=0.08756, mel_loss=0.03305, linear_loss=0.04505]
[2020-05-12 09:49:42.667]  Step 158134  [3.346 sec/step, loss=0.07380, avg_loss=0.08734, mel_loss=0.03485, linear_loss=0.03895]
[2020-05-12 09:49:49.180]  Step 158135  [3.266 sec/step, loss=0.09516, avg_loss=0.08754, mel_loss=0.04311, linear_loss=0.05205]
[2020-05-12 09:49:57.766]  Step 158136  [3.303 sec/step, loss=0.09292, avg_loss=0.08752, mel_loss=0.04233, linear_loss=0.05059]
[2020-05-12 09:50:02.368]  Step 158137  [3.330 sec/step, loss=0.09492, avg_loss=0.08760, mel_loss=0.04242, linear_loss=0.05251]
[2020-05-12 09:50:05.005]  Step 158138  [3.337 sec/step, loss=0.09018, avg_loss=0.08761, mel_loss=0.03969, linear_loss=0.05048]
[2020-05-12 09:50:06.397]  Step 158139  [3.317 sec/step, loss=0.08187, avg_loss=0.08752, mel_loss=0.03520, linear_loss=0.04667]
[2020-05-12 09:50:07.441]  Step 158140  [3.320 sec/step, loss=0.07894, avg_loss=0.08757, mel_loss=0.03370, linear_loss=0.04524]
[2020-05-12 09:50:07.966]  Step 158141  [3.314 sec/step, loss=0.07231, avg_loss=0.08749, mel_loss=0.03113, linear_loss=0.04118]
[2020-05-12 09:50:11.135]  Step 158142  [3.329 sec/step, loss=0.09345, avg_loss=0.08754, mel_loss=0.04124, linear_loss=0.05220]
[2020-05-12 09:50:16.813]  Step 158143  [3.370 sec/step, loss=0.09479, avg_loss=0.08765, mel_loss=0.04287, linear_loss=0.05192]
[2020-05-12 09:50:18.347]  Step 158144  [3.341 sec/step, loss=0.08411, avg_loss=0.08753, mel_loss=0.03630, linear_loss=0.04781]
[2020-05-12 09:50:22.714]  Step 158145  [3.356 sec/step, loss=0.09243, avg_loss=0.08755, mel_loss=0.04111, linear_loss=0.05132]
[2020-05-12 09:50:25.209]  Step 158146  [3.350 sec/step, loss=0.08841, avg_loss=0.08750, mel_loss=0.03858, linear_loss=0.04982]
[2020-05-12 09:50:28.992]  Step 158147  [3.366 sec/step, loss=0.09564, avg_loss=0.08757, mel_loss=0.04223, linear_loss=0.05342]
[2020-05-12 09:50:29.831]  Step 158148  [3.350 sec/step, loss=0.07091, avg_loss=0.08736, mel_loss=0.03076, linear_loss=0.04015]
[2020-05-12 09:50:31.820]  Step 158149  [3.356 sec/step, loss=0.08812, avg_loss=0.08741, mel_loss=0.03848, linear_loss=0.04963]
[2020-05-12 09:50:33.052]  Step 158150  [3.282 sec/step, loss=0.08075, avg_loss=0.08729, mel_loss=0.03451, linear_loss=0.04624]
[2020-05-12 09:50:33.052]  Writing summary at step: 158150
[2020-05-12 09:50:36.628]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158150
[2020-05-12 09:50:38.255]  Saving audio and alignment...
[2020-05-12 09:50:41.537]  Input: 소중한 것을 지켜야 한다아~____________
[2020-05-12 09:51:42.432]  Generated 32 batches of size 32 in 85.613 sec
[2020-05-12 09:51:49.252]  Step 158151  [3.954 sec/step, loss=0.09757, avg_loss=0.08759, mel_loss=0.04426, linear_loss=0.05331]
[2020-05-12 09:51:49.810]  Step 158152  [3.927 sec/step, loss=0.07197, avg_loss=0.08736, mel_loss=0.03108, linear_loss=0.04088]
[2020-05-12 09:51:52.029]  Step 158153  [3.940 sec/step, loss=0.08883, avg_loss=0.08746, mel_loss=0.03891, linear_loss=0.04992]
[2020-05-12 09:51:54.171]  Step 158154  [3.944 sec/step, loss=0.08904, avg_loss=0.08749, mel_loss=0.03883, linear_loss=0.05021]
[2020-05-12 09:51:54.975]  Step 158155  [3.914 sec/step, loss=0.07692, avg_loss=0.08732, mel_loss=0.03226, linear_loss=0.04466]
[2020-05-12 09:51:57.377]  Step 158156  [3.878 sec/step, loss=0.08864, avg_loss=0.08724, mel_loss=0.03872, linear_loss=0.04992]
[2020-05-12 09:52:04.468]  Step 158157  [3.941 sec/step, loss=0.09418, avg_loss=0.08743, mel_loss=0.04219, linear_loss=0.05199]
[2020-05-12 09:52:10.513]  Step 158158  [3.948 sec/step, loss=0.09709, avg_loss=0.08744, mel_loss=0.04370, linear_loss=0.05339]
[2020-05-12 09:52:11.730]  Step 158159  [3.909 sec/step, loss=0.08025, avg_loss=0.08732, mel_loss=0.03443, linear_loss=0.04581]
[2020-05-12 09:52:15.869]  Step 158160  [3.940 sec/step, loss=0.09306, avg_loss=0.08741, mel_loss=0.04156, linear_loss=0.05151]
[2020-05-12 09:52:17.197]  Step 158161  [3.948 sec/step, loss=0.08523, avg_loss=0.08755, mel_loss=0.03641, linear_loss=0.04882]
[2020-05-12 09:52:19.161]  Step 158162  [3.945 sec/step, loss=0.08703, avg_loss=0.08754, mel_loss=0.03777, linear_loss=0.04926]
[2020-05-12 09:52:22.169]  Step 158163  [3.956 sec/step, loss=0.09324, avg_loss=0.08759, mel_loss=0.04114, linear_loss=0.05210]
[2020-05-12 09:52:22.835]  Step 158164  [3.947 sec/step, loss=0.07687, avg_loss=0.08749, mel_loss=0.03319, linear_loss=0.04368]
[2020-05-12 09:52:23.863]  Step 158165  [3.939 sec/step, loss=0.07829, avg_loss=0.08742, mel_loss=0.03336, linear_loss=0.04493]
[2020-05-12 09:52:31.885]  Step 158166  [3.955 sec/step, loss=0.09643, avg_loss=0.08745, mel_loss=0.04418, linear_loss=0.05225]
[2020-05-12 09:52:35.010]  Step 158167  [3.957 sec/step, loss=0.09470, avg_loss=0.08747, mel_loss=0.04183, linear_loss=0.05287]
[2020-05-12 09:52:37.688]  Step 158168  [3.941 sec/step, loss=0.09210, avg_loss=0.08745, mel_loss=0.04082, linear_loss=0.05128]
[2020-05-12 09:52:46.640]  Step 158169  [4.016 sec/step, loss=0.09539, avg_loss=0.08755, mel_loss=0.04375, linear_loss=0.05164]
[2020-05-12 09:53:00.126]  Step 158170  [4.139 sec/step, loss=0.08123, avg_loss=0.08755, mel_loss=0.03788, linear_loss=0.04335]
[2020-05-12 09:53:04.272]  Step 158171  [4.124 sec/step, loss=0.09498, avg_loss=0.08756, mel_loss=0.04283, linear_loss=0.05215]
[2020-05-12 09:53:05.376]  Step 158172  [4.129 sec/step, loss=0.08379, avg_loss=0.08767, mel_loss=0.03540, linear_loss=0.04838]
[2020-05-12 09:53:07.123]  Step 158173  [4.113 sec/step, loss=0.08782, avg_loss=0.08762, mel_loss=0.03792, linear_loss=0.04990]
[2020-05-12 09:53:08.655]  Step 158174  [4.118 sec/step, loss=0.08398, avg_loss=0.08767, mel_loss=0.03642, linear_loss=0.04756]
[2020-05-12 09:53:11.026]  Step 158175  [4.108 sec/step, loss=0.08861, avg_loss=0.08763, mel_loss=0.03878, linear_loss=0.04982]
[2020-05-12 09:53:12.403]  Step 158176  [4.032 sec/step, loss=0.08446, avg_loss=0.08752, mel_loss=0.03664, linear_loss=0.04781]
[2020-05-12 09:53:16.040]  Step 158177  [4.044 sec/step, loss=0.09364, avg_loss=0.08756, mel_loss=0.04142, linear_loss=0.05222]
[2020-05-12 09:53:18.625]  Step 158178  [3.938 sec/step, loss=0.08931, avg_loss=0.08763, mel_loss=0.03915, linear_loss=0.05016]
[2020-05-12 09:53:19.529]  Step 158179  [3.937 sec/step, loss=0.08121, avg_loss=0.08766, mel_loss=0.03442, linear_loss=0.04679]
[2020-05-12 09:53:22.956]  Step 158180  [3.928 sec/step, loss=0.09137, avg_loss=0.08761, mel_loss=0.04049, linear_loss=0.05088]
[2020-05-12 09:53:24.916]  Step 158181  [3.927 sec/step, loss=0.08790, avg_loss=0.08761, mel_loss=0.03814, linear_loss=0.04977]
[2020-05-12 09:53:30.216]  Step 158182  [3.942 sec/step, loss=0.09502, avg_loss=0.08761, mel_loss=0.04291, linear_loss=0.05211]
[2020-05-12 09:53:55.161]  Generated 32 batches of size 32 in 48.033 sec
[2020-05-12 09:54:03.811]  Step 158183  [4.205 sec/step, loss=0.09194, avg_loss=0.08756, mel_loss=0.04198, linear_loss=0.04996]
[2020-05-12 09:54:09.935]  Step 158184  [4.258 sec/step, loss=0.09320, avg_loss=0.08772, mel_loss=0.04229, linear_loss=0.05092]
[2020-05-12 09:54:12.191]  Step 158185  [4.244 sec/step, loss=0.08980, avg_loss=0.08770, mel_loss=0.03948, linear_loss=0.05032]
[2020-05-12 09:54:14.350]  Step 158186  [4.253 sec/step, loss=0.09001, avg_loss=0.08775, mel_loss=0.03935, linear_loss=0.05066]
[2020-05-12 09:54:15.408]  Step 158187  [4.250 sec/step, loss=0.08016, avg_loss=0.08770, mel_loss=0.03435, linear_loss=0.04581]
[2020-05-12 09:54:16.711]  Step 158188  [4.213 sec/step, loss=0.08364, avg_loss=0.08760, mel_loss=0.03582, linear_loss=0.04782]
[2020-05-12 09:54:18.737]  Step 158189  [4.206 sec/step, loss=0.08777, avg_loss=0.08758, mel_loss=0.03823, linear_loss=0.04954]
[2020-05-12 09:54:19.540]  Step 158190  [4.196 sec/step, loss=0.07632, avg_loss=0.08748, mel_loss=0.03253, linear_loss=0.04379]
[2020-05-12 09:54:20.506]  Step 158191  [4.149 sec/step, loss=0.08228, avg_loss=0.08735, mel_loss=0.03536, linear_loss=0.04693]
[2020-05-12 09:54:24.616]  Step 158192  [4.168 sec/step, loss=0.09455, avg_loss=0.08742, mel_loss=0.04213, linear_loss=0.05242]
[2020-05-12 09:54:29.102]  Step 158193  [4.197 sec/step, loss=0.09554, avg_loss=0.08751, mel_loss=0.04250, linear_loss=0.05304]
[2020-05-12 09:54:32.609]  Step 158194  [4.203 sec/step, loss=0.09271, avg_loss=0.08752, mel_loss=0.04107, linear_loss=0.05163]
[2020-05-12 09:54:35.510]  Step 158195  [4.219 sec/step, loss=0.09244, avg_loss=0.08759, mel_loss=0.04056, linear_loss=0.05188]
[2020-05-12 09:54:36.905]  Step 158196  [4.215 sec/step, loss=0.08259, avg_loss=0.08756, mel_loss=0.03568, linear_loss=0.04691]
[2020-05-12 09:54:37.771]  Step 158197  [4.210 sec/step, loss=0.06996, avg_loss=0.08746, mel_loss=0.02984, linear_loss=0.04012]
[2020-05-12 09:54:41.125]  Step 158198  [4.205 sec/step, loss=0.09308, avg_loss=0.08743, mel_loss=0.04133, linear_loss=0.05174]
[2020-05-12 09:54:42.893]  Step 158199  [4.192 sec/step, loss=0.08781, avg_loss=0.08736, mel_loss=0.03795, linear_loss=0.04986]
[2020-05-12 09:54:43.450]  Step 158200  [4.154 sec/step, loss=0.06846, avg_loss=0.08709, mel_loss=0.02993, linear_loss=0.03853]
[2020-05-12 09:54:43.450]  Writing summary at step: 158200
[2020-05-12 09:54:46.239]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158200
[2020-05-12 09:54:47.846]  Saving audio and alignment...
[2020-05-12 09:54:52.775]  Input: 이렇게 어미를 자주 올리는 평소의 말과는 달리~_____________
[2020-05-12 09:54:56.419]  Step 158201  [4.161 sec/step, loss=0.09507, avg_loss=0.08716, mel_loss=0.04238, linear_loss=0.05269]
[2020-05-12 09:55:00.182]  Step 158202  [4.177 sec/step, loss=0.09444, avg_loss=0.08724, mel_loss=0.04184, linear_loss=0.05260]
[2020-05-12 09:55:01.790]  Step 158203  [4.184 sec/step, loss=0.08846, avg_loss=0.08734, mel_loss=0.03831, linear_loss=0.05015]
[2020-05-12 09:55:04.240]  Step 158204  [4.182 sec/step, loss=0.09091, avg_loss=0.08735, mel_loss=0.03947, linear_loss=0.05144]
[2020-05-12 09:55:16.411]  Step 158205  [4.237 sec/step, loss=0.08596, avg_loss=0.08725, mel_loss=0.04028, linear_loss=0.04569]
[2020-05-12 09:55:17.572]  Step 158206  [4.228 sec/step, loss=0.08192, avg_loss=0.08716, mel_loss=0.03527, linear_loss=0.04665]
[2020-05-12 09:55:19.149]  Step 158207  [4.232 sec/step, loss=0.08506, avg_loss=0.08721, mel_loss=0.03676, linear_loss=0.04830]
[2020-05-12 09:55:20.221]  Generated 32 batches of size 32 in 18.425 sec
[2020-05-12 09:55:24.704]  Step 158208  [4.234 sec/step, loss=0.09517, avg_loss=0.08721, mel_loss=0.04267, linear_loss=0.05250]
[2020-05-12 09:55:25.701]  Step 158209  [4.234 sec/step, loss=0.07962, avg_loss=0.08723, mel_loss=0.03381, linear_loss=0.04581]
[2020-05-12 09:55:30.603]  Step 158210  [4.253 sec/step, loss=0.09377, avg_loss=0.08723, mel_loss=0.04202, linear_loss=0.05175]
[2020-05-12 09:55:32.445]  Step 158211  [4.263 sec/step, loss=0.08924, avg_loss=0.08742, mel_loss=0.03865, linear_loss=0.05059]
[2020-05-12 09:55:39.668]  Step 158212  [4.327 sec/step, loss=0.09606, avg_loss=0.08770, mel_loss=0.04367, linear_loss=0.05238]
[2020-05-12 09:55:40.673]  Step 158213  [4.295 sec/step, loss=0.08050, avg_loss=0.08756, mel_loss=0.03423, linear_loss=0.04627]
[2020-05-12 09:55:42.052]  Step 158214  [4.234 sec/step, loss=0.08469, avg_loss=0.08745, mel_loss=0.03669, linear_loss=0.04800]
[2020-05-12 09:55:44.819]  Step 158215  [4.244 sec/step, loss=0.08966, avg_loss=0.08749, mel_loss=0.03950, linear_loss=0.05016]
[2020-05-12 09:55:46.475]  Step 158216  [4.178 sec/step, loss=0.08472, avg_loss=0.08739, mel_loss=0.03657, linear_loss=0.04814]
[2020-05-12 09:55:52.072]  Step 158217  [4.217 sec/step, loss=0.09620, avg_loss=0.08748, mel_loss=0.04358, linear_loss=0.05262]
[2020-05-12 09:55:57.350]  Step 158218  [4.232 sec/step, loss=0.09440, avg_loss=0.08749, mel_loss=0.04263, linear_loss=0.05177]
[2020-05-12 09:56:00.398]  Step 158219  [4.121 sec/step, loss=0.09278, avg_loss=0.08769, mel_loss=0.04077, linear_loss=0.05201]
[2020-05-12 09:56:04.055]  Step 158220  [4.122 sec/step, loss=0.09470, avg_loss=0.08772, mel_loss=0.04219, linear_loss=0.05251]
[2020-05-12 09:56:06.003]  Step 158221  [4.129 sec/step, loss=0.08624, avg_loss=0.08773, mel_loss=0.03759, linear_loss=0.04866]
[2020-05-12 09:56:10.533]  Step 158222  [4.138 sec/step, loss=0.09455, avg_loss=0.08773, mel_loss=0.04203, linear_loss=0.05251]
[2020-05-12 09:56:12.532]  Step 158223  [4.134 sec/step, loss=0.08912, avg_loss=0.08773, mel_loss=0.03893, linear_loss=0.05020]
[2020-05-12 09:56:13.277]  Step 158224  [4.089 sec/step, loss=0.07201, avg_loss=0.08750, mel_loss=0.03106, linear_loss=0.04094]
[2020-05-12 09:56:15.877]  Step 158225  [4.104 sec/step, loss=0.08853, avg_loss=0.08758, mel_loss=0.03898, linear_loss=0.04955]
[2020-05-12 09:56:17.629]  Step 158226  [4.093 sec/step, loss=0.08592, avg_loss=0.08754, mel_loss=0.03674, linear_loss=0.04918]
[2020-05-12 09:56:18.408]  Step 158227  [4.083 sec/step, loss=0.07511, avg_loss=0.08742, mel_loss=0.03180, linear_loss=0.04331]
[2020-05-12 09:56:20.187]  Step 158228  [4.068 sec/step, loss=0.08772, avg_loss=0.08735, mel_loss=0.03795, linear_loss=0.04977]
[2020-05-12 09:56:21.643]  Step 158229  [4.067 sec/step, loss=0.08483, avg_loss=0.08734, mel_loss=0.03624, linear_loss=0.04859]
[2020-05-12 09:56:25.013]  Step 158230  [4.027 sec/step, loss=0.09144, avg_loss=0.08728, mel_loss=0.04069, linear_loss=0.05075]
[2020-05-12 09:56:26.108]  Step 158231  [4.016 sec/step, loss=0.08261, avg_loss=0.08724, mel_loss=0.03492, linear_loss=0.04769]
[2020-05-12 09:56:29.175]  Step 158232  [4.038 sec/step, loss=0.09506, avg_loss=0.08746, mel_loss=0.04197, linear_loss=0.05309]
[2020-05-12 09:56:30.382]  Step 158233  [4.042 sec/step, loss=0.08210, avg_loss=0.08750, mel_loss=0.03513, linear_loss=0.04697]
[2020-05-12 09:56:34.758]  Step 158234  [3.943 sec/step, loss=0.09475, avg_loss=0.08771, mel_loss=0.04240, linear_loss=0.05234]
[2020-05-12 09:56:48.926]  Step 158235  [4.019 sec/step, loss=0.07613, avg_loss=0.08752, mel_loss=0.03576, linear_loss=0.04037]
[2020-05-12 09:56:51.256]  Step 158236  [3.957 sec/step, loss=0.08618, avg_loss=0.08745, mel_loss=0.03779, linear_loss=0.04839]
[2020-05-12 09:56:54.848]  Step 158237  [3.946 sec/step, loss=0.09150, avg_loss=0.08741, mel_loss=0.04053, linear_loss=0.05098]
[2020-05-12 09:56:58.816]  Step 158238  [3.960 sec/step, loss=0.09322, avg_loss=0.08744, mel_loss=0.04142, linear_loss=0.05180]
[2020-05-12 09:56:59.351]  Step 158239  [3.951 sec/step, loss=0.07396, avg_loss=0.08737, mel_loss=0.03185, linear_loss=0.04211]
[2020-05-12 09:57:08.217]  Step 158240  [4.029 sec/step, loss=0.09476, avg_loss=0.08752, mel_loss=0.04347, linear_loss=0.05129]
[2020-05-12 09:57:10.742]  Step 158241  [4.049 sec/step, loss=0.08937, avg_loss=0.08769, mel_loss=0.03902, linear_loss=0.05035]
[2020-05-12 09:57:11.747]  Step 158242  [4.028 sec/step, loss=0.07721, avg_loss=0.08753, mel_loss=0.03267, linear_loss=0.04454]
[2020-05-12 09:57:18.178]  Step 158243  [4.035 sec/step, loss=0.09493, avg_loss=0.08753, mel_loss=0.04303, linear_loss=0.05190]
[2020-05-12 09:57:25.344]  Step 158244  [4.092 sec/step, loss=0.09474, avg_loss=0.08764, mel_loss=0.04308, linear_loss=0.05166]
[2020-05-12 09:58:42.068]  Generated 32 batches of size 32 in 113.137 sec
[2020-05-12 09:58:44.625]  Step 158245  [4.841 sec/step, loss=0.08821, avg_loss=0.08760, mel_loss=0.03844, linear_loss=0.04977]
[2020-05-12 09:58:46.609]  Step 158246  [4.836 sec/step, loss=0.08605, avg_loss=0.08757, mel_loss=0.03730, linear_loss=0.04875]
[2020-05-12 09:58:48.122]  Step 158247  [4.813 sec/step, loss=0.08531, avg_loss=0.08747, mel_loss=0.03696, linear_loss=0.04835]
[2020-05-12 09:58:53.345]  Step 158248  [4.857 sec/step, loss=0.09367, avg_loss=0.08770, mel_loss=0.04210, linear_loss=0.05157]
[2020-05-12 09:58:55.105]  Step 158249  [4.855 sec/step, loss=0.08728, avg_loss=0.08769, mel_loss=0.03749, linear_loss=0.04979]
[2020-05-12 09:58:56.107]  Step 158250  [4.852 sec/step, loss=0.07887, avg_loss=0.08767, mel_loss=0.03375, linear_loss=0.04512]
[2020-05-12 09:58:56.107]  Writing summary at step: 158250
[2020-05-12 09:58:57.355]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158250
[2020-05-12 09:58:58.908]  Saving audio and alignment...
[2020-05-12 09:59:04.629]  Input: 아주 유려함을 살릴 수 있는 고난도 기술이 듭니다~_____________________
[2020-05-12 09:59:08.951]  Step 158251  [4.218 sec/step, loss=0.09407, avg_loss=0.08764, mel_loss=0.04198, linear_loss=0.05209]
[2020-05-12 09:59:17.804]  Step 158252  [4.301 sec/step, loss=0.09427, avg_loss=0.08786, mel_loss=0.04328, linear_loss=0.05099]
[2020-05-12 09:59:30.963]  Step 158253  [4.411 sec/step, loss=0.08095, avg_loss=0.08778, mel_loss=0.03795, linear_loss=0.04300]
[2020-05-12 09:59:31.659]  Step 158254  [4.396 sec/step, loss=0.07484, avg_loss=0.08764, mel_loss=0.03214, linear_loss=0.04270]
[2020-05-12 09:59:38.493]  Step 158255  [4.456 sec/step, loss=0.09484, avg_loss=0.08782, mel_loss=0.04304, linear_loss=0.05180]
[2020-05-12 09:59:40.131]  Step 158256  [4.449 sec/step, loss=0.08661, avg_loss=0.08780, mel_loss=0.03795, linear_loss=0.04866]
[2020-05-12 09:59:45.529]  Step 158257  [4.432 sec/step, loss=0.09507, avg_loss=0.08781, mel_loss=0.04294, linear_loss=0.05213]
[2020-05-12 09:59:53.125]  Step 158258  [4.447 sec/step, loss=0.09655, avg_loss=0.08780, mel_loss=0.04410, linear_loss=0.05246]
[2020-05-12 09:59:55.864]  Step 158259  [4.463 sec/step, loss=0.09102, avg_loss=0.08791, mel_loss=0.03985, linear_loss=0.05117]
[2020-05-12 10:00:00.632]  Step 158260  [4.469 sec/step, loss=0.09521, avg_loss=0.08793, mel_loss=0.04275, linear_loss=0.05246]
[2020-05-12 10:00:04.780]  Step 158261  [4.497 sec/step, loss=0.09520, avg_loss=0.08803, mel_loss=0.04217, linear_loss=0.05303]
[2020-05-12 10:00:07.703]  Step 158262  [4.507 sec/step, loss=0.09065, avg_loss=0.08807, mel_loss=0.04015, linear_loss=0.05050]
[2020-05-12 10:00:08.779]  Step 158263  [4.487 sec/step, loss=0.08018, avg_loss=0.08794, mel_loss=0.03424, linear_loss=0.04594]
[2020-05-12 10:00:09.545]  Step 158264  [4.488 sec/step, loss=0.06965, avg_loss=0.08786, mel_loss=0.02999, linear_loss=0.03967]
[2020-05-12 10:00:12.707]  Step 158265  [4.510 sec/step, loss=0.09238, avg_loss=0.08800, mel_loss=0.04092, linear_loss=0.05145]
[2020-05-12 10:00:13.990]  Step 158266  [4.442 sec/step, loss=0.08448, avg_loss=0.08788, mel_loss=0.03638, linear_loss=0.04810]
[2020-05-12 10:00:17.437]  Step 158267  [4.446 sec/step, loss=0.09338, avg_loss=0.08787, mel_loss=0.04132, linear_loss=0.05206]
[2020-05-12 10:00:19.739]  Step 158268  [4.442 sec/step, loss=0.09021, avg_loss=0.08785, mel_loss=0.03959, linear_loss=0.05062]
[2020-05-12 10:00:23.284]  Step 158269  [4.388 sec/step, loss=0.09234, avg_loss=0.08782, mel_loss=0.04088, linear_loss=0.05145]
[2020-05-12 10:00:25.368]  Step 158270  [4.274 sec/step, loss=0.08654, avg_loss=0.08787, mel_loss=0.03747, linear_loss=0.04907]
[2020-05-12 10:00:26.196]  Step 158271  [4.241 sec/step, loss=0.07631, avg_loss=0.08769, mel_loss=0.03223, linear_loss=0.04408]
[2020-05-12 10:00:27.123]  Step 158272  [4.239 sec/step, loss=0.07656, avg_loss=0.08762, mel_loss=0.03220, linear_loss=0.04436]
[2020-05-12 10:00:29.294]  Step 158273  [4.243 sec/step, loss=0.09010, avg_loss=0.08764, mel_loss=0.03933, linear_loss=0.05078]
[2020-05-12 10:00:30.671]  Step 158274  [4.241 sec/step, loss=0.08586, avg_loss=0.08766, mel_loss=0.03684, linear_loss=0.04902]
[2020-05-12 10:00:36.982]  Generated 32 batches of size 32 in 24.269 sec
[2020-05-12 10:00:39.048]  Step 158275  [4.302 sec/step, loss=0.08910, avg_loss=0.08766, mel_loss=0.03861, linear_loss=0.05050]
[2020-05-12 10:00:40.172]  Step 158276  [4.299 sec/step, loss=0.08234, avg_loss=0.08764, mel_loss=0.03493, linear_loss=0.04741]
[2020-05-12 10:00:43.717]  Step 158277  [4.298 sec/step, loss=0.09017, avg_loss=0.08761, mel_loss=0.03994, linear_loss=0.05024]
[2020-05-12 10:00:44.536]  Step 158278  [4.280 sec/step, loss=0.07333, avg_loss=0.08745, mel_loss=0.03115, linear_loss=0.04218]
[2020-05-12 10:00:46.350]  Step 158279  [4.289 sec/step, loss=0.08534, avg_loss=0.08749, mel_loss=0.03674, linear_loss=0.04860]
[2020-05-12 10:00:53.225]  Step 158280  [4.324 sec/step, loss=0.09654, avg_loss=0.08754, mel_loss=0.04372, linear_loss=0.05282]
[2020-05-12 10:00:54.597]  Step 158281  [4.318 sec/step, loss=0.08135, avg_loss=0.08747, mel_loss=0.03474, linear_loss=0.04661]
[2020-05-12 10:00:55.166]  Step 158282  [4.271 sec/step, loss=0.06660, avg_loss=0.08719, mel_loss=0.02873, linear_loss=0.03787]
[2020-05-12 10:01:01.043]  Step 158283  [3.994 sec/step, loss=0.09437, avg_loss=0.08721, mel_loss=0.04231, linear_loss=0.05206]
[2020-05-12 10:01:02.737]  Step 158284  [3.949 sec/step, loss=0.08581, avg_loss=0.08714, mel_loss=0.03701, linear_loss=0.04880]
[2020-05-12 10:01:03.391]  Step 158285  [3.933 sec/step, loss=0.07312, avg_loss=0.08697, mel_loss=0.03144, linear_loss=0.04168]
[2020-05-12 10:01:04.632]  Step 158286  [3.924 sec/step, loss=0.08178, avg_loss=0.08689, mel_loss=0.03512, linear_loss=0.04666]
[2020-05-12 10:01:05.647]  Step 158287  [3.924 sec/step, loss=0.07841, avg_loss=0.08687, mel_loss=0.03299, linear_loss=0.04542]
[2020-05-12 10:01:08.348]  Step 158288  [3.938 sec/step, loss=0.09037, avg_loss=0.08694, mel_loss=0.03971, linear_loss=0.05066]
[2020-05-12 10:01:10.345]  Step 158289  [3.937 sec/step, loss=0.08835, avg_loss=0.08695, mel_loss=0.03856, linear_loss=0.04979]
[2020-05-12 10:01:14.632]  Step 158290  [3.972 sec/step, loss=0.09470, avg_loss=0.08713, mel_loss=0.04247, linear_loss=0.05224]
[2020-05-12 10:01:17.582]  Step 158291  [3.992 sec/step, loss=0.09458, avg_loss=0.08725, mel_loss=0.04168, linear_loss=0.05289]
[2020-05-12 10:01:20.194]  Step 158292  [3.977 sec/step, loss=0.08911, avg_loss=0.08720, mel_loss=0.03905, linear_loss=0.05006]
[2020-05-12 10:01:23.919]  Step 158293  [3.969 sec/step, loss=0.09582, avg_loss=0.08720, mel_loss=0.04264, linear_loss=0.05318]
[2020-05-12 10:01:38.474]  Step 158294  [4.080 sec/step, loss=0.07561, avg_loss=0.08703, mel_loss=0.03547, linear_loss=0.04015]
[2020-05-12 10:01:39.898]  Step 158295  [4.065 sec/step, loss=0.08406, avg_loss=0.08695, mel_loss=0.03622, linear_loss=0.04784]
[2020-05-12 10:01:48.811]  Step 158296  [4.140 sec/step, loss=0.09586, avg_loss=0.08708, mel_loss=0.04393, linear_loss=0.05193]
[2020-05-12 10:01:53.653]  Step 158297  [4.180 sec/step, loss=0.09357, avg_loss=0.08732, mel_loss=0.04157, linear_loss=0.05199]
[2020-05-12 10:01:57.896]  Step 158298  [4.189 sec/step, loss=0.09325, avg_loss=0.08732, mel_loss=0.04135, linear_loss=0.05190]
[2020-05-12 10:02:03.459]  Step 158299  [4.227 sec/step, loss=0.09541, avg_loss=0.08739, mel_loss=0.04325, linear_loss=0.05216]
[2020-05-12 10:02:05.877]  Step 158300  [4.246 sec/step, loss=0.08813, avg_loss=0.08759, mel_loss=0.03837, linear_loss=0.04976]
[2020-05-12 10:02:05.877]  Writing summary at step: 158300
[2020-05-12 10:02:09.666]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158300
[2020-05-12 10:02:12.872]  Generated 32 batches of size 32 in 19.214 sec
[2020-05-12 10:02:13.192]  Saving audio and alignment...
[2020-05-12 10:02:23.464]  Input: 자 우리 인류가 부분을 아주 상큼하게 상승조 처리 주시고 이게 어렵다면 고개를 함께 들어서~_______________________________________
[2020-05-12 10:02:24.568]  Step 158301  [4.220 sec/step, loss=0.07549, avg_loss=0.08739, mel_loss=0.03225, linear_loss=0.04324]
[2020-05-12 10:02:26.215]  Step 158302  [4.199 sec/step, loss=0.08392, avg_loss=0.08729, mel_loss=0.03626, linear_loss=0.04766]
[2020-05-12 10:02:29.411]  Step 158303  [4.215 sec/step, loss=0.09514, avg_loss=0.08736, mel_loss=0.04195, linear_loss=0.05320]
[2020-05-12 10:02:32.929]  Step 158304  [4.226 sec/step, loss=0.09395, avg_loss=0.08739, mel_loss=0.04145, linear_loss=0.05249]
[2020-05-12 10:02:34.433]  Step 158305  [4.119 sec/step, loss=0.08784, avg_loss=0.08741, mel_loss=0.03796, linear_loss=0.04988]
[2020-05-12 10:02:38.093]  Step 158306  [4.144 sec/step, loss=0.09372, avg_loss=0.08752, mel_loss=0.04173, linear_loss=0.05200]
[2020-05-12 10:02:40.806]  Step 158307  [4.155 sec/step, loss=0.08813, avg_loss=0.08755, mel_loss=0.03842, linear_loss=0.04972]
[2020-05-12 10:02:48.427]  Step 158308  [4.176 sec/step, loss=0.09597, avg_loss=0.08756, mel_loss=0.04364, linear_loss=0.05233]
[2020-05-12 10:02:56.914]  Step 158309  [4.251 sec/step, loss=0.09027, avg_loss=0.08767, mel_loss=0.04139, linear_loss=0.04888]
[2020-05-12 10:03:01.829]  Step 158310  [4.251 sec/step, loss=0.09594, avg_loss=0.08769, mel_loss=0.04302, linear_loss=0.05292]
[2020-05-12 10:03:03.150]  Step 158311  [4.246 sec/step, loss=0.08424, avg_loss=0.08764, mel_loss=0.03642, linear_loss=0.04782]
[2020-05-12 10:03:04.492]  Step 158312  [4.187 sec/step, loss=0.08485, avg_loss=0.08753, mel_loss=0.03653, linear_loss=0.04832]
[2020-05-12 10:03:08.263]  Step 158313  [4.215 sec/step, loss=0.09310, avg_loss=0.08765, mel_loss=0.04118, linear_loss=0.05192]
[2020-05-12 10:03:10.181]  Step 158314  [4.220 sec/step, loss=0.08965, avg_loss=0.08770, mel_loss=0.03878, linear_loss=0.05087]
[2020-05-12 10:03:13.438]  Step 158315  [4.225 sec/step, loss=0.09340, avg_loss=0.08774, mel_loss=0.04133, linear_loss=0.05207]
[2020-05-12 10:03:14.043]  Step 158316  [4.214 sec/step, loss=0.07002, avg_loss=0.08759, mel_loss=0.03073, linear_loss=0.03929]
[2020-05-12 10:03:16.200]  Step 158317  [4.180 sec/step, loss=0.08763, avg_loss=0.08751, mel_loss=0.03817, linear_loss=0.04946]
[2020-05-12 10:03:28.791]  Step 158318  [4.253 sec/step, loss=0.08438, avg_loss=0.08741, mel_loss=0.03943, linear_loss=0.04495]
[2020-05-12 10:03:29.664]  Step 158319  [4.231 sec/step, loss=0.07891, avg_loss=0.08727, mel_loss=0.03334, linear_loss=0.04556]
[2020-05-12 10:03:35.747]  Step 158320  [4.256 sec/step, loss=0.09302, avg_loss=0.08725, mel_loss=0.04224, linear_loss=0.05078]
[2020-05-12 10:03:39.088]  Step 158321  [4.269 sec/step, loss=0.09294, avg_loss=0.08732, mel_loss=0.04133, linear_loss=0.05161]
[2020-05-12 10:03:41.291]  Step 158322  [4.246 sec/step, loss=0.08889, avg_loss=0.08726, mel_loss=0.03911, linear_loss=0.04978]
[2020-05-12 10:03:42.101]  Step 158323  [4.234 sec/step, loss=0.07338, avg_loss=0.08711, mel_loss=0.03099, linear_loss=0.04239]
[2020-05-12 10:03:46.697]  Step 158324  [4.273 sec/step, loss=0.09483, avg_loss=0.08733, mel_loss=0.04249, linear_loss=0.05233]
[2020-05-12 10:03:49.746]  Step 158325  [4.277 sec/step, loss=0.09092, avg_loss=0.08736, mel_loss=0.03998, linear_loss=0.05094]
[2020-05-12 10:03:51.555]  Step 158326  [4.278 sec/step, loss=0.08696, avg_loss=0.08737, mel_loss=0.03759, linear_loss=0.04938]
[2020-05-12 10:03:53.277]  Step 158327  [4.287 sec/step, loss=0.08914, avg_loss=0.08751, mel_loss=0.03832, linear_loss=0.05083]
[2020-05-12 10:03:54.429]  Step 158328  [4.281 sec/step, loss=0.07853, avg_loss=0.08742, mel_loss=0.03363, linear_loss=0.04491]
[2020-05-12 10:03:55.037]  Generated 32 batches of size 32 in 1.752 sec
[2020-05-12 10:03:57.254]  Step 158329  [4.295 sec/step, loss=0.09003, avg_loss=0.08747, mel_loss=0.03961, linear_loss=0.05041]
[2020-05-12 10:03:58.132]  Step 158330  [4.270 sec/step, loss=0.07058, avg_loss=0.08726, mel_loss=0.03016, linear_loss=0.04042]
[2020-05-12 10:03:59.743]  Step 158331  [4.275 sec/step, loss=0.08680, avg_loss=0.08730, mel_loss=0.03773, linear_loss=0.04907]
[2020-05-12 10:04:00.920]  Step 158332  [4.256 sec/step, loss=0.08060, avg_loss=0.08716, mel_loss=0.03431, linear_loss=0.04629]
[2020-05-12 10:04:03.304]  Step 158333  [4.268 sec/step, loss=0.08901, avg_loss=0.08723, mel_loss=0.03891, linear_loss=0.05011]
[2020-05-12 10:04:08.802]  Step 158334  [4.279 sec/step, loss=0.09597, avg_loss=0.08724, mel_loss=0.04316, linear_loss=0.05281]
[2020-05-12 10:04:13.166]  Step 158335  [4.181 sec/step, loss=0.09283, avg_loss=0.08741, mel_loss=0.04139, linear_loss=0.05144]
[2020-05-12 10:04:14.127]  Step 158336  [4.167 sec/step, loss=0.08179, avg_loss=0.08736, mel_loss=0.03498, linear_loss=0.04681]
[2020-05-12 10:04:14.995]  Step 158337  [4.140 sec/step, loss=0.07946, avg_loss=0.08724, mel_loss=0.03347, linear_loss=0.04599]
[2020-05-12 10:04:15.977]  Step 158338  [4.110 sec/step, loss=0.07999, avg_loss=0.08711, mel_loss=0.03430, linear_loss=0.04569]
[2020-05-12 10:04:25.079]  Step 158339  [4.196 sec/step, loss=0.09175, avg_loss=0.08729, mel_loss=0.04202, linear_loss=0.04973]
[2020-05-12 10:04:26.711]  Step 158340  [4.124 sec/step, loss=0.08600, avg_loss=0.08720, mel_loss=0.03728, linear_loss=0.04872]
[2020-05-12 10:04:27.475]  Step 158341  [4.106 sec/step, loss=0.07848, avg_loss=0.08709, mel_loss=0.03307, linear_loss=0.04542]
[2020-05-12 10:04:29.499]  Step 158342  [4.116 sec/step, loss=0.08651, avg_loss=0.08718, mel_loss=0.03764, linear_loss=0.04888]
[2020-05-12 10:04:30.342]  Step 158343  [4.060 sec/step, loss=0.07609, avg_loss=0.08700, mel_loss=0.03225, linear_loss=0.04384]
[2020-05-12 10:04:32.958]  Step 158344  [4.015 sec/step, loss=0.08861, avg_loss=0.08693, mel_loss=0.03907, linear_loss=0.04954]
[2020-05-12 10:04:34.995]  Step 158345  [3.242 sec/step, loss=0.08858, avg_loss=0.08694, mel_loss=0.03860, linear_loss=0.04998]
[2020-05-12 10:04:37.360]  Step 158346  [3.246 sec/step, loss=0.08942, avg_loss=0.08697, mel_loss=0.03912, linear_loss=0.05030]
[2020-05-12 10:04:41.410]  Step 158347  [3.272 sec/step, loss=0.09428, avg_loss=0.08706, mel_loss=0.04186, linear_loss=0.05242]
[2020-05-12 10:04:42.460]  Step 158348  [3.230 sec/step, loss=0.08188, avg_loss=0.08694, mel_loss=0.03484, linear_loss=0.04704]
[2020-05-12 10:04:45.366]  Step 158349  [3.241 sec/step, loss=0.09123, avg_loss=0.08698, mel_loss=0.04026, linear_loss=0.05097]
[2020-05-12 10:04:49.474]  Step 158350  [3.272 sec/step, loss=0.09514, avg_loss=0.08715, mel_loss=0.04247, linear_loss=0.05268]
[2020-05-12 10:04:49.474]  Writing summary at step: 158350
[2020-05-12 10:04:51.922]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158350
[2020-05-12 10:04:53.504]  Saving audio and alignment...
[2020-05-12 10:05:02.300]  Input: 브이오케이 모이 방송제 이렇게 띄웠고 또한 어조가 다양해요~______________________________________________________
[2020-05-12 10:05:07.582]  Step 158351  [3.282 sec/step, loss=0.09420, avg_loss=0.08715, mel_loss=0.04241, linear_loss=0.05179]
[2020-05-12 10:05:08.961]  Step 158352  [3.207 sec/step, loss=0.08325, avg_loss=0.08704, mel_loss=0.03580, linear_loss=0.04745]
[2020-05-12 10:05:10.527]  Step 158353  [3.091 sec/step, loss=0.08453, avg_loss=0.08707, mel_loss=0.03652, linear_loss=0.04800]
[2020-05-12 10:05:13.898]  Step 158354  [3.118 sec/step, loss=0.09383, avg_loss=0.08726, mel_loss=0.04151, linear_loss=0.05232]
[2020-05-12 10:05:15.017]  Step 158355  [3.061 sec/step, loss=0.08214, avg_loss=0.08714, mel_loss=0.03487, linear_loss=0.04726]
[2020-05-12 10:05:16.318]  Step 158356  [3.057 sec/step, loss=0.08467, avg_loss=0.08712, mel_loss=0.03642, linear_loss=0.04825]
[2020-05-12 10:05:18.167]  Step 158357  [3.022 sec/step, loss=0.08593, avg_loss=0.08702, mel_loss=0.03711, linear_loss=0.04882]
[2020-05-12 10:05:19.902]  Generated 32 batches of size 32 in 1.729 sec
[2020-05-12 10:05:21.710]  Step 158358  [2.981 sec/step, loss=0.09164, avg_loss=0.08698, mel_loss=0.04054, linear_loss=0.05110]
[2020-05-12 10:05:23.441]  Step 158359  [2.971 sec/step, loss=0.08660, avg_loss=0.08693, mel_loss=0.03720, linear_loss=0.04940]
[2020-05-12 10:05:26.591]  Step 158360  [2.955 sec/step, loss=0.09339, avg_loss=0.08691, mel_loss=0.04149, linear_loss=0.05189]
[2020-05-12 10:05:30.206]  Step 158361  [2.950 sec/step, loss=0.09452, avg_loss=0.08691, mel_loss=0.04202, linear_loss=0.05249]
[2020-05-12 10:05:30.764]  Step 158362  [2.926 sec/step, loss=0.06925, avg_loss=0.08669, mel_loss=0.03028, linear_loss=0.03897]
[2020-05-12 10:05:45.286]  Step 158363  [3.061 sec/step, loss=0.07514, avg_loss=0.08664, mel_loss=0.03515, linear_loss=0.03999]
[2020-05-12 10:05:49.967]  Step 158364  [3.100 sec/step, loss=0.09513, avg_loss=0.08690, mel_loss=0.04261, linear_loss=0.05252]
[2020-05-12 10:05:57.430]  Step 158365  [3.143 sec/step, loss=0.09505, avg_loss=0.08692, mel_loss=0.04337, linear_loss=0.05168]
[2020-05-12 10:06:03.107]  Step 158366  [3.187 sec/step, loss=0.09575, avg_loss=0.08704, mel_loss=0.04336, linear_loss=0.05238]
[2020-05-12 10:06:04.943]  Step 158367  [3.171 sec/step, loss=0.08608, avg_loss=0.08696, mel_loss=0.03729, linear_loss=0.04879]
[2020-05-12 10:06:08.350]  Step 158368  [3.182 sec/step, loss=0.09248, avg_loss=0.08699, mel_loss=0.04094, linear_loss=0.05154]
[2020-05-12 10:06:09.781]  Step 158369  [3.161 sec/step, loss=0.08477, avg_loss=0.08691, mel_loss=0.03666, linear_loss=0.04810]
[2020-05-12 10:06:12.241]  Step 158370  [3.164 sec/step, loss=0.08898, avg_loss=0.08693, mel_loss=0.03891, linear_loss=0.05007]
[2020-05-12 10:06:14.003]  Step 158371  [3.174 sec/step, loss=0.08604, avg_loss=0.08703, mel_loss=0.03747, linear_loss=0.04857]
[2020-05-12 10:06:15.391]  Step 158372  [3.178 sec/step, loss=0.08176, avg_loss=0.08708, mel_loss=0.03523, linear_loss=0.04654]
[2020-05-12 10:06:17.569]  Step 158373  [3.178 sec/step, loss=0.08951, avg_loss=0.08708, mel_loss=0.03901, linear_loss=0.05050]
[2020-05-12 10:06:18.610]  Step 158374  [3.175 sec/step, loss=0.07715, avg_loss=0.08699, mel_loss=0.03268, linear_loss=0.04447]
[2020-05-12 10:06:22.127]  Step 158375  [3.126 sec/step, loss=0.09365, avg_loss=0.08704, mel_loss=0.04167, linear_loss=0.05199]
[2020-05-12 10:06:22.967]  Step 158376  [3.124 sec/step, loss=0.07385, avg_loss=0.08695, mel_loss=0.03165, linear_loss=0.04220]
[2020-05-12 10:06:25.817]  Step 158377  [3.117 sec/step, loss=0.09199, avg_loss=0.08697, mel_loss=0.04048, linear_loss=0.05151]
[2020-05-12 10:06:28.551]  Step 158378  [3.136 sec/step, loss=0.09013, avg_loss=0.08714, mel_loss=0.03959, linear_loss=0.05054]
[2020-05-12 10:06:30.220]  Step 158379  [3.134 sec/step, loss=0.08500, avg_loss=0.08713, mel_loss=0.03686, linear_loss=0.04814]
[2020-05-12 10:06:32.582]  Step 158380  [3.089 sec/step, loss=0.09056, avg_loss=0.08707, mel_loss=0.03943, linear_loss=0.05113]
[2020-05-12 10:06:39.265]  Step 158381  [3.142 sec/step, loss=0.09441, avg_loss=0.08720, mel_loss=0.04254, linear_loss=0.05187]
[2020-05-12 10:06:39.832]  Step 158382  [3.142 sec/step, loss=0.06836, avg_loss=0.08722, mel_loss=0.02942, linear_loss=0.03894]
[2020-05-12 10:06:52.874]  Step 158383  [3.214 sec/step, loss=0.07949, avg_loss=0.08707, mel_loss=0.03707, linear_loss=0.04243]
[2020-05-12 10:06:56.978]  Step 158384  [3.238 sec/step, loss=0.09311, avg_loss=0.08715, mel_loss=0.04135, linear_loss=0.05177]
[2020-05-12 10:06:58.997]  Step 158385  [3.252 sec/step, loss=0.09024, avg_loss=0.08732, mel_loss=0.03926, linear_loss=0.05098]
[2020-05-12 10:07:02.219]  Step 158386  [3.271 sec/step, loss=0.09423, avg_loss=0.08744, mel_loss=0.04145, linear_loss=0.05278]
[2020-05-12 10:07:07.800]  Step 158387  [3.317 sec/step, loss=0.09533, avg_loss=0.08761, mel_loss=0.04306, linear_loss=0.05226]
[2020-05-12 10:07:15.292]  Step 158388  [3.365 sec/step, loss=0.09713, avg_loss=0.08768, mel_loss=0.04409, linear_loss=0.05304]
[2020-05-12 10:07:16.633]  Step 158389  [3.358 sec/step, loss=0.08110, avg_loss=0.08761, mel_loss=0.03495, linear_loss=0.04615]
[2020-05-12 10:07:17.796]  Step 158390  [3.327 sec/step, loss=0.07886, avg_loss=0.08745, mel_loss=0.03337, linear_loss=0.04549]
[2020-05-12 10:07:22.761]  Step 158391  [3.347 sec/step, loss=0.09476, avg_loss=0.08745, mel_loss=0.04261, linear_loss=0.05215]
[2020-05-12 10:07:27.143]  Step 158392  [3.365 sec/step, loss=0.09330, avg_loss=0.08749, mel_loss=0.04165, linear_loss=0.05165]
[2020-05-12 10:07:31.828]  Step 158393  [3.375 sec/step, loss=0.09608, avg_loss=0.08749, mel_loss=0.04286, linear_loss=0.05322]
[2020-05-12 10:07:32.916]  Step 158394  [3.240 sec/step, loss=0.07877, avg_loss=0.08753, mel_loss=0.03364, linear_loss=0.04513]
[2020-05-12 10:07:41.880]  Step 158395  [3.315 sec/step, loss=0.09362, avg_loss=0.08762, mel_loss=0.04280, linear_loss=0.05082]
[2020-05-12 10:07:45.095]  Step 158396  [3.258 sec/step, loss=0.09355, avg_loss=0.08760, mel_loss=0.04105, linear_loss=0.05249]
[2020-05-12 10:07:45.960]  Step 158397  [3.219 sec/step, loss=0.06985, avg_loss=0.08736, mel_loss=0.02981, linear_loss=0.04004]
[2020-05-12 10:07:48.057]  Step 158398  [3.197 sec/step, loss=0.08809, avg_loss=0.08731, mel_loss=0.03857, linear_loss=0.04952]
[2020-05-12 10:08:51.203]  Generated 32 batches of size 32 in 94.565 sec
[2020-05-12 10:08:53.525]  Step 158399  [3.796 sec/step, loss=0.08969, avg_loss=0.08725, mel_loss=0.03951, linear_loss=0.05018]
[2020-05-12 10:08:56.450]  Step 158400  [3.801 sec/step, loss=0.09205, avg_loss=0.08729, mel_loss=0.04075, linear_loss=0.05130]
[2020-05-12 10:08:56.451]  Writing summary at step: 158400
[2020-05-12 10:08:57.244]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158400
[2020-05-12 10:08:58.805]  Saving audio and alignment...
[2020-05-12 10:09:00.182]  Input: 할 수~_______
[2020-05-12 10:09:14.352]  Step 158401  [3.932 sec/step, loss=0.07462, avg_loss=0.08728, mel_loss=0.03504, linear_loss=0.03958]
[2020-05-12 10:09:17.872]  Step 158402  [3.951 sec/step, loss=0.09151, avg_loss=0.08736, mel_loss=0.04058, linear_loss=0.05093]
[2020-05-12 10:09:19.629]  Step 158403  [3.936 sec/step, loss=0.08748, avg_loss=0.08728, mel_loss=0.03763, linear_loss=0.04985]
[2020-05-12 10:09:22.285]  Step 158404  [3.928 sec/step, loss=0.09026, avg_loss=0.08725, mel_loss=0.03972, linear_loss=0.05055]
[2020-05-12 10:09:23.573]  Step 158405  [3.926 sec/step, loss=0.08321, avg_loss=0.08720, mel_loss=0.03572, linear_loss=0.04748]
[2020-05-12 10:09:24.198]  Step 158406  [3.895 sec/step, loss=0.07306, avg_loss=0.08699, mel_loss=0.03184, linear_loss=0.04122]
[2020-05-12 10:09:32.718]  Step 158407  [3.953 sec/step, loss=0.09306, avg_loss=0.08704, mel_loss=0.04264, linear_loss=0.05041]
[2020-05-12 10:09:33.704]  Step 158408  [3.887 sec/step, loss=0.08084, avg_loss=0.08689, mel_loss=0.03455, linear_loss=0.04629]
[2020-05-12 10:09:34.564]  Step 158409  [3.811 sec/step, loss=0.07668, avg_loss=0.08675, mel_loss=0.03194, linear_loss=0.04474]
[2020-05-12 10:09:36.603]  Step 158410  [3.782 sec/step, loss=0.08697, avg_loss=0.08667, mel_loss=0.03774, linear_loss=0.04922]
[2020-05-12 10:09:44.083]  Step 158411  [3.844 sec/step, loss=0.09730, avg_loss=0.08680, mel_loss=0.04438, linear_loss=0.05293]
[2020-05-12 10:09:47.130]  Step 158412  [3.861 sec/step, loss=0.09277, avg_loss=0.08687, mel_loss=0.04116, linear_loss=0.05161]
[2020-05-12 10:09:51.519]  Step 158413  [3.867 sec/step, loss=0.09337, avg_loss=0.08688, mel_loss=0.04178, linear_loss=0.05159]
[2020-05-12 10:09:52.994]  Step 158414  [3.862 sec/step, loss=0.08277, avg_loss=0.08681, mel_loss=0.03560, linear_loss=0.04717]
[2020-05-12 10:09:57.720]  Step 158415  [3.877 sec/step, loss=0.09413, avg_loss=0.08682, mel_loss=0.04213, linear_loss=0.05200]
[2020-05-12 10:09:59.895]  Step 158416  [3.893 sec/step, loss=0.08940, avg_loss=0.08701, mel_loss=0.03919, linear_loss=0.05021]
[2020-05-12 10:10:04.060]  Step 158417  [3.913 sec/step, loss=0.09312, avg_loss=0.08706, mel_loss=0.04129, linear_loss=0.05183]
[2020-05-12 10:10:10.802]  Step 158418  [3.854 sec/step, loss=0.09577, avg_loss=0.08718, mel_loss=0.04356, linear_loss=0.05221]
[2020-05-12 10:10:14.513]  Step 158419  [3.883 sec/step, loss=0.09446, avg_loss=0.08733, mel_loss=0.04193, linear_loss=0.05253]
[2020-05-12 10:10:15.748]  Step 158420  [3.834 sec/step, loss=0.08044, avg_loss=0.08721, mel_loss=0.03432, linear_loss=0.04612]
[2020-05-12 10:10:19.189]  Step 158421  [3.835 sec/step, loss=0.09231, avg_loss=0.08720, mel_loss=0.04092, linear_loss=0.05139]
[2020-05-12 10:10:21.108]  Step 158422  [3.832 sec/step, loss=0.08788, avg_loss=0.08719, mel_loss=0.03804, linear_loss=0.04984]
[2020-05-12 10:10:22.727]  Step 158423  [3.840 sec/step, loss=0.08733, avg_loss=0.08733, mel_loss=0.03791, linear_loss=0.04942]
[2020-05-12 10:10:24.221]  Step 158424  [3.809 sec/step, loss=0.08294, avg_loss=0.08721, mel_loss=0.03575, linear_loss=0.04719]
[2020-05-12 10:10:29.478]  Step 158425  [3.832 sec/step, loss=0.09339, avg_loss=0.08724, mel_loss=0.04183, linear_loss=0.05157]
[2020-05-12 10:10:32.044]  Step 158426  [3.839 sec/step, loss=0.08852, avg_loss=0.08725, mel_loss=0.03830, linear_loss=0.05022]
[2020-05-12 10:10:33.131]  Step 158427  [3.833 sec/step, loss=0.08391, avg_loss=0.08720, mel_loss=0.03570, linear_loss=0.04821]
[2020-05-12 10:10:38.852]  Step 158428  [3.878 sec/step, loss=0.09610, avg_loss=0.08738, mel_loss=0.04340, linear_loss=0.05270]
[2020-05-12 10:11:04.236]  Generated 32 batches of size 32 in 49.717 sec
[2020-05-12 10:11:06.311]  Step 158429  [4.125 sec/step, loss=0.08824, avg_loss=0.08736, mel_loss=0.03832, linear_loss=0.04992]
[2020-05-12 10:11:07.295]  Step 158430  [4.126 sec/step, loss=0.08148, avg_loss=0.08747, mel_loss=0.03478, linear_loss=0.04670]
[2020-05-12 10:11:08.299]  Step 158431  [4.120 sec/step, loss=0.07597, avg_loss=0.08736, mel_loss=0.03244, linear_loss=0.04353]
[2020-05-12 10:11:09.773]  Step 158432  [4.123 sec/step, loss=0.08360, avg_loss=0.08739, mel_loss=0.03583, linear_loss=0.04777]
[2020-05-12 10:11:14.134]  Step 158433  [4.142 sec/step, loss=0.09421, avg_loss=0.08744, mel_loss=0.04186, linear_loss=0.05235]
[2020-05-12 10:11:22.770]  Step 158434  [4.174 sec/step, loss=0.09500, avg_loss=0.08743, mel_loss=0.04353, linear_loss=0.05147]
[2020-05-12 10:11:25.652]  Step 158435  [4.159 sec/step, loss=0.09096, avg_loss=0.08741, mel_loss=0.04000, linear_loss=0.05095]
[2020-05-12 10:11:27.460]  Step 158436  [4.168 sec/step, loss=0.08443, avg_loss=0.08744, mel_loss=0.03651, linear_loss=0.04792]
[2020-05-12 10:11:32.575]  Step 158437  [4.210 sec/step, loss=0.09528, avg_loss=0.08760, mel_loss=0.04281, linear_loss=0.05247]
[2020-05-12 10:11:38.683]  Step 158438  [4.261 sec/step, loss=0.09429, avg_loss=0.08774, mel_loss=0.04269, linear_loss=0.05160]
[2020-05-12 10:11:41.020]  Step 158439  [4.194 sec/step, loss=0.08940, avg_loss=0.08772, mel_loss=0.03949, linear_loss=0.04991]
[2020-05-12 10:11:48.210]  Step 158440  [4.249 sec/step, loss=0.09595, avg_loss=0.08782, mel_loss=0.04364, linear_loss=0.05231]
[2020-05-12 10:11:52.852]  Step 158441  [4.288 sec/step, loss=0.09388, avg_loss=0.08797, mel_loss=0.04164, linear_loss=0.05224]
[2020-05-12 10:11:56.281]  Step 158442  [4.302 sec/step, loss=0.09286, avg_loss=0.08803, mel_loss=0.04127, linear_loss=0.05159]
[2020-05-12 10:11:57.037]  Step 158443  [4.301 sec/step, loss=0.06964, avg_loss=0.08797, mel_loss=0.03067, linear_loss=0.03897]
[2020-05-12 10:12:02.445]  Step 158444  [4.329 sec/step, loss=0.09415, avg_loss=0.08802, mel_loss=0.04219, linear_loss=0.05196]
[2020-05-12 10:12:04.173]  Step 158445  [4.326 sec/step, loss=0.08816, avg_loss=0.08802, mel_loss=0.03791, linear_loss=0.05025]
[2020-05-12 10:12:18.270]  Step 158446  [4.443 sec/step, loss=0.08148, avg_loss=0.08794, mel_loss=0.03807, linear_loss=0.04341]
[2020-05-12 10:12:23.835]  Step 158447  [4.458 sec/step, loss=0.09397, avg_loss=0.08794, mel_loss=0.04168, linear_loss=0.05229]
[2020-05-12 10:12:25.174]  Step 158448  [4.461 sec/step, loss=0.08017, avg_loss=0.08792, mel_loss=0.03397, linear_loss=0.04620]
[2020-05-12 10:12:27.852]  Step 158449  [4.459 sec/step, loss=0.09067, avg_loss=0.08792, mel_loss=0.03979, linear_loss=0.05087]
[2020-05-12 10:12:29.009]  Step 158450  [4.430 sec/step, loss=0.08302, avg_loss=0.08779, mel_loss=0.03574, linear_loss=0.04728]
[2020-05-12 10:12:29.009]  Writing summary at step: 158450
[2020-05-12 10:12:29.772]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158450
[2020-05-12 10:12:31.357]  Saving audio and alignment...
[2020-05-12 10:12:35.697]  Input: 시이작 이라고 느려 쓰시고~_______________________________
[2020-05-12 10:12:39.631]  Step 158451  [4.416 sec/step, loss=0.09394, avg_loss=0.08779, mel_loss=0.04180, linear_loss=0.05214]
[2020-05-12 10:12:41.192]  Step 158452  [4.418 sec/step, loss=0.08864, avg_loss=0.08785, mel_loss=0.03823, linear_loss=0.05041]
[2020-05-12 10:12:42.027]  Step 158453  [4.411 sec/step, loss=0.07558, avg_loss=0.08776, mel_loss=0.03227, linear_loss=0.04331]
[2020-05-12 10:12:43.345]  Step 158454  [4.390 sec/step, loss=0.08304, avg_loss=0.08765, mel_loss=0.03565, linear_loss=0.04739]
[2020-05-12 10:12:46.733]  Step 158455  [4.413 sec/step, loss=0.09467, avg_loss=0.08777, mel_loss=0.04184, linear_loss=0.05284]
[2020-05-12 10:12:48.644]  Step 158456  [4.419 sec/step, loss=0.08809, avg_loss=0.08781, mel_loss=0.03807, linear_loss=0.05002]
[2020-05-12 10:12:51.865]  Step 158457  [4.433 sec/step, loss=0.09273, avg_loss=0.08788, mel_loss=0.04088, linear_loss=0.05186]
[2020-05-12 10:12:54.128]  Step 158458  [4.420 sec/step, loss=0.08827, avg_loss=0.08784, mel_loss=0.03843, linear_loss=0.04985]
[2020-05-12 10:12:55.253]  Generated 32 batches of size 32 in 23.281 sec
[2020-05-12 10:12:57.481]  Step 158459  [4.436 sec/step, loss=0.08829, avg_loss=0.08786, mel_loss=0.03844, linear_loss=0.04984]
[2020-05-12 10:13:06.472]  Step 158460  [4.494 sec/step, loss=0.09503, avg_loss=0.08788, mel_loss=0.04358, linear_loss=0.05145]
[2020-05-12 10:13:10.976]  Step 158461  [4.503 sec/step, loss=0.09502, avg_loss=0.08788, mel_loss=0.04256, linear_loss=0.05246]
[2020-05-12 10:13:12.539]  Step 158462  [4.513 sec/step, loss=0.08605, avg_loss=0.08805, mel_loss=0.03677, linear_loss=0.04928]
[2020-05-12 10:13:14.285]  Step 158463  [4.386 sec/step, loss=0.08641, avg_loss=0.08816, mel_loss=0.03772, linear_loss=0.04870]
[2020-05-12 10:13:21.901]  Step 158464  [4.415 sec/step, loss=0.09517, avg_loss=0.08816, mel_loss=0.04342, linear_loss=0.05175]
[2020-05-12 10:13:25.562]  Step 158465  [4.377 sec/step, loss=0.09592, avg_loss=0.08817, mel_loss=0.04271, linear_loss=0.05322]
[2020-05-12 10:13:31.260]  Step 158466  [4.377 sec/step, loss=0.09525, avg_loss=0.08817, mel_loss=0.04311, linear_loss=0.05214]
[2020-05-12 10:13:32.491]  Step 158467  [4.371 sec/step, loss=0.08312, avg_loss=0.08814, mel_loss=0.03584, linear_loss=0.04728]
[2020-05-12 10:13:33.597]  Step 158468  [4.348 sec/step, loss=0.08121, avg_loss=0.08802, mel_loss=0.03429, linear_loss=0.04692]
[2020-05-12 10:13:36.925]  Step 158469  [4.367 sec/step, loss=0.09310, avg_loss=0.08811, mel_loss=0.04152, linear_loss=0.05158]
[2020-05-12 10:13:38.658]  Step 158470  [4.360 sec/step, loss=0.08683, avg_loss=0.08808, mel_loss=0.03769, linear_loss=0.04914]
[2020-05-12 10:13:39.639]  Step 158471  [4.352 sec/step, loss=0.08002, avg_loss=0.08802, mel_loss=0.03392, linear_loss=0.04610]
[2020-05-12 10:13:41.084]  Step 158472  [4.352 sec/step, loss=0.08166, avg_loss=0.08802, mel_loss=0.03489, linear_loss=0.04677]
[2020-05-12 10:13:44.800]  Step 158473  [4.368 sec/step, loss=0.09154, avg_loss=0.08804, mel_loss=0.04044, linear_loss=0.05110]
[2020-05-12 10:13:47.508]  Step 158474  [4.385 sec/step, loss=0.08908, avg_loss=0.08816, mel_loss=0.03906, linear_loss=0.05002]
[2020-05-12 10:13:51.577]  Step 158475  [4.390 sec/step, loss=0.09443, avg_loss=0.08817, mel_loss=0.04174, linear_loss=0.05269]
[2020-05-12 10:13:52.799]  Step 158476  [4.394 sec/step, loss=0.08079, avg_loss=0.08824, mel_loss=0.03438, linear_loss=0.04641]
[2020-05-12 10:13:56.646]  Step 158477  [4.404 sec/step, loss=0.09138, avg_loss=0.08823, mel_loss=0.04026, linear_loss=0.05112]
[2020-05-12 10:13:57.204]  Step 158478  [4.382 sec/step, loss=0.06804, avg_loss=0.08801, mel_loss=0.02937, linear_loss=0.03867]
[2020-05-12 10:13:59.655]  Step 158479  [4.390 sec/step, loss=0.08856, avg_loss=0.08805, mel_loss=0.03848, linear_loss=0.05007]
[2020-05-12 10:14:06.071]  Step 158480  [4.430 sec/step, loss=0.09478, avg_loss=0.08809, mel_loss=0.04291, linear_loss=0.05187]
[2020-05-12 10:14:06.822]  Step 158481  [4.371 sec/step, loss=0.07231, avg_loss=0.08787, mel_loss=0.03105, linear_loss=0.04126]
[2020-05-12 10:14:08.173]  Step 158482  [4.379 sec/step, loss=0.08680, avg_loss=0.08805, mel_loss=0.03740, linear_loss=0.04940]
[2020-05-12 10:14:11.087]  Generated 32 batches of size 32 in 4.260 sec
[2020-05-12 10:14:22.587]  Step 158483  [4.393 sec/step, loss=0.07525, avg_loss=0.08801, mel_loss=0.03537, linear_loss=0.03988]
[2020-05-12 10:14:24.993]  Step 158484  [4.376 sec/step, loss=0.08860, avg_loss=0.08797, mel_loss=0.03872, linear_loss=0.04988]
[2020-05-12 10:14:25.810]  Step 158485  [4.364 sec/step, loss=0.07706, avg_loss=0.08783, mel_loss=0.03247, linear_loss=0.04459]
[2020-05-12 10:14:31.042]  Step 158486  [4.384 sec/step, loss=0.09412, avg_loss=0.08783, mel_loss=0.04235, linear_loss=0.05177]
[2020-05-12 10:14:33.071]  Step 158487  [4.348 sec/step, loss=0.08861, avg_loss=0.08777, mel_loss=0.03850, linear_loss=0.05010]
[2020-05-12 10:14:34.992]  Step 158488  [4.293 sec/step, loss=0.08612, avg_loss=0.08766, mel_loss=0.03702, linear_loss=0.04909]
[2020-05-12 10:14:39.157]  Step 158489  [4.321 sec/step, loss=0.09420, avg_loss=0.08779, mel_loss=0.04208, linear_loss=0.05212]
[2020-05-12 10:14:42.528]  Step 158490  [4.343 sec/step, loss=0.09226, avg_loss=0.08792, mel_loss=0.04075, linear_loss=0.05151]
[2020-05-12 10:14:43.489]  Step 158491  [4.303 sec/step, loss=0.07957, avg_loss=0.08777, mel_loss=0.03401, linear_loss=0.04556]
[2020-05-12 10:14:48.503]  Step 158492  [4.309 sec/step, loss=0.09492, avg_loss=0.08779, mel_loss=0.04268, linear_loss=0.05224]
[2020-05-12 10:14:57.378]  Step 158493  [4.351 sec/step, loss=0.09412, avg_loss=0.08777, mel_loss=0.04298, linear_loss=0.05114]
[2020-05-12 10:14:58.218]  Step 158494  [4.349 sec/step, loss=0.07073, avg_loss=0.08769, mel_loss=0.03060, linear_loss=0.04012]
[2020-05-12 10:15:00.383]  Step 158495  [4.281 sec/step, loss=0.08955, avg_loss=0.08765, mel_loss=0.03907, linear_loss=0.05048]
[2020-05-12 10:15:02.276]  Step 158496  [4.267 sec/step, loss=0.08584, avg_loss=0.08757, mel_loss=0.03758, linear_loss=0.04826]
[2020-05-12 10:15:06.862]  Step 158497  [4.305 sec/step, loss=0.09486, avg_loss=0.08782, mel_loss=0.04249, linear_loss=0.05236]
[2020-05-12 10:15:14.066]  Step 158498  [4.356 sec/step, loss=0.09528, avg_loss=0.08789, mel_loss=0.04330, linear_loss=0.05198]
[2020-05-12 10:15:20.813]  Step 158499  [3.768 sec/step, loss=0.09453, avg_loss=0.08794, mel_loss=0.04290, linear_loss=0.05163]
[2020-05-12 10:15:33.946]  Step 158500  [3.871 sec/step, loss=0.08164, avg_loss=0.08783, mel_loss=0.03795, linear_loss=0.04368]
[2020-05-12 10:15:33.946]  Writing summary at step: 158500
[2020-05-12 10:15:34.473]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158500
[2020-05-12 10:15:36.110]  Saving audio and alignment...
[2020-05-12 10:15:39.102]  Input: 시련을 당한 베를리오즈~___________
[2020-05-12 10:15:41.855]  Step 158501  [3.756 sec/step, loss=0.08750, avg_loss=0.08796, mel_loss=0.03839, linear_loss=0.04911]
[2020-05-12 10:15:45.496]  Step 158502  [3.758 sec/step, loss=0.09426, avg_loss=0.08799, mel_loss=0.04189, linear_loss=0.05236]
[2020-05-12 10:15:49.839]  Step 158503  [3.783 sec/step, loss=0.09469, avg_loss=0.08806, mel_loss=0.04207, linear_loss=0.05262]
[2020-05-12 10:15:50.563]  Step 158504  [3.764 sec/step, loss=0.07484, avg_loss=0.08791, mel_loss=0.03204, linear_loss=0.04280]
[2020-05-12 10:15:53.022]  Step 158505  [3.776 sec/step, loss=0.08910, avg_loss=0.08797, mel_loss=0.03894, linear_loss=0.05015]
[2020-05-12 10:15:57.086]  Step 158506  [3.810 sec/step, loss=0.09476, avg_loss=0.08818, mel_loss=0.04182, linear_loss=0.05293]
[2020-05-12 10:15:58.590]  Step 158507  [3.740 sec/step, loss=0.08585, avg_loss=0.08811, mel_loss=0.03711, linear_loss=0.04874]
[2020-05-12 10:15:59.957]  Step 158508  [3.744 sec/step, loss=0.08303, avg_loss=0.08813, mel_loss=0.03564, linear_loss=0.04739]
[2020-05-12 10:16:01.024]  Step 158509  [3.746 sec/step, loss=0.08180, avg_loss=0.08819, mel_loss=0.03493, linear_loss=0.04687]
[2020-05-12 10:16:04.176]  Step 158510  [3.757 sec/step, loss=0.09310, avg_loss=0.08825, mel_loss=0.04112, linear_loss=0.05198]
[2020-05-12 10:16:06.218]  Step 158511  [3.703 sec/step, loss=0.08744, avg_loss=0.08815, mel_loss=0.03808, linear_loss=0.04936]
[2020-05-12 10:16:07.547]  Step 158512  [3.685 sec/step, loss=0.08221, avg_loss=0.08804, mel_loss=0.03522, linear_loss=0.04699]
[2020-05-12 10:16:08.735]  Step 158513  [3.653 sec/step, loss=0.07960, avg_loss=0.08790, mel_loss=0.03408, linear_loss=0.04553]
[2020-05-12 10:16:14.424]  Step 158514  [3.696 sec/step, loss=0.09457, avg_loss=0.08802, mel_loss=0.04278, linear_loss=0.05179]
[2020-05-12 10:16:15.394]  Step 158515  [3.658 sec/step, loss=0.07754, avg_loss=0.08786, mel_loss=0.03255, linear_loss=0.04499]
[2020-05-12 10:16:18.280]  Step 158516  [3.665 sec/step, loss=0.09219, avg_loss=0.08788, mel_loss=0.04083, linear_loss=0.05135]
[2020-05-12 10:16:20.527]  Step 158517  [3.646 sec/step, loss=0.08751, avg_loss=0.08783, mel_loss=0.03833, linear_loss=0.04917]
[2020-05-12 10:16:23.938]  Step 158518  [3.613 sec/step, loss=0.09371, avg_loss=0.08781, mel_loss=0.04154, linear_loss=0.05217]
[2020-05-12 10:16:25.716]  Step 158519  [3.593 sec/step, loss=0.08731, avg_loss=0.08774, mel_loss=0.03771, linear_loss=0.04960]
[2020-05-12 10:16:29.254]  Step 158520  [3.616 sec/step, loss=0.09041, avg_loss=0.08784, mel_loss=0.03992, linear_loss=0.05048]
[2020-05-12 10:17:20.162]  Generated 32 batches of size 32 in 73.938 sec
[2020-05-12 10:17:21.307]  Step 158521  [4.102 sec/step, loss=0.08268, avg_loss=0.08774, mel_loss=0.03471, linear_loss=0.04797]
[2020-05-12 10:17:25.388]  Step 158522  [4.124 sec/step, loss=0.09273, avg_loss=0.08779, mel_loss=0.04125, linear_loss=0.05148]
[2020-05-12 10:17:27.098]  Step 158523  [4.125 sec/step, loss=0.08772, avg_loss=0.08779, mel_loss=0.03783, linear_loss=0.04989]
[2020-05-12 10:17:32.192]  Step 158524  [4.161 sec/step, loss=0.09531, avg_loss=0.08792, mel_loss=0.04284, linear_loss=0.05247]
[2020-05-12 10:17:33.653]  Step 158525  [4.123 sec/step, loss=0.08422, avg_loss=0.08782, mel_loss=0.03627, linear_loss=0.04795]
[2020-05-12 10:17:42.007]  Step 158526  [4.181 sec/step, loss=0.09308, avg_loss=0.08787, mel_loss=0.04240, linear_loss=0.05069]
[2020-05-12 10:17:44.446]  Step 158527  [4.194 sec/step, loss=0.09080, avg_loss=0.08794, mel_loss=0.03965, linear_loss=0.05115]
[2020-05-12 10:17:50.621]  Step 158528  [4.199 sec/step, loss=0.09505, avg_loss=0.08793, mel_loss=0.04300, linear_loss=0.05205]
[2020-05-12 10:17:51.672]  Step 158529  [3.935 sec/step, loss=0.07992, avg_loss=0.08784, mel_loss=0.03440, linear_loss=0.04552]
[2020-05-12 10:17:55.858]  Step 158530  [3.967 sec/step, loss=0.09514, avg_loss=0.08798, mel_loss=0.04263, linear_loss=0.05251]
[2020-05-12 10:18:03.456]  Step 158531  [4.033 sec/step, loss=0.09661, avg_loss=0.08819, mel_loss=0.04413, linear_loss=0.05248]
[2020-05-12 10:18:05.235]  Step 158532  [4.036 sec/step, loss=0.08660, avg_loss=0.08822, mel_loss=0.03711, linear_loss=0.04949]
[2020-05-12 10:18:06.207]  Step 158533  [4.002 sec/step, loss=0.07762, avg_loss=0.08805, mel_loss=0.03303, linear_loss=0.04459]
[2020-05-12 10:18:07.030]  Step 158534  [3.924 sec/step, loss=0.07276, avg_loss=0.08783, mel_loss=0.03134, linear_loss=0.04142]
[2020-05-12 10:18:10.453]  Step 158535  [3.929 sec/step, loss=0.09234, avg_loss=0.08784, mel_loss=0.04121, linear_loss=0.05113]
[2020-05-12 10:18:24.766]  Step 158536  [4.054 sec/step, loss=0.07340, avg_loss=0.08773, mel_loss=0.03448, linear_loss=0.03892]
[2020-05-12 10:18:26.148]  Step 158537  [4.017 sec/step, loss=0.08345, avg_loss=0.08761, mel_loss=0.03603, linear_loss=0.04743]
[2020-05-12 10:18:28.719]  Step 158538  [3.982 sec/step, loss=0.09069, avg_loss=0.08758, mel_loss=0.03973, linear_loss=0.05096]
[2020-05-12 10:18:29.281]  Step 158539  [3.964 sec/step, loss=0.06731, avg_loss=0.08736, mel_loss=0.02927, linear_loss=0.03804]
[2020-05-12 10:18:32.190]  Step 158540  [3.921 sec/step, loss=0.09277, avg_loss=0.08733, mel_loss=0.04099, linear_loss=0.05178]
[2020-05-12 10:18:33.812]  Step 158541  [3.891 sec/step, loss=0.08565, avg_loss=0.08724, mel_loss=0.03732, linear_loss=0.04833]
[2020-05-12 10:18:35.730]  Step 158542  [3.876 sec/step, loss=0.08792, avg_loss=0.08719, mel_loss=0.03821, linear_loss=0.04972]
[2020-05-12 10:18:37.927]  Step 158543  [3.890 sec/step, loss=0.08735, avg_loss=0.08737, mel_loss=0.03829, linear_loss=0.04906]
[2020-05-12 10:18:41.626]  Step 158544  [3.873 sec/step, loss=0.09416, avg_loss=0.08737, mel_loss=0.04191, linear_loss=0.05225]
[2020-05-12 10:18:42.469]  Step 158545  [3.864 sec/step, loss=0.07533, avg_loss=0.08724, mel_loss=0.03206, linear_loss=0.04327]
[2020-05-12 10:18:47.189]  Step 158546  [3.770 sec/step, loss=0.09607, avg_loss=0.08739, mel_loss=0.04273, linear_loss=0.05334]
[2020-05-12 10:18:53.333]  Step 158547  [3.776 sec/step, loss=0.09416, avg_loss=0.08739, mel_loss=0.04228, linear_loss=0.05187]
[2020-05-12 10:18:56.412]  Step 158548  [3.794 sec/step, loss=0.09025, avg_loss=0.08749, mel_loss=0.03947, linear_loss=0.05077]
[2020-05-12 10:18:59.698]  Step 158549  [3.800 sec/step, loss=0.09410, avg_loss=0.08753, mel_loss=0.04169, linear_loss=0.05241]
[2020-05-12 10:19:02.852]  Step 158550  [3.820 sec/step, loss=0.09239, avg_loss=0.08762, mel_loss=0.04064, linear_loss=0.05175]
[2020-05-12 10:19:02.852]  Writing summary at step: 158550
[2020-05-12 10:19:04.141]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158550
[2020-05-12 10:19:05.763]  Saving audio and alignment...
[2020-05-12 10:19:09.409]  Input: 십년전 전 이금희 아나운서의 조언을~____
[2020-05-12 10:19:09.664]  Generated 32 batches of size 32 in 31.732 sec
[2020-05-12 10:19:12.056]  Step 158551  [3.807 sec/step, loss=0.09016, avg_loss=0.08758, mel_loss=0.03939, linear_loss=0.05076]
[2020-05-12 10:19:14.913]  Step 158552  [3.820 sec/step, loss=0.09060, avg_loss=0.08760, mel_loss=0.04013, linear_loss=0.05046]
[2020-05-12 10:19:21.654]  Step 158553  [3.879 sec/step, loss=0.09374, avg_loss=0.08778, mel_loss=0.04264, linear_loss=0.05110]
[2020-05-12 10:19:25.810]  Step 158554  [3.907 sec/step, loss=0.09286, avg_loss=0.08788, mel_loss=0.04113, linear_loss=0.05173]
[2020-05-12 10:19:31.338]  Step 158555  [3.929 sec/step, loss=0.09348, avg_loss=0.08787, mel_loss=0.04198, linear_loss=0.05151]
[2020-05-12 10:19:32.440]  Step 158556  [3.921 sec/step, loss=0.07901, avg_loss=0.08778, mel_loss=0.03359, linear_loss=0.04542]
[2020-05-12 10:19:33.202]  Step 158557  [3.896 sec/step, loss=0.07363, avg_loss=0.08759, mel_loss=0.03169, linear_loss=0.04194]
[2020-05-12 10:19:34.787]  Step 158558  [3.889 sec/step, loss=0.08550, avg_loss=0.08756, mel_loss=0.03676, linear_loss=0.04874]
[2020-05-12 10:19:36.920]  Step 158559  [3.877 sec/step, loss=0.09010, avg_loss=0.08758, mel_loss=0.03931, linear_loss=0.05078]
[2020-05-12 10:19:40.604]  Step 158560  [3.824 sec/step, loss=0.09450, avg_loss=0.08757, mel_loss=0.04217, linear_loss=0.05233]
[2020-05-12 10:19:47.886]  Step 158561  [3.852 sec/step, loss=0.09582, avg_loss=0.08758, mel_loss=0.04367, linear_loss=0.05216]
[2020-05-12 10:19:48.874]  Step 158562  [3.846 sec/step, loss=0.07956, avg_loss=0.08752, mel_loss=0.03394, linear_loss=0.04562]
[2020-05-12 10:19:50.786]  Step 158563  [3.848 sec/step, loss=0.08598, avg_loss=0.08751, mel_loss=0.03703, linear_loss=0.04895]
[2020-05-12 10:19:55.192]  Step 158564  [3.816 sec/step, loss=0.09601, avg_loss=0.08752, mel_loss=0.04306, linear_loss=0.05295]
[2020-05-12 10:19:56.533]  Step 158565  [3.792 sec/step, loss=0.08213, avg_loss=0.08738, mel_loss=0.03509, linear_loss=0.04704]
[2020-05-12 10:19:57.091]  Step 158566  [3.741 sec/step, loss=0.06794, avg_loss=0.08711, mel_loss=0.02943, linear_loss=0.03851]
[2020-05-12 10:20:00.573]  Step 158567  [3.763 sec/step, loss=0.09171, avg_loss=0.08719, mel_loss=0.04052, linear_loss=0.05119]
[2020-05-12 10:20:02.322]  Step 158568  [3.770 sec/step, loss=0.08703, avg_loss=0.08725, mel_loss=0.03741, linear_loss=0.04963]
[2020-05-12 10:20:11.156]  Step 158569  [3.825 sec/step, loss=0.09464, avg_loss=0.08727, mel_loss=0.04347, linear_loss=0.05118]
[2020-05-12 10:20:13.573]  Step 158570  [3.832 sec/step, loss=0.08935, avg_loss=0.08729, mel_loss=0.03905, linear_loss=0.05030]
[2020-05-12 10:20:27.672]  Step 158571  [3.963 sec/step, loss=0.07447, avg_loss=0.08724, mel_loss=0.03501, linear_loss=0.03945]
[2020-05-12 10:20:30.393]  Step 158572  [3.976 sec/step, loss=0.08950, avg_loss=0.08732, mel_loss=0.03914, linear_loss=0.05036]
[2020-05-12 10:20:32.009]  Step 158573  [3.955 sec/step, loss=0.08683, avg_loss=0.08727, mel_loss=0.03771, linear_loss=0.04912]
[2020-05-12 10:20:32.885]  Step 158574  [3.936 sec/step, loss=0.07837, avg_loss=0.08716, mel_loss=0.03294, linear_loss=0.04543]
[2020-05-12 10:20:34.942]  Step 158575  [3.916 sec/step, loss=0.08709, avg_loss=0.08709, mel_loss=0.03779, linear_loss=0.04930]
[2020-05-12 10:20:36.350]  Step 158576  [3.918 sec/step, loss=0.08426, avg_loss=0.08712, mel_loss=0.03648, linear_loss=0.04778]
[2020-05-12 10:20:39.787]  Step 158577  [3.914 sec/step, loss=0.09236, avg_loss=0.08713, mel_loss=0.04081, linear_loss=0.05155]
[2020-05-12 10:20:44.685]  Step 158578  [3.957 sec/step, loss=0.09389, avg_loss=0.08739, mel_loss=0.04199, linear_loss=0.05190]
[2020-05-12 10:20:45.925]  Step 158579  [3.945 sec/step, loss=0.08026, avg_loss=0.08731, mel_loss=0.03433, linear_loss=0.04593]
[2020-05-12 10:20:46.699]  Step 158580  [3.889 sec/step, loss=0.07773, avg_loss=0.08714, mel_loss=0.03303, linear_loss=0.04470]
[2020-05-12 10:20:49.738]  Step 158581  [3.912 sec/step, loss=0.09206, avg_loss=0.08734, mel_loss=0.04055, linear_loss=0.05152]
[2020-05-12 10:20:52.084]  Generated 32 batches of size 32 in 20.069 sec
[2020-05-12 10:20:52.882]  Step 158582  [3.930 sec/step, loss=0.09462, avg_loss=0.08741, mel_loss=0.04178, linear_loss=0.05284]
[2020-05-12 10:20:53.692]  Step 158583  [3.794 sec/step, loss=0.07691, avg_loss=0.08743, mel_loss=0.03248, linear_loss=0.04443]
[2020-05-12 10:21:07.817]  Step 158584  [3.911 sec/step, loss=0.07457, avg_loss=0.08729, mel_loss=0.03515, linear_loss=0.03942]
[2020-05-12 10:21:11.914]  Step 158585  [3.944 sec/step, loss=0.09455, avg_loss=0.08747, mel_loss=0.04223, linear_loss=0.05232]
[2020-05-12 10:21:12.578]  Step 158586  [3.898 sec/step, loss=0.07251, avg_loss=0.08725, mel_loss=0.03094, linear_loss=0.04157]
[2020-05-12 10:21:13.922]  Step 158587  [3.891 sec/step, loss=0.08271, avg_loss=0.08719, mel_loss=0.03555, linear_loss=0.04716]
[2020-05-12 10:21:18.451]  Step 158588  [3.917 sec/step, loss=0.09470, avg_loss=0.08728, mel_loss=0.04229, linear_loss=0.05241]
[2020-05-12 10:21:19.582]  Step 158589  [3.887 sec/step, loss=0.08218, avg_loss=0.08716, mel_loss=0.03485, linear_loss=0.04733]
[2020-05-12 10:21:27.135]  Step 158590  [3.929 sec/step, loss=0.09667, avg_loss=0.08720, mel_loss=0.04402, linear_loss=0.05265]
[2020-05-12 10:21:32.934]  Step 158591  [3.977 sec/step, loss=0.09729, avg_loss=0.08738, mel_loss=0.04406, linear_loss=0.05323]
[2020-05-12 10:21:34.596]  Step 158592  [3.944 sec/step, loss=0.08709, avg_loss=0.08730, mel_loss=0.03784, linear_loss=0.04925]
[2020-05-12 10:21:38.103]  Step 158593  [3.890 sec/step, loss=0.09068, avg_loss=0.08726, mel_loss=0.04004, linear_loss=0.05064]
[2020-05-12 10:21:40.811]  Step 158594  [3.909 sec/step, loss=0.08936, avg_loss=0.08745, mel_loss=0.03903, linear_loss=0.05034]
[2020-05-12 10:21:44.449]  Step 158595  [3.923 sec/step, loss=0.09513, avg_loss=0.08751, mel_loss=0.04218, linear_loss=0.05296]
[2020-05-12 10:21:49.415]  Step 158596  [3.954 sec/step, loss=0.09327, avg_loss=0.08758, mel_loss=0.04171, linear_loss=0.05156]
[2020-05-12 10:21:52.571]  Step 158597  [3.940 sec/step, loss=0.09314, avg_loss=0.08756, mel_loss=0.04098, linear_loss=0.05217]
[2020-05-12 10:22:01.351]  Step 158598  [3.955 sec/step, loss=0.09364, avg_loss=0.08755, mel_loss=0.04294, linear_loss=0.05071]
[2020-05-12 10:22:03.778]  Step 158599  [3.912 sec/step, loss=0.08916, avg_loss=0.08749, mel_loss=0.03894, linear_loss=0.05022]
[2020-05-12 10:22:04.960]  Step 158600  [3.793 sec/step, loss=0.08309, avg_loss=0.08751, mel_loss=0.03551, linear_loss=0.04758]
[2020-05-12 10:22:04.960]  Writing summary at step: 158600
[2020-05-12 10:22:07.041]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158600
[2020-05-12 10:22:08.640]  Saving audio and alignment...
[2020-05-12 10:22:11.524]  Input: 얼마 전 우리 인류가~___________________
[2020-05-12 10:22:13.719]  Step 158601  [3.787 sec/step, loss=0.08997, avg_loss=0.08753, mel_loss=0.03935, linear_loss=0.05063]
[2020-05-12 10:22:14.746]  Step 158602  [3.761 sec/step, loss=0.08037, avg_loss=0.08739, mel_loss=0.03425, linear_loss=0.04612]
[2020-05-12 10:22:17.947]  Step 158603  [3.750 sec/step, loss=0.09459, avg_loss=0.08739, mel_loss=0.04207, linear_loss=0.05252]
[2020-05-12 10:22:22.019]  Step 158604  [3.783 sec/step, loss=0.09402, avg_loss=0.08758, mel_loss=0.04185, linear_loss=0.05217]
[2020-05-12 10:22:28.476]  Step 158605  [3.823 sec/step, loss=0.09573, avg_loss=0.08765, mel_loss=0.04324, linear_loss=0.05249]
[2020-05-12 10:22:32.994]  Step 158606  [3.828 sec/step, loss=0.08881, avg_loss=0.08759, mel_loss=0.03919, linear_loss=0.04963]
[2020-05-12 10:22:35.104]  Step 158607  [3.834 sec/step, loss=0.08762, avg_loss=0.08761, mel_loss=0.03788, linear_loss=0.04974]
[2020-05-12 10:22:36.526]  Step 158608  [3.834 sec/step, loss=0.08405, avg_loss=0.08762, mel_loss=0.03624, linear_loss=0.04781]
[2020-05-12 10:22:38.537]  Step 158609  [3.844 sec/step, loss=0.08849, avg_loss=0.08769, mel_loss=0.03851, linear_loss=0.04998]
[2020-05-12 10:22:39.296]  Step 158610  [3.820 sec/step, loss=0.06896, avg_loss=0.08745, mel_loss=0.02986, linear_loss=0.03910]
[2020-05-12 10:22:46.329]  Step 158611  [3.870 sec/step, loss=0.09583, avg_loss=0.08753, mel_loss=0.04336, linear_loss=0.05247]
[2020-05-12 10:22:47.340]  Step 158612  [3.866 sec/step, loss=0.08111, avg_loss=0.08752, mel_loss=0.03422, linear_loss=0.04689]
[2020-05-12 10:23:50.355]  Generated 32 batches of size 32 in 92.402 sec
[2020-05-12 10:23:54.968]  Step 158613  [4.531 sec/step, loss=0.09543, avg_loss=0.08768, mel_loss=0.04262, linear_loss=0.05281]
[2020-05-12 10:23:55.803]  Step 158614  [4.482 sec/step, loss=0.07391, avg_loss=0.08747, mel_loss=0.03161, linear_loss=0.04230]
[2020-05-12 10:23:58.311]  Step 158615  [4.498 sec/step, loss=0.09084, avg_loss=0.08760, mel_loss=0.03951, linear_loss=0.05133]
[2020-05-12 10:23:59.709]  Step 158616  [4.483 sec/step, loss=0.08429, avg_loss=0.08752, mel_loss=0.03619, linear_loss=0.04810]
[2020-05-12 10:24:00.855]  Step 158617  [4.472 sec/step, loss=0.08213, avg_loss=0.08747, mel_loss=0.03508, linear_loss=0.04705]
[2020-05-12 10:24:02.969]  Step 158618  [4.459 sec/step, loss=0.08584, avg_loss=0.08739, mel_loss=0.03694, linear_loss=0.04890]
[2020-05-12 10:24:06.855]  Step 158619  [4.480 sec/step, loss=0.09469, avg_loss=0.08747, mel_loss=0.04201, linear_loss=0.05268]
[2020-05-12 10:24:11.193]  Step 158620  [4.488 sec/step, loss=0.09444, avg_loss=0.08751, mel_loss=0.04197, linear_loss=0.05247]
[2020-05-12 10:24:14.038]  Step 158621  [3.996 sec/step, loss=0.09040, avg_loss=0.08758, mel_loss=0.03980, linear_loss=0.05060]
[2020-05-12 10:24:15.772]  Step 158622  [3.972 sec/step, loss=0.08801, avg_loss=0.08754, mel_loss=0.03789, linear_loss=0.05012]
[2020-05-12 10:24:18.002]  Step 158623  [3.978 sec/step, loss=0.08904, avg_loss=0.08755, mel_loss=0.03883, linear_loss=0.05021]
[2020-05-12 10:24:19.171]  Step 158624  [3.938 sec/step, loss=0.08117, avg_loss=0.08741, mel_loss=0.03466, linear_loss=0.04651]
[2020-05-12 10:24:20.116]  Step 158625  [3.933 sec/step, loss=0.07895, avg_loss=0.08735, mel_loss=0.03360, linear_loss=0.04535]
[2020-05-12 10:24:21.520]  Step 158626  [3.864 sec/step, loss=0.08391, avg_loss=0.08726, mel_loss=0.03631, linear_loss=0.04761]
[2020-05-12 10:24:29.005]  Step 158627  [3.914 sec/step, loss=0.09568, avg_loss=0.08731, mel_loss=0.04343, linear_loss=0.05225]
[2020-05-12 10:24:29.850]  Step 158628  [3.861 sec/step, loss=0.07839, avg_loss=0.08715, mel_loss=0.03313, linear_loss=0.04526]
[2020-05-12 10:24:31.923]  Step 158629  [3.871 sec/step, loss=0.08800, avg_loss=0.08723, mel_loss=0.03832, linear_loss=0.04968]
[2020-05-12 10:24:33.444]  Step 158630  [3.844 sec/step, loss=0.08356, avg_loss=0.08711, mel_loss=0.03618, linear_loss=0.04737]
[2020-05-12 10:24:36.865]  Step 158631  [3.803 sec/step, loss=0.09160, avg_loss=0.08706, mel_loss=0.04060, linear_loss=0.05100]
[2020-05-12 10:24:42.459]  Step 158632  [3.841 sec/step, loss=0.09520, avg_loss=0.08715, mel_loss=0.04312, linear_loss=0.05208]
[2020-05-12 10:24:43.031]  Step 158633  [3.837 sec/step, loss=0.06912, avg_loss=0.08706, mel_loss=0.03019, linear_loss=0.03893]
[2020-05-12 10:24:45.593]  Step 158634  [3.854 sec/step, loss=0.08704, avg_loss=0.08720, mel_loss=0.03796, linear_loss=0.04908]
[2020-05-12 10:24:51.661]  Step 158635  [3.881 sec/step, loss=0.09426, avg_loss=0.08722, mel_loss=0.04262, linear_loss=0.05164]
[2020-05-12 10:24:53.294]  Step 158636  [3.754 sec/step, loss=0.08654, avg_loss=0.08735, mel_loss=0.03729, linear_loss=0.04925]
[2020-05-12 10:24:57.102]  Step 158637  [3.778 sec/step, loss=0.09421, avg_loss=0.08746, mel_loss=0.04173, linear_loss=0.05249]
[2020-05-12 10:25:00.477]  Step 158638  [3.786 sec/step, loss=0.09237, avg_loss=0.08748, mel_loss=0.04078, linear_loss=0.05159]
[2020-05-12 10:25:01.236]  Step 158639  [3.788 sec/step, loss=0.07646, avg_loss=0.08757, mel_loss=0.03242, linear_loss=0.04404]
[2020-05-12 10:25:09.635]  Step 158640  [3.843 sec/step, loss=0.09187, avg_loss=0.08756, mel_loss=0.04206, linear_loss=0.04981]
[2020-05-12 10:25:14.399]  Step 158641  [3.874 sec/step, loss=0.09359, avg_loss=0.08764, mel_loss=0.04189, linear_loss=0.05170]
[2020-05-12 10:25:27.498]  Step 158642  [3.986 sec/step, loss=0.08187, avg_loss=0.08758, mel_loss=0.03828, linear_loss=0.04359]
[2020-05-12 10:25:29.278]  Step 158643  [3.982 sec/step, loss=0.08696, avg_loss=0.08758, mel_loss=0.03776, linear_loss=0.04920]
[2020-05-12 10:25:32.389]  Step 158644  [3.976 sec/step, loss=0.09292, avg_loss=0.08756, mel_loss=0.04088, linear_loss=0.05204]
[2020-05-12 10:25:37.595]  Generated 32 batches of size 32 in 45.928 sec
[2020-05-12 10:25:42.779]  Step 158645  [4.072 sec/step, loss=0.09797, avg_loss=0.08779, mel_loss=0.04412, linear_loss=0.05385]
[2020-05-12 10:25:44.437]  Step 158646  [4.041 sec/step, loss=0.08678, avg_loss=0.08770, mel_loss=0.03789, linear_loss=0.04890]
[2020-05-12 10:25:46.958]  Step 158647  [4.005 sec/step, loss=0.08963, avg_loss=0.08765, mel_loss=0.03895, linear_loss=0.05068]
[2020-05-12 10:25:55.971]  Step 158648  [4.064 sec/step, loss=0.09564, avg_loss=0.08771, mel_loss=0.04403, linear_loss=0.05161]
[2020-05-12 10:25:59.444]  Step 158649  [4.066 sec/step, loss=0.09012, avg_loss=0.08767, mel_loss=0.03993, linear_loss=0.05019]
[2020-05-12 10:26:00.294]  Step 158650  [4.043 sec/step, loss=0.07189, avg_loss=0.08746, mel_loss=0.03062, linear_loss=0.04127]
[2020-05-12 10:26:00.294]  Writing summary at step: 158650
[2020-05-12 10:26:03.479]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158650
[2020-05-12 10:26:05.089]  Saving audio and alignment...
[2020-05-12 10:26:23.154]  Input: 손님 여러분 이 비행기는 제주까지 가는 이스타항공 이공일편입니다 탑승권을 다시 한번 확인해 주십시오~________________________________________________________________
[2020-05-12 10:26:26.403]  Step 158651  [4.049 sec/step, loss=0.09399, avg_loss=0.08750, mel_loss=0.04165, linear_loss=0.05234]
[2020-05-12 10:26:28.190]  Step 158652  [4.038 sec/step, loss=0.08483, avg_loss=0.08744, mel_loss=0.03656, linear_loss=0.04827]
[2020-05-12 10:26:31.816]  Step 158653  [4.007 sec/step, loss=0.09293, avg_loss=0.08743, mel_loss=0.04113, linear_loss=0.05181]
[2020-05-12 10:26:32.861]  Step 158654  [3.976 sec/step, loss=0.07873, avg_loss=0.08729, mel_loss=0.03375, linear_loss=0.04498]
[2020-05-12 10:26:34.906]  Step 158655  [3.941 sec/step, loss=0.08822, avg_loss=0.08724, mel_loss=0.03832, linear_loss=0.04989]
[2020-05-12 10:26:36.465]  Step 158656  [3.946 sec/step, loss=0.08507, avg_loss=0.08730, mel_loss=0.03715, linear_loss=0.04792]
[2020-05-12 10:26:37.920]  Step 158657  [3.953 sec/step, loss=0.08327, avg_loss=0.08740, mel_loss=0.03585, linear_loss=0.04742]
[2020-05-12 10:26:43.660]  Step 158658  [3.994 sec/step, loss=0.09515, avg_loss=0.08749, mel_loss=0.04305, linear_loss=0.05210]
[2020-05-12 10:26:46.532]  Step 158659  [4.002 sec/step, loss=0.09211, avg_loss=0.08751, mel_loss=0.04076, linear_loss=0.05135]
[2020-05-12 10:26:47.316]  Step 158660  [3.973 sec/step, loss=0.07050, avg_loss=0.08727, mel_loss=0.02997, linear_loss=0.04053]
[2020-05-12 10:26:48.532]  Step 158661  [3.912 sec/step, loss=0.08299, avg_loss=0.08715, mel_loss=0.03548, linear_loss=0.04752]
[2020-05-12 10:26:52.738]  Step 158662  [3.944 sec/step, loss=0.09444, avg_loss=0.08729, mel_loss=0.04225, linear_loss=0.05219]
[2020-05-12 10:26:53.305]  Step 158663  [3.931 sec/step, loss=0.06903, avg_loss=0.08712, mel_loss=0.02980, linear_loss=0.03923]
[2020-05-12 10:26:54.393]  Step 158664  [3.898 sec/step, loss=0.07835, avg_loss=0.08695, mel_loss=0.03356, linear_loss=0.04479]
[2020-05-12 10:26:56.340]  Step 158665  [3.904 sec/step, loss=0.08743, avg_loss=0.08700, mel_loss=0.03819, linear_loss=0.04924]
[2020-05-12 10:26:57.735]  Step 158666  [3.912 sec/step, loss=0.08347, avg_loss=0.08716, mel_loss=0.03575, linear_loss=0.04772]
[2020-05-12 10:27:05.510]  Step 158667  [3.955 sec/step, loss=0.09727, avg_loss=0.08721, mel_loss=0.04452, linear_loss=0.05275]
[2020-05-12 10:27:06.719]  Generated 32 batches of size 32 in 10.373 sec
[2020-05-12 10:27:07.813]  Step 158668  [3.960 sec/step, loss=0.08845, avg_loss=0.08723, mel_loss=0.03884, linear_loss=0.04961]
[2020-05-12 10:27:10.414]  Step 158669  [3.898 sec/step, loss=0.09057, avg_loss=0.08719, mel_loss=0.03984, linear_loss=0.05072]
[2020-05-12 10:27:11.348]  Step 158670  [3.883 sec/step, loss=0.07522, avg_loss=0.08704, mel_loss=0.03178, linear_loss=0.04345]
[2020-05-12 10:27:16.121]  Step 158671  [3.790 sec/step, loss=0.09434, avg_loss=0.08724, mel_loss=0.04225, linear_loss=0.05209]
[2020-05-12 10:27:22.520]  Step 158672  [3.827 sec/step, loss=0.09503, avg_loss=0.08730, mel_loss=0.04324, linear_loss=0.05179]
[2020-05-12 10:27:24.669]  Step 158673  [3.832 sec/step, loss=0.08834, avg_loss=0.08731, mel_loss=0.03878, linear_loss=0.04957]
[2020-05-12 10:27:28.772]  Step 158674  [3.864 sec/step, loss=0.09314, avg_loss=0.08746, mel_loss=0.04125, linear_loss=0.05189]
[2020-05-12 10:27:29.302]  Step 158675  [3.849 sec/step, loss=0.06877, avg_loss=0.08728, mel_loss=0.03023, linear_loss=0.03853]
[2020-05-12 10:27:30.864]  Step 158676  [3.851 sec/step, loss=0.08751, avg_loss=0.08731, mel_loss=0.03775, linear_loss=0.04976]
[2020-05-12 10:27:33.803]  Step 158677  [3.846 sec/step, loss=0.09205, avg_loss=0.08731, mel_loss=0.04048, linear_loss=0.05157]
[2020-05-12 10:27:34.786]  Step 158678  [3.807 sec/step, loss=0.07751, avg_loss=0.08714, mel_loss=0.03288, linear_loss=0.04463]
[2020-05-12 10:27:36.727]  Step 158679  [3.814 sec/step, loss=0.08814, avg_loss=0.08722, mel_loss=0.03825, linear_loss=0.04989]
[2020-05-12 10:27:37.528]  Step 158680  [3.814 sec/step, loss=0.07467, avg_loss=0.08719, mel_loss=0.03147, linear_loss=0.04320]
[2020-05-12 10:27:38.931]  Step 158681  [3.797 sec/step, loss=0.08382, avg_loss=0.08711, mel_loss=0.03644, linear_loss=0.04738]
[2020-05-12 10:27:42.987]  Step 158682  [3.807 sec/step, loss=0.09402, avg_loss=0.08710, mel_loss=0.04172, linear_loss=0.05230]
[2020-05-12 10:27:45.631]  Step 158683  [3.825 sec/step, loss=0.08685, avg_loss=0.08720, mel_loss=0.03813, linear_loss=0.04873]
[2020-05-12 10:27:49.060]  Step 158684  [3.718 sec/step, loss=0.09351, avg_loss=0.08739, mel_loss=0.04149, linear_loss=0.05202]
[2020-05-12 10:27:51.699]  Step 158685  [3.703 sec/step, loss=0.09041, avg_loss=0.08735, mel_loss=0.03973, linear_loss=0.05067]
[2020-05-12 10:27:52.922]  Step 158686  [3.709 sec/step, loss=0.08077, avg_loss=0.08743, mel_loss=0.03446, linear_loss=0.04631]
[2020-05-12 10:27:53.780]  Step 158687  [3.704 sec/step, loss=0.06993, avg_loss=0.08731, mel_loss=0.02979, linear_loss=0.04015]
[2020-05-12 10:27:55.770]  Step 158688  [3.679 sec/step, loss=0.08948, avg_loss=0.08725, mel_loss=0.03907, linear_loss=0.05041]
[2020-05-12 10:27:57.470]  Step 158689  [3.684 sec/step, loss=0.08823, avg_loss=0.08731, mel_loss=0.03808, linear_loss=0.05014]
[2020-05-12 10:28:04.076]  Step 158690  [3.675 sec/step, loss=0.09441, avg_loss=0.08729, mel_loss=0.04273, linear_loss=0.05169]
[2020-05-12 10:28:07.768]  Step 158691  [3.654 sec/step, loss=0.09575, avg_loss=0.08728, mel_loss=0.04263, linear_loss=0.05312]
[2020-05-12 10:28:11.379]  Step 158692  [3.673 sec/step, loss=0.09292, avg_loss=0.08733, mel_loss=0.04115, linear_loss=0.05177]
[2020-05-12 10:28:17.028]  Step 158693  [3.695 sec/step, loss=0.09232, avg_loss=0.08735, mel_loss=0.04148, linear_loss=0.05083]
[2020-05-12 10:28:18.135]  Step 158694  [3.679 sec/step, loss=0.08112, avg_loss=0.08727, mel_loss=0.03468, linear_loss=0.04643]
[2020-05-12 10:28:22.449]  Step 158695  [3.686 sec/step, loss=0.09350, avg_loss=0.08725, mel_loss=0.04171, linear_loss=0.05179]
[2020-05-12 10:28:23.778]  Step 158696  [3.649 sec/step, loss=0.08167, avg_loss=0.08714, mel_loss=0.03532, linear_loss=0.04635]
[2020-05-12 10:28:25.919]  Step 158697  [3.639 sec/step, loss=0.08939, avg_loss=0.08710, mel_loss=0.03896, linear_loss=0.05043]
[2020-05-12 10:28:29.019]  Step 158698  [3.582 sec/step, loss=0.09418, avg_loss=0.08710, mel_loss=0.04162, linear_loss=0.05256]
[2020-05-12 10:28:29.916]  Generated 32 batches of size 32 in 3.992 sec
[2020-05-12 10:28:31.437]  Step 158699  [3.582 sec/step, loss=0.09139, avg_loss=0.08713, mel_loss=0.03995, linear_loss=0.05144]
[2020-05-12 10:28:33.210]  Step 158700  [3.588 sec/step, loss=0.08779, avg_loss=0.08717, mel_loss=0.03803, linear_loss=0.04976]
[2020-05-12 10:28:33.210]  Writing summary at step: 158700
[2020-05-12 10:28:37.806]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158700
[2020-05-12 10:28:39.353]  Saving audio and alignment...
[2020-05-12 10:28:46.320]  Input: 자 다음으로 주최 협찬 사례 확실하게 고지 해 주시고요~________________________________________
[2020-05-12 10:28:53.337]  Step 158701  [3.636 sec/step, loss=0.09552, avg_loss=0.08723, mel_loss=0.04347, linear_loss=0.05205]
[2020-05-12 10:29:01.456]  Step 158702  [3.707 sec/step, loss=0.09462, avg_loss=0.08737, mel_loss=0.04309, linear_loss=0.05153]
[2020-05-12 10:29:02.469]  Step 158703  [3.685 sec/step, loss=0.07823, avg_loss=0.08721, mel_loss=0.03336, linear_loss=0.04487]
[2020-05-12 10:29:14.774]  Step 158704  [3.768 sec/step, loss=0.08165, avg_loss=0.08708, mel_loss=0.03795, linear_loss=0.04370]
[2020-05-12 10:29:15.894]  Step 158705  [3.714 sec/step, loss=0.07882, avg_loss=0.08691, mel_loss=0.03357, linear_loss=0.04525]
[2020-05-12 10:29:20.113]  Step 158706  [3.711 sec/step, loss=0.09409, avg_loss=0.08697, mel_loss=0.04191, linear_loss=0.05218]
[2020-05-12 10:29:25.286]  Step 158707  [3.742 sec/step, loss=0.09362, avg_loss=0.08703, mel_loss=0.04206, linear_loss=0.05155]
[2020-05-12 10:29:27.767]  Step 158708  [3.752 sec/step, loss=0.08915, avg_loss=0.08708, mel_loss=0.03892, linear_loss=0.05024]
[2020-05-12 10:29:31.765]  Step 158709  [3.772 sec/step, loss=0.09566, avg_loss=0.08715, mel_loss=0.04239, linear_loss=0.05327]
[2020-05-12 10:29:32.887]  Step 158710  [3.776 sec/step, loss=0.08148, avg_loss=0.08727, mel_loss=0.03457, linear_loss=0.04692]
[2020-05-12 10:29:34.494]  Step 158711  [3.722 sec/step, loss=0.08310, avg_loss=0.08715, mel_loss=0.03593, linear_loss=0.04717]
[2020-05-12 10:29:37.409]  Step 158712  [3.741 sec/step, loss=0.09126, avg_loss=0.08725, mel_loss=0.03993, linear_loss=0.05134]
[2020-05-12 10:29:37.960]  Step 158713  [3.070 sec/step, loss=0.06765, avg_loss=0.08697, mel_loss=0.02909, linear_loss=0.03856]
[2020-05-12 10:29:42.425]  Step 158714  [3.106 sec/step, loss=0.09523, avg_loss=0.08718, mel_loss=0.04246, linear_loss=0.05277]
[2020-05-12 10:29:45.542]  Step 158715  [3.112 sec/step, loss=0.09309, avg_loss=0.08721, mel_loss=0.04109, linear_loss=0.05201]
[2020-05-12 10:29:52.851]  Step 158716  [3.171 sec/step, loss=0.09690, avg_loss=0.08733, mel_loss=0.04406, linear_loss=0.05284]
[2020-05-12 10:29:58.383]  Step 158717  [3.215 sec/step, loss=0.09573, avg_loss=0.08747, mel_loss=0.04323, linear_loss=0.05250]
[2020-05-12 10:30:00.104]  Step 158718  [3.211 sec/step, loss=0.08798, avg_loss=0.08749, mel_loss=0.03818, linear_loss=0.04979]
[2020-05-12 10:30:02.221]  Step 158719  [3.194 sec/step, loss=0.08825, avg_loss=0.08743, mel_loss=0.03839, linear_loss=0.04986]
[2020-05-12 10:30:05.851]  Step 158720  [3.187 sec/step, loss=0.09548, avg_loss=0.08744, mel_loss=0.04232, linear_loss=0.05315]
[2020-05-12 10:30:09.207]  Step 158721  [3.192 sec/step, loss=0.09208, avg_loss=0.08745, mel_loss=0.04088, linear_loss=0.05120]
[2020-05-12 10:30:10.028]  Step 158722  [3.183 sec/step, loss=0.07092, avg_loss=0.08728, mel_loss=0.03042, linear_loss=0.04051]
[2020-05-12 10:30:13.444]  Step 158723  [3.194 sec/step, loss=0.09233, avg_loss=0.08732, mel_loss=0.04089, linear_loss=0.05145]
[2020-05-12 10:30:16.161]  Step 158724  [3.210 sec/step, loss=0.09178, avg_loss=0.08742, mel_loss=0.04053, linear_loss=0.05125]
[2020-05-12 10:30:17.488]  Step 158725  [3.214 sec/step, loss=0.08305, avg_loss=0.08746, mel_loss=0.03599, linear_loss=0.04706]
[2020-05-12 10:30:19.519]  Step 158726  [3.220 sec/step, loss=0.08764, avg_loss=0.08750, mel_loss=0.03834, linear_loss=0.04930]
[2020-05-12 10:30:33.751]  Step 158727  [3.288 sec/step, loss=0.07389, avg_loss=0.08728, mel_loss=0.03480, linear_loss=0.03908]
[2020-05-12 10:30:34.963]  Step 158728  [3.291 sec/step, loss=0.08433, avg_loss=0.08734, mel_loss=0.03600, linear_loss=0.04833]
[2020-05-12 10:30:36.750]  Step 158729  [3.288 sec/step, loss=0.08675, avg_loss=0.08733, mel_loss=0.03762, linear_loss=0.04913]
[2020-05-12 10:30:38.943]  Step 158730  [3.295 sec/step, loss=0.08970, avg_loss=0.08739, mel_loss=0.03890, linear_loss=0.05081]
[2020-05-12 10:30:39.790]  Step 158731  [3.269 sec/step, loss=0.07549, avg_loss=0.08723, mel_loss=0.03183, linear_loss=0.04366]
[2020-05-12 10:30:40.730]  Step 158732  [3.223 sec/step, loss=0.07875, avg_loss=0.08706, mel_loss=0.03374, linear_loss=0.04501]
[2020-05-12 10:30:43.043]  Step 158733  [3.240 sec/step, loss=0.08940, avg_loss=0.08727, mel_loss=0.03921, linear_loss=0.05018]
[2020-05-12 10:30:44.469]  Step 158734  [3.229 sec/step, loss=0.08669, avg_loss=0.08726, mel_loss=0.03731, linear_loss=0.04938]
[2020-05-12 10:30:52.789]  Step 158735  [3.251 sec/step, loss=0.09370, avg_loss=0.08726, mel_loss=0.04282, linear_loss=0.05088]
[2020-05-12 10:30:58.943]  Step 158736  [3.297 sec/step, loss=0.09565, avg_loss=0.08735, mel_loss=0.04332, linear_loss=0.05233]
[2020-05-12 10:32:22.898]  Generated 32 batches of size 32 in 109.141 sec
[2020-05-12 10:32:25.954]  Step 158737  [4.129 sec/step, loss=0.09280, avg_loss=0.08734, mel_loss=0.04106, linear_loss=0.05175]
[2020-05-12 10:32:26.787]  Step 158738  [4.103 sec/step, loss=0.07206, avg_loss=0.08713, mel_loss=0.03151, linear_loss=0.04055]
[2020-05-12 10:32:31.108]  Step 158739  [4.139 sec/step, loss=0.09348, avg_loss=0.08730, mel_loss=0.04181, linear_loss=0.05167]
[2020-05-12 10:32:34.497]  Step 158740  [4.089 sec/step, loss=0.09237, avg_loss=0.08731, mel_loss=0.04091, linear_loss=0.05146]
[2020-05-12 10:32:50.241]  Step 158741  [4.198 sec/step, loss=0.08047, avg_loss=0.08718, mel_loss=0.03748, linear_loss=0.04299]
[2020-05-12 10:32:52.745]  Step 158742  [4.093 sec/step, loss=0.08909, avg_loss=0.08725, mel_loss=0.03882, linear_loss=0.05027]
[2020-05-12 10:33:01.424]  Step 158743  [4.162 sec/step, loss=0.09385, avg_loss=0.08732, mel_loss=0.04306, linear_loss=0.05079]
[2020-05-12 10:33:03.023]  Step 158744  [4.146 sec/step, loss=0.08515, avg_loss=0.08724, mel_loss=0.03687, linear_loss=0.04827]
[2020-05-12 10:33:07.681]  Step 158745  [4.089 sec/step, loss=0.09446, avg_loss=0.08720, mel_loss=0.04238, linear_loss=0.05207]
[2020-05-12 10:33:09.764]  Step 158746  [4.093 sec/step, loss=0.08850, avg_loss=0.08722, mel_loss=0.03856, linear_loss=0.04995]
[2020-05-12 10:33:10.816]  Step 158747  [4.079 sec/step, loss=0.07846, avg_loss=0.08711, mel_loss=0.03341, linear_loss=0.04504]
[2020-05-12 10:33:12.202]  Step 158748  [4.002 sec/step, loss=0.08488, avg_loss=0.08700, mel_loss=0.03630, linear_loss=0.04858]
[2020-05-12 10:33:14.745]  Step 158749  [3.993 sec/step, loss=0.08753, avg_loss=0.08698, mel_loss=0.03848, linear_loss=0.04905]
[2020-05-12 10:33:16.860]  Step 158750  [4.006 sec/step, loss=0.08778, avg_loss=0.08714, mel_loss=0.03806, linear_loss=0.04972]
[2020-05-12 10:33:16.860]  Writing summary at step: 158750
[2020-05-12 10:33:19.613]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158750
[2020-05-12 10:33:21.296]  Saving audio and alignment...
[2020-05-12 10:33:22.802]  Input: 제가~______
[2020-05-12 10:33:30.083]  Step 158751  [4.046 sec/step, loss=0.09512, avg_loss=0.08715, mel_loss=0.04342, linear_loss=0.05170]
[2020-05-12 10:33:31.231]  Step 158752  [4.040 sec/step, loss=0.08139, avg_loss=0.08711, mel_loss=0.03464, linear_loss=0.04675]
[2020-05-12 10:33:34.073]  Step 158753  [4.032 sec/step, loss=0.09128, avg_loss=0.08710, mel_loss=0.04029, linear_loss=0.05099]
[2020-05-12 10:33:39.145]  Step 158754  [4.072 sec/step, loss=0.09454, avg_loss=0.08725, mel_loss=0.04256, linear_loss=0.05197]
[2020-05-12 10:33:40.970]  Step 158755  [4.070 sec/step, loss=0.08867, avg_loss=0.08726, mel_loss=0.03815, linear_loss=0.05052]
[2020-05-12 10:33:42.606]  Step 158756  [4.071 sec/step, loss=0.08811, avg_loss=0.08729, mel_loss=0.03806, linear_loss=0.05005]
[2020-05-12 10:33:43.925]  Step 158757  [4.069 sec/step, loss=0.08385, avg_loss=0.08729, mel_loss=0.03603, linear_loss=0.04782]
[2020-05-12 10:33:47.550]  Step 158758  [4.048 sec/step, loss=0.09270, avg_loss=0.08727, mel_loss=0.04117, linear_loss=0.05152]
[2020-05-12 10:33:53.261]  Step 158759  [4.077 sec/step, loss=0.09456, avg_loss=0.08729, mel_loss=0.04250, linear_loss=0.05206]
[2020-05-12 10:33:54.121]  Step 158760  [4.077 sec/step, loss=0.07644, avg_loss=0.08735, mel_loss=0.03220, linear_loss=0.04424]
[2020-05-12 10:33:55.184]  Step 158761  [4.076 sec/step, loss=0.08211, avg_loss=0.08734, mel_loss=0.03513, linear_loss=0.04698]
[2020-05-12 10:33:56.089]  Step 158762  [4.043 sec/step, loss=0.07317, avg_loss=0.08713, mel_loss=0.03126, linear_loss=0.04192]
[2020-05-12 10:33:57.898]  Step 158763  [4.055 sec/step, loss=0.08533, avg_loss=0.08730, mel_loss=0.03671, linear_loss=0.04862]
[2020-05-12 10:34:04.770]  Step 158764  [4.113 sec/step, loss=0.09348, avg_loss=0.08745, mel_loss=0.04234, linear_loss=0.05114]
[2020-05-12 10:34:08.216]  Step 158765  [4.128 sec/step, loss=0.09387, avg_loss=0.08751, mel_loss=0.04143, linear_loss=0.05244]
[2020-05-12 10:34:12.021]  Step 158766  [4.152 sec/step, loss=0.09462, avg_loss=0.08762, mel_loss=0.04199, linear_loss=0.05263]
[2020-05-12 10:34:54.861]  Generated 32 batches of size 32 in 70.930 sec
[2020-05-12 10:34:57.053]  Step 158767  [4.525 sec/step, loss=0.08782, avg_loss=0.08753, mel_loss=0.03832, linear_loss=0.04950]
[2020-05-12 10:34:58.144]  Step 158768  [4.513 sec/step, loss=0.08117, avg_loss=0.08746, mel_loss=0.03469, linear_loss=0.04648]
[2020-05-12 10:34:59.687]  Step 158769  [4.502 sec/step, loss=0.08356, avg_loss=0.08739, mel_loss=0.03604, linear_loss=0.04752]
[2020-05-12 10:35:01.545]  Step 158770  [4.511 sec/step, loss=0.08737, avg_loss=0.08751, mel_loss=0.03773, linear_loss=0.04964]
[2020-05-12 10:35:02.323]  Step 158771  [4.471 sec/step, loss=0.07634, avg_loss=0.08733, mel_loss=0.03209, linear_loss=0.04425]
[2020-05-12 10:35:03.196]  Step 158772  [4.416 sec/step, loss=0.07789, avg_loss=0.08716, mel_loss=0.03275, linear_loss=0.04514]
[2020-05-12 10:35:03.767]  Step 158773  [4.400 sec/step, loss=0.06923, avg_loss=0.08696, mel_loss=0.02992, linear_loss=0.03931]
[2020-05-12 10:35:12.711]  Step 158774  [4.449 sec/step, loss=0.09391, avg_loss=0.08697, mel_loss=0.04284, linear_loss=0.05108]
[2020-05-12 10:35:18.405]  Step 158775  [4.500 sec/step, loss=0.09640, avg_loss=0.08725, mel_loss=0.04359, linear_loss=0.05281]
[2020-05-12 10:35:25.878]  Step 158776  [4.559 sec/step, loss=0.09610, avg_loss=0.08733, mel_loss=0.04389, linear_loss=0.05220]
[2020-05-12 10:35:30.251]  Step 158777  [4.574 sec/step, loss=0.09346, avg_loss=0.08735, mel_loss=0.04172, linear_loss=0.05175]
[2020-05-12 10:35:42.799]  Step 158778  [4.689 sec/step, loss=0.08299, avg_loss=0.08740, mel_loss=0.03855, linear_loss=0.04444]
[2020-05-12 10:35:44.522]  Step 158779  [4.687 sec/step, loss=0.08604, avg_loss=0.08738, mel_loss=0.03744, linear_loss=0.04861]
[2020-05-12 10:35:47.741]  Step 158780  [4.711 sec/step, loss=0.09456, avg_loss=0.08758, mel_loss=0.04181, linear_loss=0.05274]
[2020-05-12 10:35:51.869]  Step 158781  [4.739 sec/step, loss=0.09266, avg_loss=0.08767, mel_loss=0.04125, linear_loss=0.05141]
[2020-05-12 10:35:52.712]  Step 158782  [4.706 sec/step, loss=0.07436, avg_loss=0.08747, mel_loss=0.03166, linear_loss=0.04270]
[2020-05-12 10:35:55.391]  Step 158783  [4.707 sec/step, loss=0.09020, avg_loss=0.08751, mel_loss=0.03959, linear_loss=0.05061]
[2020-05-12 10:35:57.857]  Step 158784  [4.697 sec/step, loss=0.08953, avg_loss=0.08747, mel_loss=0.03911, linear_loss=0.05042]
[2020-05-12 10:36:03.206]  Step 158785  [4.724 sec/step, loss=0.09482, avg_loss=0.08751, mel_loss=0.04256, linear_loss=0.05226]
[2020-05-12 10:36:04.480]  Step 158786  [4.725 sec/step, loss=0.08309, avg_loss=0.08753, mel_loss=0.03566, linear_loss=0.04743]
[2020-05-12 10:36:07.076]  Step 158787  [4.742 sec/step, loss=0.09019, avg_loss=0.08774, mel_loss=0.03945, linear_loss=0.05074]
[2020-05-12 10:36:08.013]  Step 158788  [4.732 sec/step, loss=0.07926, avg_loss=0.08763, mel_loss=0.03394, linear_loss=0.04532]
[2020-05-12 10:36:11.406]  Step 158789  [4.749 sec/step, loss=0.09227, avg_loss=0.08767, mel_loss=0.04095, linear_loss=0.05132]
[2020-05-12 10:36:18.128]  Step 158790  [4.750 sec/step, loss=0.09649, avg_loss=0.08770, mel_loss=0.04361, linear_loss=0.05288]
[2020-05-12 10:36:22.787]  Step 158791  [4.759 sec/step, loss=0.09502, avg_loss=0.08769, mel_loss=0.04239, linear_loss=0.05263]
[2020-05-12 10:36:24.429]  Step 158792  [4.740 sec/step, loss=0.08749, avg_loss=0.08763, mel_loss=0.03787, linear_loss=0.04961]
[2020-05-12 10:36:26.676]  Step 158793  [4.705 sec/step, loss=0.08857, avg_loss=0.08760, mel_loss=0.03877, linear_loss=0.04980]
[2020-05-12 10:36:28.729]  Step 158794  [4.715 sec/step, loss=0.08609, avg_loss=0.08765, mel_loss=0.03731, linear_loss=0.04878]
[2020-05-12 10:36:30.127]  Step 158795  [4.686 sec/step, loss=0.08202, avg_loss=0.08753, mel_loss=0.03536, linear_loss=0.04667]
[2020-05-12 10:36:31.274]  Step 158796  [4.684 sec/step, loss=0.08145, avg_loss=0.08753, mel_loss=0.03455, linear_loss=0.04691]
[2020-05-12 10:36:34.336]  Step 158797  [4.693 sec/step, loss=0.09286, avg_loss=0.08756, mel_loss=0.04101, linear_loss=0.05186]
[2020-05-12 10:36:37.884]  Step 158798  [4.698 sec/step, loss=0.09416, avg_loss=0.08756, mel_loss=0.04195, linear_loss=0.05220]
[2020-05-12 10:37:02.745]  Generated 32 batches of size 32 in 51.334 sec
[2020-05-12 10:37:04.859]  Step 158799  [4.943 sec/step, loss=0.08814, avg_loss=0.08753, mel_loss=0.03844, linear_loss=0.04970]
[2020-05-12 10:37:06.011]  Step 158800  [4.937 sec/step, loss=0.08192, avg_loss=0.08747, mel_loss=0.03473, linear_loss=0.04719]
[2020-05-12 10:37:06.011]  Writing summary at step: 158800
[2020-05-12 10:37:07.841]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158800
[2020-05-12 10:37:09.467]  Saving audio and alignment...
[2020-05-12 10:37:12.235]  Input: 커필라 그런데 웬 연애편지~____
[2020-05-12 10:37:13.820]  Step 158801  [4.883 sec/step, loss=0.08479, avg_loss=0.08736, mel_loss=0.03683, linear_loss=0.04796]
[2020-05-12 10:37:16.233]  Step 158802  [4.826 sec/step, loss=0.08927, avg_loss=0.08731, mel_loss=0.03911, linear_loss=0.05016]
[2020-05-12 10:37:18.918]  Step 158803  [4.842 sec/step, loss=0.08744, avg_loss=0.08740, mel_loss=0.03813, linear_loss=0.04930]
[2020-05-12 10:37:20.372]  Step 158804  [4.734 sec/step, loss=0.08461, avg_loss=0.08743, mel_loss=0.03636, linear_loss=0.04825]
[2020-05-12 10:37:25.636]  Step 158805  [4.775 sec/step, loss=0.09436, avg_loss=0.08759, mel_loss=0.04251, linear_loss=0.05185]
[2020-05-12 10:37:28.574]  Step 158806  [4.762 sec/step, loss=0.09230, avg_loss=0.08757, mel_loss=0.04055, linear_loss=0.05174]
[2020-05-12 10:37:36.138]  Step 158807  [4.786 sec/step, loss=0.09550, avg_loss=0.08759, mel_loss=0.04351, linear_loss=0.05200]
[2020-05-12 10:37:39.861]  Step 158808  [4.799 sec/step, loss=0.09659, avg_loss=0.08766, mel_loss=0.04291, linear_loss=0.05368]
[2020-05-12 10:37:42.057]  Step 158809  [4.781 sec/step, loss=0.09025, avg_loss=0.08761, mel_loss=0.03919, linear_loss=0.05106]
[2020-05-12 10:37:44.901]  Step 158810  [4.798 sec/step, loss=0.09133, avg_loss=0.08771, mel_loss=0.04044, linear_loss=0.05089]
[2020-05-12 10:37:45.706]  Step 158811  [4.790 sec/step, loss=0.07464, avg_loss=0.08762, mel_loss=0.03207, linear_loss=0.04258]
[2020-05-12 10:37:50.367]  Step 158812  [4.807 sec/step, loss=0.09473, avg_loss=0.08766, mel_loss=0.04242, linear_loss=0.05231]
[2020-05-12 10:38:05.174]  Step 158813  [4.950 sec/step, loss=0.07786, avg_loss=0.08776, mel_loss=0.03658, linear_loss=0.04128]
[2020-05-12 10:38:08.839]  Step 158814  [4.942 sec/step, loss=0.09291, avg_loss=0.08774, mel_loss=0.04109, linear_loss=0.05182]
[2020-05-12 10:38:12.452]  Step 158815  [4.947 sec/step, loss=0.09230, avg_loss=0.08773, mel_loss=0.04109, linear_loss=0.05121]
[2020-05-12 10:38:13.513]  Step 158816  [4.884 sec/step, loss=0.07601, avg_loss=0.08752, mel_loss=0.03262, linear_loss=0.04339]
[2020-05-12 10:38:19.368]  Step 158817  [4.888 sec/step, loss=0.09460, avg_loss=0.08751, mel_loss=0.04270, linear_loss=0.05190]
[2020-05-12 10:38:28.551]  Step 158818  [4.962 sec/step, loss=0.09408, avg_loss=0.08757, mel_loss=0.04336, linear_loss=0.05073]
[2020-05-12 10:38:29.298]  Step 158819  [4.949 sec/step, loss=0.07171, avg_loss=0.08740, mel_loss=0.03046, linear_loss=0.04125]
[2020-05-12 10:38:32.485]  Step 158820  [4.944 sec/step, loss=0.09319, avg_loss=0.08738, mel_loss=0.04086, linear_loss=0.05233]
[2020-05-12 10:38:36.769]  Step 158821  [4.953 sec/step, loss=0.09380, avg_loss=0.08740, mel_loss=0.04152, linear_loss=0.05227]
[2020-05-12 10:38:37.824]  Step 158822  [4.956 sec/step, loss=0.07717, avg_loss=0.08746, mel_loss=0.03272, linear_loss=0.04446]
[2020-05-12 10:38:42.348]  Step 158823  [4.967 sec/step, loss=0.09465, avg_loss=0.08748, mel_loss=0.04213, linear_loss=0.05252]
[2020-05-12 10:38:44.210]  Step 158824  [4.958 sec/step, loss=0.08908, avg_loss=0.08746, mel_loss=0.03837, linear_loss=0.05071]
[2020-05-12 10:38:46.318]  Step 158825  [4.966 sec/step, loss=0.08959, avg_loss=0.08752, mel_loss=0.03878, linear_loss=0.05081]
[2020-05-12 10:38:46.906]  Step 158826  [4.952 sec/step, loss=0.06728, avg_loss=0.08732, mel_loss=0.02996, linear_loss=0.03732]
[2020-05-12 10:38:48.232]  Step 158827  [4.823 sec/step, loss=0.08107, avg_loss=0.08739, mel_loss=0.03490, linear_loss=0.04617]
[2020-05-12 10:38:55.293]  Step 158828  [4.881 sec/step, loss=0.09527, avg_loss=0.08750, mel_loss=0.04341, linear_loss=0.05186]
[2020-05-12 10:40:27.197]  Generated 32 batches of size 32 in 117.893 sec
[2020-05-12 10:40:32.696]  Step 158829  [5.837 sec/step, loss=0.09557, avg_loss=0.08759, mel_loss=0.04278, linear_loss=0.05278]
[2020-05-12 10:40:36.898]  Step 158830  [5.857 sec/step, loss=0.09305, avg_loss=0.08762, mel_loss=0.04121, linear_loss=0.05184]
[2020-05-12 10:40:38.616]  Step 158831  [5.866 sec/step, loss=0.08719, avg_loss=0.08774, mel_loss=0.03779, linear_loss=0.04940]
[2020-05-12 10:40:47.559]  Step 158832  [5.946 sec/step, loss=0.09301, avg_loss=0.08788, mel_loss=0.04240, linear_loss=0.05061]
[2020-05-12 10:40:49.476]  Step 158833  [5.942 sec/step, loss=0.08357, avg_loss=0.08782, mel_loss=0.03602, linear_loss=0.04755]
[2020-05-12 10:40:55.281]  Step 158834  [5.986 sec/step, loss=0.09537, avg_loss=0.08791, mel_loss=0.04308, linear_loss=0.05229]
[2020-05-12 10:40:59.018]  Step 158835  [5.940 sec/step, loss=0.09378, avg_loss=0.08791, mel_loss=0.04170, linear_loss=0.05208]
[2020-05-12 10:41:01.225]  Step 158836  [5.901 sec/step, loss=0.09002, avg_loss=0.08785, mel_loss=0.03958, linear_loss=0.05043]
[2020-05-12 10:41:15.626]  Step 158837  [5.175 sec/step, loss=0.07460, avg_loss=0.08767, mel_loss=0.03511, linear_loss=0.03949]
[2020-05-12 10:41:23.290]  Step 158838  [5.243 sec/step, loss=0.09628, avg_loss=0.08791, mel_loss=0.04371, linear_loss=0.05257]
[2020-05-12 10:41:26.813]  Step 158839  [5.235 sec/step, loss=0.09126, avg_loss=0.08789, mel_loss=0.04040, linear_loss=0.05086]
[2020-05-12 10:41:29.269]  Step 158840  [5.226 sec/step, loss=0.08814, avg_loss=0.08785, mel_loss=0.03830, linear_loss=0.04984]
[2020-05-12 10:41:30.196]  Step 158841  [5.077 sec/step, loss=0.07738, avg_loss=0.08782, mel_loss=0.03268, linear_loss=0.04470]
[2020-05-12 10:41:36.716]  Step 158842  [5.118 sec/step, loss=0.09503, avg_loss=0.08788, mel_loss=0.04319, linear_loss=0.05184]
[2020-05-12 10:41:38.346]  Step 158843  [5.047 sec/step, loss=0.08625, avg_loss=0.08780, mel_loss=0.03727, linear_loss=0.04898]
[2020-05-12 10:41:41.432]  Step 158844  [5.062 sec/step, loss=0.09223, avg_loss=0.08787, mel_loss=0.04052, linear_loss=0.05172]
[2020-05-12 10:41:42.634]  Step 158845  [5.027 sec/step, loss=0.08020, avg_loss=0.08773, mel_loss=0.03418, linear_loss=0.04602]
[2020-05-12 10:41:44.838]  Step 158846  [5.029 sec/step, loss=0.08861, avg_loss=0.08773, mel_loss=0.03868, linear_loss=0.04993]
[2020-05-12 10:41:45.822]  Step 158847  [5.028 sec/step, loss=0.08158, avg_loss=0.08776, mel_loss=0.03479, linear_loss=0.04679]
[2020-05-12 10:41:47.153]  Step 158848  [5.027 sec/step, loss=0.08342, avg_loss=0.08775, mel_loss=0.03578, linear_loss=0.04764]
[2020-05-12 10:41:48.637]  Step 158849  [5.017 sec/step, loss=0.08520, avg_loss=0.08773, mel_loss=0.03665, linear_loss=0.04855]
[2020-05-12 10:41:53.352]  Step 158850  [5.043 sec/step, loss=0.09557, avg_loss=0.08780, mel_loss=0.04272, linear_loss=0.05285]
[2020-05-12 10:41:53.352]  Writing summary at step: 158850
[2020-05-12 10:41:54.121]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158850
[2020-05-12 10:41:55.722]  Saving audio and alignment...
[2020-05-12 10:42:03.098]  Input: 어 그런 생각을 가진 친구들이 가장 먼저 시도해 볼 수 있는 것이 바로 제스쳐입니다~
[2020-05-12 10:42:04.167]  Step 158851  [4.981 sec/step, loss=0.08222, avg_loss=0.08767, mel_loss=0.03489, linear_loss=0.04733]
[2020-05-12 10:42:05.529]  Step 158852  [4.983 sec/step, loss=0.08397, avg_loss=0.08770, mel_loss=0.03616, linear_loss=0.04781]
[2020-05-12 10:42:06.096]  Step 158853  [4.960 sec/step, loss=0.06796, avg_loss=0.08747, mel_loss=0.02902, linear_loss=0.03894]
[2020-05-12 10:42:06.926]  Step 158854  [4.918 sec/step, loss=0.07348, avg_loss=0.08726, mel_loss=0.03119, linear_loss=0.04229]
[2020-05-12 10:42:10.257]  Step 158855  [4.933 sec/step, loss=0.09319, avg_loss=0.08730, mel_loss=0.04106, linear_loss=0.05214]
[2020-05-12 10:42:12.303]  Step 158856  [4.937 sec/step, loss=0.08910, avg_loss=0.08731, mel_loss=0.03885, linear_loss=0.05024]
[2020-05-12 10:42:14.950]  Step 158857  [4.950 sec/step, loss=0.09139, avg_loss=0.08739, mel_loss=0.04001, linear_loss=0.05138]
[2020-05-12 10:42:17.809]  Step 158858  [4.942 sec/step, loss=0.09115, avg_loss=0.08737, mel_loss=0.04031, linear_loss=0.05084]
[2020-05-12 10:42:54.352]  Generated 32 batches of size 32 in 57.853 sec
[2020-05-12 10:42:58.140]  Step 158859  [5.289 sec/step, loss=0.09247, avg_loss=0.08735, mel_loss=0.04089, linear_loss=0.05158]
[2020-05-12 10:43:01.334]  Step 158860  [5.312 sec/step, loss=0.09488, avg_loss=0.08754, mel_loss=0.04180, linear_loss=0.05307]
[2020-05-12 10:43:04.286]  Step 158861  [5.331 sec/step, loss=0.09117, avg_loss=0.08763, mel_loss=0.04045, linear_loss=0.05072]
[2020-05-12 10:43:08.911]  Step 158862  [5.368 sec/step, loss=0.09522, avg_loss=0.08785, mel_loss=0.04253, linear_loss=0.05269]
[2020-05-12 10:43:10.626]  Step 158863  [5.367 sec/step, loss=0.08532, avg_loss=0.08785, mel_loss=0.03697, linear_loss=0.04835]
[2020-05-12 10:43:12.192]  Step 158864  [5.314 sec/step, loss=0.08484, avg_loss=0.08776, mel_loss=0.03659, linear_loss=0.04825]
[2020-05-12 10:43:13.864]  Step 158865  [5.296 sec/step, loss=0.08384, avg_loss=0.08766, mel_loss=0.03628, linear_loss=0.04756]
[2020-05-12 10:43:15.691]  Step 158866  [5.276 sec/step, loss=0.08657, avg_loss=0.08758, mel_loss=0.03745, linear_loss=0.04913]
[2020-05-12 10:43:19.369]  Step 158867  [4.863 sec/step, loss=0.09438, avg_loss=0.08764, mel_loss=0.04199, linear_loss=0.05239]
[2020-05-12 10:43:22.133]  Step 158868  [4.880 sec/step, loss=0.09015, avg_loss=0.08773, mel_loss=0.03970, linear_loss=0.05045]
[2020-05-12 10:43:23.521]  Step 158869  [4.878 sec/step, loss=0.08392, avg_loss=0.08774, mel_loss=0.03604, linear_loss=0.04788]
[2020-05-12 10:43:26.088]  Step 158870  [4.885 sec/step, loss=0.08795, avg_loss=0.08774, mel_loss=0.03853, linear_loss=0.04942]
[2020-05-12 10:43:26.947]  Step 158871  [4.886 sec/step, loss=0.07449, avg_loss=0.08773, mel_loss=0.03152, linear_loss=0.04297]
[2020-05-12 10:43:28.159]  Step 158872  [4.889 sec/step, loss=0.08054, avg_loss=0.08775, mel_loss=0.03434, linear_loss=0.04621]
[2020-05-12 10:43:33.875]  Step 158873  [4.941 sec/step, loss=0.09517, avg_loss=0.08801, mel_loss=0.04288, linear_loss=0.05228]
[2020-05-12 10:43:35.832]  Step 158874  [4.871 sec/step, loss=0.08748, avg_loss=0.08795, mel_loss=0.03786, linear_loss=0.04961]
[2020-05-12 10:43:36.913]  Step 158875  [4.825 sec/step, loss=0.08073, avg_loss=0.08779, mel_loss=0.03462, linear_loss=0.04612]
[2020-05-12 10:43:41.782]  Step 158876  [4.799 sec/step, loss=0.09399, avg_loss=0.08777, mel_loss=0.04181, linear_loss=0.05218]
[2020-05-12 10:43:47.912]  Step 158877  [4.816 sec/step, loss=0.09442, avg_loss=0.08778, mel_loss=0.04266, linear_loss=0.05176]
[2020-05-12 10:43:49.218]  Step 158878  [4.704 sec/step, loss=0.08124, avg_loss=0.08776, mel_loss=0.03502, linear_loss=0.04622]
[2020-05-12 10:43:52.687]  Step 158879  [4.721 sec/step, loss=0.09396, avg_loss=0.08784, mel_loss=0.04178, linear_loss=0.05218]
[2020-05-12 10:43:54.726]  Step 158880  [4.710 sec/step, loss=0.08845, avg_loss=0.08778, mel_loss=0.03853, linear_loss=0.04992]
[2020-05-12 10:44:03.149]  Step 158881  [4.753 sec/step, loss=0.09381, avg_loss=0.08779, mel_loss=0.04285, linear_loss=0.05096]
[2020-05-12 10:44:07.010]  Step 158882  [4.783 sec/step, loss=0.09451, avg_loss=0.08799, mel_loss=0.04193, linear_loss=0.05258]
[2020-05-12 10:44:09.217]  Step 158883  [4.778 sec/step, loss=0.08749, avg_loss=0.08797, mel_loss=0.03828, linear_loss=0.04921]
[2020-05-12 10:44:10.703]  Generated 32 batches of size 32 in 7.548 sec
[2020-05-12 10:44:16.117]  Step 158884  [4.822 sec/step, loss=0.09680, avg_loss=0.08804, mel_loss=0.04428, linear_loss=0.05252]
[2020-05-12 10:44:16.886]  Step 158885  [4.777 sec/step, loss=0.07101, avg_loss=0.08780, mel_loss=0.03122, linear_loss=0.03978]
[2020-05-12 10:44:29.003]  Step 158886  [4.885 sec/step, loss=0.08237, avg_loss=0.08779, mel_loss=0.03835, linear_loss=0.04402]
[2020-05-12 10:44:31.498]  Step 158887  [4.884 sec/step, loss=0.09022, avg_loss=0.08779, mel_loss=0.03957, linear_loss=0.05065]
[2020-05-12 10:44:32.355]  Step 158888  [4.883 sec/step, loss=0.07510, avg_loss=0.08775, mel_loss=0.03173, linear_loss=0.04337]
[2020-05-12 10:44:36.580]  Step 158889  [4.892 sec/step, loss=0.09273, avg_loss=0.08776, mel_loss=0.04137, linear_loss=0.05136]
[2020-05-12 10:44:37.620]  Step 158890  [4.835 sec/step, loss=0.07854, avg_loss=0.08758, mel_loss=0.03348, linear_loss=0.04506]
[2020-05-12 10:44:42.976]  Step 158891  [4.842 sec/step, loss=0.09334, avg_loss=0.08756, mel_loss=0.04196, linear_loss=0.05138]
[2020-05-12 10:44:46.027]  Step 158892  [4.856 sec/step, loss=0.09104, avg_loss=0.08760, mel_loss=0.04014, linear_loss=0.05090]
[2020-05-12 10:44:47.526]  Step 158893  [4.849 sec/step, loss=0.08440, avg_loss=0.08755, mel_loss=0.03641, linear_loss=0.04798]
[2020-05-12 10:44:49.848]  Step 158894  [4.851 sec/step, loss=0.08931, avg_loss=0.08759, mel_loss=0.03891, linear_loss=0.05040]
[2020-05-12 10:44:51.568]  Step 158895  [4.854 sec/step, loss=0.08738, avg_loss=0.08764, mel_loss=0.03786, linear_loss=0.04952]
[2020-05-12 10:44:58.367]  Step 158896  [4.911 sec/step, loss=0.09381, avg_loss=0.08776, mel_loss=0.04245, linear_loss=0.05136]
[2020-05-12 10:45:01.578]  Step 158897  [4.912 sec/step, loss=0.09312, avg_loss=0.08777, mel_loss=0.04130, linear_loss=0.05182]
[2020-05-12 10:45:03.127]  Step 158898  [4.892 sec/step, loss=0.08517, avg_loss=0.08768, mel_loss=0.03683, linear_loss=0.04834]
[2020-05-12 10:45:06.143]  Step 158899  [4.653 sec/step, loss=0.09280, avg_loss=0.08772, mel_loss=0.04078, linear_loss=0.05202]
[2020-05-12 10:45:11.772]  Step 158900  [4.698 sec/step, loss=0.09476, avg_loss=0.08785, mel_loss=0.04272, linear_loss=0.05204]
[2020-05-12 10:45:11.772]  Writing summary at step: 158900
[2020-05-12 10:45:12.337]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158900
[2020-05-12 10:45:13.932]  Saving audio and alignment...
[2020-05-12 10:45:15.647]  Input: 골든벨~_________________________
[2020-05-12 10:45:19.656]  Step 158901  [4.722 sec/step, loss=0.09287, avg_loss=0.08793, mel_loss=0.04110, linear_loss=0.05177]
[2020-05-12 10:45:24.309]  Step 158902  [4.744 sec/step, loss=0.09549, avg_loss=0.08799, mel_loss=0.04268, linear_loss=0.05281]
[2020-05-12 10:45:26.766]  Step 158903  [4.742 sec/step, loss=0.08815, avg_loss=0.08800, mel_loss=0.03842, linear_loss=0.04972]
[2020-05-12 10:45:27.563]  Step 158904  [4.735 sec/step, loss=0.07673, avg_loss=0.08792, mel_loss=0.03241, linear_loss=0.04432]
[2020-05-12 10:45:31.007]  Step 158905  [4.717 sec/step, loss=0.09151, avg_loss=0.08789, mel_loss=0.04074, linear_loss=0.05078]
[2020-05-12 10:45:33.286]  Step 158906  [4.711 sec/step, loss=0.08925, avg_loss=0.08786, mel_loss=0.03920, linear_loss=0.05004]
[2020-05-12 10:45:35.886]  Step 158907  [4.661 sec/step, loss=0.09053, avg_loss=0.08781, mel_loss=0.03986, linear_loss=0.05067]
[2020-05-12 10:45:37.671]  Step 158908  [4.642 sec/step, loss=0.08747, avg_loss=0.08772, mel_loss=0.03759, linear_loss=0.04988]
[2020-05-12 10:45:41.785]  Step 158909  [4.661 sec/step, loss=0.09397, avg_loss=0.08776, mel_loss=0.04184, linear_loss=0.05212]
[2020-05-12 10:45:45.403]  Step 158910  [4.669 sec/step, loss=0.09428, avg_loss=0.08779, mel_loss=0.04187, linear_loss=0.05242]
[2020-05-12 10:45:46.583]  Step 158911  [4.672 sec/step, loss=0.07947, avg_loss=0.08784, mel_loss=0.03397, linear_loss=0.04549]
[2020-05-12 10:45:47.453]  Step 158912  [4.634 sec/step, loss=0.07572, avg_loss=0.08765, mel_loss=0.03175, linear_loss=0.04397]
[2020-05-12 10:45:48.530]  Step 158913  [4.497 sec/step, loss=0.07852, avg_loss=0.08765, mel_loss=0.03328, linear_loss=0.04524]
[2020-05-12 10:45:49.632]  Generated 32 batches of size 32 in 3.044 sec
[2020-05-12 10:45:56.159]  Step 158914  [4.537 sec/step, loss=0.09618, avg_loss=0.08769, mel_loss=0.04370, linear_loss=0.05248]
[2020-05-12 10:45:58.203]  Step 158915  [4.521 sec/step, loss=0.08709, avg_loss=0.08763, mel_loss=0.03792, linear_loss=0.04917]
[2020-05-12 10:45:59.547]  Step 158916  [4.524 sec/step, loss=0.08064, avg_loss=0.08768, mel_loss=0.03448, linear_loss=0.04616]
[2020-05-12 10:46:08.349]  Step 158917  [4.553 sec/step, loss=0.09386, avg_loss=0.08767, mel_loss=0.04295, linear_loss=0.05090]
[2020-05-12 10:46:10.253]  Step 158918  [4.481 sec/step, loss=0.08702, avg_loss=0.08760, mel_loss=0.03773, linear_loss=0.04930]
[2020-05-12 10:46:24.896]  Step 158919  [4.620 sec/step, loss=0.07416, avg_loss=0.08763, mel_loss=0.03478, linear_loss=0.03938]
[2020-05-12 10:46:25.921]  Step 158920  [4.598 sec/step, loss=0.08210, avg_loss=0.08752, mel_loss=0.03526, linear_loss=0.04684]
[2020-05-12 10:46:33.627]  Step 158921  [4.632 sec/step, loss=0.09576, avg_loss=0.08754, mel_loss=0.04351, linear_loss=0.05225]
[2020-05-12 10:46:37.378]  Step 158922  [4.659 sec/step, loss=0.09236, avg_loss=0.08769, mel_loss=0.04108, linear_loss=0.05128]
[2020-05-12 10:46:39.256]  Step 158923  [4.633 sec/step, loss=0.08662, avg_loss=0.08761, mel_loss=0.03738, linear_loss=0.04925]
[2020-05-12 10:46:44.098]  Step 158924  [4.662 sec/step, loss=0.09457, avg_loss=0.08766, mel_loss=0.04229, linear_loss=0.05228]
[2020-05-12 10:46:47.216]  Step 158925  [4.673 sec/step, loss=0.09267, avg_loss=0.08769, mel_loss=0.04095, linear_loss=0.05171]
[2020-05-12 10:46:48.188]  Step 158926  [4.676 sec/step, loss=0.08147, avg_loss=0.08783, mel_loss=0.03445, linear_loss=0.04702]
[2020-05-12 10:46:49.106]  Step 158927  [4.672 sec/step, loss=0.07773, avg_loss=0.08780, mel_loss=0.03280, linear_loss=0.04493]
[2020-05-12 10:46:51.104]  Step 158928  [4.622 sec/step, loss=0.08762, avg_loss=0.08772, mel_loss=0.03800, linear_loss=0.04962]
[2020-05-12 10:46:52.223]  Step 158929  [3.659 sec/step, loss=0.07855, avg_loss=0.08755, mel_loss=0.03307, linear_loss=0.04548]
[2020-05-12 10:46:52.787]  Step 158930  [3.622 sec/step, loss=0.07126, avg_loss=0.08734, mel_loss=0.03181, linear_loss=0.03945]
[2020-05-12 10:46:53.591]  Step 158931  [3.613 sec/step, loss=0.07566, avg_loss=0.08722, mel_loss=0.03188, linear_loss=0.04378]
[2020-05-12 10:47:00.436]  Step 158932  [3.592 sec/step, loss=0.09584, avg_loss=0.08725, mel_loss=0.04324, linear_loss=0.05260]
[2020-05-12 10:47:02.080]  Step 158933  [3.590 sec/step, loss=0.08613, avg_loss=0.08728, mel_loss=0.03724, linear_loss=0.04889]
[2020-05-12 10:47:04.831]  Step 158934  [3.559 sec/step, loss=0.08924, avg_loss=0.08721, mel_loss=0.03895, linear_loss=0.05029]
[2020-05-12 10:47:06.968]  Step 158935  [3.543 sec/step, loss=0.08799, avg_loss=0.08716, mel_loss=0.03811, linear_loss=0.04988]
[2020-05-12 10:47:10.513]  Step 158936  [3.556 sec/step, loss=0.09245, avg_loss=0.08718, mel_loss=0.04094, linear_loss=0.05150]
[2020-05-12 10:47:19.157]  Step 158937  [3.499 sec/step, loss=0.09292, avg_loss=0.08736, mel_loss=0.04252, linear_loss=0.05040]
[2020-05-12 10:47:20.520]  Step 158938  [3.436 sec/step, loss=0.08292, avg_loss=0.08723, mel_loss=0.03541, linear_loss=0.04751]
[2020-05-12 10:47:21.901]  Step 158939  [3.414 sec/step, loss=0.08466, avg_loss=0.08716, mel_loss=0.03631, linear_loss=0.04835]
[2020-05-12 10:47:23.433]  Step 158940  [3.405 sec/step, loss=0.08361, avg_loss=0.08712, mel_loss=0.03601, linear_loss=0.04760]
[2020-05-12 10:47:27.887]  Step 158941  [3.440 sec/step, loss=0.09375, avg_loss=0.08728, mel_loss=0.04177, linear_loss=0.05198]
[2020-05-12 10:47:31.834]  Step 158942  [3.415 sec/step, loss=0.09427, avg_loss=0.08727, mel_loss=0.04183, linear_loss=0.05244]
[2020-05-12 10:47:37.621]  Step 158943  [3.456 sec/step, loss=0.09419, avg_loss=0.08735, mel_loss=0.04264, linear_loss=0.05155]
[2020-05-12 10:47:39.890]  Step 158944  [3.448 sec/step, loss=0.08793, avg_loss=0.08731, mel_loss=0.03850, linear_loss=0.04943]
[2020-05-12 10:47:41.674]  Step 158945  [3.454 sec/step, loss=0.08552, avg_loss=0.08736, mel_loss=0.03671, linear_loss=0.04881]
[2020-05-12 10:47:46.703]  Step 158946  [3.482 sec/step, loss=0.09573, avg_loss=0.08744, mel_loss=0.04315, linear_loss=0.05257]
[2020-05-12 10:47:59.245]  Step 158947  [3.598 sec/step, loss=0.08606, avg_loss=0.08748, mel_loss=0.04030, linear_loss=0.04576]
[2020-05-12 10:48:02.164]  Step 158948  [3.614 sec/step, loss=0.09143, avg_loss=0.08756, mel_loss=0.04001, linear_loss=0.05143]
[2020-05-12 10:48:05.664]  Step 158949  [3.634 sec/step, loss=0.09280, avg_loss=0.08764, mel_loss=0.04112, linear_loss=0.05168]
[2020-05-12 10:48:06.850]  Step 158950  [3.599 sec/step, loss=0.08027, avg_loss=0.08748, mel_loss=0.03406, linear_loss=0.04621]
[2020-05-12 10:48:06.850]  Writing summary at step: 158950
[2020-05-12 10:48:07.535]  Saving checkpoint to: ./logs-tacotron/model.ckpt-158950
[2020-05-12 10:48:09.164]  Saving audio and alignment...
[2020-05-12 10:48:13.278]  Input: 눈부신 햇살과 함께 하고 고개를 확~_________________
[2020-05-12 10:49:33.670]  Generated 32 batches of size 32 in 116.044 sec
[2020-05-12 10:49:36.908]  Step 158951  [4.424 sec/step, loss=0.09297, avg_loss=0.08759, mel_loss=0.04111, linear_loss=0.05187]
[2020-05-12 10:49:51.260]  Step 158952  [4.554 sec/step, loss=0.07502, avg_loss=0.08750, mel_loss=0.03502, linear_loss=0.04000]
[2020-05-12 10:49:52.902]  Step 158953  [4.565 sec/step, loss=0.08600, avg_loss=0.08768, mel_loss=0.03737, linear_loss=0.04863]
[2020-05-12 10:49:58.824]  Step 158954  [4.616 sec/step, loss=0.09502, avg_loss=0.08790, mel_loss=0.04256, linear_loss=0.05245]
[2020-05-12 10:50:03.723]  Step 158955  [4.631 sec/step, loss=0.09421, avg_loss=0.08791, mel_loss=0.04211, linear_loss=0.05210]
[2020-05-12 10:50:04.287]  Step 158956  [4.617 sec/step, loss=0.06951, avg_loss=0.08771, mel_loss=0.03024, linear_loss=0.03927]
[2020-05-12 10:50:09.549]  Step 158957  [4.643 sec/step, loss=0.09434, avg_loss=0.08774, mel_loss=0.04247, linear_loss=0.05187]
[2020-05-12 10:50:10.975]  Step 158958  [4.628 sec/step, loss=0.08384, avg_loss=0.08767, mel_loss=0.03625, linear_loss=0.04760]
[2020-05-12 10:50:13.764]  Step 158959  [4.253 sec/step, loss=0.08825, avg_loss=0.08763, mel_loss=0.03897, linear_loss=0.04928]
[2020-05-12 10:50:19.962]  Step 158960  [4.283 sec/step, loss=0.09362, avg_loss=0.08761, mel_loss=0.04249, linear_loss=0.05114]
[2020-05-12 10:50:22.085]  Step 158961  [4.275 sec/step, loss=0.08694, avg_loss=0.08757, mel_loss=0.03803, linear_loss=0.04891]
[2020-05-12 10:50:23.343]  Step 158962  [4.241 sec/step, loss=0.08192, avg_loss=0.08744, mel_loss=0.03543, linear_loss=0.04649]
[2020-05-12 10:50:24.178]  Step 158963  [4.232 sec/step, loss=0.07339, avg_loss=0.08732, mel_loss=0.03169, linear_loss=0.04169]
[2020-05-12 10:50:25.227]  Step 158964  [4.227 sec/step, loss=0.07806, avg_loss=0.08725, mel_loss=0.03379, linear_loss=0.04427]
[2020-05-12 10:50:27.661]  Step 158965  [4.235 sec/step, loss=0.09089, avg_loss=0.08732, mel_loss=0.03944, linear_loss=0.05145]
[2020-05-12 10:50:36.595]  Step 158966  [4.306 sec/step, loss=0.09341, avg_loss=0.08739, mel_loss=0.04284, linear_loss=0.05057]
[2020-05-12 10:50:40.924]  Step 158967  [4.312 sec/step, loss=0.09484, avg_loss=0.08739, mel_loss=0.04229, linear_loss=0.05255]
[2020-05-12 10:50:41.925]  Step 158968  [4.295 sec/step, loss=0.07820, avg_loss=0.08727, mel_loss=0.03320, linear_loss=0.04500]
[2020-05-12 10:50:43.022]  Step 158969  [4.292 sec/step, loss=0.07985, avg_loss=0.08723, mel_loss=0.03404, linear_loss=0.04581]
[2020-05-12 10:50:49.965]  Step 158970  [4.335 sec/step, loss=0.09669, avg_loss=0.08732, mel_loss=0.04425, linear_loss=0.05245]
[2020-05-12 10:50:52.890]  Step 158971  [4.356 sec/step, loss=0.09335, avg_loss=0.08751, mel_loss=0.04114, linear_loss=0.05221]
[2020-05-12 10:50:55.444]  Step 158972  [4.370 sec/step, loss=0.09046, avg_loss=0.08761, mel_loss=0.03975, linear_loss=0.05071]
[2020-05-12 10:50:57.148]  Step 158973  [4.329 sec/step, loss=0.08704, avg_loss=0.08753, mel_loss=0.03761, linear_loss=0.04943]
[2020-05-12 10:51:01.298]  Step 158974  [4.351 sec/step, loss=0.09341, avg_loss=0.08759, mel_loss=0.04145, linear_loss=0.05196]
[2020-05-12 10:51:03.278]  Step 158975  [4.360 sec/step, loss=0.08758, avg_loss=0.08766, mel_loss=0.03806, linear_loss=0.04952]
[2020-05-12 10:51:06.551]  Step 158976  [4.344 sec/step, loss=0.09372, avg_loss=0.08765, mel_loss=0.04134, linear_loss=0.05238]
[2020-05-12 10:51:08.739]  Step 158977  [4.305 sec/step, loss=0.08905, avg_loss=0.08760, mel_loss=0.03879, linear_loss=0.05025]
[2020-05-12 10:51:10.123]  Step 158978  [4.306 sec/step, loss=0.08308, avg_loss=0.08762, mel_loss=0.03602, linear_loss=0.04706]
[2020-05-12 10:51:11.949]  Step 158979  [4.289 sec/step, loss=0.08462, avg_loss=0.08752, mel_loss=0.03650, linear_loss=0.04812]
[2020-05-12 10:51:15.456]  Step 158980  [4.304 sec/step, loss=0.09191, avg_loss=0.08756, mel_loss=0.04050, linear_loss=0.05140]
[2020-05-12 10:51:19.147]  Step 158981  [4.257 sec/step, loss=0.09433, avg_loss=0.08756, mel_loss=0.04178, linear_loss=0.05255]
[2020-05-12 10:51:19.899]  Step 158982  [4.226 sec/step, loss=0.07847, avg_loss=0.08740, mel_loss=0.03321, linear_loss=0.04526]
[2020-05-12 10:51:45.042]  Generated 32 batches of size 32 in 47.889 sec
[2020-05-12 10:51:46.061]  Step 158983  [4.465 sec/step, loss=0.07899, avg_loss=0.08732, mel_loss=0.03349, linear_loss=0.04550]
[2020-05-12 10:51:51.729]  Step 158984  [4.453 sec/step, loss=0.09443, avg_loss=0.08729, mel_loss=0.04260, linear_loss=0.05184]
[2020-05-12 10:51:56.545]  Step 158985  [4.493 sec/step, loss=0.09329, avg_loss=0.08752, mel_loss=0.04155, linear_loss=0.05174]
[2020-05-12 10:51:59.414]  Step 158986  [4.401 sec/step, loss=0.08981, avg_loss=0.08759, mel_loss=0.03953, linear_loss=0.05027]
[2020-05-12 10:52:03.663]  Step 158987  [4.418 sec/step, loss=0.09320, avg_loss=0.08762, mel_loss=0.04135, linear_loss=0.05186]
[2020-05-12 10:52:04.379]  Step 158988  [4.417 sec/step, loss=0.07376, avg_loss=0.08761, mel_loss=0.03117, linear_loss=0.04259]
[2020-05-12 10:52:11.454]  Step 158989  [4.445 sec/step, loss=0.09618, avg_loss=0.08764, mel_loss=0.04363, linear_loss=0.05255]
[2020-05-12 10:52:12.740]  Step 158990  [4.448 sec/step, loss=0.08221, avg_loss=0.08768, mel_loss=0.03526, linear_loss=0.04695]
[2020-05-12 10:52:14.169]  Step 158991  [4.409 sec/step, loss=0.08554, avg_loss=0.08760, mel_loss=0.03687, linear_loss=0.04867]
[2020-05-12 10:52:17.540]  Step 158992  [4.412 sec/step, loss=0.09444, avg_loss=0.08764, mel_loss=0.04188, linear_loss=0.05255]
[2020-05-12 10:52:21.126]  Step 158993  [4.433 sec/step, loss=0.09325, avg_loss=0.08772, mel_loss=0.04128, linear_loss=0.05196]
[2020-05-12 10:52:22.837]  Step 158994  [4.427 sec/step, loss=0.08723, avg_loss=0.08770, mel_loss=0.03789, linear_loss=0.04934]
[2020-05-12 10:52:29.555]  Step 158995  [4.477 sec/step, loss=0.09478, avg_loss=0.08778, mel_loss=0.04282, linear_loss=0.05196]
[2020-05-12 10:52:31.365]  Step 158996  [4.427 sec/step, loss=0.08872, avg_loss=0.08773, mel_loss=0.03820, linear_loss=0.05052]
[2020-05-12 10:52:33.530]  Step 158997  [4.416 sec/step, loss=0.08847, avg_loss=0.08768, mel_loss=0.03848, linear_loss=0.04999]
[2020-05-12 10:52:35.487]  Step 158998  [4.420 sec/step, loss=0.08751, avg_loss=0.08770, mel_loss=0.03781, linear_loss=0.04970]
[2020-05-12 10:52:39.183]  Step 158999  [4.427 sec/step, loss=0.09435, avg_loss=0.08772, mel_loss=0.04165, linear_loss=0.05270]
[2020-05-12 10:52:39.742]  Step 159000  [4.376 sec/step, loss=0.06890, avg_loss=0.08746, mel_loss=0.02979, linear_loss=0.03910]
[2020-05-12 10:52:39.742]  Writing summary at step: 159000
[2020-05-12 10:52:42.170]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159000
[2020-05-12 10:52:43.756]  Saving audio and alignment...
[2020-05-12 10:52:51.282]  Input: 하강조 잠시 후 상승 이었다가 몇시를 알려드립니다 다시 하강조~____________________________________________
[2020-05-12 10:52:52.244]  Step 159001  [4.346 sec/step, loss=0.08054, avg_loss=0.08734, mel_loss=0.03386, linear_loss=0.04668]
[2020-05-12 10:52:53.349]  Step 159002  [4.310 sec/step, loss=0.07921, avg_loss=0.08717, mel_loss=0.03355, linear_loss=0.04565]
[2020-05-12 10:53:10.642]  Step 159003  [4.459 sec/step, loss=0.07224, avg_loss=0.08701, mel_loss=0.03370, linear_loss=0.03855]
[2020-05-12 10:53:13.766]  Step 159004  [4.482 sec/step, loss=0.09343, avg_loss=0.08718, mel_loss=0.04129, linear_loss=0.05214]
[2020-05-12 10:53:22.050]  Step 159005  [4.530 sec/step, loss=0.09408, avg_loss=0.08721, mel_loss=0.04307, linear_loss=0.05101]
[2020-05-12 10:53:26.533]  Step 159006  [4.553 sec/step, loss=0.09679, avg_loss=0.08728, mel_loss=0.04329, linear_loss=0.05350]
[2020-05-12 10:53:29.279]  Step 159007  [4.554 sec/step, loss=0.09033, avg_loss=0.08728, mel_loss=0.03964, linear_loss=0.05069]
[2020-05-12 10:53:31.366]  Step 159008  [4.557 sec/step, loss=0.08831, avg_loss=0.08729, mel_loss=0.03853, linear_loss=0.04978]
[2020-05-12 10:53:33.012]  Step 159009  [4.532 sec/step, loss=0.08503, avg_loss=0.08720, mel_loss=0.03671, linear_loss=0.04832]
[2020-05-12 10:53:36.588]  Step 159010  [4.532 sec/step, loss=0.09078, avg_loss=0.08717, mel_loss=0.04017, linear_loss=0.05060]
[2020-05-12 10:53:37.892]  Step 159011  [4.533 sec/step, loss=0.08142, avg_loss=0.08718, mel_loss=0.03479, linear_loss=0.04663]
[2020-05-12 10:53:38.746]  Step 159012  [4.533 sec/step, loss=0.07386, avg_loss=0.08717, mel_loss=0.03103, linear_loss=0.04284]
[2020-05-12 10:54:51.227]  Generated 32 batches of size 32 in 100.580 sec
[2020-05-12 10:54:53.814]  Step 159013  [5.273 sec/step, loss=0.09165, avg_loss=0.08730, mel_loss=0.03984, linear_loss=0.05181]
[2020-05-12 10:55:01.396]  Step 159014  [5.272 sec/step, loss=0.09275, avg_loss=0.08726, mel_loss=0.04217, linear_loss=0.05057]
[2020-05-12 10:55:02.761]  Step 159015  [5.266 sec/step, loss=0.08177, avg_loss=0.08721, mel_loss=0.03493, linear_loss=0.04684]
[2020-05-12 10:55:04.560]  Step 159016  [5.270 sec/step, loss=0.08578, avg_loss=0.08726, mel_loss=0.03680, linear_loss=0.04899]
[2020-05-12 10:55:07.893]  Step 159017  [5.216 sec/step, loss=0.09188, avg_loss=0.08724, mel_loss=0.04029, linear_loss=0.05159]
[2020-05-12 10:55:10.285]  Step 159018  [5.220 sec/step, loss=0.08926, avg_loss=0.08726, mel_loss=0.03898, linear_loss=0.05028]
[2020-05-12 10:55:12.475]  Step 159019  [5.096 sec/step, loss=0.08885, avg_loss=0.08741, mel_loss=0.03843, linear_loss=0.05042]
[2020-05-12 10:55:16.016]  Step 159020  [5.121 sec/step, loss=0.09084, avg_loss=0.08750, mel_loss=0.04007, linear_loss=0.05077]
[2020-05-12 10:55:20.767]  Step 159021  [5.091 sec/step, loss=0.09260, avg_loss=0.08747, mel_loss=0.04145, linear_loss=0.05115]
[2020-05-12 10:55:24.608]  Step 159022  [5.092 sec/step, loss=0.09378, avg_loss=0.08748, mel_loss=0.04186, linear_loss=0.05191]
[2020-05-12 10:55:26.082]  Step 159023  [5.088 sec/step, loss=0.08481, avg_loss=0.08746, mel_loss=0.03648, linear_loss=0.04833]
[2020-05-12 10:55:35.002]  Step 159024  [5.129 sec/step, loss=0.09457, avg_loss=0.08746, mel_loss=0.04323, linear_loss=0.05134]
[2020-05-12 10:55:35.800]  Step 159025  [5.106 sec/step, loss=0.07594, avg_loss=0.08730, mel_loss=0.03214, linear_loss=0.04379]
[2020-05-12 10:55:37.205]  Step 159026  [5.110 sec/step, loss=0.08367, avg_loss=0.08732, mel_loss=0.03609, linear_loss=0.04758]
[2020-05-12 10:55:39.812]  Step 159027  [5.127 sec/step, loss=0.09003, avg_loss=0.08744, mel_loss=0.03939, linear_loss=0.05063]
[2020-05-12 10:55:45.194]  Step 159028  [5.161 sec/step, loss=0.09591, avg_loss=0.08752, mel_loss=0.04327, linear_loss=0.05264]
[2020-05-12 10:55:49.398]  Step 159029  [5.192 sec/step, loss=0.09228, avg_loss=0.08766, mel_loss=0.04117, linear_loss=0.05112]
[2020-05-12 10:55:50.507]  Step 159030  [5.197 sec/step, loss=0.08215, avg_loss=0.08777, mel_loss=0.03485, linear_loss=0.04731]
[2020-05-12 10:55:51.374]  Step 159031  [5.198 sec/step, loss=0.07054, avg_loss=0.08772, mel_loss=0.03069, linear_loss=0.03984]
[2020-05-12 10:55:54.242]  Step 159032  [5.158 sec/step, loss=0.08939, avg_loss=0.08765, mel_loss=0.03929, linear_loss=0.05010]
[2020-05-12 10:55:55.258]  Step 159033  [5.152 sec/step, loss=0.08110, avg_loss=0.08760, mel_loss=0.03448, linear_loss=0.04662]
[2020-05-12 10:55:56.453]  Step 159034  [5.136 sec/step, loss=0.08225, avg_loss=0.08753, mel_loss=0.03532, linear_loss=0.04694]
[2020-05-12 10:55:56.948]  Step 159035  [5.120 sec/step, loss=0.07408, avg_loss=0.08739, mel_loss=0.03246, linear_loss=0.04162]
[2020-05-12 10:55:59.361]  Step 159036  [5.109 sec/step, loss=0.09041, avg_loss=0.08737, mel_loss=0.03963, linear_loss=0.05078]
[2020-05-12 10:56:01.338]  Step 159037  [5.042 sec/step, loss=0.08793, avg_loss=0.08732, mel_loss=0.03831, linear_loss=0.04962]
[2020-05-12 10:56:02.379]  Step 159038  [5.039 sec/step, loss=0.07526, avg_loss=0.08725, mel_loss=0.03215, linear_loss=0.04311]
[2020-05-12 10:56:08.305]  Step 159039  [5.084 sec/step, loss=0.09559, avg_loss=0.08736, mel_loss=0.04315, linear_loss=0.05244]
[2020-05-12 10:56:11.427]  Step 159040  [5.100 sec/step, loss=0.09324, avg_loss=0.08745, mel_loss=0.04118, linear_loss=0.05206]
[2020-05-12 10:56:25.990]  Step 159041  [5.201 sec/step, loss=0.07587, avg_loss=0.08727, mel_loss=0.03567, linear_loss=0.04019]
[2020-05-12 10:56:27.601]  Step 159042  [5.178 sec/step, loss=0.08548, avg_loss=0.08719, mel_loss=0.03717, linear_loss=0.04832]
[2020-05-12 10:56:31.154]  Step 159043  [5.155 sec/step, loss=0.09487, avg_loss=0.08719, mel_loss=0.04233, linear_loss=0.05254]
[2020-05-12 10:56:32.990]  Step 159044  [5.151 sec/step, loss=0.08392, avg_loss=0.08715, mel_loss=0.03630, linear_loss=0.04761]
[2020-05-12 10:57:05.120]  Generated 32 batches of size 32 in 68.167 sec
[2020-05-12 10:57:08.637]  Step 159045  [5.490 sec/step, loss=0.09125, avg_loss=0.08721, mel_loss=0.04044, linear_loss=0.05081]
[2020-05-12 10:57:10.243]  Step 159046  [5.455 sec/step, loss=0.08522, avg_loss=0.08711, mel_loss=0.03695, linear_loss=0.04827]
[2020-05-12 10:57:12.508]  Step 159047  [5.353 sec/step, loss=0.08808, avg_loss=0.08713, mel_loss=0.03851, linear_loss=0.04957]
[2020-05-12 10:57:19.269]  Step 159048  [5.391 sec/step, loss=0.09546, avg_loss=0.08717, mel_loss=0.04333, linear_loss=0.05212]
[2020-05-12 10:57:20.094]  Step 159049  [5.364 sec/step, loss=0.07404, avg_loss=0.08698, mel_loss=0.03186, linear_loss=0.04218]
[2020-05-12 10:57:21.474]  Step 159050  [5.366 sec/step, loss=0.08362, avg_loss=0.08701, mel_loss=0.03613, linear_loss=0.04749]
[2020-05-12 10:57:21.474]  Writing summary at step: 159050
[2020-05-12 10:57:22.696]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159050
[2020-05-12 10:57:24.256]  Saving audio and alignment...
[2020-05-12 10:57:40.763]  Input: 제가 합격할 가능성이 단 영점 일퍼센트라 할지라도 그 꿈이 실현됐을때 제가 얻을 행복감은 천이고 만이고 백만입니다~_____________________________________________
[2020-05-12 10:57:42.065]  Step 159051  [4.543 sec/step, loss=0.08390, avg_loss=0.08692, mel_loss=0.03627, linear_loss=0.04763]
[2020-05-12 10:57:42.937]  Step 159052  [4.408 sec/step, loss=0.07617, avg_loss=0.08693, mel_loss=0.03228, linear_loss=0.04388]
[2020-05-12 10:57:48.113]  Step 159053  [4.444 sec/step, loss=0.09391, avg_loss=0.08701, mel_loss=0.04228, linear_loss=0.05163]
[2020-05-12 10:57:50.972]  Step 159054  [4.413 sec/step, loss=0.09294, avg_loss=0.08699, mel_loss=0.04105, linear_loss=0.05189]
[2020-05-12 10:57:51.719]  Step 159055  [4.371 sec/step, loss=0.07690, avg_loss=0.08682, mel_loss=0.03229, linear_loss=0.04461]
[2020-05-12 10:57:53.763]  Step 159056  [4.386 sec/step, loss=0.08848, avg_loss=0.08701, mel_loss=0.03851, linear_loss=0.04997]
[2020-05-12 10:58:01.373]  Step 159057  [4.410 sec/step, loss=0.09693, avg_loss=0.08703, mel_loss=0.04419, linear_loss=0.05274]
[2020-05-12 10:58:03.070]  Step 159058  [4.412 sec/step, loss=0.08537, avg_loss=0.08705, mel_loss=0.03684, linear_loss=0.04853]
[2020-05-12 10:58:04.004]  Step 159059  [4.394 sec/step, loss=0.08094, avg_loss=0.08698, mel_loss=0.03451, linear_loss=0.04642]
[2020-05-12 10:58:07.615]  Step 159060  [4.368 sec/step, loss=0.09398, avg_loss=0.08698, mel_loss=0.04153, linear_loss=0.05246]
[2020-05-12 10:58:11.898]  Step 159061  [4.390 sec/step, loss=0.09462, avg_loss=0.08706, mel_loss=0.04221, linear_loss=0.05241]
[2020-05-12 10:58:20.452]  Step 159062  [4.463 sec/step, loss=0.09482, avg_loss=0.08718, mel_loss=0.04338, linear_loss=0.05144]
[2020-05-12 10:58:24.931]  Step 159063  [4.499 sec/step, loss=0.09553, avg_loss=0.08741, mel_loss=0.04254, linear_loss=0.05299]
[2020-05-12 10:58:30.475]  Step 159064  [4.544 sec/step, loss=0.09500, avg_loss=0.08758, mel_loss=0.04253, linear_loss=0.05247]
[2020-05-12 10:58:32.365]  Step 159065  [4.538 sec/step, loss=0.08740, avg_loss=0.08754, mel_loss=0.03785, linear_loss=0.04954]
[2020-05-12 10:58:36.441]  Step 159066  [4.490 sec/step, loss=0.09387, avg_loss=0.08755, mel_loss=0.04157, linear_loss=0.05230]
[2020-05-12 10:58:38.429]  Step 159067  [4.467 sec/step, loss=0.08868, avg_loss=0.08748, mel_loss=0.03831, linear_loss=0.05037]
[2020-05-12 10:58:41.161]  Step 159068  [4.484 sec/step, loss=0.08939, avg_loss=0.08760, mel_loss=0.03934, linear_loss=0.05005]
[2020-05-12 10:58:44.628]  Step 159069  [4.508 sec/step, loss=0.09584, avg_loss=0.08776, mel_loss=0.04236, linear_loss=0.05348]
[2020-05-12 10:58:46.446]  Step 159070  [4.456 sec/step, loss=0.08804, avg_loss=0.08767, mel_loss=0.03795, linear_loss=0.05009]
[2020-05-12 10:58:48.958]  Step 159071  [4.452 sec/step, loss=0.08765, avg_loss=0.08761, mel_loss=0.03804, linear_loss=0.04960]
[2020-05-12 10:58:52.042]  Step 159072  [4.457 sec/step, loss=0.09311, avg_loss=0.08764, mel_loss=0.04116, linear_loss=0.05195]
[2020-05-12 10:58:52.591]  Step 159073  [4.446 sec/step, loss=0.06744, avg_loss=0.08744, mel_loss=0.02905, linear_loss=0.03839]
[2020-05-12 10:58:53.699]  Step 159074  [4.415 sec/step, loss=0.07986, avg_loss=0.08731, mel_loss=0.03415, linear_loss=0.04571]
[2020-05-12 10:59:07.311]  Generated 32 batches of size 32 in 34.940 sec
[2020-05-12 10:59:07.917]  Step 159075  [4.538 sec/step, loss=0.06886, avg_loss=0.08712, mel_loss=0.02988, linear_loss=0.03897]
[2020-05-12 10:59:12.767]  Step 159076  [4.554 sec/step, loss=0.09583, avg_loss=0.08714, mel_loss=0.04325, linear_loss=0.05258]
[2020-05-12 10:59:14.523]  Step 159077  [4.549 sec/step, loss=0.08715, avg_loss=0.08712, mel_loss=0.03748, linear_loss=0.04967]
[2020-05-12 10:59:17.035]  Step 159078  [4.561 sec/step, loss=0.09005, avg_loss=0.08719, mel_loss=0.03969, linear_loss=0.05037]
[2020-05-12 10:59:18.357]  Step 159079  [4.556 sec/step, loss=0.08461, avg_loss=0.08719, mel_loss=0.03643, linear_loss=0.04818]
[2020-05-12 10:59:32.349]  Step 159080  [4.660 sec/step, loss=0.07475, avg_loss=0.08702, mel_loss=0.03523, linear_loss=0.03953]
[2020-05-12 10:59:33.096]  Step 159081  [4.631 sec/step, loss=0.07365, avg_loss=0.08681, mel_loss=0.03121, linear_loss=0.04243]
[2020-05-12 10:59:35.213]  Step 159082  [4.645 sec/step, loss=0.08906, avg_loss=0.08692, mel_loss=0.03888, linear_loss=0.05018]
[2020-05-12 10:59:42.585]  Step 159083  [4.457 sec/step, loss=0.09492, avg_loss=0.08708, mel_loss=0.04296, linear_loss=0.05196]
[2020-05-12 10:59:44.251]  Step 159084  [4.417 sec/step, loss=0.08440, avg_loss=0.08698, mel_loss=0.03654, linear_loss=0.04787]
[2020-05-12 10:59:45.282]  Step 159085  [4.379 sec/step, loss=0.07771, avg_loss=0.08682, mel_loss=0.03315, linear_loss=0.04456]
[2020-05-12 10:59:51.091]  Step 159086  [4.408 sec/step, loss=0.09629, avg_loss=0.08689, mel_loss=0.04355, linear_loss=0.05275]
[2020-05-12 10:59:56.294]  Step 159087  [4.418 sec/step, loss=0.09707, avg_loss=0.08693, mel_loss=0.04392, linear_loss=0.05315]
[2020-05-12 10:59:58.010]  Step 159088  [4.428 sec/step, loss=0.08883, avg_loss=0.08708, mel_loss=0.03837, linear_loss=0.05046]
[2020-05-12 10:59:59.000]  Step 159089  [4.367 sec/step, loss=0.07986, avg_loss=0.08691, mel_loss=0.03369, linear_loss=0.04617]
[2020-05-12 10:59:59.801]  Step 159090  [4.362 sec/step, loss=0.07588, avg_loss=0.08685, mel_loss=0.03218, linear_loss=0.04371]
[2020-05-12 11:00:00.940]  Step 159091  [4.359 sec/step, loss=0.07893, avg_loss=0.08678, mel_loss=0.03347, linear_loss=0.04546]
[2020-05-12 11:00:05.538]  Step 159092  [4.371 sec/step, loss=0.09409, avg_loss=0.08678, mel_loss=0.04203, linear_loss=0.05206]
[2020-05-12 11:00:14.348]  Step 159093  [4.424 sec/step, loss=0.09511, avg_loss=0.08680, mel_loss=0.04368, linear_loss=0.05142]
[2020-05-12 11:00:17.525]  Step 159094  [4.438 sec/step, loss=0.09317, avg_loss=0.08686, mel_loss=0.04104, linear_loss=0.05214]
[2020-05-12 11:00:21.538]  Step 159095  [4.411 sec/step, loss=0.09405, avg_loss=0.08685, mel_loss=0.04180, linear_loss=0.05226]
[2020-05-12 11:00:25.004]  Step 159096  [4.428 sec/step, loss=0.09276, avg_loss=0.08689, mel_loss=0.04103, linear_loss=0.05173]
[2020-05-12 11:00:26.994]  Step 159097  [4.426 sec/step, loss=0.08707, avg_loss=0.08688, mel_loss=0.03785, linear_loss=0.04923]
[2020-05-12 11:00:31.117]  Step 159098  [4.448 sec/step, loss=0.09443, avg_loss=0.08695, mel_loss=0.04216, linear_loss=0.05227]
[2020-05-12 11:00:34.793]  Step 159099  [4.448 sec/step, loss=0.09510, avg_loss=0.08695, mel_loss=0.04229, linear_loss=0.05281]
[2020-05-12 11:00:36.261]  Step 159100  [4.457 sec/step, loss=0.08433, avg_loss=0.08711, mel_loss=0.03646, linear_loss=0.04787]
[2020-05-12 11:00:36.261]  Writing summary at step: 159100
[2020-05-12 11:00:39.756]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159100
[2020-05-12 11:00:41.414]  Saving audio and alignment...
[2020-05-12 11:00:50.486]  Input: 그런 상담사 님들의 공통점이 바로 이 끝은 있기에 달인이다는 점입니다~_______________________________________
[2020-05-12 11:00:52.918]  Step 159101  [4.471 sec/step, loss=0.09095, avg_loss=0.08721, mel_loss=0.03971, linear_loss=0.05124]
[2020-05-12 11:00:55.130]  Step 159102  [4.482 sec/step, loss=0.09095, avg_loss=0.08733, mel_loss=0.03991, linear_loss=0.05104]
[2020-05-12 11:00:56.404]  Step 159103  [4.322 sec/step, loss=0.08158, avg_loss=0.08742, mel_loss=0.03513, linear_loss=0.04645]
[2020-05-12 11:01:01.886]  Step 159104  [4.346 sec/step, loss=0.08839, avg_loss=0.08737, mel_loss=0.03898, linear_loss=0.04940]
[2020-05-12 11:02:04.090]  Generated 32 batches of size 32 in 97.091 sec
[2020-05-12 11:02:05.930]  Step 159105  [4.903 sec/step, loss=0.08550, avg_loss=0.08729, mel_loss=0.03697, linear_loss=0.04853]
[2020-05-12 11:02:07.268]  Step 159106  [4.872 sec/step, loss=0.08309, avg_loss=0.08715, mel_loss=0.03571, linear_loss=0.04738]
[2020-05-12 11:02:07.825]  Step 159107  [4.850 sec/step, loss=0.06803, avg_loss=0.08693, mel_loss=0.02977, linear_loss=0.03825]
[2020-05-12 11:02:15.242]  Step 159108  [4.903 sec/step, loss=0.09683, avg_loss=0.08701, mel_loss=0.04405, linear_loss=0.05278]
[2020-05-12 11:02:18.635]  Step 159109  [4.921 sec/step, loss=0.09139, avg_loss=0.08708, mel_loss=0.04049, linear_loss=0.05090]
[2020-05-12 11:02:20.874]  Step 159110  [4.907 sec/step, loss=0.08963, avg_loss=0.08706, mel_loss=0.03945, linear_loss=0.05018]
[2020-05-12 11:02:25.412]  Step 159111  [4.940 sec/step, loss=0.09545, avg_loss=0.08720, mel_loss=0.04260, linear_loss=0.05285]
[2020-05-12 11:02:26.172]  Step 159112  [4.939 sec/step, loss=0.07505, avg_loss=0.08722, mel_loss=0.03205, linear_loss=0.04300]
[2020-05-12 11:02:39.197]  Step 159113  [4.318 sec/step, loss=0.08131, avg_loss=0.08711, mel_loss=0.03798, linear_loss=0.04332]
[2020-05-12 11:02:42.878]  Step 159114  [4.279 sec/step, loss=0.09440, avg_loss=0.08713, mel_loss=0.04198, linear_loss=0.05242]
[2020-05-12 11:02:44.091]  Step 159115  [4.278 sec/step, loss=0.08150, avg_loss=0.08713, mel_loss=0.03506, linear_loss=0.04643]
[2020-05-12 11:02:48.314]  Step 159116  [4.302 sec/step, loss=0.09316, avg_loss=0.08720, mel_loss=0.04142, linear_loss=0.05174]
[2020-05-12 11:02:51.401]  Step 159117  [4.300 sec/step, loss=0.09203, avg_loss=0.08720, mel_loss=0.04059, linear_loss=0.05144]
[2020-05-12 11:02:52.202]  Step 159118  [4.284 sec/step, loss=0.07442, avg_loss=0.08705, mel_loss=0.03176, linear_loss=0.04265]
[2020-05-12 11:02:54.876]  Step 159119  [4.289 sec/step, loss=0.09011, avg_loss=0.08707, mel_loss=0.03955, linear_loss=0.05056]
[2020-05-12 11:03:01.525]  Step 159120  [4.320 sec/step, loss=0.09310, avg_loss=0.08709, mel_loss=0.04227, linear_loss=0.05083]
[2020-05-12 11:03:10.273]  Step 159121  [4.360 sec/step, loss=0.09330, avg_loss=0.08710, mel_loss=0.04254, linear_loss=0.05076]
[2020-05-12 11:03:13.636]  Step 159122  [4.355 sec/step, loss=0.09415, avg_loss=0.08710, mel_loss=0.04157, linear_loss=0.05258]
[2020-05-12 11:03:15.736]  Step 159123  [4.361 sec/step, loss=0.08894, avg_loss=0.08714, mel_loss=0.03860, linear_loss=0.05034]
[2020-05-12 11:03:17.266]  Step 159124  [4.287 sec/step, loss=0.08699, avg_loss=0.08707, mel_loss=0.03773, linear_loss=0.04926]
[2020-05-12 11:03:20.115]  Step 159125  [4.308 sec/step, loss=0.09240, avg_loss=0.08723, mel_loss=0.04066, linear_loss=0.05174]
[2020-05-12 11:03:25.634]  Step 159126  [4.349 sec/step, loss=0.09551, avg_loss=0.08735, mel_loss=0.04294, linear_loss=0.05257]
[2020-05-12 11:03:26.730]  Step 159127  [4.334 sec/step, loss=0.08187, avg_loss=0.08727, mel_loss=0.03501, linear_loss=0.04686]
[2020-05-12 11:03:27.631]  Step 159128  [4.289 sec/step, loss=0.07717, avg_loss=0.08708, mel_loss=0.03271, linear_loss=0.04446]
[2020-05-12 11:03:30.070]  Step 159129  [4.271 sec/step, loss=0.08922, avg_loss=0.08705, mel_loss=0.03875, linear_loss=0.05047]
[2020-05-12 11:03:31.977]  Step 159130  [4.279 sec/step, loss=0.08736, avg_loss=0.08710, mel_loss=0.03786, linear_loss=0.04949]
[2020-05-12 11:03:32.992]  Step 159131  [4.281 sec/step, loss=0.07826, avg_loss=0.08718, mel_loss=0.03347, linear_loss=0.04480]
[2020-05-12 11:03:36.573]  Step 159132  [4.288 sec/step, loss=0.09435, avg_loss=0.08723, mel_loss=0.04190, linear_loss=0.05245]
[2020-05-12 11:03:38.210]  Step 159133  [4.294 sec/step, loss=0.08559, avg_loss=0.08727, mel_loss=0.03694, linear_loss=0.04865]
[2020-05-12 11:03:43.064]  Step 159134  [4.331 sec/step, loss=0.09555, avg_loss=0.08741, mel_loss=0.04268, linear_loss=0.05287]
[2020-05-12 11:03:44.455]  Step 159135  [4.340 sec/step, loss=0.08405, avg_loss=0.08751, mel_loss=0.03634, linear_loss=0.04771]
[2020-05-12 11:03:46.441]  Step 159136  [4.335 sec/step, loss=0.08775, avg_loss=0.08748, mel_loss=0.03802, linear_loss=0.04973]
[2020-05-12 11:03:56.126]  Generated 32 batches of size 32 in 29.391 sec
[2020-05-12 11:03:57.068]  Step 159137  [4.422 sec/step, loss=0.07583, avg_loss=0.08736, mel_loss=0.03198, linear_loss=0.04385]
[2020-05-12 11:03:58.235]  Step 159138  [4.423 sec/step, loss=0.07889, avg_loss=0.08739, mel_loss=0.03352, linear_loss=0.04537]
[2020-05-12 11:03:59.979]  Step 159139  [4.381 sec/step, loss=0.08508, avg_loss=0.08729, mel_loss=0.03673, linear_loss=0.04836]
[2020-05-12 11:04:02.982]  Step 159140  [4.380 sec/step, loss=0.09135, avg_loss=0.08727, mel_loss=0.03995, linear_loss=0.05141]
[2020-05-12 11:04:06.715]  Step 159141  [4.272 sec/step, loss=0.09417, avg_loss=0.08745, mel_loss=0.04180, linear_loss=0.05237]
[2020-05-12 11:04:08.700]  Step 159142  [4.276 sec/step, loss=0.08763, avg_loss=0.08747, mel_loss=0.03835, linear_loss=0.04928]
[2020-05-12 11:04:12.125]  Step 159143  [4.274 sec/step, loss=0.09380, avg_loss=0.08746, mel_loss=0.04139, linear_loss=0.05241]
[2020-05-12 11:04:15.532]  Step 159144  [4.290 sec/step, loss=0.08952, avg_loss=0.08752, mel_loss=0.03950, linear_loss=0.05002]
[2020-05-12 11:04:16.601]  Step 159145  [3.944 sec/step, loss=0.08045, avg_loss=0.08741, mel_loss=0.03415, linear_loss=0.04630]
[2020-05-12 11:04:23.969]  Step 159146  [4.002 sec/step, loss=0.09594, avg_loss=0.08752, mel_loss=0.04366, linear_loss=0.05228]
[2020-05-12 11:04:25.556]  Step 159147  [3.995 sec/step, loss=0.08727, avg_loss=0.08751, mel_loss=0.03810, linear_loss=0.04917]
[2020-05-12 11:04:30.326]  Step 159148  [3.975 sec/step, loss=0.09425, avg_loss=0.08750, mel_loss=0.04228, linear_loss=0.05197]
[2020-05-12 11:04:31.082]  Step 159149  [3.974 sec/step, loss=0.07166, avg_loss=0.08748, mel_loss=0.03210, linear_loss=0.03955]
[2020-05-12 11:04:37.674]  Step 159150  [4.027 sec/step, loss=0.09340, avg_loss=0.08757, mel_loss=0.04218, linear_loss=0.05122]
[2020-05-12 11:04:37.674]  Writing summary at step: 159150
[2020-05-12 11:04:40.812]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159150
[2020-05-12 11:04:42.403]  Saving audio and alignment...
[2020-05-12 11:04:57.399]  Input: 자 먼저어 엠씨에게는요 적극적이고 활기찬 느낌이 가장 중요합니다 그런 느낌을 낼 수 있는 구체적인 방법 세가지 알려 드릴게요~______________________
[2020-05-12 11:05:01.723]  Step 159151  [4.057 sec/step, loss=0.09429, avg_loss=0.08768, mel_loss=0.04227, linear_loss=0.05202]
[2020-05-12 11:05:04.550]  Step 159152  [4.076 sec/step, loss=0.09036, avg_loss=0.08782, mel_loss=0.03958, linear_loss=0.05078]
[2020-05-12 11:05:05.884]  Step 159153  [4.038 sec/step, loss=0.08518, avg_loss=0.08773, mel_loss=0.03662, linear_loss=0.04855]
[2020-05-12 11:05:09.997]  Step 159154  [4.050 sec/step, loss=0.09318, avg_loss=0.08773, mel_loss=0.04111, linear_loss=0.05207]
[2020-05-12 11:05:12.163]  Step 159155  [4.065 sec/step, loss=0.08751, avg_loss=0.08784, mel_loss=0.03825, linear_loss=0.04926]
[2020-05-12 11:05:13.128]  Step 159156  [4.054 sec/step, loss=0.08000, avg_loss=0.08776, mel_loss=0.03415, linear_loss=0.04584]
[2020-05-12 11:05:15.658]  Step 159157  [4.003 sec/step, loss=0.09139, avg_loss=0.08770, mel_loss=0.03993, linear_loss=0.05146]
[2020-05-12 11:05:16.480]  Step 159158  [3.994 sec/step, loss=0.07556, avg_loss=0.08760, mel_loss=0.03197, linear_loss=0.04359]
[2020-05-12 11:05:17.244]  Step 159159  [3.993 sec/step, loss=0.07376, avg_loss=0.08753, mel_loss=0.03143, linear_loss=0.04233]
[2020-05-12 11:05:19.311]  Step 159160  [3.977 sec/step, loss=0.08944, avg_loss=0.08748, mel_loss=0.03889, linear_loss=0.05055]
[2020-05-12 11:05:26.014]  Generated 32 batches of size 32 in 10.351 sec
[2020-05-12 11:05:28.165]  Step 159161  [4.023 sec/step, loss=0.09394, avg_loss=0.08748, mel_loss=0.04315, linear_loss=0.05080]
[2020-05-12 11:05:30.134]  Step 159162  [3.957 sec/step, loss=0.08473, avg_loss=0.08738, mel_loss=0.03639, linear_loss=0.04835]
[2020-05-12 11:05:31.687]  Step 159163  [3.928 sec/step, loss=0.08269, avg_loss=0.08725, mel_loss=0.03568, linear_loss=0.04702]
[2020-05-12 11:05:33.065]  Step 159164  [3.886 sec/step, loss=0.08252, avg_loss=0.08712, mel_loss=0.03542, linear_loss=0.04710]
[2020-05-12 11:05:38.594]  Step 159165  [3.923 sec/step, loss=0.09477, avg_loss=0.08720, mel_loss=0.04262, linear_loss=0.05214]
[2020-05-12 11:05:40.918]  Step 159166  [3.905 sec/step, loss=0.08984, avg_loss=0.08716, mel_loss=0.03925, linear_loss=0.05059]
[2020-05-12 11:05:42.107]  Step 159167  [3.897 sec/step, loss=0.08129, avg_loss=0.08708, mel_loss=0.03484, linear_loss=0.04646]
[2020-05-12 11:05:45.535]  Step 159168  [3.904 sec/step, loss=0.09106, avg_loss=0.08710, mel_loss=0.04020, linear_loss=0.05086]
[2020-05-12 11:05:49.597]  Step 159169  [3.910 sec/step, loss=0.09378, avg_loss=0.08708, mel_loss=0.04168, linear_loss=0.05210]
[2020-05-12 11:05:55.878]  Step 159170  [3.955 sec/step, loss=0.09460, avg_loss=0.08715, mel_loss=0.04284, linear_loss=0.05176]
[2020-05-12 11:06:03.235]  Step 159171  [4.003 sec/step, loss=0.09523, avg_loss=0.08722, mel_loss=0.04324, linear_loss=0.05199]
[2020-05-12 11:06:05.403]  Step 159172  [3.994 sec/step, loss=0.08676, avg_loss=0.08716, mel_loss=0.03781, linear_loss=0.04895]
[2020-05-12 11:06:06.404]  Step 159173  [3.998 sec/step, loss=0.07555, avg_loss=0.08724, mel_loss=0.03208, linear_loss=0.04346]
[2020-05-12 11:06:07.751]  Step 159174  [4.001 sec/step, loss=0.08195, avg_loss=0.08726, mel_loss=0.03531, linear_loss=0.04664]
[2020-05-12 11:06:08.769]  Step 159175  [3.869 sec/step, loss=0.07830, avg_loss=0.08735, mel_loss=0.03327, linear_loss=0.04503]
[2020-05-12 11:06:23.306]  Step 159176  [3.966 sec/step, loss=0.07405, avg_loss=0.08714, mel_loss=0.03458, linear_loss=0.03947]
[2020-05-12 11:06:26.452]  Step 159177  [3.980 sec/step, loss=0.09370, avg_loss=0.08720, mel_loss=0.04152, linear_loss=0.05217]
[2020-05-12 11:06:29.898]  Step 159178  [3.989 sec/step, loss=0.09453, avg_loss=0.08725, mel_loss=0.04195, linear_loss=0.05258]
[2020-05-12 11:06:31.458]  Step 159179  [3.991 sec/step, loss=0.08688, avg_loss=0.08727, mel_loss=0.03734, linear_loss=0.04954]
[2020-05-12 11:06:33.917]  Step 159180  [3.876 sec/step, loss=0.08878, avg_loss=0.08741, mel_loss=0.03862, linear_loss=0.05016]
[2020-05-12 11:06:38.277]  Step 159181  [3.912 sec/step, loss=0.09552, avg_loss=0.08763, mel_loss=0.04277, linear_loss=0.05275]
[2020-05-12 11:06:40.291]  Step 159182  [3.911 sec/step, loss=0.08861, avg_loss=0.08762, mel_loss=0.03864, linear_loss=0.04996]
[2020-05-12 11:06:41.065]  Step 159183  [3.845 sec/step, loss=0.07645, avg_loss=0.08744, mel_loss=0.03248, linear_loss=0.04397]
[2020-05-12 11:06:43.788]  Step 159184  [3.856 sec/step, loss=0.08966, avg_loss=0.08749, mel_loss=0.03952, linear_loss=0.05013]
[2020-05-12 11:06:44.503]  Step 159185  [3.852 sec/step, loss=0.07448, avg_loss=0.08746, mel_loss=0.03194, linear_loss=0.04254]
[2020-05-12 11:06:46.374]  Step 159186  [3.813 sec/step, loss=0.08701, avg_loss=0.08737, mel_loss=0.03760, linear_loss=0.04941]
[2020-05-12 11:06:54.749]  Step 159187  [3.845 sec/step, loss=0.09284, avg_loss=0.08732, mel_loss=0.04234, linear_loss=0.05049]
[2020-05-12 11:06:55.821]  Step 159188  [3.838 sec/step, loss=0.08424, avg_loss=0.08728, mel_loss=0.03577, linear_loss=0.04847]
[2020-05-12 11:06:56.385]  Step 159189  [3.834 sec/step, loss=0.06794, avg_loss=0.08716, mel_loss=0.02900, linear_loss=0.03893]
[2020-05-12 11:07:02.030]  Step 159190  [3.883 sec/step, loss=0.09652, avg_loss=0.08737, mel_loss=0.04368, linear_loss=0.05284]
[2020-05-12 11:07:06.770]  Step 159191  [3.919 sec/step, loss=0.09385, avg_loss=0.08751, mel_loss=0.04169, linear_loss=0.05216]
[2020-05-12 11:07:10.446]  Step 159192  [3.909 sec/step, loss=0.09518, avg_loss=0.08753, mel_loss=0.04227, linear_loss=0.05291]
[2020-05-12 11:07:12.234]  Step 159193  [3.839 sec/step, loss=0.08758, avg_loss=0.08745, mel_loss=0.03758, linear_loss=0.05000]
[2020-05-12 11:07:14.630]  Step 159194  [3.831 sec/step, loss=0.08929, avg_loss=0.08741, mel_loss=0.03920, linear_loss=0.05009]
[2020-05-12 11:07:19.990]  Step 159195  [3.845 sec/step, loss=0.09425, avg_loss=0.08741, mel_loss=0.04228, linear_loss=0.05197]
[2020-05-12 11:07:21.614]  Step 159196  [3.826 sec/step, loss=0.08603, avg_loss=0.08735, mel_loss=0.03710, linear_loss=0.04893]
[2020-05-12 11:07:23.032]  Step 159197  [3.821 sec/step, loss=0.08495, avg_loss=0.08732, mel_loss=0.03666, linear_loss=0.04829]
[2020-05-12 11:07:25.934]  Step 159198  [3.808 sec/step, loss=0.09007, avg_loss=0.08728, mel_loss=0.03979, linear_loss=0.05028]
[2020-05-12 11:07:31.391]  Generated 32 batches of size 32 in 35.001 sec
[2020-05-12 11:07:34.601]  Step 159199  [3.858 sec/step, loss=0.09155, avg_loss=0.08725, mel_loss=0.04040, linear_loss=0.05116]
[2020-05-12 11:07:35.163]  Step 159200  [3.849 sec/step, loss=0.06896, avg_loss=0.08709, mel_loss=0.02989, linear_loss=0.03907]
[2020-05-12 11:07:35.163]  Writing summary at step: 159200
[2020-05-12 11:07:37.544]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159200
[2020-05-12 11:07:39.115]  Saving audio and alignment...
[2020-05-12 11:07:42.834]  Input: 네 그 다음 정류에 시작합니다~___________________
[2020-05-12 11:07:44.368]  Step 159201  [3.840 sec/step, loss=0.08286, avg_loss=0.08701, mel_loss=0.03553, linear_loss=0.04732]
[2020-05-12 11:07:46.372]  Step 159202  [3.838 sec/step, loss=0.08827, avg_loss=0.08698, mel_loss=0.03841, linear_loss=0.04987]
[2020-05-12 11:07:52.488]  Step 159203  [3.887 sec/step, loss=0.09223, avg_loss=0.08709, mel_loss=0.04153, linear_loss=0.05070]
[2020-05-12 11:07:57.330]  Step 159204  [3.880 sec/step, loss=0.09281, avg_loss=0.08713, mel_loss=0.04136, linear_loss=0.05145]
[2020-05-12 11:07:58.162]  Step 159205  [3.248 sec/step, loss=0.07247, avg_loss=0.08700, mel_loss=0.03088, linear_loss=0.04159]
[2020-05-12 11:08:00.711]  Step 159206  [3.260 sec/step, loss=0.09140, avg_loss=0.08709, mel_loss=0.03995, linear_loss=0.05145]
[2020-05-12 11:08:03.610]  Step 159207  [3.284 sec/step, loss=0.09337, avg_loss=0.08734, mel_loss=0.04093, linear_loss=0.05244]
[2020-05-12 11:08:04.654]  Step 159208  [3.220 sec/step, loss=0.07914, avg_loss=0.08716, mel_loss=0.03370, linear_loss=0.04543]
[2020-05-12 11:08:06.414]  Step 159209  [3.204 sec/step, loss=0.08634, avg_loss=0.08711, mel_loss=0.03709, linear_loss=0.04925]
[2020-05-12 11:08:08.850]  Step 159210  [3.206 sec/step, loss=0.08858, avg_loss=0.08710, mel_loss=0.03850, linear_loss=0.05008]
[2020-05-12 11:08:12.308]  Step 159211  [3.195 sec/step, loss=0.09228, avg_loss=0.08707, mel_loss=0.04060, linear_loss=0.05168]
[2020-05-12 11:08:16.548]  Step 159212  [3.230 sec/step, loss=0.09244, avg_loss=0.08724, mel_loss=0.04088, linear_loss=0.05155]
[2020-05-12 11:08:18.163]  Step 159213  [3.115 sec/step, loss=0.08660, avg_loss=0.08730, mel_loss=0.03729, linear_loss=0.04931]
[2020-05-12 11:08:25.529]  Step 159214  [3.152 sec/step, loss=0.09598, avg_loss=0.08731, mel_loss=0.04372, linear_loss=0.05225]
[2020-05-12 11:08:27.488]  Step 159215  [3.160 sec/step, loss=0.08602, avg_loss=0.08736, mel_loss=0.03715, linear_loss=0.04887]
[2020-05-12 11:08:28.577]  Step 159216  [3.128 sec/step, loss=0.07851, avg_loss=0.08721, mel_loss=0.03332, linear_loss=0.04520]
[2020-05-12 11:08:36.696]  Step 159217  [3.179 sec/step, loss=0.09288, avg_loss=0.08722, mel_loss=0.04257, linear_loss=0.05030]
[2020-05-12 11:08:40.248]  Step 159218  [3.206 sec/step, loss=0.09148, avg_loss=0.08739, mel_loss=0.04034, linear_loss=0.05114]
[2020-05-12 11:08:54.459]  Step 159219  [3.322 sec/step, loss=0.07291, avg_loss=0.08722, mel_loss=0.03406, linear_loss=0.03885]
[2020-05-12 11:08:55.265]  Step 159220  [3.263 sec/step, loss=0.07665, avg_loss=0.08705, mel_loss=0.03235, linear_loss=0.04430]
[2020-05-12 11:08:58.052]  Step 159221  [3.204 sec/step, loss=0.09102, avg_loss=0.08703, mel_loss=0.04011, linear_loss=0.05092]
[2020-05-12 11:08:59.280]  Step 159222  [3.182 sec/step, loss=0.08073, avg_loss=0.08690, mel_loss=0.03456, linear_loss=0.04618]
[2020-05-12 11:09:00.601]  Step 159223  [3.174 sec/step, loss=0.08260, avg_loss=0.08683, mel_loss=0.03541, linear_loss=0.04719]
[2020-05-12 11:09:04.365]  Step 159224  [3.197 sec/step, loss=0.09358, avg_loss=0.08690, mel_loss=0.04161, linear_loss=0.05197]
[2020-05-12 11:09:05.218]  Step 159225  [3.177 sec/step, loss=0.07686, avg_loss=0.08675, mel_loss=0.03251, linear_loss=0.04435]
[2020-05-12 11:09:10.821]  Step 159226  [3.178 sec/step, loss=0.09596, avg_loss=0.08675, mel_loss=0.04340, linear_loss=0.05256]
[2020-05-12 11:09:12.247]  Step 159227  [3.181 sec/step, loss=0.08268, avg_loss=0.08676, mel_loss=0.03549, linear_loss=0.04719]
[2020-05-12 11:09:16.785]  Step 159228  [3.217 sec/step, loss=0.09407, avg_loss=0.08693, mel_loss=0.04196, linear_loss=0.05211]
[2020-05-12 11:09:20.202]  Generated 32 batches of size 32 in 25.738 sec
[2020-05-12 11:09:25.595]  Step 159229  [3.281 sec/step, loss=0.09547, avg_loss=0.08699, mel_loss=0.04293, linear_loss=0.05254]
[2020-05-12 11:09:30.062]  Step 159230  [3.307 sec/step, loss=0.08917, avg_loss=0.08701, mel_loss=0.03932, linear_loss=0.04985]
[2020-05-12 11:09:32.779]  Step 159231  [3.324 sec/step, loss=0.08576, avg_loss=0.08708, mel_loss=0.03711, linear_loss=0.04864]
[2020-05-12 11:09:36.671]  Step 159232  [3.327 sec/step, loss=0.09217, avg_loss=0.08706, mel_loss=0.04063, linear_loss=0.05154]
[2020-05-12 11:09:37.431]  Step 159233  [3.318 sec/step, loss=0.07163, avg_loss=0.08692, mel_loss=0.03083, linear_loss=0.04080]
[2020-05-12 11:09:39.223]  Step 159234  [3.287 sec/step, loss=0.08790, avg_loss=0.08684, mel_loss=0.03783, linear_loss=0.05007]
[2020-05-12 11:09:41.462]  Step 159235  [3.296 sec/step, loss=0.08885, avg_loss=0.08689, mel_loss=0.03888, linear_loss=0.04997]
[2020-05-12 11:09:42.901]  Step 159236  [3.290 sec/step, loss=0.08331, avg_loss=0.08685, mel_loss=0.03582, linear_loss=0.04750]
[2020-05-12 11:09:44.533]  Step 159237  [3.200 sec/step, loss=0.08503, avg_loss=0.08694, mel_loss=0.03718, linear_loss=0.04785]
[2020-05-12 11:09:51.982]  Step 159238  [3.263 sec/step, loss=0.09680, avg_loss=0.08712, mel_loss=0.04397, linear_loss=0.05283]
[2020-05-12 11:09:55.453]  Step 159239  [3.281 sec/step, loss=0.09088, avg_loss=0.08718, mel_loss=0.04023, linear_loss=0.05065]
[2020-05-12 11:09:59.958]  Step 159240  [3.296 sec/step, loss=0.09567, avg_loss=0.08722, mel_loss=0.04293, linear_loss=0.05274]
[2020-05-12 11:10:00.962]  Step 159241  [3.268 sec/step, loss=0.08079, avg_loss=0.08709, mel_loss=0.03413, linear_loss=0.04666]
[2020-05-12 11:10:05.811]  Step 159242  [3.297 sec/step, loss=0.09319, avg_loss=0.08714, mel_loss=0.04170, linear_loss=0.05149]
[2020-05-12 11:10:08.225]  Step 159243  [3.287 sec/step, loss=0.08754, avg_loss=0.08708, mel_loss=0.03823, linear_loss=0.04931]
[2020-05-12 11:10:10.932]  Step 159244  [3.280 sec/step, loss=0.08706, avg_loss=0.08705, mel_loss=0.03821, linear_loss=0.04885]
[2020-05-12 11:10:26.034]  Step 159245  [3.420 sec/step, loss=0.07732, avg_loss=0.08702, mel_loss=0.03647, linear_loss=0.04085]
[2020-05-12 11:10:33.183]  Step 159246  [3.418 sec/step, loss=0.09427, avg_loss=0.08701, mel_loss=0.04276, linear_loss=0.05151]
[2020-05-12 11:10:37.399]  Step 159247  [3.444 sec/step, loss=0.09330, avg_loss=0.08707, mel_loss=0.04134, linear_loss=0.05196]
[2020-05-12 11:10:39.474]  Step 159248  [3.417 sec/step, loss=0.08775, avg_loss=0.08700, mel_loss=0.03792, linear_loss=0.04983]
[2020-05-12 11:10:40.078]  Step 159249  [3.416 sec/step, loss=0.06806, avg_loss=0.08697, mel_loss=0.02963, linear_loss=0.03843]
[2020-05-12 11:10:44.108]  Step 159250  [3.390 sec/step, loss=0.09391, avg_loss=0.08697, mel_loss=0.04159, linear_loss=0.05232]
[2020-05-12 11:10:44.108]  Writing summary at step: 159250
[2020-05-12 11:10:47.407]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159250
[2020-05-12 11:10:49.050]  Saving audio and alignment...
[2020-05-12 11:10:52.644]  Input: 어어 반대말인 상승 역시~___________________
[2020-05-12 11:10:56.172]  Step 159251  [3.382 sec/step, loss=0.09431, avg_loss=0.08697, mel_loss=0.04183, linear_loss=0.05248]
[2020-05-12 11:11:05.170]  Step 159252  [3.444 sec/step, loss=0.09545, avg_loss=0.08702, mel_loss=0.04366, linear_loss=0.05179]
[2020-05-12 11:11:06.295]  Step 159253  [3.442 sec/step, loss=0.08245, avg_loss=0.08700, mel_loss=0.03468, linear_loss=0.04777]
[2020-05-12 11:11:07.138]  Step 159254  [3.409 sec/step, loss=0.07245, avg_loss=0.08679, mel_loss=0.03065, linear_loss=0.04179]
[2020-05-12 11:11:08.449]  Step 159255  [3.401 sec/step, loss=0.07914, avg_loss=0.08670, mel_loss=0.03407, linear_loss=0.04507]
[2020-05-12 11:11:09.497]  Step 159256  [3.401 sec/step, loss=0.07858, avg_loss=0.08669, mel_loss=0.03357, linear_loss=0.04501]
[2020-05-12 11:11:15.274]  Step 159257  [3.434 sec/step, loss=0.09614, avg_loss=0.08674, mel_loss=0.04350, linear_loss=0.05263]
[2020-05-12 11:11:16.636]  Step 159258  [3.439 sec/step, loss=0.08348, avg_loss=0.08682, mel_loss=0.03601, linear_loss=0.04747]
[2020-05-12 11:12:17.013]  Generated 32 batches of size 32 in 87.335 sec
[2020-05-12 11:12:18.443]  Step 159259  [4.050 sec/step, loss=0.08351, avg_loss=0.08691, mel_loss=0.03571, linear_loss=0.04780]
[2020-05-12 11:12:26.137]  Step 159260  [4.106 sec/step, loss=0.09526, avg_loss=0.08697, mel_loss=0.04339, linear_loss=0.05187]
[2020-05-12 11:12:29.274]  Step 159261  [4.049 sec/step, loss=0.09156, avg_loss=0.08695, mel_loss=0.03998, linear_loss=0.05157]
[2020-05-12 11:12:34.565]  Step 159262  [4.082 sec/step, loss=0.09284, avg_loss=0.08703, mel_loss=0.04140, linear_loss=0.05144]
[2020-05-12 11:12:41.093]  Step 159263  [4.132 sec/step, loss=0.09596, avg_loss=0.08716, mel_loss=0.04340, linear_loss=0.05256]
[2020-05-12 11:12:42.399]  Step 159264  [4.131 sec/step, loss=0.08383, avg_loss=0.08718, mel_loss=0.03602, linear_loss=0.04781]
[2020-05-12 11:12:46.819]  Step 159265  [4.120 sec/step, loss=0.09264, avg_loss=0.08715, mel_loss=0.04145, linear_loss=0.05119]
[2020-05-12 11:12:48.358]  Step 159266  [4.112 sec/step, loss=0.08656, avg_loss=0.08712, mel_loss=0.03716, linear_loss=0.04940]
[2020-05-12 11:12:52.514]  Step 159267  [4.142 sec/step, loss=0.09243, avg_loss=0.08723, mel_loss=0.04077, linear_loss=0.05166]
[2020-05-12 11:12:54.382]  Step 159268  [4.126 sec/step, loss=0.08782, avg_loss=0.08720, mel_loss=0.03817, linear_loss=0.04965]
[2020-05-12 11:13:00.189]  Step 159269  [4.144 sec/step, loss=0.09575, avg_loss=0.08722, mel_loss=0.04326, linear_loss=0.05249]
[2020-05-12 11:13:03.069]  Step 159270  [4.110 sec/step, loss=0.09025, avg_loss=0.08718, mel_loss=0.03976, linear_loss=0.05049]
[2020-05-12 11:13:06.476]  Step 159271  [4.070 sec/step, loss=0.09321, avg_loss=0.08716, mel_loss=0.04125, linear_loss=0.05196]
[2020-05-12 11:13:19.624]  Step 159272  [4.180 sec/step, loss=0.08200, avg_loss=0.08711, mel_loss=0.03802, linear_loss=0.04398]
[2020-05-12 11:13:20.745]  Step 159273  [4.181 sec/step, loss=0.07970, avg_loss=0.08715, mel_loss=0.03403, linear_loss=0.04567]
[2020-05-12 11:13:23.183]  Step 159274  [4.192 sec/step, loss=0.08743, avg_loss=0.08720, mel_loss=0.03814, linear_loss=0.04929]
[2020-05-12 11:13:25.364]  Step 159275  [4.204 sec/step, loss=0.08904, avg_loss=0.08731, mel_loss=0.03901, linear_loss=0.05002]
[2020-05-12 11:13:26.334]  Step 159276  [4.068 sec/step, loss=0.07900, avg_loss=0.08736, mel_loss=0.03349, linear_loss=0.04550]
[2020-05-12 11:13:30.008]  Step 159277  [4.073 sec/step, loss=0.09342, avg_loss=0.08736, mel_loss=0.04142, linear_loss=0.05200]
[2020-05-12 11:13:31.693]  Step 159278  [4.056 sec/step, loss=0.08722, avg_loss=0.08729, mel_loss=0.03774, linear_loss=0.04948]
[2020-05-12 11:13:32.251]  Step 159279  [4.046 sec/step, loss=0.06778, avg_loss=0.08709, mel_loss=0.02916, linear_loss=0.03862]
[2020-05-12 11:13:35.676]  Step 159280  [4.055 sec/step, loss=0.09107, avg_loss=0.08712, mel_loss=0.04045, linear_loss=0.05061]
[2020-05-12 11:13:38.411]  Step 159281  [4.039 sec/step, loss=0.08917, avg_loss=0.08705, mel_loss=0.03909, linear_loss=0.05008]
[2020-05-12 11:13:39.296]  Step 159282  [4.028 sec/step, loss=0.07745, avg_loss=0.08694, mel_loss=0.03256, linear_loss=0.04489]
[2020-05-12 11:13:48.575]  Step 159283  [4.113 sec/step, loss=0.09417, avg_loss=0.08712, mel_loss=0.04327, linear_loss=0.05090]
[2020-05-12 11:13:49.210]  Step 159284  [4.092 sec/step, loss=0.07408, avg_loss=0.08696, mel_loss=0.03239, linear_loss=0.04169]
[2020-05-12 11:13:50.987]  Step 159285  [4.103 sec/step, loss=0.08694, avg_loss=0.08709, mel_loss=0.03744, linear_loss=0.04950]
[2020-05-12 11:13:53.482]  Step 159286  [4.109 sec/step, loss=0.08917, avg_loss=0.08711, mel_loss=0.03885, linear_loss=0.05032]
[2020-05-12 11:13:54.642]  Step 159287  [4.037 sec/step, loss=0.08213, avg_loss=0.08700, mel_loss=0.03510, linear_loss=0.04703]
[2020-05-12 11:13:59.486]  Step 159288  [4.074 sec/step, loss=0.09515, avg_loss=0.08711, mel_loss=0.04270, linear_loss=0.05245]
[2020-05-12 11:14:01.697]  Step 159289  [4.091 sec/step, loss=0.08654, avg_loss=0.08730, mel_loss=0.03772, linear_loss=0.04882]
[2020-05-12 11:14:02.555]  Step 159290  [4.043 sec/step, loss=0.07575, avg_loss=0.08709, mel_loss=0.03214, linear_loss=0.04361]
[2020-05-12 11:14:29.129]  Generated 32 batches of size 32 in 50.714 sec
[2020-05-12 11:14:33.305]  Step 159291  [4.303 sec/step, loss=0.09410, avg_loss=0.08709, mel_loss=0.04199, linear_loss=0.05212]
[2020-05-12 11:14:34.648]  Step 159292  [4.280 sec/step, loss=0.08160, avg_loss=0.08696, mel_loss=0.03506, linear_loss=0.04654]
[2020-05-12 11:14:37.174]  Step 159293  [4.287 sec/step, loss=0.09022, avg_loss=0.08698, mel_loss=0.03921, linear_loss=0.05101]
[2020-05-12 11:14:38.898]  Step 159294  [4.280 sec/step, loss=0.08771, avg_loss=0.08697, mel_loss=0.03750, linear_loss=0.05021]
[2020-05-12 11:14:41.522]  Step 159295  [4.253 sec/step, loss=0.09148, avg_loss=0.08694, mel_loss=0.04015, linear_loss=0.05132]
[2020-05-12 11:14:45.209]  Step 159296  [4.274 sec/step, loss=0.09475, avg_loss=0.08703, mel_loss=0.04206, linear_loss=0.05269]
[2020-05-12 11:14:46.011]  Step 159297  [4.267 sec/step, loss=0.07456, avg_loss=0.08692, mel_loss=0.03174, linear_loss=0.04283]
[2020-05-12 11:14:47.028]  Step 159298  [4.249 sec/step, loss=0.07914, avg_loss=0.08681, mel_loss=0.03376, linear_loss=0.04538]
[2020-05-12 11:14:55.202]  Step 159299  [4.244 sec/step, loss=0.09405, avg_loss=0.08684, mel_loss=0.04315, linear_loss=0.05090]
[2020-05-12 11:14:56.862]  Step 159300  [4.255 sec/step, loss=0.08569, avg_loss=0.08701, mel_loss=0.03724, linear_loss=0.04845]
[2020-05-12 11:14:56.862]  Writing summary at step: 159300
[2020-05-12 11:14:57.631]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159300
[2020-05-12 11:14:59.217]  Saving audio and alignment...
[2020-05-12 11:15:04.149]  Input: 이게 바로 아저씨가 물고기를 잡는 맛입니다~_________________________
[2020-05-12 11:15:06.097]  Step 159301  [4.259 sec/step, loss=0.08604, avg_loss=0.08704, mel_loss=0.03736, linear_loss=0.04868]
[2020-05-12 11:15:10.570]  Step 159302  [4.283 sec/step, loss=0.09519, avg_loss=0.08711, mel_loss=0.04235, linear_loss=0.05284]
[2020-05-12 11:15:11.945]  Step 159303  [4.236 sec/step, loss=0.08308, avg_loss=0.08702, mel_loss=0.03573, linear_loss=0.04735]
[2020-05-12 11:15:14.095]  Step 159304  [4.209 sec/step, loss=0.08857, avg_loss=0.08697, mel_loss=0.03852, linear_loss=0.05005]
[2020-05-12 11:15:16.093]  Step 159305  [4.221 sec/step, loss=0.08922, avg_loss=0.08714, mel_loss=0.03870, linear_loss=0.05052]
[2020-05-12 11:15:19.523]  Step 159306  [4.230 sec/step, loss=0.09501, avg_loss=0.08718, mel_loss=0.04203, linear_loss=0.05297]
[2020-05-12 11:15:21.118]  Step 159307  [4.217 sec/step, loss=0.08643, avg_loss=0.08711, mel_loss=0.03747, linear_loss=0.04896]
[2020-05-12 11:15:22.228]  Step 159308  [4.217 sec/step, loss=0.08204, avg_loss=0.08714, mel_loss=0.03511, linear_loss=0.04693]
[2020-05-12 11:15:27.205]  Step 159309  [4.249 sec/step, loss=0.09318, avg_loss=0.08721, mel_loss=0.04184, linear_loss=0.05135]
[2020-05-12 11:15:28.406]  Step 159310  [4.237 sec/step, loss=0.08118, avg_loss=0.08713, mel_loss=0.03449, linear_loss=0.04669]
[2020-05-12 11:15:41.425]  Step 159311  [4.333 sec/step, loss=0.07885, avg_loss=0.08700, mel_loss=0.03682, linear_loss=0.04203]
[2020-05-12 11:15:43.840]  Step 159312  [4.314 sec/step, loss=0.08837, avg_loss=0.08696, mel_loss=0.03866, linear_loss=0.04971]
[2020-05-12 11:15:51.002]  Generated 32 batches of size 32 in 9.573 sec
[2020-05-12 11:15:51.082]  Step 159313  [4.371 sec/step, loss=0.09559, avg_loss=0.08705, mel_loss=0.04317, linear_loss=0.05242]
[2020-05-12 11:15:55.336]  Step 159314  [4.340 sec/step, loss=0.09456, avg_loss=0.08703, mel_loss=0.04180, linear_loss=0.05276]
[2020-05-12 11:16:01.118]  Step 159315  [4.378 sec/step, loss=0.09366, avg_loss=0.08711, mel_loss=0.04193, linear_loss=0.05174]
[2020-05-12 11:16:04.547]  Step 159316  [4.401 sec/step, loss=0.09262, avg_loss=0.08725, mel_loss=0.04107, linear_loss=0.05155]
[2020-05-12 11:16:11.075]  Step 159317  [4.385 sec/step, loss=0.09495, avg_loss=0.08727, mel_loss=0.04306, linear_loss=0.05189]
[2020-05-12 11:16:12.073]  Step 159318  [4.360 sec/step, loss=0.07836, avg_loss=0.08714, mel_loss=0.03289, linear_loss=0.04547]
[2020-05-12 11:16:12.871]  Step 159319  [4.226 sec/step, loss=0.07704, avg_loss=0.08718, mel_loss=0.03245, linear_loss=0.04459]
[2020-05-12 11:16:15.720]  Step 159320  [4.246 sec/step, loss=0.09377, avg_loss=0.08735, mel_loss=0.04119, linear_loss=0.05258]
[2020-05-12 11:16:17.445]  Step 159321  [4.235 sec/step, loss=0.08647, avg_loss=0.08731, mel_loss=0.03722, linear_loss=0.04925]
[2020-05-12 11:16:20.705]  Step 159322  [4.256 sec/step, loss=0.09240, avg_loss=0.08742, mel_loss=0.04069, linear_loss=0.05171]
[2020-05-12 11:16:28.148]  Step 159323  [4.317 sec/step, loss=0.09602, avg_loss=0.08756, mel_loss=0.04378, linear_loss=0.05224]
[2020-05-12 11:16:30.137]  Step 159324  [4.299 sec/step, loss=0.08828, avg_loss=0.08750, mel_loss=0.03822, linear_loss=0.05006]
[2020-05-12 11:16:35.407]  Step 159325  [4.343 sec/step, loss=0.09337, avg_loss=0.08767, mel_loss=0.04189, linear_loss=0.05148]
[2020-05-12 11:16:43.724]  Step 159326  [4.371 sec/step, loss=0.09304, avg_loss=0.08764, mel_loss=0.04246, linear_loss=0.05058]
[2020-05-12 11:16:45.029]  Step 159327  [4.369 sec/step, loss=0.08395, avg_loss=0.08765, mel_loss=0.03623, linear_loss=0.04772]
[2020-05-12 11:16:48.076]  Step 159328  [4.354 sec/step, loss=0.09278, avg_loss=0.08764, mel_loss=0.04105, linear_loss=0.05173]
[2020-05-12 11:16:54.212]  Step 159329  [4.328 sec/step, loss=0.09357, avg_loss=0.08762, mel_loss=0.04226, linear_loss=0.05131]
[2020-05-12 11:16:56.151]  Step 159330  [4.302 sec/step, loss=0.08782, avg_loss=0.08761, mel_loss=0.03787, linear_loss=0.04995]
[2020-05-12 11:16:58.620]  Step 159331  [4.300 sec/step, loss=0.08964, avg_loss=0.08765, mel_loss=0.03904, linear_loss=0.05059]
[2020-05-12 11:16:59.150]  Step 159332  [4.266 sec/step, loss=0.07281, avg_loss=0.08745, mel_loss=0.03122, linear_loss=0.04159]
[2020-05-12 11:17:00.661]  Step 159333  [4.274 sec/step, loss=0.08486, avg_loss=0.08758, mel_loss=0.03668, linear_loss=0.04818]
[2020-05-12 11:17:01.493]  Step 159334  [4.264 sec/step, loss=0.07294, avg_loss=0.08744, mel_loss=0.03108, linear_loss=0.04187]
[2020-05-12 11:17:02.366]  Step 159335  [4.251 sec/step, loss=0.07677, avg_loss=0.08731, mel_loss=0.03255, linear_loss=0.04422]
[2020-05-12 11:17:03.383]  Step 159336  [4.246 sec/step, loss=0.07768, avg_loss=0.08726, mel_loss=0.03312, linear_loss=0.04456]
[2020-05-12 11:17:06.878]  Step 159337  [4.265 sec/step, loss=0.09151, avg_loss=0.08732, mel_loss=0.04052, linear_loss=0.05099]
[2020-05-12 11:17:08.098]  Step 159338  [4.203 sec/step, loss=0.08298, avg_loss=0.08718, mel_loss=0.03558, linear_loss=0.04740]
[2020-05-12 11:17:11.783]  Step 159339  [4.205 sec/step, loss=0.09364, avg_loss=0.08721, mel_loss=0.04150, linear_loss=0.05214]
[2020-05-12 11:17:13.972]  Step 159340  [4.182 sec/step, loss=0.08804, avg_loss=0.08714, mel_loss=0.03835, linear_loss=0.04969]
[2020-05-12 11:17:18.165]  Step 159341  [4.214 sec/step, loss=0.09196, avg_loss=0.08725, mel_loss=0.04063, linear_loss=0.05133]
[2020-05-12 11:17:21.039]  Step 159342  [4.194 sec/step, loss=0.09068, avg_loss=0.08722, mel_loss=0.04005, linear_loss=0.05064]
[2020-05-12 11:17:35.300]  Step 159343  [4.312 sec/step, loss=0.07334, avg_loss=0.08708, mel_loss=0.03420, linear_loss=0.03914]
[2020-05-12 11:17:36.969]  Step 159344  [4.302 sec/step, loss=0.08750, avg_loss=0.08709, mel_loss=0.03769, linear_loss=0.04981]
[2020-05-12 11:17:41.769]  Step 159345  [4.199 sec/step, loss=0.09410, avg_loss=0.08725, mel_loss=0.04203, linear_loss=0.05207]
[2020-05-12 11:17:42.906]  Step 159346  [4.139 sec/step, loss=0.08126, avg_loss=0.08712, mel_loss=0.03460, linear_loss=0.04666]
[2020-05-12 11:17:43.679]  Step 159347  [4.104 sec/step, loss=0.07358, avg_loss=0.08693, mel_loss=0.03152, linear_loss=0.04206]
[2020-05-12 11:17:47.952]  Step 159348  [4.126 sec/step, loss=0.09503, avg_loss=0.08700, mel_loss=0.04240, linear_loss=0.05263]
[2020-05-12 11:17:50.714]  Step 159349  [4.148 sec/step, loss=0.08976, avg_loss=0.08722, mel_loss=0.03949, linear_loss=0.05028]
[2020-05-12 11:17:52.144]  Step 159350  [4.122 sec/step, loss=0.08402, avg_loss=0.08712, mel_loss=0.03620, linear_loss=0.04782]
[2020-05-12 11:17:52.144]  Writing summary at step: 159350
[2020-05-12 11:17:54.467]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159350
[2020-05-12 11:17:56.091]  Saving audio and alignment...
[2020-05-12 11:18:04.482]  Input: 자 그런가 하면 지킬앤하이드는 뮤지컬 역사상 가장 아름다운 스릴러라고 불리는 작품이죠~____________
[2020-05-12 11:18:21.927]  Generated 32 batches of size 32 in 46.622 sec
[2020-05-12 11:18:23.909]  Step 159351  [4.281 sec/step, loss=0.08637, avg_loss=0.08704, mel_loss=0.03732, linear_loss=0.04905]
[2020-05-12 11:18:28.606]  Step 159352  [4.238 sec/step, loss=0.09424, avg_loss=0.08703, mel_loss=0.04200, linear_loss=0.05225]
[2020-05-12 11:18:29.412]  Step 159353  [4.235 sec/step, loss=0.07031, avg_loss=0.08690, mel_loss=0.02980, linear_loss=0.04051]
[2020-05-12 11:18:32.908]  Step 159354  [4.261 sec/step, loss=0.09196, avg_loss=0.08710, mel_loss=0.04060, linear_loss=0.05136]
[2020-05-12 11:18:40.504]  Step 159355  [4.324 sec/step, loss=0.09545, avg_loss=0.08726, mel_loss=0.04356, linear_loss=0.05189]
[2020-05-12 11:18:49.500]  Step 159356  [4.404 sec/step, loss=0.09194, avg_loss=0.08740, mel_loss=0.04224, linear_loss=0.04971]
[2020-05-12 11:18:52.432]  Step 159357  [4.375 sec/step, loss=0.09039, avg_loss=0.08734, mel_loss=0.03964, linear_loss=0.05074]
[2020-05-12 11:18:56.070]  Step 159358  [4.398 sec/step, loss=0.09656, avg_loss=0.08747, mel_loss=0.04297, linear_loss=0.05360]
[2020-05-12 11:18:57.434]  Step 159359  [3.793 sec/step, loss=0.08228, avg_loss=0.08746, mel_loss=0.03502, linear_loss=0.04726]
[2020-05-12 11:18:58.673]  Step 159360  [3.729 sec/step, loss=0.08146, avg_loss=0.08732, mel_loss=0.03496, linear_loss=0.04650]
[2020-05-12 11:19:13.208]  Step 159361  [3.843 sec/step, loss=0.07539, avg_loss=0.08716, mel_loss=0.03557, linear_loss=0.03982]
[2020-05-12 11:19:15.501]  Step 159362  [3.813 sec/step, loss=0.08831, avg_loss=0.08711, mel_loss=0.03888, linear_loss=0.04943]
[2020-05-12 11:19:19.857]  Step 159363  [3.791 sec/step, loss=0.09456, avg_loss=0.08710, mel_loss=0.04205, linear_loss=0.05251]
[2020-05-12 11:19:21.508]  Step 159364  [3.795 sec/step, loss=0.08385, avg_loss=0.08710, mel_loss=0.03615, linear_loss=0.04770]
[2020-05-12 11:19:22.923]  Step 159365  [3.765 sec/step, loss=0.08384, avg_loss=0.08701, mel_loss=0.03615, linear_loss=0.04769]
[2020-05-12 11:19:24.565]  Step 159366  [3.766 sec/step, loss=0.08689, avg_loss=0.08701, mel_loss=0.03739, linear_loss=0.04951]
[2020-05-12 11:19:27.221]  Step 159367  [3.751 sec/step, loss=0.08856, avg_loss=0.08697, mel_loss=0.03901, linear_loss=0.04954]
[2020-05-12 11:19:31.036]  Step 159368  [3.770 sec/step, loss=0.09322, avg_loss=0.08703, mel_loss=0.04121, linear_loss=0.05202]
[2020-05-12 11:19:31.857]  Step 159369  [3.720 sec/step, loss=0.07663, avg_loss=0.08684, mel_loss=0.03244, linear_loss=0.04419]
[2020-05-12 11:19:32.892]  Step 159370  [3.702 sec/step, loss=0.08091, avg_loss=0.08674, mel_loss=0.03438, linear_loss=0.04653]
[2020-05-12 11:19:41.455]  Step 159371  [3.753 sec/step, loss=0.09564, avg_loss=0.08677, mel_loss=0.04341, linear_loss=0.05224]
[2020-05-12 11:19:44.515]  Step 159372  [3.652 sec/step, loss=0.08808, avg_loss=0.08683, mel_loss=0.03844, linear_loss=0.04964]
[2020-05-12 11:19:46.362]  Step 159373  [3.660 sec/step, loss=0.08735, avg_loss=0.08691, mel_loss=0.03745, linear_loss=0.04990]
[2020-05-12 11:19:47.384]  Step 159374  [3.646 sec/step, loss=0.08082, avg_loss=0.08684, mel_loss=0.03401, linear_loss=0.04681]
[2020-05-12 11:19:48.514]  Step 159375  [3.635 sec/step, loss=0.08030, avg_loss=0.08675, mel_loss=0.03387, linear_loss=0.04643]
[2020-05-12 11:19:54.477]  Step 159376  [3.685 sec/step, loss=0.09508, avg_loss=0.08691, mel_loss=0.04276, linear_loss=0.05232]
[2020-05-12 11:19:55.244]  Step 159377  [3.656 sec/step, loss=0.07050, avg_loss=0.08668, mel_loss=0.03106, linear_loss=0.03945]
[2020-05-12 11:19:57.297]  Step 159378  [3.660 sec/step, loss=0.08878, avg_loss=0.08670, mel_loss=0.03845, linear_loss=0.05033]
[2020-05-12 11:20:02.615]  Step 159379  [3.707 sec/step, loss=0.09540, avg_loss=0.08698, mel_loss=0.04290, linear_loss=0.05250]
[2020-05-12 11:20:04.946]  Generated 32 batches of size 32 in 18.579 sec
[2020-05-12 11:20:06.096]  Step 159380  [3.708 sec/step, loss=0.09314, avg_loss=0.08700, mel_loss=0.04117, linear_loss=0.05198]
[2020-05-12 11:20:08.184]  Step 159381  [3.701 sec/step, loss=0.09052, avg_loss=0.08701, mel_loss=0.03958, linear_loss=0.05094]
[2020-05-12 11:20:11.387]  Step 159382  [3.724 sec/step, loss=0.09359, avg_loss=0.08717, mel_loss=0.04138, linear_loss=0.05221]
[2020-05-12 11:20:13.870]  Step 159383  [3.656 sec/step, loss=0.08896, avg_loss=0.08712, mel_loss=0.03855, linear_loss=0.05040]
[2020-05-12 11:20:17.319]  Step 159384  [3.685 sec/step, loss=0.09201, avg_loss=0.08730, mel_loss=0.04089, linear_loss=0.05111]
[2020-05-12 11:20:21.943]  Step 159385  [3.713 sec/step, loss=0.09532, avg_loss=0.08738, mel_loss=0.04278, linear_loss=0.05254]
[2020-05-12 11:20:23.154]  Step 159386  [3.700 sec/step, loss=0.08283, avg_loss=0.08732, mel_loss=0.03556, linear_loss=0.04727]
[2020-05-12 11:20:28.917]  Step 159387  [3.746 sec/step, loss=0.09454, avg_loss=0.08744, mel_loss=0.04276, linear_loss=0.05178]
[2020-05-12 11:20:31.970]  Step 159388  [3.728 sec/step, loss=0.09180, avg_loss=0.08741, mel_loss=0.04041, linear_loss=0.05139]
[2020-05-12 11:20:34.184]  Step 159389  [3.728 sec/step, loss=0.08788, avg_loss=0.08742, mel_loss=0.03839, linear_loss=0.04949]
[2020-05-12 11:20:35.280]  Step 159390  [3.731 sec/step, loss=0.08097, avg_loss=0.08747, mel_loss=0.03435, linear_loss=0.04662]
[2020-05-12 11:20:42.012]  Step 159391  [3.491 sec/step, loss=0.09332, avg_loss=0.08747, mel_loss=0.04219, linear_loss=0.05113]
[2020-05-12 11:20:43.010]  Step 159392  [3.487 sec/step, loss=0.08095, avg_loss=0.08746, mel_loss=0.03435, linear_loss=0.04660]
[2020-05-12 11:20:45.774]  Step 159393  [3.489 sec/step, loss=0.09018, avg_loss=0.08746, mel_loss=0.03964, linear_loss=0.05054]
[2020-05-12 11:20:49.893]  Step 159394  [3.513 sec/step, loss=0.09452, avg_loss=0.08753, mel_loss=0.04191, linear_loss=0.05261]
[2020-05-12 11:21:03.186]  Step 159395  [3.620 sec/step, loss=0.08013, avg_loss=0.08741, mel_loss=0.03737, linear_loss=0.04276]
[2020-05-12 11:21:05.095]  Step 159396  [3.602 sec/step, loss=0.08450, avg_loss=0.08731, mel_loss=0.03632, linear_loss=0.04818]
[2020-05-12 11:21:07.208]  Step 159397  [3.615 sec/step, loss=0.08750, avg_loss=0.08744, mel_loss=0.03789, linear_loss=0.04961]
[2020-05-12 11:21:10.644]  Step 159398  [3.640 sec/step, loss=0.09283, avg_loss=0.08758, mel_loss=0.04094, linear_loss=0.05189]
[2020-05-12 11:21:12.037]  Step 159399  [3.572 sec/step, loss=0.08336, avg_loss=0.08747, mel_loss=0.03591, linear_loss=0.04745]
[2020-05-12 11:21:12.795]  Step 159400  [3.563 sec/step, loss=0.07109, avg_loss=0.08733, mel_loss=0.03042, linear_loss=0.04067]
[2020-05-12 11:21:12.795]  Writing summary at step: 159400
[2020-05-12 11:21:14.134]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159400
[2020-05-12 11:21:15.746]  Saving audio and alignment...
[2020-05-12 11:21:18.959]  Input: 프로 행사 엠씨들은 어떻게 할까요~____
[2020-05-12 11:21:19.881]  Step 159401  [3.553 sec/step, loss=0.07693, avg_loss=0.08723, mel_loss=0.03257, linear_loss=0.04436]
[2020-05-12 11:21:28.304]  Step 159402  [3.592 sec/step, loss=0.09506, avg_loss=0.08723, mel_loss=0.04340, linear_loss=0.05165]
[2020-05-12 11:21:28.875]  Step 159403  [3.584 sec/step, loss=0.06836, avg_loss=0.08709, mel_loss=0.02957, linear_loss=0.03880]
[2020-05-12 11:21:30.473]  Step 159404  [3.578 sec/step, loss=0.08615, avg_loss=0.08706, mel_loss=0.03715, linear_loss=0.04901]
[2020-05-12 11:21:31.480]  Generated 32 batches of size 32 in 2.600 sec
[2020-05-12 11:21:37.526]  Step 159405  [3.629 sec/step, loss=0.09642, avg_loss=0.08713, mel_loss=0.04389, linear_loss=0.05253]
[2020-05-12 11:21:39.574]  Step 159406  [3.615 sec/step, loss=0.08673, avg_loss=0.08705, mel_loss=0.03767, linear_loss=0.04906]
[2020-05-12 11:21:41.976]  Step 159407  [3.623 sec/step, loss=0.08871, avg_loss=0.08707, mel_loss=0.03873, linear_loss=0.04998]
[2020-05-12 11:21:46.135]  Step 159408  [3.654 sec/step, loss=0.09283, avg_loss=0.08718, mel_loss=0.04136, linear_loss=0.05147]
[2020-05-12 11:21:51.159]  Step 159409  [3.654 sec/step, loss=0.09385, avg_loss=0.08719, mel_loss=0.04206, linear_loss=0.05179]
[2020-05-12 11:21:51.982]  Step 159410  [3.650 sec/step, loss=0.07415, avg_loss=0.08712, mel_loss=0.03129, linear_loss=0.04287]
[2020-05-12 11:21:55.671]  Step 159411  [3.557 sec/step, loss=0.09316, avg_loss=0.08726, mel_loss=0.04114, linear_loss=0.05202]
[2020-05-12 11:21:58.588]  Step 159412  [3.562 sec/step, loss=0.09193, avg_loss=0.08730, mel_loss=0.04032, linear_loss=0.05160]
[2020-05-12 11:21:59.612]  Step 159413  [3.500 sec/step, loss=0.07886, avg_loss=0.08713, mel_loss=0.03367, linear_loss=0.04519]
[2020-05-12 11:22:02.121]  Step 159414  [3.483 sec/step, loss=0.08538, avg_loss=0.08704, mel_loss=0.03682, linear_loss=0.04857]
[2020-05-12 11:22:03.528]  Step 159415  [3.439 sec/step, loss=0.08609, avg_loss=0.08696, mel_loss=0.03707, linear_loss=0.04902]
[2020-05-12 11:22:05.157]  Step 159416  [3.421 sec/step, loss=0.08537, avg_loss=0.08689, mel_loss=0.03692, linear_loss=0.04844]
[2020-05-12 11:22:06.759]  Step 159417  [3.372 sec/step, loss=0.08767, avg_loss=0.08682, mel_loss=0.03782, linear_loss=0.04985]
[2020-05-12 11:22:13.795]  Step 159418  [3.432 sec/step, loss=0.09635, avg_loss=0.08700, mel_loss=0.04359, linear_loss=0.05276]
[2020-05-12 11:22:16.652]  Step 159419  [3.453 sec/step, loss=0.08943, avg_loss=0.08712, mel_loss=0.03945, linear_loss=0.04998]
[2020-05-12 11:22:19.642]  Step 159420  [3.454 sec/step, loss=0.09162, avg_loss=0.08710, mel_loss=0.04020, linear_loss=0.05142]
[2020-05-12 11:22:24.645]  Step 159421  [3.487 sec/step, loss=0.09388, avg_loss=0.08717, mel_loss=0.04204, linear_loss=0.05184]
[2020-05-12 11:22:31.003]  Step 159422  [3.518 sec/step, loss=0.09331, avg_loss=0.08718, mel_loss=0.04212, linear_loss=0.05119]
[2020-05-12 11:22:32.162]  Step 159423  [3.455 sec/step, loss=0.07735, avg_loss=0.08700, mel_loss=0.03263, linear_loss=0.04473]
[2020-05-12 11:22:34.423]  Step 159424  [3.458 sec/step, loss=0.08683, avg_loss=0.08698, mel_loss=0.03802, linear_loss=0.04881]
[2020-05-12 11:22:39.028]  Step 159425  [3.451 sec/step, loss=0.09525, avg_loss=0.08700, mel_loss=0.04241, linear_loss=0.05284]
[2020-05-12 11:22:40.057]  Step 159426  [3.378 sec/step, loss=0.07879, avg_loss=0.08686, mel_loss=0.03300, linear_loss=0.04579]
[2020-05-12 11:22:41.282]  Step 159427  [3.377 sec/step, loss=0.08310, avg_loss=0.08685, mel_loss=0.03545, linear_loss=0.04765]
[2020-05-12 11:22:43.297]  Step 159428  [3.367 sec/step, loss=0.08908, avg_loss=0.08681, mel_loss=0.03879, linear_loss=0.05029]
[2020-05-12 11:22:45.992]  Step 159429  [3.333 sec/step, loss=0.08999, avg_loss=0.08678, mel_loss=0.03951, linear_loss=0.05048]
[2020-05-12 11:22:49.627]  Step 159430  [3.349 sec/step, loss=0.09408, avg_loss=0.08684, mel_loss=0.04177, linear_loss=0.05231]
[2020-05-12 11:22:53.014]  Step 159431  [3.359 sec/step, loss=0.09118, avg_loss=0.08685, mel_loss=0.04031, linear_loss=0.05087]
[2020-05-12 11:22:54.778]  Step 159432  [3.371 sec/step, loss=0.08588, avg_loss=0.08698, mel_loss=0.03704, linear_loss=0.04884]
[2020-05-12 11:22:57.998]  Step 159433  [3.388 sec/step, loss=0.09410, avg_loss=0.08708, mel_loss=0.04139, linear_loss=0.05270]
[2020-05-12 11:23:02.331]  Step 159434  [3.423 sec/step, loss=0.09297, avg_loss=0.08728, mel_loss=0.04116, linear_loss=0.05181]
[2020-05-12 11:23:03.683]  Step 159435  [3.428 sec/step, loss=0.08315, avg_loss=0.08734, mel_loss=0.03567, linear_loss=0.04748]
[2020-05-12 11:23:05.620]  Generated 32 batches of size 32 in 1.932 sec
[2020-05-12 11:23:05.914]  Step 159436  [3.440 sec/step, loss=0.08947, avg_loss=0.08746, mel_loss=0.03880, linear_loss=0.05067]
[2020-05-12 11:23:09.953]  Step 159437  [3.445 sec/step, loss=0.09332, avg_loss=0.08748, mel_loss=0.04131, linear_loss=0.05200]
[2020-05-12 11:23:10.620]  Step 159438  [3.440 sec/step, loss=0.07343, avg_loss=0.08738, mel_loss=0.03162, linear_loss=0.04181]
[2020-05-12 11:23:19.468]  Step 159439  [3.492 sec/step, loss=0.09167, avg_loss=0.08736, mel_loss=0.04180, linear_loss=0.04987]
[2020-05-12 11:23:21.966]  Step 159440  [3.495 sec/step, loss=0.08875, avg_loss=0.08737, mel_loss=0.03884, linear_loss=0.04991]
[2020-05-12 11:23:27.552]  Step 159441  [3.509 sec/step, loss=0.09440, avg_loss=0.08739, mel_loss=0.04220, linear_loss=0.05220]
[2020-05-12 11:23:28.113]  Step 159442  [3.485 sec/step, loss=0.06603, avg_loss=0.08715, mel_loss=0.02856, linear_loss=0.03747]
[2020-05-12 11:23:40.089]  Step 159443  [3.463 sec/step, loss=0.08368, avg_loss=0.08725, mel_loss=0.03888, linear_loss=0.04480]
[2020-05-12 11:23:40.922]  Step 159444  [3.454 sec/step, loss=0.07498, avg_loss=0.08712, mel_loss=0.03170, linear_loss=0.04327]
[2020-05-12 11:23:49.795]  Step 159445  [3.495 sec/step, loss=0.09270, avg_loss=0.08711, mel_loss=0.04232, linear_loss=0.05038]
[2020-05-12 11:23:51.131]  Step 159446  [3.497 sec/step, loss=0.08180, avg_loss=0.08712, mel_loss=0.03479, linear_loss=0.04701]
[2020-05-12 11:23:58.750]  Step 159447  [3.565 sec/step, loss=0.09463, avg_loss=0.08733, mel_loss=0.04311, linear_loss=0.05152]
[2020-05-12 11:24:00.471]  Step 159448  [3.540 sec/step, loss=0.08747, avg_loss=0.08725, mel_loss=0.03772, linear_loss=0.04975]
[2020-05-12 11:24:01.574]  Step 159449  [3.523 sec/step, loss=0.08088, avg_loss=0.08716, mel_loss=0.03439, linear_loss=0.04649]
[2020-05-12 11:24:02.981]  Step 159450  [3.523 sec/step, loss=0.08376, avg_loss=0.08716, mel_loss=0.03618, linear_loss=0.04758]
[2020-05-12 11:24:02.981]  Writing summary at step: 159450
[2020-05-12 11:24:03.744]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159450
[2020-05-12 11:24:05.403]  Saving audio and alignment...
[2020-05-12 11:24:07.032]  Input: 그리고~____________________________
[2020-05-12 11:24:21.849]  Step 159451  [3.477 sec/step, loss=0.07753, avg_loss=0.08707, mel_loss=0.03635, linear_loss=0.04119]
[2020-05-12 11:24:23.917]  Step 159452  [3.451 sec/step, loss=0.08693, avg_loss=0.08700, mel_loss=0.03757, linear_loss=0.04935]
[2020-05-12 11:24:27.086]  Step 159453  [3.474 sec/step, loss=0.09247, avg_loss=0.08722, mel_loss=0.04093, linear_loss=0.05155]
[2020-05-12 11:24:28.122]  Step 159454  [3.450 sec/step, loss=0.07768, avg_loss=0.08708, mel_loss=0.03355, linear_loss=0.04413]
[2020-05-12 11:24:34.873]  Step 159455  [3.441 sec/step, loss=0.09570, avg_loss=0.08708, mel_loss=0.04319, linear_loss=0.05251]
[2020-05-12 11:24:39.367]  Step 159456  [3.396 sec/step, loss=0.09543, avg_loss=0.08711, mel_loss=0.04285, linear_loss=0.05258]
[2020-05-12 11:24:42.417]  Step 159457  [3.397 sec/step, loss=0.09249, avg_loss=0.08714, mel_loss=0.04047, linear_loss=0.05202]
[2020-05-12 11:24:44.256]  Step 159458  [3.379 sec/step, loss=0.08674, avg_loss=0.08704, mel_loss=0.03740, linear_loss=0.04935]
[2020-05-12 11:24:45.152]  Step 159459  [3.375 sec/step, loss=0.07568, avg_loss=0.08697, mel_loss=0.03197, linear_loss=0.04372]
[2020-05-12 11:24:45.728]  Step 159460  [3.368 sec/step, loss=0.06988, avg_loss=0.08686, mel_loss=0.03065, linear_loss=0.03923]
[2020-05-12 11:24:50.454]  Step 159461  [3.270 sec/step, loss=0.09542, avg_loss=0.08706, mel_loss=0.04249, linear_loss=0.05293]
[2020-05-12 11:24:53.204]  Step 159462  [3.275 sec/step, loss=0.09038, avg_loss=0.08708, mel_loss=0.03968, linear_loss=0.05070]
[2020-05-12 11:24:58.941]  Step 159463  [3.288 sec/step, loss=0.09448, avg_loss=0.08708, mel_loss=0.04272, linear_loss=0.05177]
[2020-05-12 11:25:04.341]  Step 159464  [3.326 sec/step, loss=0.09497, avg_loss=0.08719, mel_loss=0.04259, linear_loss=0.05238]
[2020-05-12 11:25:08.105]  Step 159465  [3.349 sec/step, loss=0.09394, avg_loss=0.08729, mel_loss=0.04168, linear_loss=0.05226]
[2020-05-12 11:25:11.612]  Step 159466  [3.368 sec/step, loss=0.09248, avg_loss=0.08734, mel_loss=0.04092, linear_loss=0.05157]
[2020-05-12 11:25:13.853]  Step 159467  [3.364 sec/step, loss=0.08761, avg_loss=0.08733, mel_loss=0.03836, linear_loss=0.04924]
[2020-05-12 11:25:15.066]  Step 159468  [3.338 sec/step, loss=0.08316, avg_loss=0.08723, mel_loss=0.03570, linear_loss=0.04746]
[2020-05-12 11:25:16.656]  Step 159469  [3.346 sec/step, loss=0.08395, avg_loss=0.08731, mel_loss=0.03626, linear_loss=0.04768]
[2020-05-12 11:25:20.208]  Step 159470  [3.371 sec/step, loss=0.09241, avg_loss=0.08742, mel_loss=0.04098, linear_loss=0.05143]
[2020-05-12 11:25:24.465]  Step 159471  [3.328 sec/step, loss=0.09349, avg_loss=0.08740, mel_loss=0.04144, linear_loss=0.05205]
[2020-05-12 11:25:26.860]  Step 159472  [3.321 sec/step, loss=0.08850, avg_loss=0.08740, mel_loss=0.03850, linear_loss=0.05000]
[2020-05-12 11:25:29.521]  Step 159473  [3.329 sec/step, loss=0.08753, avg_loss=0.08741, mel_loss=0.03812, linear_loss=0.04941]
[2020-05-12 11:25:31.482]  Step 159474  [3.339 sec/step, loss=0.08765, avg_loss=0.08747, mel_loss=0.03799, linear_loss=0.04965]
[2020-05-12 11:26:27.910]  Generated 32 batches of size 32 in 79.799 sec
[2020-05-12 11:26:30.495]  Step 159475  [3.917 sec/step, loss=0.08730, avg_loss=0.08754, mel_loss=0.03783, linear_loss=0.04946]
[2020-05-12 11:26:31.162]  Step 159476  [3.864 sec/step, loss=0.07096, avg_loss=0.08730, mel_loss=0.03056, linear_loss=0.04040]
[2020-05-12 11:26:34.276]  Step 159477  [3.888 sec/step, loss=0.09376, avg_loss=0.08754, mel_loss=0.04163, linear_loss=0.05213]
[2020-05-12 11:26:35.514]  Step 159478  [3.880 sec/step, loss=0.07993, avg_loss=0.08745, mel_loss=0.03404, linear_loss=0.04589]
[2020-05-12 11:26:36.084]  Step 159479  [3.832 sec/step, loss=0.06951, avg_loss=0.08719, mel_loss=0.02977, linear_loss=0.03974]
[2020-05-12 11:26:40.969]  Step 159480  [3.846 sec/step, loss=0.09425, avg_loss=0.08720, mel_loss=0.04205, linear_loss=0.05220]
[2020-05-12 11:26:44.463]  Step 159481  [3.860 sec/step, loss=0.09231, avg_loss=0.08722, mel_loss=0.04103, linear_loss=0.05127]
[2020-05-12 11:26:46.067]  Step 159482  [3.844 sec/step, loss=0.08401, avg_loss=0.08712, mel_loss=0.03648, linear_loss=0.04753]
[2020-05-12 11:26:55.067]  Step 159483  [3.910 sec/step, loss=0.09536, avg_loss=0.08719, mel_loss=0.04366, linear_loss=0.05170]
[2020-05-12 11:26:55.868]  Step 159484  [3.883 sec/step, loss=0.07521, avg_loss=0.08702, mel_loss=0.03186, linear_loss=0.04335]
[2020-05-12 11:26:58.783]  Step 159485  [3.866 sec/step, loss=0.09040, avg_loss=0.08697, mel_loss=0.03996, linear_loss=0.05044]
[2020-05-12 11:27:02.961]  Step 159486  [3.896 sec/step, loss=0.09325, avg_loss=0.08707, mel_loss=0.04141, linear_loss=0.05184]
[2020-05-12 11:27:03.963]  Step 159487  [3.848 sec/step, loss=0.07813, avg_loss=0.08691, mel_loss=0.03337, linear_loss=0.04476]
[2020-05-12 11:27:11.415]  Step 159488  [3.892 sec/step, loss=0.09629, avg_loss=0.08695, mel_loss=0.04372, linear_loss=0.05257]
[2020-05-12 11:27:12.419]  Step 159489  [3.880 sec/step, loss=0.07770, avg_loss=0.08685, mel_loss=0.03283, linear_loss=0.04487]
[2020-05-12 11:27:18.409]  Step 159490  [3.929 sec/step, loss=0.09418, avg_loss=0.08698, mel_loss=0.04251, linear_loss=0.05167]
[2020-05-12 11:27:20.177]  Step 159491  [3.879 sec/step, loss=0.08763, avg_loss=0.08693, mel_loss=0.03778, linear_loss=0.04985]
[2020-05-12 11:27:24.609]  Step 159492  [3.914 sec/step, loss=0.09285, avg_loss=0.08705, mel_loss=0.04147, linear_loss=0.05139]
[2020-05-12 11:27:26.536]  Step 159493  [3.905 sec/step, loss=0.08716, avg_loss=0.08702, mel_loss=0.03761, linear_loss=0.04955]
[2020-05-12 11:27:28.918]  Step 159494  [3.888 sec/step, loss=0.08984, avg_loss=0.08697, mel_loss=0.03924, linear_loss=0.05060]
[2020-05-12 11:27:30.025]  Step 159495  [3.766 sec/step, loss=0.08111, avg_loss=0.08698, mel_loss=0.03469, linear_loss=0.04642]
[2020-05-12 11:27:31.752]  Step 159496  [3.764 sec/step, loss=0.08621, avg_loss=0.08700, mel_loss=0.03730, linear_loss=0.04891]
[2020-05-12 11:27:43.588]  Step 159497  [3.861 sec/step, loss=0.09056, avg_loss=0.08703, mel_loss=0.04251, linear_loss=0.04805]
[2020-05-12 11:27:45.775]  Step 159498  [3.849 sec/step, loss=0.08905, avg_loss=0.08699, mel_loss=0.03880, linear_loss=0.05025]
[2020-05-12 11:27:48.416]  Step 159499  [3.861 sec/step, loss=0.09089, avg_loss=0.08706, mel_loss=0.03988, linear_loss=0.05101]
[2020-05-12 11:27:49.818]  Step 159500  [3.868 sec/step, loss=0.08350, avg_loss=0.08719, mel_loss=0.03578, linear_loss=0.04772]
[2020-05-12 11:27:49.818]  Writing summary at step: 159500
[2020-05-12 11:27:55.375]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159500
[2020-05-12 11:27:57.015]  Saving audio and alignment...
[2020-05-12 11:28:06.556]  Input: 또한 오시는 동안 심한 기류 변화로 비행기가 많이 흔들렸던 점 양해해 주시기 바랍니다~______________________________________
[2020-05-12 11:28:08.603]  Step 159501  [3.879 sec/step, loss=0.08814, avg_loss=0.08730, mel_loss=0.03814, linear_loss=0.05000]
[2020-05-12 11:28:12.114]  Step 159502  [3.830 sec/step, loss=0.09187, avg_loss=0.08727, mel_loss=0.04054, linear_loss=0.05133]
[2020-05-12 11:28:15.842]  Step 159503  [3.862 sec/step, loss=0.09362, avg_loss=0.08752, mel_loss=0.04143, linear_loss=0.05219]
[2020-05-12 11:28:17.163]  Step 159504  [3.859 sec/step, loss=0.08460, avg_loss=0.08751, mel_loss=0.03628, linear_loss=0.04831]
[2020-05-12 11:28:35.415]  Generated 32 batches of size 32 in 51.822 sec
[2020-05-12 11:28:37.804]  Step 159505  [3.995 sec/step, loss=0.08944, avg_loss=0.08744, mel_loss=0.03897, linear_loss=0.05047]
[2020-05-12 11:28:38.686]  Step 159506  [3.983 sec/step, loss=0.06912, avg_loss=0.08726, mel_loss=0.02952, linear_loss=0.03960]
[2020-05-12 11:28:39.796]  Step 159507  [3.970 sec/step, loss=0.08095, avg_loss=0.08718, mel_loss=0.03426, linear_loss=0.04669]
[2020-05-12 11:28:43.267]  Step 159508  [3.963 sec/step, loss=0.09043, avg_loss=0.08716, mel_loss=0.03989, linear_loss=0.05054]
[2020-05-12 11:28:45.638]  Step 159509  [3.937 sec/step, loss=0.08899, avg_loss=0.08711, mel_loss=0.03910, linear_loss=0.04989]
[2020-05-12 11:28:47.618]  Step 159510  [3.948 sec/step, loss=0.08625, avg_loss=0.08723, mel_loss=0.03733, linear_loss=0.04892]
[2020-05-12 11:28:49.368]  Step 159511  [3.929 sec/step, loss=0.08610, avg_loss=0.08716, mel_loss=0.03686, linear_loss=0.04924]
[2020-05-12 11:28:50.598]  Step 159512  [3.912 sec/step, loss=0.07989, avg_loss=0.08704, mel_loss=0.03400, linear_loss=0.04589]
[2020-05-12 11:28:51.582]  Step 159513  [3.912 sec/step, loss=0.07901, avg_loss=0.08704, mel_loss=0.03323, linear_loss=0.04578]
[2020-05-12 11:28:53.193]  Step 159514  [3.903 sec/step, loss=0.08639, avg_loss=0.08705, mel_loss=0.03732, linear_loss=0.04907]
[2020-05-12 11:28:58.540]  Step 159515  [3.942 sec/step, loss=0.09505, avg_loss=0.08714, mel_loss=0.04289, linear_loss=0.05216]
[2020-05-12 11:28:59.109]  Step 159516  [3.931 sec/step, loss=0.06708, avg_loss=0.08696, mel_loss=0.02950, linear_loss=0.03758]
[2020-05-12 11:29:02.765]  Step 159517  [3.952 sec/step, loss=0.09395, avg_loss=0.08702, mel_loss=0.04182, linear_loss=0.05213]
[2020-05-12 11:29:05.886]  Step 159518  [3.913 sec/step, loss=0.09287, avg_loss=0.08698, mel_loss=0.04098, linear_loss=0.05190]
[2020-05-12 11:29:10.695]  Step 159519  [3.932 sec/step, loss=0.09264, avg_loss=0.08702, mel_loss=0.04111, linear_loss=0.05153]
[2020-05-12 11:29:14.398]  Step 159520  [3.939 sec/step, loss=0.09462, avg_loss=0.08705, mel_loss=0.04197, linear_loss=0.05265]
[2020-05-12 11:29:17.127]  Step 159521  [3.917 sec/step, loss=0.08919, avg_loss=0.08700, mel_loss=0.03901, linear_loss=0.05018]
[2020-05-12 11:29:18.514]  Step 159522  [3.867 sec/step, loss=0.08323, avg_loss=0.08690, mel_loss=0.03581, linear_loss=0.04742]
[2020-05-12 11:29:20.761]  Step 159523  [3.878 sec/step, loss=0.08968, avg_loss=0.08702, mel_loss=0.03894, linear_loss=0.05073]
[2020-05-12 11:29:21.814]  Step 159524  [3.866 sec/step, loss=0.07745, avg_loss=0.08693, mel_loss=0.03288, linear_loss=0.04456]
[2020-05-12 11:29:30.008]  Step 159525  [3.902 sec/step, loss=0.09223, avg_loss=0.08690, mel_loss=0.04219, linear_loss=0.05004]
[2020-05-12 11:29:34.053]  Step 159526  [3.932 sec/step, loss=0.09386, avg_loss=0.08705, mel_loss=0.04162, linear_loss=0.05224]
[2020-05-12 11:29:35.632]  Step 159527  [3.935 sec/step, loss=0.08582, avg_loss=0.08708, mel_loss=0.03700, linear_loss=0.04882]
[2020-05-12 11:29:40.102]  Step 159528  [3.960 sec/step, loss=0.09573, avg_loss=0.08714, mel_loss=0.04268, linear_loss=0.05304]
[2020-05-12 11:29:44.346]  Generated 32 batches of size 32 in 8.710 sec
[2020-05-12 11:29:56.538]  Step 159529  [4.097 sec/step, loss=0.07796, avg_loss=0.08702, mel_loss=0.03609, linear_loss=0.04187]
[2020-05-12 11:30:02.461]  Step 159530  [4.120 sec/step, loss=0.09532, avg_loss=0.08704, mel_loss=0.04310, linear_loss=0.05222]
[2020-05-12 11:30:05.406]  Step 159531  [4.116 sec/step, loss=0.08772, avg_loss=0.08700, mel_loss=0.03855, linear_loss=0.04917]
[2020-05-12 11:30:08.616]  Step 159532  [4.130 sec/step, loss=0.09296, avg_loss=0.08707, mel_loss=0.04088, linear_loss=0.05209]
[2020-05-12 11:30:10.690]  Step 159533  [4.119 sec/step, loss=0.08600, avg_loss=0.08699, mel_loss=0.03741, linear_loss=0.04859]
[2020-05-12 11:30:12.067]  Step 159534  [4.089 sec/step, loss=0.08350, avg_loss=0.08690, mel_loss=0.03628, linear_loss=0.04722]
[2020-05-12 11:30:19.479]  Step 159535  [4.150 sec/step, loss=0.09423, avg_loss=0.08701, mel_loss=0.04283, linear_loss=0.05141]
[2020-05-12 11:30:20.281]  Step 159536  [4.136 sec/step, loss=0.07460, avg_loss=0.08686, mel_loss=0.03142, linear_loss=0.04318]
[2020-05-12 11:30:21.271]  Step 159537  [4.105 sec/step, loss=0.08070, avg_loss=0.08673, mel_loss=0.03436, linear_loss=0.04634]
[2020-05-12 11:30:26.487]  Step 159538  [4.151 sec/step, loss=0.09290, avg_loss=0.08693, mel_loss=0.04172, linear_loss=0.05118]
[2020-05-12 11:30:35.281]  Step 159539  [4.150 sec/step, loss=0.09235, avg_loss=0.08693, mel_loss=0.04217, linear_loss=0.05018]
[2020-05-12 11:30:38.142]  Step 159540  [4.154 sec/step, loss=0.08889, avg_loss=0.08693, mel_loss=0.03901, linear_loss=0.04987]
[2020-05-12 11:30:39.220]  Step 159541  [4.109 sec/step, loss=0.08143, avg_loss=0.08680, mel_loss=0.03466, linear_loss=0.04677]
[2020-05-12 11:30:43.555]  Step 159542  [4.146 sec/step, loss=0.09097, avg_loss=0.08705, mel_loss=0.04034, linear_loss=0.05063]
[2020-05-12 11:30:44.979]  Step 159543  [4.041 sec/step, loss=0.08115, avg_loss=0.08703, mel_loss=0.03488, linear_loss=0.04628]
[2020-05-12 11:30:46.623]  Step 159544  [4.049 sec/step, loss=0.08480, avg_loss=0.08713, mel_loss=0.03671, linear_loss=0.04810]
[2020-05-12 11:30:49.092]  Step 159545  [3.985 sec/step, loss=0.08894, avg_loss=0.08709, mel_loss=0.03884, linear_loss=0.05010]
[2020-05-12 11:30:52.595]  Step 159546  [4.007 sec/step, loss=0.09257, avg_loss=0.08720, mel_loss=0.04105, linear_loss=0.05152]
[2020-05-12 11:30:56.368]  Step 159547  [3.968 sec/step, loss=0.09367, avg_loss=0.08719, mel_loss=0.04148, linear_loss=0.05219]
[2020-05-12 11:30:57.694]  Step 159548  [3.964 sec/step, loss=0.08245, avg_loss=0.08714, mel_loss=0.03510, linear_loss=0.04735]
[2020-05-12 11:31:00.390]  Step 159549  [3.980 sec/step, loss=0.08889, avg_loss=0.08722, mel_loss=0.03889, linear_loss=0.05000]
[2020-05-12 11:31:02.412]  Step 159550  [3.986 sec/step, loss=0.08634, avg_loss=0.08724, mel_loss=0.03743, linear_loss=0.04891]
[2020-05-12 11:31:02.412]  Writing summary at step: 159550
[2020-05-12 11:31:06.006]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159550
[2020-05-12 11:31:07.656]  Saving audio and alignment...
[2020-05-12 11:31:10.078]  Input: 작게 띄우셔도 돼요~_________
[2020-05-12 11:31:15.760]  Step 159551  [3.895 sec/step, loss=0.09417, avg_loss=0.08741, mel_loss=0.04229, linear_loss=0.05187]
[2020-05-12 11:31:16.337]  Step 159552  [3.880 sec/step, loss=0.06557, avg_loss=0.08720, mel_loss=0.02833, linear_loss=0.03725]
[2020-05-12 11:31:24.003]  Step 159553  [3.925 sec/step, loss=0.09494, avg_loss=0.08722, mel_loss=0.04320, linear_loss=0.05174]
[2020-05-12 11:31:26.254]  Step 159554  [3.937 sec/step, loss=0.08891, avg_loss=0.08733, mel_loss=0.03852, linear_loss=0.05040]
[2020-05-12 11:31:31.240]  Step 159555  [3.919 sec/step, loss=0.09400, avg_loss=0.08732, mel_loss=0.04210, linear_loss=0.05190]
[2020-05-12 11:31:32.828]  Step 159556  [3.890 sec/step, loss=0.08586, avg_loss=0.08722, mel_loss=0.03683, linear_loss=0.04902]
[2020-05-12 11:31:33.624]  Step 159557  [3.868 sec/step, loss=0.07583, avg_loss=0.08705, mel_loss=0.03221, linear_loss=0.04362]
[2020-05-12 11:31:36.590]  Step 159558  [3.879 sec/step, loss=0.09250, avg_loss=0.08711, mel_loss=0.04068, linear_loss=0.05182]
[2020-05-12 11:31:37.375]  Step 159559  [3.878 sec/step, loss=0.07411, avg_loss=0.08710, mel_loss=0.03157, linear_loss=0.04254]
[2020-05-12 11:31:40.462]  Step 159560  [3.903 sec/step, loss=0.09431, avg_loss=0.08734, mel_loss=0.04172, linear_loss=0.05259]
[2020-05-12 11:31:42.280]  Step 159561  [3.874 sec/step, loss=0.08770, avg_loss=0.08726, mel_loss=0.03765, linear_loss=0.05004]
[2020-05-12 11:31:56.911]  Step 159562  [3.993 sec/step, loss=0.07427, avg_loss=0.08710, mel_loss=0.03477, linear_loss=0.03950]
[2020-05-12 11:31:57.799]  Step 159563  [3.944 sec/step, loss=0.07772, avg_loss=0.08693, mel_loss=0.03266, linear_loss=0.04506]
[2020-05-12 11:31:59.584]  Step 159564  [3.908 sec/step, loss=0.08473, avg_loss=0.08683, mel_loss=0.03645, linear_loss=0.04828]
[2020-05-12 11:32:01.871]  Step 159565  [3.893 sec/step, loss=0.08777, avg_loss=0.08677, mel_loss=0.03836, linear_loss=0.04941]
[2020-05-12 11:32:08.114]  Step 159566  [3.921 sec/step, loss=0.09433, avg_loss=0.08679, mel_loss=0.04267, linear_loss=0.05166]
[2020-05-12 11:32:08.625]  Generated 32 batches of size 32 in 34.996 sec
[2020-05-12 11:32:17.259]  Step 159567  [3.990 sec/step, loss=0.09448, avg_loss=0.08686, mel_loss=0.04306, linear_loss=0.05142]
[2020-05-12 11:32:20.784]  Step 159568  [4.013 sec/step, loss=0.09115, avg_loss=0.08694, mel_loss=0.04015, linear_loss=0.05100]
[2020-05-12 11:32:34.013]  Step 159569  [4.129 sec/step, loss=0.08253, avg_loss=0.08692, mel_loss=0.03852, linear_loss=0.04400]
[2020-05-12 11:32:37.008]  Step 159570  [4.124 sec/step, loss=0.09268, avg_loss=0.08693, mel_loss=0.04085, linear_loss=0.05183]
[2020-05-12 11:32:38.997]  Step 159571  [4.101 sec/step, loss=0.08706, avg_loss=0.08686, mel_loss=0.03765, linear_loss=0.04941]
[2020-05-12 11:32:40.748]  Step 159572  [4.095 sec/step, loss=0.08726, avg_loss=0.08685, mel_loss=0.03760, linear_loss=0.04966]
[2020-05-12 11:32:44.433]  Step 159573  [4.105 sec/step, loss=0.09642, avg_loss=0.08694, mel_loss=0.04285, linear_loss=0.05357]
[2020-05-12 11:32:45.682]  Step 159574  [4.098 sec/step, loss=0.07887, avg_loss=0.08685, mel_loss=0.03378, linear_loss=0.04508]
[2020-05-12 11:32:49.711]  Step 159575  [3.548 sec/step, loss=0.09369, avg_loss=0.08691, mel_loss=0.04156, linear_loss=0.05212]
[2020-05-12 11:32:50.284]  Step 159576  [3.547 sec/step, loss=0.06869, avg_loss=0.08689, mel_loss=0.02984, linear_loss=0.03885]
[2020-05-12 11:32:52.365]  Step 159577  [3.537 sec/step, loss=0.08908, avg_loss=0.08684, mel_loss=0.03864, linear_loss=0.05043]
[2020-05-12 11:32:54.190]  Step 159578  [3.542 sec/step, loss=0.08670, avg_loss=0.08691, mel_loss=0.03754, linear_loss=0.04916]
[2020-05-12 11:32:55.870]  Step 159579  [3.554 sec/step, loss=0.08556, avg_loss=0.08707, mel_loss=0.03708, linear_loss=0.04848]
[2020-05-12 11:32:58.552]  Step 159580  [3.532 sec/step, loss=0.09224, avg_loss=0.08705, mel_loss=0.04042, linear_loss=0.05182]
[2020-05-12 11:33:01.932]  Step 159581  [3.530 sec/step, loss=0.09170, avg_loss=0.08705, mel_loss=0.04085, linear_loss=0.05086]
[2020-05-12 11:33:07.707]  Step 159582  [3.572 sec/step, loss=0.09647, avg_loss=0.08717, mel_loss=0.04343, linear_loss=0.05304]
[2020-05-12 11:33:09.200]  Step 159583  [3.497 sec/step, loss=0.08216, avg_loss=0.08704, mel_loss=0.03532, linear_loss=0.04685]
[2020-05-12 11:33:10.001]  Step 159584  [3.497 sec/step, loss=0.07431, avg_loss=0.08703, mel_loss=0.03134, linear_loss=0.04297]
[2020-05-12 11:33:10.862]  Step 159585  [3.476 sec/step, loss=0.07339, avg_loss=0.08686, mel_loss=0.03148, linear_loss=0.04191]
[2020-05-12 11:33:16.232]  Step 159586  [3.488 sec/step, loss=0.09727, avg_loss=0.08690, mel_loss=0.04369, linear_loss=0.05358]
[2020-05-12 11:33:20.716]  Step 159587  [3.523 sec/step, loss=0.09535, avg_loss=0.08707, mel_loss=0.04259, linear_loss=0.05276]
[2020-05-12 11:33:22.903]  Step 159588  [3.471 sec/step, loss=0.08789, avg_loss=0.08699, mel_loss=0.03799, linear_loss=0.04990]
[2020-05-12 11:33:25.361]  Step 159589  [3.485 sec/step, loss=0.08769, avg_loss=0.08709, mel_loss=0.03809, linear_loss=0.04960]
[2020-05-12 11:33:30.343]  Step 159590  [3.475 sec/step, loss=0.09355, avg_loss=0.08708, mel_loss=0.04165, linear_loss=0.05190]
[2020-05-12 11:33:31.375]  Step 159591  [3.468 sec/step, loss=0.07838, avg_loss=0.08699, mel_loss=0.03322, linear_loss=0.04516]
[2020-05-12 11:33:32.540]  Generated 32 batches of size 32 in 7.174 sec
[2020-05-12 11:33:38.276]  Step 159592  [3.492 sec/step, loss=0.09505, avg_loss=0.08701, mel_loss=0.04292, linear_loss=0.05212]
[2020-05-12 11:33:39.640]  Step 159593  [3.487 sec/step, loss=0.08483, avg_loss=0.08699, mel_loss=0.03652, linear_loss=0.04831]
[2020-05-12 11:33:46.922]  Step 159594  [3.536 sec/step, loss=0.09464, avg_loss=0.08704, mel_loss=0.04288, linear_loss=0.05175]
[2020-05-12 11:33:47.961]  Step 159595  [3.535 sec/step, loss=0.07598, avg_loss=0.08699, mel_loss=0.03239, linear_loss=0.04359]
[2020-05-12 11:33:49.071]  Step 159596  [3.529 sec/step, loss=0.08089, avg_loss=0.08693, mel_loss=0.03435, linear_loss=0.04655]
[2020-05-12 11:33:52.163]  Step 159597  [3.441 sec/step, loss=0.09346, avg_loss=0.08696, mel_loss=0.04095, linear_loss=0.05251]
[2020-05-12 11:33:54.716]  Step 159598  [3.445 sec/step, loss=0.08917, avg_loss=0.08696, mel_loss=0.03879, linear_loss=0.05037]
[2020-05-12 11:33:57.485]  Step 159599  [3.446 sec/step, loss=0.08876, avg_loss=0.08694, mel_loss=0.03918, linear_loss=0.04958]
[2020-05-12 11:33:58.844]  Step 159600  [3.446 sec/step, loss=0.08101, avg_loss=0.08692, mel_loss=0.03491, linear_loss=0.04610]
[2020-05-12 11:33:58.844]  Writing summary at step: 159600
[2020-05-12 11:34:00.800]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159600
[2020-05-12 11:34:02.426]  Saving audio and alignment...
[2020-05-12 11:34:04.120]  Input: 아니죠오~__________________________
[2020-05-12 11:34:06.299]  Step 159601  [3.447 sec/step, loss=0.08892, avg_loss=0.08692, mel_loss=0.03869, linear_loss=0.05024]
[2020-05-12 11:34:10.391]  Step 159602  [3.453 sec/step, loss=0.09313, avg_loss=0.08694, mel_loss=0.04114, linear_loss=0.05199]
[2020-05-12 11:34:11.310]  Step 159603  [3.425 sec/step, loss=0.07494, avg_loss=0.08675, mel_loss=0.03163, linear_loss=0.04332]
[2020-05-12 11:34:12.436]  Step 159604  [3.423 sec/step, loss=0.08061, avg_loss=0.08671, mel_loss=0.03425, linear_loss=0.04636]
[2020-05-12 11:34:19.952]  Step 159605  [3.292 sec/step, loss=0.09574, avg_loss=0.08677, mel_loss=0.04360, linear_loss=0.05215]
[2020-05-12 11:34:20.945]  Step 159606  [3.293 sec/step, loss=0.08131, avg_loss=0.08689, mel_loss=0.03475, linear_loss=0.04656]
[2020-05-12 11:34:23.875]  Step 159607  [3.311 sec/step, loss=0.09199, avg_loss=0.08701, mel_loss=0.04058, linear_loss=0.05141]
[2020-05-12 11:34:38.649]  Step 159608  [3.424 sec/step, loss=0.07343, avg_loss=0.08684, mel_loss=0.03425, linear_loss=0.03918]
[2020-05-12 11:34:41.154]  Step 159609  [3.425 sec/step, loss=0.08975, avg_loss=0.08684, mel_loss=0.03907, linear_loss=0.05068]
[2020-05-12 11:34:44.638]  Step 159610  [3.441 sec/step, loss=0.09280, avg_loss=0.08691, mel_loss=0.04114, linear_loss=0.05166]
[2020-05-12 11:34:46.276]  Step 159611  [3.439 sec/step, loss=0.08621, avg_loss=0.08691, mel_loss=0.03748, linear_loss=0.04873]
[2020-05-12 11:34:50.622]  Step 159612  [3.471 sec/step, loss=0.09296, avg_loss=0.08704, mel_loss=0.04148, linear_loss=0.05148]
[2020-05-12 11:34:51.867]  Step 159613  [3.473 sec/step, loss=0.08228, avg_loss=0.08707, mel_loss=0.03519, linear_loss=0.04710]
[2020-05-12 11:34:53.274]  Step 159614  [3.471 sec/step, loss=0.08279, avg_loss=0.08704, mel_loss=0.03580, linear_loss=0.04699]
[2020-05-12 11:34:56.767]  Step 159615  [3.453 sec/step, loss=0.09264, avg_loss=0.08701, mel_loss=0.04113, linear_loss=0.05152]
[2020-05-12 11:34:58.531]  Step 159616  [3.465 sec/step, loss=0.08713, avg_loss=0.08721, mel_loss=0.03756, linear_loss=0.04957]
[2020-05-12 11:35:02.209]  Step 159617  [3.465 sec/step, loss=0.09238, avg_loss=0.08720, mel_loss=0.04092, linear_loss=0.05147]
[2020-05-12 11:35:03.793]  Step 159618  [3.449 sec/step, loss=0.08470, avg_loss=0.08712, mel_loss=0.03644, linear_loss=0.04826]
[2020-05-12 11:35:05.758]  Step 159619  [3.421 sec/step, loss=0.08901, avg_loss=0.08708, mel_loss=0.03862, linear_loss=0.05038]
[2020-05-12 11:35:12.063]  Step 159620  [3.447 sec/step, loss=0.09493, avg_loss=0.08708, mel_loss=0.04294, linear_loss=0.05199]
[2020-05-12 11:35:12.616]  Step 159621  [3.425 sec/step, loss=0.06757, avg_loss=0.08687, mel_loss=0.02913, linear_loss=0.03844]
[2020-05-12 11:35:13.415]  Step 159622  [3.419 sec/step, loss=0.07346, avg_loss=0.08677, mel_loss=0.03134, linear_loss=0.04211]
[2020-05-12 11:35:18.462]  Step 159623  [3.447 sec/step, loss=0.09325, avg_loss=0.08680, mel_loss=0.04204, linear_loss=0.05120]
[2020-05-12 11:35:27.116]  Step 159624  [3.523 sec/step, loss=0.09290, avg_loss=0.08696, mel_loss=0.04261, linear_loss=0.05029]
[2020-05-12 11:35:32.726]  Step 159625  [3.498 sec/step, loss=0.09571, avg_loss=0.08699, mel_loss=0.04305, linear_loss=0.05266]
[2020-05-12 11:35:37.340]  Step 159626  [3.503 sec/step, loss=0.09498, avg_loss=0.08701, mel_loss=0.04236, linear_loss=0.05262]
[2020-05-12 11:35:40.485]  Step 159627  [3.519 sec/step, loss=0.09389, avg_loss=0.08709, mel_loss=0.04169, linear_loss=0.05220]
[2020-05-12 11:35:41.768]  Generated 32 batches of size 32 in 36.005 sec
[2020-05-12 11:35:42.949]  Step 159628  [3.499 sec/step, loss=0.08821, avg_loss=0.08701, mel_loss=0.03889, linear_loss=0.04932]
[2020-05-12 11:35:44.694]  Step 159629  [3.352 sec/step, loss=0.08612, avg_loss=0.08709, mel_loss=0.03710, linear_loss=0.04902]
[2020-05-12 11:35:50.269]  Step 159630  [3.348 sec/step, loss=0.09548, avg_loss=0.08709, mel_loss=0.04319, linear_loss=0.05229]
[2020-05-12 11:35:58.969]  Step 159631  [3.406 sec/step, loss=0.09380, avg_loss=0.08715, mel_loss=0.04289, linear_loss=0.05091]
[2020-05-12 11:36:12.010]  Step 159632  [3.504 sec/step, loss=0.07847, avg_loss=0.08701, mel_loss=0.03642, linear_loss=0.04205]
[2020-05-12 11:36:13.356]  Step 159633  [3.497 sec/step, loss=0.08472, avg_loss=0.08700, mel_loss=0.03630, linear_loss=0.04843]
[2020-05-12 11:36:17.741]  Step 159634  [3.527 sec/step, loss=0.09335, avg_loss=0.08710, mel_loss=0.04163, linear_loss=0.05172]
[2020-05-12 11:36:18.571]  Step 159635  [3.461 sec/step, loss=0.07420, avg_loss=0.08689, mel_loss=0.03135, linear_loss=0.04286]
[2020-05-12 11:36:22.088]  Step 159636  [3.488 sec/step, loss=0.09107, avg_loss=0.08706, mel_loss=0.04038, linear_loss=0.05069]
[2020-05-12 11:36:24.735]  Step 159637  [3.505 sec/step, loss=0.08826, avg_loss=0.08714, mel_loss=0.03870, linear_loss=0.04956]
[2020-05-12 11:36:26.755]  Step 159638  [3.473 sec/step, loss=0.08823, avg_loss=0.08709, mel_loss=0.03828, linear_loss=0.04995]
[2020-05-12 11:36:27.950]  Step 159639  [3.397 sec/step, loss=0.08102, avg_loss=0.08698, mel_loss=0.03490, linear_loss=0.04611]
[2020-05-12 11:36:30.856]  Step 159640  [3.397 sec/step, loss=0.09096, avg_loss=0.08700, mel_loss=0.03983, linear_loss=0.05113]
[2020-05-12 11:36:37.493]  Step 159641  [3.453 sec/step, loss=0.09493, avg_loss=0.08713, mel_loss=0.04291, linear_loss=0.05202]
[2020-05-12 11:36:43.063]  Step 159642  [3.465 sec/step, loss=0.09265, avg_loss=0.08715, mel_loss=0.04163, linear_loss=0.05102]
[2020-05-12 11:36:44.059]  Step 159643  [3.461 sec/step, loss=0.07986, avg_loss=0.08713, mel_loss=0.03438, linear_loss=0.04549]
[2020-05-12 11:36:46.513]  Step 159644  [3.469 sec/step, loss=0.08833, avg_loss=0.08717, mel_loss=0.03854, linear_loss=0.04979]
[2020-05-12 11:36:50.166]  Step 159645  [3.481 sec/step, loss=0.09402, avg_loss=0.08722, mel_loss=0.04162, linear_loss=0.05240]
[2020-05-12 11:36:50.732]  Step 159646  [3.452 sec/step, loss=0.06651, avg_loss=0.08696, mel_loss=0.02888, linear_loss=0.03764]
[2020-05-12 11:36:52.615]  Step 159647  [3.433 sec/step, loss=0.08354, avg_loss=0.08686, mel_loss=0.03590, linear_loss=0.04763]
[2020-05-12 11:36:55.789]  Step 159648  [3.451 sec/step, loss=0.09333, avg_loss=0.08697, mel_loss=0.04106, linear_loss=0.05227]
[2020-05-12 11:36:59.603]  Step 159649  [3.462 sec/step, loss=0.09445, avg_loss=0.08702, mel_loss=0.04193, linear_loss=0.05252]
[2020-05-12 11:37:01.667]  Step 159650  [3.463 sec/step, loss=0.08935, avg_loss=0.08705, mel_loss=0.03889, linear_loss=0.05046]
[2020-05-12 11:37:01.667]  Writing summary at step: 159650
[2020-05-12 11:37:02.786]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159650
[2020-05-12 11:37:04.443]  Saving audio and alignment...
[2020-05-12 11:37:07.394]  Input: 왜 이런 질문 하실까요~________________
[2020-05-12 11:37:08.999]  Step 159651  [3.422 sec/step, loss=0.08662, avg_loss=0.08698, mel_loss=0.03741, linear_loss=0.04920]
[2020-05-12 11:37:13.708]  Step 159652  [3.463 sec/step, loss=0.09496, avg_loss=0.08727, mel_loss=0.04243, linear_loss=0.05252]
[2020-05-12 11:37:14.522]  Step 159653  [3.395 sec/step, loss=0.07414, avg_loss=0.08706, mel_loss=0.03159, linear_loss=0.04254]
[2020-05-12 11:37:16.896]  Step 159654  [3.396 sec/step, loss=0.09029, avg_loss=0.08708, mel_loss=0.03962, linear_loss=0.05067]
[2020-05-12 11:37:20.327]  Step 159655  [3.381 sec/step, loss=0.09459, avg_loss=0.08708, mel_loss=0.04183, linear_loss=0.05276]
[2020-05-12 11:37:27.560]  Step 159656  [3.437 sec/step, loss=0.09493, avg_loss=0.08717, mel_loss=0.04308, linear_loss=0.05185]
[2020-05-12 11:37:28.955]  Step 159657  [3.443 sec/step, loss=0.08342, avg_loss=0.08725, mel_loss=0.03598, linear_loss=0.04743]
[2020-05-12 11:37:29.961]  Step 159658  [3.423 sec/step, loss=0.07767, avg_loss=0.08710, mel_loss=0.03285, linear_loss=0.04481]
[2020-05-12 11:37:32.460]  Generated 32 batches of size 32 in 27.425 sec
[2020-05-12 11:37:35.376]  Step 159659  [3.470 sec/step, loss=0.09170, avg_loss=0.08728, mel_loss=0.04059, linear_loss=0.05111]
[2020-05-12 11:37:38.967]  Step 159660  [3.475 sec/step, loss=0.09421, avg_loss=0.08728, mel_loss=0.04182, linear_loss=0.05239]
[2020-05-12 11:37:41.679]  Step 159661  [3.484 sec/step, loss=0.09015, avg_loss=0.08730, mel_loss=0.03963, linear_loss=0.05052]
[2020-05-12 11:37:44.143]  Step 159662  [3.362 sec/step, loss=0.08936, avg_loss=0.08745, mel_loss=0.03888, linear_loss=0.05048]
[2020-05-12 11:37:48.254]  Step 159663  [3.394 sec/step, loss=0.09410, avg_loss=0.08762, mel_loss=0.04159, linear_loss=0.05251]
[2020-05-12 11:37:49.605]  Step 159664  [3.390 sec/step, loss=0.08213, avg_loss=0.08759, mel_loss=0.03504, linear_loss=0.04709]
[2020-05-12 11:37:52.771]  Step 159665  [3.399 sec/step, loss=0.09240, avg_loss=0.08764, mel_loss=0.04076, linear_loss=0.05163]
[2020-05-12 11:38:01.339]  Step 159666  [3.422 sec/step, loss=0.09282, avg_loss=0.08762, mel_loss=0.04235, linear_loss=0.05047]
[2020-05-12 11:38:06.965]  Step 159667  [3.387 sec/step, loss=0.09173, avg_loss=0.08759, mel_loss=0.04093, linear_loss=0.05080]
[2020-05-12 11:38:08.677]  Step 159668  [3.369 sec/step, loss=0.08724, avg_loss=0.08755, mel_loss=0.03762, linear_loss=0.04962]
[2020-05-12 11:38:12.145]  Step 159669  [3.271 sec/step, loss=0.09145, avg_loss=0.08764, mel_loss=0.04064, linear_loss=0.05081]
[2020-05-12 11:38:13.701]  Step 159670  [3.257 sec/step, loss=0.08478, avg_loss=0.08756, mel_loss=0.03672, linear_loss=0.04806]
[2020-05-12 11:38:28.025]  Step 159671  [3.380 sec/step, loss=0.07535, avg_loss=0.08745, mel_loss=0.03548, linear_loss=0.03986]
[2020-05-12 11:38:28.591]  Step 159672  [3.368 sec/step, loss=0.06993, avg_loss=0.08727, mel_loss=0.03050, linear_loss=0.03942]
[2020-05-12 11:38:32.701]  Step 159673  [3.372 sec/step, loss=0.09387, avg_loss=0.08725, mel_loss=0.04163, linear_loss=0.05225]
[2020-05-12 11:38:38.348]  Step 159674  [3.416 sec/step, loss=0.09464, avg_loss=0.08741, mel_loss=0.04246, linear_loss=0.05218]
[2020-05-12 11:38:42.711]  Step 159675  [3.420 sec/step, loss=0.09526, avg_loss=0.08742, mel_loss=0.04280, linear_loss=0.05247]
[2020-05-12 11:38:43.618]  Step 159676  [3.423 sec/step, loss=0.07670, avg_loss=0.08750, mel_loss=0.03217, linear_loss=0.04453]
[2020-05-12 11:38:44.427]  Step 159677  [3.410 sec/step, loss=0.07525, avg_loss=0.08736, mel_loss=0.03186, linear_loss=0.04339]
[2020-05-12 11:38:46.404]  Step 159678  [3.412 sec/step, loss=0.08738, avg_loss=0.08737, mel_loss=0.03780, linear_loss=0.04958]
[2020-05-12 11:38:47.425]  Step 159679  [3.405 sec/step, loss=0.07760, avg_loss=0.08729, mel_loss=0.03289, linear_loss=0.04471]
[2020-05-12 11:38:50.490]  Step 159680  [3.409 sec/step, loss=0.09290, avg_loss=0.08730, mel_loss=0.04088, linear_loss=0.05203]
[2020-05-12 11:38:57.201]  Step 159681  [3.442 sec/step, loss=0.09445, avg_loss=0.08733, mel_loss=0.04278, linear_loss=0.05167]
[2020-05-12 11:39:04.774]  Step 159682  [3.460 sec/step, loss=0.09657, avg_loss=0.08733, mel_loss=0.04395, linear_loss=0.05262]
[2020-05-12 11:39:06.206]  Step 159683  [3.460 sec/step, loss=0.08631, avg_loss=0.08737, mel_loss=0.03710, linear_loss=0.04920]
[2020-05-12 11:39:08.227]  Step 159684  [3.472 sec/step, loss=0.08832, avg_loss=0.08751, mel_loss=0.03844, linear_loss=0.04988]
[2020-05-12 11:39:09.324]  Step 159685  [3.474 sec/step, loss=0.07995, avg_loss=0.08757, mel_loss=0.03412, linear_loss=0.04584]
[2020-05-12 11:39:11.599]  Step 159686  [3.443 sec/step, loss=0.08916, avg_loss=0.08749, mel_loss=0.03886, linear_loss=0.05031]
[2020-05-12 11:39:13.750]  Step 159687  [3.420 sec/step, loss=0.09030, avg_loss=0.08744, mel_loss=0.03949, linear_loss=0.05081]
[2020-05-12 11:39:14.531]  Step 159688  [3.406 sec/step, loss=0.07157, avg_loss=0.08728, mel_loss=0.03053, linear_loss=0.04105]
[2020-05-12 11:39:16.318]  Step 159689  [3.399 sec/step, loss=0.08832, avg_loss=0.08729, mel_loss=0.03789, linear_loss=0.05044]
[2020-05-12 11:39:17.549]  Step 159690  [3.362 sec/step, loss=0.08205, avg_loss=0.08717, mel_loss=0.03493, linear_loss=0.04712]
[2020-05-12 11:40:50.862]  Generated 32 batches of size 32 in 113.655 sec
[2020-05-12 11:40:52.484]  Step 159691  [4.301 sec/step, loss=0.08628, avg_loss=0.08725, mel_loss=0.03689, linear_loss=0.04939]
[2020-05-12 11:41:00.040]  Step 159692  [4.307 sec/step, loss=0.09468, avg_loss=0.08725, mel_loss=0.04297, linear_loss=0.05172]
[2020-05-12 11:41:00.597]  Step 159693  [4.299 sec/step, loss=0.06962, avg_loss=0.08709, mel_loss=0.03000, linear_loss=0.03962]
[2020-05-12 11:41:01.521]  Step 159694  [4.236 sec/step, loss=0.08059, avg_loss=0.08695, mel_loss=0.03420, linear_loss=0.04639]
[2020-05-12 11:41:10.363]  Step 159695  [4.314 sec/step, loss=0.09532, avg_loss=0.08715, mel_loss=0.04347, linear_loss=0.05184]
[2020-05-12 11:41:11.616]  Step 159696  [4.315 sec/step, loss=0.08262, avg_loss=0.08716, mel_loss=0.03545, linear_loss=0.04717]
[2020-05-12 11:41:14.050]  Step 159697  [4.309 sec/step, loss=0.08896, avg_loss=0.08712, mel_loss=0.03876, linear_loss=0.05020]
[2020-05-12 11:41:18.994]  Step 159698  [4.333 sec/step, loss=0.09599, avg_loss=0.08719, mel_loss=0.04294, linear_loss=0.05305]
[2020-05-12 11:41:21.954]  Step 159699  [4.334 sec/step, loss=0.09136, avg_loss=0.08721, mel_loss=0.04020, linear_loss=0.05116]
[2020-05-12 11:41:28.625]  Step 159700  [4.388 sec/step, loss=0.09431, avg_loss=0.08735, mel_loss=0.04260, linear_loss=0.05172]
[2020-05-12 11:41:28.625]  Writing summary at step: 159700
[2020-05-12 11:41:30.384]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159700
[2020-05-12 11:41:32.006]  Saving audio and alignment...
[2020-05-12 11:41:34.385]  Input: 이렇게 적혀 있습니다~_____
[2020-05-12 11:41:35.760]  Step 159701  [4.380 sec/step, loss=0.08304, avg_loss=0.08729, mel_loss=0.03582, linear_loss=0.04722]
[2020-05-12 11:41:39.172]  Step 159702  [4.373 sec/step, loss=0.09144, avg_loss=0.08727, mel_loss=0.04033, linear_loss=0.05111]
[2020-05-12 11:41:43.351]  Step 159703  [4.405 sec/step, loss=0.09146, avg_loss=0.08744, mel_loss=0.04059, linear_loss=0.05086]
[2020-05-12 11:41:45.587]  Step 159704  [4.416 sec/step, loss=0.08901, avg_loss=0.08752, mel_loss=0.03864, linear_loss=0.05037]
[2020-05-12 11:41:46.715]  Step 159705  [4.353 sec/step, loss=0.08254, avg_loss=0.08739, mel_loss=0.03509, linear_loss=0.04745]
[2020-05-12 11:41:47.559]  Step 159706  [4.351 sec/step, loss=0.07145, avg_loss=0.08729, mel_loss=0.03053, linear_loss=0.04092]
[2020-05-12 11:41:49.701]  Step 159707  [4.343 sec/step, loss=0.08906, avg_loss=0.08726, mel_loss=0.03863, linear_loss=0.05043]
[2020-05-12 11:41:51.425]  Step 159708  [4.213 sec/step, loss=0.08693, avg_loss=0.08739, mel_loss=0.03766, linear_loss=0.04927]
[2020-05-12 11:41:57.255]  Step 159709  [4.246 sec/step, loss=0.09591, avg_loss=0.08746, mel_loss=0.04313, linear_loss=0.05278]
[2020-05-12 11:41:58.051]  Step 159710  [4.219 sec/step, loss=0.07560, avg_loss=0.08728, mel_loss=0.03220, linear_loss=0.04340]
[2020-05-12 11:42:02.884]  Step 159711  [4.251 sec/step, loss=0.09418, avg_loss=0.08736, mel_loss=0.04195, linear_loss=0.05223]
[2020-05-12 11:42:04.707]  Step 159712  [4.226 sec/step, loss=0.08542, avg_loss=0.08729, mel_loss=0.03683, linear_loss=0.04859]
[2020-05-12 11:42:07.475]  Step 159713  [4.241 sec/step, loss=0.09184, avg_loss=0.08738, mel_loss=0.04046, linear_loss=0.05139]
[2020-05-12 11:42:20.594]  Step 159714  [4.358 sec/step, loss=0.08167, avg_loss=0.08737, mel_loss=0.03820, linear_loss=0.04347]
[2020-05-12 11:42:24.263]  Step 159715  [4.360 sec/step, loss=0.09546, avg_loss=0.08740, mel_loss=0.04237, linear_loss=0.05309]
[2020-05-12 11:42:25.259]  Step 159716  [4.352 sec/step, loss=0.07601, avg_loss=0.08729, mel_loss=0.03211, linear_loss=0.04390]
[2020-05-12 11:42:28.603]  Step 159717  [4.349 sec/step, loss=0.09265, avg_loss=0.08729, mel_loss=0.04105, linear_loss=0.05160]
[2020-05-12 11:42:33.908]  Step 159718  [4.386 sec/step, loss=0.09576, avg_loss=0.08740, mel_loss=0.04310, linear_loss=0.05266]
[2020-05-12 11:42:37.456]  Step 159719  [4.402 sec/step, loss=0.09325, avg_loss=0.08745, mel_loss=0.04129, linear_loss=0.05196]
[2020-05-12 11:42:39.965]  Step 159720  [4.364 sec/step, loss=0.08818, avg_loss=0.08738, mel_loss=0.03854, linear_loss=0.04964]
[2020-05-12 11:43:19.804]  Generated 32 batches of size 32 in 76.915 sec
[2020-05-12 11:43:26.563]  Step 159721  [4.824 sec/step, loss=0.09442, avg_loss=0.08765, mel_loss=0.04272, linear_loss=0.05170]
[2020-05-12 11:43:27.615]  Step 159722  [4.827 sec/step, loss=0.07789, avg_loss=0.08769, mel_loss=0.03363, linear_loss=0.04426]
[2020-05-12 11:43:30.991]  Step 159723  [4.810 sec/step, loss=0.09275, avg_loss=0.08769, mel_loss=0.04070, linear_loss=0.05204]
[2020-05-12 11:43:31.753]  Step 159724  [4.731 sec/step, loss=0.06904, avg_loss=0.08745, mel_loss=0.03058, linear_loss=0.03846]
[2020-05-12 11:43:38.629]  Step 159725  [4.744 sec/step, loss=0.09747, avg_loss=0.08746, mel_loss=0.04444, linear_loss=0.05303]
[2020-05-12 11:43:40.785]  Step 159726  [4.719 sec/step, loss=0.08705, avg_loss=0.08739, mel_loss=0.03799, linear_loss=0.04906]
[2020-05-12 11:43:44.828]  Step 159727  [4.728 sec/step, loss=0.09311, avg_loss=0.08738, mel_loss=0.04115, linear_loss=0.05197]
[2020-05-12 11:43:46.793]  Step 159728  [4.723 sec/step, loss=0.08781, avg_loss=0.08737, mel_loss=0.03817, linear_loss=0.04964]
[2020-05-12 11:43:51.938]  Step 159729  [4.757 sec/step, loss=0.09243, avg_loss=0.08744, mel_loss=0.04132, linear_loss=0.05111]
[2020-05-12 11:43:53.370]  Step 159730  [4.716 sec/step, loss=0.08535, avg_loss=0.08734, mel_loss=0.03674, linear_loss=0.04862]
[2020-05-12 11:43:54.584]  Step 159731  [4.641 sec/step, loss=0.08309, avg_loss=0.08723, mel_loss=0.03541, linear_loss=0.04768]
[2020-05-12 11:43:57.010]  Step 159732  [4.535 sec/step, loss=0.08917, avg_loss=0.08734, mel_loss=0.03861, linear_loss=0.05056]
[2020-05-12 11:43:58.809]  Step 159733  [4.539 sec/step, loss=0.08643, avg_loss=0.08735, mel_loss=0.03712, linear_loss=0.04931]
[2020-05-12 11:44:01.532]  Step 159734  [4.523 sec/step, loss=0.08885, avg_loss=0.08731, mel_loss=0.03887, linear_loss=0.04997]
[2020-05-12 11:44:06.085]  Step 159735  [4.560 sec/step, loss=0.09357, avg_loss=0.08750, mel_loss=0.04185, linear_loss=0.05172]
[2020-05-12 11:44:07.708]  Step 159736  [4.541 sec/step, loss=0.08454, avg_loss=0.08744, mel_loss=0.03640, linear_loss=0.04814]
[2020-05-12 11:44:08.676]  Step 159737  [4.524 sec/step, loss=0.07400, avg_loss=0.08729, mel_loss=0.03113, linear_loss=0.04287]
[2020-05-12 11:44:10.875]  Step 159738  [4.526 sec/step, loss=0.08955, avg_loss=0.08731, mel_loss=0.03940, linear_loss=0.05016]
[2020-05-12 11:44:11.717]  Step 159739  [4.523 sec/step, loss=0.07349, avg_loss=0.08723, mel_loss=0.03136, linear_loss=0.04213]
[2020-05-12 11:44:13.336]  Step 159740  [4.510 sec/step, loss=0.08826, avg_loss=0.08720, mel_loss=0.03847, linear_loss=0.04979]
[2020-05-12 11:44:17.477]  Step 159741  [4.485 sec/step, loss=0.09280, avg_loss=0.08718, mel_loss=0.04118, linear_loss=0.05161]
[2020-05-12 11:44:20.175]  Step 159742  [4.456 sec/step, loss=0.08920, avg_loss=0.08715, mel_loss=0.03918, linear_loss=0.05002]
[2020-05-12 11:44:23.764]  Step 159743  [4.482 sec/step, loss=0.09523, avg_loss=0.08730, mel_loss=0.04228, linear_loss=0.05295]
[2020-05-12 11:44:25.168]  Step 159744  [4.471 sec/step, loss=0.08389, avg_loss=0.08726, mel_loss=0.03606, linear_loss=0.04783]
[2020-05-12 11:44:28.681]  Step 159745  [4.470 sec/step, loss=0.09179, avg_loss=0.08724, mel_loss=0.04085, linear_loss=0.05094]
[2020-05-12 11:44:31.646]  Generated 32 batches of size 32 in 7.877 sec
[2020-05-12 11:44:31.845]  Step 159746  [4.496 sec/step, loss=0.09251, avg_loss=0.08750, mel_loss=0.04092, linear_loss=0.05158]
[2020-05-12 11:44:32.983]  Step 159747  [4.489 sec/step, loss=0.08027, avg_loss=0.08746, mel_loss=0.03387, linear_loss=0.04640]
[2020-05-12 11:44:47.238]  Step 159748  [4.599 sec/step, loss=0.07475, avg_loss=0.08728, mel_loss=0.03498, linear_loss=0.03978]
[2020-05-12 11:44:55.802]  Step 159749  [4.647 sec/step, loss=0.09360, avg_loss=0.08727, mel_loss=0.04267, linear_loss=0.05093]
[2020-05-12 11:45:01.487]  Step 159750  [4.683 sec/step, loss=0.09395, avg_loss=0.08731, mel_loss=0.04221, linear_loss=0.05174]
[2020-05-12 11:45:01.487]  Writing summary at step: 159750
[2020-05-12 11:45:03.461]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159750
[2020-05-12 11:45:05.050]  Saving audio and alignment...
[2020-05-12 11:45:06.845]  Input: 예를 들어서~_______
[2020-05-12 11:45:08.201]  Step 159751  [4.681 sec/step, loss=0.08319, avg_loss=0.08728, mel_loss=0.03568, linear_loss=0.04751]
[2020-05-12 11:45:15.761]  Step 159752  [4.709 sec/step, loss=0.09515, avg_loss=0.08728, mel_loss=0.04327, linear_loss=0.05189]
[2020-05-12 11:45:16.868]  Step 159753  [4.712 sec/step, loss=0.08021, avg_loss=0.08734, mel_loss=0.03409, linear_loss=0.04612]
[2020-05-12 11:45:17.630]  Step 159754  [4.696 sec/step, loss=0.07488, avg_loss=0.08719, mel_loss=0.03165, linear_loss=0.04324]
[2020-05-12 11:45:22.305]  Step 159755  [4.708 sec/step, loss=0.09420, avg_loss=0.08718, mel_loss=0.04221, linear_loss=0.05199]
[2020-05-12 11:45:24.413]  Step 159756  [4.657 sec/step, loss=0.09128, avg_loss=0.08715, mel_loss=0.03972, linear_loss=0.05157]
[2020-05-12 11:45:27.069]  Step 159757  [4.670 sec/step, loss=0.08974, avg_loss=0.08721, mel_loss=0.03930, linear_loss=0.05044]
[2020-05-12 11:45:31.199]  Step 159758  [4.701 sec/step, loss=0.09319, avg_loss=0.08737, mel_loss=0.04110, linear_loss=0.05210]
[2020-05-12 11:45:33.613]  Step 159759  [4.671 sec/step, loss=0.08849, avg_loss=0.08733, mel_loss=0.03845, linear_loss=0.05004]
[2020-05-12 11:45:37.245]  Step 159760  [4.671 sec/step, loss=0.09312, avg_loss=0.08732, mel_loss=0.04128, linear_loss=0.05184]
[2020-05-12 11:45:38.872]  Step 159761  [4.660 sec/step, loss=0.08495, avg_loss=0.08727, mel_loss=0.03689, linear_loss=0.04806]
[2020-05-12 11:45:40.088]  Step 159762  [4.648 sec/step, loss=0.08279, avg_loss=0.08721, mel_loss=0.03568, linear_loss=0.04712]
[2020-05-12 11:45:41.087]  Step 159763  [4.617 sec/step, loss=0.07773, avg_loss=0.08704, mel_loss=0.03269, linear_loss=0.04503]
[2020-05-12 11:45:54.021]  Step 159764  [4.733 sec/step, loss=0.08114, avg_loss=0.08703, mel_loss=0.03808, linear_loss=0.04306]
[2020-05-12 11:45:57.093]  Step 159765  [4.732 sec/step, loss=0.09431, avg_loss=0.08705, mel_loss=0.04147, linear_loss=0.05283]
[2020-05-12 11:46:00.503]  Step 159766  [4.680 sec/step, loss=0.09103, avg_loss=0.08703, mel_loss=0.04045, linear_loss=0.05059]
[2020-05-12 11:46:05.547]  Step 159767  [4.674 sec/step, loss=0.09214, avg_loss=0.08704, mel_loss=0.04117, linear_loss=0.05097]
[2020-05-12 11:46:07.581]  Step 159768  [4.678 sec/step, loss=0.08756, avg_loss=0.08704, mel_loss=0.03789, linear_loss=0.04968]
[2020-05-12 11:46:09.557]  Step 159769  [4.663 sec/step, loss=0.08644, avg_loss=0.08699, mel_loss=0.03763, linear_loss=0.04881]
[2020-05-12 11:46:13.799]  Step 159770  [4.690 sec/step, loss=0.09481, avg_loss=0.08709, mel_loss=0.04224, linear_loss=0.05257]
[2020-05-12 11:46:14.361]  Step 159771  [4.552 sec/step, loss=0.06903, avg_loss=0.08703, mel_loss=0.02994, linear_loss=0.03909]
[2020-05-12 11:46:17.218]  Step 159772  [4.575 sec/step, loss=0.09266, avg_loss=0.08726, mel_loss=0.04073, linear_loss=0.05193]
[2020-05-12 11:46:20.419]  Step 159773  [4.566 sec/step, loss=0.09241, avg_loss=0.08724, mel_loss=0.04086, linear_loss=0.05154]
[2020-05-12 11:46:26.867]  Step 159774  [4.574 sec/step, loss=0.09389, avg_loss=0.08723, mel_loss=0.04243, linear_loss=0.05147]
[2020-05-12 11:46:27.880]  Step 159775  [4.540 sec/step, loss=0.07782, avg_loss=0.08706, mel_loss=0.03285, linear_loss=0.04498]
[2020-05-12 11:46:28.690]  Step 159776  [4.539 sec/step, loss=0.07541, avg_loss=0.08705, mel_loss=0.03193, linear_loss=0.04347]
[2020-05-12 11:46:30.124]  Step 159777  [4.546 sec/step, loss=0.08331, avg_loss=0.08713, mel_loss=0.03607, linear_loss=0.04724]
[2020-05-12 11:46:31.941]  Step 159778  [4.544 sec/step, loss=0.08520, avg_loss=0.08710, mel_loss=0.03686, linear_loss=0.04833]
[2020-05-12 11:46:40.357]  Step 159779  [4.618 sec/step, loss=0.09362, avg_loss=0.08726, mel_loss=0.04259, linear_loss=0.05103]
[2020-05-12 11:46:46.013]  Step 159780  [4.644 sec/step, loss=0.09453, avg_loss=0.08728, mel_loss=0.04229, linear_loss=0.05224]
[2020-05-12 11:46:48.585]  Step 159781  [4.602 sec/step, loss=0.08885, avg_loss=0.08722, mel_loss=0.03867, linear_loss=0.05018]
[2020-05-12 11:46:50.333]  Step 159782  [4.544 sec/step, loss=0.08753, avg_loss=0.08713, mel_loss=0.03757, linear_loss=0.04997]
[2020-05-12 11:47:23.829]  Generated 32 batches of size 32 in 63.404 sec
[2020-05-12 11:47:27.213]  Step 159783  [4.899 sec/step, loss=0.09303, avg_loss=0.08720, mel_loss=0.04101, linear_loss=0.05203]
[2020-05-12 11:47:32.877]  Step 159784  [4.935 sec/step, loss=0.09707, avg_loss=0.08729, mel_loss=0.04395, linear_loss=0.05311]
[2020-05-12 11:47:33.842]  Step 159785  [4.934 sec/step, loss=0.07677, avg_loss=0.08726, mel_loss=0.03213, linear_loss=0.04463]
[2020-05-12 11:47:36.339]  Step 159786  [4.936 sec/step, loss=0.08906, avg_loss=0.08726, mel_loss=0.03902, linear_loss=0.05005]
[2020-05-12 11:47:39.991]  Step 159787  [4.951 sec/step, loss=0.09385, avg_loss=0.08729, mel_loss=0.04150, linear_loss=0.05235]
[2020-05-12 11:47:41.655]  Step 159788  [4.960 sec/step, loss=0.08720, avg_loss=0.08745, mel_loss=0.03743, linear_loss=0.04977]
[2020-05-12 11:47:43.024]  Step 159789  [4.956 sec/step, loss=0.08383, avg_loss=0.08740, mel_loss=0.03605, linear_loss=0.04778]
[2020-05-12 11:47:44.939]  Step 159790  [4.962 sec/step, loss=0.08496, avg_loss=0.08743, mel_loss=0.03678, linear_loss=0.04818]
[2020-05-12 11:47:46.157]  Step 159791  [4.025 sec/step, loss=0.07969, avg_loss=0.08737, mel_loss=0.03409, linear_loss=0.04559]
[2020-05-12 11:47:46.688]  Step 159792  [3.955 sec/step, loss=0.06610, avg_loss=0.08708, mel_loss=0.02842, linear_loss=0.03768]
[2020-05-12 11:47:48.665]  Step 159793  [3.969 sec/step, loss=0.09008, avg_loss=0.08729, mel_loss=0.03888, linear_loss=0.05119]
[2020-05-12 11:47:52.257]  Step 159794  [3.996 sec/step, loss=0.09332, avg_loss=0.08741, mel_loss=0.04135, linear_loss=0.05197]
[2020-05-12 11:47:53.327]  Step 159795  [3.918 sec/step, loss=0.08115, avg_loss=0.08727, mel_loss=0.03447, linear_loss=0.04668]
[2020-05-12 11:47:56.732]  Step 159796  [3.940 sec/step, loss=0.09055, avg_loss=0.08735, mel_loss=0.03987, linear_loss=0.05068]
[2020-05-12 11:47:57.691]  Step 159797  [3.925 sec/step, loss=0.07973, avg_loss=0.08726, mel_loss=0.03373, linear_loss=0.04600]
[2020-05-12 11:48:10.698]  Step 159798  [4.006 sec/step, loss=0.08013, avg_loss=0.08710, mel_loss=0.03721, linear_loss=0.04292]
[2020-05-12 11:48:15.547]  Step 159799  [4.024 sec/step, loss=0.09251, avg_loss=0.08711, mel_loss=0.04141, linear_loss=0.05109]
[2020-05-12 11:48:18.402]  Step 159800  [3.986 sec/step, loss=0.08897, avg_loss=0.08706, mel_loss=0.03944, linear_loss=0.04954]
[2020-05-12 11:48:18.402]  Writing summary at step: 159800
[2020-05-12 11:48:22.701]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159800
[2020-05-12 11:48:24.321]  Saving audio and alignment...
[2020-05-12 11:48:34.683]  Input: 궁합에 조화가 아주 뛰어나고 전체 상담과정에 아주 원활하고 매끄럽게 진행되는 경우들이 있거든요~_____________________________
[2020-05-12 11:48:36.992]  Step 159801  [3.996 sec/step, loss=0.08911, avg_loss=0.08712, mel_loss=0.03894, linear_loss=0.05017]
[2020-05-12 11:48:39.974]  Step 159802  [3.991 sec/step, loss=0.09184, avg_loss=0.08712, mel_loss=0.04053, linear_loss=0.05130]
[2020-05-12 11:48:41.727]  Step 159803  [3.967 sec/step, loss=0.08743, avg_loss=0.08708, mel_loss=0.03741, linear_loss=0.05002]
[2020-05-12 11:48:43.923]  Step 159804  [3.967 sec/step, loss=0.08669, avg_loss=0.08706, mel_loss=0.03800, linear_loss=0.04869]
[2020-05-12 11:48:44.689]  Step 159805  [3.963 sec/step, loss=0.07867, avg_loss=0.08702, mel_loss=0.03330, linear_loss=0.04537]
[2020-05-12 11:48:50.075]  Step 159806  [4.009 sec/step, loss=0.09719, avg_loss=0.08728, mel_loss=0.04383, linear_loss=0.05336]
[2020-05-12 11:48:54.527]  Step 159807  [4.032 sec/step, loss=0.09523, avg_loss=0.08734, mel_loss=0.04249, linear_loss=0.05274]
[2020-05-12 11:49:00.999]  Step 159808  [4.079 sec/step, loss=0.09365, avg_loss=0.08741, mel_loss=0.04256, linear_loss=0.05108]
[2020-05-12 11:49:01.775]  Step 159809  [4.029 sec/step, loss=0.07358, avg_loss=0.08718, mel_loss=0.03122, linear_loss=0.04235]
[2020-05-12 11:49:03.067]  Step 159810  [4.034 sec/step, loss=0.08159, avg_loss=0.08724, mel_loss=0.03482, linear_loss=0.04677]
[2020-05-12 11:49:11.981]  Step 159811  [4.074 sec/step, loss=0.09358, avg_loss=0.08724, mel_loss=0.04298, linear_loss=0.05060]
[2020-05-12 11:49:13.495]  Step 159812  [4.071 sec/step, loss=0.08400, avg_loss=0.08722, mel_loss=0.03627, linear_loss=0.04773]
[2020-05-12 11:49:14.751]  Generated 32 batches of size 32 in 33.019 sec
[2020-05-12 11:49:15.799]  Step 159813  [4.067 sec/step, loss=0.07839, avg_loss=0.08709, mel_loss=0.03347, linear_loss=0.04491]
[2020-05-12 11:49:17.231]  Step 159814  [3.950 sec/step, loss=0.08279, avg_loss=0.08710, mel_loss=0.03570, linear_loss=0.04709]
[2020-05-12 11:49:22.544]  Step 159815  [3.966 sec/step, loss=0.09279, avg_loss=0.08707, mel_loss=0.04172, linear_loss=0.05106]
[2020-05-12 11:49:24.332]  Step 159816  [3.974 sec/step, loss=0.08637, avg_loss=0.08718, mel_loss=0.03731, linear_loss=0.04907]
[2020-05-12 11:49:25.722]  Step 159817  [3.955 sec/step, loss=0.08193, avg_loss=0.08707, mel_loss=0.03528, linear_loss=0.04664]
[2020-05-12 11:49:26.283]  Step 159818  [3.907 sec/step, loss=0.06800, avg_loss=0.08679, mel_loss=0.02956, linear_loss=0.03844]
[2020-05-12 11:49:27.196]  Step 159819  [3.881 sec/step, loss=0.07819, avg_loss=0.08664, mel_loss=0.03302, linear_loss=0.04517]
[2020-05-12 11:49:29.658]  Step 159820  [3.880 sec/step, loss=0.08941, avg_loss=0.08665, mel_loss=0.03865, linear_loss=0.05075]
[2020-05-12 11:49:30.460]  Step 159821  [3.422 sec/step, loss=0.07367, avg_loss=0.08644, mel_loss=0.03146, linear_loss=0.04221]
[2020-05-12 11:49:37.952]  Step 159822  [3.487 sec/step, loss=0.09701, avg_loss=0.08664, mel_loss=0.04413, linear_loss=0.05287]
[2020-05-12 11:49:43.648]  Step 159823  [3.510 sec/step, loss=0.09445, avg_loss=0.08665, mel_loss=0.04250, linear_loss=0.05195]
[2020-05-12 11:49:48.097]  Step 159824  [3.547 sec/step, loss=0.09288, avg_loss=0.08689, mel_loss=0.04138, linear_loss=0.05150]
[2020-05-12 11:49:49.715]  Step 159825  [3.494 sec/step, loss=0.08494, avg_loss=0.08677, mel_loss=0.03680, linear_loss=0.04813]
[2020-05-12 11:49:51.973]  Step 159826  [3.495 sec/step, loss=0.08627, avg_loss=0.08676, mel_loss=0.03787, linear_loss=0.04839]
[2020-05-12 11:49:55.510]  Step 159827  [3.490 sec/step, loss=0.09424, avg_loss=0.08677, mel_loss=0.04169, linear_loss=0.05255]
[2020-05-12 11:49:58.571]  Step 159828  [3.501 sec/step, loss=0.09248, avg_loss=0.08682, mel_loss=0.04056, linear_loss=0.05192]
[2020-05-12 11:50:15.725]  Step 159829  [3.621 sec/step, loss=0.07540, avg_loss=0.08665, mel_loss=0.03535, linear_loss=0.04005]
[2020-05-12 11:50:16.951]  Step 159830  [3.619 sec/step, loss=0.08051, avg_loss=0.08660, mel_loss=0.03454, linear_loss=0.04597]
[2020-05-12 11:50:20.131]  Step 159831  [3.639 sec/step, loss=0.09491, avg_loss=0.08672, mel_loss=0.04195, linear_loss=0.05297]
[2020-05-12 11:50:22.879]  Step 159832  [3.642 sec/step, loss=0.09174, avg_loss=0.08674, mel_loss=0.04029, linear_loss=0.05145]
[2020-05-12 11:50:23.993]  Step 159833  [3.635 sec/step, loss=0.08185, avg_loss=0.08670, mel_loss=0.03445, linear_loss=0.04740]
[2020-05-12 11:50:25.701]  Step 159834  [3.625 sec/step, loss=0.08631, avg_loss=0.08667, mel_loss=0.03741, linear_loss=0.04890]
[2020-05-12 11:50:30.353]  Step 159835  [3.626 sec/step, loss=0.09566, avg_loss=0.08669, mel_loss=0.04276, linear_loss=0.05290]
[2020-05-12 11:50:32.290]  Step 159836  [3.629 sec/step, loss=0.08904, avg_loss=0.08674, mel_loss=0.03864, linear_loss=0.05040]
[2020-05-12 11:50:34.446]  Step 159837  [3.641 sec/step, loss=0.08896, avg_loss=0.08689, mel_loss=0.03867, linear_loss=0.05028]
[2020-05-12 11:50:35.283]  Step 159838  [3.627 sec/step, loss=0.07288, avg_loss=0.08672, mel_loss=0.03158, linear_loss=0.04130]
[2020-05-12 11:50:37.330]  Step 159839  [3.639 sec/step, loss=0.08747, avg_loss=0.08686, mel_loss=0.03799, linear_loss=0.04947]
[2020-05-12 11:50:40.196]  Step 159840  [3.652 sec/step, loss=0.09227, avg_loss=0.08690, mel_loss=0.04052, linear_loss=0.05175]
[2020-05-12 11:50:49.268]  Step 159841  [3.701 sec/step, loss=0.09305, avg_loss=0.08690, mel_loss=0.04252, linear_loss=0.05053]
[2020-05-12 11:50:53.043]  Step 159842  [3.712 sec/step, loss=0.09516, avg_loss=0.08696, mel_loss=0.04220, linear_loss=0.05296]
[2020-05-12 11:50:59.800]  Step 159843  [3.744 sec/step, loss=0.09568, avg_loss=0.08697, mel_loss=0.04326, linear_loss=0.05242]
[2020-05-12 11:51:03.245]  Step 159844  [3.764 sec/step, loss=0.09102, avg_loss=0.08704, mel_loss=0.04027, linear_loss=0.05075]
[2020-05-12 11:51:10.712]  Generated 32 batches of size 32 in 40.354 sec
[2020-05-12 11:51:16.347]  Step 159845  [3.860 sec/step, loss=0.09525, avg_loss=0.08707, mel_loss=0.04299, linear_loss=0.05226]
[2020-05-12 11:51:18.935]  Step 159846  [3.854 sec/step, loss=0.09051, avg_loss=0.08705, mel_loss=0.03974, linear_loss=0.05077]
[2020-05-12 11:51:21.370]  Step 159847  [3.867 sec/step, loss=0.08938, avg_loss=0.08714, mel_loss=0.03888, linear_loss=0.05050]
[2020-05-12 11:51:24.807]  Step 159848  [3.759 sec/step, loss=0.09199, avg_loss=0.08731, mel_loss=0.04069, linear_loss=0.05130]
[2020-05-12 11:51:33.226]  Step 159849  [3.758 sec/step, loss=0.09445, avg_loss=0.08732, mel_loss=0.04316, linear_loss=0.05129]
[2020-05-12 11:51:36.488]  Step 159850  [3.733 sec/step, loss=0.09249, avg_loss=0.08731, mel_loss=0.04121, linear_loss=0.05128]
[2020-05-12 11:51:36.488]  Writing summary at step: 159850
[2020-05-12 11:51:40.407]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159850
[2020-05-12 11:51:42.044]  Saving audio and alignment...
[2020-05-12 11:51:44.577]  Input: 예문으로 연습해 보죠~___________
[2020-05-12 11:51:46.355]  Step 159851  [3.738 sec/step, loss=0.08592, avg_loss=0.08734, mel_loss=0.03707, linear_loss=0.04885]
[2020-05-12 11:51:47.360]  Step 159852  [3.672 sec/step, loss=0.07759, avg_loss=0.08716, mel_loss=0.03336, linear_loss=0.04423]
[2020-05-12 11:51:51.684]  Step 159853  [3.704 sec/step, loss=0.09308, avg_loss=0.08729, mel_loss=0.04149, linear_loss=0.05159]
[2020-05-12 11:51:53.852]  Step 159854  [3.718 sec/step, loss=0.08704, avg_loss=0.08741, mel_loss=0.03778, linear_loss=0.04926]
[2020-05-12 11:52:08.028]  Step 159855  [3.813 sec/step, loss=0.07489, avg_loss=0.08722, mel_loss=0.03522, linear_loss=0.03966]
[2020-05-12 11:52:11.030]  Step 159856  [3.822 sec/step, loss=0.08916, avg_loss=0.08720, mel_loss=0.03929, linear_loss=0.04987]
[2020-05-12 11:52:13.079]  Step 159857  [3.816 sec/step, loss=0.08455, avg_loss=0.08714, mel_loss=0.03687, linear_loss=0.04768]
[2020-05-12 11:52:19.873]  Step 159858  [3.843 sec/step, loss=0.09396, avg_loss=0.08715, mel_loss=0.04250, linear_loss=0.05147]
[2020-05-12 11:52:22.223]  Step 159859  [3.842 sec/step, loss=0.09198, avg_loss=0.08719, mel_loss=0.04044, linear_loss=0.05154]
[2020-05-12 11:52:23.442]  Step 159860  [3.818 sec/step, loss=0.07983, avg_loss=0.08705, mel_loss=0.03407, linear_loss=0.04577]
[2020-05-12 11:52:28.661]  Step 159861  [3.854 sec/step, loss=0.09530, avg_loss=0.08716, mel_loss=0.04278, linear_loss=0.05252]
[2020-05-12 11:52:33.329]  Step 159862  [3.888 sec/step, loss=0.09419, avg_loss=0.08727, mel_loss=0.04179, linear_loss=0.05240]
[2020-05-12 11:52:34.336]  Step 159863  [3.889 sec/step, loss=0.07691, avg_loss=0.08726, mel_loss=0.03235, linear_loss=0.04456]
[2020-05-12 11:52:35.097]  Step 159864  [3.767 sec/step, loss=0.07864, avg_loss=0.08724, mel_loss=0.03290, linear_loss=0.04574]
[2020-05-12 11:52:36.614]  Step 159865  [3.751 sec/step, loss=0.08407, avg_loss=0.08714, mel_loss=0.03619, linear_loss=0.04788]
[2020-05-12 11:52:40.302]  Step 159866  [3.754 sec/step, loss=0.09317, avg_loss=0.08716, mel_loss=0.04128, linear_loss=0.05188]
[2020-05-12 11:52:41.682]  Step 159867  [3.717 sec/step, loss=0.08334, avg_loss=0.08707, mel_loss=0.03594, linear_loss=0.04740]
[2020-05-12 11:52:43.312]  Step 159868  [3.713 sec/step, loss=0.08746, avg_loss=0.08707, mel_loss=0.03801, linear_loss=0.04945]
[2020-05-12 11:52:44.073]  Step 159869  [3.701 sec/step, loss=0.07261, avg_loss=0.08693, mel_loss=0.03123, linear_loss=0.04138]
[2020-05-12 11:52:45.181]  Step 159870  [3.670 sec/step, loss=0.08106, avg_loss=0.08679, mel_loss=0.03464, linear_loss=0.04642]
[2020-05-12 11:52:47.214]  Step 159871  [3.685 sec/step, loss=0.08753, avg_loss=0.08698, mel_loss=0.03813, linear_loss=0.04940]
[2020-05-12 11:52:54.193]  Step 159872  [3.726 sec/step, loss=0.09539, avg_loss=0.08701, mel_loss=0.04344, linear_loss=0.05195]
[2020-05-12 11:52:57.298]  Step 159873  [3.725 sec/step, loss=0.09354, avg_loss=0.08702, mel_loss=0.04127, linear_loss=0.05227]
[2020-05-12 11:52:57.976]  Step 159874  [3.667 sec/step, loss=0.07168, avg_loss=0.08679, mel_loss=0.03067, linear_loss=0.04101]
[2020-05-12 11:53:04.734]  Generated 32 batches of size 32 in 28.115 sec
[2020-05-12 11:53:08.357]  Step 159875  [3.761 sec/step, loss=0.09365, avg_loss=0.08695, mel_loss=0.04153, linear_loss=0.05212]
[2020-05-12 11:53:11.712]  Step 159876  [3.786 sec/step, loss=0.09339, avg_loss=0.08713, mel_loss=0.04106, linear_loss=0.05233]
[2020-05-12 11:53:16.752]  Step 159877  [3.822 sec/step, loss=0.09101, avg_loss=0.08721, mel_loss=0.04066, linear_loss=0.05035]
[2020-05-12 11:53:18.445]  Step 159878  [3.821 sec/step, loss=0.08623, avg_loss=0.08722, mel_loss=0.03725, linear_loss=0.04898]
[2020-05-12 11:53:19.597]  Step 159879  [3.748 sec/step, loss=0.08420, avg_loss=0.08713, mel_loss=0.03606, linear_loss=0.04815]
[2020-05-12 11:53:21.334]  Step 159880  [3.709 sec/step, loss=0.08730, avg_loss=0.08705, mel_loss=0.03737, linear_loss=0.04993]
[2020-05-12 11:53:22.127]  Step 159881  [3.691 sec/step, loss=0.06989, avg_loss=0.08686, mel_loss=0.03030, linear_loss=0.03959]
[2020-05-12 11:53:25.108]  Step 159882  [3.704 sec/step, loss=0.09261, avg_loss=0.08691, mel_loss=0.04095, linear_loss=0.05166]
[2020-05-12 11:53:27.863]  Step 159883  [3.363 sec/step, loss=0.08902, avg_loss=0.08687, mel_loss=0.03903, linear_loss=0.05000]
[2020-05-12 11:53:30.207]  Step 159884  [3.329 sec/step, loss=0.08832, avg_loss=0.08679, mel_loss=0.03843, linear_loss=0.04989]
[2020-05-12 11:53:31.814]  Step 159885  [3.336 sec/step, loss=0.08407, avg_loss=0.08686, mel_loss=0.03621, linear_loss=0.04786]
[2020-05-12 11:53:33.121]  Step 159886  [3.324 sec/step, loss=0.08363, avg_loss=0.08681, mel_loss=0.03594, linear_loss=0.04769]
[2020-05-12 11:53:34.024]  Step 159887  [3.296 sec/step, loss=0.07866, avg_loss=0.08665, mel_loss=0.03321, linear_loss=0.04546]
[2020-05-12 11:53:35.452]  Step 159888  [3.294 sec/step, loss=0.08359, avg_loss=0.08662, mel_loss=0.03594, linear_loss=0.04765]
[2020-05-12 11:53:44.068]  Step 159889  [3.366 sec/step, loss=0.09298, avg_loss=0.08671, mel_loss=0.04250, linear_loss=0.05048]
[2020-05-12 11:53:46.094]  Step 159890  [3.368 sec/step, loss=0.08868, avg_loss=0.08675, mel_loss=0.03824, linear_loss=0.05044]
[2020-05-12 11:53:48.546]  Step 159891  [3.380 sec/step, loss=0.08900, avg_loss=0.08684, mel_loss=0.03858, linear_loss=0.05042]
[2020-05-12 11:54:01.733]  Step 159892  [3.506 sec/step, loss=0.07858, avg_loss=0.08696, mel_loss=0.03658, linear_loss=0.04200]
[2020-05-12 11:54:09.231]  Step 159893  [3.562 sec/step, loss=0.09590, avg_loss=0.08702, mel_loss=0.04352, linear_loss=0.05238]
[2020-05-12 11:54:09.798]  Step 159894  [3.531 sec/step, loss=0.06619, avg_loss=0.08675, mel_loss=0.02888, linear_loss=0.03732]
[2020-05-12 11:54:10.611]  Step 159895  [3.529 sec/step, loss=0.07655, avg_loss=0.08671, mel_loss=0.03250, linear_loss=0.04405]
[2020-05-12 11:54:11.671]  Step 159896  [3.505 sec/step, loss=0.07813, avg_loss=0.08658, mel_loss=0.03320, linear_loss=0.04494]
[2020-05-12 11:54:14.581]  Step 159897  [3.525 sec/step, loss=0.09193, avg_loss=0.08670, mel_loss=0.04044, linear_loss=0.05149]
[2020-05-12 11:54:16.323]  Generated 32 batches of size 32 in 1.737 sec
[2020-05-12 11:54:19.032]  Step 159898  [3.439 sec/step, loss=0.09593, avg_loss=0.08686, mel_loss=0.04292, linear_loss=0.05302]
[2020-05-12 11:54:22.780]  Step 159899  [3.428 sec/step, loss=0.09524, avg_loss=0.08689, mel_loss=0.04208, linear_loss=0.05316]
[2020-05-12 11:54:26.250]  Step 159900  [3.435 sec/step, loss=0.09156, avg_loss=0.08691, mel_loss=0.04024, linear_loss=0.05132]
[2020-05-12 11:54:26.250]  Writing summary at step: 159900
[2020-05-12 11:54:27.386]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159900
[2020-05-12 11:54:29.000]  Saving audio and alignment...
[2020-05-12 11:54:32.466]  Input: 이러면 남자친구가 귀를 쫑긋 세워 줄까요~_
[2020-05-12 11:54:38.631]  Step 159901  [3.473 sec/step, loss=0.09356, avg_loss=0.08696, mel_loss=0.04231, linear_loss=0.05125]
[2020-05-12 11:54:43.938]  Step 159902  [3.496 sec/step, loss=0.09453, avg_loss=0.08699, mel_loss=0.04230, linear_loss=0.05223]
[2020-05-12 11:54:46.056]  Step 159903  [3.500 sec/step, loss=0.08807, avg_loss=0.08699, mel_loss=0.03836, linear_loss=0.04972]
[2020-05-12 11:54:50.458]  Step 159904  [3.522 sec/step, loss=0.09356, avg_loss=0.08706, mel_loss=0.04151, linear_loss=0.05206]
[2020-05-12 11:54:52.682]  Step 159905  [3.537 sec/step, loss=0.08927, avg_loss=0.08717, mel_loss=0.03889, linear_loss=0.05038]
[2020-05-12 11:54:59.492]  Step 159906  [3.551 sec/step, loss=0.09412, avg_loss=0.08714, mel_loss=0.04264, linear_loss=0.05149]
[2020-05-12 11:55:02.093]  Step 159907  [3.532 sec/step, loss=0.08836, avg_loss=0.08707, mel_loss=0.03860, linear_loss=0.04976]
[2020-05-12 11:55:06.197]  Step 159908  [3.509 sec/step, loss=0.09231, avg_loss=0.08705, mel_loss=0.04085, linear_loss=0.05145]
[2020-05-12 11:55:07.945]  Step 159909  [3.518 sec/step, loss=0.08635, avg_loss=0.08718, mel_loss=0.03706, linear_loss=0.04929]
[2020-05-12 11:55:09.555]  Step 159910  [3.522 sec/step, loss=0.08336, avg_loss=0.08720, mel_loss=0.03596, linear_loss=0.04740]
[2020-05-12 11:55:10.397]  Step 159911  [3.441 sec/step, loss=0.07418, avg_loss=0.08701, mel_loss=0.03134, linear_loss=0.04284]
[2020-05-12 11:55:15.707]  Step 159912  [3.479 sec/step, loss=0.09287, avg_loss=0.08709, mel_loss=0.04139, linear_loss=0.05148]
[2020-05-12 11:55:20.418]  Step 159913  [3.503 sec/step, loss=0.09387, avg_loss=0.08725, mel_loss=0.04183, linear_loss=0.05204]
[2020-05-12 11:55:22.048]  Step 159914  [3.505 sec/step, loss=0.08687, avg_loss=0.08729, mel_loss=0.03747, linear_loss=0.04940]
[2020-05-12 11:55:25.521]  Step 159915  [3.486 sec/step, loss=0.09059, avg_loss=0.08727, mel_loss=0.03996, linear_loss=0.05063]
[2020-05-12 11:55:26.493]  Step 159916  [3.478 sec/step, loss=0.07650, avg_loss=0.08717, mel_loss=0.03181, linear_loss=0.04469]
[2020-05-12 11:55:35.344]  Step 159917  [3.553 sec/step, loss=0.09173, avg_loss=0.08727, mel_loss=0.04192, linear_loss=0.04982]
[2020-05-12 11:55:37.639]  Step 159918  [3.570 sec/step, loss=0.08962, avg_loss=0.08748, mel_loss=0.03910, linear_loss=0.05052]
[2020-05-12 11:55:52.032]  Step 159919  [3.705 sec/step, loss=0.07390, avg_loss=0.08744, mel_loss=0.03479, linear_loss=0.03911]
[2020-05-12 11:55:56.429]  Step 159920  [3.724 sec/step, loss=0.09450, avg_loss=0.08749, mel_loss=0.04232, linear_loss=0.05218]
[2020-05-12 11:55:58.378]  Step 159921  [3.736 sec/step, loss=0.08475, avg_loss=0.08760, mel_loss=0.03649, linear_loss=0.04825]
[2020-05-12 11:55:59.454]  Step 159922  [3.672 sec/step, loss=0.07974, avg_loss=0.08743, mel_loss=0.03388, linear_loss=0.04586]
[2020-05-12 11:56:00.214]  Step 159923  [3.622 sec/step, loss=0.07844, avg_loss=0.08727, mel_loss=0.03316, linear_loss=0.04528]
[2020-05-12 11:56:01.370]  Step 159924  [3.589 sec/step, loss=0.08078, avg_loss=0.08715, mel_loss=0.03433, linear_loss=0.04645]
[2020-05-12 11:56:08.981]  Step 159925  [3.649 sec/step, loss=0.09636, avg_loss=0.08726, mel_loss=0.04392, linear_loss=0.05244]
[2020-05-12 11:56:11.042]  Step 159926  [3.647 sec/step, loss=0.08817, avg_loss=0.08728, mel_loss=0.03799, linear_loss=0.05018]
[2020-05-12 11:56:14.694]  Step 159927  [3.649 sec/step, loss=0.09311, avg_loss=0.08727, mel_loss=0.04124, linear_loss=0.05187]
[2020-05-12 11:56:17.844]  Step 159928  [3.649 sec/step, loss=0.09282, avg_loss=0.08727, mel_loss=0.04076, linear_loss=0.05206]
[2020-05-12 11:56:18.423]  Step 159929  [3.484 sec/step, loss=0.06912, avg_loss=0.08721, mel_loss=0.03011, linear_loss=0.03901]
[2020-05-12 11:56:19.763]  Step 159930  [3.485 sec/step, loss=0.08234, avg_loss=0.08723, mel_loss=0.03519, linear_loss=0.04715]
[2020-05-12 11:56:22.147]  Step 159931  [3.477 sec/step, loss=0.08995, avg_loss=0.08718, mel_loss=0.03904, linear_loss=0.05091]
[2020-05-12 11:56:25.054]  Step 159932  [3.478 sec/step, loss=0.08962, avg_loss=0.08716, mel_loss=0.03939, linear_loss=0.05023]
[2020-05-12 11:56:26.004]  Step 159933  [3.477 sec/step, loss=0.07872, avg_loss=0.08713, mel_loss=0.03357, linear_loss=0.04515]
[2020-05-12 11:56:27.374]  Step 159934  [3.473 sec/step, loss=0.08331, avg_loss=0.08710, mel_loss=0.03574, linear_loss=0.04757]
[2020-05-12 11:56:33.151]  Step 159935  [3.485 sec/step, loss=0.09569, avg_loss=0.08710, mel_loss=0.04302, linear_loss=0.05267]
[2020-05-12 11:56:36.380]  Step 159936  [3.498 sec/step, loss=0.09402, avg_loss=0.08715, mel_loss=0.04146, linear_loss=0.05256]
[2020-05-12 11:57:23.514]  Generated 32 batches of size 32 in 68.814 sec
[2020-05-12 11:57:24.930]  Step 159937  [3.962 sec/step, loss=0.08129, avg_loss=0.08707, mel_loss=0.03517, linear_loss=0.04612]
[2020-05-12 11:57:30.523]  Step 159938  [4.009 sec/step, loss=0.09664, avg_loss=0.08731, mel_loss=0.04345, linear_loss=0.05319]
[2020-05-12 11:57:31.529]  Step 159939  [3.999 sec/step, loss=0.07663, avg_loss=0.08720, mel_loss=0.03231, linear_loss=0.04431]
[2020-05-12 11:57:35.569]  Step 159940  [4.010 sec/step, loss=0.09364, avg_loss=0.08721, mel_loss=0.04148, linear_loss=0.05217]
[2020-05-12 11:57:44.051]  Step 159941  [4.005 sec/step, loss=0.09236, avg_loss=0.08721, mel_loss=0.04196, linear_loss=0.05040]
[2020-05-12 11:57:47.553]  Step 159942  [4.002 sec/step, loss=0.09108, avg_loss=0.08717, mel_loss=0.04039, linear_loss=0.05068]
[2020-05-12 11:57:49.732]  Step 159943  [3.956 sec/step, loss=0.08918, avg_loss=0.08710, mel_loss=0.03869, linear_loss=0.05049]
[2020-05-12 11:57:52.492]  Step 159944  [3.949 sec/step, loss=0.08936, avg_loss=0.08708, mel_loss=0.03911, linear_loss=0.05025]
[2020-05-12 11:57:55.905]  Step 159945  [3.852 sec/step, loss=0.09275, avg_loss=0.08706, mel_loss=0.04082, linear_loss=0.05193]
[2020-05-12 11:58:01.773]  Step 159946  [3.885 sec/step, loss=0.09555, avg_loss=0.08711, mel_loss=0.04337, linear_loss=0.05218]
[2020-05-12 11:58:06.167]  Step 159947  [3.905 sec/step, loss=0.09371, avg_loss=0.08715, mel_loss=0.04159, linear_loss=0.05212]
[2020-05-12 11:58:07.965]  Step 159948  [3.888 sec/step, loss=0.08552, avg_loss=0.08709, mel_loss=0.03691, linear_loss=0.04862]
[2020-05-12 11:58:09.517]  Step 159949  [3.820 sec/step, loss=0.08524, avg_loss=0.08700, mel_loss=0.03686, linear_loss=0.04838]
[2020-05-12 11:58:10.014]  Step 159950  [3.792 sec/step, loss=0.07138, avg_loss=0.08679, mel_loss=0.03087, linear_loss=0.04051]
[2020-05-12 11:58:10.014]  Writing summary at step: 159950
[2020-05-12 11:58:14.539]  Saving checkpoint to: ./logs-tacotron/model.ckpt-159950
[2020-05-12 11:58:16.198]  Saving audio and alignment...
[2020-05-12 11:58:18.801]  Input: 그 차이를 주면~__________________
[2020-05-12 11:58:19.882]  Step 159951  [3.785 sec/step, loss=0.08400, avg_loss=0.08677, mel_loss=0.03545, linear_loss=0.04855]
[2020-05-12 11:58:20.723]  Step 159952  [3.783 sec/step, loss=0.07227, avg_loss=0.08671, mel_loss=0.03119, linear_loss=0.04108]
[2020-05-12 11:58:23.273]  Step 159953  [3.766 sec/step, loss=0.08990, avg_loss=0.08668, mel_loss=0.03918, linear_loss=0.05072]
[2020-05-12 11:58:26.470]  Step 159954  [3.776 sec/step, loss=0.09136, avg_loss=0.08672, mel_loss=0.04031, linear_loss=0.05105]
[2020-05-12 11:58:31.224]  Step 159955  [3.682 sec/step, loss=0.09321, avg_loss=0.08691, mel_loss=0.04167, linear_loss=0.05154]
[2020-05-12 11:58:32.253]  Step 159956  [3.662 sec/step, loss=0.07823, avg_loss=0.08680, mel_loss=0.03322, linear_loss=0.04501]
[2020-05-12 11:58:33.862]  Step 159957  [3.658 sec/step, loss=0.08371, avg_loss=0.08679, mel_loss=0.03624, linear_loss=0.04748]
[2020-05-12 11:58:35.927]  Generated 32 batches of size 32 in 2.059 sec
[2020-05-12 11:58:36.938]  Step 159958  [3.620 sec/step, loss=0.09170, avg_loss=0.08677, mel_loss=0.04047, linear_loss=0.05123]
[2020-05-12 11:58:40.602]  Step 159959  [3.634 sec/step, loss=0.09497, avg_loss=0.08680, mel_loss=0.04215, linear_loss=0.05282]
[2020-05-12 11:58:47.568]  Step 159960  [3.691 sec/step, loss=0.09430, avg_loss=0.08694, mel_loss=0.04248, linear_loss=0.05182]
[2020-05-12 11:58:49.534]  Step 159961  [3.658 sec/step, loss=0.08581, avg_loss=0.08685, mel_loss=0.03723, linear_loss=0.04859]
[2020-05-12 11:59:02.696]  Step 159962  [3.743 sec/step, loss=0.07979, avg_loss=0.08670, mel_loss=0.03678, linear_loss=0.04301]
[2020-05-12 11:59:05.108]  Step 159963  [3.757 sec/step, loss=0.08801, avg_loss=0.08681, mel_loss=0.03848, linear_loss=0.04953]
[2020-05-12 11:59:07.127]  Step 159964  [3.770 sec/step, loss=0.08582, avg_loss=0.08689, mel_loss=0.03724, linear_loss=0.04858]
[2020-05-12 11:59:08.601]  Step 159965  [3.770 sec/step, loss=0.08385, avg_loss=0.08688, mel_loss=0.03628, linear_loss=0.04757]
[2020-05-12 11:59:09.473]  Step 159966  [3.741 sec/step, loss=0.07059, avg_loss=0.08666, mel_loss=0.02990, linear_loss=0.04068]
[2020-05-12 11:59:18.557]  Step 159967  [3.818 sec/step, loss=0.09492, avg_loss=0.08677, mel_loss=0.04363, linear_loss=0.05129]
[2020-05-12 11:59:19.663]  Step 159968  [3.813 sec/step, loss=0.08116, avg_loss=0.08671, mel_loss=0.03455, linear_loss=0.04661]
[2020-05-12 11:59:23.937]  Step 159969  [3.848 sec/step, loss=0.09308, avg_loss=0.08692, mel_loss=0.04169, linear_loss=0.05139]
[2020-05-12 11:59:29.415]  Step 159970  [3.892 sec/step, loss=0.09479, avg_loss=0.08705, mel_loss=0.04262, linear_loss=0.05217]
[2020-05-12 11:59:30.328]  Step 159971  [3.881 sec/step, loss=0.08021, avg_loss=0.08698, mel_loss=0.03400, linear_loss=0.04621]
[2020-05-12 11:59:32.705]  Step 159972  [3.835 sec/step, loss=0.09019, avg_loss=0.08693, mel_loss=0.03942, linear_loss=0.05077]
[2020-05-12 11:59:34.639]  Step 159973  [3.823 sec/step, loss=0.08889, avg_loss=0.08688, mel_loss=0.03864, linear_loss=0.05025]
[2020-05-12 11:59:36.269]  Step 159974  [3.833 sec/step, loss=0.08481, avg_loss=0.08701, mel_loss=0.03638, linear_loss=0.04843]
[2020-05-12 11:59:39.258]  Step 159975  [3.759 sec/step, loss=0.09287, avg_loss=0.08700, mel_loss=0.04126, linear_loss=0.05161]
[2020-05-12 11:59:41.317]  Step 159976  [3.746 sec/step, loss=0.08779, avg_loss=0.08695, mel_loss=0.03821, linear_loss=0.04958]
[2020-05-12 11:59:42.708]  Step 159977  [3.709 sec/step, loss=0.08475, avg_loss=0.08689, mel_loss=0.03656, linear_loss=0.04819]
[2020-05-12 11:59:46.171]  Step 159978  [3.727 sec/step, loss=0.09090, avg_loss=0.08693, mel_loss=0.04011, linear_loss=0.05079]
[2020-05-12 11:59:48.311]  Step 159979  [3.737 sec/step, loss=0.08929, avg_loss=0.08698, mel_loss=0.03868, linear_loss=0.05061]
[2020-05-12 11:59:49.100]  Step 159980  [3.727 sec/step, loss=0.07347, avg_loss=0.08685, mel_loss=0.03141, linear_loss=0.04207]
[2020-05-12 11:59:50.381]  Step 159981  [3.732 sec/step, loss=0.08255, avg_loss=0.08697, mel_loss=0.03531, linear_loss=0.04724]
[2020-05-12 11:59:53.893]  Step 159982  [3.738 sec/step, loss=0.09282, avg_loss=0.08697, mel_loss=0.04116, linear_loss=0.05166]
[2020-05-12 11:59:55.147]  Step 159983  [3.723 sec/step, loss=0.08102, avg_loss=0.08689, mel_loss=0.03457, linear_loss=0.04645]
[2020-05-12 11:59:56.925]  Step 159984  [3.717 sec/step, loss=0.08541, avg_loss=0.08686, mel_loss=0.03683, linear_loss=0.04858]
[2020-05-12 12:00:01.884]  Step 159985  [3.750 sec/step, loss=0.09416, avg_loss=0.08697, mel_loss=0.04200, linear_loss=0.05216]
[2020-05-12 12:00:02.915]  Step 159986  [3.748 sec/step, loss=0.07896, avg_loss=0.08692, mel_loss=0.03354, linear_loss=0.04541]
[2020-05-12 12:00:07.052]  Step 159987  [3.780 sec/step, loss=0.09302, avg_loss=0.08706, mel_loss=0.04124, linear_loss=0.05178]
[2020-05-12 12:00:07.885]  Step 159988  [3.774 sec/step, loss=0.07326, avg_loss=0.08696, mel_loss=0.03098, linear_loss=0.04227]
[2020-05-12 12:00:11.532]  Step 159989  [3.724 sec/step, loss=0.09442, avg_loss=0.08697, mel_loss=0.04198, linear_loss=0.05245]
[2020-05-12 12:00:12.115]  Step 159990  [3.710 sec/step, loss=0.07051, avg_loss=0.08679, mel_loss=0.03058, linear_loss=0.03993]
[2020-05-12 12:00:13.464]  Generated 32 batches of size 32 in 1.927 sec
[2020-05-12 12:00:15.094]  Step 159991  [3.715 sec/step, loss=0.09275, avg_loss=0.08683, mel_loss=0.04074, linear_loss=0.05201]
[2020-05-12 12:00:19.061]  Step 159992  [3.623 sec/step, loss=0.09101, avg_loss=0.08695, mel_loss=0.04014, linear_loss=0.05088]
[2020-05-12 12:00:26.480]  Step 159993  [3.622 sec/step, loss=0.09519, avg_loss=0.08695, mel_loss=0.04274, linear_loss=0.05246]
[2020-05-12 12:00:41.336]  Step 159994  [3.765 sec/step, loss=0.07532, avg_loss=0.08704, mel_loss=0.03520, linear_loss=0.04012]
[2020-05-12 12:00:47.949]  Step 159995  [3.823 sec/step, loss=0.09519, avg_loss=0.08722, mel_loss=0.04302, linear_loss=0.05217]
[2020-05-12 12:00:55.743]  Step 159996  [3.890 sec/step, loss=0.09552, avg_loss=0.08740, mel_loss=0.04345, linear_loss=0.05208]
[2020-05-12 12:00:57.577]  Step 159997  [3.880 sec/step, loss=0.08646, avg_loss=0.08734, mel_loss=0.03724, linear_loss=0.04921]
[2020-05-12 12:01:00.119]  Step 159998  [3.861 sec/step, loss=0.08841, avg_loss=0.08727, mel_loss=0.03857, linear_loss=0.04984]
[2020-05-12 12:01:04.713]  Step 159999  [3.869 sec/step, loss=0.09553, avg_loss=0.08727, mel_loss=0.04263, linear_loss=0.05290]
[2020-05-12 12:01:06.916]  Step 160000  [3.856 sec/step, loss=0.08890, avg_loss=0.08724, mel_loss=0.03884, linear_loss=0.05007]
[2020-05-12 12:01:06.916]  Writing summary at step: 160000
[2020-05-12 12:01:11.428]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160000
[2020-05-12 12:01:13.049]  Saving audio and alignment...
[2020-05-12 12:01:14.864]  Input: 제안을 합니다~__
[2020-05-12 12:01:16.180]  Step 160001  [3.808 sec/step, loss=0.08107, avg_loss=0.08712, mel_loss=0.03493, linear_loss=0.04614]
[2020-05-12 12:01:17.700]  Step 160002  [3.770 sec/step, loss=0.08391, avg_loss=0.08701, mel_loss=0.03606, linear_loss=0.04785]
[2020-05-12 12:01:18.715]  Step 160003  [3.759 sec/step, loss=0.07640, avg_loss=0.08690, mel_loss=0.03239, linear_loss=0.04401]
[2020-05-12 12:01:19.666]  Step 160004  [3.724 sec/step, loss=0.07763, avg_loss=0.08674, mel_loss=0.03319, linear_loss=0.04444]
[2020-05-12 12:01:28.225]  Step 160005  [3.788 sec/step, loss=0.09237, avg_loss=0.08677, mel_loss=0.04203, linear_loss=0.05033]
[2020-05-12 12:01:30.999]  Step 160006  [3.747 sec/step, loss=0.08940, avg_loss=0.08672, mel_loss=0.03914, linear_loss=0.05026]
[2020-05-12 12:01:36.320]  Step 160007  [3.775 sec/step, loss=0.09342, avg_loss=0.08677, mel_loss=0.04162, linear_loss=0.05180]
[2020-05-12 12:01:48.687]  Step 160008  [3.857 sec/step, loss=0.08420, avg_loss=0.08669, mel_loss=0.03937, linear_loss=0.04484]
[2020-05-12 12:01:52.110]  Step 160009  [3.874 sec/step, loss=0.09472, avg_loss=0.08677, mel_loss=0.04164, linear_loss=0.05308]
[2020-05-12 12:01:54.548]  Step 160010  [3.882 sec/step, loss=0.08774, avg_loss=0.08682, mel_loss=0.03821, linear_loss=0.04953]
[2020-05-12 12:01:57.985]  Step 160011  [3.908 sec/step, loss=0.09084, avg_loss=0.08698, mel_loss=0.03988, linear_loss=0.05097]
[2020-05-12 12:02:03.680]  Step 160012  [3.912 sec/step, loss=0.09432, avg_loss=0.08700, mel_loss=0.04237, linear_loss=0.05195]
[2020-05-12 12:02:06.187]  Step 160013  [3.890 sec/step, loss=0.08877, avg_loss=0.08695, mel_loss=0.03826, linear_loss=0.05052]
[2020-05-12 12:02:08.094]  Step 160014  [3.893 sec/step, loss=0.08669, avg_loss=0.08695, mel_loss=0.03762, linear_loss=0.04907]
[2020-05-12 12:02:09.498]  Step 160015  [3.872 sec/step, loss=0.08313, avg_loss=0.08687, mel_loss=0.03558, linear_loss=0.04755]
[2020-05-12 12:02:11.267]  Step 160016  [3.880 sec/step, loss=0.08533, avg_loss=0.08696, mel_loss=0.03660, linear_loss=0.04873]
[2020-05-12 12:02:18.433]  Step 160017  [3.863 sec/step, loss=0.09755, avg_loss=0.08702, mel_loss=0.04419, linear_loss=0.05337]
[2020-05-12 12:02:19.000]  Step 160018  [3.846 sec/step, loss=0.06996, avg_loss=0.08682, mel_loss=0.03068, linear_loss=0.03928]
[2020-05-12 12:02:23.020]  Step 160019  [3.742 sec/step, loss=0.09193, avg_loss=0.08700, mel_loss=0.04075, linear_loss=0.05117]
[2020-05-12 12:02:24.182]  Step 160020  [3.710 sec/step, loss=0.08027, avg_loss=0.08686, mel_loss=0.03427, linear_loss=0.04600]
[2020-05-12 12:02:27.152]  Step 160021  [3.720 sec/step, loss=0.09134, avg_loss=0.08693, mel_loss=0.03989, linear_loss=0.05145]
[2020-05-12 12:02:29.305]  Step 160022  [3.731 sec/step, loss=0.08784, avg_loss=0.08701, mel_loss=0.03797, linear_loss=0.04987]
[2020-05-12 12:02:31.071]  Step 160023  [3.741 sec/step, loss=0.08576, avg_loss=0.08708, mel_loss=0.03731, linear_loss=0.04845]
[2020-05-12 12:02:34.431]  Step 160024  [3.763 sec/step, loss=0.09411, avg_loss=0.08721, mel_loss=0.04171, linear_loss=0.05240]
[2020-05-12 12:02:35.375]  Step 160025  [3.696 sec/step, loss=0.06936, avg_loss=0.08694, mel_loss=0.02968, linear_loss=0.03968]
[2020-05-12 12:02:36.585]  Step 160026  [3.688 sec/step, loss=0.08055, avg_loss=0.08687, mel_loss=0.03434, linear_loss=0.04621]
[2020-05-12 12:02:43.516]  Step 160027  [3.721 sec/step, loss=0.09456, avg_loss=0.08688, mel_loss=0.04276, linear_loss=0.05180]
[2020-05-12 12:02:47.093]  Step 160028  [3.725 sec/step, loss=0.09475, avg_loss=0.08690, mel_loss=0.04191, linear_loss=0.05284]
[2020-05-12 12:03:41.491]  Generated 32 batches of size 32 in 78.466 sec
[2020-05-12 12:03:42.091]  Step 160029  [4.269 sec/step, loss=0.06645, avg_loss=0.08687, mel_loss=0.02884, linear_loss=0.03760]
[2020-05-12 12:03:45.566]  Step 160030  [4.290 sec/step, loss=0.09164, avg_loss=0.08697, mel_loss=0.04061, linear_loss=0.05103]
[2020-05-12 12:03:46.485]  Step 160031  [4.276 sec/step, loss=0.07819, avg_loss=0.08685, mel_loss=0.03293, linear_loss=0.04526]
[2020-05-12 12:03:55.323]  Step 160032  [4.335 sec/step, loss=0.09407, avg_loss=0.08689, mel_loss=0.04301, linear_loss=0.05106]
[2020-05-12 12:03:57.091]  Step 160033  [4.343 sec/step, loss=0.08757, avg_loss=0.08698, mel_loss=0.03759, linear_loss=0.04997]
[2020-05-12 12:04:00.228]  Step 160034  [4.361 sec/step, loss=0.09266, avg_loss=0.08708, mel_loss=0.04074, linear_loss=0.05191]
[2020-05-12 12:04:04.261]  Step 160035  [4.344 sec/step, loss=0.09364, avg_loss=0.08706, mel_loss=0.04147, linear_loss=0.05217]
[2020-05-12 12:04:05.076]  Step 160036  [4.319 sec/step, loss=0.07388, avg_loss=0.08685, mel_loss=0.03135, linear_loss=0.04253]
[2020-05-12 12:04:07.638]  Step 160037  [3.859 sec/step, loss=0.08933, avg_loss=0.08693, mel_loss=0.03923, linear_loss=0.05009]
[2020-05-12 12:04:09.633]  Step 160038  [3.823 sec/step, loss=0.08647, avg_loss=0.08683, mel_loss=0.03764, linear_loss=0.04884]
[2020-05-12 12:04:13.762]  Step 160039  [3.855 sec/step, loss=0.09282, avg_loss=0.08699, mel_loss=0.04104, linear_loss=0.05178]
[2020-05-12 12:04:28.187]  Step 160040  [3.959 sec/step, loss=0.07406, avg_loss=0.08680, mel_loss=0.03458, linear_loss=0.03949]
[2020-05-12 12:04:30.986]  Step 160041  [3.902 sec/step, loss=0.08971, avg_loss=0.08677, mel_loss=0.03935, linear_loss=0.05036]
[2020-05-12 12:04:32.142]  Step 160042  [3.878 sec/step, loss=0.07866, avg_loss=0.08665, mel_loss=0.03358, linear_loss=0.04507]
[2020-05-12 12:04:32.856]  Step 160043  [3.864 sec/step, loss=0.07372, avg_loss=0.08649, mel_loss=0.03127, linear_loss=0.04245]
[2020-05-12 12:04:37.812]  Step 160044  [3.886 sec/step, loss=0.09361, avg_loss=0.08654, mel_loss=0.04195, linear_loss=0.05165]
[2020-05-12 12:04:44.146]  Step 160045  [3.915 sec/step, loss=0.09401, avg_loss=0.08655, mel_loss=0.04250, linear_loss=0.05150]
[2020-05-12 12:04:49.799]  Step 160046  [3.913 sec/step, loss=0.09373, avg_loss=0.08653, mel_loss=0.04204, linear_loss=0.05169]
[2020-05-12 12:04:51.444]  Step 160047  [3.885 sec/step, loss=0.08555, avg_loss=0.08645, mel_loss=0.03674, linear_loss=0.04881]
[2020-05-12 12:04:52.708]  Step 160048  [3.880 sec/step, loss=0.08194, avg_loss=0.08641, mel_loss=0.03496, linear_loss=0.04698]
[2020-05-12 12:04:54.615]  Step 160049  [3.883 sec/step, loss=0.08495, avg_loss=0.08641, mel_loss=0.03650, linear_loss=0.04845]
[2020-05-12 12:04:56.021]  Step 160050  [3.892 sec/step, loss=0.08383, avg_loss=0.08653, mel_loss=0.03604, linear_loss=0.04779]
[2020-05-12 12:04:56.021]  Writing summary at step: 160050
[2020-05-12 12:04:58.272]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160050
[2020-05-12 12:04:59.892]  Saving audio and alignment...
[2020-05-12 12:05:03.797]  Input: 총장님이 결국에 이런 말씀을 하시더라고요~
[2020-05-12 12:05:04.872]  Step 160051  [3.892 sec/step, loss=0.07628, avg_loss=0.08646, mel_loss=0.03262, linear_loss=0.04367]
[2020-05-12 12:05:08.463]  Step 160052  [3.920 sec/step, loss=0.09440, avg_loss=0.08668, mel_loss=0.04202, linear_loss=0.05238]
[2020-05-12 12:05:10.162]  Step 160053  [3.911 sec/step, loss=0.08485, avg_loss=0.08663, mel_loss=0.03672, linear_loss=0.04813]
[2020-05-12 12:05:17.502]  Step 160054  [3.953 sec/step, loss=0.09493, avg_loss=0.08666, mel_loss=0.04321, linear_loss=0.05171]
[2020-05-12 12:05:18.972]  Step 160055  [3.920 sec/step, loss=0.08350, avg_loss=0.08657, mel_loss=0.03602, linear_loss=0.04749]
[2020-05-12 12:05:21.291]  Step 160056  [3.933 sec/step, loss=0.08926, avg_loss=0.08668, mel_loss=0.03903, linear_loss=0.05023]
[2020-05-12 12:05:25.798]  Step 160057  [3.962 sec/step, loss=0.09494, avg_loss=0.08679, mel_loss=0.04233, linear_loss=0.05260]
[2020-05-12 12:05:28.804]  Step 160058  [3.961 sec/step, loss=0.09234, avg_loss=0.08680, mel_loss=0.04088, linear_loss=0.05146]
[2020-05-12 12:05:31.354]  Generated 32 batches of size 32 in 30.826 sec
[2020-05-12 12:05:37.034]  Step 160059  [4.007 sec/step, loss=0.09494, avg_loss=0.08680, mel_loss=0.04277, linear_loss=0.05217]
[2020-05-12 12:05:38.031]  Step 160060  [3.947 sec/step, loss=0.07832, avg_loss=0.08664, mel_loss=0.03315, linear_loss=0.04516]
[2020-05-12 12:05:40.461]  Step 160061  [3.952 sec/step, loss=0.08965, avg_loss=0.08667, mel_loss=0.03905, linear_loss=0.05060]
[2020-05-12 12:05:46.631]  Step 160062  [3.882 sec/step, loss=0.09558, avg_loss=0.08683, mel_loss=0.04317, linear_loss=0.05241]
[2020-05-12 12:05:50.622]  Step 160063  [3.898 sec/step, loss=0.09330, avg_loss=0.08688, mel_loss=0.04146, linear_loss=0.05184]
[2020-05-12 12:05:51.606]  Step 160064  [3.887 sec/step, loss=0.07794, avg_loss=0.08681, mel_loss=0.03267, linear_loss=0.04527]
[2020-05-12 12:05:53.617]  Step 160065  [3.893 sec/step, loss=0.08668, avg_loss=0.08683, mel_loss=0.03758, linear_loss=0.04910]
[2020-05-12 12:05:55.379]  Step 160066  [3.902 sec/step, loss=0.08432, avg_loss=0.08697, mel_loss=0.03617, linear_loss=0.04815]
[2020-05-12 12:05:57.263]  Step 160067  [3.830 sec/step, loss=0.08728, avg_loss=0.08690, mel_loss=0.03769, linear_loss=0.04959]
[2020-05-12 12:06:00.843]  Step 160068  [3.854 sec/step, loss=0.09348, avg_loss=0.08702, mel_loss=0.04159, linear_loss=0.05189]
[2020-05-12 12:06:05.519]  Step 160069  [3.858 sec/step, loss=0.09357, avg_loss=0.08702, mel_loss=0.04158, linear_loss=0.05199]
[2020-05-12 12:06:10.921]  Step 160070  [3.858 sec/step, loss=0.09271, avg_loss=0.08700, mel_loss=0.04148, linear_loss=0.05122]
[2020-05-12 12:06:11.724]  Step 160071  [3.856 sec/step, loss=0.07521, avg_loss=0.08695, mel_loss=0.03157, linear_loss=0.04365]
[2020-05-12 12:06:13.850]  Step 160072  [3.854 sec/step, loss=0.08907, avg_loss=0.08694, mel_loss=0.03905, linear_loss=0.05002]
[2020-05-12 12:06:16.717]  Step 160073  [3.863 sec/step, loss=0.08997, avg_loss=0.08695, mel_loss=0.03968, linear_loss=0.05029]
[2020-05-12 12:06:28.178]  Step 160074  [3.962 sec/step, loss=0.08615, avg_loss=0.08697, mel_loss=0.04021, linear_loss=0.04594]
[2020-05-12 12:06:30.872]  Step 160075  [3.959 sec/step, loss=0.09051, avg_loss=0.08694, mel_loss=0.03971, linear_loss=0.05080]
[2020-05-12 12:06:34.250]  Step 160076  [3.972 sec/step, loss=0.09204, avg_loss=0.08698, mel_loss=0.04039, linear_loss=0.05165]
[2020-05-12 12:06:34.802]  Step 160077  [3.963 sec/step, loss=0.06928, avg_loss=0.08683, mel_loss=0.03006, linear_loss=0.03921]
[2020-05-12 12:06:42.876]  Step 160078  [4.010 sec/step, loss=0.09434, avg_loss=0.08686, mel_loss=0.04320, linear_loss=0.05114]
[2020-05-12 12:06:47.179]  Step 160079  [4.031 sec/step, loss=0.09380, avg_loss=0.08691, mel_loss=0.04172, linear_loss=0.05207]
[2020-05-12 12:06:48.528]  Step 160080  [4.037 sec/step, loss=0.08327, avg_loss=0.08701, mel_loss=0.03545, linear_loss=0.04782]
[2020-05-12 12:06:51.979]  Step 160081  [4.058 sec/step, loss=0.09093, avg_loss=0.08709, mel_loss=0.04024, linear_loss=0.05068]
[2020-05-12 12:06:53.604]  Step 160082  [4.040 sec/step, loss=0.08391, avg_loss=0.08700, mel_loss=0.03620, linear_loss=0.04770]
[2020-05-12 12:06:55.005]  Step 160083  [4.041 sec/step, loss=0.08386, avg_loss=0.08703, mel_loss=0.03610, linear_loss=0.04776]
[2020-05-12 12:06:58.131]  Step 160084  [4.055 sec/step, loss=0.09061, avg_loss=0.08708, mel_loss=0.03985, linear_loss=0.05076]
[2020-05-12 12:06:59.364]  Step 160085  [4.017 sec/step, loss=0.07938, avg_loss=0.08693, mel_loss=0.03435, linear_loss=0.04503]
[2020-05-12 12:07:00.407]  Step 160086  [4.017 sec/step, loss=0.08153, avg_loss=0.08696, mel_loss=0.03464, linear_loss=0.04689]
[2020-05-12 12:07:02.754]  Step 160087  [4.000 sec/step, loss=0.09060, avg_loss=0.08694, mel_loss=0.03968, linear_loss=0.05092]
[2020-05-12 12:07:03.536]  Step 160088  [3.999 sec/step, loss=0.07133, avg_loss=0.08692, mel_loss=0.03035, linear_loss=0.04098]
[2020-05-12 12:07:04.174]  Generated 32 batches of size 32 in 12.190 sec
[2020-05-12 12:07:10.918]  Step 160089  [4.036 sec/step, loss=0.09589, avg_loss=0.08693, mel_loss=0.04350, linear_loss=0.05239]
[2020-05-12 12:07:12.572]  Step 160090  [4.047 sec/step, loss=0.08543, avg_loss=0.08708, mel_loss=0.03707, linear_loss=0.04836]
[2020-05-12 12:07:13.545]  Step 160091  [4.027 sec/step, loss=0.08091, avg_loss=0.08696, mel_loss=0.03429, linear_loss=0.04662]
[2020-05-12 12:07:15.325]  Step 160092  [4.005 sec/step, loss=0.08601, avg_loss=0.08691, mel_loss=0.03690, linear_loss=0.04911]
[2020-05-12 12:07:16.431]  Step 160093  [3.942 sec/step, loss=0.07912, avg_loss=0.08675, mel_loss=0.03359, linear_loss=0.04554]
[2020-05-12 12:07:20.090]  Step 160094  [3.830 sec/step, loss=0.09428, avg_loss=0.08694, mel_loss=0.04165, linear_loss=0.05264]
[2020-05-12 12:07:24.123]  Step 160095  [3.804 sec/step, loss=0.09283, avg_loss=0.08692, mel_loss=0.04111, linear_loss=0.05172]
[2020-05-12 12:07:24.874]  Step 160096  [3.734 sec/step, loss=0.07724, avg_loss=0.08673, mel_loss=0.03306, linear_loss=0.04418]
[2020-05-12 12:07:26.202]  Step 160097  [3.729 sec/step, loss=0.08225, avg_loss=0.08669, mel_loss=0.03527, linear_loss=0.04698]
[2020-05-12 12:07:28.798]  Step 160098  [3.729 sec/step, loss=0.08914, avg_loss=0.08670, mel_loss=0.03899, linear_loss=0.05015]
[2020-05-12 12:07:36.342]  Step 160099  [3.759 sec/step, loss=0.09498, avg_loss=0.08669, mel_loss=0.04323, linear_loss=0.05175]
[2020-05-12 12:07:37.718]  Step 160100  [3.751 sec/step, loss=0.08443, avg_loss=0.08665, mel_loss=0.03641, linear_loss=0.04803]
[2020-05-12 12:07:37.718]  Writing summary at step: 160100
[2020-05-12 12:07:47.177]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160100
[2020-05-12 12:07:48.783]  Saving audio and alignment...
[2020-05-12 12:07:56.845]  Input: 이렇게요 그 다음 해답은 오늘 컨퍼런스의 주제 별로 안중요해요 키워드~___________________________________
[2020-05-12 12:08:03.556]  Step 160101  [3.804 sec/step, loss=0.09350, avg_loss=0.08677, mel_loss=0.04230, linear_loss=0.05120]
[2020-05-12 12:08:06.988]  Step 160102  [3.824 sec/step, loss=0.09205, avg_loss=0.08686, mel_loss=0.04062, linear_loss=0.05142]
[2020-05-12 12:08:08.535]  Step 160103  [3.829 sec/step, loss=0.08398, avg_loss=0.08693, mel_loss=0.03617, linear_loss=0.04781]
[2020-05-12 12:08:10.563]  Step 160104  [3.840 sec/step, loss=0.08779, avg_loss=0.08703, mel_loss=0.03805, linear_loss=0.04974]
[2020-05-12 12:08:13.734]  Step 160105  [3.786 sec/step, loss=0.09461, avg_loss=0.08705, mel_loss=0.04191, linear_loss=0.05271]
[2020-05-12 12:08:16.197]  Step 160106  [3.783 sec/step, loss=0.08775, avg_loss=0.08704, mel_loss=0.03805, linear_loss=0.04970]
[2020-05-12 12:08:16.915]  Step 160107  [3.737 sec/step, loss=0.07398, avg_loss=0.08684, mel_loss=0.03134, linear_loss=0.04264]
[2020-05-12 12:08:19.057]  Step 160108  [3.634 sec/step, loss=0.08797, avg_loss=0.08688, mel_loss=0.03834, linear_loss=0.04964]
[2020-05-12 12:08:24.098]  Step 160109  [3.651 sec/step, loss=0.09397, avg_loss=0.08687, mel_loss=0.04219, linear_loss=0.05178]
[2020-05-12 12:08:25.973]  Step 160110  [3.645 sec/step, loss=0.08696, avg_loss=0.08687, mel_loss=0.03779, linear_loss=0.04917]
[2020-05-12 12:08:28.857]  Step 160111  [3.639 sec/step, loss=0.09070, avg_loss=0.08687, mel_loss=0.03998, linear_loss=0.05072]
[2020-05-12 12:08:30.629]  Step 160112  [3.600 sec/step, loss=0.08609, avg_loss=0.08678, mel_loss=0.03736, linear_loss=0.04872]
[2020-05-12 12:08:30.635]  Generated 32 batches of size 32 in 1.773 sec
[2020-05-12 12:08:31.843]  Step 160113  [3.587 sec/step, loss=0.08108, avg_loss=0.08671, mel_loss=0.03440, linear_loss=0.04668]
[2020-05-12 12:08:36.479]  Step 160114  [3.615 sec/step, loss=0.09395, avg_loss=0.08678, mel_loss=0.04199, linear_loss=0.05196]
[2020-05-12 12:08:50.893]  Step 160115  [3.745 sec/step, loss=0.07579, avg_loss=0.08671, mel_loss=0.03552, linear_loss=0.04027]
[2020-05-12 12:08:53.295]  Step 160116  [3.751 sec/step, loss=0.08694, avg_loss=0.08672, mel_loss=0.03788, linear_loss=0.04906]
[2020-05-12 12:08:54.052]  Step 160117  [3.687 sec/step, loss=0.06912, avg_loss=0.08644, mel_loss=0.03029, linear_loss=0.03883]
[2020-05-12 12:08:58.230]  Step 160118  [3.723 sec/step, loss=0.09495, avg_loss=0.08669, mel_loss=0.04224, linear_loss=0.05271]
[2020-05-12 12:08:59.108]  Step 160119  [3.692 sec/step, loss=0.07537, avg_loss=0.08652, mel_loss=0.03198, linear_loss=0.04339]
[2020-05-12 12:09:02.214]  Step 160120  [3.711 sec/step, loss=0.09322, avg_loss=0.08665, mel_loss=0.04108, linear_loss=0.05214]
[2020-05-12 12:09:03.442]  Step 160121  [3.694 sec/step, loss=0.08292, avg_loss=0.08657, mel_loss=0.03546, linear_loss=0.04746]
[2020-05-12 12:09:05.277]  Step 160122  [3.690 sec/step, loss=0.08530, avg_loss=0.08654, mel_loss=0.03685, linear_loss=0.04845]
[2020-05-12 12:09:12.024]  Step 160123  [3.740 sec/step, loss=0.09461, avg_loss=0.08663, mel_loss=0.04282, linear_loss=0.05180]
[2020-05-12 12:09:14.425]  Step 160124  [3.731 sec/step, loss=0.08836, avg_loss=0.08657, mel_loss=0.03837, linear_loss=0.04999]
[2020-05-12 12:09:17.135]  Step 160125  [3.748 sec/step, loss=0.08858, avg_loss=0.08676, mel_loss=0.03869, linear_loss=0.04989]
[2020-05-12 12:09:17.899]  Step 160126  [3.744 sec/step, loss=0.07458, avg_loss=0.08670, mel_loss=0.03176, linear_loss=0.04282]
[2020-05-12 12:09:32.125]  Step 160127  [3.817 sec/step, loss=0.07470, avg_loss=0.08651, mel_loss=0.03516, linear_loss=0.03954]
[2020-05-12 12:09:33.178]  Step 160128  [3.792 sec/step, loss=0.08117, avg_loss=0.08637, mel_loss=0.03464, linear_loss=0.04652]
[2020-05-12 12:09:37.360]  Step 160129  [3.283 sec/step, loss=0.09522, avg_loss=0.08666, mel_loss=0.04254, linear_loss=0.05269]
[2020-05-12 12:09:37.894]  Step 160130  [3.254 sec/step, loss=0.06778, avg_loss=0.08642, mel_loss=0.02935, linear_loss=0.03843]
[2020-05-12 12:09:38.850]  Step 160131  [3.254 sec/step, loss=0.08057, avg_loss=0.08644, mel_loss=0.03394, linear_loss=0.04664]
[2020-05-12 12:09:42.544]  Step 160132  [3.203 sec/step, loss=0.09359, avg_loss=0.08644, mel_loss=0.04146, linear_loss=0.05213]
[2020-05-12 12:09:43.691]  Step 160133  [3.197 sec/step, loss=0.07936, avg_loss=0.08636, mel_loss=0.03372, linear_loss=0.04563]
[2020-05-12 12:09:48.388]  Step 160134  [3.212 sec/step, loss=0.09457, avg_loss=0.08638, mel_loss=0.04199, linear_loss=0.05258]
[2020-05-12 12:09:54.099]  Step 160135  [3.229 sec/step, loss=0.09554, avg_loss=0.08639, mel_loss=0.04325, linear_loss=0.05230]
[2020-05-12 12:09:55.484]  Step 160136  [3.235 sec/step, loss=0.08255, avg_loss=0.08648, mel_loss=0.03565, linear_loss=0.04690]
[2020-05-12 12:09:58.418]  Step 160137  [3.239 sec/step, loss=0.08840, avg_loss=0.08647, mel_loss=0.03900, linear_loss=0.04941]
[2020-05-12 12:10:05.982]  Step 160138  [3.294 sec/step, loss=0.09672, avg_loss=0.08657, mel_loss=0.04394, linear_loss=0.05278]
[2020-05-12 12:10:07.650]  Step 160139  [3.270 sec/step, loss=0.08618, avg_loss=0.08651, mel_loss=0.03718, linear_loss=0.04900]
[2020-05-12 12:10:09.176]  Step 160140  [3.141 sec/step, loss=0.08354, avg_loss=0.08660, mel_loss=0.03596, linear_loss=0.04758]
[2020-05-12 12:10:10.186]  Step 160141  [3.123 sec/step, loss=0.07846, avg_loss=0.08649, mel_loss=0.03327, linear_loss=0.04519]
[2020-05-12 12:10:11.008]  Step 160142  [3.119 sec/step, loss=0.07407, avg_loss=0.08644, mel_loss=0.03144, linear_loss=0.04264]
[2020-05-12 12:10:14.552]  Step 160143  [3.148 sec/step, loss=0.09214, avg_loss=0.08663, mel_loss=0.04065, linear_loss=0.05149]
[2020-05-12 12:10:16.316]  Step 160144  [3.116 sec/step, loss=0.08335, avg_loss=0.08653, mel_loss=0.03587, linear_loss=0.04748]
[2020-05-12 12:10:18.508]  Step 160145  [3.074 sec/step, loss=0.08765, avg_loss=0.08646, mel_loss=0.03834, linear_loss=0.04931]
[2020-05-12 12:10:23.609]  Step 160146  [3.069 sec/step, loss=0.09535, avg_loss=0.08648, mel_loss=0.04276, linear_loss=0.05260]
[2020-05-12 12:10:29.088]  Step 160147  [3.107 sec/step, loss=0.09297, avg_loss=0.08655, mel_loss=0.04126, linear_loss=0.05171]
[2020-05-12 12:10:33.732]  Step 160148  [3.141 sec/step, loss=0.09291, avg_loss=0.08666, mel_loss=0.04084, linear_loss=0.05207]
[2020-05-12 12:10:35.858]  Step 160149  [3.143 sec/step, loss=0.08726, avg_loss=0.08669, mel_loss=0.03781, linear_loss=0.04945]
[2020-05-12 12:10:38.273]  Step 160150  [3.153 sec/step, loss=0.08927, avg_loss=0.08674, mel_loss=0.03911, linear_loss=0.05017]
[2020-05-12 12:10:38.273]  Writing summary at step: 160150
[2020-05-12 12:10:47.442]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160150
[2020-05-12 12:10:49.074]  Saving audio and alignment...
[2020-05-12 12:10:54.489]  Input: 퀴즈 프로그램에서 정말로 중요한 정답을 발표할 때 어떻게 하나요~________
[2020-05-12 12:11:26.976]  Generated 32 batches of size 32 in 72.419 sec
[2020-05-12 12:11:35.859]  Step 160151  [3.556 sec/step, loss=0.09387, avg_loss=0.08692, mel_loss=0.04285, linear_loss=0.05102]
[2020-05-12 12:11:36.634]  Step 160152  [3.528 sec/step, loss=0.07026, avg_loss=0.08667, mel_loss=0.03049, linear_loss=0.03977]
[2020-05-12 12:11:39.249]  Step 160153  [3.537 sec/step, loss=0.09235, avg_loss=0.08675, mel_loss=0.04075, linear_loss=0.05160]
[2020-05-12 12:11:43.323]  Step 160154  [3.505 sec/step, loss=0.09345, avg_loss=0.08673, mel_loss=0.04158, linear_loss=0.05187]
[2020-05-12 12:11:44.087]  Step 160155  [3.497 sec/step, loss=0.06909, avg_loss=0.08659, mel_loss=0.02958, linear_loss=0.03951]
[2020-05-12 12:11:56.373]  Step 160156  [3.597 sec/step, loss=0.08421, avg_loss=0.08654, mel_loss=0.03920, linear_loss=0.04501]
[2020-05-12 12:11:57.347]  Step 160157  [3.562 sec/step, loss=0.07732, avg_loss=0.08636, mel_loss=0.03303, linear_loss=0.04429]
[2020-05-12 12:12:00.610]  Step 160158  [3.564 sec/step, loss=0.09475, avg_loss=0.08639, mel_loss=0.04173, linear_loss=0.05302]
[2020-05-12 12:12:03.110]  Step 160159  [3.507 sec/step, loss=0.08883, avg_loss=0.08633, mel_loss=0.03862, linear_loss=0.05021]
[2020-05-12 12:12:05.072]  Step 160160  [3.517 sec/step, loss=0.08651, avg_loss=0.08641, mel_loss=0.03750, linear_loss=0.04900]
[2020-05-12 12:12:10.529]  Step 160161  [3.547 sec/step, loss=0.09428, avg_loss=0.08646, mel_loss=0.04232, linear_loss=0.05197]
[2020-05-12 12:12:11.754]  Step 160162  [3.498 sec/step, loss=0.08195, avg_loss=0.08632, mel_loss=0.03519, linear_loss=0.04676]
[2020-05-12 12:12:13.556]  Step 160163  [3.476 sec/step, loss=0.08832, avg_loss=0.08627, mel_loss=0.03809, linear_loss=0.05023]
[2020-05-12 12:12:15.679]  Step 160164  [3.487 sec/step, loss=0.08900, avg_loss=0.08638, mel_loss=0.03874, linear_loss=0.05026]
[2020-05-12 12:12:17.285]  Step 160165  [3.483 sec/step, loss=0.08519, avg_loss=0.08637, mel_loss=0.03685, linear_loss=0.04834]
[2020-05-12 12:12:18.093]  Step 160166  [3.473 sec/step, loss=0.07439, avg_loss=0.08627, mel_loss=0.03130, linear_loss=0.04309]
[2020-05-12 12:12:20.057]  Step 160167  [3.474 sec/step, loss=0.08949, avg_loss=0.08629, mel_loss=0.03894, linear_loss=0.05055]
[2020-05-12 12:12:24.521]  Step 160168  [3.483 sec/step, loss=0.09557, avg_loss=0.08631, mel_loss=0.04262, linear_loss=0.05294]
[2020-05-12 12:12:26.062]  Step 160169  [3.452 sec/step, loss=0.08542, avg_loss=0.08623, mel_loss=0.03688, linear_loss=0.04854]
[2020-05-12 12:12:29.805]  Step 160170  [3.435 sec/step, loss=0.09378, avg_loss=0.08624, mel_loss=0.04161, linear_loss=0.05217]
[2020-05-12 12:12:34.637]  Step 160171  [3.475 sec/step, loss=0.09329, avg_loss=0.08642, mel_loss=0.04178, linear_loss=0.05152]
[2020-05-12 12:12:35.685]  Step 160172  [3.465 sec/step, loss=0.07900, avg_loss=0.08632, mel_loss=0.03379, linear_loss=0.04521]
[2020-05-12 12:12:36.999]  Step 160173  [3.449 sec/step, loss=0.08091, avg_loss=0.08623, mel_loss=0.03445, linear_loss=0.04645]
[2020-05-12 12:12:39.294]  Step 160174  [3.357 sec/step, loss=0.08693, avg_loss=0.08624, mel_loss=0.03812, linear_loss=0.04882]
[2020-05-12 12:12:46.602]  Step 160175  [3.404 sec/step, loss=0.09451, avg_loss=0.08628, mel_loss=0.04299, linear_loss=0.05152]
[2020-05-12 12:12:48.001]  Step 160176  [3.384 sec/step, loss=0.08353, avg_loss=0.08619, mel_loss=0.03591, linear_loss=0.04762]
[2020-05-12 12:12:51.487]  Step 160177  [3.413 sec/step, loss=0.09070, avg_loss=0.08640, mel_loss=0.04014, linear_loss=0.05057]
[2020-05-12 12:12:54.572]  Step 160178  [3.363 sec/step, loss=0.09107, avg_loss=0.08637, mel_loss=0.03993, linear_loss=0.05114]
[2020-05-12 12:12:57.790]  Step 160179  [3.352 sec/step, loss=0.09288, avg_loss=0.08636, mel_loss=0.04097, linear_loss=0.05191]
[2020-05-12 12:12:59.641]  Step 160180  [3.357 sec/step, loss=0.08773, avg_loss=0.08641, mel_loss=0.03793, linear_loss=0.04980]
[2020-05-12 12:13:03.365]  Step 160181  [3.360 sec/step, loss=0.09497, avg_loss=0.08645, mel_loss=0.04200, linear_loss=0.05297]
[2020-05-12 12:13:09.448]  Step 160182  [3.405 sec/step, loss=0.09258, avg_loss=0.08653, mel_loss=0.04158, linear_loss=0.05100]
[2020-05-12 12:13:12.546]  Generated 32 batches of size 32 in 35.542 sec
[2020-05-12 12:13:15.872]  Step 160183  [3.455 sec/step, loss=0.09399, avg_loss=0.08664, mel_loss=0.04142, linear_loss=0.05257]
[2020-05-12 12:13:20.586]  Step 160184  [3.471 sec/step, loss=0.09382, avg_loss=0.08667, mel_loss=0.04199, linear_loss=0.05183]
[2020-05-12 12:13:21.518]  Step 160185  [3.468 sec/step, loss=0.07607, avg_loss=0.08663, mel_loss=0.03209, linear_loss=0.04398]
[2020-05-12 12:13:22.549]  Step 160186  [3.468 sec/step, loss=0.07823, avg_loss=0.08660, mel_loss=0.03338, linear_loss=0.04484]
[2020-05-12 12:13:24.339]  Step 160187  [3.462 sec/step, loss=0.08523, avg_loss=0.08655, mel_loss=0.03677, linear_loss=0.04847]
[2020-05-12 12:13:37.521]  Step 160188  [3.586 sec/step, loss=0.07944, avg_loss=0.08663, mel_loss=0.03699, linear_loss=0.04245]
[2020-05-12 12:13:41.259]  Step 160189  [3.550 sec/step, loss=0.09281, avg_loss=0.08660, mel_loss=0.04108, linear_loss=0.05173]
[2020-05-12 12:13:42.627]  Step 160190  [3.547 sec/step, loss=0.08108, avg_loss=0.08655, mel_loss=0.03470, linear_loss=0.04639]
[2020-05-12 12:13:45.361]  Step 160191  [3.564 sec/step, loss=0.08869, avg_loss=0.08663, mel_loss=0.03904, linear_loss=0.04965]
[2020-05-12 12:13:47.403]  Step 160192  [3.567 sec/step, loss=0.08787, avg_loss=0.08665, mel_loss=0.03816, linear_loss=0.04971]
[2020-05-12 12:13:51.600]  Step 160193  [3.598 sec/step, loss=0.09249, avg_loss=0.08678, mel_loss=0.04126, linear_loss=0.05123]
[2020-05-12 12:13:54.618]  Step 160194  [3.592 sec/step, loss=0.09168, avg_loss=0.08676, mel_loss=0.04029, linear_loss=0.05139]
[2020-05-12 12:14:01.655]  Step 160195  [3.622 sec/step, loss=0.09497, avg_loss=0.08678, mel_loss=0.04305, linear_loss=0.05191]
[2020-05-12 12:14:04.349]  Step 160196  [3.641 sec/step, loss=0.08894, avg_loss=0.08690, mel_loss=0.03895, linear_loss=0.05000]
[2020-05-12 12:14:05.577]  Step 160197  [3.640 sec/step, loss=0.08127, avg_loss=0.08689, mel_loss=0.03479, linear_loss=0.04648]
[2020-05-12 12:14:07.289]  Step 160198  [3.631 sec/step, loss=0.08354, avg_loss=0.08683, mel_loss=0.03600, linear_loss=0.04754]
[2020-05-12 12:14:09.020]  Step 160199  [3.573 sec/step, loss=0.08584, avg_loss=0.08674, mel_loss=0.03694, linear_loss=0.04890]
[2020-05-12 12:14:11.262]  Step 160200  [3.582 sec/step, loss=0.08776, avg_loss=0.08677, mel_loss=0.03805, linear_loss=0.04971]
[2020-05-12 12:14:11.262]  Writing summary at step: 160200
[2020-05-12 12:14:15.416]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160200
[2020-05-12 12:14:17.090]  Saving audio and alignment...
[2020-05-12 12:14:20.025]  Input: 어 여러분  참고해주시고요~______________
[2020-05-12 12:14:22.481]  Step 160201  [3.539 sec/step, loss=0.08796, avg_loss=0.08672, mel_loss=0.03825, linear_loss=0.04971]
[2020-05-12 12:14:31.289]  Step 160202  [3.593 sec/step, loss=0.09244, avg_loss=0.08672, mel_loss=0.04222, linear_loss=0.05022]
[2020-05-12 12:14:37.374]  Step 160203  [3.638 sec/step, loss=0.09367, avg_loss=0.08682, mel_loss=0.04230, linear_loss=0.05137]
[2020-05-12 12:14:38.493]  Step 160204  [3.629 sec/step, loss=0.07946, avg_loss=0.08674, mel_loss=0.03380, linear_loss=0.04566]
[2020-05-12 12:14:40.459]  Step 160205  [3.617 sec/step, loss=0.08646, avg_loss=0.08665, mel_loss=0.03748, linear_loss=0.04899]
[2020-05-12 12:14:45.685]  Step 160206  [3.645 sec/step, loss=0.09345, avg_loss=0.08671, mel_loss=0.04192, linear_loss=0.05153]
[2020-05-12 12:14:46.255]  Step 160207  [3.643 sec/step, loss=0.06782, avg_loss=0.08665, mel_loss=0.02942, linear_loss=0.03841]
[2020-05-12 12:14:51.939]  Step 160208  [3.679 sec/step, loss=0.09447, avg_loss=0.08671, mel_loss=0.04239, linear_loss=0.05208]
[2020-05-12 12:14:52.827]  Step 160209  [3.637 sec/step, loss=0.07052, avg_loss=0.08648, mel_loss=0.03012, linear_loss=0.04040]
[2020-05-12 12:14:53.645]  Step 160210  [3.627 sec/step, loss=0.07480, avg_loss=0.08636, mel_loss=0.03201, linear_loss=0.04279]
[2020-05-12 12:14:54.797]  Generated 32 batches of size 32 in 17.418 sec
[2020-05-12 12:14:56.895]  Step 160211  [3.630 sec/step, loss=0.09235, avg_loss=0.08637, mel_loss=0.04080, linear_loss=0.05155]
[2020-05-12 12:15:00.421]  Step 160212  [3.648 sec/step, loss=0.09187, avg_loss=0.08643, mel_loss=0.04067, linear_loss=0.05120]
[2020-05-12 12:15:02.112]  Step 160213  [3.653 sec/step, loss=0.08428, avg_loss=0.08646, mel_loss=0.03609, linear_loss=0.04819]
[2020-05-12 12:15:07.473]  Step 160214  [3.660 sec/step, loss=0.09381, avg_loss=0.08646, mel_loss=0.04199, linear_loss=0.05182]
[2020-05-12 12:15:09.197]  Step 160215  [3.533 sec/step, loss=0.08864, avg_loss=0.08659, mel_loss=0.03811, linear_loss=0.05053]
[2020-05-12 12:15:10.033]  Step 160216  [3.517 sec/step, loss=0.07296, avg_loss=0.08645, mel_loss=0.03163, linear_loss=0.04133]
[2020-05-12 12:15:13.540]  Step 160217  [3.545 sec/step, loss=0.09143, avg_loss=0.08667, mel_loss=0.04032, linear_loss=0.05111]
[2020-05-12 12:15:15.461]  Step 160218  [3.522 sec/step, loss=0.08740, avg_loss=0.08660, mel_loss=0.03774, linear_loss=0.04966]
[2020-05-12 12:15:30.148]  Step 160219  [3.660 sec/step, loss=0.07644, avg_loss=0.08661, mel_loss=0.03595, linear_loss=0.04049]
[2020-05-12 12:15:33.613]  Step 160220  [3.664 sec/step, loss=0.09341, avg_loss=0.08661, mel_loss=0.04110, linear_loss=0.05230]
[2020-05-12 12:15:41.339]  Step 160221  [3.729 sec/step, loss=0.09479, avg_loss=0.08673, mel_loss=0.04300, linear_loss=0.05179]
[2020-05-12 12:15:47.172]  Step 160222  [3.769 sec/step, loss=0.09588, avg_loss=0.08684, mel_loss=0.04328, linear_loss=0.05260]
[2020-05-12 12:15:48.524]  Step 160223  [3.715 sec/step, loss=0.08458, avg_loss=0.08674, mel_loss=0.03635, linear_loss=0.04823]
[2020-05-12 12:15:49.053]  Step 160224  [3.696 sec/step, loss=0.06697, avg_loss=0.08652, mel_loss=0.02893, linear_loss=0.03804]
[2020-05-12 12:15:50.184]  Step 160225  [3.680 sec/step, loss=0.08225, avg_loss=0.08646, mel_loss=0.03503, linear_loss=0.04722]
[2020-05-12 12:15:52.564]  Step 160226  [3.697 sec/step, loss=0.08850, avg_loss=0.08660, mel_loss=0.03874, linear_loss=0.04975]
[2020-05-12 12:15:54.560]  Step 160227  [3.574 sec/step, loss=0.08772, avg_loss=0.08673, mel_loss=0.03799, linear_loss=0.04973]
[2020-05-12 12:15:56.018]  Step 160228  [3.578 sec/step, loss=0.08628, avg_loss=0.08678, mel_loss=0.03727, linear_loss=0.04900]
[2020-05-12 12:15:58.925]  Step 160229  [3.566 sec/step, loss=0.09050, avg_loss=0.08673, mel_loss=0.03978, linear_loss=0.05072]
[2020-05-12 12:16:03.607]  Step 160230  [3.607 sec/step, loss=0.09549, avg_loss=0.08701, mel_loss=0.04245, linear_loss=0.05304]
[2020-05-12 12:16:08.051]  Step 160231  [3.642 sec/step, loss=0.09246, avg_loss=0.08713, mel_loss=0.04109, linear_loss=0.05137]
[2020-05-12 12:16:14.871]  Step 160232  [3.673 sec/step, loss=0.09528, avg_loss=0.08714, mel_loss=0.04312, linear_loss=0.05216]
[2020-05-12 12:16:17.481]  Step 160233  [3.688 sec/step, loss=0.08878, avg_loss=0.08724, mel_loss=0.03874, linear_loss=0.05003]
[2020-05-12 12:16:19.502]  Step 160234  [3.661 sec/step, loss=0.08914, avg_loss=0.08718, mel_loss=0.03860, linear_loss=0.05054]
[2020-05-12 12:16:20.827]  Step 160235  [3.617 sec/step, loss=0.08499, avg_loss=0.08708, mel_loss=0.03652, linear_loss=0.04847]
[2020-05-12 12:16:21.861]  Step 160236  [3.614 sec/step, loss=0.07910, avg_loss=0.08704, mel_loss=0.03384, linear_loss=0.04525]
[2020-05-12 12:16:30.796]  Step 160237  [3.674 sec/step, loss=0.09415, avg_loss=0.08710, mel_loss=0.04323, linear_loss=0.05092]
[2020-05-12 12:16:33.991]  Step 160238  [3.630 sec/step, loss=0.09356, avg_loss=0.08707, mel_loss=0.04121, linear_loss=0.05235]
[2020-05-12 12:16:37.904]  Step 160239  [3.652 sec/step, loss=0.09487, avg_loss=0.08716, mel_loss=0.04198, linear_loss=0.05289]
[2020-05-12 12:16:38.728]  Step 160240  [3.645 sec/step, loss=0.07318, avg_loss=0.08705, mel_loss=0.03101, linear_loss=0.04217]
[2020-05-12 12:16:39.913]  Step 160241  [3.647 sec/step, loss=0.08173, avg_loss=0.08709, mel_loss=0.03480, linear_loss=0.04693]
[2020-05-12 12:16:42.140]  Step 160242  [3.661 sec/step, loss=0.08737, avg_loss=0.08722, mel_loss=0.03817, linear_loss=0.04920]
[2020-05-12 12:16:45.847]  Step 160243  [3.663 sec/step, loss=0.09310, avg_loss=0.08723, mel_loss=0.04118, linear_loss=0.05191]
[2020-05-12 12:16:46.877]  Step 160244  [3.656 sec/step, loss=0.07809, avg_loss=0.08718, mel_loss=0.03287, linear_loss=0.04522]
[2020-05-12 12:16:59.312]  Generated 32 batches of size 32 in 38.479 sec
[2020-05-12 12:17:06.992]  Step 160245  [3.835 sec/step, loss=0.09597, avg_loss=0.08726, mel_loss=0.04367, linear_loss=0.05230]
[2020-05-12 12:17:09.495]  Step 160246  [3.809 sec/step, loss=0.08844, avg_loss=0.08719, mel_loss=0.03852, linear_loss=0.04992]
[2020-05-12 12:17:14.824]  Step 160247  [3.807 sec/step, loss=0.09333, avg_loss=0.08719, mel_loss=0.04191, linear_loss=0.05143]
[2020-05-12 12:17:21.212]  Step 160248  [3.825 sec/step, loss=0.09421, avg_loss=0.08721, mel_loss=0.04250, linear_loss=0.05170]
[2020-05-12 12:17:21.987]  Step 160249  [3.811 sec/step, loss=0.06977, avg_loss=0.08703, mel_loss=0.02975, linear_loss=0.04002]
[2020-05-12 12:17:23.701]  Step 160250  [3.804 sec/step, loss=0.08534, avg_loss=0.08699, mel_loss=0.03690, linear_loss=0.04845]
[2020-05-12 12:17:23.701]  Writing summary at step: 160250
[2020-05-12 12:17:29.364]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160250
[2020-05-12 12:17:31.008]  Saving audio and alignment...
[2020-05-12 12:17:32.998]  Input: 예를 들어 볼까요~____
[2020-05-12 12:17:34.770]  Step 160251  [3.408 sec/step, loss=0.08744, avg_loss=0.08693, mel_loss=0.03756, linear_loss=0.04989]
[2020-05-12 12:17:35.313]  Step 160252  [3.406 sec/step, loss=0.06892, avg_loss=0.08692, mel_loss=0.03004, linear_loss=0.03888]
[2020-05-12 12:17:38.988]  Step 160253  [3.417 sec/step, loss=0.09428, avg_loss=0.08693, mel_loss=0.04173, linear_loss=0.05255]
[2020-05-12 12:17:41.868]  Step 160254  [3.405 sec/step, loss=0.09105, avg_loss=0.08691, mel_loss=0.04013, linear_loss=0.05092]
[2020-05-12 12:17:43.455]  Step 160255  [3.413 sec/step, loss=0.08406, avg_loss=0.08706, mel_loss=0.03634, linear_loss=0.04773]
[2020-05-12 12:17:55.051]  Step 160256  [3.406 sec/step, loss=0.08997, avg_loss=0.08712, mel_loss=0.04191, linear_loss=0.04806]
[2020-05-12 12:17:59.366]  Step 160257  [3.439 sec/step, loss=0.09445, avg_loss=0.08729, mel_loss=0.04202, linear_loss=0.05243]
[2020-05-12 12:18:04.135]  Step 160258  [3.454 sec/step, loss=0.09447, avg_loss=0.08729, mel_loss=0.04215, linear_loss=0.05232]
[2020-05-12 12:18:07.100]  Step 160259  [3.459 sec/step, loss=0.09105, avg_loss=0.08731, mel_loss=0.04003, linear_loss=0.05102]
[2020-05-12 12:18:08.666]  Step 160260  [3.455 sec/step, loss=0.08515, avg_loss=0.08730, mel_loss=0.03663, linear_loss=0.04852]
[2020-05-12 12:18:10.024]  Step 160261  [3.414 sec/step, loss=0.08198, avg_loss=0.08717, mel_loss=0.03501, linear_loss=0.04697]
[2020-05-12 12:18:12.222]  Step 160262  [3.424 sec/step, loss=0.08691, avg_loss=0.08722, mel_loss=0.03787, linear_loss=0.04904]
[2020-05-12 12:18:13.593]  Step 160263  [3.420 sec/step, loss=0.08254, avg_loss=0.08716, mel_loss=0.03578, linear_loss=0.04676]
[2020-05-12 12:18:22.004]  Step 160264  [3.482 sec/step, loss=0.09395, avg_loss=0.08721, mel_loss=0.04308, linear_loss=0.05086]
[2020-05-12 12:18:25.050]  Step 160265  [3.497 sec/step, loss=0.09257, avg_loss=0.08729, mel_loss=0.04072, linear_loss=0.05185]
[2020-05-12 12:18:26.156]  Step 160266  [3.500 sec/step, loss=0.07844, avg_loss=0.08733, mel_loss=0.03339, linear_loss=0.04505]
[2020-05-12 12:18:28.366]  Step 160267  [3.502 sec/step, loss=0.08824, avg_loss=0.08732, mel_loss=0.03863, linear_loss=0.04961]
[2020-05-12 12:18:30.296]  Step 160268  [3.477 sec/step, loss=0.08752, avg_loss=0.08723, mel_loss=0.03793, linear_loss=0.04959]
[2020-05-12 12:18:31.069]  Step 160269  [3.469 sec/step, loss=0.07886, avg_loss=0.08717, mel_loss=0.03335, linear_loss=0.04550]
[2020-05-12 12:18:35.267]  Step 160270  [3.474 sec/step, loss=0.09374, avg_loss=0.08717, mel_loss=0.04157, linear_loss=0.05217]
[2020-05-12 12:18:35.430]  Generated 32 batches of size 32 in 10.374 sec
[2020-05-12 12:18:37.725]  Step 160271  [3.450 sec/step, loss=0.08768, avg_loss=0.08711, mel_loss=0.03839, linear_loss=0.04930]
[2020-05-12 12:18:38.715]  Step 160272  [3.449 sec/step, loss=0.07956, avg_loss=0.08712, mel_loss=0.03418, linear_loss=0.04538]
[2020-05-12 12:18:42.279]  Step 160273  [3.472 sec/step, loss=0.09117, avg_loss=0.08722, mel_loss=0.04031, linear_loss=0.05085]
[2020-05-12 12:18:45.741]  Step 160274  [3.484 sec/step, loss=0.09267, avg_loss=0.08728, mel_loss=0.04122, linear_loss=0.05145]
[2020-05-12 12:18:46.727]  Step 160275  [3.420 sec/step, loss=0.07622, avg_loss=0.08710, mel_loss=0.03256, linear_loss=0.04366]
[2020-05-12 12:18:49.099]  Step 160276  [3.430 sec/step, loss=0.09039, avg_loss=0.08716, mel_loss=0.03947, linear_loss=0.05093]
[2020-05-12 12:18:50.801]  Step 160277  [3.412 sec/step, loss=0.08651, avg_loss=0.08712, mel_loss=0.03752, linear_loss=0.04899]
[2020-05-12 12:18:51.890]  Step 160278  [3.392 sec/step, loss=0.08258, avg_loss=0.08704, mel_loss=0.03521, linear_loss=0.04737]
[2020-05-12 12:18:56.361]  Step 160279  [3.405 sec/step, loss=0.09447, avg_loss=0.08705, mel_loss=0.04242, linear_loss=0.05205]
[2020-05-12 12:18:59.259]  Step 160280  [3.415 sec/step, loss=0.09219, avg_loss=0.08710, mel_loss=0.04034, linear_loss=0.05185]
[2020-05-12 12:19:00.659]  Step 160281  [3.392 sec/step, loss=0.08611, avg_loss=0.08701, mel_loss=0.03741, linear_loss=0.04870]
[2020-05-12 12:19:02.752]  Step 160282  [3.352 sec/step, loss=0.08732, avg_loss=0.08696, mel_loss=0.03778, linear_loss=0.04955]
[2020-05-12 12:19:11.713]  Step 160283  [3.378 sec/step, loss=0.09446, avg_loss=0.08696, mel_loss=0.04323, linear_loss=0.05123]
[2020-05-12 12:19:13.305]  Step 160284  [3.346 sec/step, loss=0.08628, avg_loss=0.08689, mel_loss=0.03701, linear_loss=0.04927]
[2020-05-12 12:19:15.105]  Step 160285  [3.355 sec/step, loss=0.08555, avg_loss=0.08698, mel_loss=0.03690, linear_loss=0.04865]
[2020-05-12 12:19:19.304]  Step 160286  [3.387 sec/step, loss=0.09314, avg_loss=0.08713, mel_loss=0.04132, linear_loss=0.05182]
[2020-05-12 12:19:26.893]  Step 160287  [3.445 sec/step, loss=0.09710, avg_loss=0.08725, mel_loss=0.04408, linear_loss=0.05301]
[2020-05-12 12:19:33.722]  Step 160288  [3.381 sec/step, loss=0.09405, avg_loss=0.08739, mel_loss=0.04242, linear_loss=0.05163]
[2020-05-12 12:19:35.692]  Step 160289  [3.363 sec/step, loss=0.08612, avg_loss=0.08733, mel_loss=0.03708, linear_loss=0.04905]
[2020-05-12 12:19:40.524]  Step 160290  [3.398 sec/step, loss=0.09226, avg_loss=0.08744, mel_loss=0.04110, linear_loss=0.05116]
[2020-05-12 12:19:41.180]  Step 160291  [3.377 sec/step, loss=0.07077, avg_loss=0.08726, mel_loss=0.03037, linear_loss=0.04040]
[2020-05-12 12:19:44.246]  Step 160292  [3.388 sec/step, loss=0.09236, avg_loss=0.08731, mel_loss=0.04066, linear_loss=0.05170]
[2020-05-12 12:19:45.154]  Step 160293  [3.355 sec/step, loss=0.07578, avg_loss=0.08714, mel_loss=0.03202, linear_loss=0.04376]
[2020-05-12 12:19:46.343]  Step 160294  [3.336 sec/step, loss=0.08232, avg_loss=0.08704, mel_loss=0.03521, linear_loss=0.04711]
[2020-05-12 12:19:48.883]  Step 160295  [3.291 sec/step, loss=0.08962, avg_loss=0.08699, mel_loss=0.03898, linear_loss=0.05064]
[2020-05-12 12:19:49.451]  Step 160296  [3.270 sec/step, loss=0.07186, avg_loss=0.08682, mel_loss=0.03137, linear_loss=0.04049]
[2020-05-12 12:19:51.670]  Step 160297  [3.280 sec/step, loss=0.08847, avg_loss=0.08689, mel_loss=0.03862, linear_loss=0.04985]
[2020-05-12 12:19:53.317]  Generated 32 batches of size 32 in 1.642 sec
[2020-05-12 12:19:57.039]  Step 160298  [3.317 sec/step, loss=0.09673, avg_loss=0.08702, mel_loss=0.04338, linear_loss=0.05335]
[2020-05-12 12:20:00.769]  Step 160299  [3.337 sec/step, loss=0.09325, avg_loss=0.08710, mel_loss=0.04137, linear_loss=0.05189]
[2020-05-12 12:20:01.588]  Step 160300  [3.322 sec/step, loss=0.07344, avg_loss=0.08696, mel_loss=0.03121, linear_loss=0.04222]
[2020-05-12 12:20:01.588]  Writing summary at step: 160300
[2020-05-12 12:20:05.112]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160300
[2020-05-12 12:20:06.724]  Saving audio and alignment...
[2020-05-12 12:20:09.288]  Input: 근데 원고까지~___________________
[2020-05-12 12:20:24.106]  Step 160301  [3.446 sec/step, loss=0.07556, avg_loss=0.08683, mel_loss=0.03525, linear_loss=0.04030]
[2020-05-12 12:20:29.920]  Step 160302  [3.416 sec/step, loss=0.09610, avg_loss=0.08687, mel_loss=0.04320, linear_loss=0.05289]
[2020-05-12 12:20:32.590]  Step 160303  [3.382 sec/step, loss=0.08947, avg_loss=0.08683, mel_loss=0.03931, linear_loss=0.05016]
[2020-05-12 12:20:35.879]  Step 160304  [3.404 sec/step, loss=0.09517, avg_loss=0.08698, mel_loss=0.04201, linear_loss=0.05316]
[2020-05-12 12:20:41.584]  Step 160305  [3.441 sec/step, loss=0.09421, avg_loss=0.08706, mel_loss=0.04248, linear_loss=0.05173]
[2020-05-12 12:20:44.364]  Step 160306  [3.417 sec/step, loss=0.09087, avg_loss=0.08703, mel_loss=0.03974, linear_loss=0.05113]
[2020-05-12 12:20:48.476]  Step 160307  [3.452 sec/step, loss=0.09337, avg_loss=0.08729, mel_loss=0.04118, linear_loss=0.05219]
[2020-05-12 12:20:50.543]  Step 160308  [3.416 sec/step, loss=0.08683, avg_loss=0.08721, mel_loss=0.03773, linear_loss=0.04910]
[2020-05-12 12:20:52.027]  Step 160309  [3.422 sec/step, loss=0.08185, avg_loss=0.08733, mel_loss=0.03518, linear_loss=0.04667]
[2020-05-12 12:20:54.532]  Step 160310  [3.439 sec/step, loss=0.08756, avg_loss=0.08745, mel_loss=0.03803, linear_loss=0.04953]
[2020-05-12 12:20:59.511]  Step 160311  [3.456 sec/step, loss=0.09515, avg_loss=0.08748, mel_loss=0.04243, linear_loss=0.05272]
[2020-05-12 12:21:00.634]  Step 160312  [3.432 sec/step, loss=0.08138, avg_loss=0.08738, mel_loss=0.03435, linear_loss=0.04703]
[2020-05-12 12:21:03.556]  Step 160313  [3.444 sec/step, loss=0.09033, avg_loss=0.08744, mel_loss=0.03962, linear_loss=0.05071]
[2020-05-12 12:21:05.488]  Step 160314  [3.410 sec/step, loss=0.08794, avg_loss=0.08738, mel_loss=0.03801, linear_loss=0.04993]
[2020-05-12 12:21:12.782]  Step 160315  [3.466 sec/step, loss=0.09457, avg_loss=0.08744, mel_loss=0.04280, linear_loss=0.05176]
[2020-05-12 12:21:13.829]  Step 160316  [3.468 sec/step, loss=0.07947, avg_loss=0.08750, mel_loss=0.03368, linear_loss=0.04579]
[2020-05-12 12:21:18.399]  Step 160317  [3.478 sec/step, loss=0.09373, avg_loss=0.08753, mel_loss=0.04177, linear_loss=0.05196]
[2020-05-12 12:21:20.136]  Step 160318  [3.477 sec/step, loss=0.08446, avg_loss=0.08750, mel_loss=0.03651, linear_loss=0.04795]
[2020-05-12 12:21:23.639]  Step 160319  [3.365 sec/step, loss=0.09141, avg_loss=0.08765, mel_loss=0.04042, linear_loss=0.05099]
[2020-05-12 12:21:27.825]  Step 160320  [3.372 sec/step, loss=0.09358, avg_loss=0.08765, mel_loss=0.04159, linear_loss=0.05198]
[2020-05-12 12:21:30.082]  Step 160321  [3.317 sec/step, loss=0.08789, avg_loss=0.08758, mel_loss=0.03858, linear_loss=0.04931]
[2020-05-12 12:21:30.933]  Step 160322  [3.267 sec/step, loss=0.07457, avg_loss=0.08737, mel_loss=0.03195, linear_loss=0.04261]
[2020-05-12 12:21:31.948]  Step 160323  [3.264 sec/step, loss=0.07993, avg_loss=0.08732, mel_loss=0.03386, linear_loss=0.04607]
[2020-05-12 12:21:33.217]  Step 160324  [3.271 sec/step, loss=0.07971, avg_loss=0.08745, mel_loss=0.03417, linear_loss=0.04554]
[2020-05-12 12:21:46.398]  Step 160325  [3.392 sec/step, loss=0.08090, avg_loss=0.08743, mel_loss=0.03784, linear_loss=0.04306]
[2020-05-12 12:21:47.992]  Step 160326  [3.384 sec/step, loss=0.08632, avg_loss=0.08741, mel_loss=0.03738, linear_loss=0.04894]
[2020-05-12 12:21:49.390]  Step 160327  [3.378 sec/step, loss=0.08262, avg_loss=0.08736, mel_loss=0.03566, linear_loss=0.04696]
[2020-05-12 12:21:52.855]  Step 160328  [3.398 sec/step, loss=0.09148, avg_loss=0.08741, mel_loss=0.04025, linear_loss=0.05123]
[2020-05-12 12:22:01.785]  Step 160329  [3.458 sec/step, loss=0.09410, avg_loss=0.08745, mel_loss=0.04304, linear_loss=0.05106]
[2020-05-12 12:22:03.998]  Step 160330  [3.434 sec/step, loss=0.08893, avg_loss=0.08738, mel_loss=0.03873, linear_loss=0.05020]
[2020-05-12 12:22:04.805]  Step 160331  [3.397 sec/step, loss=0.07586, avg_loss=0.08722, mel_loss=0.03219, linear_loss=0.04367]
[2020-05-12 12:22:11.103]  Step 160332  [3.392 sec/step, loss=0.09374, avg_loss=0.08720, mel_loss=0.04240, linear_loss=0.05133]
[2020-05-12 12:22:12.937]  Step 160333  [3.384 sec/step, loss=0.08676, avg_loss=0.08718, mel_loss=0.03735, linear_loss=0.04941]
[2020-05-12 12:22:16.679]  Step 160334  [3.402 sec/step, loss=0.09402, avg_loss=0.08723, mel_loss=0.04179, linear_loss=0.05224]
[2020-05-12 12:22:19.893]  Step 160335  [3.420 sec/step, loss=0.09190, avg_loss=0.08730, mel_loss=0.04074, linear_loss=0.05116]
[2020-05-12 12:22:20.454]  Step 160336  [3.416 sec/step, loss=0.06685, avg_loss=0.08718, mel_loss=0.02900, linear_loss=0.03785]
[2020-05-12 12:23:04.579]  Generated 32 batches of size 32 in 75.183 sec
[2020-05-12 12:23:05.193]  Step 160337  [3.774 sec/step, loss=0.06751, avg_loss=0.08691, mel_loss=0.02907, linear_loss=0.03844]
[2020-05-12 12:23:08.136]  Step 160338  [3.771 sec/step, loss=0.08929, avg_loss=0.08687, mel_loss=0.03901, linear_loss=0.05028]
[2020-05-12 12:23:10.146]  Step 160339  [3.752 sec/step, loss=0.08581, avg_loss=0.08678, mel_loss=0.03696, linear_loss=0.04885]
[2020-05-12 12:23:16.369]  Step 160340  [3.806 sec/step, loss=0.09275, avg_loss=0.08697, mel_loss=0.04170, linear_loss=0.05105]
[2020-05-12 12:23:17.957]  Step 160341  [3.810 sec/step, loss=0.08468, avg_loss=0.08700, mel_loss=0.03643, linear_loss=0.04824]
[2020-05-12 12:23:32.835]  Step 160342  [3.937 sec/step, loss=0.07617, avg_loss=0.08689, mel_loss=0.03570, linear_loss=0.04047]
[2020-05-12 12:23:35.580]  Step 160343  [3.927 sec/step, loss=0.09009, avg_loss=0.08686, mel_loss=0.03926, linear_loss=0.05083]
[2020-05-12 12:23:39.138]  Step 160344  [3.952 sec/step, loss=0.09199, avg_loss=0.08700, mel_loss=0.04079, linear_loss=0.05120]
[2020-05-12 12:23:39.952]  Step 160345  [3.759 sec/step, loss=0.07008, avg_loss=0.08674, mel_loss=0.02992, linear_loss=0.04016]
[2020-05-12 12:23:41.606]  Step 160346  [3.751 sec/step, loss=0.08639, avg_loss=0.08672, mel_loss=0.03730, linear_loss=0.04910]
[2020-05-12 12:23:43.732]  Step 160347  [3.719 sec/step, loss=0.09010, avg_loss=0.08669, mel_loss=0.03903, linear_loss=0.05106]
[2020-05-12 12:23:48.028]  Step 160348  [3.698 sec/step, loss=0.09438, avg_loss=0.08669, mel_loss=0.04189, linear_loss=0.05250]
[2020-05-12 12:23:49.182]  Step 160349  [3.702 sec/step, loss=0.07861, avg_loss=0.08678, mel_loss=0.03342, linear_loss=0.04519]
[2020-05-12 12:23:52.509]  Step 160350  [3.718 sec/step, loss=0.09240, avg_loss=0.08685, mel_loss=0.04070, linear_loss=0.05170]
[2020-05-12 12:23:52.510]  Writing summary at step: 160350
[2020-05-12 12:23:54.544]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160350
[2020-05-12 12:23:56.146]  Saving audio and alignment...
[2020-05-12 12:24:04.142]  Input: 이렇게 적극적으로 좀 참여를 하다 보니까 아직까지도 그 행사는 제 기억에 잘 남아있~____________________
[2020-05-12 12:24:05.404]  Step 160351  [3.713 sec/step, loss=0.08161, avg_loss=0.08679, mel_loss=0.03486, linear_loss=0.04675]
[2020-05-12 12:24:06.811]  Step 160352  [3.721 sec/step, loss=0.08166, avg_loss=0.08692, mel_loss=0.03517, linear_loss=0.04649]
[2020-05-12 12:24:07.716]  Step 160353  [3.694 sec/step, loss=0.07843, avg_loss=0.08676, mel_loss=0.03288, linear_loss=0.04555]
[2020-05-12 12:24:10.044]  Step 160354  [3.688 sec/step, loss=0.08870, avg_loss=0.08674, mel_loss=0.03901, linear_loss=0.04969]
[2020-05-12 12:24:17.622]  Step 160355  [3.748 sec/step, loss=0.09440, avg_loss=0.08684, mel_loss=0.04295, linear_loss=0.05145]
[2020-05-12 12:24:22.143]  Step 160356  [3.677 sec/step, loss=0.09556, avg_loss=0.08689, mel_loss=0.04263, linear_loss=0.05293]
[2020-05-12 12:24:27.084]  Step 160357  [3.684 sec/step, loss=0.09438, avg_loss=0.08689, mel_loss=0.04222, linear_loss=0.05216]
[2020-05-12 12:24:28.810]  Step 160358  [3.653 sec/step, loss=0.08729, avg_loss=0.08682, mel_loss=0.03773, linear_loss=0.04956]
[2020-05-12 12:24:29.621]  Step 160359  [3.632 sec/step, loss=0.07530, avg_loss=0.08666, mel_loss=0.03192, linear_loss=0.04338]
[2020-05-12 12:24:30.686]  Step 160360  [3.627 sec/step, loss=0.07684, avg_loss=0.08658, mel_loss=0.03277, linear_loss=0.04407]
[2020-05-12 12:24:33.845]  Step 160361  [3.645 sec/step, loss=0.09292, avg_loss=0.08669, mel_loss=0.04080, linear_loss=0.05212]
[2020-05-12 12:24:37.671]  Step 160362  [3.661 sec/step, loss=0.09365, avg_loss=0.08676, mel_loss=0.04158, linear_loss=0.05207]
[2020-05-12 12:24:46.613]  Step 160363  [3.737 sec/step, loss=0.09333, avg_loss=0.08687, mel_loss=0.04263, linear_loss=0.05070]
[2020-05-12 12:24:49.145]  Step 160364  [3.678 sec/step, loss=0.08963, avg_loss=0.08682, mel_loss=0.03899, linear_loss=0.05063]
[2020-05-12 12:24:52.709]  Step 160365  [3.683 sec/step, loss=0.09499, avg_loss=0.08685, mel_loss=0.04192, linear_loss=0.05307]
[2020-05-12 12:24:54.534]  Step 160366  [3.690 sec/step, loss=0.08569, avg_loss=0.08692, mel_loss=0.03694, linear_loss=0.04875]
[2020-05-12 12:25:24.943]  Generated 32 batches of size 32 in 57.852 sec
[2020-05-12 12:25:28.983]  Step 160367  [4.013 sec/step, loss=0.09537, avg_loss=0.08699, mel_loss=0.04247, linear_loss=0.05290]
[2020-05-12 12:25:33.693]  Step 160368  [4.040 sec/step, loss=0.09300, avg_loss=0.08705, mel_loss=0.04140, linear_loss=0.05160]
[2020-05-12 12:25:37.983]  Step 160369  [4.076 sec/step, loss=0.09318, avg_loss=0.08719, mel_loss=0.04161, linear_loss=0.05156]
[2020-05-12 12:25:43.410]  Step 160370  [4.088 sec/step, loss=0.09500, avg_loss=0.08720, mel_loss=0.04292, linear_loss=0.05209]
[2020-05-12 12:25:43.981]  Step 160371  [4.069 sec/step, loss=0.07012, avg_loss=0.08703, mel_loss=0.03140, linear_loss=0.03871]
[2020-05-12 12:25:52.447]  Step 160372  [4.144 sec/step, loss=0.09385, avg_loss=0.08717, mel_loss=0.04287, linear_loss=0.05097]
[2020-05-12 12:25:54.044]  Step 160373  [4.124 sec/step, loss=0.08478, avg_loss=0.08710, mel_loss=0.03682, linear_loss=0.04796]
[2020-05-12 12:25:56.420]  Step 160374  [4.113 sec/step, loss=0.08980, avg_loss=0.08708, mel_loss=0.03914, linear_loss=0.05066]
[2020-05-12 12:26:02.257]  Step 160375  [4.162 sec/step, loss=0.09500, avg_loss=0.08726, mel_loss=0.04279, linear_loss=0.05222]
[2020-05-12 12:26:05.736]  Step 160376  [4.173 sec/step, loss=0.09046, avg_loss=0.08726, mel_loss=0.03977, linear_loss=0.05069]
[2020-05-12 12:26:06.555]  Step 160377  [4.164 sec/step, loss=0.07495, avg_loss=0.08715, mel_loss=0.03168, linear_loss=0.04327]
[2020-05-12 12:26:07.619]  Step 160378  [4.164 sec/step, loss=0.08046, avg_loss=0.08713, mel_loss=0.03406, linear_loss=0.04640]
[2020-05-12 12:26:15.043]  Step 160379  [4.193 sec/step, loss=0.09587, avg_loss=0.08714, mel_loss=0.04359, linear_loss=0.05229]
[2020-05-12 12:26:17.712]  Step 160380  [4.191 sec/step, loss=0.08958, avg_loss=0.08712, mel_loss=0.03963, linear_loss=0.04995]
[2020-05-12 12:26:28.725]  Step 160381  [4.287 sec/step, loss=0.09317, avg_loss=0.08719, mel_loss=0.04310, linear_loss=0.05007]
[2020-05-12 12:26:30.088]  Step 160382  [4.280 sec/step, loss=0.08496, avg_loss=0.08716, mel_loss=0.03647, linear_loss=0.04849]
[2020-05-12 12:26:31.251]  Step 160383  [4.202 sec/step, loss=0.08150, avg_loss=0.08703, mel_loss=0.03458, linear_loss=0.04692]
[2020-05-12 12:26:34.126]  Step 160384  [4.215 sec/step, loss=0.09115, avg_loss=0.08708, mel_loss=0.04026, linear_loss=0.05088]
[2020-05-12 12:26:35.099]  Step 160385  [4.206 sec/step, loss=0.08010, avg_loss=0.08703, mel_loss=0.03370, linear_loss=0.04640]
[2020-05-12 12:26:37.066]  Step 160386  [4.184 sec/step, loss=0.08855, avg_loss=0.08698, mel_loss=0.03865, linear_loss=0.04990]
[2020-05-12 12:26:38.524]  Step 160387  [4.123 sec/step, loss=0.08323, avg_loss=0.08684, mel_loss=0.03579, linear_loss=0.04743]
[2020-05-12 12:26:42.677]  Step 160388  [4.096 sec/step, loss=0.09221, avg_loss=0.08682, mel_loss=0.04063, linear_loss=0.05158]
[2020-05-12 12:26:43.620]  Step 160389  [4.086 sec/step, loss=0.08060, avg_loss=0.08677, mel_loss=0.03445, linear_loss=0.04615]
[2020-05-12 12:26:45.429]  Generated 32 batches of size 32 in 1.803 sec
[2020-05-12 12:26:46.816]  Step 160390  [4.069 sec/step, loss=0.09223, avg_loss=0.08677, mel_loss=0.04070, linear_loss=0.05153]
[2020-05-12 12:26:47.650]  Step 160391  [4.071 sec/step, loss=0.07490, avg_loss=0.08681, mel_loss=0.03171, linear_loss=0.04319]
[2020-05-12 12:26:49.331]  Step 160392  [4.057 sec/step, loss=0.08494, avg_loss=0.08674, mel_loss=0.03664, linear_loss=0.04831]
[2020-05-12 12:26:55.798]  Step 160393  [4.113 sec/step, loss=0.09713, avg_loss=0.08695, mel_loss=0.04399, linear_loss=0.05314]
[2020-05-12 12:26:58.241]  Step 160394  [4.125 sec/step, loss=0.08888, avg_loss=0.08701, mel_loss=0.03865, linear_loss=0.05023]
[2020-05-12 12:27:01.593]  Step 160395  [4.134 sec/step, loss=0.09402, avg_loss=0.08706, mel_loss=0.04157, linear_loss=0.05245]
[2020-05-12 12:27:03.417]  Step 160396  [4.146 sec/step, loss=0.08726, avg_loss=0.08721, mel_loss=0.03767, linear_loss=0.04959]
[2020-05-12 12:27:05.566]  Step 160397  [4.145 sec/step, loss=0.08760, avg_loss=0.08720, mel_loss=0.03818, linear_loss=0.04942]
[2020-05-12 12:27:06.873]  Step 160398  [4.105 sec/step, loss=0.08181, avg_loss=0.08705, mel_loss=0.03510, linear_loss=0.04670]
[2020-05-12 12:27:08.426]  Step 160399  [4.083 sec/step, loss=0.08668, avg_loss=0.08699, mel_loss=0.03745, linear_loss=0.04923]
[2020-05-12 12:27:09.418]  Step 160400  [4.085 sec/step, loss=0.07416, avg_loss=0.08700, mel_loss=0.03124, linear_loss=0.04292]
[2020-05-12 12:27:09.418]  Writing summary at step: 160400
[2020-05-12 12:27:12.316]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160400
[2020-05-12 12:27:16.987]  Saving audio and alignment...
[2020-05-12 12:27:27.187]  Input: 궁합에 조화가 아주 뛰어나고 전체 상담과정에 아주 원활하고 매끄럽게 진행되는 경우들이 있거든요~_____________________________________
[2020-05-12 12:27:28.407]  Step 160401  [3.949 sec/step, loss=0.07885, avg_loss=0.08703, mel_loss=0.03394, linear_loss=0.04491]
[2020-05-12 12:27:30.580]  Step 160402  [3.912 sec/step, loss=0.08924, avg_loss=0.08696, mel_loss=0.03907, linear_loss=0.05017]
[2020-05-12 12:27:31.137]  Step 160403  [3.891 sec/step, loss=0.06729, avg_loss=0.08674, mel_loss=0.02925, linear_loss=0.03804]
[2020-05-12 12:27:33.620]  Step 160404  [3.883 sec/step, loss=0.08887, avg_loss=0.08668, mel_loss=0.03866, linear_loss=0.05021]
[2020-05-12 12:27:35.567]  Step 160405  [3.846 sec/step, loss=0.08969, avg_loss=0.08663, mel_loss=0.03868, linear_loss=0.05101]
[2020-05-12 12:27:37.043]  Step 160406  [3.833 sec/step, loss=0.08357, avg_loss=0.08656, mel_loss=0.03583, linear_loss=0.04774]
[2020-05-12 12:27:41.082]  Step 160407  [3.832 sec/step, loss=0.09467, avg_loss=0.08657, mel_loss=0.04200, linear_loss=0.05267]
[2020-05-12 12:27:46.560]  Step 160408  [3.866 sec/step, loss=0.09538, avg_loss=0.08666, mel_loss=0.04316, linear_loss=0.05222]
[2020-05-12 12:27:50.148]  Step 160409  [3.887 sec/step, loss=0.09435, avg_loss=0.08678, mel_loss=0.04181, linear_loss=0.05254]
[2020-05-12 12:27:52.849]  Step 160410  [3.889 sec/step, loss=0.08944, avg_loss=0.08680, mel_loss=0.03929, linear_loss=0.05015]
[2020-05-12 12:27:54.799]  Step 160411  [3.859 sec/step, loss=0.08653, avg_loss=0.08671, mel_loss=0.03739, linear_loss=0.04914]
[2020-05-12 12:27:55.549]  Step 160412  [3.855 sec/step, loss=0.07770, avg_loss=0.08668, mel_loss=0.03267, linear_loss=0.04503]
[2020-05-12 12:27:58.918]  Step 160413  [3.859 sec/step, loss=0.09400, avg_loss=0.08671, mel_loss=0.04145, linear_loss=0.05255]
[2020-05-12 12:28:00.032]  Step 160414  [3.851 sec/step, loss=0.08142, avg_loss=0.08665, mel_loss=0.03446, linear_loss=0.04696]
[2020-05-12 12:28:06.645]  Step 160415  [3.844 sec/step, loss=0.09542, avg_loss=0.08666, mel_loss=0.04308, linear_loss=0.05234]
[2020-05-12 12:28:19.906]  Step 160416  [3.966 sec/step, loss=0.08112, avg_loss=0.08667, mel_loss=0.03775, linear_loss=0.04337]
[2020-05-12 12:28:21.267]  Step 160417  [3.934 sec/step, loss=0.08234, avg_loss=0.08656, mel_loss=0.03508, linear_loss=0.04726]
[2020-05-12 12:28:24.776]  Step 160418  [3.952 sec/step, loss=0.09068, avg_loss=0.08662, mel_loss=0.04017, linear_loss=0.05051]
[2020-05-12 12:28:29.238]  Step 160419  [3.962 sec/step, loss=0.09391, avg_loss=0.08665, mel_loss=0.04173, linear_loss=0.05218]
[2020-05-12 12:28:34.606]  Step 160420  [3.974 sec/step, loss=0.09388, avg_loss=0.08665, mel_loss=0.04207, linear_loss=0.05181]
[2020-05-12 12:28:39.336]  Step 160421  [3.998 sec/step, loss=0.09390, avg_loss=0.08671, mel_loss=0.04189, linear_loss=0.05201]
[2020-05-12 12:28:48.107]  Step 160422  [4.077 sec/step, loss=0.09350, avg_loss=0.08690, mel_loss=0.04273, linear_loss=0.05076]
[2020-05-12 12:28:49.914]  Step 160423  [4.085 sec/step, loss=0.08668, avg_loss=0.08697, mel_loss=0.03735, linear_loss=0.04933]
[2020-05-12 12:28:50.944]  Step 160424  [4.083 sec/step, loss=0.07920, avg_loss=0.08696, mel_loss=0.03394, linear_loss=0.04526]
[2020-05-12 12:28:53.114]  Step 160425  [3.973 sec/step, loss=0.08781, avg_loss=0.08703, mel_loss=0.03799, linear_loss=0.04982]
[2020-05-12 12:28:53.876]  Step 160426  [3.965 sec/step, loss=0.07349, avg_loss=0.08690, mel_loss=0.03139, linear_loss=0.04210]
[2020-05-12 12:28:56.953]  Step 160427  [3.981 sec/step, loss=0.09363, avg_loss=0.08701, mel_loss=0.04130, linear_loss=0.05234]
[2020-05-12 12:28:58.630]  Step 160428  [3.963 sec/step, loss=0.08494, avg_loss=0.08695, mel_loss=0.03658, linear_loss=0.04836]
[2020-05-12 12:29:30.657]  Generated 32 batches of size 32 in 61.414 sec
[2020-05-12 12:29:34.133]  Step 160429  [4.229 sec/step, loss=0.09089, avg_loss=0.08692, mel_loss=0.04003, linear_loss=0.05087]
[2020-05-12 12:29:35.502]  Step 160430  [4.221 sec/step, loss=0.08295, avg_loss=0.08686, mel_loss=0.03577, linear_loss=0.04717]
[2020-05-12 12:29:36.568]  Step 160431  [4.223 sec/step, loss=0.08286, avg_loss=0.08693, mel_loss=0.03511, linear_loss=0.04775]
[2020-05-12 12:29:42.479]  Step 160432  [4.219 sec/step, loss=0.09416, avg_loss=0.08693, mel_loss=0.04224, linear_loss=0.05191]
[2020-05-12 12:29:45.099]  Step 160433  [4.227 sec/step, loss=0.08925, avg_loss=0.08695, mel_loss=0.03911, linear_loss=0.05014]
[2020-05-12 12:29:48.119]  Step 160434  [4.220 sec/step, loss=0.09195, avg_loss=0.08693, mel_loss=0.04057, linear_loss=0.05138]
[2020-05-12 12:29:48.903]  Step 160435  [4.196 sec/step, loss=0.07470, avg_loss=0.08676, mel_loss=0.03177, linear_loss=0.04293]
[2020-05-12 12:29:53.183]  Step 160436  [4.233 sec/step, loss=0.09343, avg_loss=0.08703, mel_loss=0.04149, linear_loss=0.05194]
[2020-05-12 12:29:54.752]  Step 160437  [3.801 sec/step, loss=0.08498, avg_loss=0.08720, mel_loss=0.03674, linear_loss=0.04824]
[2020-05-12 12:29:57.187]  Step 160438  [3.796 sec/step, loss=0.08912, avg_loss=0.08720, mel_loss=0.03855, linear_loss=0.05057]
[2020-05-12 12:29:59.335]  Step 160439  [3.798 sec/step, loss=0.08902, avg_loss=0.08723, mel_loss=0.03879, linear_loss=0.05022]
[2020-05-12 12:30:02.539]  Step 160440  [3.767 sec/step, loss=0.09350, avg_loss=0.08724, mel_loss=0.04125, linear_loss=0.05225]
[2020-05-12 12:30:07.045]  Step 160441  [3.797 sec/step, loss=0.09487, avg_loss=0.08734, mel_loss=0.04211, linear_loss=0.05276]
[2020-05-12 12:30:10.736]  Step 160442  [3.685 sec/step, loss=0.09419, avg_loss=0.08752, mel_loss=0.04164, linear_loss=0.05255]
[2020-05-12 12:30:11.414]  Step 160443  [3.664 sec/step, loss=0.07161, avg_loss=0.08734, mel_loss=0.03077, linear_loss=0.04084]
[2020-05-12 12:30:11.971]  Step 160444  [3.634 sec/step, loss=0.06522, avg_loss=0.08707, mel_loss=0.02774, linear_loss=0.03747]
[2020-05-12 12:30:15.972]  Step 160445  [3.666 sec/step, loss=0.09359, avg_loss=0.08731, mel_loss=0.04133, linear_loss=0.05226]
[2020-05-12 12:30:16.985]  Step 160446  [3.660 sec/step, loss=0.07999, avg_loss=0.08724, mel_loss=0.03425, linear_loss=0.04574]
[2020-05-12 12:30:18.645]  Step 160447  [3.655 sec/step, loss=0.08825, avg_loss=0.08722, mel_loss=0.03817, linear_loss=0.05008]
[2020-05-12 12:30:20.385]  Step 160448  [3.629 sec/step, loss=0.08642, avg_loss=0.08714, mel_loss=0.03686, linear_loss=0.04956]
[2020-05-12 12:30:34.642]  Step 160449  [3.760 sec/step, loss=0.07485, avg_loss=0.08711, mel_loss=0.03504, linear_loss=0.03981]
[2020-05-12 12:30:37.591]  Step 160450  [3.757 sec/step, loss=0.09203, avg_loss=0.08710, mel_loss=0.04037, linear_loss=0.05165]
[2020-05-12 12:30:37.591]  Writing summary at step: 160450
[2020-05-12 12:30:38.865]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160450
[2020-05-12 12:30:40.505]  Saving audio and alignment...
[2020-05-12 12:30:43.040]  Input: 한국석유공사는~_______________
[2020-05-12 12:30:45.314]  Step 160451  [3.767 sec/step, loss=0.09023, avg_loss=0.08719, mel_loss=0.03939, linear_loss=0.05084]
[2020-05-12 12:30:47.321]  Step 160452  [3.773 sec/step, loss=0.08748, avg_loss=0.08725, mel_loss=0.03809, linear_loss=0.04939]
[2020-05-12 12:30:48.201]  Step 160453  [3.772 sec/step, loss=0.07890, avg_loss=0.08725, mel_loss=0.03326, linear_loss=0.04563]
[2020-05-12 12:30:53.302]  Step 160454  [3.800 sec/step, loss=0.09333, avg_loss=0.08730, mel_loss=0.04162, linear_loss=0.05170]
[2020-05-12 12:30:55.186]  Step 160455  [3.743 sec/step, loss=0.08571, avg_loss=0.08721, mel_loss=0.03711, linear_loss=0.04860]
[2020-05-12 12:31:03.864]  Step 160456  [3.785 sec/step, loss=0.09415, avg_loss=0.08720, mel_loss=0.04312, linear_loss=0.05104]
[2020-05-12 12:31:11.128]  Step 160457  [3.808 sec/step, loss=0.09644, avg_loss=0.08722, mel_loss=0.04384, linear_loss=0.05260]
[2020-05-12 12:31:16.735]  Step 160458  [3.847 sec/step, loss=0.09374, avg_loss=0.08728, mel_loss=0.04222, linear_loss=0.05152]
[2020-05-12 12:31:44.122]  Generated 32 batches of size 32 in 63.021 sec
[2020-05-12 12:31:44.700]  Step 160459  [4.118 sec/step, loss=0.06968, avg_loss=0.08723, mel_loss=0.03001, linear_loss=0.03967]
[2020-05-12 12:31:48.737]  Step 160460  [4.148 sec/step, loss=0.09425, avg_loss=0.08740, mel_loss=0.04178, linear_loss=0.05246]
[2020-05-12 12:31:49.729]  Step 160461  [4.126 sec/step, loss=0.07737, avg_loss=0.08724, mel_loss=0.03301, linear_loss=0.04436]
[2020-05-12 12:31:51.755]  Step 160462  [4.108 sec/step, loss=0.08734, avg_loss=0.08718, mel_loss=0.03790, linear_loss=0.04944]
[2020-05-12 12:31:53.290]  Step 160463  [4.034 sec/step, loss=0.08419, avg_loss=0.08709, mel_loss=0.03621, linear_loss=0.04798]
[2020-05-12 12:31:55.430]  Step 160464  [4.030 sec/step, loss=0.08886, avg_loss=0.08708, mel_loss=0.03866, linear_loss=0.05020]
[2020-05-12 12:31:58.761]  Step 160465  [4.028 sec/step, loss=0.09407, avg_loss=0.08707, mel_loss=0.04157, linear_loss=0.05250]
[2020-05-12 12:32:05.532]  Step 160466  [4.078 sec/step, loss=0.09449, avg_loss=0.08716, mel_loss=0.04277, linear_loss=0.05172]
[2020-05-12 12:32:14.367]  Step 160467  [3.821 sec/step, loss=0.09380, avg_loss=0.08714, mel_loss=0.04302, linear_loss=0.05078]
[2020-05-12 12:32:15.476]  Step 160468  [3.785 sec/step, loss=0.08180, avg_loss=0.08703, mel_loss=0.03468, linear_loss=0.04713]
[2020-05-12 12:32:17.863]  Step 160469  [3.766 sec/step, loss=0.08763, avg_loss=0.08698, mel_loss=0.03821, linear_loss=0.04942]
[2020-05-12 12:32:19.801]  Step 160470  [3.731 sec/step, loss=0.08590, avg_loss=0.08689, mel_loss=0.03718, linear_loss=0.04872]
[2020-05-12 12:32:20.785]  Step 160471  [3.736 sec/step, loss=0.07831, avg_loss=0.08697, mel_loss=0.03288, linear_loss=0.04543]
[2020-05-12 12:32:24.254]  Step 160472  [3.686 sec/step, loss=0.09127, avg_loss=0.08694, mel_loss=0.04053, linear_loss=0.05074]
[2020-05-12 12:32:31.452]  Step 160473  [3.742 sec/step, loss=0.09668, avg_loss=0.08706, mel_loss=0.04389, linear_loss=0.05279]
[2020-05-12 12:32:32.784]  Step 160474  [3.731 sec/step, loss=0.08347, avg_loss=0.08700, mel_loss=0.03580, linear_loss=0.04767]
[2020-05-12 12:32:38.478]  Step 160475  [3.730 sec/step, loss=0.09454, avg_loss=0.08699, mel_loss=0.04260, linear_loss=0.05194]
[2020-05-12 12:32:41.350]  Step 160476  [3.724 sec/step, loss=0.09097, avg_loss=0.08700, mel_loss=0.03993, linear_loss=0.05103]
[2020-05-12 12:32:42.563]  Step 160477  [3.728 sec/step, loss=0.08170, avg_loss=0.08707, mel_loss=0.03487, linear_loss=0.04683]
[2020-05-12 12:32:55.525]  Step 160478  [3.847 sec/step, loss=0.08313, avg_loss=0.08709, mel_loss=0.03874, linear_loss=0.04439]
[2020-05-12 12:32:59.816]  Step 160479  [3.815 sec/step, loss=0.09278, avg_loss=0.08706, mel_loss=0.04118, linear_loss=0.05161]
[2020-05-12 12:33:00.622]  Step 160480  [3.797 sec/step, loss=0.07567, avg_loss=0.08692, mel_loss=0.03184, linear_loss=0.04383]
[2020-05-12 12:33:03.346]  Step 160481  [3.714 sec/step, loss=0.08990, avg_loss=0.08689, mel_loss=0.03949, linear_loss=0.05041]
[2020-05-12 12:33:06.941]  Step 160482  [3.736 sec/step, loss=0.09315, avg_loss=0.08697, mel_loss=0.04114, linear_loss=0.05201]
[2020-05-12 12:33:09.376]  Step 160483  [3.749 sec/step, loss=0.09046, avg_loss=0.08706, mel_loss=0.03933, linear_loss=0.05114]
[2020-05-12 12:33:10.161]  Step 160484  [3.728 sec/step, loss=0.06900, avg_loss=0.08684, mel_loss=0.02938, linear_loss=0.03962]
[2020-05-12 12:33:11.854]  Step 160485  [3.735 sec/step, loss=0.08434, avg_loss=0.08688, mel_loss=0.03660, linear_loss=0.04774]
[2020-05-12 12:33:13.245]  Step 160486  [3.729 sec/step, loss=0.08495, avg_loss=0.08685, mel_loss=0.03678, linear_loss=0.04817]
[2020-05-12 12:33:18.471]  Step 160487  [3.767 sec/step, loss=0.09435, avg_loss=0.08696, mel_loss=0.04229, linear_loss=0.05206]
[2020-05-12 12:33:20.259]  Step 160488  [3.743 sec/step, loss=0.08527, avg_loss=0.08689, mel_loss=0.03665, linear_loss=0.04862]
[2020-05-12 12:33:24.990]  Step 160489  [3.781 sec/step, loss=0.09338, avg_loss=0.08702, mel_loss=0.04162, linear_loss=0.05177]
[2020-05-12 12:33:25.004]  Generated 32 batches of size 32 in 21.652 sec
[2020-05-12 12:33:29.808]  Step 160490  [3.797 sec/step, loss=0.09268, avg_loss=0.08702, mel_loss=0.04075, linear_loss=0.05193]
[2020-05-12 12:33:34.367]  Step 160491  [3.835 sec/step, loss=0.09132, avg_loss=0.08719, mel_loss=0.04042, linear_loss=0.05090]
[2020-05-12 12:33:36.701]  Step 160492  [3.841 sec/step, loss=0.08662, avg_loss=0.08720, mel_loss=0.03779, linear_loss=0.04883]
[2020-05-12 12:33:38.491]  Step 160493  [3.795 sec/step, loss=0.08589, avg_loss=0.08709, mel_loss=0.03668, linear_loss=0.04922]
[2020-05-12 12:33:42.067]  Step 160494  [3.806 sec/step, loss=0.09356, avg_loss=0.08714, mel_loss=0.04132, linear_loss=0.05224]
[2020-05-12 12:33:43.747]  Step 160495  [3.789 sec/step, loss=0.08404, avg_loss=0.08704, mel_loss=0.03616, linear_loss=0.04788]
[2020-05-12 12:33:47.544]  Step 160496  [3.809 sec/step, loss=0.09279, avg_loss=0.08709, mel_loss=0.04108, linear_loss=0.05171]
[2020-05-12 12:33:50.510]  Step 160497  [3.817 sec/step, loss=0.09161, avg_loss=0.08713, mel_loss=0.04030, linear_loss=0.05131]
[2020-05-12 12:33:51.384]  Step 160498  [3.813 sec/step, loss=0.07323, avg_loss=0.08705, mel_loss=0.03091, linear_loss=0.04232]
[2020-05-12 12:33:53.531]  Step 160499  [3.819 sec/step, loss=0.08910, avg_loss=0.08707, mel_loss=0.03892, linear_loss=0.05018]
[2020-05-12 12:33:56.209]  Step 160500  [3.835 sec/step, loss=0.08978, avg_loss=0.08723, mel_loss=0.03936, linear_loss=0.05042]
[2020-05-12 12:33:56.209]  Writing summary at step: 160500
[2020-05-12 12:33:57.312]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160500
[2020-05-12 12:33:58.886]  Saving audio and alignment...
[2020-05-12 12:34:07.697]  Input: 궁금한데요 하고 내렸다면 내가 밑에서 그럼 혹시 이메일 주소 등록해 드릴까요~_______________________________
[2020-05-12 12:34:08.998]  Step 160501  [3.836 sec/step, loss=0.08315, avg_loss=0.08727, mel_loss=0.03557, linear_loss=0.04758]
[2020-05-12 12:34:10.143]  Step 160502  [3.826 sec/step, loss=0.08101, avg_loss=0.08719, mel_loss=0.03461, linear_loss=0.04641]
[2020-05-12 12:34:18.406]  Step 160503  [3.903 sec/step, loss=0.09481, avg_loss=0.08746, mel_loss=0.04296, linear_loss=0.05185]
[2020-05-12 12:34:22.201]  Step 160504  [3.916 sec/step, loss=0.09259, avg_loss=0.08750, mel_loss=0.04077, linear_loss=0.05182]
[2020-05-12 12:34:23.856]  Step 160505  [3.913 sec/step, loss=0.08633, avg_loss=0.08747, mel_loss=0.03729, linear_loss=0.04904]
[2020-05-12 12:34:25.189]  Step 160506  [3.912 sec/step, loss=0.08549, avg_loss=0.08749, mel_loss=0.03673, linear_loss=0.04876]
[2020-05-12 12:34:28.068]  Step 160507  [3.900 sec/step, loss=0.09199, avg_loss=0.08746, mel_loss=0.04031, linear_loss=0.05168]
[2020-05-12 12:34:28.602]  Step 160508  [3.851 sec/step, loss=0.06732, avg_loss=0.08718, mel_loss=0.02949, linear_loss=0.03784]
[2020-05-12 12:34:32.754]  Step 160509  [3.856 sec/step, loss=0.09471, avg_loss=0.08718, mel_loss=0.04252, linear_loss=0.05219]
[2020-05-12 12:34:33.513]  Step 160510  [3.837 sec/step, loss=0.07724, avg_loss=0.08706, mel_loss=0.03269, linear_loss=0.04456]
[2020-05-12 12:34:38.502]  Step 160511  [3.867 sec/step, loss=0.09389, avg_loss=0.08713, mel_loss=0.04225, linear_loss=0.05164]
[2020-05-12 12:34:40.301]  Generated 32 batches of size 32 in 1.794 sec
[2020-05-12 12:34:40.507]  Step 160512  [3.880 sec/step, loss=0.08688, avg_loss=0.08722, mel_loss=0.03742, linear_loss=0.04946]
[2020-05-12 12:34:47.806]  Step 160513  [3.919 sec/step, loss=0.09488, avg_loss=0.08723, mel_loss=0.04294, linear_loss=0.05193]
[2020-05-12 12:34:48.638]  Step 160514  [3.916 sec/step, loss=0.07195, avg_loss=0.08714, mel_loss=0.03084, linear_loss=0.04111]
[2020-05-12 12:34:50.580]  Step 160515  [3.870 sec/step, loss=0.08743, avg_loss=0.08706, mel_loss=0.03761, linear_loss=0.04981]
[2020-05-12 12:34:51.481]  Step 160516  [3.746 sec/step, loss=0.08162, avg_loss=0.08706, mel_loss=0.03475, linear_loss=0.04687]
[2020-05-12 12:34:53.891]  Step 160517  [3.757 sec/step, loss=0.08957, avg_loss=0.08714, mel_loss=0.03909, linear_loss=0.05048]
[2020-05-12 12:35:08.188]  Step 160518  [3.865 sec/step, loss=0.07103, avg_loss=0.08694, mel_loss=0.03311, linear_loss=0.03791]
[2020-05-12 12:35:12.935]  Step 160519  [3.867 sec/step, loss=0.09319, avg_loss=0.08693, mel_loss=0.04162, linear_loss=0.05157]
[2020-05-12 12:35:18.612]  Step 160520  [3.870 sec/step, loss=0.09423, avg_loss=0.08694, mel_loss=0.04236, linear_loss=0.05187]
[2020-05-12 12:35:19.331]  Step 160521  [3.830 sec/step, loss=0.07566, avg_loss=0.08675, mel_loss=0.03209, linear_loss=0.04357]
[2020-05-12 12:35:23.476]  Step 160522  [3.784 sec/step, loss=0.09216, avg_loss=0.08674, mel_loss=0.04080, linear_loss=0.05136]
[2020-05-12 12:35:24.477]  Step 160523  [3.776 sec/step, loss=0.07772, avg_loss=0.08665, mel_loss=0.03322, linear_loss=0.04450]
[2020-05-12 12:35:25.548]  Step 160524  [3.776 sec/step, loss=0.08161, avg_loss=0.08667, mel_loss=0.03457, linear_loss=0.04704]
[2020-05-12 12:35:26.772]  Step 160525  [3.767 sec/step, loss=0.07919, avg_loss=0.08659, mel_loss=0.03389, linear_loss=0.04530]
[2020-05-12 12:35:35.594]  Step 160526  [3.848 sec/step, loss=0.09319, avg_loss=0.08679, mel_loss=0.04274, linear_loss=0.05045]
[2020-05-12 12:35:38.202]  Step 160527  [3.843 sec/step, loss=0.08946, avg_loss=0.08674, mel_loss=0.03878, linear_loss=0.05068]
[2020-05-12 12:35:43.785]  Step 160528  [3.882 sec/step, loss=0.09409, avg_loss=0.08684, mel_loss=0.04209, linear_loss=0.05200]
[2020-05-12 12:35:49.013]  Step 160529  [3.579 sec/step, loss=0.09323, avg_loss=0.08686, mel_loss=0.04183, linear_loss=0.05140]
[2020-05-12 12:35:51.660]  Step 160530  [3.592 sec/step, loss=0.08934, avg_loss=0.08692, mel_loss=0.03931, linear_loss=0.05003]
[2020-05-12 12:35:53.767]  Step 160531  [3.602 sec/step, loss=0.08917, avg_loss=0.08699, mel_loss=0.03877, linear_loss=0.05039]
[2020-05-12 12:35:58.316]  Step 160532  [3.589 sec/step, loss=0.09476, avg_loss=0.08699, mel_loss=0.04217, linear_loss=0.05259]
[2020-05-12 12:36:00.335]  Step 160533  [3.583 sec/step, loss=0.08896, avg_loss=0.08699, mel_loss=0.03868, linear_loss=0.05028]
[2020-05-12 12:36:01.831]  Step 160534  [3.568 sec/step, loss=0.08607, avg_loss=0.08693, mel_loss=0.03698, linear_loss=0.04909]
[2020-05-12 12:36:03.604]  Step 160535  [3.577 sec/step, loss=0.08773, avg_loss=0.08706, mel_loss=0.03797, linear_loss=0.04976]
[2020-05-12 12:36:07.090]  Step 160536  [3.569 sec/step, loss=0.09179, avg_loss=0.08704, mel_loss=0.04049, linear_loss=0.05129]
[2020-05-12 12:36:08.395]  Step 160537  [3.567 sec/step, loss=0.08336, avg_loss=0.08703, mel_loss=0.03577, linear_loss=0.04759]
[2020-05-12 12:36:12.725]  Step 160538  [3.586 sec/step, loss=0.09297, avg_loss=0.08707, mel_loss=0.04130, linear_loss=0.05166]
[2020-05-12 12:36:13.529]  Step 160539  [3.572 sec/step, loss=0.07488, avg_loss=0.08692, mel_loss=0.03173, linear_loss=0.04315]
[2020-05-12 12:36:26.521]  Step 160540  [3.670 sec/step, loss=0.08303, avg_loss=0.08682, mel_loss=0.03887, linear_loss=0.04416]
[2020-05-12 12:36:29.659]  Step 160541  [3.657 sec/step, loss=0.09429, avg_loss=0.08681, mel_loss=0.04167, linear_loss=0.05262]
[2020-05-12 12:36:37.157]  Step 160542  [3.695 sec/step, loss=0.09586, avg_loss=0.08683, mel_loss=0.04359, linear_loss=0.05227]
[2020-05-12 12:36:38.139]  Step 160543  [3.698 sec/step, loss=0.08227, avg_loss=0.08694, mel_loss=0.03524, linear_loss=0.04703]
[2020-05-12 12:36:41.852]  Step 160544  [3.729 sec/step, loss=0.09493, avg_loss=0.08723, mel_loss=0.04209, linear_loss=0.05284]
[2020-05-12 12:36:44.219]  Step 160545  [3.713 sec/step, loss=0.09057, avg_loss=0.08720, mel_loss=0.03943, linear_loss=0.05114]
[2020-05-12 12:36:45.837]  Step 160546  [3.719 sec/step, loss=0.08634, avg_loss=0.08727, mel_loss=0.03714, linear_loss=0.04919]
[2020-05-12 12:36:47.690]  Step 160547  [3.721 sec/step, loss=0.08689, avg_loss=0.08725, mel_loss=0.03744, linear_loss=0.04945]
[2020-05-12 12:36:50.618]  Step 160548  [3.733 sec/step, loss=0.09086, avg_loss=0.08730, mel_loss=0.04015, linear_loss=0.05070]
[2020-05-12 12:36:52.019]  Step 160549  [3.604 sec/step, loss=0.08263, avg_loss=0.08738, mel_loss=0.03562, linear_loss=0.04701]
[2020-05-12 12:36:52.774]  Step 160550  [3.582 sec/step, loss=0.07250, avg_loss=0.08718, mel_loss=0.03179, linear_loss=0.04070]
[2020-05-12 12:36:52.774]  Writing summary at step: 160550
[2020-05-12 12:36:56.267]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160550
[2020-05-12 12:36:57.899]  Saving audio and alignment...
[2020-05-12 12:37:07.104]  Input: 좋은 방법 알려드릴께요 땡땡땡 시장님 참석하셨습니다 했는데 아무도 안 일어나세요~______________________________________
[2020-05-12 12:38:01.640]  Generated 32 batches of size 32 in 83.496 sec
[2020-05-12 12:38:03.304]  Step 160551  [4.121 sec/step, loss=0.08362, avg_loss=0.08712, mel_loss=0.03600, linear_loss=0.04762]
[2020-05-12 12:38:04.689]  Step 160552  [4.115 sec/step, loss=0.08348, avg_loss=0.08708, mel_loss=0.03595, linear_loss=0.04753]
[2020-05-12 12:38:06.640]  Step 160553  [4.126 sec/step, loss=0.08610, avg_loss=0.08715, mel_loss=0.03714, linear_loss=0.04896]
[2020-05-12 12:38:07.703]  Step 160554  [4.086 sec/step, loss=0.07989, avg_loss=0.08701, mel_loss=0.03397, linear_loss=0.04593]
[2020-05-12 12:38:20.806]  Step 160555  [4.198 sec/step, loss=0.08103, avg_loss=0.08697, mel_loss=0.03777, linear_loss=0.04326]
[2020-05-12 12:38:26.394]  Step 160556  [4.167 sec/step, loss=0.09525, avg_loss=0.08698, mel_loss=0.04317, linear_loss=0.05209]
[2020-05-12 12:38:27.610]  Step 160557  [4.106 sec/step, loss=0.08169, avg_loss=0.08683, mel_loss=0.03505, linear_loss=0.04663]
[2020-05-12 12:38:29.822]  Step 160558  [4.072 sec/step, loss=0.08802, avg_loss=0.08677, mel_loss=0.03855, linear_loss=0.04947]
[2020-05-12 12:38:31.586]  Step 160559  [3.810 sec/step, loss=0.08567, avg_loss=0.08693, mel_loss=0.03671, linear_loss=0.04896]
[2020-05-12 12:38:36.790]  Step 160560  [3.822 sec/step, loss=0.09358, avg_loss=0.08693, mel_loss=0.04207, linear_loss=0.05151]
[2020-05-12 12:38:37.316]  Step 160561  [3.817 sec/step, loss=0.07068, avg_loss=0.08686, mel_loss=0.03100, linear_loss=0.03968]
[2020-05-12 12:38:44.405]  Step 160562  [3.868 sec/step, loss=0.09493, avg_loss=0.08693, mel_loss=0.04299, linear_loss=0.05194]
[2020-05-12 12:38:45.168]  Step 160563  [3.860 sec/step, loss=0.07306, avg_loss=0.08682, mel_loss=0.03127, linear_loss=0.04179]
[2020-05-12 12:38:45.937]  Step 160564  [3.847 sec/step, loss=0.07753, avg_loss=0.08671, mel_loss=0.03279, linear_loss=0.04474]
[2020-05-12 12:38:47.277]  Step 160565  [3.827 sec/step, loss=0.08250, avg_loss=0.08659, mel_loss=0.03528, linear_loss=0.04722]
[2020-05-12 12:38:50.047]  Step 160566  [3.787 sec/step, loss=0.09011, avg_loss=0.08655, mel_loss=0.03960, linear_loss=0.05051]
[2020-05-12 12:38:52.327]  Step 160567  [3.721 sec/step, loss=0.08958, avg_loss=0.08651, mel_loss=0.03889, linear_loss=0.05069]
[2020-05-12 12:38:54.951]  Step 160568  [3.736 sec/step, loss=0.08844, avg_loss=0.08657, mel_loss=0.03847, linear_loss=0.04997]
[2020-05-12 12:38:56.777]  Step 160569  [3.731 sec/step, loss=0.08432, avg_loss=0.08654, mel_loss=0.03633, linear_loss=0.04800]
[2020-05-12 12:38:59.683]  Step 160570  [3.740 sec/step, loss=0.09084, avg_loss=0.08659, mel_loss=0.04021, linear_loss=0.05062]
[2020-05-12 12:39:03.903]  Step 160571  [3.773 sec/step, loss=0.09300, avg_loss=0.08674, mel_loss=0.04135, linear_loss=0.05165]
[2020-05-12 12:39:07.300]  Step 160572  [3.772 sec/step, loss=0.09090, avg_loss=0.08673, mel_loss=0.04016, linear_loss=0.05074]
[2020-05-12 12:39:15.979]  Step 160573  [3.787 sec/step, loss=0.09398, avg_loss=0.08671, mel_loss=0.04287, linear_loss=0.05111]
[2020-05-12 12:39:19.334]  Step 160574  [3.807 sec/step, loss=0.09317, avg_loss=0.08680, mel_loss=0.04118, linear_loss=0.05199]
[2020-05-12 12:39:25.934]  Step 160575  [3.816 sec/step, loss=0.09419, avg_loss=0.08680, mel_loss=0.04259, linear_loss=0.05160]
[2020-05-12 12:39:30.489]  Step 160576  [3.833 sec/step, loss=0.09387, avg_loss=0.08683, mel_loss=0.04181, linear_loss=0.05206]
[2020-05-12 12:39:33.570]  Step 160577  [3.852 sec/step, loss=0.09250, avg_loss=0.08694, mel_loss=0.04057, linear_loss=0.05192]
[2020-05-12 12:39:37.335]  Step 160578  [3.760 sec/step, loss=0.09376, avg_loss=0.08704, mel_loss=0.04153, linear_loss=0.05223]
[2020-05-12 12:39:38.429]  Step 160579  [3.728 sec/step, loss=0.08209, avg_loss=0.08694, mel_loss=0.03489, linear_loss=0.04720]
[2020-05-12 12:39:39.304]  Step 160580  [3.728 sec/step, loss=0.07786, avg_loss=0.08696, mel_loss=0.03315, linear_loss=0.04471]
[2020-05-12 12:39:42.866]  Step 160581  [3.737 sec/step, loss=0.09462, avg_loss=0.08701, mel_loss=0.04182, linear_loss=0.05280]
[2020-05-12 12:39:44.906]  Step 160582  [3.721 sec/step, loss=0.08653, avg_loss=0.08694, mel_loss=0.03785, linear_loss=0.04868]
[2020-05-12 12:40:21.641]  Generated 32 batches of size 32 in 65.657 sec
[2020-05-12 12:40:22.874]  Step 160583  [4.077 sec/step, loss=0.08306, avg_loss=0.08687, mel_loss=0.03564, linear_loss=0.04742]
[2020-05-12 12:40:31.540]  Step 160584  [4.155 sec/step, loss=0.09338, avg_loss=0.08711, mel_loss=0.04278, linear_loss=0.05060]
[2020-05-12 12:40:33.688]  Step 160585  [4.160 sec/step, loss=0.08713, avg_loss=0.08714, mel_loss=0.03771, linear_loss=0.04942]
[2020-05-12 12:40:34.797]  Step 160586  [4.157 sec/step, loss=0.07960, avg_loss=0.08708, mel_loss=0.03386, linear_loss=0.04574]
[2020-05-12 12:40:35.805]  Step 160587  [4.115 sec/step, loss=0.07834, avg_loss=0.08692, mel_loss=0.03349, linear_loss=0.04485]
[2020-05-12 12:40:36.560]  Step 160588  [4.105 sec/step, loss=0.06850, avg_loss=0.08676, mel_loss=0.02984, linear_loss=0.03866]
[2020-05-12 12:40:39.583]  Step 160589  [4.087 sec/step, loss=0.09262, avg_loss=0.08675, mel_loss=0.04092, linear_loss=0.05170]
[2020-05-12 12:40:42.333]  Step 160590  [4.067 sec/step, loss=0.08788, avg_loss=0.08670, mel_loss=0.03830, linear_loss=0.04959]
[2020-05-12 12:40:43.923]  Step 160591  [4.037 sec/step, loss=0.08634, avg_loss=0.08665, mel_loss=0.03720, linear_loss=0.04914]
[2020-05-12 12:40:47.600]  Step 160592  [4.051 sec/step, loss=0.09164, avg_loss=0.08670, mel_loss=0.04056, linear_loss=0.05109]
[2020-05-12 12:40:49.581]  Step 160593  [4.052 sec/step, loss=0.08824, avg_loss=0.08672, mel_loss=0.03818, linear_loss=0.05006]
[2020-05-12 12:40:50.378]  Step 160594  [4.025 sec/step, loss=0.07714, avg_loss=0.08656, mel_loss=0.03226, linear_loss=0.04488]
[2020-05-12 12:40:56.640]  Step 160595  [4.070 sec/step, loss=0.09445, avg_loss=0.08666, mel_loss=0.04272, linear_loss=0.05173]
[2020-05-12 12:40:59.820]  Step 160596  [4.064 sec/step, loss=0.09271, avg_loss=0.08666, mel_loss=0.04081, linear_loss=0.05190]
[2020-05-12 12:41:05.424]  Step 160597  [4.091 sec/step, loss=0.09459, avg_loss=0.08669, mel_loss=0.04270, linear_loss=0.05188]
[2020-05-12 12:41:07.057]  Step 160598  [4.098 sec/step, loss=0.08625, avg_loss=0.08682, mel_loss=0.03732, linear_loss=0.04893]
[2020-05-12 12:41:09.928]  Step 160599  [4.106 sec/step, loss=0.09156, avg_loss=0.08685, mel_loss=0.04022, linear_loss=0.05134]
[2020-05-12 12:41:14.086]  Step 160600  [4.120 sec/step, loss=0.09494, avg_loss=0.08690, mel_loss=0.04255, linear_loss=0.05239]
[2020-05-12 12:41:14.086]  Writing summary at step: 160600
[2020-05-12 12:41:16.548]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160600
[2020-05-12 12:41:18.181]  Saving audio and alignment...
[2020-05-12 12:41:21.291]  Input: 재미가 있거나 정보가 있거나~_____________
[2020-05-12 12:41:23.609]  Step 160601  [4.131 sec/step, loss=0.08911, avg_loss=0.08696, mel_loss=0.03885, linear_loss=0.05026]
[2020-05-12 12:41:28.897]  Step 160602  [4.172 sec/step, loss=0.09433, avg_loss=0.08709, mel_loss=0.04220, linear_loss=0.05214]
[2020-05-12 12:41:30.234]  Step 160603  [4.103 sec/step, loss=0.08294, avg_loss=0.08697, mel_loss=0.03556, linear_loss=0.04738]
[2020-05-12 12:41:32.000]  Generated 32 batches of size 32 in 1.762 sec
[2020-05-12 12:41:33.961]  Step 160604  [4.102 sec/step, loss=0.09348, avg_loss=0.08698, mel_loss=0.04137, linear_loss=0.05210]
[2020-05-12 12:41:35.841]  Step 160605  [4.104 sec/step, loss=0.08787, avg_loss=0.08700, mel_loss=0.03800, linear_loss=0.04987]
[2020-05-12 12:41:39.906]  Step 160606  [4.132 sec/step, loss=0.09264, avg_loss=0.08707, mel_loss=0.04088, linear_loss=0.05176]
[2020-05-12 12:41:47.359]  Step 160607  [4.177 sec/step, loss=0.09566, avg_loss=0.08711, mel_loss=0.04361, linear_loss=0.05206]
[2020-05-12 12:41:48.739]  Step 160608  [4.186 sec/step, loss=0.08278, avg_loss=0.08726, mel_loss=0.03589, linear_loss=0.04689]
[2020-05-12 12:41:49.492]  Step 160609  [4.152 sec/step, loss=0.07261, avg_loss=0.08704, mel_loss=0.03103, linear_loss=0.04158]
[2020-05-12 12:41:50.481]  Step 160610  [4.154 sec/step, loss=0.07701, avg_loss=0.08704, mel_loss=0.03273, linear_loss=0.04428]
[2020-05-12 12:42:04.643]  Step 160611  [4.246 sec/step, loss=0.07326, avg_loss=0.08683, mel_loss=0.03418, linear_loss=0.03909]
[2020-05-12 12:42:09.387]  Step 160612  [4.273 sec/step, loss=0.09425, avg_loss=0.08690, mel_loss=0.04198, linear_loss=0.05227]
[2020-05-12 12:42:13.664]  Step 160613  [4.243 sec/step, loss=0.09115, avg_loss=0.08687, mel_loss=0.04033, linear_loss=0.05082]
[2020-05-12 12:42:15.294]  Step 160614  [4.251 sec/step, loss=0.08396, avg_loss=0.08699, mel_loss=0.03627, linear_loss=0.04768]
[2020-05-12 12:42:17.207]  Step 160615  [4.251 sec/step, loss=0.08456, avg_loss=0.08696, mel_loss=0.03653, linear_loss=0.04803]
[2020-05-12 12:42:19.734]  Step 160616  [4.267 sec/step, loss=0.08822, avg_loss=0.08702, mel_loss=0.03825, linear_loss=0.04997]
[2020-05-12 12:42:21.508]  Step 160617  [4.261 sec/step, loss=0.08764, avg_loss=0.08701, mel_loss=0.03781, linear_loss=0.04982]
[2020-05-12 12:42:25.131]  Step 160618  [4.154 sec/step, loss=0.09269, avg_loss=0.08722, mel_loss=0.04093, linear_loss=0.05175]
[2020-05-12 12:42:27.168]  Step 160619  [4.127 sec/step, loss=0.08683, avg_loss=0.08716, mel_loss=0.03764, linear_loss=0.04919]
[2020-05-12 12:42:27.979]  Step 160620  [4.078 sec/step, loss=0.07727, avg_loss=0.08699, mel_loss=0.03307, linear_loss=0.04420]
[2020-05-12 12:42:29.089]  Step 160621  [4.082 sec/step, loss=0.08142, avg_loss=0.08705, mel_loss=0.03433, linear_loss=0.04709]
[2020-05-12 12:42:32.050]  Step 160622  [4.070 sec/step, loss=0.09168, avg_loss=0.08704, mel_loss=0.04021, linear_loss=0.05147]
[2020-05-12 12:42:34.522]  Step 160623  [4.085 sec/step, loss=0.08783, avg_loss=0.08714, mel_loss=0.03847, linear_loss=0.04937]
[2020-05-12 12:42:35.536]  Step 160624  [4.084 sec/step, loss=0.07960, avg_loss=0.08712, mel_loss=0.03319, linear_loss=0.04641]
[2020-05-12 12:42:39.304]  Step 160625  [4.110 sec/step, loss=0.09312, avg_loss=0.08726, mel_loss=0.04125, linear_loss=0.05187]
[2020-05-12 12:42:40.381]  Step 160626  [4.032 sec/step, loss=0.07770, avg_loss=0.08711, mel_loss=0.03334, linear_loss=0.04437]
[2020-05-12 12:42:43.864]  Step 160627  [4.041 sec/step, loss=0.09237, avg_loss=0.08714, mel_loss=0.04097, linear_loss=0.05140]
[2020-05-12 12:42:50.411]  Step 160628  [4.051 sec/step, loss=0.09500, avg_loss=0.08715, mel_loss=0.04306, linear_loss=0.05194]
[2020-05-12 12:42:59.266]  Step 160629  [4.087 sec/step, loss=0.09240, avg_loss=0.08714, mel_loss=0.04213, linear_loss=0.05027]
[2020-05-12 12:43:07.111]  Step 160630  [4.139 sec/step, loss=0.09552, avg_loss=0.08720, mel_loss=0.04323, linear_loss=0.05229]
[2020-05-12 12:43:08.613]  Step 160631  [4.133 sec/step, loss=0.08557, avg_loss=0.08716, mel_loss=0.03670, linear_loss=0.04887]
[2020-05-12 12:43:09.198]  Step 160632  [4.093 sec/step, loss=0.06776, avg_loss=0.08689, mel_loss=0.02903, linear_loss=0.03873]
[2020-05-12 12:43:14.745]  Step 160633  [4.128 sec/step, loss=0.09576, avg_loss=0.08696, mel_loss=0.04280, linear_loss=0.05297]
[2020-05-12 12:43:16.993]  Step 160634  [4.136 sec/step, loss=0.08710, avg_loss=0.08697, mel_loss=0.03799, linear_loss=0.04911]
[2020-05-12 12:43:30.730]  Step 160635  [4.256 sec/step, loss=0.08647, avg_loss=0.08696, mel_loss=0.04029, linear_loss=0.04617]
[2020-05-12 12:43:32.384]  Step 160636  [4.237 sec/step, loss=0.08603, avg_loss=0.08690, mel_loss=0.03749, linear_loss=0.04854]
[2020-05-12 12:43:35.215]  Step 160637  [4.253 sec/step, loss=0.09070, avg_loss=0.08697, mel_loss=0.03989, linear_loss=0.05082]
[2020-05-12 12:43:43.580]  Step 160638  [4.293 sec/step, loss=0.09495, avg_loss=0.08699, mel_loss=0.04275, linear_loss=0.05220]
[2020-05-12 12:43:46.879]  Step 160639  [4.318 sec/step, loss=0.09300, avg_loss=0.08718, mel_loss=0.04094, linear_loss=0.05206]
[2020-05-12 12:43:51.997]  Step 160640  [4.239 sec/step, loss=0.09324, avg_loss=0.08728, mel_loss=0.04170, linear_loss=0.05154]
[2020-05-12 12:43:53.272]  Step 160641  [4.221 sec/step, loss=0.08115, avg_loss=0.08715, mel_loss=0.03494, linear_loss=0.04621]
[2020-05-12 12:43:54.153]  Step 160642  [4.154 sec/step, loss=0.07051, avg_loss=0.08689, mel_loss=0.03029, linear_loss=0.04021]
[2020-05-12 12:43:55.507]  Step 160643  [4.158 sec/step, loss=0.08406, avg_loss=0.08691, mel_loss=0.03597, linear_loss=0.04809]
[2020-05-12 12:44:00.093]  Step 160644  [4.167 sec/step, loss=0.09595, avg_loss=0.08692, mel_loss=0.04278, linear_loss=0.05317]
[2020-05-12 12:45:01.766]  Generated 32 batches of size 32 in 91.030 sec
[2020-05-12 12:45:05.244]  Step 160645  [4.795 sec/step, loss=0.09126, avg_loss=0.08693, mel_loss=0.04023, linear_loss=0.05103]
[2020-05-12 12:45:06.652]  Step 160646  [4.793 sec/step, loss=0.08471, avg_loss=0.08691, mel_loss=0.03652, linear_loss=0.04819]
[2020-05-12 12:45:12.073]  Step 160647  [4.828 sec/step, loss=0.09376, avg_loss=0.08698, mel_loss=0.04218, linear_loss=0.05158]
[2020-05-12 12:45:14.133]  Step 160648  [4.820 sec/step, loss=0.08759, avg_loss=0.08695, mel_loss=0.03806, linear_loss=0.04953]
[2020-05-12 12:45:17.852]  Step 160649  [4.843 sec/step, loss=0.09428, avg_loss=0.08706, mel_loss=0.04179, linear_loss=0.05249]
[2020-05-12 12:45:19.777]  Step 160650  [4.854 sec/step, loss=0.08671, avg_loss=0.08721, mel_loss=0.03753, linear_loss=0.04918]
[2020-05-12 12:45:19.777]  Writing summary at step: 160650
[2020-05-12 12:45:22.816]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160650
[2020-05-12 12:45:24.502]  Saving audio and alignment...
[2020-05-12 12:45:28.702]  Input: 박영아 기자가 보도합니다 이렇게 하는 거죠~________
[2020-05-12 12:45:29.670]  Step 160651  [4.302 sec/step, loss=0.07863, avg_loss=0.08716, mel_loss=0.03349, linear_loss=0.04514]
[2020-05-12 12:45:31.020]  Step 160652  [4.302 sec/step, loss=0.08115, avg_loss=0.08713, mel_loss=0.03469, linear_loss=0.04647]
[2020-05-12 12:45:33.289]  Step 160653  [4.305 sec/step, loss=0.08958, avg_loss=0.08717, mel_loss=0.03901, linear_loss=0.05058]
[2020-05-12 12:45:47.706]  Step 160654  [4.438 sec/step, loss=0.07425, avg_loss=0.08711, mel_loss=0.03477, linear_loss=0.03948]
[2020-05-12 12:45:52.640]  Step 160655  [4.357 sec/step, loss=0.09437, avg_loss=0.08724, mel_loss=0.04191, linear_loss=0.05247]
[2020-05-12 12:45:58.587]  Step 160656  [4.360 sec/step, loss=0.09356, avg_loss=0.08723, mel_loss=0.04209, linear_loss=0.05147]
[2020-05-12 12:46:00.773]  Step 160657  [4.370 sec/step, loss=0.08965, avg_loss=0.08731, mel_loss=0.03909, linear_loss=0.05056]
[2020-05-12 12:46:03.492]  Step 160658  [4.375 sec/step, loss=0.08987, avg_loss=0.08733, mel_loss=0.03963, linear_loss=0.05024]
[2020-05-12 12:46:10.848]  Step 160659  [4.431 sec/step, loss=0.09597, avg_loss=0.08743, mel_loss=0.04358, linear_loss=0.05239]
[2020-05-12 12:46:12.425]  Step 160660  [4.395 sec/step, loss=0.08547, avg_loss=0.08735, mel_loss=0.03690, linear_loss=0.04857]
[2020-05-12 12:46:14.111]  Step 160661  [4.406 sec/step, loss=0.08801, avg_loss=0.08752, mel_loss=0.03785, linear_loss=0.05016]
[2020-05-12 12:46:17.735]  Step 160662  [4.372 sec/step, loss=0.09179, avg_loss=0.08749, mel_loss=0.04090, linear_loss=0.05089]
[2020-05-12 12:46:22.131]  Step 160663  [4.408 sec/step, loss=0.09611, avg_loss=0.08772, mel_loss=0.04313, linear_loss=0.05299]
[2020-05-12 12:46:26.379]  Step 160664  [4.443 sec/step, loss=0.09236, avg_loss=0.08787, mel_loss=0.04080, linear_loss=0.05155]
[2020-05-12 12:46:28.154]  Step 160665  [4.447 sec/step, loss=0.08435, avg_loss=0.08789, mel_loss=0.03610, linear_loss=0.04825]
[2020-05-12 12:46:29.326]  Step 160666  [4.431 sec/step, loss=0.08098, avg_loss=0.08780, mel_loss=0.03461, linear_loss=0.04637]
[2020-05-12 12:46:38.106]  Step 160667  [4.496 sec/step, loss=0.09328, avg_loss=0.08783, mel_loss=0.04256, linear_loss=0.05073]
[2020-05-12 12:46:39.203]  Step 160668  [4.481 sec/step, loss=0.08184, avg_loss=0.08777, mel_loss=0.03440, linear_loss=0.04744]
[2020-05-12 12:46:41.948]  Step 160669  [4.490 sec/step, loss=0.09060, avg_loss=0.08783, mel_loss=0.03986, linear_loss=0.05074]
[2020-05-12 12:46:42.709]  Step 160670  [4.469 sec/step, loss=0.07353, avg_loss=0.08766, mel_loss=0.03118, linear_loss=0.04235]
[2020-05-12 12:46:43.287]  Step 160671  [4.432 sec/step, loss=0.06883, avg_loss=0.08741, mel_loss=0.03044, linear_loss=0.03838]
[2020-05-12 12:46:44.060]  Step 160672  [4.406 sec/step, loss=0.07750, avg_loss=0.08728, mel_loss=0.03221, linear_loss=0.04529]
[2020-05-12 12:46:47.437]  Step 160673  [4.353 sec/step, loss=0.09291, avg_loss=0.08727, mel_loss=0.04092, linear_loss=0.05199]
[2020-05-12 12:46:48.354]  Step 160674  [4.329 sec/step, loss=0.07580, avg_loss=0.08710, mel_loss=0.03218, linear_loss=0.04362]
[2020-05-12 12:47:24.122]  Generated 32 batches of size 32 in 55.962 sec
[2020-05-12 12:47:27.266]  Step 160675  [4.652 sec/step, loss=0.09389, avg_loss=0.08709, mel_loss=0.04128, linear_loss=0.05262]
[2020-05-12 12:47:28.260]  Step 160676  [4.616 sec/step, loss=0.07553, avg_loss=0.08691, mel_loss=0.03168, linear_loss=0.04384]
[2020-05-12 12:47:35.072]  Step 160677  [4.653 sec/step, loss=0.09706, avg_loss=0.08696, mel_loss=0.04393, linear_loss=0.05314]
[2020-05-12 12:47:37.422]  Step 160678  [4.639 sec/step, loss=0.09085, avg_loss=0.08693, mel_loss=0.03969, linear_loss=0.05117]
[2020-05-12 12:47:39.219]  Step 160679  [4.646 sec/step, loss=0.08688, avg_loss=0.08697, mel_loss=0.03753, linear_loss=0.04935]
[2020-05-12 12:47:41.721]  Step 160680  [4.663 sec/step, loss=0.08748, avg_loss=0.08707, mel_loss=0.03804, linear_loss=0.04945]
[2020-05-12 12:47:43.617]  Step 160681  [4.646 sec/step, loss=0.08826, avg_loss=0.08701, mel_loss=0.03817, linear_loss=0.05009]
[2020-05-12 12:47:47.813]  Step 160682  [4.668 sec/step, loss=0.09228, avg_loss=0.08706, mel_loss=0.04102, linear_loss=0.05127]
[2020-05-12 12:47:48.613]  Step 160683  [4.296 sec/step, loss=0.07258, avg_loss=0.08696, mel_loss=0.03092, linear_loss=0.04166]
[2020-05-12 12:47:49.455]  Step 160684  [4.218 sec/step, loss=0.07376, avg_loss=0.08676, mel_loss=0.03146, linear_loss=0.04230]
[2020-05-12 12:47:50.802]  Step 160685  [4.210 sec/step, loss=0.08395, avg_loss=0.08673, mel_loss=0.03585, linear_loss=0.04810]
[2020-05-12 12:47:54.260]  Step 160686  [4.233 sec/step, loss=0.09292, avg_loss=0.08687, mel_loss=0.04099, linear_loss=0.05193]
[2020-05-12 12:47:58.839]  Step 160687  [4.269 sec/step, loss=0.09282, avg_loss=0.08701, mel_loss=0.04122, linear_loss=0.05159]
[2020-05-12 12:47:59.857]  Step 160688  [4.271 sec/step, loss=0.07865, avg_loss=0.08711, mel_loss=0.03340, linear_loss=0.04525]
[2020-05-12 12:48:05.621]  Step 160689  [4.299 sec/step, loss=0.09582, avg_loss=0.08714, mel_loss=0.04331, linear_loss=0.05250]
[2020-05-12 12:48:06.182]  Step 160690  [4.277 sec/step, loss=0.06823, avg_loss=0.08695, mel_loss=0.02969, linear_loss=0.03855]
[2020-05-12 12:48:08.844]  Step 160691  [4.288 sec/step, loss=0.08884, avg_loss=0.08697, mel_loss=0.03884, linear_loss=0.05000]
[2020-05-12 12:48:11.800]  Step 160692  [4.280 sec/step, loss=0.09224, avg_loss=0.08698, mel_loss=0.04055, linear_loss=0.05169]
[2020-05-12 12:48:13.522]  Step 160693  [4.278 sec/step, loss=0.08737, avg_loss=0.08697, mel_loss=0.03746, linear_loss=0.04992]
[2020-05-12 12:48:14.906]  Step 160694  [4.284 sec/step, loss=0.08339, avg_loss=0.08703, mel_loss=0.03587, linear_loss=0.04752]
[2020-05-12 12:48:18.433]  Step 160695  [4.256 sec/step, loss=0.09200, avg_loss=0.08701, mel_loss=0.04084, linear_loss=0.05116]
[2020-05-12 12:48:20.456]  Step 160696  [4.245 sec/step, loss=0.08873, avg_loss=0.08697, mel_loss=0.03828, linear_loss=0.05044]
[2020-05-12 12:48:24.178]  Step 160697  [4.226 sec/step, loss=0.09346, avg_loss=0.08696, mel_loss=0.04134, linear_loss=0.05212]
[2020-05-12 12:48:37.296]  Step 160698  [4.341 sec/step, loss=0.08150, avg_loss=0.08691, mel_loss=0.03805, linear_loss=0.04345]
[2020-05-12 12:48:38.525]  Step 160699  [4.324 sec/step, loss=0.08279, avg_loss=0.08682, mel_loss=0.03556, linear_loss=0.04723]
[2020-05-12 12:48:43.996]  Step 160700  [4.338 sec/step, loss=0.09491, avg_loss=0.08682, mel_loss=0.04239, linear_loss=0.05252]
[2020-05-12 12:48:43.996]  Writing summary at step: 160700
[2020-05-12 12:48:46.168]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160700
[2020-05-12 12:48:47.829]  Saving audio and alignment...
[2020-05-12 12:48:49.376]  Generated 32 batches of size 32 in 25.192 sec
[2020-05-12 12:48:50.427]  Input: 그러나 중요한 것은~_______
[2020-05-12 12:48:57.817]  Step 160701  [4.388 sec/step, loss=0.09542, avg_loss=0.08688, mel_loss=0.04329, linear_loss=0.05213]
[2020-05-12 12:49:06.638]  Step 160702  [4.424 sec/step, loss=0.09441, avg_loss=0.08688, mel_loss=0.04320, linear_loss=0.05121]
[2020-05-12 12:49:11.589]  Step 160703  [4.460 sec/step, loss=0.09439, avg_loss=0.08700, mel_loss=0.04211, linear_loss=0.05228]
[2020-05-12 12:49:13.266]  Step 160704  [4.439 sec/step, loss=0.08418, avg_loss=0.08691, mel_loss=0.03628, linear_loss=0.04791]
[2020-05-12 12:49:15.001]  Step 160705  [4.438 sec/step, loss=0.08495, avg_loss=0.08688, mel_loss=0.03674, linear_loss=0.04821]
[2020-05-12 12:49:16.925]  Step 160706  [4.416 sec/step, loss=0.08538, avg_loss=0.08680, mel_loss=0.03672, linear_loss=0.04866]
[2020-05-12 12:49:19.297]  Step 160707  [4.366 sec/step, loss=0.08744, avg_loss=0.08672, mel_loss=0.03815, linear_loss=0.04929]
[2020-05-12 12:49:21.881]  Step 160708  [4.378 sec/step, loss=0.08946, avg_loss=0.08679, mel_loss=0.03901, linear_loss=0.05045]
[2020-05-12 12:49:24.552]  Step 160709  [4.397 sec/step, loss=0.09192, avg_loss=0.08698, mel_loss=0.04036, linear_loss=0.05156]
[2020-05-12 12:49:25.089]  Step 160710  [4.392 sec/step, loss=0.06684, avg_loss=0.08688, mel_loss=0.02892, linear_loss=0.03791]
[2020-05-12 12:49:38.937]  Step 160711  [4.389 sec/step, loss=0.06986, avg_loss=0.08685, mel_loss=0.03251, linear_loss=0.03735]
[2020-05-12 12:49:41.430]  Step 160712  [4.367 sec/step, loss=0.08790, avg_loss=0.08678, mel_loss=0.03806, linear_loss=0.04983]
[2020-05-12 12:49:42.254]  Step 160713  [4.332 sec/step, loss=0.07475, avg_loss=0.08662, mel_loss=0.03177, linear_loss=0.04298]
[2020-05-12 12:49:45.291]  Step 160714  [4.346 sec/step, loss=0.09202, avg_loss=0.08670, mel_loss=0.04050, linear_loss=0.05152]
[2020-05-12 12:49:48.793]  Step 160715  [4.362 sec/step, loss=0.09144, avg_loss=0.08677, mel_loss=0.04034, linear_loss=0.05111]
[2020-05-12 12:49:56.937]  Step 160716  [4.418 sec/step, loss=0.09245, avg_loss=0.08681, mel_loss=0.04192, linear_loss=0.05053]
[2020-05-12 12:50:00.704]  Step 160717  [4.438 sec/step, loss=0.09461, avg_loss=0.08688, mel_loss=0.04206, linear_loss=0.05255]
[2020-05-12 12:50:02.464]  Step 160718  [4.420 sec/step, loss=0.08745, avg_loss=0.08683, mel_loss=0.03742, linear_loss=0.05003]
[2020-05-12 12:50:05.701]  Step 160719  [4.432 sec/step, loss=0.09275, avg_loss=0.08689, mel_loss=0.04076, linear_loss=0.05199]
[2020-05-12 12:50:06.620]  Step 160720  [4.433 sec/step, loss=0.07500, avg_loss=0.08686, mel_loss=0.03151, linear_loss=0.04348]
[2020-05-12 12:50:10.853]  Step 160721  [4.464 sec/step, loss=0.09431, avg_loss=0.08699, mel_loss=0.04175, linear_loss=0.05256]
[2020-05-12 12:50:12.226]  Step 160722  [4.448 sec/step, loss=0.08329, avg_loss=0.08691, mel_loss=0.03563, linear_loss=0.04766]
[2020-05-12 12:50:17.072]  Step 160723  [4.472 sec/step, loss=0.09172, avg_loss=0.08695, mel_loss=0.04077, linear_loss=0.05095]
[2020-05-12 12:50:20.550]  Step 160724  [4.496 sec/step, loss=0.09267, avg_loss=0.08708, mel_loss=0.04092, linear_loss=0.05175]
[2020-05-12 12:50:22.581]  Step 160725  [4.479 sec/step, loss=0.08661, avg_loss=0.08701, mel_loss=0.03753, linear_loss=0.04907]
[2020-05-12 12:50:24.171]  Step 160726  [4.484 sec/step, loss=0.08515, avg_loss=0.08709, mel_loss=0.03671, linear_loss=0.04844]
[2020-05-12 12:50:25.242]  Step 160727  [4.460 sec/step, loss=0.08162, avg_loss=0.08698, mel_loss=0.03487, linear_loss=0.04674]
[2020-05-12 12:50:27.201]  Step 160728  [4.414 sec/step, loss=0.08805, avg_loss=0.08691, mel_loss=0.03795, linear_loss=0.05010]
[2020-05-12 12:50:28.542]  Step 160729  [4.339 sec/step, loss=0.08069, avg_loss=0.08679, mel_loss=0.03447, linear_loss=0.04621]
[2020-05-12 12:50:29.307]  Step 160730  [4.268 sec/step, loss=0.07423, avg_loss=0.08658, mel_loss=0.03161, linear_loss=0.04263]
[2020-05-12 12:50:30.459]  Step 160731  [4.265 sec/step, loss=0.08093, avg_loss=0.08653, mel_loss=0.03419, linear_loss=0.04675]
[2020-05-12 12:50:31.406]  Step 160732  [4.268 sec/step, loss=0.08125, avg_loss=0.08667, mel_loss=0.03461, linear_loss=0.04664]
[2020-05-12 12:50:38.417]  Step 160733  [4.283 sec/step, loss=0.09635, avg_loss=0.08668, mel_loss=0.04375, linear_loss=0.05260]
[2020-05-12 12:50:43.855]  Step 160734  [4.315 sec/step, loss=0.09548, avg_loss=0.08676, mel_loss=0.04277, linear_loss=0.05272]
[2020-05-12 12:50:49.928]  Step 160735  [4.238 sec/step, loss=0.09447, avg_loss=0.08684, mel_loss=0.04274, linear_loss=0.05173]
[2020-05-12 12:50:54.310]  Step 160736  [4.265 sec/step, loss=0.09401, avg_loss=0.08692, mel_loss=0.04194, linear_loss=0.05206]
[2020-05-12 12:51:59.833]  Generated 32 batches of size 32 in 94.587 sec
[2020-05-12 12:52:03.082]  Step 160737  [4.925 sec/step, loss=0.09303, avg_loss=0.08694, mel_loss=0.04084, linear_loss=0.05219]
[2020-05-12 12:52:06.587]  Step 160738  [4.876 sec/step, loss=0.09134, avg_loss=0.08691, mel_loss=0.04028, linear_loss=0.05106]
[2020-05-12 12:52:07.359]  Step 160739  [4.851 sec/step, loss=0.07120, avg_loss=0.08669, mel_loss=0.03160, linear_loss=0.03960]
[2020-05-12 12:52:12.490]  Step 160740  [4.851 sec/step, loss=0.09376, avg_loss=0.08669, mel_loss=0.04220, linear_loss=0.05156]
[2020-05-12 12:52:15.267]  Step 160741  [4.866 sec/step, loss=0.08837, avg_loss=0.08677, mel_loss=0.03899, linear_loss=0.04938]
[2020-05-12 12:52:17.221]  Step 160742  [4.877 sec/step, loss=0.08715, avg_loss=0.08693, mel_loss=0.03800, linear_loss=0.04915]
[2020-05-12 12:52:20.643]  Step 160743  [4.898 sec/step, loss=0.09380, avg_loss=0.08703, mel_loss=0.04159, linear_loss=0.05221]
[2020-05-12 12:52:22.852]  Step 160744  [4.874 sec/step, loss=0.08842, avg_loss=0.08695, mel_loss=0.03860, linear_loss=0.04982]
[2020-05-12 12:52:25.771]  Step 160745  [4.251 sec/step, loss=0.09235, avg_loss=0.08697, mel_loss=0.04038, linear_loss=0.05197]
[2020-05-12 12:52:28.091]  Step 160746  [4.261 sec/step, loss=0.08848, avg_loss=0.08700, mel_loss=0.03873, linear_loss=0.04975]
[2020-05-12 12:52:41.229]  Step 160747  [4.338 sec/step, loss=0.08238, avg_loss=0.08689, mel_loss=0.03846, linear_loss=0.04392]
[2020-05-12 12:52:46.997]  Step 160748  [4.375 sec/step, loss=0.09548, avg_loss=0.08697, mel_loss=0.04290, linear_loss=0.05258]
[2020-05-12 12:52:49.059]  Step 160749  [4.358 sec/step, loss=0.08799, avg_loss=0.08691, mel_loss=0.03824, linear_loss=0.04975]
[2020-05-12 12:52:49.783]  Step 160750  [4.346 sec/step, loss=0.07567, avg_loss=0.08679, mel_loss=0.03229, linear_loss=0.04339]
[2020-05-12 12:52:49.783]  Writing summary at step: 160750
[2020-05-12 12:52:50.599]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160750
[2020-05-12 12:52:52.235]  Saving audio and alignment...
[2020-05-12 12:52:56.372]  Input: 자 다음이 문장을 시켜보면~__________________________
[2020-05-12 12:53:05.298]  Step 160751  [4.426 sec/step, loss=0.09400, avg_loss=0.08695, mel_loss=0.04334, linear_loss=0.05066]
[2020-05-12 12:53:10.089]  Step 160752  [4.460 sec/step, loss=0.09410, avg_loss=0.08708, mel_loss=0.04192, linear_loss=0.05218]
[2020-05-12 12:53:17.794]  Step 160753  [4.515 sec/step, loss=0.09491, avg_loss=0.08713, mel_loss=0.04306, linear_loss=0.05185]
[2020-05-12 12:53:21.672]  Step 160754  [4.409 sec/step, loss=0.09217, avg_loss=0.08731, mel_loss=0.04070, linear_loss=0.05147]
[2020-05-12 12:53:22.590]  Step 160755  [4.369 sec/step, loss=0.07718, avg_loss=0.08714, mel_loss=0.03254, linear_loss=0.04464]
[2020-05-12 12:53:23.709]  Step 160756  [4.321 sec/step, loss=0.08159, avg_loss=0.08702, mel_loss=0.03463, linear_loss=0.04696]
[2020-05-12 12:53:30.268]  Step 160757  [4.364 sec/step, loss=0.09418, avg_loss=0.08706, mel_loss=0.04268, linear_loss=0.05150]
[2020-05-12 12:53:34.650]  Step 160758  [4.381 sec/step, loss=0.09342, avg_loss=0.08710, mel_loss=0.04144, linear_loss=0.05198]
[2020-05-12 12:53:35.673]  Step 160759  [4.318 sec/step, loss=0.07730, avg_loss=0.08691, mel_loss=0.03293, linear_loss=0.04437]
[2020-05-12 12:53:37.213]  Step 160760  [4.317 sec/step, loss=0.08518, avg_loss=0.08691, mel_loss=0.03674, linear_loss=0.04844]
[2020-05-12 12:53:38.620]  Step 160761  [4.315 sec/step, loss=0.08320, avg_loss=0.08686, mel_loss=0.03579, linear_loss=0.04740]
[2020-05-12 12:53:39.843]  Step 160762  [4.291 sec/step, loss=0.08151, avg_loss=0.08676, mel_loss=0.03497, linear_loss=0.04654]
[2020-05-12 12:53:43.566]  Step 160763  [4.284 sec/step, loss=0.09387, avg_loss=0.08674, mel_loss=0.04162, linear_loss=0.05225]
[2020-05-12 12:53:45.186]  Step 160764  [4.258 sec/step, loss=0.08734, avg_loss=0.08669, mel_loss=0.03779, linear_loss=0.04956]
[2020-05-12 12:53:48.012]  Step 160765  [4.268 sec/step, loss=0.08437, avg_loss=0.08669, mel_loss=0.03632, linear_loss=0.04804]
[2020-05-12 12:53:50.056]  Step 160766  [4.277 sec/step, loss=0.08231, avg_loss=0.08670, mel_loss=0.03528, linear_loss=0.04703]
[2020-05-12 12:53:54.107]  Generated 32 batches of size 32 in 23.832 sec
[2020-05-12 12:53:56.827]  Step 160767  [4.257 sec/step, loss=0.08909, avg_loss=0.08666, mel_loss=0.03877, linear_loss=0.05031]
[2020-05-12 12:53:58.848]  Step 160768  [4.266 sec/step, loss=0.08881, avg_loss=0.08673, mel_loss=0.03835, linear_loss=0.05047]
[2020-05-12 12:54:00.102]  Step 160769  [4.251 sec/step, loss=0.08015, avg_loss=0.08662, mel_loss=0.03431, linear_loss=0.04584]
[2020-05-12 12:54:03.692]  Step 160770  [4.279 sec/step, loss=0.09171, avg_loss=0.08680, mel_loss=0.04047, linear_loss=0.05124]
[2020-05-12 12:54:07.877]  Step 160771  [4.315 sec/step, loss=0.09277, avg_loss=0.08704, mel_loss=0.04114, linear_loss=0.05163]
[2020-05-12 12:54:10.070]  Step 160772  [4.330 sec/step, loss=0.08706, avg_loss=0.08714, mel_loss=0.03788, linear_loss=0.04917]
[2020-05-12 12:54:24.828]  Step 160773  [4.443 sec/step, loss=0.07738, avg_loss=0.08698, mel_loss=0.03633, linear_loss=0.04105]
[2020-05-12 12:54:26.936]  Step 160774  [4.455 sec/step, loss=0.08397, avg_loss=0.08707, mel_loss=0.03643, linear_loss=0.04754]
[2020-05-12 12:54:29.560]  Step 160775  [4.092 sec/step, loss=0.08928, avg_loss=0.08702, mel_loss=0.03924, linear_loss=0.05004]
[2020-05-12 12:54:30.666]  Step 160776  [4.094 sec/step, loss=0.07721, avg_loss=0.08704, mel_loss=0.03259, linear_loss=0.04462]
[2020-05-12 12:54:31.562]  Step 160777  [4.034 sec/step, loss=0.07231, avg_loss=0.08679, mel_loss=0.03084, linear_loss=0.04147]
[2020-05-12 12:54:32.354]  Step 160778  [4.019 sec/step, loss=0.07317, avg_loss=0.08661, mel_loss=0.03087, linear_loss=0.04230]
[2020-05-12 12:54:41.239]  Step 160779  [4.090 sec/step, loss=0.09408, avg_loss=0.08668, mel_loss=0.04288, linear_loss=0.05120]
[2020-05-12 12:54:43.942]  Step 160780  [4.092 sec/step, loss=0.09070, avg_loss=0.08672, mel_loss=0.03977, linear_loss=0.05094]
[2020-05-12 12:54:45.740]  Step 160781  [4.091 sec/step, loss=0.08728, avg_loss=0.08671, mel_loss=0.03750, linear_loss=0.04979]
[2020-05-12 12:54:47.117]  Step 160782  [4.063 sec/step, loss=0.08515, avg_loss=0.08664, mel_loss=0.03619, linear_loss=0.04896]
[2020-05-12 12:54:47.657]  Step 160783  [4.060 sec/step, loss=0.06679, avg_loss=0.08658, mel_loss=0.02899, linear_loss=0.03780]
[2020-05-12 12:54:50.866]  Step 160784  [4.084 sec/step, loss=0.09245, avg_loss=0.08676, mel_loss=0.04076, linear_loss=0.05169]
[2020-05-12 12:54:52.520]  Step 160785  [4.087 sec/step, loss=0.08477, avg_loss=0.08677, mel_loss=0.03656, linear_loss=0.04821]
[2020-05-12 12:54:53.931]  Step 160786  [4.066 sec/step, loss=0.08471, avg_loss=0.08669, mel_loss=0.03665, linear_loss=0.04806]
[2020-05-12 12:54:54.945]  Step 160787  [4.031 sec/step, loss=0.07826, avg_loss=0.08655, mel_loss=0.03316, linear_loss=0.04509]
[2020-05-12 12:54:59.226]  Step 160788  [4.063 sec/step, loss=0.09318, avg_loss=0.08669, mel_loss=0.04150, linear_loss=0.05168]
[2020-05-12 12:55:05.678]  Step 160789  [4.070 sec/step, loss=0.09475, avg_loss=0.08668, mel_loss=0.04304, linear_loss=0.05172]
[2020-05-12 12:55:09.192]  Step 160790  [4.100 sec/step, loss=0.09191, avg_loss=0.08692, mel_loss=0.04064, linear_loss=0.05127]
[2020-05-12 12:55:10.308]  Step 160791  [4.084 sec/step, loss=0.08334, avg_loss=0.08686, mel_loss=0.03524, linear_loss=0.04811]
[2020-05-12 12:55:13.286]  Step 160792  [4.084 sec/step, loss=0.09139, avg_loss=0.08685, mel_loss=0.04047, linear_loss=0.05092]
[2020-05-12 12:55:15.031]  Step 160793  [4.085 sec/step, loss=0.08457, avg_loss=0.08683, mel_loss=0.03652, linear_loss=0.04805]
[2020-05-12 12:55:20.324]  Step 160794  [4.124 sec/step, loss=0.09522, avg_loss=0.08694, mel_loss=0.04268, linear_loss=0.05254]
[2020-05-12 12:55:24.034]  Step 160795  [4.126 sec/step, loss=0.09304, avg_loss=0.08695, mel_loss=0.04097, linear_loss=0.05207]
[2020-05-12 12:55:28.789]  Step 160796  [4.153 sec/step, loss=0.09392, avg_loss=0.08701, mel_loss=0.04187, linear_loss=0.05205]
[2020-05-12 12:55:34.595]  Step 160797  [4.174 sec/step, loss=0.09516, avg_loss=0.08702, mel_loss=0.04294, linear_loss=0.05221]
[2020-05-12 12:55:42.330]  Step 160798  [4.120 sec/step, loss=0.09395, avg_loss=0.08715, mel_loss=0.04268, linear_loss=0.05126]
[2020-05-12 12:56:39.510]  Generated 32 batches of size 32 in 93.827 sec
[2020-05-12 12:56:44.999]  Step 160799  [4.734 sec/step, loss=0.09148, avg_loss=0.08723, mel_loss=0.04093, linear_loss=0.05055]
[2020-05-12 12:56:48.046]  Step 160800  [4.710 sec/step, loss=0.09211, avg_loss=0.08721, mel_loss=0.04056, linear_loss=0.05155]
[2020-05-12 12:56:48.046]  Writing summary at step: 160800
[2020-05-12 12:56:51.765]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160800
[2020-05-12 12:56:53.409]  Saving audio and alignment...
[2020-05-12 12:57:04.641]  Input: 상대로 하여금 내가 참 잘 경청해 주고 적극 공감해주는 한마디로 말이 잘 통하는 상대다 라는 생각을~______________________
[2020-05-12 12:57:07.519]  Step 160801  [4.665 sec/step, loss=0.09201, avg_loss=0.08717, mel_loss=0.04029, linear_loss=0.05171]
[2020-05-12 12:57:13.149]  Step 160802  [4.633 sec/step, loss=0.09306, avg_loss=0.08716, mel_loss=0.04150, linear_loss=0.05155]
[2020-05-12 12:57:15.089]  Step 160803  [4.603 sec/step, loss=0.08808, avg_loss=0.08710, mel_loss=0.03792, linear_loss=0.05015]
[2020-05-12 12:57:22.058]  Step 160804  [4.656 sec/step, loss=0.09615, avg_loss=0.08721, mel_loss=0.04366, linear_loss=0.05249]
[2020-05-12 12:57:23.859]  Step 160805  [4.656 sec/step, loss=0.08581, avg_loss=0.08722, mel_loss=0.03677, linear_loss=0.04904]
[2020-05-12 12:57:28.501]  Step 160806  [4.684 sec/step, loss=0.09428, avg_loss=0.08731, mel_loss=0.04206, linear_loss=0.05222]
[2020-05-12 12:57:29.520]  Step 160807  [4.670 sec/step, loss=0.07917, avg_loss=0.08723, mel_loss=0.03386, linear_loss=0.04531]
[2020-05-12 12:57:31.719]  Step 160808  [4.666 sec/step, loss=0.08867, avg_loss=0.08722, mel_loss=0.03870, linear_loss=0.04996]
[2020-05-12 12:57:38.378]  Step 160809  [4.706 sec/step, loss=0.09418, avg_loss=0.08724, mel_loss=0.04238, linear_loss=0.05180]
[2020-05-12 12:57:41.662]  Step 160810  [4.734 sec/step, loss=0.09179, avg_loss=0.08749, mel_loss=0.04028, linear_loss=0.05151]
[2020-05-12 12:57:44.394]  Step 160811  [4.622 sec/step, loss=0.08957, avg_loss=0.08769, mel_loss=0.03914, linear_loss=0.05044]
[2020-05-12 12:57:56.176]  Step 160812  [4.715 sec/step, loss=0.08690, avg_loss=0.08768, mel_loss=0.04032, linear_loss=0.04658]
[2020-05-12 12:57:56.993]  Step 160813  [4.715 sec/step, loss=0.07417, avg_loss=0.08768, mel_loss=0.03145, linear_loss=0.04272]
[2020-05-12 12:58:01.102]  Step 160814  [4.726 sec/step, loss=0.09304, avg_loss=0.08769, mel_loss=0.04105, linear_loss=0.05199]
[2020-05-12 12:58:02.631]  Step 160815  [4.706 sec/step, loss=0.08197, avg_loss=0.08759, mel_loss=0.03518, linear_loss=0.04679]
[2020-05-12 12:58:03.188]  Step 160816  [4.630 sec/step, loss=0.06818, avg_loss=0.08735, mel_loss=0.02995, linear_loss=0.03823]
[2020-05-12 12:58:07.549]  Step 160817  [4.636 sec/step, loss=0.09372, avg_loss=0.08734, mel_loss=0.04166, linear_loss=0.05206]
[2020-05-12 12:58:10.183]  Step 160818  [4.645 sec/step, loss=0.08968, avg_loss=0.08736, mel_loss=0.03911, linear_loss=0.05056]
[2020-05-12 12:58:11.195]  Step 160819  [4.623 sec/step, loss=0.07596, avg_loss=0.08719, mel_loss=0.03218, linear_loss=0.04377]
[2020-05-12 12:58:13.355]  Step 160820  [4.635 sec/step, loss=0.08873, avg_loss=0.08733, mel_loss=0.03876, linear_loss=0.04997]
[2020-05-12 12:58:15.042]  Step 160821  [4.610 sec/step, loss=0.08558, avg_loss=0.08724, mel_loss=0.03709, linear_loss=0.04849]
[2020-05-12 12:58:16.241]  Step 160822  [4.608 sec/step, loss=0.08174, avg_loss=0.08723, mel_loss=0.03492, linear_loss=0.04682]
[2020-05-12 12:58:17.369]  Step 160823  [4.571 sec/step, loss=0.08031, avg_loss=0.08711, mel_loss=0.03400, linear_loss=0.04631]
[2020-05-12 12:58:20.917]  Step 160824  [4.572 sec/step, loss=0.09143, avg_loss=0.08710, mel_loss=0.04035, linear_loss=0.05108]
[2020-05-12 12:58:22.290]  Step 160825  [4.565 sec/step, loss=0.08193, avg_loss=0.08705, mel_loss=0.03528, linear_loss=0.04665]
[2020-05-12 12:58:23.022]  Step 160826  [4.556 sec/step, loss=0.07444, avg_loss=0.08695, mel_loss=0.03157, linear_loss=0.04287]
[2020-05-12 12:58:25.068]  Step 160827  [4.566 sec/step, loss=0.08880, avg_loss=0.08702, mel_loss=0.03843, linear_loss=0.05037]
[2020-05-12 12:58:26.483]  Step 160828  [4.561 sec/step, loss=0.08316, avg_loss=0.08697, mel_loss=0.03576, linear_loss=0.04740]
[2020-05-12 12:58:48.180]  Generated 32 batches of size 32 in 36.979 sec
[2020-05-12 12:58:50.128]  Step 160829  [4.784 sec/step, loss=0.08682, avg_loss=0.08703, mel_loss=0.03722, linear_loss=0.04960]
[2020-05-12 12:58:51.162]  Step 160830  [4.786 sec/step, loss=0.07911, avg_loss=0.08708, mel_loss=0.03350, linear_loss=0.04561]
[2020-05-12 12:58:53.663]  Step 160831  [4.800 sec/step, loss=0.08670, avg_loss=0.08714, mel_loss=0.03754, linear_loss=0.04916]
[2020-05-12 12:58:58.698]  Step 160832  [4.841 sec/step, loss=0.09240, avg_loss=0.08725, mel_loss=0.04132, linear_loss=0.05108]
[2020-05-12 12:59:03.347]  Step 160833  [4.817 sec/step, loss=0.09444, avg_loss=0.08723, mel_loss=0.04203, linear_loss=0.05241]
[2020-05-12 12:59:07.017]  Step 160834  [4.800 sec/step, loss=0.09486, avg_loss=0.08722, mel_loss=0.04209, linear_loss=0.05278]
[2020-05-12 12:59:09.259]  Step 160835  [4.761 sec/step, loss=0.08693, avg_loss=0.08715, mel_loss=0.03779, linear_loss=0.04914]
[2020-05-12 12:59:22.397]  Step 160836  [4.849 sec/step, loss=0.08013, avg_loss=0.08701, mel_loss=0.03715, linear_loss=0.04298]
[2020-05-12 12:59:23.755]  Step 160837  [4.175 sec/step, loss=0.08394, avg_loss=0.08692, mel_loss=0.03584, linear_loss=0.04809]
[2020-05-12 12:59:25.786]  Step 160838  [4.160 sec/step, loss=0.08782, avg_loss=0.08688, mel_loss=0.03799, linear_loss=0.04983]
[2020-05-12 12:59:32.300]  Step 160839  [4.217 sec/step, loss=0.09429, avg_loss=0.08712, mel_loss=0.04264, linear_loss=0.05165]
[2020-05-12 12:59:36.896]  Step 160840  [4.212 sec/step, loss=0.09289, avg_loss=0.08711, mel_loss=0.04113, linear_loss=0.05176]
[2020-05-12 12:59:37.716]  Step 160841  [4.192 sec/step, loss=0.06779, avg_loss=0.08690, mel_loss=0.02925, linear_loss=0.03854]
[2020-05-12 12:59:46.730]  Step 160842  [4.263 sec/step, loss=0.09266, avg_loss=0.08696, mel_loss=0.04221, linear_loss=0.05045]
[2020-05-12 12:59:50.841]  Step 160843  [4.270 sec/step, loss=0.09458, avg_loss=0.08696, mel_loss=0.04167, linear_loss=0.05291]
[2020-05-12 12:59:51.975]  Step 160844  [4.259 sec/step, loss=0.08001, avg_loss=0.08688, mel_loss=0.03387, linear_loss=0.04613]
[2020-05-12 12:59:52.793]  Step 160845  [4.238 sec/step, loss=0.07514, avg_loss=0.08671, mel_loss=0.03148, linear_loss=0.04366]
[2020-05-12 12:59:55.534]  Step 160846  [4.242 sec/step, loss=0.08914, avg_loss=0.08671, mel_loss=0.03900, linear_loss=0.05014]
[2020-05-12 12:59:57.136]  Step 160847  [4.127 sec/step, loss=0.08652, avg_loss=0.08676, mel_loss=0.03711, linear_loss=0.04940]
[2020-05-12 13:00:04.737]  Step 160848  [4.145 sec/step, loss=0.09591, avg_loss=0.08676, mel_loss=0.04345, linear_loss=0.05246]
[2020-05-12 13:00:08.328]  Step 160849  [4.161 sec/step, loss=0.09135, avg_loss=0.08679, mel_loss=0.04019, linear_loss=0.05116]
[2020-05-12 13:00:10.100]  Step 160850  [4.171 sec/step, loss=0.08583, avg_loss=0.08689, mel_loss=0.03679, linear_loss=0.04904]
[2020-05-12 13:00:10.100]  Writing summary at step: 160850
[2020-05-12 13:00:10.870]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160850
[2020-05-12 13:00:12.518]  Saving audio and alignment...
[2020-05-12 13:00:17.835]  Input: 작성을 해 주신다면 백 사십만원을 주겠다~_______________________
[2020-05-12 13:00:20.015]  Step 160851  [4.104 sec/step, loss=0.08625, avg_loss=0.08682, mel_loss=0.03754, linear_loss=0.04871]
[2020-05-12 13:00:21.689]  Step 160852  [4.072 sec/step, loss=0.08588, avg_loss=0.08674, mel_loss=0.03715, linear_loss=0.04873]
[2020-05-12 13:00:27.325]  Step 160853  [4.052 sec/step, loss=0.09423, avg_loss=0.08673, mel_loss=0.04238, linear_loss=0.05185]
[2020-05-12 13:00:28.589]  Step 160854  [4.026 sec/step, loss=0.07860, avg_loss=0.08659, mel_loss=0.03349, linear_loss=0.04511]
[2020-05-12 13:00:30.005]  Step 160855  [4.031 sec/step, loss=0.08332, avg_loss=0.08665, mel_loss=0.03585, linear_loss=0.04746]
[2020-05-12 13:00:31.013]  Step 160856  [4.029 sec/step, loss=0.07926, avg_loss=0.08663, mel_loss=0.03334, linear_loss=0.04592]
[2020-05-12 13:00:34.210]  Step 160857  [3.996 sec/step, loss=0.09209, avg_loss=0.08661, mel_loss=0.04037, linear_loss=0.05172]
[2020-05-12 13:00:37.125]  Step 160858  [3.981 sec/step, loss=0.09199, avg_loss=0.08660, mel_loss=0.04018, linear_loss=0.05181]
[2020-05-12 13:00:37.171]  Generated 32 batches of size 32 in 24.005 sec
[2020-05-12 13:00:38.481]  Step 160859  [3.985 sec/step, loss=0.08146, avg_loss=0.08664, mel_loss=0.03487, linear_loss=0.04659]
[2020-05-12 13:00:39.589]  Step 160860  [3.980 sec/step, loss=0.07914, avg_loss=0.08658, mel_loss=0.03371, linear_loss=0.04543]
[2020-05-12 13:00:40.715]  Step 160861  [3.977 sec/step, loss=0.08242, avg_loss=0.08657, mel_loss=0.03492, linear_loss=0.04751]
[2020-05-12 13:00:44.849]  Step 160862  [4.006 sec/step, loss=0.09431, avg_loss=0.08670, mel_loss=0.04216, linear_loss=0.05215]
[2020-05-12 13:00:47.910]  Step 160863  [4.000 sec/step, loss=0.09168, avg_loss=0.08668, mel_loss=0.04038, linear_loss=0.05130]
[2020-05-12 13:00:50.544]  Step 160864  [4.010 sec/step, loss=0.08972, avg_loss=0.08670, mel_loss=0.03962, linear_loss=0.05010]
[2020-05-12 13:00:52.520]  Step 160865  [4.002 sec/step, loss=0.08537, avg_loss=0.08671, mel_loss=0.03689, linear_loss=0.04847]
[2020-05-12 13:00:54.261]  Step 160866  [3.998 sec/step, loss=0.08727, avg_loss=0.08676, mel_loss=0.03739, linear_loss=0.04988]
[2020-05-12 13:00:55.183]  Step 160867  [3.940 sec/step, loss=0.08012, avg_loss=0.08667, mel_loss=0.03420, linear_loss=0.04591]
[2020-05-12 13:00:57.418]  Step 160868  [3.942 sec/step, loss=0.08793, avg_loss=0.08666, mel_loss=0.03840, linear_loss=0.04953]
[2020-05-12 13:01:01.053]  Step 160869  [3.966 sec/step, loss=0.09360, avg_loss=0.08679, mel_loss=0.04154, linear_loss=0.05205]
[2020-05-12 13:01:01.593]  Step 160870  [3.935 sec/step, loss=0.07097, avg_loss=0.08659, mel_loss=0.03123, linear_loss=0.03974]
[2020-05-12 13:01:03.135]  Step 160871  [3.909 sec/step, loss=0.08358, avg_loss=0.08650, mel_loss=0.03598, linear_loss=0.04760]
[2020-05-12 13:01:08.547]  Step 160872  [3.941 sec/step, loss=0.09403, avg_loss=0.08656, mel_loss=0.04209, linear_loss=0.05194]
[2020-05-12 13:01:09.404]  Step 160873  [3.802 sec/step, loss=0.07389, avg_loss=0.08653, mel_loss=0.03120, linear_loss=0.04269]
[2020-05-12 13:01:23.920]  Step 160874  [3.926 sec/step, loss=0.07230, avg_loss=0.08641, mel_loss=0.03377, linear_loss=0.03854]
[2020-05-12 13:01:31.296]  Step 160875  [3.974 sec/step, loss=0.09403, avg_loss=0.08646, mel_loss=0.04251, linear_loss=0.05151]
[2020-05-12 13:01:33.033]  Step 160876  [3.980 sec/step, loss=0.08558, avg_loss=0.08654, mel_loss=0.03703, linear_loss=0.04855]
[2020-05-12 13:01:37.820]  Step 160877  [4.019 sec/step, loss=0.09362, avg_loss=0.08676, mel_loss=0.04174, linear_loss=0.05188]
[2020-05-12 13:01:40.284]  Step 160878  [4.036 sec/step, loss=0.08863, avg_loss=0.08691, mel_loss=0.03871, linear_loss=0.04993]
[2020-05-12 13:01:41.684]  Step 160879  [3.961 sec/step, loss=0.08327, avg_loss=0.08680, mel_loss=0.03589, linear_loss=0.04738]
[2020-05-12 13:01:47.335]  Step 160880  [3.990 sec/step, loss=0.09605, avg_loss=0.08686, mel_loss=0.04311, linear_loss=0.05294]
[2020-05-12 13:01:50.775]  Step 160881  [4.007 sec/step, loss=0.09179, avg_loss=0.08690, mel_loss=0.04061, linear_loss=0.05117]
[2020-05-12 13:01:51.536]  Step 160882  [4.001 sec/step, loss=0.07540, avg_loss=0.08681, mel_loss=0.03199, linear_loss=0.04341]
[2020-05-12 13:01:54.547]  Step 160883  [4.025 sec/step, loss=0.09026, avg_loss=0.08704, mel_loss=0.03977, linear_loss=0.05049]
[2020-05-12 13:02:00.721]  Step 160884  [4.055 sec/step, loss=0.09369, avg_loss=0.08705, mel_loss=0.04220, linear_loss=0.05149]
[2020-05-12 13:02:04.551]  Step 160885  [4.077 sec/step, loss=0.09305, avg_loss=0.08713, mel_loss=0.04114, linear_loss=0.05191]
[2020-05-12 13:02:07.099]  Step 160886  [4.088 sec/step, loss=0.08986, avg_loss=0.08719, mel_loss=0.03923, linear_loss=0.05064]
[2020-05-12 13:02:07.984]  Step 160887  [4.087 sec/step, loss=0.07555, avg_loss=0.08716, mel_loss=0.03213, linear_loss=0.04342]
[2020-05-12 13:02:16.897]  Step 160888  [4.133 sec/step, loss=0.09355, avg_loss=0.08716, mel_loss=0.04278, linear_loss=0.05077]
[2020-05-12 13:02:18.942]  Step 160889  [4.089 sec/step, loss=0.08888, avg_loss=0.08710, mel_loss=0.03832, linear_loss=0.05056]
[2020-05-12 13:02:22.429]  Step 160890  [4.089 sec/step, loss=0.09244, avg_loss=0.08711, mel_loss=0.04068, linear_loss=0.05176]
[2020-05-12 13:03:30.019]  Generated 32 batches of size 32 in 99.240 sec
[2020-05-12 13:03:31.845]  Step 160891  [4.772 sec/step, loss=0.08672, avg_loss=0.08714, mel_loss=0.03743, linear_loss=0.04929]
[2020-05-12 13:03:35.382]  Step 160892  [4.777 sec/step, loss=0.09137, avg_loss=0.08714, mel_loss=0.04012, linear_loss=0.05124]
[2020-05-12 13:03:37.799]  Step 160893  [4.784 sec/step, loss=0.08879, avg_loss=0.08719, mel_loss=0.03846, linear_loss=0.05033]
[2020-05-12 13:03:40.819]  Step 160894  [4.761 sec/step, loss=0.09221, avg_loss=0.08716, mel_loss=0.04065, linear_loss=0.05156]
[2020-05-12 13:03:41.953]  Step 160895  [4.736 sec/step, loss=0.07932, avg_loss=0.08702, mel_loss=0.03396, linear_loss=0.04536]
[2020-05-12 13:03:46.291]  Step 160896  [4.731 sec/step, loss=0.09529, avg_loss=0.08703, mel_loss=0.04249, linear_loss=0.05280]
[2020-05-12 13:03:47.671]  Step 160897  [4.687 sec/step, loss=0.08239, avg_loss=0.08690, mel_loss=0.03531, linear_loss=0.04708]
[2020-05-12 13:03:51.815]  Step 160898  [4.651 sec/step, loss=0.09365, avg_loss=0.08690, mel_loss=0.04135, linear_loss=0.05230]
[2020-05-12 13:03:54.626]  Step 160899  [4.053 sec/step, loss=0.08919, avg_loss=0.08688, mel_loss=0.03885, linear_loss=0.05034]
[2020-05-12 13:03:56.852]  Step 160900  [4.045 sec/step, loss=0.08854, avg_loss=0.08684, mel_loss=0.03837, linear_loss=0.05017]
[2020-05-12 13:03:56.852]  Writing summary at step: 160900
[2020-05-12 13:03:57.615]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160900
[2020-05-12 13:03:59.275]  Saving audio and alignment...
[2020-05-12 13:04:02.254]  Input: 처음부터 해 보도록 할게요~_____________
[2020-05-12 13:04:07.881]  Step 160901  [4.072 sec/step, loss=0.09359, avg_loss=0.08686, mel_loss=0.04214, linear_loss=0.05145]
[2020-05-12 13:04:09.841]  Step 160902  [4.035 sec/step, loss=0.08661, avg_loss=0.08679, mel_loss=0.03765, linear_loss=0.04897]
[2020-05-12 13:04:12.766]  Step 160903  [4.045 sec/step, loss=0.09123, avg_loss=0.08683, mel_loss=0.03998, linear_loss=0.05125]
[2020-05-12 13:04:14.818]  Step 160904  [3.996 sec/step, loss=0.08729, avg_loss=0.08674, mel_loss=0.03813, linear_loss=0.04915]
[2020-05-12 13:04:29.130]  Step 160905  [4.121 sec/step, loss=0.07438, avg_loss=0.08662, mel_loss=0.03467, linear_loss=0.03971]
[2020-05-12 13:04:32.603]  Step 160906  [4.109 sec/step, loss=0.09238, avg_loss=0.08660, mel_loss=0.04092, linear_loss=0.05146]
[2020-05-12 13:04:34.325]  Step 160907  [4.116 sec/step, loss=0.08685, avg_loss=0.08668, mel_loss=0.03723, linear_loss=0.04962]
[2020-05-12 13:04:36.984]  Step 160908  [4.121 sec/step, loss=0.08847, avg_loss=0.08668, mel_loss=0.03855, linear_loss=0.04992]
[2020-05-12 13:04:41.490]  Step 160909  [4.099 sec/step, loss=0.09424, avg_loss=0.08668, mel_loss=0.04188, linear_loss=0.05236]
[2020-05-12 13:04:45.215]  Step 160910  [4.104 sec/step, loss=0.09479, avg_loss=0.08671, mel_loss=0.04196, linear_loss=0.05283]
[2020-05-12 13:04:46.777]  Step 160911  [4.092 sec/step, loss=0.08365, avg_loss=0.08665, mel_loss=0.03601, linear_loss=0.04764]
[2020-05-12 13:04:47.830]  Step 160912  [3.985 sec/step, loss=0.07761, avg_loss=0.08656, mel_loss=0.03254, linear_loss=0.04508]
[2020-05-12 13:04:48.940]  Step 160913  [3.988 sec/step, loss=0.07743, avg_loss=0.08659, mel_loss=0.03299, linear_loss=0.04444]
[2020-05-12 13:04:49.740]  Step 160914  [3.955 sec/step, loss=0.07029, avg_loss=0.08636, mel_loss=0.03079, linear_loss=0.03951]
[2020-05-12 13:04:58.373]  Step 160915  [4.026 sec/step, loss=0.09281, avg_loss=0.08647, mel_loss=0.04236, linear_loss=0.05045]
[2020-05-12 13:05:05.787]  Step 160916  [4.094 sec/step, loss=0.09638, avg_loss=0.08675, mel_loss=0.04388, linear_loss=0.05249]
[2020-05-12 13:05:12.059]  Step 160917  [4.113 sec/step, loss=0.09261, avg_loss=0.08674, mel_loss=0.04177, linear_loss=0.05085]
[2020-05-12 13:05:12.863]  Step 160918  [4.095 sec/step, loss=0.07611, avg_loss=0.08661, mel_loss=0.03242, linear_loss=0.04369]
[2020-05-12 13:05:14.173]  Step 160919  [4.098 sec/step, loss=0.08172, avg_loss=0.08666, mel_loss=0.03506, linear_loss=0.04666]
[2020-05-12 13:05:19.280]  Step 160920  [4.128 sec/step, loss=0.09471, avg_loss=0.08672, mel_loss=0.04245, linear_loss=0.05226]
[2020-05-12 13:05:32.444]  Generated 32 batches of size 32 in 45.661 sec
[2020-05-12 13:05:37.883]  Step 160921  [4.297 sec/step, loss=0.09400, avg_loss=0.08681, mel_loss=0.04194, linear_loss=0.05207]
[2020-05-12 13:05:44.372]  Step 160922  [4.350 sec/step, loss=0.09619, avg_loss=0.08695, mel_loss=0.04350, linear_loss=0.05270]
[2020-05-12 13:05:47.097]  Step 160923  [4.366 sec/step, loss=0.09046, avg_loss=0.08705, mel_loss=0.03964, linear_loss=0.05083]
[2020-05-12 13:05:50.501]  Step 160924  [4.364 sec/step, loss=0.09018, avg_loss=0.08704, mel_loss=0.03999, linear_loss=0.05019]
[2020-05-12 13:05:54.118]  Step 160925  [4.387 sec/step, loss=0.09195, avg_loss=0.08714, mel_loss=0.04036, linear_loss=0.05159]
[2020-05-12 13:05:55.970]  Step 160926  [4.398 sec/step, loss=0.08687, avg_loss=0.08727, mel_loss=0.03728, linear_loss=0.04959]
[2020-05-12 13:05:58.092]  Step 160927  [4.399 sec/step, loss=0.08774, avg_loss=0.08725, mel_loss=0.03819, linear_loss=0.04955]
[2020-05-12 13:06:00.104]  Step 160928  [4.405 sec/step, loss=0.08648, avg_loss=0.08729, mel_loss=0.03731, linear_loss=0.04917]
[2020-05-12 13:06:01.706]  Step 160929  [4.184 sec/step, loss=0.08608, avg_loss=0.08728, mel_loss=0.03740, linear_loss=0.04868]
[2020-05-12 13:06:03.128]  Step 160930  [4.188 sec/step, loss=0.08434, avg_loss=0.08733, mel_loss=0.03619, linear_loss=0.04815]
[2020-05-12 13:06:04.450]  Step 160931  [4.176 sec/step, loss=0.08143, avg_loss=0.08728, mel_loss=0.03471, linear_loss=0.04672]
[2020-05-12 13:06:09.338]  Step 160932  [4.175 sec/step, loss=0.09202, avg_loss=0.08728, mel_loss=0.04097, linear_loss=0.05105]
[2020-05-12 13:06:10.283]  Step 160933  [4.138 sec/step, loss=0.07224, avg_loss=0.08705, mel_loss=0.03022, linear_loss=0.04202]
[2020-05-12 13:06:15.334]  Step 160934  [4.152 sec/step, loss=0.09391, avg_loss=0.08704, mel_loss=0.04190, linear_loss=0.05201]
[2020-05-12 13:06:21.263]  Step 160935  [4.188 sec/step, loss=0.09663, avg_loss=0.08714, mel_loss=0.04387, linear_loss=0.05276]
[2020-05-12 13:06:22.190]  Step 160936  [4.066 sec/step, loss=0.07620, avg_loss=0.08710, mel_loss=0.03231, linear_loss=0.04389]
[2020-05-12 13:06:23.252]  Step 160937  [4.063 sec/step, loss=0.08154, avg_loss=0.08708, mel_loss=0.03457, linear_loss=0.04697]
[2020-05-12 13:06:25.604]  Step 160938  [4.067 sec/step, loss=0.08918, avg_loss=0.08709, mel_loss=0.03901, linear_loss=0.05017]
[2020-05-12 13:06:27.379]  Step 160939  [4.019 sec/step, loss=0.08634, avg_loss=0.08701, mel_loss=0.03713, linear_loss=0.04922]
[2020-05-12 13:06:31.545]  Step 160940  [4.015 sec/step, loss=0.09138, avg_loss=0.08700, mel_loss=0.04043, linear_loss=0.05094]
[2020-05-12 13:06:34.274]  Step 160941  [4.034 sec/step, loss=0.08757, avg_loss=0.08720, mel_loss=0.03821, linear_loss=0.04936]
[2020-05-12 13:06:35.039]  Step 160942  [3.951 sec/step, loss=0.07212, avg_loss=0.08699, mel_loss=0.03131, linear_loss=0.04081]
[2020-05-12 13:06:38.281]  Step 160943  [3.943 sec/step, loss=0.09118, avg_loss=0.08696, mel_loss=0.04017, linear_loss=0.05101]
[2020-05-12 13:06:39.262]  Step 160944  [3.941 sec/step, loss=0.07918, avg_loss=0.08695, mel_loss=0.03369, linear_loss=0.04549]
[2020-05-12 13:06:51.020]  Generated 32 batches of size 32 in 12.733 sec
[2020-05-12 13:06:51.841]  Step 160945  [4.059 sec/step, loss=0.08585, avg_loss=0.08706, mel_loss=0.04023, linear_loss=0.04563]
[2020-05-12 13:06:53.379]  Step 160946  [4.047 sec/step, loss=0.08542, avg_loss=0.08702, mel_loss=0.03661, linear_loss=0.04882]
[2020-05-12 13:06:56.466]  Step 160947  [4.062 sec/step, loss=0.09437, avg_loss=0.08710, mel_loss=0.04157, linear_loss=0.05280]
[2020-05-12 13:06:57.619]  Step 160948  [3.997 sec/step, loss=0.07887, avg_loss=0.08693, mel_loss=0.03343, linear_loss=0.04544]
[2020-05-12 13:06:58.142]  Step 160949  [3.967 sec/step, loss=0.06737, avg_loss=0.08669, mel_loss=0.02925, linear_loss=0.03812]
[2020-05-12 13:07:00.312]  Step 160950  [3.970 sec/step, loss=0.08989, avg_loss=0.08673, mel_loss=0.03920, linear_loss=0.05070]
[2020-05-12 13:07:00.312]  Writing summary at step: 160950
[2020-05-12 13:07:08.148]  Saving checkpoint to: ./logs-tacotron/model.ckpt-160950
[2020-05-12 13:07:09.849]  Saving audio and alignment...
[2020-05-12 13:07:21.739]  Input: 상대로 하여금 내가 참 잘 경청해 주고 적극 공감해주는 한마디로 말이 잘 통하는 상대다 라는 생각을~__________________________________________
[2020-05-12 13:07:24.624]  Step 160951  [3.978 sec/step, loss=0.09085, avg_loss=0.08677, mel_loss=0.04002, linear_loss=0.05083]
[2020-05-12 13:07:26.206]  Step 160952  [3.977 sec/step, loss=0.08295, avg_loss=0.08674, mel_loss=0.03589, linear_loss=0.04706]
[2020-05-12 13:07:28.093]  Step 160953  [3.939 sec/step, loss=0.08554, avg_loss=0.08666, mel_loss=0.03680, linear_loss=0.04874]
[2020-05-12 13:07:28.850]  Step 160954  [3.934 sec/step, loss=0.06849, avg_loss=0.08656, mel_loss=0.02979, linear_loss=0.03870]
[2020-05-12 13:07:31.118]  Step 160955  [3.943 sec/step, loss=0.08716, avg_loss=0.08659, mel_loss=0.03811, linear_loss=0.04905]
[2020-05-12 13:07:35.381]  Step 160956  [3.975 sec/step, loss=0.09248, avg_loss=0.08673, mel_loss=0.04084, linear_loss=0.05163]
[2020-05-12 13:07:50.057]  Step 160957  [4.090 sec/step, loss=0.07406, avg_loss=0.08655, mel_loss=0.03449, linear_loss=0.03957]
[2020-05-12 13:07:52.182]  Step 160958  [4.082 sec/step, loss=0.08953, avg_loss=0.08652, mel_loss=0.03875, linear_loss=0.05078]
[2020-05-12 13:07:55.974]  Step 160959  [4.106 sec/step, loss=0.09439, avg_loss=0.08665, mel_loss=0.04168, linear_loss=0.05271]
[2020-05-12 13:07:57.336]  Step 160960  [4.109 sec/step, loss=0.08368, avg_loss=0.08670, mel_loss=0.03577, linear_loss=0.04791]
[2020-05-12 13:07:59.366]  Step 160961  [4.118 sec/step, loss=0.08856, avg_loss=0.08676, mel_loss=0.03856, linear_loss=0.05001]
[2020-05-12 13:08:06.461]  Step 160962  [4.148 sec/step, loss=0.09432, avg_loss=0.08676, mel_loss=0.04278, linear_loss=0.05154]
[2020-05-12 13:08:10.111]  Step 160963  [4.153 sec/step, loss=0.09409, avg_loss=0.08678, mel_loss=0.04185, linear_loss=0.05225]
[2020-05-12 13:08:11.892]  Step 160964  [4.145 sec/step, loss=0.08685, avg_loss=0.08675, mel_loss=0.03729, linear_loss=0.04956]
[2020-05-12 13:08:18.559]  Step 160965  [4.192 sec/step, loss=0.09293, avg_loss=0.08683, mel_loss=0.04192, linear_loss=0.05101]
[2020-05-12 13:08:23.508]  Step 160966  [4.224 sec/step, loss=0.09515, avg_loss=0.08691, mel_loss=0.04262, linear_loss=0.05253]
[2020-05-12 13:08:24.140]  Step 160967  [4.221 sec/step, loss=0.07518, avg_loss=0.08686, mel_loss=0.03233, linear_loss=0.04285]
[2020-05-12 13:08:25.068]  Step 160968  [4.208 sec/step, loss=0.08063, avg_loss=0.08678, mel_loss=0.03429, linear_loss=0.04634]
[2020-05-12 13:08:26.349]  Step 160969  [4.184 sec/step, loss=0.08352, avg_loss=0.08668, mel_loss=0.03598, linear_loss=0.04754]
[2020-05-12 13:08:30.861]  Step 160970  [4.224 sec/step, loss=0.09427, avg_loss=0.08692, mel_loss=0.04208, linear_loss=0.05219]
[2020-05-12 13:08:34.379]  Step 160971  [4.244 sec/step, loss=0.09084, avg_loss=0.08699, mel_loss=0.04001, linear_loss=0.05083]
[2020-05-12 13:08:37.757]  Step 160972  [4.224 sec/step, loss=0.09356, avg_loss=0.08698, mel_loss=0.04109, linear_loss=0.05247]
[2020-05-12 13:08:46.326]  Step 160973  [4.301 sec/step, loss=0.09589, avg_loss=0.08720, mel_loss=0.04389, linear_loss=0.05199]
[2020-05-12 13:08:47.562]  Step 160974  [4.168 sec/step, loss=0.08094, avg_loss=0.08729, mel_loss=0.03439, linear_loss=0.04655]
[2020-05-12 13:08:48.329]  Step 160975  [4.102 sec/step, loss=0.07611, avg_loss=0.08711, mel_loss=0.03211, linear_loss=0.04399]
[2020-05-12 13:08:50.838]  Step 160976  [4.109 sec/step, loss=0.08822, avg_loss=0.08714, mel_loss=0.03831, linear_loss=0.04991]
[2020-05-12 13:08:51.815]  Step 160977  [4.071 sec/step, loss=0.07865, avg_loss=0.08699, mel_loss=0.03297, linear_loss=0.04568]
[2020-05-12 13:08:53.431]  Step 160978  [4.063 sec/step, loss=0.08579, avg_loss=0.08696, mel_loss=0.03702, linear_loss=0.04877]
[2020-05-12 13:08:58.814]  Step 160979  [4.103 sec/step, loss=0.09320, avg_loss=0.08706, mel_loss=0.04173, linear_loss=0.05147]
[2020-05-12 13:08:59.870]  Step 160980  [4.057 sec/step, loss=0.07883, avg_loss=0.08689, mel_loss=0.03362, linear_loss=0.04521]
[2020-05-12 13:09:02.509]  Step 160981  [4.049 sec/step, loss=0.08986, avg_loss=0.08687, mel_loss=0.03937, linear_loss=0.05049]
[2020-05-12 13:09:05.473]  Step 160982  [4.071 sec/step, loss=0.09250, avg_loss=0.08704, mel_loss=0.04070, linear_loss=0.05180]
[2020-05-12 13:10:05.616]  Generated 32 batches of size 32 in 79.284 sec
[2020-05-12 13:10:08.569]  Step 160983  [4.672 sec/step, loss=0.09185, avg_loss=0.08706, mel_loss=0.04042, linear_loss=0.05143]
[2020-05-12 13:10:10.039]  Step 160984  [4.625 sec/step, loss=0.08272, avg_loss=0.08695, mel_loss=0.03558, linear_loss=0.04714]
[2020-05-12 13:10:15.216]  Step 160985  [4.638 sec/step, loss=0.09582, avg_loss=0.08697, mel_loss=0.04293, linear_loss=0.05289]
[2020-05-12 13:10:18.850]  Step 160986  [4.649 sec/step, loss=0.09572, avg_loss=0.08703, mel_loss=0.04267, linear_loss=0.05305]
[2020-05-12 13:10:23.486]  Step 160987  [4.686 sec/step, loss=0.09393, avg_loss=0.08722, mel_loss=0.04139, linear_loss=0.05254]
[2020-05-12 13:10:24.352]  Step 160988  [4.606 sec/step, loss=0.06974, avg_loss=0.08698, mel_loss=0.02972, linear_loss=0.04002]
[2020-05-12 13:10:25.387]  Step 160989  [4.596 sec/step, loss=0.07474, avg_loss=0.08684, mel_loss=0.03175, linear_loss=0.04299]
[2020-05-12 13:10:39.688]  Step 160990  [4.704 sec/step, loss=0.07188, avg_loss=0.08663, mel_loss=0.03360, linear_loss=0.03827]
[2020-05-12 13:10:41.475]  Step 160991  [4.028 sec/step, loss=0.08529, avg_loss=0.08662, mel_loss=0.03686, linear_loss=0.04843]
[2020-05-12 13:10:43.401]  Step 160992  [4.012 sec/step, loss=0.08846, avg_loss=0.08659, mel_loss=0.03798, linear_loss=0.05048]
[2020-05-12 13:10:45.454]  Step 160993  [4.008 sec/step, loss=0.08606, avg_loss=0.08656, mel_loss=0.03715, linear_loss=0.04891]
[2020-05-12 13:10:50.421]  Step 160994  [4.027 sec/step, loss=0.09472, avg_loss=0.08658, mel_loss=0.04239, linear_loss=0.05232]
[2020-05-12 13:10:52.574]  Step 160995  [4.038 sec/step, loss=0.09057, avg_loss=0.08670, mel_loss=0.03962, linear_loss=0.05095]
[2020-05-12 13:10:54.138]  Step 160996  [4.010 sec/step, loss=0.08382, avg_loss=0.08658, mel_loss=0.03604, linear_loss=0.04778]
[2020-05-12 13:10:55.354]  Step 160997  [4.008 sec/step, loss=0.08065, avg_loss=0.08657, mel_loss=0.03450, linear_loss=0.04615]
[2020-05-12 13:11:03.531]  Step 160998  [4.049 sec/step, loss=0.09242, avg_loss=0.08655, mel_loss=0.04195, linear_loss=0.05047]
[2020-05-12 13:11:06.196]  Step 160999  [4.047 sec/step, loss=0.09114, avg_loss=0.08657, mel_loss=0.04005, linear_loss=0.05109]
[2020-05-12 13:11:09.368]  Step 161000  [4.057 sec/step, loss=0.09267, avg_loss=0.08661, mel_loss=0.04080, linear_loss=0.05187]
[2020-05-12 13:11:09.368]  Writing summary at step: 161000
[2020-05-12 13:11:11.110]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161000
[2020-05-12 13:11:12.734]  Saving audio and alignment...
[2020-05-12 13:11:16.861]  Input: 온도에서 습도까지 조금 올리시고~_______________________
[2020-05-12 13:11:17.417]  Step 161001  [4.006 sec/step, loss=0.06809, avg_loss=0.08636, mel_loss=0.03029, linear_loss=0.03780]
[2020-05-12 13:11:18.821]  Step 161002  [4.000 sec/step, loss=0.08242, avg_loss=0.08632, mel_loss=0.03522, linear_loss=0.04720]
[2020-05-12 13:11:19.681]  Step 161003  [3.980 sec/step, loss=0.07550, avg_loss=0.08616, mel_loss=0.03206, linear_loss=0.04344]
[2020-05-12 13:11:23.326]  Step 161004  [3.996 sec/step, loss=0.09095, avg_loss=0.08620, mel_loss=0.03986, linear_loss=0.05109]
[2020-05-12 13:11:29.376]  Step 161005  [3.913 sec/step, loss=0.09436, avg_loss=0.08640, mel_loss=0.04252, linear_loss=0.05185]
[2020-05-12 13:11:36.313]  Step 161006  [3.948 sec/step, loss=0.09906, avg_loss=0.08646, mel_loss=0.04475, linear_loss=0.05431]
[2020-05-12 13:11:37.437]  Step 161007  [3.942 sec/step, loss=0.08279, avg_loss=0.08642, mel_loss=0.03511, linear_loss=0.04768]
[2020-05-12 13:11:41.633]  Step 161008  [3.957 sec/step, loss=0.09157, avg_loss=0.08645, mel_loss=0.04029, linear_loss=0.05128]
[2020-05-12 13:11:42.661]  Step 161009  [3.922 sec/step, loss=0.08028, avg_loss=0.08631, mel_loss=0.03398, linear_loss=0.04629]
[2020-05-12 13:11:46.881]  Step 161010  [3.927 sec/step, loss=0.09466, avg_loss=0.08631, mel_loss=0.04230, linear_loss=0.05237]
[2020-05-12 13:11:50.227]  Step 161011  [3.945 sec/step, loss=0.09270, avg_loss=0.08640, mel_loss=0.04115, linear_loss=0.05155]
[2020-05-12 13:11:52.646]  Step 161012  [3.959 sec/step, loss=0.08858, avg_loss=0.08651, mel_loss=0.03851, linear_loss=0.05007]
[2020-05-12 13:12:22.759]  Generated 32 batches of size 32 in 63.072 sec
[2020-05-12 13:12:24.560]  Step 161013  [4.267 sec/step, loss=0.08724, avg_loss=0.08661, mel_loss=0.03746, linear_loss=0.04977]
[2020-05-12 13:12:25.483]  Step 161014  [4.268 sec/step, loss=0.07708, avg_loss=0.08668, mel_loss=0.03253, linear_loss=0.04455]
[2020-05-12 13:12:26.713]  Step 161015  [4.194 sec/step, loss=0.08120, avg_loss=0.08656, mel_loss=0.03464, linear_loss=0.04656]
[2020-05-12 13:12:32.487]  Step 161016  [4.178 sec/step, loss=0.09455, avg_loss=0.08654, mel_loss=0.04263, linear_loss=0.05192]
[2020-05-12 13:12:40.126]  Step 161017  [4.191 sec/step, loss=0.09654, avg_loss=0.08658, mel_loss=0.04376, linear_loss=0.05278]
[2020-05-12 13:12:42.605]  Step 161018  [4.208 sec/step, loss=0.08863, avg_loss=0.08671, mel_loss=0.03849, linear_loss=0.05013]
[2020-05-12 13:12:44.628]  Step 161019  [4.215 sec/step, loss=0.08704, avg_loss=0.08676, mel_loss=0.03781, linear_loss=0.04923]
[2020-05-12 13:12:48.269]  Step 161020  [4.200 sec/step, loss=0.09243, avg_loss=0.08674, mel_loss=0.04084, linear_loss=0.05160]
[2020-05-12 13:12:50.615]  Step 161021  [4.038 sec/step, loss=0.08822, avg_loss=0.08668, mel_loss=0.03847, linear_loss=0.04975]
[2020-05-12 13:12:53.642]  Step 161022  [4.003 sec/step, loss=0.09163, avg_loss=0.08664, mel_loss=0.04036, linear_loss=0.05127]
[2020-05-12 13:12:54.415]  Step 161023  [3.984 sec/step, loss=0.07118, avg_loss=0.08644, mel_loss=0.03041, linear_loss=0.04078]
[2020-05-12 13:12:55.994]  Step 161024  [3.965 sec/step, loss=0.08433, avg_loss=0.08638, mel_loss=0.03622, linear_loss=0.04811]
[2020-05-12 13:12:58.697]  Step 161025  [3.956 sec/step, loss=0.08938, avg_loss=0.08636, mel_loss=0.03907, linear_loss=0.05031]
[2020-05-12 13:12:59.491]  Step 161026  [3.946 sec/step, loss=0.07538, avg_loss=0.08624, mel_loss=0.03177, linear_loss=0.04360]
[2020-05-12 13:13:00.457]  Step 161027  [3.934 sec/step, loss=0.08089, avg_loss=0.08617, mel_loss=0.03450, linear_loss=0.04639]
[2020-05-12 13:13:05.756]  Step 161028  [3.967 sec/step, loss=0.09344, avg_loss=0.08624, mel_loss=0.04176, linear_loss=0.05168]
[2020-05-12 13:13:08.609]  Step 161029  [3.980 sec/step, loss=0.09014, avg_loss=0.08629, mel_loss=0.03956, linear_loss=0.05059]
[2020-05-12 13:13:13.115]  Step 161030  [4.010 sec/step, loss=0.09435, avg_loss=0.08639, mel_loss=0.04218, linear_loss=0.05217]
[2020-05-12 13:13:14.519]  Step 161031  [4.011 sec/step, loss=0.08180, avg_loss=0.08639, mel_loss=0.03496, linear_loss=0.04684]
[2020-05-12 13:13:27.109]  Step 161032  [4.088 sec/step, loss=0.08449, avg_loss=0.08631, mel_loss=0.03918, linear_loss=0.04531]
[2020-05-12 13:13:29.022]  Step 161033  [4.098 sec/step, loss=0.08595, avg_loss=0.08645, mel_loss=0.03699, linear_loss=0.04896]
[2020-05-12 13:13:33.083]  Step 161034  [4.088 sec/step, loss=0.09272, avg_loss=0.08644, mel_loss=0.04119, linear_loss=0.05153]
[2020-05-12 13:13:36.472]  Step 161035  [4.063 sec/step, loss=0.09392, avg_loss=0.08641, mel_loss=0.04129, linear_loss=0.05263]
[2020-05-12 13:13:42.946]  Step 161036  [4.118 sec/step, loss=0.09420, avg_loss=0.08659, mel_loss=0.04251, linear_loss=0.05169]
[2020-05-12 13:13:44.583]  Step 161037  [4.124 sec/step, loss=0.08710, avg_loss=0.08665, mel_loss=0.03748, linear_loss=0.04962]
[2020-05-12 13:13:46.784]  Step 161038  [4.122 sec/step, loss=0.08815, avg_loss=0.08664, mel_loss=0.03822, linear_loss=0.04993]
[2020-05-12 13:13:50.296]  Step 161039  [4.140 sec/step, loss=0.09007, avg_loss=0.08667, mel_loss=0.03983, linear_loss=0.05024]
[2020-05-12 13:13:59.309]  Step 161040  [4.188 sec/step, loss=0.09339, avg_loss=0.08669, mel_loss=0.04276, linear_loss=0.05063]
[2020-05-12 13:14:00.650]  Step 161041  [4.174 sec/step, loss=0.08382, avg_loss=0.08666, mel_loss=0.03594, linear_loss=0.04788]
[2020-05-12 13:14:01.215]  Step 161042  [4.172 sec/step, loss=0.07106, avg_loss=0.08665, mel_loss=0.03090, linear_loss=0.04016]
[2020-05-12 13:14:02.321]  Step 161043  [4.151 sec/step, loss=0.08130, avg_loss=0.08655, mel_loss=0.03442, linear_loss=0.04688]
[2020-05-12 13:14:06.164]  Step 161044  [4.180 sec/step, loss=0.09385, avg_loss=0.08669, mel_loss=0.04143, linear_loss=0.05241]
[2020-05-12 13:14:29.382]  Generated 32 batches of size 32 in 52.906 sec
[2020-05-12 13:14:30.473]  Step 161045  [4.297 sec/step, loss=0.07650, avg_loss=0.08660, mel_loss=0.03265, linear_loss=0.04385]
[2020-05-12 13:14:33.645]  Step 161046  [4.313 sec/step, loss=0.09239, avg_loss=0.08667, mel_loss=0.04085, linear_loss=0.05154]
[2020-05-12 13:14:37.132]  Step 161047  [4.317 sec/step, loss=0.09119, avg_loss=0.08664, mel_loss=0.04024, linear_loss=0.05095]
[2020-05-12 13:14:40.775]  Step 161048  [4.342 sec/step, loss=0.09362, avg_loss=0.08679, mel_loss=0.04150, linear_loss=0.05212]
[2020-05-12 13:14:42.989]  Step 161049  [4.359 sec/step, loss=0.08630, avg_loss=0.08698, mel_loss=0.03754, linear_loss=0.04877]
[2020-05-12 13:14:44.767]  Step 161050  [4.355 sec/step, loss=0.08465, avg_loss=0.08692, mel_loss=0.03636, linear_loss=0.04828]
[2020-05-12 13:14:44.768]  Writing summary at step: 161050
[2020-05-12 13:14:57.966]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161050
[2020-05-12 13:14:59.603]  Saving audio and alignment...
[2020-05-12 13:15:06.616]  Input: 자 계속해서 전주 엠비씨에서요 최종 합격한 학생에게 질문 주셨대요~_______________________
[2020-05-12 13:15:09.559]  Step 161051  [4.356 sec/step, loss=0.08852, avg_loss=0.08690, mel_loss=0.03881, linear_loss=0.04971]
[2020-05-12 13:15:10.791]  Step 161052  [4.352 sec/step, loss=0.07912, avg_loss=0.08686, mel_loss=0.03363, linear_loss=0.04549]
[2020-05-12 13:15:11.625]  Step 161053  [4.342 sec/step, loss=0.06812, avg_loss=0.08669, mel_loss=0.02972, linear_loss=0.03840]
[2020-05-12 13:15:20.834]  Step 161054  [4.426 sec/step, loss=0.09431, avg_loss=0.08695, mel_loss=0.04296, linear_loss=0.05135]
[2020-05-12 13:15:24.958]  Step 161055  [4.445 sec/step, loss=0.09295, avg_loss=0.08700, mel_loss=0.04106, linear_loss=0.05189]
[2020-05-12 13:15:26.377]  Step 161056  [4.416 sec/step, loss=0.08107, avg_loss=0.08689, mel_loss=0.03488, linear_loss=0.04619]
[2020-05-12 13:15:32.688]  Step 161057  [4.333 sec/step, loss=0.09408, avg_loss=0.08709, mel_loss=0.04249, linear_loss=0.05159]
[2020-05-12 13:15:33.517]  Step 161058  [4.320 sec/step, loss=0.07184, avg_loss=0.08691, mel_loss=0.03055, linear_loss=0.04129]
[2020-05-12 13:15:38.846]  Step 161059  [4.335 sec/step, loss=0.09454, avg_loss=0.08691, mel_loss=0.04244, linear_loss=0.05210]
[2020-05-12 13:15:39.839]  Step 161060  [4.331 sec/step, loss=0.07930, avg_loss=0.08687, mel_loss=0.03321, linear_loss=0.04609]
[2020-05-12 13:15:41.853]  Step 161061  [4.331 sec/step, loss=0.08720, avg_loss=0.08686, mel_loss=0.03782, linear_loss=0.04938]
[2020-05-12 13:15:49.357]  Step 161062  [4.335 sec/step, loss=0.09493, avg_loss=0.08686, mel_loss=0.04306, linear_loss=0.05186]
[2020-05-12 13:15:51.306]  Step 161063  [4.318 sec/step, loss=0.08700, avg_loss=0.08679, mel_loss=0.03760, linear_loss=0.04941]
[2020-05-12 13:15:53.671]  Step 161064  [4.324 sec/step, loss=0.09094, avg_loss=0.08683, mel_loss=0.03978, linear_loss=0.05116]
[2020-05-12 13:15:56.104]  Step 161065  [4.282 sec/step, loss=0.08883, avg_loss=0.08679, mel_loss=0.03856, linear_loss=0.05027]
[2020-05-12 13:15:57.462]  Step 161066  [4.246 sec/step, loss=0.08040, avg_loss=0.08664, mel_loss=0.03459, linear_loss=0.04581]
[2020-05-12 13:15:58.248]  Step 161067  [4.247 sec/step, loss=0.07076, avg_loss=0.08660, mel_loss=0.03017, linear_loss=0.04060]
[2020-05-12 13:16:01.173]  Step 161068  [4.267 sec/step, loss=0.08881, avg_loss=0.08668, mel_loss=0.03885, linear_loss=0.04995]
[2020-05-12 13:16:02.820]  Step 161069  [4.271 sec/step, loss=0.08579, avg_loss=0.08670, mel_loss=0.03710, linear_loss=0.04869]
[2020-05-12 13:16:07.084]  Step 161070  [4.269 sec/step, loss=0.09386, avg_loss=0.08670, mel_loss=0.04192, linear_loss=0.05194]
[2020-05-12 13:16:12.706]  Step 161071  [4.290 sec/step, loss=0.09539, avg_loss=0.08675, mel_loss=0.04284, linear_loss=0.05255]
[2020-05-12 13:16:13.975]  Step 161072  [4.269 sec/step, loss=0.08144, avg_loss=0.08662, mel_loss=0.03490, linear_loss=0.04655]
[2020-05-12 13:16:17.268]  Step 161073  [4.216 sec/step, loss=0.09423, avg_loss=0.08661, mel_loss=0.04156, linear_loss=0.05267]
[2020-05-12 13:16:18.921]  Step 161074  [4.220 sec/step, loss=0.08580, avg_loss=0.08666, mel_loss=0.03692, linear_loss=0.04888]
[2020-05-12 13:16:27.332]  Generated 32 batches of size 32 in 31.224 sec
[2020-05-12 13:16:27.888]  Step 161075  [4.302 sec/step, loss=0.07489, avg_loss=0.08664, mel_loss=0.03275, linear_loss=0.04214]
[2020-05-12 13:16:30.967]  Step 161076  [4.308 sec/step, loss=0.09152, avg_loss=0.08668, mel_loss=0.04013, linear_loss=0.05139]
[2020-05-12 13:16:32.446]  Step 161077  [4.313 sec/step, loss=0.08306, avg_loss=0.08672, mel_loss=0.03584, linear_loss=0.04722]
[2020-05-12 13:16:36.933]  Step 161078  [4.341 sec/step, loss=0.09276, avg_loss=0.08679, mel_loss=0.04137, linear_loss=0.05139]
[2020-05-12 13:16:40.648]  Step 161079  [4.325 sec/step, loss=0.09471, avg_loss=0.08681, mel_loss=0.04177, linear_loss=0.05294]
[2020-05-12 13:16:41.878]  Step 161080  [4.326 sec/step, loss=0.08037, avg_loss=0.08682, mel_loss=0.03452, linear_loss=0.04585]
[2020-05-12 13:16:42.935]  Step 161081  [4.311 sec/step, loss=0.08076, avg_loss=0.08673, mel_loss=0.03452, linear_loss=0.04624]
[2020-05-12 13:16:44.921]  Step 161082  [4.301 sec/step, loss=0.08924, avg_loss=0.08670, mel_loss=0.03865, linear_loss=0.05059]
[2020-05-12 13:16:47.638]  Step 161083  [3.697 sec/step, loss=0.09061, avg_loss=0.08669, mel_loss=0.03973, linear_loss=0.05088]
[2020-05-12 13:16:49.179]  Step 161084  [3.698 sec/step, loss=0.08378, avg_loss=0.08670, mel_loss=0.03595, linear_loss=0.04783]
[2020-05-12 13:16:53.954]  Step 161085  [3.694 sec/step, loss=0.09424, avg_loss=0.08668, mel_loss=0.04187, linear_loss=0.05237]
[2020-05-12 13:16:56.113]  Step 161086  [3.679 sec/step, loss=0.09009, avg_loss=0.08662, mel_loss=0.03923, linear_loss=0.05086]
[2020-05-12 13:17:01.657]  Step 161087  [3.688 sec/step, loss=0.09388, avg_loss=0.08662, mel_loss=0.04228, linear_loss=0.05160]
[2020-05-12 13:17:02.634]  Step 161088  [3.689 sec/step, loss=0.07803, avg_loss=0.08671, mel_loss=0.03307, linear_loss=0.04496]
[2020-05-12 13:17:03.484]  Step 161089  [3.687 sec/step, loss=0.07479, avg_loss=0.08671, mel_loss=0.03140, linear_loss=0.04339]
[2020-05-12 13:17:07.728]  Step 161090  [3.587 sec/step, loss=0.09279, avg_loss=0.08692, mel_loss=0.04111, linear_loss=0.05168]
[2020-05-12 13:17:14.407]  Step 161091  [3.636 sec/step, loss=0.09362, avg_loss=0.08700, mel_loss=0.04211, linear_loss=0.05151]
[2020-05-12 13:17:28.584]  Step 161092  [3.758 sec/step, loss=0.07501, avg_loss=0.08686, mel_loss=0.03526, linear_loss=0.03975]
[2020-05-12 13:17:36.915]  Step 161093  [3.821 sec/step, loss=0.09443, avg_loss=0.08695, mel_loss=0.04311, linear_loss=0.05132]
[2020-05-12 13:17:37.561]  Step 161094  [3.778 sec/step, loss=0.07031, avg_loss=0.08670, mel_loss=0.03014, linear_loss=0.04018]
[2020-05-12 13:17:38.322]  Step 161095  [3.764 sec/step, loss=0.07540, avg_loss=0.08655, mel_loss=0.03200, linear_loss=0.04339]
[2020-05-12 13:17:39.684]  Step 161096  [3.762 sec/step, loss=0.08596, avg_loss=0.08657, mel_loss=0.03672, linear_loss=0.04924]
[2020-05-12 13:17:41.691]  Step 161097  [3.770 sec/step, loss=0.08738, avg_loss=0.08664, mel_loss=0.03788, linear_loss=0.04949]
[2020-05-12 13:17:44.148]  Step 161098  [3.713 sec/step, loss=0.08896, avg_loss=0.08661, mel_loss=0.03849, linear_loss=0.05047]
[2020-05-12 13:17:46.419]  Step 161099  [3.709 sec/step, loss=0.08584, avg_loss=0.08655, mel_loss=0.03716, linear_loss=0.04868]
[2020-05-12 13:17:48.122]  Step 161100  [3.694 sec/step, loss=0.08170, avg_loss=0.08644, mel_loss=0.03428, linear_loss=0.04741]
[2020-05-12 13:17:48.122]  Writing summary at step: 161100
[2020-05-12 13:17:53.265]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161100
[2020-05-12 13:17:54.980]  Saving audio and alignment...
[2020-05-12 13:17:58.120]  Input: 폭죽처럼 터지는 날도 있어요~__________
[2020-05-12 13:18:00.899]  Step 161101  [3.716 sec/step, loss=0.08871, avg_loss=0.08665, mel_loss=0.03859, linear_loss=0.05013]
[2020-05-12 13:18:04.469]  Step 161102  [3.738 sec/step, loss=0.09009, avg_loss=0.08673, mel_loss=0.03978, linear_loss=0.05031]
[2020-05-12 13:18:12.275]  Step 161103  [3.807 sec/step, loss=0.09572, avg_loss=0.08693, mel_loss=0.04361, linear_loss=0.05211]
[2020-05-12 13:18:15.796]  Step 161104  [3.806 sec/step, loss=0.09475, avg_loss=0.08697, mel_loss=0.04194, linear_loss=0.05282]
[2020-05-12 13:18:58.271]  Generated 32 batches of size 32 in 76.575 sec
[2020-05-12 13:19:04.746]  Step 161105  [4.235 sec/step, loss=0.09494, avg_loss=0.08697, mel_loss=0.04277, linear_loss=0.05217]
[2020-05-12 13:19:06.366]  Step 161106  [4.182 sec/step, loss=0.08369, avg_loss=0.08682, mel_loss=0.03617, linear_loss=0.04752]
[2020-05-12 13:19:09.895]  Step 161107  [4.206 sec/step, loss=0.09151, avg_loss=0.08691, mel_loss=0.04046, linear_loss=0.05105]
[2020-05-12 13:19:10.772]  Step 161108  [4.173 sec/step, loss=0.07011, avg_loss=0.08669, mel_loss=0.03003, linear_loss=0.04008]
[2020-05-12 13:19:13.146]  Step 161109  [4.186 sec/step, loss=0.08847, avg_loss=0.08677, mel_loss=0.03856, linear_loss=0.04990]
[2020-05-12 13:19:14.258]  Step 161110  [4.155 sec/step, loss=0.08148, avg_loss=0.08664, mel_loss=0.03461, linear_loss=0.04687]
[2020-05-12 13:19:17.651]  Step 161111  [4.156 sec/step, loss=0.09263, avg_loss=0.08664, mel_loss=0.04079, linear_loss=0.05184]
[2020-05-12 13:19:21.828]  Step 161112  [4.173 sec/step, loss=0.09174, avg_loss=0.08667, mel_loss=0.04094, linear_loss=0.05080]
[2020-05-12 13:19:23.858]  Step 161113  [3.874 sec/step, loss=0.08565, avg_loss=0.08666, mel_loss=0.03692, linear_loss=0.04873]
[2020-05-12 13:19:25.252]  Step 161114  [3.879 sec/step, loss=0.08499, avg_loss=0.08674, mel_loss=0.03640, linear_loss=0.04859]
[2020-05-12 13:19:26.953]  Step 161115  [3.884 sec/step, loss=0.08554, avg_loss=0.08678, mel_loss=0.03670, linear_loss=0.04884]
[2020-05-12 13:19:39.073]  Step 161116  [3.947 sec/step, loss=0.08608, avg_loss=0.08669, mel_loss=0.04017, linear_loss=0.04591]
[2020-05-12 13:19:46.448]  Step 161117  [3.944 sec/step, loss=0.09456, avg_loss=0.08667, mel_loss=0.04284, linear_loss=0.05173]
[2020-05-12 13:19:50.486]  Step 161118  [3.960 sec/step, loss=0.09237, avg_loss=0.08671, mel_loss=0.04073, linear_loss=0.05164]
[2020-05-12 13:19:53.234]  Step 161119  [3.967 sec/step, loss=0.09012, avg_loss=0.08674, mel_loss=0.03950, linear_loss=0.05062]
[2020-05-12 13:19:54.541]  Step 161120  [3.944 sec/step, loss=0.08422, avg_loss=0.08666, mel_loss=0.03582, linear_loss=0.04840]
[2020-05-12 13:19:56.460]  Step 161121  [3.940 sec/step, loss=0.08716, avg_loss=0.08665, mel_loss=0.03740, linear_loss=0.04977]
[2020-05-12 13:19:57.011]  Step 161122  [3.915 sec/step, loss=0.06746, avg_loss=0.08641, mel_loss=0.02909, linear_loss=0.03837]
[2020-05-12 13:19:59.867]  Step 161123  [3.936 sec/step, loss=0.09167, avg_loss=0.08661, mel_loss=0.04043, linear_loss=0.05123]
[2020-05-12 13:20:03.499]  Step 161124  [3.956 sec/step, loss=0.09433, avg_loss=0.08671, mel_loss=0.04181, linear_loss=0.05253]
[2020-05-12 13:20:04.515]  Step 161125  [3.939 sec/step, loss=0.07924, avg_loss=0.08661, mel_loss=0.03361, linear_loss=0.04563]
[2020-05-12 13:20:05.313]  Step 161126  [3.940 sec/step, loss=0.07475, avg_loss=0.08661, mel_loss=0.03138, linear_loss=0.04337]
[2020-05-12 13:20:09.940]  Step 161127  [3.976 sec/step, loss=0.09534, avg_loss=0.08675, mel_loss=0.04232, linear_loss=0.05302]
[2020-05-12 13:20:18.901]  Step 161128  [4.013 sec/step, loss=0.09349, avg_loss=0.08675, mel_loss=0.04280, linear_loss=0.05070]
[2020-05-12 13:20:19.988]  Step 161129  [3.995 sec/step, loss=0.07719, avg_loss=0.08662, mel_loss=0.03251, linear_loss=0.04468]
[2020-05-12 13:20:22.719]  Step 161130  [3.977 sec/step, loss=0.08868, avg_loss=0.08656, mel_loss=0.03837, linear_loss=0.05031]
[2020-05-12 13:20:26.109]  Step 161131  [3.997 sec/step, loss=0.09253, avg_loss=0.08667, mel_loss=0.04092, linear_loss=0.05161]
[2020-05-12 13:20:31.882]  Step 161132  [3.929 sec/step, loss=0.09503, avg_loss=0.08678, mel_loss=0.04266, linear_loss=0.05237]
[2020-05-12 13:20:33.134]  Step 161133  [3.922 sec/step, loss=0.08024, avg_loss=0.08672, mel_loss=0.03438, linear_loss=0.04586]
[2020-05-12 13:20:38.375]  Step 161134  [3.934 sec/step, loss=0.09289, avg_loss=0.08672, mel_loss=0.04150, linear_loss=0.05139]
[2020-05-12 13:20:40.510]  Step 161135  [3.922 sec/step, loss=0.08722, avg_loss=0.08666, mel_loss=0.03801, linear_loss=0.04921]
[2020-05-12 13:20:42.265]  Step 161136  [3.874 sec/step, loss=0.08537, avg_loss=0.08657, mel_loss=0.03636, linear_loss=0.04902]
[2020-05-12 13:20:44.864]  Generated 32 batches of size 32 in 34.918 sec
[2020-05-12 13:20:47.358]  Step 161137  [3.909 sec/step, loss=0.08787, avg_loss=0.08657, mel_loss=0.03816, linear_loss=0.04972]
[2020-05-12 13:20:48.910]  Step 161138  [3.903 sec/step, loss=0.08593, avg_loss=0.08655, mel_loss=0.03709, linear_loss=0.04884]
[2020-05-12 13:20:51.640]  Step 161139  [3.895 sec/step, loss=0.08913, avg_loss=0.08654, mel_loss=0.03954, linear_loss=0.04959]
[2020-05-12 13:20:52.617]  Step 161140  [3.814 sec/step, loss=0.07919, avg_loss=0.08640, mel_loss=0.03380, linear_loss=0.04539]
[2020-05-12 13:20:56.983]  Step 161141  [3.845 sec/step, loss=0.09420, avg_loss=0.08650, mel_loss=0.04186, linear_loss=0.05233]
[2020-05-12 13:21:01.051]  Step 161142  [3.880 sec/step, loss=0.09140, avg_loss=0.08671, mel_loss=0.04030, linear_loss=0.05110]
[2020-05-12 13:21:04.043]  Step 161143  [3.899 sec/step, loss=0.09050, avg_loss=0.08680, mel_loss=0.03961, linear_loss=0.05089]
[2020-05-12 13:21:05.375]  Step 161144  [3.873 sec/step, loss=0.08210, avg_loss=0.08668, mel_loss=0.03552, linear_loss=0.04658]
[2020-05-12 13:21:07.304]  Step 161145  [3.650 sec/step, loss=0.08571, avg_loss=0.08677, mel_loss=0.03698, linear_loss=0.04873]
[2020-05-12 13:21:08.263]  Step 161146  [3.627 sec/step, loss=0.08020, avg_loss=0.08665, mel_loss=0.03343, linear_loss=0.04677]
[2020-05-12 13:21:08.824]  Step 161147  [3.598 sec/step, loss=0.06605, avg_loss=0.08640, mel_loss=0.02849, linear_loss=0.03756]
[2020-05-12 13:21:09.925]  Step 161148  [3.573 sec/step, loss=0.07937, avg_loss=0.08626, mel_loss=0.03371, linear_loss=0.04566]
[2020-05-12 13:21:15.495]  Step 161149  [3.606 sec/step, loss=0.09465, avg_loss=0.08634, mel_loss=0.04256, linear_loss=0.05209]
[2020-05-12 13:21:16.708]  Step 161150  [3.601 sec/step, loss=0.08090, avg_loss=0.08630, mel_loss=0.03429, linear_loss=0.04661]
[2020-05-12 13:21:16.708]  Writing summary at step: 161150
[2020-05-12 13:21:20.091]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161150
[2020-05-12 13:21:21.684]  Saving audio and alignment...
[2020-05-12 13:21:25.180]  Input: 어어 반대말인 상승 역시~_________________
[2020-05-12 13:21:28.618]  Step 161151  [3.606 sec/step, loss=0.09088, avg_loss=0.08633, mel_loss=0.04013, linear_loss=0.05075]
[2020-05-12 13:21:42.077]  Step 161152  [3.728 sec/step, loss=0.08110, avg_loss=0.08635, mel_loss=0.03787, linear_loss=0.04323]
[2020-05-12 13:21:46.812]  Step 161153  [3.767 sec/step, loss=0.09366, avg_loss=0.08660, mel_loss=0.04169, linear_loss=0.05197]
[2020-05-12 13:21:54.508]  Step 161154  [3.752 sec/step, loss=0.09548, avg_loss=0.08662, mel_loss=0.04328, linear_loss=0.05220]
[2020-05-12 13:21:55.148]  Step 161155  [3.717 sec/step, loss=0.07252, avg_loss=0.08641, mel_loss=0.03081, linear_loss=0.04171]
[2020-05-12 13:21:55.936]  Step 161156  [3.711 sec/step, loss=0.07141, avg_loss=0.08631, mel_loss=0.03030, linear_loss=0.04112]
[2020-05-12 13:21:59.669]  Step 161157  [3.685 sec/step, loss=0.09425, avg_loss=0.08632, mel_loss=0.04183, linear_loss=0.05242]
[2020-05-12 13:22:01.855]  Step 161158  [3.698 sec/step, loss=0.08925, avg_loss=0.08649, mel_loss=0.03872, linear_loss=0.05053]
[2020-05-12 13:22:03.660]  Step 161159  [3.663 sec/step, loss=0.08587, avg_loss=0.08640, mel_loss=0.03696, linear_loss=0.04891]
[2020-05-12 13:22:05.066]  Step 161160  [3.667 sec/step, loss=0.08177, avg_loss=0.08643, mel_loss=0.03517, linear_loss=0.04660]
[2020-05-12 13:22:07.372]  Step 161161  [3.670 sec/step, loss=0.08753, avg_loss=0.08643, mel_loss=0.03790, linear_loss=0.04962]
[2020-05-12 13:22:10.531]  Step 161162  [3.627 sec/step, loss=0.09399, avg_loss=0.08642, mel_loss=0.04157, linear_loss=0.05242]
[2020-05-12 13:22:15.930]  Step 161163  [3.661 sec/step, loss=0.09522, avg_loss=0.08650, mel_loss=0.04264, linear_loss=0.05258]
[2020-05-12 13:22:24.523]  Step 161164  [3.724 sec/step, loss=0.09504, avg_loss=0.08655, mel_loss=0.04353, linear_loss=0.05151]
[2020-05-12 13:22:31.523]  Step 161165  [3.769 sec/step, loss=0.09496, avg_loss=0.08661, mel_loss=0.04302, linear_loss=0.05194]
[2020-05-12 13:22:33.217]  Step 161166  [3.773 sec/step, loss=0.08717, avg_loss=0.08667, mel_loss=0.03747, linear_loss=0.04971]
[2020-05-12 13:22:53.401]  Generated 32 batches of size 32 in 53.728 sec
[2020-05-12 13:22:54.291]  Step 161167  [3.975 sec/step, loss=0.06852, avg_loss=0.08665, mel_loss=0.02906, linear_loss=0.03946]
[2020-05-12 13:22:55.725]  Step 161168  [3.961 sec/step, loss=0.08476, avg_loss=0.08661, mel_loss=0.03648, linear_loss=0.04828]
[2020-05-12 13:22:59.884]  Step 161169  [3.986 sec/step, loss=0.09284, avg_loss=0.08668, mel_loss=0.04120, linear_loss=0.05164]
[2020-05-12 13:23:12.991]  Step 161170  [4.074 sec/step, loss=0.07816, avg_loss=0.08652, mel_loss=0.03601, linear_loss=0.04215]
[2020-05-12 13:23:13.801]  Step 161171  [4.026 sec/step, loss=0.07664, avg_loss=0.08634, mel_loss=0.03236, linear_loss=0.04428]
[2020-05-12 13:23:21.970]  Step 161172  [4.095 sec/step, loss=0.09124, avg_loss=0.08644, mel_loss=0.04146, linear_loss=0.04977]
[2020-05-12 13:23:29.369]  Step 161173  [4.136 sec/step, loss=0.09492, avg_loss=0.08644, mel_loss=0.04293, linear_loss=0.05199]
[2020-05-12 13:23:34.250]  Step 161174  [4.168 sec/step, loss=0.09270, avg_loss=0.08651, mel_loss=0.04133, linear_loss=0.05137]
[2020-05-12 13:23:35.449]  Step 161175  [4.091 sec/step, loss=0.08306, avg_loss=0.08659, mel_loss=0.03554, linear_loss=0.04751]
[2020-05-12 13:23:37.933]  Step 161176  [4.085 sec/step, loss=0.08808, avg_loss=0.08656, mel_loss=0.03833, linear_loss=0.04974]
[2020-05-12 13:23:41.301]  Step 161177  [4.104 sec/step, loss=0.09228, avg_loss=0.08665, mel_loss=0.04060, linear_loss=0.05168]
[2020-05-12 13:23:43.255]  Step 161178  [4.078 sec/step, loss=0.08878, avg_loss=0.08661, mel_loss=0.03870, linear_loss=0.05008]
[2020-05-12 13:23:48.729]  Step 161179  [4.096 sec/step, loss=0.09454, avg_loss=0.08661, mel_loss=0.04229, linear_loss=0.05224]
[2020-05-12 13:23:52.430]  Step 161180  [4.121 sec/step, loss=0.09377, avg_loss=0.08674, mel_loss=0.04145, linear_loss=0.05232]
[2020-05-12 13:23:54.185]  Step 161181  [4.128 sec/step, loss=0.08696, avg_loss=0.08680, mel_loss=0.03705, linear_loss=0.04990]
[2020-05-12 13:23:56.313]  Step 161182  [4.129 sec/step, loss=0.08978, avg_loss=0.08681, mel_loss=0.03900, linear_loss=0.05078]
[2020-05-12 13:23:57.256]  Step 161183  [4.111 sec/step, loss=0.07533, avg_loss=0.08666, mel_loss=0.03182, linear_loss=0.04351]
[2020-05-12 13:24:00.709]  Step 161184  [4.130 sec/step, loss=0.09106, avg_loss=0.08673, mel_loss=0.04046, linear_loss=0.05061]
[2020-05-12 13:24:02.413]  Step 161185  [4.100 sec/step, loss=0.08447, avg_loss=0.08663, mel_loss=0.03679, linear_loss=0.04768]
[2020-05-12 13:24:06.823]  Step 161186  [4.122 sec/step, loss=0.09498, avg_loss=0.08668, mel_loss=0.04223, linear_loss=0.05275]
[2020-05-12 13:24:09.717]  Step 161187  [4.096 sec/step, loss=0.09021, avg_loss=0.08665, mel_loss=0.03942, linear_loss=0.05079]
[2020-05-12 13:24:11.003]  Step 161188  [4.099 sec/step, loss=0.08338, avg_loss=0.08670, mel_loss=0.03553, linear_loss=0.04785]
[2020-05-12 13:24:11.773]  Step 161189  [4.098 sec/step, loss=0.06962, avg_loss=0.08665, mel_loss=0.03050, linear_loss=0.03912]
[2020-05-12 13:24:14.772]  Step 161190  [4.085 sec/step, loss=0.09094, avg_loss=0.08663, mel_loss=0.03987, linear_loss=0.05107]
[2020-05-12 13:24:18.392]  Step 161191  [4.055 sec/step, loss=0.09434, avg_loss=0.08664, mel_loss=0.04173, linear_loss=0.05261]
[2020-05-12 13:24:19.947]  Step 161192  [3.929 sec/step, loss=0.08290, avg_loss=0.08671, mel_loss=0.03558, linear_loss=0.04732]
[2020-05-12 13:24:21.005]  Step 161193  [3.856 sec/step, loss=0.07786, avg_loss=0.08655, mel_loss=0.03312, linear_loss=0.04473]
[2020-05-12 13:24:22.936]  Step 161194  [3.869 sec/step, loss=0.08756, avg_loss=0.08672, mel_loss=0.03786, linear_loss=0.04970]
[2020-05-12 13:24:25.655]  Step 161195  [3.888 sec/step, loss=0.08905, avg_loss=0.08686, mel_loss=0.03881, linear_loss=0.05023]
[2020-05-12 13:24:25.978]  Generated 32 batches of size 32 in 14.200 sec
[2020-05-12 13:24:26.789]  Step 161196  [3.886 sec/step, loss=0.07845, avg_loss=0.08678, mel_loss=0.03315, linear_loss=0.04530]
[2020-05-12 13:24:29.183]  Step 161197  [3.890 sec/step, loss=0.08861, avg_loss=0.08679, mel_loss=0.03890, linear_loss=0.04971]
[2020-05-12 13:24:35.249]  Step 161198  [3.926 sec/step, loss=0.09316, avg_loss=0.08684, mel_loss=0.04208, linear_loss=0.05109]
[2020-05-12 13:24:44.015]  Step 161199  [3.991 sec/step, loss=0.09365, avg_loss=0.08692, mel_loss=0.04264, linear_loss=0.05101]
[2020-05-12 13:24:44.576]  Step 161200  [3.980 sec/step, loss=0.06773, avg_loss=0.08678, mel_loss=0.02971, linear_loss=0.03801]
[2020-05-12 13:24:44.576]  Writing summary at step: 161200
[2020-05-12 13:24:45.685]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161200
[2020-05-12 13:24:47.374]  Saving audio and alignment...
[2020-05-12 13:24:49.418]  Input: 두 가지가 있는데요~______
[2020-05-12 13:24:51.156]  Step 161201  [3.969 sec/step, loss=0.08609, avg_loss=0.08675, mel_loss=0.03707, linear_loss=0.04903]
[2020-05-12 13:24:51.917]  Step 161202  [3.941 sec/step, loss=0.07707, avg_loss=0.08662, mel_loss=0.03235, linear_loss=0.04472]
[2020-05-12 13:24:56.020]  Step 161203  [3.904 sec/step, loss=0.09537, avg_loss=0.08662, mel_loss=0.04257, linear_loss=0.05280]
[2020-05-12 13:25:01.375]  Step 161204  [3.922 sec/step, loss=0.09360, avg_loss=0.08660, mel_loss=0.04227, linear_loss=0.05133]
[2020-05-12 13:25:08.811]  Step 161205  [3.507 sec/step, loss=0.09553, avg_loss=0.08661, mel_loss=0.04316, linear_loss=0.05238]
[2020-05-12 13:25:10.202]  Step 161206  [3.505 sec/step, loss=0.08304, avg_loss=0.08660, mel_loss=0.03573, linear_loss=0.04731]
[2020-05-12 13:25:12.718]  Step 161207  [3.495 sec/step, loss=0.08865, avg_loss=0.08657, mel_loss=0.03838, linear_loss=0.05027]
[2020-05-12 13:25:15.876]  Step 161208  [3.518 sec/step, loss=0.09320, avg_loss=0.08681, mel_loss=0.04098, linear_loss=0.05222]
[2020-05-12 13:25:18.037]  Step 161209  [3.516 sec/step, loss=0.08639, avg_loss=0.08678, mel_loss=0.03722, linear_loss=0.04917]
[2020-05-12 13:25:20.432]  Step 161210  [3.528 sec/step, loss=0.08770, avg_loss=0.08685, mel_loss=0.03818, linear_loss=0.04953]
[2020-05-12 13:25:23.916]  Step 161211  [3.529 sec/step, loss=0.09153, avg_loss=0.08684, mel_loss=0.04038, linear_loss=0.05115]
[2020-05-12 13:25:25.517]  Step 161212  [3.504 sec/step, loss=0.08314, avg_loss=0.08675, mel_loss=0.03597, linear_loss=0.04717]
[2020-05-12 13:25:40.318]  Step 161213  [3.631 sec/step, loss=0.07517, avg_loss=0.08665, mel_loss=0.03513, linear_loss=0.04004]
[2020-05-12 13:25:41.956]  Step 161214  [3.634 sec/step, loss=0.08649, avg_loss=0.08666, mel_loss=0.03732, linear_loss=0.04916]
[2020-05-12 13:25:45.468]  Step 161215  [3.652 sec/step, loss=0.09214, avg_loss=0.08673, mel_loss=0.04076, linear_loss=0.05138]
[2020-05-12 13:25:50.293]  Step 161216  [3.579 sec/step, loss=0.09376, avg_loss=0.08680, mel_loss=0.04156, linear_loss=0.05220]
[2020-05-12 13:25:52.223]  Step 161217  [3.524 sec/step, loss=0.08479, avg_loss=0.08671, mel_loss=0.03634, linear_loss=0.04845]
[2020-05-12 13:25:54.237]  Step 161218  [3.504 sec/step, loss=0.08779, avg_loss=0.08666, mel_loss=0.03818, linear_loss=0.04961]
[2020-05-12 13:25:57.109]  Step 161219  [3.505 sec/step, loss=0.09028, avg_loss=0.08666, mel_loss=0.03967, linear_loss=0.05062]
[2020-05-12 13:26:02.935]  Step 161220  [3.551 sec/step, loss=0.09457, avg_loss=0.08676, mel_loss=0.04251, linear_loss=0.05206]
[2020-05-12 13:26:07.189]  Step 161221  [3.574 sec/step, loss=0.09217, avg_loss=0.08681, mel_loss=0.04081, linear_loss=0.05136]
[2020-05-12 13:26:07.954]  Step 161222  [3.576 sec/step, loss=0.07399, avg_loss=0.08688, mel_loss=0.03127, linear_loss=0.04272]
[2020-05-12 13:26:09.135]  Step 161223  [3.559 sec/step, loss=0.08203, avg_loss=0.08678, mel_loss=0.03483, linear_loss=0.04720]
[2020-05-12 13:26:10.497]  Step 161224  [3.537 sec/step, loss=0.08202, avg_loss=0.08666, mel_loss=0.03479, linear_loss=0.04723]
[2020-05-12 13:26:14.247]  Step 161225  [3.564 sec/step, loss=0.09393, avg_loss=0.08681, mel_loss=0.04162, linear_loss=0.05231]
[2020-05-12 13:26:17.046]  Step 161226  [3.584 sec/step, loss=0.09001, avg_loss=0.08696, mel_loss=0.03964, linear_loss=0.05037]
[2020-05-12 13:26:18.015]  Step 161227  [3.547 sec/step, loss=0.07719, avg_loss=0.08678, mel_loss=0.03240, linear_loss=0.04479]
[2020-05-12 13:26:24.435]  Step 161228  [3.522 sec/step, loss=0.09423, avg_loss=0.08679, mel_loss=0.04257, linear_loss=0.05166]
[2020-05-12 13:27:47.065]  Generated 32 batches of size 32 in 109.951 sec
[2020-05-12 13:27:52.701]  Step 161229  [4.394 sec/step, loss=0.09440, avg_loss=0.08696, mel_loss=0.04222, linear_loss=0.05218]
[2020-05-12 13:27:53.674]  Step 161230  [4.376 sec/step, loss=0.07905, avg_loss=0.08686, mel_loss=0.03370, linear_loss=0.04535]
[2020-05-12 13:27:54.577]  Step 161231  [4.351 sec/step, loss=0.07858, avg_loss=0.08672, mel_loss=0.03297, linear_loss=0.04561]
[2020-05-12 13:27:59.363]  Step 161232  [4.341 sec/step, loss=0.09201, avg_loss=0.08669, mel_loss=0.04045, linear_loss=0.05156]
[2020-05-12 13:28:05.102]  Step 161233  [4.386 sec/step, loss=0.09256, avg_loss=0.08682, mel_loss=0.04118, linear_loss=0.05137]
[2020-05-12 13:28:08.303]  Step 161234  [4.366 sec/step, loss=0.09371, avg_loss=0.08682, mel_loss=0.04107, linear_loss=0.05264]
[2020-05-12 13:28:08.866]  Step 161235  [4.350 sec/step, loss=0.06702, avg_loss=0.08662, mel_loss=0.02857, linear_loss=0.03845]
[2020-05-12 13:28:10.675]  Step 161236  [4.351 sec/step, loss=0.08470, avg_loss=0.08661, mel_loss=0.03632, linear_loss=0.04838]
[2020-05-12 13:28:12.632]  Step 161237  [4.319 sec/step, loss=0.08507, avg_loss=0.08659, mel_loss=0.03670, linear_loss=0.04837]
[2020-05-12 13:28:13.739]  Step 161238  [4.315 sec/step, loss=0.07883, avg_loss=0.08652, mel_loss=0.03351, linear_loss=0.04532]
[2020-05-12 13:28:16.331]  Step 161239  [4.314 sec/step, loss=0.08830, avg_loss=0.08651, mel_loss=0.03849, linear_loss=0.04982]
[2020-05-12 13:28:18.479]  Step 161240  [4.325 sec/step, loss=0.08838, avg_loss=0.08660, mel_loss=0.03833, linear_loss=0.05004]
[2020-05-12 13:28:25.226]  Step 161241  [4.349 sec/step, loss=0.09449, avg_loss=0.08660, mel_loss=0.04255, linear_loss=0.05195]
[2020-05-12 13:28:26.464]  Step 161242  [4.321 sec/step, loss=0.07958, avg_loss=0.08648, mel_loss=0.03391, linear_loss=0.04567]
[2020-05-12 13:28:30.079]  Step 161243  [4.327 sec/step, loss=0.09290, avg_loss=0.08651, mel_loss=0.04108, linear_loss=0.05182]
[2020-05-12 13:28:32.283]  Step 161244  [4.336 sec/step, loss=0.08830, avg_loss=0.08657, mel_loss=0.03857, linear_loss=0.04973]
[2020-05-12 13:28:33.982]  Step 161245  [4.333 sec/step, loss=0.08533, avg_loss=0.08657, mel_loss=0.03685, linear_loss=0.04848]
[2020-05-12 13:28:34.854]  Step 161246  [4.333 sec/step, loss=0.06916, avg_loss=0.08646, mel_loss=0.02963, linear_loss=0.03953]
[2020-05-12 13:28:38.906]  Step 161247  [4.367 sec/step, loss=0.09367, avg_loss=0.08673, mel_loss=0.04127, linear_loss=0.05240]
[2020-05-12 13:28:41.329]  Step 161248  [4.381 sec/step, loss=0.08974, avg_loss=0.08684, mel_loss=0.03896, linear_loss=0.05079]
[2020-05-12 13:28:42.642]  Step 161249  [4.338 sec/step, loss=0.08108, avg_loss=0.08670, mel_loss=0.03494, linear_loss=0.04614]
[2020-05-12 13:28:51.496]  Step 161250  [4.414 sec/step, loss=0.09243, avg_loss=0.08682, mel_loss=0.04220, linear_loss=0.05023]
[2020-05-12 13:28:51.496]  Writing summary at step: 161250
[2020-05-12 13:28:52.333]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161250
[2020-05-12 13:28:53.953]  Saving audio and alignment...
[2020-05-12 13:28:59.347]  Input: 그래서 저는 실제로 점집을 찾아가서 물어 본 적도 있어요~___
[2020-05-12 13:29:06.698]  Step 161251  [4.454 sec/step, loss=0.09454, avg_loss=0.08685, mel_loss=0.04296, linear_loss=0.05158]
[2020-05-12 13:29:08.794]  Generated 32 batches of size 32 in 14.218 sec
[2020-05-12 13:29:11.292]  Step 161252  [4.365 sec/step, loss=0.09448, avg_loss=0.08699, mel_loss=0.04193, linear_loss=0.05255]
[2020-05-12 13:29:14.141]  Step 161253  [4.346 sec/step, loss=0.09101, avg_loss=0.08696, mel_loss=0.03992, linear_loss=0.05109]
[2020-05-12 13:29:19.241]  Step 161254  [4.320 sec/step, loss=0.09346, avg_loss=0.08694, mel_loss=0.04176, linear_loss=0.05169]
[2020-05-12 13:29:21.281]  Step 161255  [4.334 sec/step, loss=0.08725, avg_loss=0.08709, mel_loss=0.03777, linear_loss=0.04949]
[2020-05-12 13:29:22.664]  Step 161256  [4.340 sec/step, loss=0.08274, avg_loss=0.08720, mel_loss=0.03553, linear_loss=0.04720]
[2020-05-12 13:29:24.207]  Step 161257  [4.318 sec/step, loss=0.08478, avg_loss=0.08711, mel_loss=0.03638, linear_loss=0.04840]
[2020-05-12 13:29:38.711]  Step 161258  [4.441 sec/step, loss=0.07382, avg_loss=0.08695, mel_loss=0.03456, linear_loss=0.03926]
[2020-05-12 13:29:40.027]  Step 161259  [4.436 sec/step, loss=0.08192, avg_loss=0.08691, mel_loss=0.03479, linear_loss=0.04712]
[2020-05-12 13:29:43.135]  Step 161260  [4.454 sec/step, loss=0.09291, avg_loss=0.08702, mel_loss=0.04088, linear_loss=0.05203]
[2020-05-12 13:29:44.892]  Step 161261  [4.448 sec/step, loss=0.08681, avg_loss=0.08702, mel_loss=0.03702, linear_loss=0.04978]
[2020-05-12 13:29:49.662]  Step 161262  [4.464 sec/step, loss=0.09387, avg_loss=0.08701, mel_loss=0.04170, linear_loss=0.05217]
[2020-05-12 13:29:51.670]  Step 161263  [4.430 sec/step, loss=0.08738, avg_loss=0.08694, mel_loss=0.03772, linear_loss=0.04966]
[2020-05-12 13:29:53.559]  Step 161264  [4.363 sec/step, loss=0.08490, avg_loss=0.08683, mel_loss=0.03627, linear_loss=0.04863]
[2020-05-12 13:29:54.360]  Step 161265  [4.301 sec/step, loss=0.07521, avg_loss=0.08664, mel_loss=0.03155, linear_loss=0.04366]
[2020-05-12 13:29:56.560]  Step 161266  [4.306 sec/step, loss=0.08628, avg_loss=0.08663, mel_loss=0.03752, linear_loss=0.04876]
[2020-05-12 13:29:57.673]  Step 161267  [4.107 sec/step, loss=0.08192, avg_loss=0.08676, mel_loss=0.03456, linear_loss=0.04736]
[2020-05-12 13:29:59.321]  Step 161268  [4.109 sec/step, loss=0.08446, avg_loss=0.08676, mel_loss=0.03647, linear_loss=0.04799]
[2020-05-12 13:30:00.320]  Step 161269  [4.077 sec/step, loss=0.07738, avg_loss=0.08660, mel_loss=0.03256, linear_loss=0.04481]
[2020-05-12 13:30:02.981]  Step 161270  [3.973 sec/step, loss=0.09006, avg_loss=0.08672, mel_loss=0.03961, linear_loss=0.05045]
[2020-05-12 13:30:17.245]  Step 161271  [4.107 sec/step, loss=0.07201, avg_loss=0.08668, mel_loss=0.03390, linear_loss=0.03811]
[2020-05-12 13:30:22.800]  Step 161272  [4.081 sec/step, loss=0.09372, avg_loss=0.08670, mel_loss=0.04191, linear_loss=0.05181]
[2020-05-12 13:30:25.804]  Step 161273  [4.037 sec/step, loss=0.09112, avg_loss=0.08666, mel_loss=0.03975, linear_loss=0.05138]
[2020-05-12 13:30:27.049]  Step 161274  [4.001 sec/step, loss=0.08204, avg_loss=0.08656, mel_loss=0.03512, linear_loss=0.04693]
[2020-05-12 13:30:27.895]  Step 161275  [3.997 sec/step, loss=0.07211, avg_loss=0.08645, mel_loss=0.03038, linear_loss=0.04173]
[2020-05-12 13:30:29.915]  Step 161276  [3.993 sec/step, loss=0.08770, avg_loss=0.08644, mel_loss=0.03803, linear_loss=0.04967]
[2020-05-12 13:30:34.350]  Step 161277  [4.003 sec/step, loss=0.09453, avg_loss=0.08647, mel_loss=0.04212, linear_loss=0.05241]
[2020-05-12 13:30:35.982]  Step 161278  [4.000 sec/step, loss=0.08275, avg_loss=0.08641, mel_loss=0.03543, linear_loss=0.04732]
[2020-05-12 13:30:42.877]  Step 161279  [4.014 sec/step, loss=0.09701, avg_loss=0.08643, mel_loss=0.04401, linear_loss=0.05301]
[2020-05-12 13:30:46.612]  Step 161280  [4.015 sec/step, loss=0.09153, avg_loss=0.08641, mel_loss=0.04028, linear_loss=0.05124]
[2020-05-12 13:30:49.379]  Step 161281  [4.025 sec/step, loss=0.08719, avg_loss=0.08641, mel_loss=0.03796, linear_loss=0.04923]
[2020-05-12 13:30:55.545]  Step 161282  [4.065 sec/step, loss=0.09303, avg_loss=0.08644, mel_loss=0.04181, linear_loss=0.05122]
[2020-05-12 13:30:59.110]  Step 161283  [4.091 sec/step, loss=0.09145, avg_loss=0.08661, mel_loss=0.04035, linear_loss=0.05111]
[2020-05-12 13:30:59.672]  Step 161284  [4.062 sec/step, loss=0.06831, avg_loss=0.08638, mel_loss=0.02943, linear_loss=0.03889]
[2020-05-12 13:31:07.935]  Step 161285  [4.128 sec/step, loss=0.09291, avg_loss=0.08646, mel_loss=0.04216, linear_loss=0.05075]
[2020-05-12 13:31:11.675]  Step 161286  [4.121 sec/step, loss=0.09447, avg_loss=0.08646, mel_loss=0.04174, linear_loss=0.05273]
[2020-05-12 13:31:14.089]  Step 161287  [4.117 sec/step, loss=0.08946, avg_loss=0.08645, mel_loss=0.03888, linear_loss=0.05058]
[2020-05-12 13:31:15.120]  Step 161288  [4.114 sec/step, loss=0.07990, avg_loss=0.08641, mel_loss=0.03402, linear_loss=0.04588]
[2020-05-12 13:31:19.192]  Step 161289  [4.147 sec/step, loss=0.09113, avg_loss=0.08663, mel_loss=0.04018, linear_loss=0.05095]
[2020-05-12 13:31:20.578]  Step 161290  [4.131 sec/step, loss=0.08427, avg_loss=0.08656, mel_loss=0.03622, linear_loss=0.04805]
[2020-05-12 13:32:16.615]  Generated 32 batches of size 32 in 87.230 sec
[2020-05-12 13:32:19.012]  Step 161291  [4.679 sec/step, loss=0.08761, avg_loss=0.08650, mel_loss=0.03810, linear_loss=0.04951]
[2020-05-12 13:32:19.573]  Step 161292  [4.669 sec/step, loss=0.06480, avg_loss=0.08631, mel_loss=0.02834, linear_loss=0.03647]
[2020-05-12 13:32:21.039]  Step 161293  [4.673 sec/step, loss=0.08172, avg_loss=0.08635, mel_loss=0.03526, linear_loss=0.04646]
[2020-05-12 13:32:25.579]  Step 161294  [4.699 sec/step, loss=0.09484, avg_loss=0.08643, mel_loss=0.04225, linear_loss=0.05259]
[2020-05-12 13:32:28.500]  Step 161295  [4.701 sec/step, loss=0.08860, avg_loss=0.08642, mel_loss=0.03903, linear_loss=0.04957]
[2020-05-12 13:32:29.237]  Step 161296  [4.697 sec/step, loss=0.07373, avg_loss=0.08637, mel_loss=0.03127, linear_loss=0.04246]
[2020-05-12 13:32:32.348]  Step 161297  [4.704 sec/step, loss=0.09122, avg_loss=0.08640, mel_loss=0.04019, linear_loss=0.05104]
[2020-05-12 13:32:35.752]  Step 161298  [4.678 sec/step, loss=0.09153, avg_loss=0.08638, mel_loss=0.04039, linear_loss=0.05114]
[2020-05-12 13:32:41.178]  Step 161299  [4.644 sec/step, loss=0.09575, avg_loss=0.08641, mel_loss=0.04303, linear_loss=0.05271]
[2020-05-12 13:32:42.959]  Step 161300  [4.657 sec/step, loss=0.08440, avg_loss=0.08657, mel_loss=0.03655, linear_loss=0.04785]
[2020-05-12 13:32:42.959]  Writing summary at step: 161300
[2020-05-12 13:32:46.605]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161300
[2020-05-12 13:32:48.242]  Saving audio and alignment...
[2020-05-12 13:32:50.470]  Input: 자 다음으로~_______________
[2020-05-12 13:32:51.538]  Step 161301  [4.650 sec/step, loss=0.07633, avg_loss=0.08647, mel_loss=0.03211, linear_loss=0.04422]
[2020-05-12 13:32:53.720]  Step 161302  [4.664 sec/step, loss=0.08753, avg_loss=0.08658, mel_loss=0.03805, linear_loss=0.04948]
[2020-05-12 13:32:54.622]  Step 161303  [4.632 sec/step, loss=0.07450, avg_loss=0.08637, mel_loss=0.03149, linear_loss=0.04301]
[2020-05-12 13:32:55.989]  Step 161304  [4.592 sec/step, loss=0.08438, avg_loss=0.08628, mel_loss=0.03600, linear_loss=0.04838]
[2020-05-12 13:32:58.449]  Step 161305  [4.543 sec/step, loss=0.08793, avg_loss=0.08620, mel_loss=0.03802, linear_loss=0.04991]
[2020-05-12 13:33:07.869]  Step 161306  [4.623 sec/step, loss=0.09694, avg_loss=0.08634, mel_loss=0.04444, linear_loss=0.05250]
[2020-05-12 13:33:14.037]  Step 161307  [4.659 sec/step, loss=0.09241, avg_loss=0.08638, mel_loss=0.04167, linear_loss=0.05074]
[2020-05-12 13:33:16.788]  Step 161308  [4.655 sec/step, loss=0.09024, avg_loss=0.08635, mel_loss=0.03903, linear_loss=0.05121]
[2020-05-12 13:33:20.014]  Step 161309  [4.666 sec/step, loss=0.09257, avg_loss=0.08641, mel_loss=0.04050, linear_loss=0.05207]
[2020-05-12 13:33:27.656]  Step 161310  [4.718 sec/step, loss=0.09572, avg_loss=0.08649, mel_loss=0.04337, linear_loss=0.05235]
[2020-05-12 13:33:32.663]  Step 161311  [4.734 sec/step, loss=0.09302, avg_loss=0.08651, mel_loss=0.04168, linear_loss=0.05134]
[2020-05-12 13:33:36.460]  Step 161312  [4.756 sec/step, loss=0.09481, avg_loss=0.08662, mel_loss=0.04198, linear_loss=0.05283]
[2020-05-12 13:33:38.175]  Step 161313  [4.625 sec/step, loss=0.08535, avg_loss=0.08672, mel_loss=0.03683, linear_loss=0.04853]
[2020-05-12 13:33:45.479]  Step 161314  [4.681 sec/step, loss=0.09505, avg_loss=0.08681, mel_loss=0.04308, linear_loss=0.05197]
[2020-05-12 13:33:47.083]  Step 161315  [4.662 sec/step, loss=0.08592, avg_loss=0.08675, mel_loss=0.03704, linear_loss=0.04888]
[2020-05-12 13:33:49.072]  Step 161316  [4.634 sec/step, loss=0.08679, avg_loss=0.08668, mel_loss=0.03781, linear_loss=0.04898]
[2020-05-12 13:33:50.259]  Step 161317  [4.626 sec/step, loss=0.08245, avg_loss=0.08665, mel_loss=0.03556, linear_loss=0.04690]
[2020-05-12 13:34:03.966]  Step 161318  [4.743 sec/step, loss=0.08266, avg_loss=0.08660, mel_loss=0.03844, linear_loss=0.04422]
[2020-05-12 13:34:04.181]  Generated 32 batches of size 32 in 31.513 sec
[2020-05-12 13:34:04.781]  Step 161319  [4.723 sec/step, loss=0.07649, avg_loss=0.08647, mel_loss=0.03241, linear_loss=0.04408]
[2020-05-12 13:34:09.179]  Step 161320  [4.709 sec/step, loss=0.09166, avg_loss=0.08644, mel_loss=0.04061, linear_loss=0.05105]
[2020-05-12 13:34:14.542]  Step 161321  [4.720 sec/step, loss=0.09386, avg_loss=0.08645, mel_loss=0.04194, linear_loss=0.05192]
[2020-05-12 13:34:17.573]  Step 161322  [4.742 sec/step, loss=0.09134, avg_loss=0.08663, mel_loss=0.04016, linear_loss=0.05118]
[2020-05-12 13:34:23.847]  Step 161323  [4.793 sec/step, loss=0.09383, avg_loss=0.08674, mel_loss=0.04215, linear_loss=0.05168]
[2020-05-12 13:34:24.854]  Step 161324  [4.790 sec/step, loss=0.07984, avg_loss=0.08672, mel_loss=0.03329, linear_loss=0.04655]
[2020-05-12 13:34:29.261]  Step 161325  [4.796 sec/step, loss=0.09497, avg_loss=0.08673, mel_loss=0.04229, linear_loss=0.05269]
[2020-05-12 13:34:30.063]  Step 161326  [4.776 sec/step, loss=0.07270, avg_loss=0.08656, mel_loss=0.03052, linear_loss=0.04217]
[2020-05-12 13:34:30.840]  Step 161327  [4.774 sec/step, loss=0.07474, avg_loss=0.08654, mel_loss=0.03163, linear_loss=0.04311]
[2020-05-12 13:34:32.818]  Step 161328  [4.730 sec/step, loss=0.08807, avg_loss=0.08647, mel_loss=0.03805, linear_loss=0.05002]
[2020-05-12 13:34:36.504]  Step 161329  [3.884 sec/step, loss=0.09482, avg_loss=0.08648, mel_loss=0.04206, linear_loss=0.05277]
[2020-05-12 13:34:38.272]  Step 161330  [3.892 sec/step, loss=0.08777, avg_loss=0.08657, mel_loss=0.03761, linear_loss=0.05016]
[2020-05-12 13:34:42.309]  Step 161331  [3.923 sec/step, loss=0.09165, avg_loss=0.08670, mel_loss=0.04064, linear_loss=0.05100]
[2020-05-12 13:34:43.423]  Step 161332  [3.887 sec/step, loss=0.07894, avg_loss=0.08657, mel_loss=0.03374, linear_loss=0.04520]
[2020-05-12 13:34:46.587]  Step 161333  [3.861 sec/step, loss=0.09224, avg_loss=0.08656, mel_loss=0.04046, linear_loss=0.05178]
[2020-05-12 13:34:51.312]  Step 161334  [3.876 sec/step, loss=0.09463, avg_loss=0.08657, mel_loss=0.04216, linear_loss=0.05247]
[2020-05-12 13:34:53.753]  Step 161335  [3.895 sec/step, loss=0.08837, avg_loss=0.08678, mel_loss=0.03841, linear_loss=0.04996]
[2020-05-12 13:35:07.073]  Step 161336  [4.010 sec/step, loss=0.08079, avg_loss=0.08675, mel_loss=0.03761, linear_loss=0.04318]
[2020-05-12 13:35:12.322]  Step 161337  [4.043 sec/step, loss=0.09541, avg_loss=0.08685, mel_loss=0.04268, linear_loss=0.05273]
[2020-05-12 13:35:20.849]  Step 161338  [4.117 sec/step, loss=0.09211, avg_loss=0.08698, mel_loss=0.04214, linear_loss=0.04998]
[2020-05-12 13:35:22.206]  Step 161339  [4.105 sec/step, loss=0.08223, avg_loss=0.08692, mel_loss=0.03525, linear_loss=0.04697]
[2020-05-12 13:35:24.856]  Step 161340  [4.110 sec/step, loss=0.08929, avg_loss=0.08693, mel_loss=0.03904, linear_loss=0.05026]
[2020-05-12 13:35:28.296]  Step 161341  [4.077 sec/step, loss=0.09145, avg_loss=0.08690, mel_loss=0.04033, linear_loss=0.05112]
[2020-05-12 13:35:29.529]  Step 161342  [4.077 sec/step, loss=0.08267, avg_loss=0.08693, mel_loss=0.03510, linear_loss=0.04757]
[2020-05-12 13:35:31.511]  Step 161343  [4.060 sec/step, loss=0.08763, avg_loss=0.08688, mel_loss=0.03783, linear_loss=0.04979]
[2020-05-12 13:35:33.727]  Step 161344  [4.061 sec/step, loss=0.08598, avg_loss=0.08685, mel_loss=0.03739, linear_loss=0.04858]
[2020-05-12 13:35:34.484]  Step 161345  [4.051 sec/step, loss=0.06916, avg_loss=0.08669, mel_loss=0.02986, linear_loss=0.03930]
[2020-05-12 13:35:36.028]  Step 161346  [4.058 sec/step, loss=0.08529, avg_loss=0.08685, mel_loss=0.03661, linear_loss=0.04869]
[2020-05-12 13:35:36.962]  Step 161347  [4.027 sec/step, loss=0.07948, avg_loss=0.08671, mel_loss=0.03384, linear_loss=0.04564]
[2020-05-12 13:35:38.755]  Step 161348  [4.020 sec/step, loss=0.08581, avg_loss=0.08667, mel_loss=0.03704, linear_loss=0.04876]
[2020-05-12 13:35:41.440]  Step 161349  [4.034 sec/step, loss=0.08842, avg_loss=0.08675, mel_loss=0.03863, linear_loss=0.04978]
[2020-05-12 13:35:42.912]  Step 161350  [3.960 sec/step, loss=0.08161, avg_loss=0.08664, mel_loss=0.03516, linear_loss=0.04645]
[2020-05-12 13:35:42.912]  Writing summary at step: 161350
[2020-05-12 13:35:46.467]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161350
[2020-05-12 13:35:48.120]  Saving audio and alignment...
[2020-05-12 13:35:57.982]  Input: 도 레 미 파 솔 라 시 도 이렇게 하시고 도 꽃이 피기까지 도음 잡고 꽃~_________________________________________________________________________
[2020-05-12 13:36:47.243]  Generated 32 batches of size 32 in 75.727 sec
[2020-05-12 13:36:48.369]  Step 161351  [4.391 sec/step, loss=0.07717, avg_loss=0.08646, mel_loss=0.03260, linear_loss=0.04457]
[2020-05-12 13:36:50.932]  Step 161352  [4.370 sec/step, loss=0.08793, avg_loss=0.08640, mel_loss=0.03820, linear_loss=0.04973]
[2020-05-12 13:36:53.621]  Step 161353  [4.369 sec/step, loss=0.08929, avg_loss=0.08638, mel_loss=0.03908, linear_loss=0.05021]
[2020-05-12 13:36:57.740]  Step 161354  [4.359 sec/step, loss=0.09364, avg_loss=0.08638, mel_loss=0.04178, linear_loss=0.05186]
[2020-05-12 13:37:04.350]  Step 161355  [4.405 sec/step, loss=0.09356, avg_loss=0.08645, mel_loss=0.04233, linear_loss=0.05124]
[2020-05-12 13:37:11.250]  Step 161356  [4.460 sec/step, loss=0.09572, avg_loss=0.08658, mel_loss=0.04329, linear_loss=0.05244]
[2020-05-12 13:37:16.759]  Step 161357  [4.499 sec/step, loss=0.09355, avg_loss=0.08666, mel_loss=0.04196, linear_loss=0.05159]
[2020-05-12 13:37:18.922]  Step 161358  [4.376 sec/step, loss=0.08786, avg_loss=0.08681, mel_loss=0.03817, linear_loss=0.04970]
[2020-05-12 13:37:22.190]  Step 161359  [4.396 sec/step, loss=0.09306, avg_loss=0.08692, mel_loss=0.04093, linear_loss=0.05213]
[2020-05-12 13:37:30.201]  Step 161360  [4.445 sec/step, loss=0.09599, avg_loss=0.08695, mel_loss=0.04350, linear_loss=0.05249]
[2020-05-12 13:37:30.865]  Step 161361  [4.434 sec/step, loss=0.07061, avg_loss=0.08679, mel_loss=0.03037, linear_loss=0.04024]
[2020-05-12 13:37:32.246]  Step 161362  [4.400 sec/step, loss=0.08484, avg_loss=0.08669, mel_loss=0.03644, linear_loss=0.04841]
[2020-05-12 13:37:46.427]  Step 161363  [4.522 sec/step, loss=0.06851, avg_loss=0.08651, mel_loss=0.03184, linear_loss=0.03667]
[2020-05-12 13:37:49.889]  Step 161364  [4.537 sec/step, loss=0.09172, avg_loss=0.08657, mel_loss=0.04073, linear_loss=0.05100]
[2020-05-12 13:37:50.451]  Step 161365  [4.535 sec/step, loss=0.06994, avg_loss=0.08652, mel_loss=0.03041, linear_loss=0.03954]
[2020-05-12 13:37:54.582]  Step 161366  [4.554 sec/step, loss=0.09260, avg_loss=0.08659, mel_loss=0.04094, linear_loss=0.05166]
[2020-05-12 13:37:55.778]  Step 161367  [4.555 sec/step, loss=0.08188, avg_loss=0.08658, mel_loss=0.03518, linear_loss=0.04670]
[2020-05-12 13:37:57.553]  Step 161368  [4.556 sec/step, loss=0.08567, avg_loss=0.08660, mel_loss=0.03672, linear_loss=0.04895]
[2020-05-12 13:38:00.564]  Step 161369  [4.576 sec/step, loss=0.09317, avg_loss=0.08675, mel_loss=0.04105, linear_loss=0.05213]
[2020-05-12 13:38:02.476]  Step 161370  [4.569 sec/step, loss=0.08547, avg_loss=0.08671, mel_loss=0.03681, linear_loss=0.04866]
[2020-05-12 13:38:04.484]  Step 161371  [4.446 sec/step, loss=0.08877, avg_loss=0.08688, mel_loss=0.03844, linear_loss=0.05033]
[2020-05-12 13:38:06.607]  Step 161372  [4.412 sec/step, loss=0.08863, avg_loss=0.08683, mel_loss=0.03857, linear_loss=0.05007]
[2020-05-12 13:38:07.749]  Step 161373  [4.393 sec/step, loss=0.07984, avg_loss=0.08671, mel_loss=0.03382, linear_loss=0.04602]
[2020-05-12 13:38:12.727]  Step 161374  [4.431 sec/step, loss=0.09314, avg_loss=0.08682, mel_loss=0.04164, linear_loss=0.05151]
[2020-05-12 13:38:14.423]  Step 161375  [4.439 sec/step, loss=0.08118, avg_loss=0.08691, mel_loss=0.03444, linear_loss=0.04673]
[2020-05-12 13:38:16.286]  Step 161376  [4.438 sec/step, loss=0.08592, avg_loss=0.08690, mel_loss=0.03687, linear_loss=0.04906]
[2020-05-12 13:38:19.978]  Step 161377  [4.430 sec/step, loss=0.09519, avg_loss=0.08690, mel_loss=0.04233, linear_loss=0.05287]
[2020-05-12 13:38:20.888]  Step 161378  [4.423 sec/step, loss=0.07763, avg_loss=0.08685, mel_loss=0.03259, linear_loss=0.04504]
[2020-05-12 13:38:25.439]  Step 161379  [4.400 sec/step, loss=0.09324, avg_loss=0.08681, mel_loss=0.04124, linear_loss=0.05200]
[2020-05-12 13:38:28.344]  Step 161380  [4.391 sec/step, loss=0.09250, avg_loss=0.08682, mel_loss=0.04052, linear_loss=0.05198]
[2020-05-12 13:38:29.150]  Step 161381  [4.372 sec/step, loss=0.07510, avg_loss=0.08670, mel_loss=0.03178, linear_loss=0.04332]
[2020-05-12 13:38:30.753]  Step 161382  [4.326 sec/step, loss=0.08527, avg_loss=0.08663, mel_loss=0.03685, linear_loss=0.04842]
[2020-05-12 13:39:25.238]  Generated 32 batches of size 32 in 77.483 sec
[2020-05-12 13:39:27.947]  Step 161383  [4.862 sec/step, loss=0.08804, avg_loss=0.08659, mel_loss=0.03842, linear_loss=0.04962]
[2020-05-12 13:39:34.666]  Step 161384  [4.924 sec/step, loss=0.09503, avg_loss=0.08686, mel_loss=0.04291, linear_loss=0.05212]
[2020-05-12 13:39:37.646]  Step 161385  [4.871 sec/step, loss=0.09084, avg_loss=0.08684, mel_loss=0.03991, linear_loss=0.05092]
[2020-05-12 13:39:38.953]  Step 161386  [4.847 sec/step, loss=0.08417, avg_loss=0.08673, mel_loss=0.03608, linear_loss=0.04810]
[2020-05-12 13:39:41.052]  Step 161387  [4.844 sec/step, loss=0.08851, avg_loss=0.08673, mel_loss=0.03828, linear_loss=0.05022]
[2020-05-12 13:39:42.098]  Step 161388  [4.844 sec/step, loss=0.08057, avg_loss=0.08673, mel_loss=0.03433, linear_loss=0.04623]
[2020-05-12 13:39:45.726]  Step 161389  [4.839 sec/step, loss=0.09366, avg_loss=0.08676, mel_loss=0.04141, linear_loss=0.05225]
[2020-05-12 13:39:46.722]  Step 161390  [4.835 sec/step, loss=0.07847, avg_loss=0.08670, mel_loss=0.03288, linear_loss=0.04559]
[2020-05-12 13:39:52.357]  Step 161391  [4.307 sec/step, loss=0.09520, avg_loss=0.08678, mel_loss=0.04273, linear_loss=0.05248]
[2020-05-12 13:39:54.091]  Step 161392  [4.319 sec/step, loss=0.08741, avg_loss=0.08700, mel_loss=0.03765, linear_loss=0.04976]
[2020-05-12 13:39:56.883]  Step 161393  [4.332 sec/step, loss=0.08894, avg_loss=0.08707, mel_loss=0.03914, linear_loss=0.04981]
[2020-05-12 13:40:00.306]  Step 161394  [4.321 sec/step, loss=0.09131, avg_loss=0.08704, mel_loss=0.04019, linear_loss=0.05112]
[2020-05-12 13:40:01.534]  Step 161395  [4.304 sec/step, loss=0.07888, avg_loss=0.08694, mel_loss=0.03357, linear_loss=0.04530]
[2020-05-12 13:40:06.796]  Step 161396  [4.350 sec/step, loss=0.09369, avg_loss=0.08714, mel_loss=0.04192, linear_loss=0.05177]
[2020-05-12 13:40:08.747]  Step 161397  [4.338 sec/step, loss=0.08738, avg_loss=0.08710, mel_loss=0.03792, linear_loss=0.04946]
[2020-05-12 13:40:10.929]  Step 161398  [4.326 sec/step, loss=0.08658, avg_loss=0.08705, mel_loss=0.03759, linear_loss=0.04899]
[2020-05-12 13:40:11.814]  Step 161399  [4.280 sec/step, loss=0.07005, avg_loss=0.08680, mel_loss=0.02977, linear_loss=0.04028]
[2020-05-12 13:40:12.376]  Step 161400  [4.268 sec/step, loss=0.06783, avg_loss=0.08663, mel_loss=0.02920, linear_loss=0.03862]
[2020-05-12 13:40:12.376]  Writing summary at step: 161400
[2020-05-12 13:40:14.819]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161400
[2020-05-12 13:40:16.583]  Saving audio and alignment...
[2020-05-12 13:40:34.108]  Input: 특별한 극 소수만이 합격자가 돼죠~________________________________________________________________________________________________________________________________________________
[2020-05-12 13:40:42.800]  Step 161401  [4.344 sec/step, loss=0.08937, avg_loss=0.08676, mel_loss=0.04095, linear_loss=0.04842]
[2020-05-12 13:40:44.172]  Step 161402  [4.336 sec/step, loss=0.08166, avg_loss=0.08670, mel_loss=0.03506, linear_loss=0.04660]
[2020-05-12 13:40:45.660]  Step 161403  [4.342 sec/step, loss=0.08364, avg_loss=0.08679, mel_loss=0.03600, linear_loss=0.04764]
[2020-05-12 13:40:46.460]  Step 161404  [4.336 sec/step, loss=0.07523, avg_loss=0.08670, mel_loss=0.03150, linear_loss=0.04373]
[2020-05-12 13:40:50.638]  Step 161405  [4.354 sec/step, loss=0.09247, avg_loss=0.08675, mel_loss=0.04084, linear_loss=0.05164]
[2020-05-12 13:40:58.003]  Step 161406  [4.333 sec/step, loss=0.09582, avg_loss=0.08674, mel_loss=0.04353, linear_loss=0.05230]
[2020-05-12 13:40:59.010]  Step 161407  [4.281 sec/step, loss=0.07812, avg_loss=0.08659, mel_loss=0.03326, linear_loss=0.04485]
[2020-05-12 13:41:00.603]  Step 161408  [4.270 sec/step, loss=0.08574, avg_loss=0.08655, mel_loss=0.03697, linear_loss=0.04877]
[2020-05-12 13:41:04.295]  Step 161409  [4.275 sec/step, loss=0.09258, avg_loss=0.08655, mel_loss=0.04056, linear_loss=0.05202]
[2020-05-12 13:41:07.701]  Generated 32 batches of size 32 in 22.036 sec
[2020-05-12 13:41:09.264]  Step 161410  [4.248 sec/step, loss=0.09382, avg_loss=0.08653, mel_loss=0.04169, linear_loss=0.05212]
[2020-05-12 13:41:11.198]  Step 161411  [4.217 sec/step, loss=0.08503, avg_loss=0.08645, mel_loss=0.03656, linear_loss=0.04847]
[2020-05-12 13:41:14.519]  Step 161412  [4.212 sec/step, loss=0.09155, avg_loss=0.08642, mel_loss=0.04003, linear_loss=0.05152]
[2020-05-12 13:41:19.922]  Step 161413  [4.249 sec/step, loss=0.09436, avg_loss=0.08651, mel_loss=0.04243, linear_loss=0.05193]
[2020-05-12 13:41:24.260]  Step 161414  [4.220 sec/step, loss=0.09596, avg_loss=0.08652, mel_loss=0.04276, linear_loss=0.05320]
[2020-05-12 13:41:25.673]  Step 161415  [4.218 sec/step, loss=0.08506, avg_loss=0.08651, mel_loss=0.03649, linear_loss=0.04858]
[2020-05-12 13:41:27.004]  Step 161416  [4.211 sec/step, loss=0.08421, avg_loss=0.08648, mel_loss=0.03599, linear_loss=0.04822]
[2020-05-12 13:41:29.887]  Step 161417  [4.228 sec/step, loss=0.08980, avg_loss=0.08655, mel_loss=0.03927, linear_loss=0.05053]
[2020-05-12 13:41:33.253]  Step 161418  [4.125 sec/step, loss=0.09215, avg_loss=0.08665, mel_loss=0.04063, linear_loss=0.05152]
[2020-05-12 13:41:34.076]  Step 161419  [4.125 sec/step, loss=0.07414, avg_loss=0.08663, mel_loss=0.03151, linear_loss=0.04263]
[2020-05-12 13:41:36.043]  Step 161420  [4.100 sec/step, loss=0.08860, avg_loss=0.08660, mel_loss=0.03843, linear_loss=0.05017]
[2020-05-12 13:41:38.460]  Step 161421  [4.071 sec/step, loss=0.08942, avg_loss=0.08655, mel_loss=0.03882, linear_loss=0.05060]
[2020-05-12 13:41:39.013]  Step 161422  [4.046 sec/step, loss=0.06748, avg_loss=0.08631, mel_loss=0.02951, linear_loss=0.03797]
[2020-05-12 13:41:40.887]  Step 161423  [4.002 sec/step, loss=0.08454, avg_loss=0.08622, mel_loss=0.03637, linear_loss=0.04817]
[2020-05-12 13:41:41.723]  Step 161424  [4.000 sec/step, loss=0.07434, avg_loss=0.08616, mel_loss=0.03132, linear_loss=0.04302]
[2020-05-12 13:41:48.656]  Step 161425  [4.026 sec/step, loss=0.09223, avg_loss=0.08614, mel_loss=0.04156, linear_loss=0.05068]
[2020-05-12 13:41:49.695]  Step 161426  [4.028 sec/step, loss=0.07915, avg_loss=0.08620, mel_loss=0.03366, linear_loss=0.04550]
[2020-05-12 13:41:51.415]  Step 161427  [4.037 sec/step, loss=0.08531, avg_loss=0.08631, mel_loss=0.03653, linear_loss=0.04878]
[2020-05-12 13:41:53.540]  Step 161428  [4.039 sec/step, loss=0.08809, avg_loss=0.08631, mel_loss=0.03849, linear_loss=0.04960]
[2020-05-12 13:41:58.551]  Step 161429  [4.052 sec/step, loss=0.09331, avg_loss=0.08629, mel_loss=0.04137, linear_loss=0.05194]
[2020-05-12 13:42:04.404]  Step 161430  [4.093 sec/step, loss=0.09559, avg_loss=0.08637, mel_loss=0.04312, linear_loss=0.05247]
[2020-05-12 13:42:08.119]  Step 161431  [4.090 sec/step, loss=0.09248, avg_loss=0.08638, mel_loss=0.04085, linear_loss=0.05163]
[2020-05-12 13:42:11.982]  Step 161432  [4.117 sec/step, loss=0.09345, avg_loss=0.08652, mel_loss=0.04113, linear_loss=0.05232]
[2020-05-12 13:42:20.679]  Step 161433  [4.173 sec/step, loss=0.09556, avg_loss=0.08656, mel_loss=0.04360, linear_loss=0.05196]
[2020-05-12 13:42:21.460]  Step 161434  [4.133 sec/step, loss=0.07436, avg_loss=0.08635, mel_loss=0.03124, linear_loss=0.04312]
[2020-05-12 13:42:24.532]  Step 161435  [4.140 sec/step, loss=0.09149, avg_loss=0.08639, mel_loss=0.04023, linear_loss=0.05126]
[2020-05-12 13:42:26.270]  Step 161436  [4.024 sec/step, loss=0.08457, avg_loss=0.08642, mel_loss=0.03654, linear_loss=0.04803]
[2020-05-12 13:42:26.363]  Generated 32 batches of size 32 in 1.826 sec
[2020-05-12 13:42:27.408]  Step 161437  [3.983 sec/step, loss=0.08021, avg_loss=0.08627, mel_loss=0.03407, linear_loss=0.04615]
[2020-05-12 13:42:28.710]  Step 161438  [3.910 sec/step, loss=0.08113, avg_loss=0.08616, mel_loss=0.03462, linear_loss=0.04651]
[2020-05-12 13:42:31.088]  Step 161439  [3.921 sec/step, loss=0.08924, avg_loss=0.08623, mel_loss=0.03894, linear_loss=0.05030]
[2020-05-12 13:42:34.468]  Step 161440  [3.928 sec/step, loss=0.09065, avg_loss=0.08625, mel_loss=0.04001, linear_loss=0.05064]
[2020-05-12 13:42:47.623]  Step 161441  [4.025 sec/step, loss=0.07974, avg_loss=0.08613, mel_loss=0.03702, linear_loss=0.04272]
[2020-05-12 13:42:48.566]  Step 161442  [4.022 sec/step, loss=0.07758, avg_loss=0.08608, mel_loss=0.03287, linear_loss=0.04471]
[2020-05-12 13:42:51.756]  Step 161443  [4.034 sec/step, loss=0.09376, avg_loss=0.08614, mel_loss=0.04148, linear_loss=0.05228]
[2020-05-12 13:42:54.415]  Step 161444  [4.039 sec/step, loss=0.08944, avg_loss=0.08617, mel_loss=0.03917, linear_loss=0.05028]
[2020-05-12 13:42:55.762]  Step 161445  [4.045 sec/step, loss=0.08351, avg_loss=0.08632, mel_loss=0.03556, linear_loss=0.04795]
[2020-05-12 13:42:59.881]  Step 161446  [4.070 sec/step, loss=0.09259, avg_loss=0.08639, mel_loss=0.04081, linear_loss=0.05178]
[2020-05-12 13:43:00.438]  Step 161447  [4.066 sec/step, loss=0.06870, avg_loss=0.08628, mel_loss=0.02987, linear_loss=0.03883]
[2020-05-12 13:43:06.918]  Step 161448  [4.113 sec/step, loss=0.09380, avg_loss=0.08636, mel_loss=0.04229, linear_loss=0.05151]
[2020-05-12 13:43:10.602]  Step 161449  [4.123 sec/step, loss=0.09474, avg_loss=0.08643, mel_loss=0.04193, linear_loss=0.05281]
[2020-05-12 13:43:13.384]  Step 161450  [4.136 sec/step, loss=0.08844, avg_loss=0.08649, mel_loss=0.03859, linear_loss=0.04986]
[2020-05-12 13:43:13.384]  Writing summary at step: 161450
[2020-05-12 13:43:16.330]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161450
[2020-05-12 13:43:17.976]  Saving audio and alignment...
[2020-05-12 13:43:20.937]  Input: 총 십오회 초급 과정 중에~______
[2020-05-12 13:43:35.120]  Step 161451  [3.774 sec/step, loss=0.07391, avg_loss=0.08646, mel_loss=0.03459, linear_loss=0.03932]
[2020-05-12 13:43:36.249]  Step 161452  [3.760 sec/step, loss=0.08141, avg_loss=0.08640, mel_loss=0.03423, linear_loss=0.04718]
[2020-05-12 13:43:37.282]  Step 161453  [3.744 sec/step, loss=0.08105, avg_loss=0.08631, mel_loss=0.03448, linear_loss=0.04656]
[2020-05-12 13:43:38.289]  Step 161454  [3.712 sec/step, loss=0.07953, avg_loss=0.08617, mel_loss=0.03351, linear_loss=0.04602]
[2020-05-12 13:43:40.097]  Step 161455  [3.664 sec/step, loss=0.08639, avg_loss=0.08610, mel_loss=0.03699, linear_loss=0.04940]
[2020-05-12 13:43:41.826]  Step 161456  [3.613 sec/step, loss=0.08630, avg_loss=0.08601, mel_loss=0.03731, linear_loss=0.04898]
[2020-05-12 13:43:46.674]  Step 161457  [3.606 sec/step, loss=0.09296, avg_loss=0.08600, mel_loss=0.04140, linear_loss=0.05156]
[2020-05-12 13:43:54.312]  Step 161458  [3.661 sec/step, loss=0.09557, avg_loss=0.08608, mel_loss=0.04343, linear_loss=0.05214]
[2020-05-12 13:43:55.161]  Step 161459  [3.637 sec/step, loss=0.07230, avg_loss=0.08587, mel_loss=0.03066, linear_loss=0.04164]
[2020-05-12 13:43:56.397]  Step 161460  [3.569 sec/step, loss=0.07999, avg_loss=0.08571, mel_loss=0.03412, linear_loss=0.04586]
[2020-05-12 13:44:05.115]  Step 161461  [3.649 sec/step, loss=0.09252, avg_loss=0.08593, mel_loss=0.04205, linear_loss=0.05047]
[2020-05-12 13:44:07.626]  Step 161462  [3.661 sec/step, loss=0.08679, avg_loss=0.08595, mel_loss=0.03755, linear_loss=0.04924]
[2020-05-12 13:44:13.448]  Step 161463  [3.577 sec/step, loss=0.09412, avg_loss=0.08620, mel_loss=0.04230, linear_loss=0.05182]
[2020-05-12 13:44:15.488]  Step 161464  [3.563 sec/step, loss=0.08872, avg_loss=0.08617, mel_loss=0.03835, linear_loss=0.05037]
[2020-05-12 13:44:16.970]  Step 161465  [3.572 sec/step, loss=0.08116, avg_loss=0.08629, mel_loss=0.03469, linear_loss=0.04647]
[2020-05-12 13:44:19.135]  Step 161466  [3.552 sec/step, loss=0.08847, avg_loss=0.08625, mel_loss=0.03832, linear_loss=0.05015]
[2020-05-12 13:44:22.595]  Step 161467  [3.575 sec/step, loss=0.09014, avg_loss=0.08633, mel_loss=0.03978, linear_loss=0.05036]
[2020-05-12 13:44:23.268]  Step 161468  [3.564 sec/step, loss=0.06909, avg_loss=0.08616, mel_loss=0.02947, linear_loss=0.03962]
[2020-05-12 13:44:25.238]  Step 161469  [3.554 sec/step, loss=0.08611, avg_loss=0.08609, mel_loss=0.03730, linear_loss=0.04880]
[2020-05-12 13:44:28.669]  Step 161470  [3.569 sec/step, loss=0.09328, avg_loss=0.08617, mel_loss=0.04100, linear_loss=0.05228]
[2020-05-12 13:44:34.024]  Step 161471  [3.602 sec/step, loss=0.09363, avg_loss=0.08622, mel_loss=0.04177, linear_loss=0.05187]
[2020-05-12 13:44:36.363]  Step 161472  [3.604 sec/step, loss=0.08806, avg_loss=0.08621, mel_loss=0.03854, linear_loss=0.04952]
[2020-05-12 13:44:40.623]  Step 161473  [3.636 sec/step, loss=0.09342, avg_loss=0.08635, mel_loss=0.04166, linear_loss=0.05176]
[2020-05-12 13:44:43.812]  Step 161474  [3.618 sec/step, loss=0.09160, avg_loss=0.08633, mel_loss=0.04040, linear_loss=0.05120]
[2020-05-12 13:45:23.362]  Generated 32 batches of size 32 in 66.386 sec
[2020-05-12 13:45:24.780]  Step 161475  [4.010 sec/step, loss=0.08548, avg_loss=0.08638, mel_loss=0.03696, linear_loss=0.04851]
[2020-05-12 13:45:25.340]  Step 161476  [3.997 sec/step, loss=0.07018, avg_loss=0.08622, mel_loss=0.03010, linear_loss=0.04008]
[2020-05-12 13:45:39.863]  Step 161477  [4.106 sec/step, loss=0.07177, avg_loss=0.08598, mel_loss=0.03344, linear_loss=0.03833]
[2020-05-12 13:45:40.628]  Step 161478  [4.104 sec/step, loss=0.07213, avg_loss=0.08593, mel_loss=0.03037, linear_loss=0.04176]
[2020-05-12 13:45:41.742]  Step 161479  [4.070 sec/step, loss=0.08044, avg_loss=0.08580, mel_loss=0.03394, linear_loss=0.04650]
[2020-05-12 13:45:46.735]  Step 161480  [4.091 sec/step, loss=0.09313, avg_loss=0.08581, mel_loss=0.04162, linear_loss=0.05151]
[2020-05-12 13:45:51.303]  Step 161481  [4.128 sec/step, loss=0.09452, avg_loss=0.08600, mel_loss=0.04201, linear_loss=0.05251]
[2020-05-12 13:45:52.316]  Step 161482  [4.123 sec/step, loss=0.08020, avg_loss=0.08595, mel_loss=0.03428, linear_loss=0.04592]
[2020-05-12 13:45:54.231]  Step 161483  [3.570 sec/step, loss=0.08525, avg_loss=0.08592, mel_loss=0.03669, linear_loss=0.04856]
[2020-05-12 13:45:57.401]  Step 161484  [3.534 sec/step, loss=0.09168, avg_loss=0.08589, mel_loss=0.04032, linear_loss=0.05135]
[2020-05-12 13:46:00.816]  Step 161485  [3.539 sec/step, loss=0.09281, avg_loss=0.08591, mel_loss=0.04090, linear_loss=0.05191]
[2020-05-12 13:46:04.287]  Step 161486  [3.560 sec/step, loss=0.09091, avg_loss=0.08598, mel_loss=0.03981, linear_loss=0.05111]
[2020-05-12 13:46:08.665]  Step 161487  [3.583 sec/step, loss=0.09461, avg_loss=0.08604, mel_loss=0.04226, linear_loss=0.05235]
[2020-05-12 13:46:10.424]  Step 161488  [3.590 sec/step, loss=0.08636, avg_loss=0.08610, mel_loss=0.03688, linear_loss=0.04948]
[2020-05-12 13:46:14.194]  Step 161489  [3.592 sec/step, loss=0.09290, avg_loss=0.08609, mel_loss=0.04129, linear_loss=0.05161]
[2020-05-12 13:46:15.511]  Step 161490  [3.595 sec/step, loss=0.08208, avg_loss=0.08612, mel_loss=0.03499, linear_loss=0.04709]
[2020-05-12 13:46:22.467]  Step 161491  [3.608 sec/step, loss=0.09416, avg_loss=0.08611, mel_loss=0.04254, linear_loss=0.05162]
[2020-05-12 13:46:24.206]  Step 161492  [3.608 sec/step, loss=0.08612, avg_loss=0.08610, mel_loss=0.03716, linear_loss=0.04896]
[2020-05-12 13:46:28.393]  Step 161493  [3.622 sec/step, loss=0.09202, avg_loss=0.08613, mel_loss=0.04060, linear_loss=0.05142]
[2020-05-12 13:46:31.265]  Step 161494  [3.616 sec/step, loss=0.09032, avg_loss=0.08612, mel_loss=0.03977, linear_loss=0.05055]
[2020-05-12 13:46:32.851]  Step 161495  [3.620 sec/step, loss=0.08444, avg_loss=0.08618, mel_loss=0.03618, linear_loss=0.04826]
[2020-05-12 13:46:34.890]  Step 161496  [3.588 sec/step, loss=0.08664, avg_loss=0.08611, mel_loss=0.03756, linear_loss=0.04908]
[2020-05-12 13:46:37.606]  Step 161497  [3.595 sec/step, loss=0.08889, avg_loss=0.08612, mel_loss=0.03886, linear_loss=0.05003]
[2020-05-12 13:46:39.772]  Step 161498  [3.595 sec/step, loss=0.08865, avg_loss=0.08614, mel_loss=0.03852, linear_loss=0.05013]
[2020-05-12 13:46:40.577]  Step 161499  [3.595 sec/step, loss=0.07582, avg_loss=0.08620, mel_loss=0.03167, linear_loss=0.04416]
[2020-05-12 13:46:42.839]  Step 161500  [3.612 sec/step, loss=0.08709, avg_loss=0.08639, mel_loss=0.03789, linear_loss=0.04919]
[2020-05-12 13:46:42.839]  Writing summary at step: 161500
[2020-05-12 13:46:45.312]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161500
[2020-05-12 13:46:46.957]  Saving audio and alignment...
[2020-05-12 13:46:57.065]  Input: 또한 오시는 동안 심한 기류 변화로 비행기가 많이 흔들렸던 점 양해해 주시기 바랍니다~________________________________________________
[2020-05-12 13:47:06.167]  Step 161501  [3.616 sec/step, loss=0.09237, avg_loss=0.08642, mel_loss=0.04204, linear_loss=0.05033]
[2020-05-12 13:47:11.862]  Step 161502  [3.659 sec/step, loss=0.09335, avg_loss=0.08654, mel_loss=0.04180, linear_loss=0.05154]
[2020-05-12 13:47:12.869]  Step 161503  [3.654 sec/step, loss=0.07690, avg_loss=0.08647, mel_loss=0.03227, linear_loss=0.04463]
[2020-05-12 13:47:14.230]  Step 161504  [3.660 sec/step, loss=0.08366, avg_loss=0.08656, mel_loss=0.03582, linear_loss=0.04784]
[2020-05-12 13:47:52.174]  Generated 32 batches of size 32 in 74.562 sec
[2020-05-12 13:47:58.062]  Step 161505  [4.056 sec/step, loss=0.09493, avg_loss=0.08658, mel_loss=0.04254, linear_loss=0.05239]
[2020-05-12 13:47:59.450]  Step 161506  [3.996 sec/step, loss=0.08064, avg_loss=0.08643, mel_loss=0.03452, linear_loss=0.04612]
[2020-05-12 13:48:02.519]  Step 161507  [4.017 sec/step, loss=0.09209, avg_loss=0.08657, mel_loss=0.04049, linear_loss=0.05160]
[2020-05-12 13:48:04.980]  Step 161508  [4.026 sec/step, loss=0.08758, avg_loss=0.08659, mel_loss=0.03797, linear_loss=0.04961]
[2020-05-12 13:48:06.148]  Step 161509  [4.000 sec/step, loss=0.08007, avg_loss=0.08646, mel_loss=0.03400, linear_loss=0.04608]
[2020-05-12 13:48:06.698]  Step 161510  [3.956 sec/step, loss=0.07066, avg_loss=0.08623, mel_loss=0.03024, linear_loss=0.04042]
[2020-05-12 13:48:11.138]  Step 161511  [3.981 sec/step, loss=0.09269, avg_loss=0.08631, mel_loss=0.04099, linear_loss=0.05171]
[2020-05-12 13:48:12.143]  Step 161512  [3.958 sec/step, loss=0.07559, avg_loss=0.08615, mel_loss=0.03211, linear_loss=0.04348]
[2020-05-12 13:48:18.721]  Step 161513  [3.970 sec/step, loss=0.09779, avg_loss=0.08618, mel_loss=0.04417, linear_loss=0.05362]
[2020-05-12 13:48:19.834]  Step 161514  [3.938 sec/step, loss=0.07954, avg_loss=0.08602, mel_loss=0.03368, linear_loss=0.04585]
[2020-05-12 13:48:27.575]  Step 161515  [4.001 sec/step, loss=0.09450, avg_loss=0.08611, mel_loss=0.04297, linear_loss=0.05153]
[2020-05-12 13:48:31.023]  Step 161516  [4.022 sec/step, loss=0.09091, avg_loss=0.08618, mel_loss=0.04012, linear_loss=0.05079]
[2020-05-12 13:48:33.634]  Step 161517  [4.019 sec/step, loss=0.08952, avg_loss=0.08618, mel_loss=0.03909, linear_loss=0.05043]
[2020-05-12 13:48:39.589]  Step 161518  [4.045 sec/step, loss=0.09390, avg_loss=0.08619, mel_loss=0.04217, linear_loss=0.05173]
[2020-05-12 13:48:53.782]  Step 161519  [4.179 sec/step, loss=0.07559, avg_loss=0.08621, mel_loss=0.03533, linear_loss=0.04025]
[2020-05-12 13:48:56.000]  Step 161520  [4.182 sec/step, loss=0.08731, avg_loss=0.08620, mel_loss=0.03793, linear_loss=0.04938]
[2020-05-12 13:48:57.927]  Step 161521  [4.177 sec/step, loss=0.08680, avg_loss=0.08617, mel_loss=0.03762, linear_loss=0.04918]
[2020-05-12 13:48:59.955]  Step 161522  [4.191 sec/step, loss=0.08669, avg_loss=0.08636, mel_loss=0.03746, linear_loss=0.04923]
[2020-05-12 13:49:03.073]  Step 161523  [4.204 sec/step, loss=0.09226, avg_loss=0.08644, mel_loss=0.04050, linear_loss=0.05176]
[2020-05-12 13:49:05.967]  Step 161524  [4.224 sec/step, loss=0.09125, avg_loss=0.08661, mel_loss=0.03997, linear_loss=0.05128]
[2020-05-12 13:49:09.616]  Step 161525  [4.192 sec/step, loss=0.09391, avg_loss=0.08662, mel_loss=0.04145, linear_loss=0.05245]
[2020-05-12 13:49:10.455]  Step 161526  [4.190 sec/step, loss=0.07140, avg_loss=0.08655, mel_loss=0.03092, linear_loss=0.04048]
[2020-05-12 13:49:15.357]  Step 161527  [4.221 sec/step, loss=0.09222, avg_loss=0.08662, mel_loss=0.04111, linear_loss=0.05111]
[2020-05-12 13:49:24.368]  Step 161528  [4.290 sec/step, loss=0.09342, avg_loss=0.08667, mel_loss=0.04273, linear_loss=0.05069]
[2020-05-12 13:49:26.052]  Step 161529  [4.257 sec/step, loss=0.08652, avg_loss=0.08660, mel_loss=0.03743, linear_loss=0.04909]
[2020-05-12 13:49:27.884]  Step 161530  [4.217 sec/step, loss=0.08509, avg_loss=0.08650, mel_loss=0.03655, linear_loss=0.04854]
[2020-05-12 13:49:32.005]  Step 161531  [4.221 sec/step, loss=0.09215, avg_loss=0.08649, mel_loss=0.04067, linear_loss=0.05149]
[2020-05-12 13:49:33.332]  Step 161532  [4.195 sec/step, loss=0.08352, avg_loss=0.08639, mel_loss=0.03581, linear_loss=0.04771]
[2020-05-12 13:49:36.785]  Step 161533  [4.143 sec/step, loss=0.09203, avg_loss=0.08636, mel_loss=0.04060, linear_loss=0.05144]
[2020-05-12 13:49:37.618]  Step 161534  [4.144 sec/step, loss=0.07528, avg_loss=0.08637, mel_loss=0.03194, linear_loss=0.04333]
[2020-05-12 13:49:38.606]  Step 161535  [4.123 sec/step, loss=0.07792, avg_loss=0.08623, mel_loss=0.03295, linear_loss=0.04496]
[2020-05-12 13:49:40.187]  Step 161536  [4.121 sec/step, loss=0.08319, avg_loss=0.08622, mel_loss=0.03596, linear_loss=0.04723]
[2020-05-12 13:49:57.724]  Generated 32 batches of size 32 in 42.361 sec
[2020-05-12 13:50:00.349]  Step 161537  [4.311 sec/step, loss=0.09060, avg_loss=0.08632, mel_loss=0.03956, linear_loss=0.05104]
[2020-05-12 13:50:01.472]  Step 161538  [4.310 sec/step, loss=0.08025, avg_loss=0.08631, mel_loss=0.03407, linear_loss=0.04618]
[2020-05-12 13:50:06.595]  Step 161539  [4.337 sec/step, loss=0.09248, avg_loss=0.08635, mel_loss=0.04113, linear_loss=0.05135]
[2020-05-12 13:50:10.853]  Step 161540  [4.346 sec/step, loss=0.09226, avg_loss=0.08636, mel_loss=0.04078, linear_loss=0.05148]
[2020-05-12 13:50:17.814]  Step 161541  [4.284 sec/step, loss=0.09562, avg_loss=0.08652, mel_loss=0.04322, linear_loss=0.05240]
[2020-05-12 13:50:21.423]  Step 161542  [4.311 sec/step, loss=0.09234, avg_loss=0.08667, mel_loss=0.04070, linear_loss=0.05164]
[2020-05-12 13:50:24.557]  Step 161543  [4.310 sec/step, loss=0.09364, avg_loss=0.08667, mel_loss=0.04110, linear_loss=0.05254]
[2020-05-12 13:50:25.948]  Step 161544  [4.297 sec/step, loss=0.08294, avg_loss=0.08660, mel_loss=0.03565, linear_loss=0.04729]
[2020-05-12 13:50:26.973]  Step 161545  [4.294 sec/step, loss=0.07743, avg_loss=0.08654, mel_loss=0.03257, linear_loss=0.04487]
[2020-05-12 13:50:28.722]  Step 161546  [4.270 sec/step, loss=0.08638, avg_loss=0.08648, mel_loss=0.03692, linear_loss=0.04946]
[2020-05-12 13:50:33.301]  Step 161547  [4.311 sec/step, loss=0.09399, avg_loss=0.08673, mel_loss=0.04190, linear_loss=0.05209]
[2020-05-12 13:50:35.431]  Step 161548  [4.267 sec/step, loss=0.08892, avg_loss=0.08668, mel_loss=0.03846, linear_loss=0.05046]
[2020-05-12 13:50:35.959]  Step 161549  [4.236 sec/step, loss=0.06985, avg_loss=0.08643, mel_loss=0.03077, linear_loss=0.03908]
[2020-05-12 13:50:37.930]  Step 161550  [4.227 sec/step, loss=0.08798, avg_loss=0.08643, mel_loss=0.03797, linear_loss=0.05000]
[2020-05-12 13:50:37.930]  Writing summary at step: 161550
[2020-05-12 13:50:40.145]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161550
[2020-05-12 13:50:41.802]  Saving audio and alignment...
[2020-05-12 13:50:47.682]  Input: 도입 부분이 확실해야 돼요 그래야만 사람의 인상이~______________________
[2020-05-12 13:50:49.044]  Step 161551  [4.099 sec/step, loss=0.08282, avg_loss=0.08652, mel_loss=0.03541, linear_loss=0.04741]
[2020-05-12 13:50:55.089]  Step 161552  [4.148 sec/step, loss=0.09244, avg_loss=0.08663, mel_loss=0.04159, linear_loss=0.05085]
[2020-05-12 13:50:55.903]  Step 161553  [4.146 sec/step, loss=0.07484, avg_loss=0.08657, mel_loss=0.03179, linear_loss=0.04304]
[2020-05-12 13:51:01.419]  Step 161554  [4.191 sec/step, loss=0.09523, avg_loss=0.08672, mel_loss=0.04266, linear_loss=0.05257]
[2020-05-12 13:51:04.904]  Step 161555  [4.208 sec/step, loss=0.09029, avg_loss=0.08676, mel_loss=0.03996, linear_loss=0.05033]
[2020-05-12 13:51:06.497]  Step 161556  [4.207 sec/step, loss=0.08561, avg_loss=0.08676, mel_loss=0.03693, linear_loss=0.04868]
[2020-05-12 13:51:14.701]  Step 161557  [4.240 sec/step, loss=0.09175, avg_loss=0.08674, mel_loss=0.04163, linear_loss=0.05012]
[2020-05-12 13:51:15.542]  Step 161558  [4.172 sec/step, loss=0.07431, avg_loss=0.08653, mel_loss=0.03180, linear_loss=0.04252]
[2020-05-12 13:51:16.778]  Step 161559  [4.176 sec/step, loss=0.08116, avg_loss=0.08662, mel_loss=0.03456, linear_loss=0.04659]
[2020-05-12 13:51:28.865]  Step 161560  [4.285 sec/step, loss=0.08734, avg_loss=0.08669, mel_loss=0.04068, linear_loss=0.04666]
[2020-05-12 13:51:31.724]  Step 161561  [4.226 sec/step, loss=0.09054, avg_loss=0.08667, mel_loss=0.03976, linear_loss=0.05079]
[2020-05-12 13:51:33.587]  Step 161562  [4.220 sec/step, loss=0.08423, avg_loss=0.08665, mel_loss=0.03634, linear_loss=0.04789]
[2020-05-12 13:51:36.152]  Step 161563  [4.187 sec/step, loss=0.08821, avg_loss=0.08659, mel_loss=0.03826, linear_loss=0.04995]
[2020-05-12 13:51:39.171]  Step 161564  [4.197 sec/step, loss=0.08991, avg_loss=0.08660, mel_loss=0.03931, linear_loss=0.05060]
[2020-05-12 13:51:40.064]  Generated 32 batches of size 32 in 25.359 sec
[2020-05-12 13:51:41.174]  Step 161565  [4.202 sec/step, loss=0.08533, avg_loss=0.08664, mel_loss=0.03654, linear_loss=0.04879]
[2020-05-12 13:51:42.056]  Step 161566  [4.189 sec/step, loss=0.07662, avg_loss=0.08652, mel_loss=0.03226, linear_loss=0.04436]
[2020-05-12 13:51:43.027]  Step 161567  [4.164 sec/step, loss=0.07963, avg_loss=0.08642, mel_loss=0.03387, linear_loss=0.04577]
[2020-05-12 13:51:44.031]  Step 161568  [4.168 sec/step, loss=0.07842, avg_loss=0.08651, mel_loss=0.03302, linear_loss=0.04540]
[2020-05-12 13:51:47.488]  Step 161569  [4.182 sec/step, loss=0.09073, avg_loss=0.08656, mel_loss=0.04017, linear_loss=0.05056]
[2020-05-12 13:51:50.376]  Step 161570  [4.177 sec/step, loss=0.09041, avg_loss=0.08653, mel_loss=0.03986, linear_loss=0.05055]
[2020-05-12 13:51:54.398]  Step 161571  [4.164 sec/step, loss=0.09361, avg_loss=0.08653, mel_loss=0.04115, linear_loss=0.05246]
[2020-05-12 13:51:56.734]  Step 161572  [4.164 sec/step, loss=0.09024, avg_loss=0.08655, mel_loss=0.03916, linear_loss=0.05108]
[2020-05-12 13:52:01.525]  Step 161573  [4.169 sec/step, loss=0.09423, avg_loss=0.08656, mel_loss=0.04198, linear_loss=0.05226]
[2020-05-12 13:52:06.836]  Step 161574  [4.190 sec/step, loss=0.09482, avg_loss=0.08659, mel_loss=0.04258, linear_loss=0.05224]
[2020-05-12 13:52:08.101]  Step 161575  [3.793 sec/step, loss=0.08121, avg_loss=0.08655, mel_loss=0.03473, linear_loss=0.04648]
[2020-05-12 13:52:14.188]  Step 161576  [3.848 sec/step, loss=0.09386, avg_loss=0.08679, mel_loss=0.04233, linear_loss=0.05153]
[2020-05-12 13:52:14.993]  Step 161577  [3.711 sec/step, loss=0.07603, avg_loss=0.08683, mel_loss=0.03186, linear_loss=0.04417]
[2020-05-12 13:52:23.901]  Step 161578  [3.793 sec/step, loss=0.09204, avg_loss=0.08703, mel_loss=0.04195, linear_loss=0.05009]
[2020-05-12 13:52:25.244]  Step 161579  [3.795 sec/step, loss=0.08343, avg_loss=0.08706, mel_loss=0.03549, linear_loss=0.04795]
[2020-05-12 13:52:26.704]  Step 161580  [3.760 sec/step, loss=0.08344, avg_loss=0.08696, mel_loss=0.03593, linear_loss=0.04751]
[2020-05-12 13:52:29.711]  Step 161581  [3.744 sec/step, loss=0.09248, avg_loss=0.08694, mel_loss=0.04068, linear_loss=0.05180]
[2020-05-12 13:52:33.960]  Step 161582  [3.776 sec/step, loss=0.09377, avg_loss=0.08708, mel_loss=0.04161, linear_loss=0.05216]
[2020-05-12 13:52:34.727]  Step 161583  [3.765 sec/step, loss=0.07175, avg_loss=0.08694, mel_loss=0.03016, linear_loss=0.04159]
[2020-05-12 13:52:37.425]  Step 161584  [3.760 sec/step, loss=0.08719, avg_loss=0.08690, mel_loss=0.03790, linear_loss=0.04929]
[2020-05-12 13:52:52.023]  Step 161585  [3.872 sec/step, loss=0.07467, avg_loss=0.08672, mel_loss=0.03472, linear_loss=0.03995]
[2020-05-12 13:52:53.933]  Step 161586  [3.856 sec/step, loss=0.08685, avg_loss=0.08667, mel_loss=0.03745, linear_loss=0.04940]
[2020-05-12 13:52:55.692]  Step 161587  [3.830 sec/step, loss=0.08608, avg_loss=0.08659, mel_loss=0.03674, linear_loss=0.04934]
[2020-05-12 13:52:57.341]  Step 161588  [3.829 sec/step, loss=0.08504, avg_loss=0.08658, mel_loss=0.03663, linear_loss=0.04841]
[2020-05-12 13:53:04.424]  Step 161589  [3.862 sec/step, loss=0.09438, avg_loss=0.08659, mel_loss=0.04274, linear_loss=0.05164]
[2020-05-12 13:53:06.616]  Step 161590  [3.871 sec/step, loss=0.08879, avg_loss=0.08666, mel_loss=0.03837, linear_loss=0.05042]
[2020-05-12 13:53:07.184]  Step 161591  [3.807 sec/step, loss=0.06681, avg_loss=0.08638, mel_loss=0.02835, linear_loss=0.03846]
[2020-05-12 13:53:10.647]  Step 161592  [3.824 sec/step, loss=0.09329, avg_loss=0.08646, mel_loss=0.04123, linear_loss=0.05206]
[2020-05-12 13:53:13.130]  Step 161593  [3.807 sec/step, loss=0.08873, avg_loss=0.08642, mel_loss=0.03858, linear_loss=0.05014]
[2020-05-12 13:53:14.249]  Step 161594  [3.790 sec/step, loss=0.07876, avg_loss=0.08631, mel_loss=0.03347, linear_loss=0.04529]
[2020-05-12 13:53:16.320]  Step 161595  [3.795 sec/step, loss=0.08756, avg_loss=0.08634, mel_loss=0.03808, linear_loss=0.04949]
[2020-05-12 13:53:17.964]  Step 161596  [3.791 sec/step, loss=0.08766, avg_loss=0.08635, mel_loss=0.03800, linear_loss=0.04966]
[2020-05-12 13:53:22.390]  Step 161597  [3.808 sec/step, loss=0.09707, avg_loss=0.08643, mel_loss=0.04326, linear_loss=0.05381]
[2020-05-12 13:53:26.054]  Step 161598  [3.823 sec/step, loss=0.09685, avg_loss=0.08651, mel_loss=0.04308, linear_loss=0.05378]
[2020-05-12 13:54:27.762]  Generated 32 batches of size 32 in 83.333 sec
[2020-05-12 13:54:31.617]  Step 161599  [4.470 sec/step, loss=0.09332, avg_loss=0.08669, mel_loss=0.04132, linear_loss=0.05199]
[2020-05-12 13:54:33.007]  Step 161600  [4.462 sec/step, loss=0.08376, avg_loss=0.08665, mel_loss=0.03592, linear_loss=0.04784]
[2020-05-12 13:54:33.008]  Writing summary at step: 161600
[2020-05-12 13:54:35.160]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161600
[2020-05-12 13:54:36.784]  Saving audio and alignment...
[2020-05-12 13:54:38.416]  Input: 예컨대~___________________________
[2020-05-12 13:54:40.900]  Step 161601  [4.395 sec/step, loss=0.08929, avg_loss=0.08662, mel_loss=0.03878, linear_loss=0.05051]
[2020-05-12 13:54:45.073]  Step 161602  [4.380 sec/step, loss=0.09211, avg_loss=0.08661, mel_loss=0.04092, linear_loss=0.05118]
[2020-05-12 13:54:48.435]  Step 161603  [4.404 sec/step, loss=0.09392, avg_loss=0.08678, mel_loss=0.04136, linear_loss=0.05256]
[2020-05-12 13:54:49.236]  Step 161604  [4.398 sec/step, loss=0.07335, avg_loss=0.08668, mel_loss=0.03098, linear_loss=0.04237]
[2020-05-12 13:54:52.694]  Step 161605  [3.994 sec/step, loss=0.09160, avg_loss=0.08665, mel_loss=0.04032, linear_loss=0.05128]
[2020-05-12 13:54:58.039]  Step 161606  [4.034 sec/step, loss=0.09308, avg_loss=0.08677, mel_loss=0.04151, linear_loss=0.05156]
[2020-05-12 13:55:01.124]  Step 161607  [4.034 sec/step, loss=0.09227, avg_loss=0.08677, mel_loss=0.04051, linear_loss=0.05176]
[2020-05-12 13:55:05.832]  Step 161608  [4.057 sec/step, loss=0.09360, avg_loss=0.08683, mel_loss=0.04142, linear_loss=0.05218]
[2020-05-12 13:55:07.498]  Step 161609  [4.062 sec/step, loss=0.08519, avg_loss=0.08688, mel_loss=0.03657, linear_loss=0.04862]
[2020-05-12 13:55:08.726]  Step 161610  [4.068 sec/step, loss=0.08183, avg_loss=0.08699, mel_loss=0.03471, linear_loss=0.04712]
[2020-05-12 13:55:17.457]  Step 161611  [4.111 sec/step, loss=0.09414, avg_loss=0.08701, mel_loss=0.04289, linear_loss=0.05126]
[2020-05-12 13:55:18.790]  Step 161612  [4.115 sec/step, loss=0.08174, avg_loss=0.08707, mel_loss=0.03532, linear_loss=0.04642]
[2020-05-12 13:55:21.054]  Step 161613  [4.071 sec/step, loss=0.08850, avg_loss=0.08698, mel_loss=0.03869, linear_loss=0.04981]
[2020-05-12 13:55:24.673]  Step 161614  [4.097 sec/step, loss=0.09319, avg_loss=0.08711, mel_loss=0.04110, linear_loss=0.05209]
[2020-05-12 13:55:26.657]  Step 161615  [4.039 sec/step, loss=0.08842, avg_loss=0.08705, mel_loss=0.03832, linear_loss=0.05011]
[2020-05-12 13:55:27.771]  Step 161616  [4.016 sec/step, loss=0.08095, avg_loss=0.08695, mel_loss=0.03427, linear_loss=0.04668]
[2020-05-12 13:55:30.634]  Step 161617  [4.018 sec/step, loss=0.09108, avg_loss=0.08697, mel_loss=0.03989, linear_loss=0.05119]
[2020-05-12 13:55:31.631]  Step 161618  [3.969 sec/step, loss=0.07609, avg_loss=0.08679, mel_loss=0.03214, linear_loss=0.04395]
[2020-05-12 13:55:34.332]  Step 161619  [3.854 sec/step, loss=0.08953, avg_loss=0.08693, mel_loss=0.03920, linear_loss=0.05034]
[2020-05-12 13:55:35.344]  Step 161620  [3.842 sec/step, loss=0.07837, avg_loss=0.08684, mel_loss=0.03329, linear_loss=0.04507]
[2020-05-12 13:55:37.128]  Step 161621  [3.840 sec/step, loss=0.08526, avg_loss=0.08683, mel_loss=0.03650, linear_loss=0.04876]
[2020-05-12 13:55:38.639]  Step 161622  [3.835 sec/step, loss=0.08344, avg_loss=0.08679, mel_loss=0.03552, linear_loss=0.04793]
[2020-05-12 13:55:39.162]  Step 161623  [3.809 sec/step, loss=0.06905, avg_loss=0.08656, mel_loss=0.03033, linear_loss=0.03871]
[2020-05-12 13:55:44.878]  Step 161624  [3.837 sec/step, loss=0.09597, avg_loss=0.08661, mel_loss=0.04335, linear_loss=0.05262]
[2020-05-12 13:55:51.705]  Step 161625  [3.869 sec/step, loss=0.09488, avg_loss=0.08662, mel_loss=0.04272, linear_loss=0.05216]
[2020-05-12 13:55:59.366]  Step 161626  [3.937 sec/step, loss=0.09588, avg_loss=0.08686, mel_loss=0.04352, linear_loss=0.05236]
[2020-05-12 13:56:00.063]  Generated 32 batches of size 32 in 25.726 sec
[2020-05-12 13:56:12.692]  Step 161627  [4.021 sec/step, loss=0.07867, avg_loss=0.08673, mel_loss=0.03652, linear_loss=0.04215]
[2020-05-12 13:56:14.676]  Step 161628  [3.951 sec/step, loss=0.08626, avg_loss=0.08666, mel_loss=0.03737, linear_loss=0.04889]
[2020-05-12 13:56:18.828]  Step 161629  [3.976 sec/step, loss=0.09323, avg_loss=0.08672, mel_loss=0.04114, linear_loss=0.05209]
[2020-05-12 13:56:26.393]  Step 161630  [4.033 sec/step, loss=0.09523, avg_loss=0.08682, mel_loss=0.04315, linear_loss=0.05209]
[2020-05-12 13:56:27.030]  Step 161631  [3.998 sec/step, loss=0.07255, avg_loss=0.08663, mel_loss=0.03150, linear_loss=0.04105]
[2020-05-12 13:56:30.547]  Step 161632  [4.020 sec/step, loss=0.09057, avg_loss=0.08670, mel_loss=0.03998, linear_loss=0.05059]
[2020-05-12 13:56:32.726]  Step 161633  [4.008 sec/step, loss=0.08901, avg_loss=0.08667, mel_loss=0.03871, linear_loss=0.05031]
[2020-05-12 13:56:33.986]  Step 161634  [4.012 sec/step, loss=0.08044, avg_loss=0.08672, mel_loss=0.03431, linear_loss=0.04613]
[2020-05-12 13:56:34.751]  Step 161635  [4.010 sec/step, loss=0.07540, avg_loss=0.08670, mel_loss=0.03204, linear_loss=0.04336]
[2020-05-12 13:56:36.655]  Step 161636  [4.013 sec/step, loss=0.08486, avg_loss=0.08671, mel_loss=0.03635, linear_loss=0.04850]
[2020-05-12 13:56:38.327]  Step 161637  [3.828 sec/step, loss=0.08668, avg_loss=0.08667, mel_loss=0.03731, linear_loss=0.04937]
[2020-05-12 13:56:44.371]  Step 161638  [3.877 sec/step, loss=0.09325, avg_loss=0.08680, mel_loss=0.04158, linear_loss=0.05167]
[2020-05-12 13:56:49.079]  Step 161639  [3.873 sec/step, loss=0.09479, avg_loss=0.08683, mel_loss=0.04242, linear_loss=0.05237]
[2020-05-12 13:56:51.581]  Step 161640  [3.855 sec/step, loss=0.08871, avg_loss=0.08679, mel_loss=0.03860, linear_loss=0.05011]
[2020-05-12 13:56:53.567]  Step 161641  [3.806 sec/step, loss=0.08680, avg_loss=0.08670, mel_loss=0.03761, linear_loss=0.04920]
[2020-05-12 13:56:55.258]  Step 161642  [3.786 sec/step, loss=0.08597, avg_loss=0.08664, mel_loss=0.03701, linear_loss=0.04896]
[2020-05-12 13:56:57.562]  Step 161643  [3.778 sec/step, loss=0.08754, avg_loss=0.08658, mel_loss=0.03798, linear_loss=0.04956]
[2020-05-12 13:57:01.256]  Step 161644  [3.801 sec/step, loss=0.09310, avg_loss=0.08668, mel_loss=0.04108, linear_loss=0.05202]
[2020-05-12 13:57:10.279]  Step 161645  [3.881 sec/step, loss=0.09409, avg_loss=0.08685, mel_loss=0.04314, linear_loss=0.05095]
[2020-05-12 13:57:11.322]  Step 161646  [3.874 sec/step, loss=0.07872, avg_loss=0.08677, mel_loss=0.03347, linear_loss=0.04525]
[2020-05-12 13:57:11.919]  Step 161647  [3.834 sec/step, loss=0.06960, avg_loss=0.08653, mel_loss=0.03032, linear_loss=0.03927]
[2020-05-12 13:57:13.508]  Step 161648  [3.829 sec/step, loss=0.08195, avg_loss=0.08646, mel_loss=0.03523, linear_loss=0.04672]
[2020-05-12 13:57:14.686]  Step 161649  [3.835 sec/step, loss=0.08165, avg_loss=0.08657, mel_loss=0.03466, linear_loss=0.04699]
[2020-05-12 13:57:19.180]  Step 161650  [3.861 sec/step, loss=0.09324, avg_loss=0.08663, mel_loss=0.04135, linear_loss=0.05189]
[2020-05-12 13:57:19.180]  Writing summary at step: 161650
[2020-05-12 13:57:22.684]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161650
[2020-05-12 13:57:24.345]  Saving audio and alignment...
[2020-05-12 13:57:42.805]  Input: 제이티비씨는 정말 아나운서를 외모가 아니라 실력 열정 방송에 대한 진심만 보고 뽑으시는 것 같아서 정말 감사드립니다~_______________________________________________
[2020-05-12 13:57:49.729]  Step 161651  [3.916 sec/step, loss=0.09371, avg_loss=0.08674, mel_loss=0.04226, linear_loss=0.05145]
[2020-05-12 13:57:52.524]  Step 161652  [3.884 sec/step, loss=0.08756, avg_loss=0.08669, mel_loss=0.03822, linear_loss=0.04934]
[2020-05-12 13:57:55.441]  Step 161653  [3.905 sec/step, loss=0.09148, avg_loss=0.08685, mel_loss=0.03996, linear_loss=0.05152]
[2020-05-12 13:57:57.504]  Step 161654  [3.870 sec/step, loss=0.08640, avg_loss=0.08676, mel_loss=0.03738, linear_loss=0.04903]
[2020-05-12 13:58:00.666]  Step 161655  [3.867 sec/step, loss=0.09385, avg_loss=0.08680, mel_loss=0.04142, linear_loss=0.05243]
[2020-05-12 13:58:01.682]  Step 161656  [3.861 sec/step, loss=0.07541, avg_loss=0.08670, mel_loss=0.03164, linear_loss=0.04377]
[2020-05-12 13:58:06.906]  Step 161657  [3.831 sec/step, loss=0.09471, avg_loss=0.08673, mel_loss=0.04253, linear_loss=0.05218]
[2020-05-12 13:58:08.275]  Step 161658  [3.837 sec/step, loss=0.08510, avg_loss=0.08684, mel_loss=0.03639, linear_loss=0.04870]
[2020-05-12 13:59:15.708]  Generated 32 batches of size 32 in 110.743 sec
[2020-05-12 13:59:18.827]  Step 161659  [4.530 sec/step, loss=0.09159, avg_loss=0.08694, mel_loss=0.04024, linear_loss=0.05136]
[2020-05-12 13:59:23.481]  Step 161660  [4.456 sec/step, loss=0.09449, avg_loss=0.08701, mel_loss=0.04196, linear_loss=0.05253]
[2020-05-12 13:59:26.093]  Step 161661  [4.453 sec/step, loss=0.08982, avg_loss=0.08700, mel_loss=0.03937, linear_loss=0.05045]
[2020-05-12 13:59:28.159]  Step 161662  [4.455 sec/step, loss=0.08905, avg_loss=0.08705, mel_loss=0.03851, linear_loss=0.05054]
[2020-05-12 13:59:29.601]  Step 161663  [4.444 sec/step, loss=0.08281, avg_loss=0.08700, mel_loss=0.03547, linear_loss=0.04734]
[2020-05-12 13:59:35.214]  Step 161664  [4.470 sec/step, loss=0.09455, avg_loss=0.08704, mel_loss=0.04250, linear_loss=0.05205]
[2020-05-12 13:59:36.356]  Step 161665  [4.461 sec/step, loss=0.07860, avg_loss=0.08698, mel_loss=0.03310, linear_loss=0.04551]
[2020-05-12 13:59:39.657]  Step 161666  [4.485 sec/step, loss=0.09111, avg_loss=0.08712, mel_loss=0.03998, linear_loss=0.05113]
[2020-05-12 13:59:41.037]  Step 161667  [4.490 sec/step, loss=0.08255, avg_loss=0.08715, mel_loss=0.03534, linear_loss=0.04721]
[2020-05-12 13:59:45.079]  Step 161668  [4.520 sec/step, loss=0.09353, avg_loss=0.08730, mel_loss=0.04130, linear_loss=0.05224]
[2020-05-12 13:59:48.549]  Step 161669  [4.520 sec/step, loss=0.09082, avg_loss=0.08730, mel_loss=0.03989, linear_loss=0.05092]
[2020-05-12 13:59:50.299]  Step 161670  [4.509 sec/step, loss=0.08562, avg_loss=0.08726, mel_loss=0.03690, linear_loss=0.04872]
[2020-05-12 13:59:51.923]  Step 161671  [4.485 sec/step, loss=0.08497, avg_loss=0.08717, mel_loss=0.03675, linear_loss=0.04821]
[2020-05-12 13:59:52.800]  Step 161672  [4.470 sec/step, loss=0.06995, avg_loss=0.08697, mel_loss=0.02965, linear_loss=0.04030]
[2020-05-12 13:59:57.896]  Step 161673  [4.473 sec/step, loss=0.09210, avg_loss=0.08694, mel_loss=0.04120, linear_loss=0.05090]
[2020-05-12 14:00:00.363]  Step 161674  [4.445 sec/step, loss=0.08779, avg_loss=0.08687, mel_loss=0.03815, linear_loss=0.04964]
[2020-05-12 14:00:02.562]  Step 161675  [4.454 sec/step, loss=0.08756, avg_loss=0.08694, mel_loss=0.03816, linear_loss=0.04940]
[2020-05-12 14:00:03.616]  Step 161676  [4.404 sec/step, loss=0.07929, avg_loss=0.08679, mel_loss=0.03378, linear_loss=0.04551]
[2020-05-12 14:00:09.813]  Step 161677  [4.458 sec/step, loss=0.09266, avg_loss=0.08696, mel_loss=0.04179, linear_loss=0.05087]
[2020-05-12 14:00:10.620]  Step 161678  [4.377 sec/step, loss=0.07391, avg_loss=0.08678, mel_loss=0.03115, linear_loss=0.04277]
[2020-05-12 14:00:11.185]  Step 161679  [4.369 sec/step, loss=0.06536, avg_loss=0.08660, mel_loss=0.02844, linear_loss=0.03692]
[2020-05-12 14:00:12.063]  Step 161680  [4.363 sec/step, loss=0.07912, avg_loss=0.08655, mel_loss=0.03306, linear_loss=0.04606]
[2020-05-12 14:00:20.478]  Step 161681  [4.417 sec/step, loss=0.09352, avg_loss=0.08656, mel_loss=0.04237, linear_loss=0.05115]
[2020-05-12 14:00:24.117]  Step 161682  [4.411 sec/step, loss=0.09429, avg_loss=0.08657, mel_loss=0.04180, linear_loss=0.05249]
[2020-05-12 14:00:26.002]  Step 161683  [4.422 sec/step, loss=0.08529, avg_loss=0.08670, mel_loss=0.03687, linear_loss=0.04842]
[2020-05-12 14:00:34.334]  Step 161684  [4.479 sec/step, loss=0.09664, avg_loss=0.08680, mel_loss=0.04383, linear_loss=0.05281]
[2020-05-12 14:00:35.281]  Step 161685  [4.342 sec/step, loss=0.07901, avg_loss=0.08684, mel_loss=0.03355, linear_loss=0.04545]
[2020-05-12 14:00:38.201]  Step 161686  [4.352 sec/step, loss=0.09012, avg_loss=0.08688, mel_loss=0.03956, linear_loss=0.05056]
[2020-05-12 14:00:39.444]  Step 161687  [4.347 sec/step, loss=0.08091, avg_loss=0.08682, mel_loss=0.03456, linear_loss=0.04635]
[2020-05-12 14:00:41.451]  Step 161688  [4.351 sec/step, loss=0.08614, avg_loss=0.08683, mel_loss=0.03722, linear_loss=0.04892]
[2020-05-12 14:00:45.621]  Step 161689  [4.321 sec/step, loss=0.09279, avg_loss=0.08682, mel_loss=0.04120, linear_loss=0.05158]
[2020-05-12 14:00:58.093]  Step 161690  [4.424 sec/step, loss=0.07970, avg_loss=0.08673, mel_loss=0.03676, linear_loss=0.04295]
[2020-05-12 14:01:11.742]  Generated 32 batches of size 32 in 51.258 sec
[2020-05-12 14:01:13.418]  Step 161691  [4.572 sec/step, loss=0.08547, avg_loss=0.08691, mel_loss=0.03691, linear_loss=0.04856]
[2020-05-12 14:01:15.564]  Step 161692  [4.559 sec/step, loss=0.08879, avg_loss=0.08687, mel_loss=0.03855, linear_loss=0.05023]
[2020-05-12 14:01:18.463]  Step 161693  [4.563 sec/step, loss=0.08980, avg_loss=0.08688, mel_loss=0.03943, linear_loss=0.05037]
[2020-05-12 14:01:19.021]  Step 161694  [4.557 sec/step, loss=0.06573, avg_loss=0.08675, mel_loss=0.02842, linear_loss=0.03731]
[2020-05-12 14:01:22.833]  Step 161695  [4.575 sec/step, loss=0.09197, avg_loss=0.08679, mel_loss=0.04056, linear_loss=0.05140]
[2020-05-12 14:01:24.187]  Step 161696  [4.572 sec/step, loss=0.08168, avg_loss=0.08673, mel_loss=0.03471, linear_loss=0.04697]
[2020-05-12 14:01:28.505]  Step 161697  [4.571 sec/step, loss=0.09347, avg_loss=0.08670, mel_loss=0.04160, linear_loss=0.05187]
[2020-05-12 14:01:41.833]  Step 161698  [4.667 sec/step, loss=0.08200, avg_loss=0.08655, mel_loss=0.03827, linear_loss=0.04373]
[2020-05-12 14:01:43.738]  Step 161699  [4.031 sec/step, loss=0.08446, avg_loss=0.08646, mel_loss=0.03647, linear_loss=0.04799]
[2020-05-12 14:01:47.239]  Step 161700  [4.052 sec/step, loss=0.09251, avg_loss=0.08655, mel_loss=0.04087, linear_loss=0.05165]
[2020-05-12 14:01:47.239]  Writing summary at step: 161700
[2020-05-12 14:01:48.585]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161700
[2020-05-12 14:01:50.317]  Saving audio and alignment...
[2020-05-12 14:01:56.237]  Input: 대본에도 기호로 적용해서 그걸 잘 지키기만 한다면~_____________________
[2020-05-12 14:01:58.074]  Step 161701  [4.045 sec/step, loss=0.08580, avg_loss=0.08651, mel_loss=0.03667, linear_loss=0.04913]
[2020-05-12 14:02:01.486]  Step 161702  [4.038 sec/step, loss=0.09341, avg_loss=0.08653, mel_loss=0.04122, linear_loss=0.05219]
[2020-05-12 14:02:09.010]  Step 161703  [4.079 sec/step, loss=0.09308, avg_loss=0.08652, mel_loss=0.04219, linear_loss=0.05088]
[2020-05-12 14:02:15.702]  Step 161704  [4.138 sec/step, loss=0.09305, avg_loss=0.08671, mel_loss=0.04192, linear_loss=0.05113]
[2020-05-12 14:02:16.703]  Step 161705  [4.114 sec/step, loss=0.08058, avg_loss=0.08660, mel_loss=0.03413, linear_loss=0.04645]
[2020-05-12 14:02:19.943]  Step 161706  [4.093 sec/step, loss=0.09199, avg_loss=0.08659, mel_loss=0.04031, linear_loss=0.05169]
[2020-05-12 14:02:25.875]  Step 161707  [4.121 sec/step, loss=0.09325, avg_loss=0.08660, mel_loss=0.04180, linear_loss=0.05145]
[2020-05-12 14:02:28.187]  Step 161708  [4.097 sec/step, loss=0.08844, avg_loss=0.08655, mel_loss=0.03869, linear_loss=0.04975]
[2020-05-12 14:02:29.580]  Step 161709  [4.094 sec/step, loss=0.08355, avg_loss=0.08654, mel_loss=0.03593, linear_loss=0.04762]
[2020-05-12 14:02:31.621]  Step 161710  [4.102 sec/step, loss=0.08570, avg_loss=0.08657, mel_loss=0.03712, linear_loss=0.04858]
[2020-05-12 14:02:32.518]  Step 161711  [4.024 sec/step, loss=0.07707, avg_loss=0.08640, mel_loss=0.03247, linear_loss=0.04460]
[2020-05-12 14:02:37.131]  Step 161712  [4.057 sec/step, loss=0.09275, avg_loss=0.08651, mel_loss=0.04139, linear_loss=0.05136]
[2020-05-12 14:02:46.426]  Step 161713  [4.127 sec/step, loss=0.09427, avg_loss=0.08657, mel_loss=0.04305, linear_loss=0.05121]
[2020-05-12 14:02:50.798]  Step 161714  [4.135 sec/step, loss=0.08981, avg_loss=0.08654, mel_loss=0.03943, linear_loss=0.05038]
[2020-05-12 14:02:56.799]  Step 161715  [4.175 sec/step, loss=0.09288, avg_loss=0.08658, mel_loss=0.04129, linear_loss=0.05160]
[2020-05-12 14:02:58.320]  Step 161716  [4.179 sec/step, loss=0.08281, avg_loss=0.08660, mel_loss=0.03549, linear_loss=0.04732]
[2020-05-12 14:02:59.146]  Step 161717  [4.159 sec/step, loss=0.07306, avg_loss=0.08642, mel_loss=0.03091, linear_loss=0.04215]
[2020-05-12 14:02:59.988]  Step 161718  [4.157 sec/step, loss=0.07353, avg_loss=0.08639, mel_loss=0.03142, linear_loss=0.04211]
[2020-05-12 14:03:02.560]  Step 161719  [4.156 sec/step, loss=0.08785, avg_loss=0.08638, mel_loss=0.03802, linear_loss=0.04983]
[2020-05-12 14:03:03.676]  Step 161720  [4.157 sec/step, loss=0.07949, avg_loss=0.08639, mel_loss=0.03378, linear_loss=0.04571]
[2020-05-12 14:03:32.750]  Generated 32 batches of size 32 in 60.226 sec
[2020-05-12 14:03:37.603]  Step 161721  [4.478 sec/step, loss=0.09380, avg_loss=0.08647, mel_loss=0.04144, linear_loss=0.05236]
[2020-05-12 14:03:40.157]  Step 161722  [4.489 sec/step, loss=0.08818, avg_loss=0.08652, mel_loss=0.03837, linear_loss=0.04981]
[2020-05-12 14:03:48.845]  Step 161723  [4.570 sec/step, loss=0.09072, avg_loss=0.08674, mel_loss=0.04112, linear_loss=0.04959]
[2020-05-12 14:03:50.869]  Step 161724  [4.533 sec/step, loss=0.08698, avg_loss=0.08665, mel_loss=0.03772, linear_loss=0.04925]
[2020-05-12 14:03:54.182]  Step 161725  [4.498 sec/step, loss=0.09042, avg_loss=0.08660, mel_loss=0.03978, linear_loss=0.05064]
[2020-05-12 14:03:54.996]  Step 161726  [4.430 sec/step, loss=0.07420, avg_loss=0.08639, mel_loss=0.03116, linear_loss=0.04304]
[2020-05-12 14:03:55.804]  Step 161727  [4.305 sec/step, loss=0.06916, avg_loss=0.08629, mel_loss=0.02915, linear_loss=0.04001]
[2020-05-12 14:03:58.233]  Step 161728  [4.309 sec/step, loss=0.09009, avg_loss=0.08633, mel_loss=0.03914, linear_loss=0.05095]
[2020-05-12 14:04:01.723]  Step 161729  [4.302 sec/step, loss=0.09040, avg_loss=0.08630, mel_loss=0.03988, linear_loss=0.05052]
[2020-05-12 14:04:05.926]  Step 161730  [4.269 sec/step, loss=0.09200, avg_loss=0.08627, mel_loss=0.04075, linear_loss=0.05125]
[2020-05-12 14:04:06.499]  Step 161731  [4.268 sec/step, loss=0.06882, avg_loss=0.08623, mel_loss=0.02974, linear_loss=0.03907]
[2020-05-12 14:04:10.142]  Step 161732  [4.269 sec/step, loss=0.09371, avg_loss=0.08626, mel_loss=0.04148, linear_loss=0.05222]
[2020-05-12 14:04:16.412]  Step 161733  [4.310 sec/step, loss=0.09525, avg_loss=0.08633, mel_loss=0.04292, linear_loss=0.05233]
[2020-05-12 14:04:18.532]  Step 161734  [4.319 sec/step, loss=0.08866, avg_loss=0.08641, mel_loss=0.03851, linear_loss=0.05016]
[2020-05-12 14:04:21.394]  Step 161735  [4.340 sec/step, loss=0.08908, avg_loss=0.08655, mel_loss=0.03928, linear_loss=0.04980]
[2020-05-12 14:04:35.465]  Step 161736  [4.462 sec/step, loss=0.07378, avg_loss=0.08643, mel_loss=0.03459, linear_loss=0.03919]
[2020-05-12 14:04:37.116]  Step 161737  [4.461 sec/step, loss=0.08328, avg_loss=0.08640, mel_loss=0.03607, linear_loss=0.04721]
[2020-05-12 14:04:38.480]  Step 161738  [4.415 sec/step, loss=0.08196, avg_loss=0.08629, mel_loss=0.03514, linear_loss=0.04682]
[2020-05-12 14:04:39.486]  Step 161739  [4.378 sec/step, loss=0.07789, avg_loss=0.08612, mel_loss=0.03272, linear_loss=0.04517]
[2020-05-12 14:04:45.187]  Step 161740  [4.410 sec/step, loss=0.09375, avg_loss=0.08617, mel_loss=0.04205, linear_loss=0.05170]
[2020-05-12 14:04:52.625]  Step 161741  [4.464 sec/step, loss=0.09715, avg_loss=0.08627, mel_loss=0.04395, linear_loss=0.05320]
[2020-05-12 14:04:54.400]  Step 161742  [4.465 sec/step, loss=0.08619, avg_loss=0.08627, mel_loss=0.03681, linear_loss=0.04938]
[2020-05-12 14:04:55.805]  Step 161743  [4.456 sec/step, loss=0.08330, avg_loss=0.08623, mel_loss=0.03571, linear_loss=0.04759]
[2020-05-12 14:04:56.838]  Step 161744  [4.429 sec/step, loss=0.07816, avg_loss=0.08608, mel_loss=0.03311, linear_loss=0.04505]
[2020-05-12 14:04:59.047]  Step 161745  [4.361 sec/step, loss=0.08799, avg_loss=0.08602, mel_loss=0.03838, linear_loss=0.04961]
[2020-05-12 14:05:04.394]  Step 161746  [4.404 sec/step, loss=0.09384, avg_loss=0.08617, mel_loss=0.04146, linear_loss=0.05238]
[2020-05-12 14:05:05.529]  Step 161747  [4.410 sec/step, loss=0.08198, avg_loss=0.08630, mel_loss=0.03456, linear_loss=0.04743]
[2020-05-12 14:05:07.220]  Step 161748  [4.411 sec/step, loss=0.08745, avg_loss=0.08635, mel_loss=0.03769, linear_loss=0.04976]
[2020-05-12 14:05:10.279]  Step 161749  [4.429 sec/step, loss=0.09187, avg_loss=0.08645, mel_loss=0.04044, linear_loss=0.05143]
[2020-05-12 14:05:11.524]  Step 161750  [4.397 sec/step, loss=0.08001, avg_loss=0.08632, mel_loss=0.03441, linear_loss=0.04560]
[2020-05-12 14:05:11.524]  Writing summary at step: 161750
[2020-05-12 14:05:16.732]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161750
[2020-05-12 14:05:18.408]  Saving audio and alignment...
[2020-05-12 14:05:21.979]  Input: 정도로 이게 좋은 말이라고 할 수 있을까요~
[2020-05-12 14:05:48.754]  Generated 32 batches of size 32 in 52.943 sec
[2020-05-12 14:05:51.014]  Step 161751  [4.618 sec/step, loss=0.08810, avg_loss=0.08627, mel_loss=0.03822, linear_loss=0.04989]
[2020-05-12 14:05:54.530]  Step 161752  [4.625 sec/step, loss=0.09223, avg_loss=0.08631, mel_loss=0.04072, linear_loss=0.05151]
[2020-05-12 14:05:55.412]  Step 161753  [4.605 sec/step, loss=0.07719, avg_loss=0.08617, mel_loss=0.03210, linear_loss=0.04509]
[2020-05-12 14:06:02.985]  Step 161754  [4.660 sec/step, loss=0.09497, avg_loss=0.08626, mel_loss=0.04315, linear_loss=0.05182]
[2020-05-12 14:06:08.610]  Step 161755  [4.685 sec/step, loss=0.09559, avg_loss=0.08627, mel_loss=0.04275, linear_loss=0.05284]
[2020-05-12 14:06:09.809]  Step 161756  [4.686 sec/step, loss=0.08163, avg_loss=0.08634, mel_loss=0.03482, linear_loss=0.04680]
[2020-05-12 14:06:11.276]  Step 161757  [4.649 sec/step, loss=0.08258, avg_loss=0.08621, mel_loss=0.03536, linear_loss=0.04723]
[2020-05-12 14:06:12.987]  Step 161758  [4.652 sec/step, loss=0.08633, avg_loss=0.08623, mel_loss=0.03716, linear_loss=0.04917]
[2020-05-12 14:06:14.984]  Step 161759  [3.967 sec/step, loss=0.08893, avg_loss=0.08620, mel_loss=0.03844, linear_loss=0.05049]
[2020-05-12 14:06:21.096]  Step 161760  [3.981 sec/step, loss=0.09432, avg_loss=0.08620, mel_loss=0.04247, linear_loss=0.05185]
[2020-05-12 14:06:35.561]  Step 161761  [4.100 sec/step, loss=0.07380, avg_loss=0.08604, mel_loss=0.03446, linear_loss=0.03934]
[2020-05-12 14:06:36.591]  Step 161762  [4.090 sec/step, loss=0.07938, avg_loss=0.08594, mel_loss=0.03365, linear_loss=0.04574]
[2020-05-12 14:06:37.353]  Step 161763  [4.083 sec/step, loss=0.07359, avg_loss=0.08585, mel_loss=0.03125, linear_loss=0.04234]
[2020-05-12 14:06:41.053]  Step 161764  [4.064 sec/step, loss=0.09420, avg_loss=0.08585, mel_loss=0.04166, linear_loss=0.05254]
[2020-05-12 14:06:43.850]  Step 161765  [4.080 sec/step, loss=0.09023, avg_loss=0.08596, mel_loss=0.03955, linear_loss=0.05068]
[2020-05-12 14:06:44.664]  Step 161766  [4.055 sec/step, loss=0.07391, avg_loss=0.08579, mel_loss=0.03132, linear_loss=0.04259]
[2020-05-12 14:06:47.766]  Step 161767  [4.072 sec/step, loss=0.09271, avg_loss=0.08589, mel_loss=0.04089, linear_loss=0.05182]
[2020-05-12 14:06:49.563]  Step 161768  [4.050 sec/step, loss=0.08618, avg_loss=0.08582, mel_loss=0.03717, linear_loss=0.04901]
[2020-05-12 14:06:52.121]  Step 161769  [4.041 sec/step, loss=0.08757, avg_loss=0.08579, mel_loss=0.03801, linear_loss=0.04956]
[2020-05-12 14:06:54.050]  Step 161770  [4.043 sec/step, loss=0.08691, avg_loss=0.08580, mel_loss=0.03758, linear_loss=0.04933]
[2020-05-12 14:07:03.085]  Step 161771  [4.117 sec/step, loss=0.09398, avg_loss=0.08589, mel_loss=0.04301, linear_loss=0.05097]
[2020-05-12 14:07:04.560]  Step 161772  [4.123 sec/step, loss=0.08185, avg_loss=0.08601, mel_loss=0.03507, linear_loss=0.04678]
[2020-05-12 14:07:09.872]  Step 161773  [4.125 sec/step, loss=0.09545, avg_loss=0.08604, mel_loss=0.04261, linear_loss=0.05284]
[2020-05-12 14:07:13.341]  Step 161774  [4.135 sec/step, loss=0.09147, avg_loss=0.08608, mel_loss=0.04042, linear_loss=0.05105]
[2020-05-12 14:07:16.330]  Step 161775  [4.143 sec/step, loss=0.09192, avg_loss=0.08612, mel_loss=0.04031, linear_loss=0.05161]
[2020-05-12 14:07:17.479]  Step 161776  [4.144 sec/step, loss=0.07846, avg_loss=0.08611, mel_loss=0.03332, linear_loss=0.04515]
[2020-05-12 14:07:21.912]  Step 161777  [4.126 sec/step, loss=0.09413, avg_loss=0.08613, mel_loss=0.04188, linear_loss=0.05225]
[2020-05-12 14:07:26.249]  Step 161778  [4.161 sec/step, loss=0.09160, avg_loss=0.08630, mel_loss=0.04044, linear_loss=0.05117]
[2020-05-12 14:07:26.854]  Step 161779  [4.162 sec/step, loss=0.06612, avg_loss=0.08631, mel_loss=0.02883, linear_loss=0.03728]
[2020-05-12 14:07:28.621]  Step 161780  [4.171 sec/step, loss=0.08301, avg_loss=0.08635, mel_loss=0.03580, linear_loss=0.04721]
[2020-05-12 14:07:33.491]  Step 161781  [4.135 sec/step, loss=0.09350, avg_loss=0.08635, mel_loss=0.04148, linear_loss=0.05203]
[2020-05-12 14:07:35.946]  Step 161782  [4.123 sec/step, loss=0.08699, avg_loss=0.08628, mel_loss=0.03785, linear_loss=0.04914]
[2020-05-12 14:08:15.072]  Generated 32 batches of size 32 in 65.194 sec
[2020-05-12 14:08:17.124]  Step 161783  [4.516 sec/step, loss=0.08797, avg_loss=0.08630, mel_loss=0.03808, linear_loss=0.04990]
[2020-05-12 14:08:18.265]  Step 161784  [4.445 sec/step, loss=0.07985, avg_loss=0.08614, mel_loss=0.03384, linear_loss=0.04601]
[2020-05-12 14:08:26.379]  Step 161785  [4.516 sec/step, loss=0.09277, avg_loss=0.08627, mel_loss=0.04218, linear_loss=0.05059]
[2020-05-12 14:08:28.646]  Step 161786  [4.510 sec/step, loss=0.08743, avg_loss=0.08625, mel_loss=0.03827, linear_loss=0.04916]
[2020-05-12 14:08:31.920]  Step 161787  [4.530 sec/step, loss=0.09312, avg_loss=0.08637, mel_loss=0.04107, linear_loss=0.05205]
[2020-05-12 14:08:35.489]  Step 161788  [4.546 sec/step, loss=0.09344, avg_loss=0.08644, mel_loss=0.04137, linear_loss=0.05207]
[2020-05-12 14:08:36.325]  Step 161789  [4.512 sec/step, loss=0.07233, avg_loss=0.08624, mel_loss=0.03054, linear_loss=0.04179]
[2020-05-12 14:08:38.060]  Step 161790  [4.405 sec/step, loss=0.08693, avg_loss=0.08631, mel_loss=0.03730, linear_loss=0.04963]
[2020-05-12 14:08:43.183]  Step 161791  [4.303 sec/step, loss=0.09290, avg_loss=0.08638, mel_loss=0.04173, linear_loss=0.05117]
[2020-05-12 14:08:45.910]  Step 161792  [4.309 sec/step, loss=0.08924, avg_loss=0.08639, mel_loss=0.03904, linear_loss=0.05020]
[2020-05-12 14:08:47.831]  Step 161793  [4.299 sec/step, loss=0.08556, avg_loss=0.08635, mel_loss=0.03666, linear_loss=0.04890]
[2020-05-12 14:08:50.993]  Step 161794  [4.325 sec/step, loss=0.09105, avg_loss=0.08660, mel_loss=0.04012, linear_loss=0.05093]
[2020-05-12 14:09:03.011]  Step 161795  [4.407 sec/step, loss=0.08358, avg_loss=0.08652, mel_loss=0.03873, linear_loss=0.04484]
[2020-05-12 14:09:04.317]  Step 161796  [4.406 sec/step, loss=0.08104, avg_loss=0.08651, mel_loss=0.03492, linear_loss=0.04613]
[2020-05-12 14:09:05.068]  Step 161797  [4.371 sec/step, loss=0.06945, avg_loss=0.08627, mel_loss=0.03005, linear_loss=0.03940]
[2020-05-12 14:09:11.944]  Step 161798  [4.306 sec/step, loss=0.09543, avg_loss=0.08640, mel_loss=0.04318, linear_loss=0.05225]
[2020-05-12 14:09:14.068]  Step 161799  [4.308 sec/step, loss=0.08811, avg_loss=0.08644, mel_loss=0.03854, linear_loss=0.04957]
[2020-05-12 14:09:18.144]  Step 161800  [4.314 sec/step, loss=0.09372, avg_loss=0.08645, mel_loss=0.04128, linear_loss=0.05244]
[2020-05-12 14:09:18.144]  Writing summary at step: 161800
[2020-05-12 14:09:20.583]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161800
[2020-05-12 14:09:22.246]  Saving audio and alignment...
[2020-05-12 14:09:24.061]  Input: 고 할수있겠죠~__
[2020-05-12 14:09:25.107]  Step 161801  [4.306 sec/step, loss=0.08033, avg_loss=0.08640, mel_loss=0.03374, linear_loss=0.04658]
[2020-05-12 14:09:26.686]  Step 161802  [4.288 sec/step, loss=0.08231, avg_loss=0.08629, mel_loss=0.03535, linear_loss=0.04696]
[2020-05-12 14:09:32.129]  Step 161803  [4.267 sec/step, loss=0.09501, avg_loss=0.08631, mel_loss=0.04262, linear_loss=0.05239]
[2020-05-12 14:09:33.208]  Step 161804  [4.211 sec/step, loss=0.07756, avg_loss=0.08615, mel_loss=0.03330, linear_loss=0.04426]
[2020-05-12 14:09:33.897]  Generated 32 batches of size 32 in 1.762 sec
[2020-05-12 14:09:35.992]  Step 161805  [4.229 sec/step, loss=0.08916, avg_loss=0.08624, mel_loss=0.03916, linear_loss=0.05000]
[2020-05-12 14:09:40.553]  Step 161806  [4.242 sec/step, loss=0.09358, avg_loss=0.08625, mel_loss=0.04182, linear_loss=0.05176]
[2020-05-12 14:09:44.627]  Step 161807  [4.224 sec/step, loss=0.09322, avg_loss=0.08625, mel_loss=0.04131, linear_loss=0.05191]
[2020-05-12 14:09:48.098]  Step 161808  [4.235 sec/step, loss=0.09050, avg_loss=0.08627, mel_loss=0.03977, linear_loss=0.05073]
[2020-05-12 14:09:49.681]  Step 161809  [4.237 sec/step, loss=0.08626, avg_loss=0.08630, mel_loss=0.03743, linear_loss=0.04883]
[2020-05-12 14:09:50.511]  Step 161810  [4.225 sec/step, loss=0.07579, avg_loss=0.08620, mel_loss=0.03193, linear_loss=0.04386]
[2020-05-12 14:09:57.059]  Step 161811  [4.281 sec/step, loss=0.09258, avg_loss=0.08636, mel_loss=0.04173, linear_loss=0.05086]
[2020-05-12 14:09:58.384]  Step 161812  [4.249 sec/step, loss=0.08257, avg_loss=0.08625, mel_loss=0.03522, linear_loss=0.04735]
[2020-05-12 14:10:12.794]  Step 161813  [4.300 sec/step, loss=0.07527, avg_loss=0.08606, mel_loss=0.03513, linear_loss=0.04013]
[2020-05-12 14:10:14.262]  Step 161814  [4.271 sec/step, loss=0.08309, avg_loss=0.08600, mel_loss=0.03540, linear_loss=0.04769]
[2020-05-12 14:10:16.848]  Step 161815  [4.236 sec/step, loss=0.08889, avg_loss=0.08596, mel_loss=0.03864, linear_loss=0.05025]
[2020-05-12 14:10:18.403]  Step 161816  [4.237 sec/step, loss=0.08568, avg_loss=0.08599, mel_loss=0.03682, linear_loss=0.04886]
[2020-05-12 14:10:21.907]  Step 161817  [4.264 sec/step, loss=0.09109, avg_loss=0.08617, mel_loss=0.03999, linear_loss=0.05110]
[2020-05-12 14:10:30.888]  Step 161818  [4.345 sec/step, loss=0.09304, avg_loss=0.08636, mel_loss=0.04263, linear_loss=0.05040]
[2020-05-12 14:10:32.938]  Step 161819  [4.340 sec/step, loss=0.08747, avg_loss=0.08636, mel_loss=0.03771, linear_loss=0.04976]
[2020-05-12 14:10:33.653]  Step 161820  [4.336 sec/step, loss=0.07425, avg_loss=0.08630, mel_loss=0.03143, linear_loss=0.04282]
[2020-05-12 14:10:40.458]  Step 161821  [4.065 sec/step, loss=0.09504, avg_loss=0.08632, mel_loss=0.04277, linear_loss=0.05227]
[2020-05-12 14:10:41.264]  Step 161822  [4.047 sec/step, loss=0.07488, avg_loss=0.08618, mel_loss=0.03132, linear_loss=0.04356]
[2020-05-12 14:10:44.228]  Step 161823  [3.990 sec/step, loss=0.09199, avg_loss=0.08620, mel_loss=0.04023, linear_loss=0.05175]
[2020-05-12 14:10:44.793]  Step 161824  [3.975 sec/step, loss=0.06743, avg_loss=0.08600, mel_loss=0.02947, linear_loss=0.03797]
[2020-05-12 14:10:50.037]  Step 161825  [3.995 sec/step, loss=0.09462, avg_loss=0.08604, mel_loss=0.04231, linear_loss=0.05232]
[2020-05-12 14:10:51.878]  Step 161826  [4.005 sec/step, loss=0.08550, avg_loss=0.08616, mel_loss=0.03681, linear_loss=0.04870]
[2020-05-12 14:10:54.704]  Step 161827  [4.025 sec/step, loss=0.08979, avg_loss=0.08636, mel_loss=0.03914, linear_loss=0.05065]
[2020-05-12 14:10:56.452]  Step 161828  [4.018 sec/step, loss=0.08586, avg_loss=0.08632, mel_loss=0.03678, linear_loss=0.04908]
[2020-05-12 14:10:57.337]  Step 161829  [3.992 sec/step, loss=0.07783, avg_loss=0.08620, mel_loss=0.03277, linear_loss=0.04506]
[2020-05-12 14:10:58.391]  Step 161830  [3.961 sec/step, loss=0.07774, avg_loss=0.08605, mel_loss=0.03304, linear_loss=0.04469]
[2020-05-12 14:10:59.646]  Step 161831  [3.967 sec/step, loss=0.08192, avg_loss=0.08618, mel_loss=0.03508, linear_loss=0.04683]
[2020-05-12 14:11:07.302]  Step 161832  [4.008 sec/step, loss=0.09479, avg_loss=0.08619, mel_loss=0.04281, linear_loss=0.05198]
[2020-05-12 14:11:12.060]  Step 161833  [3.992 sec/step, loss=0.09457, avg_loss=0.08619, mel_loss=0.04193, linear_loss=0.05264]
[2020-05-12 14:11:14.043]  Step 161834  [3.991 sec/step, loss=0.08638, avg_loss=0.08616, mel_loss=0.03748, linear_loss=0.04890]
[2020-05-12 14:11:17.232]  Step 161835  [3.994 sec/step, loss=0.09173, avg_loss=0.08619, mel_loss=0.04033, linear_loss=0.05140]
[2020-05-12 14:11:18.361]  Step 161836  [3.865 sec/step, loss=0.07860, avg_loss=0.08624, mel_loss=0.03336, linear_loss=0.04524]
[2020-05-12 14:11:22.529]  Step 161837  [3.890 sec/step, loss=0.09207, avg_loss=0.08633, mel_loss=0.04079, linear_loss=0.05129]
[2020-05-12 14:11:24.954]  Step 161838  [3.901 sec/step, loss=0.08908, avg_loss=0.08640, mel_loss=0.03863, linear_loss=0.05045]
[2020-05-12 14:11:28.684]  Step 161839  [3.928 sec/step, loss=0.09400, avg_loss=0.08656, mel_loss=0.04176, linear_loss=0.05224]
[2020-05-12 14:11:32.236]  Step 161840  [3.907 sec/step, loss=0.09304, avg_loss=0.08655, mel_loss=0.04105, linear_loss=0.05199]
[2020-05-12 14:11:34.449]  Step 161841  [3.854 sec/step, loss=0.08664, avg_loss=0.08645, mel_loss=0.03756, linear_loss=0.04909]
[2020-05-12 14:11:40.178]  Step 161842  [3.894 sec/step, loss=0.09404, avg_loss=0.08653, mel_loss=0.04231, linear_loss=0.05173]
[2020-05-12 14:11:41.520]  Step 161843  [3.893 sec/step, loss=0.08213, avg_loss=0.08651, mel_loss=0.03526, linear_loss=0.04687]
[2020-05-12 14:11:45.925]  Step 161844  [3.927 sec/step, loss=0.09447, avg_loss=0.08668, mel_loss=0.04204, linear_loss=0.05243]
[2020-05-12 14:12:13.065]  Generated 32 batches of size 32 in 55.828 sec
[2020-05-12 14:12:16.137]  Step 161845  [4.207 sec/step, loss=0.08921, avg_loss=0.08669, mel_loss=0.03930, linear_loss=0.04992]
[2020-05-12 14:12:17.316]  Step 161846  [4.165 sec/step, loss=0.08119, avg_loss=0.08656, mel_loss=0.03435, linear_loss=0.04684]
[2020-05-12 14:12:17.884]  Step 161847  [4.160 sec/step, loss=0.06856, avg_loss=0.08643, mel_loss=0.02941, linear_loss=0.03915]
[2020-05-12 14:12:20.109]  Step 161848  [4.165 sec/step, loss=0.08810, avg_loss=0.08644, mel_loss=0.03836, linear_loss=0.04974]
[2020-05-12 14:12:27.312]  Step 161849  [4.206 sec/step, loss=0.09671, avg_loss=0.08648, mel_loss=0.04390, linear_loss=0.05281]
[2020-05-12 14:12:32.880]  Step 161850  [4.250 sec/step, loss=0.09292, avg_loss=0.08661, mel_loss=0.04148, linear_loss=0.05144]
[2020-05-12 14:12:32.880]  Writing summary at step: 161850
[2020-05-12 14:12:33.906]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161850
[2020-05-12 14:12:35.521]  Saving audio and alignment...
[2020-05-12 14:12:41.708]  Input: 또한 기내에서는 보조 배터리에 사용을 자제해 주시기 바랍니다~____________________
[2020-05-12 14:12:49.731]  Step 161851  [4.039 sec/step, loss=0.09155, avg_loss=0.08665, mel_loss=0.04158, linear_loss=0.04997]
[2020-05-12 14:12:51.834]  Step 161852  [4.025 sec/step, loss=0.08772, avg_loss=0.08660, mel_loss=0.03809, linear_loss=0.04963]
[2020-05-12 14:12:53.535]  Step 161853  [4.034 sec/step, loss=0.08802, avg_loss=0.08671, mel_loss=0.03761, linear_loss=0.05040]
[2020-05-12 14:12:54.859]  Step 161854  [3.971 sec/step, loss=0.08451, avg_loss=0.08661, mel_loss=0.03594, linear_loss=0.04857]
[2020-05-12 14:12:59.612]  Step 161855  [3.962 sec/step, loss=0.09263, avg_loss=0.08658, mel_loss=0.04117, linear_loss=0.05146]
[2020-05-12 14:13:00.740]  Step 161856  [3.962 sec/step, loss=0.08187, avg_loss=0.08658, mel_loss=0.03518, linear_loss=0.04669]
[2020-05-12 14:13:03.143]  Step 161857  [3.971 sec/step, loss=0.08957, avg_loss=0.08665, mel_loss=0.03890, linear_loss=0.05067]
[2020-05-12 14:13:17.002]  Step 161858  [4.092 sec/step, loss=0.07142, avg_loss=0.08650, mel_loss=0.03325, linear_loss=0.03816]
[2020-05-12 14:13:17.909]  Step 161859  [4.082 sec/step, loss=0.07982, avg_loss=0.08641, mel_loss=0.03338, linear_loss=0.04644]
[2020-05-12 14:13:21.339]  Step 161860  [4.055 sec/step, loss=0.09170, avg_loss=0.08638, mel_loss=0.04050, linear_loss=0.05120]
[2020-05-12 14:13:25.455]  Step 161861  [3.951 sec/step, loss=0.09371, avg_loss=0.08658, mel_loss=0.04178, linear_loss=0.05193]
[2020-05-12 14:13:28.882]  Step 161862  [3.975 sec/step, loss=0.09211, avg_loss=0.08671, mel_loss=0.04055, linear_loss=0.05156]
[2020-05-12 14:13:32.538]  Step 161863  [4.004 sec/step, loss=0.09412, avg_loss=0.08691, mel_loss=0.04167, linear_loss=0.05245]
[2020-05-12 14:13:34.478]  Step 161864  [3.987 sec/step, loss=0.08756, avg_loss=0.08685, mel_loss=0.03778, linear_loss=0.04978]
[2020-05-12 14:13:37.423]  Step 161865  [3.988 sec/step, loss=0.09279, avg_loss=0.08687, mel_loss=0.04049, linear_loss=0.05229]
[2020-05-12 14:13:39.240]  Step 161866  [3.998 sec/step, loss=0.08396, avg_loss=0.08697, mel_loss=0.03624, linear_loss=0.04773]
[2020-05-12 14:13:41.766]  Step 161867  [3.992 sec/step, loss=0.08976, avg_loss=0.08694, mel_loss=0.03919, linear_loss=0.05057]
[2020-05-12 14:13:43.332]  Step 161868  [3.990 sec/step, loss=0.08516, avg_loss=0.08693, mel_loss=0.03663, linear_loss=0.04852]
[2020-05-12 14:13:49.327]  Step 161869  [4.024 sec/step, loss=0.09291, avg_loss=0.08699, mel_loss=0.04187, linear_loss=0.05104]
[2020-05-12 14:13:50.187]  Step 161870  [4.014 sec/step, loss=0.07182, avg_loss=0.08684, mel_loss=0.03042, linear_loss=0.04139]
[2020-05-12 14:13:51.725]  Step 161871  [3.939 sec/step, loss=0.08644, avg_loss=0.08676, mel_loss=0.03719, linear_loss=0.04925]
[2020-05-12 14:13:54.742]  Step 161872  [3.954 sec/step, loss=0.09375, avg_loss=0.08688, mel_loss=0.04106, linear_loss=0.05269]
[2020-05-12 14:13:56.050]  Step 161873  [3.914 sec/step, loss=0.08352, avg_loss=0.08676, mel_loss=0.03536, linear_loss=0.04816]
[2020-05-12 14:13:56.840]  Step 161874  [3.887 sec/step, loss=0.07719, avg_loss=0.08662, mel_loss=0.03242, linear_loss=0.04476]
[2020-05-12 14:14:58.715]  Generated 32 batches of size 32 in 81.287 sec
[2020-05-12 14:15:03.157]  Step 161875  [4.521 sec/step, loss=0.09530, avg_loss=0.08665, mel_loss=0.04262, linear_loss=0.05268]
[2020-05-12 14:15:09.568]  Step 161876  [4.573 sec/step, loss=0.09482, avg_loss=0.08681, mel_loss=0.04270, linear_loss=0.05211]
[2020-05-12 14:15:11.806]  Step 161877  [4.551 sec/step, loss=0.08914, avg_loss=0.08676, mel_loss=0.03884, linear_loss=0.05030]
[2020-05-12 14:15:13.191]  Step 161878  [4.522 sec/step, loss=0.08267, avg_loss=0.08668, mel_loss=0.03538, linear_loss=0.04729]
[2020-05-12 14:15:17.927]  Step 161879  [4.563 sec/step, loss=0.09343, avg_loss=0.08695, mel_loss=0.04146, linear_loss=0.05197]
[2020-05-12 14:15:22.102]  Step 161880  [4.587 sec/step, loss=0.09177, avg_loss=0.08704, mel_loss=0.04039, linear_loss=0.05138]
[2020-05-12 14:15:24.486]  Step 161881  [4.562 sec/step, loss=0.08931, avg_loss=0.08699, mel_loss=0.03878, linear_loss=0.05053]
[2020-05-12 14:15:28.113]  Step 161882  [4.574 sec/step, loss=0.09353, avg_loss=0.08706, mel_loss=0.04120, linear_loss=0.05233]
[2020-05-12 14:15:31.324]  Step 161883  [4.194 sec/step, loss=0.09200, avg_loss=0.08710, mel_loss=0.04074, linear_loss=0.05126]
[2020-05-12 14:15:32.309]  Step 161884  [4.193 sec/step, loss=0.07380, avg_loss=0.08704, mel_loss=0.03108, linear_loss=0.04273]
[2020-05-12 14:15:33.324]  Step 161885  [4.122 sec/step, loss=0.07642, avg_loss=0.08688, mel_loss=0.03231, linear_loss=0.04412]
[2020-05-12 14:15:36.178]  Step 161886  [4.128 sec/step, loss=0.09009, avg_loss=0.08690, mel_loss=0.03939, linear_loss=0.05070]
[2020-05-12 14:15:37.513]  Step 161887  [4.108 sec/step, loss=0.08099, avg_loss=0.08678, mel_loss=0.03476, linear_loss=0.04623]
[2020-05-12 14:15:39.593]  Step 161888  [4.093 sec/step, loss=0.09000, avg_loss=0.08675, mel_loss=0.03912, linear_loss=0.05088]
[2020-05-12 14:15:47.219]  Step 161889  [4.161 sec/step, loss=0.09571, avg_loss=0.08698, mel_loss=0.04333, linear_loss=0.05238]
[2020-05-12 14:15:49.957]  Step 161890  [4.171 sec/step, loss=0.08784, avg_loss=0.08699, mel_loss=0.03836, linear_loss=0.04949]
[2020-05-12 14:15:56.194]  Step 161891  [4.182 sec/step, loss=0.09372, avg_loss=0.08700, mel_loss=0.04225, linear_loss=0.05147]
[2020-05-12 14:15:58.280]  Step 161892  [4.176 sec/step, loss=0.08477, avg_loss=0.08695, mel_loss=0.03677, linear_loss=0.04800]
[2020-05-12 14:16:00.480]  Step 161893  [4.179 sec/step, loss=0.08449, avg_loss=0.08694, mel_loss=0.03630, linear_loss=0.04819]
[2020-05-12 14:16:09.579]  Step 161894  [4.238 sec/step, loss=0.09607, avg_loss=0.08699, mel_loss=0.04401, linear_loss=0.05206]
[2020-05-12 14:16:15.347]  Step 161895  [4.176 sec/step, loss=0.09527, avg_loss=0.08711, mel_loss=0.04272, linear_loss=0.05255]
[2020-05-12 14:16:17.250]  Step 161896  [4.182 sec/step, loss=0.08785, avg_loss=0.08718, mel_loss=0.03784, linear_loss=0.05001]
[2020-05-12 14:16:18.037]  Step 161897  [4.182 sec/step, loss=0.07621, avg_loss=0.08725, mel_loss=0.03220, linear_loss=0.04401]
[2020-05-12 14:16:18.681]  Step 161898  [4.120 sec/step, loss=0.07196, avg_loss=0.08701, mel_loss=0.03098, linear_loss=0.04099]
[2020-05-12 14:16:20.198]  Step 161899  [4.114 sec/step, loss=0.08230, avg_loss=0.08695, mel_loss=0.03553, linear_loss=0.04677]
[2020-05-12 14:16:23.626]  Step 161900  [4.107 sec/step, loss=0.09172, avg_loss=0.08693, mel_loss=0.04033, linear_loss=0.05139]
[2020-05-12 14:16:23.626]  Writing summary at step: 161900
[2020-05-12 14:16:32.124]  Generated 32 batches of size 32 in 14.081 sec
[2020-05-12 14:16:37.238]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161900
[2020-05-12 14:16:38.942]  Saving audio and alignment...
[2020-05-12 14:16:44.118]  Input: 그다음 정말 어려웠던 내용들에 관한 구체적인 설명~___________
[2020-05-12 14:16:44.696]  Step 161901  [4.102 sec/step, loss=0.06785, avg_loss=0.08681, mel_loss=0.02967, linear_loss=0.03817]
[2020-05-12 14:16:45.929]  Step 161902  [4.099 sec/step, loss=0.08114, avg_loss=0.08680, mel_loss=0.03456, linear_loss=0.04658]
[2020-05-12 14:16:48.000]  Step 161903  [4.065 sec/step, loss=0.08718, avg_loss=0.08672, mel_loss=0.03772, linear_loss=0.04946]
[2020-05-12 14:16:49.105]  Step 161904  [4.066 sec/step, loss=0.07933, avg_loss=0.08674, mel_loss=0.03363, linear_loss=0.04570]
[2020-05-12 14:16:52.016]  Step 161905  [4.067 sec/step, loss=0.08919, avg_loss=0.08674, mel_loss=0.03907, linear_loss=0.05013]
[2020-05-12 14:16:53.347]  Step 161906  [4.034 sec/step, loss=0.08237, avg_loss=0.08662, mel_loss=0.03528, linear_loss=0.04709]
[2020-05-12 14:16:58.980]  Step 161907  [4.050 sec/step, loss=0.09314, avg_loss=0.08662, mel_loss=0.04162, linear_loss=0.05152]
[2020-05-12 14:17:07.782]  Step 161908  [4.103 sec/step, loss=0.09271, avg_loss=0.08665, mel_loss=0.04232, linear_loss=0.05039]
[2020-05-12 14:17:11.170]  Step 161909  [4.121 sec/step, loss=0.09375, avg_loss=0.08672, mel_loss=0.04125, linear_loss=0.05250]
[2020-05-12 14:17:17.756]  Step 161910  [4.179 sec/step, loss=0.09426, avg_loss=0.08690, mel_loss=0.04242, linear_loss=0.05183]
[2020-05-12 14:17:19.513]  Step 161911  [4.131 sec/step, loss=0.08427, avg_loss=0.08682, mel_loss=0.03606, linear_loss=0.04821]
[2020-05-12 14:17:24.196]  Step 161912  [4.165 sec/step, loss=0.09474, avg_loss=0.08694, mel_loss=0.04191, linear_loss=0.05284]
[2020-05-12 14:17:27.388]  Step 161913  [4.052 sec/step, loss=0.09309, avg_loss=0.08712, mel_loss=0.04068, linear_loss=0.05241]
[2020-05-12 14:17:28.258]  Step 161914  [4.046 sec/step, loss=0.07474, avg_loss=0.08704, mel_loss=0.03141, linear_loss=0.04332]
[2020-05-12 14:17:42.901]  Step 161915  [4.167 sec/step, loss=0.07545, avg_loss=0.08690, mel_loss=0.03516, linear_loss=0.04029]
[2020-05-12 14:17:44.243]  Step 161916  [4.165 sec/step, loss=0.08353, avg_loss=0.08688, mel_loss=0.03581, linear_loss=0.04772]
[2020-05-12 14:17:49.114]  Step 161917  [4.179 sec/step, loss=0.09218, avg_loss=0.08689, mel_loss=0.04127, linear_loss=0.05091]
[2020-05-12 14:17:50.972]  Step 161918  [4.107 sec/step, loss=0.08671, avg_loss=0.08683, mel_loss=0.03740, linear_loss=0.04931]
[2020-05-12 14:17:53.479]  Step 161919  [4.112 sec/step, loss=0.08724, avg_loss=0.08683, mel_loss=0.03786, linear_loss=0.04938]
[2020-05-12 14:17:57.234]  Step 161920  [4.142 sec/step, loss=0.09262, avg_loss=0.08701, mel_loss=0.04100, linear_loss=0.05162]
[2020-05-12 14:18:04.831]  Step 161921  [4.150 sec/step, loss=0.09325, avg_loss=0.08699, mel_loss=0.04225, linear_loss=0.05100]
[2020-05-12 14:18:07.123]  Step 161922  [4.165 sec/step, loss=0.08745, avg_loss=0.08712, mel_loss=0.03811, linear_loss=0.04934]
[2020-05-12 14:18:09.224]  Step 161923  [4.156 sec/step, loss=0.08958, avg_loss=0.08709, mel_loss=0.03906, linear_loss=0.05052]
[2020-05-12 14:18:10.105]  Step 161924  [4.160 sec/step, loss=0.06806, avg_loss=0.08710, mel_loss=0.02890, linear_loss=0.03916]
[2020-05-12 14:18:11.277]  Step 161925  [4.119 sec/step, loss=0.07983, avg_loss=0.08695, mel_loss=0.03380, linear_loss=0.04603]
[2020-05-12 14:18:12.267]  Step 161926  [4.110 sec/step, loss=0.08047, avg_loss=0.08690, mel_loss=0.03385, linear_loss=0.04662]
[2020-05-12 14:18:15.926]  Step 161927  [4.119 sec/step, loss=0.09452, avg_loss=0.08695, mel_loss=0.04183, linear_loss=0.05268]
[2020-05-12 14:18:16.481]  Step 161928  [4.107 sec/step, loss=0.06745, avg_loss=0.08677, mel_loss=0.02939, linear_loss=0.03806]
[2020-05-12 14:18:17.638]  Step 161929  [4.110 sec/step, loss=0.07570, avg_loss=0.08674, mel_loss=0.03196, linear_loss=0.04374]
[2020-05-12 14:18:19.275]  Step 161930  [4.115 sec/step, loss=0.08573, avg_loss=0.08682, mel_loss=0.03706, linear_loss=0.04867]
[2020-05-12 14:18:23.545]  Step 161931  [4.146 sec/step, loss=0.09230, avg_loss=0.08693, mel_loss=0.04087, linear_loss=0.05142]
[2020-05-12 14:18:26.315]  Step 161932  [4.097 sec/step, loss=0.08975, avg_loss=0.08688, mel_loss=0.03921, linear_loss=0.05054]
[2020-05-12 14:18:27.421]  Step 161933  [4.060 sec/step, loss=0.07831, avg_loss=0.08672, mel_loss=0.03327, linear_loss=0.04503]
[2020-05-12 14:18:30.955]  Step 161934  [4.076 sec/step, loss=0.09020, avg_loss=0.08675, mel_loss=0.03996, linear_loss=0.05024]
[2020-05-12 14:18:32.464]  Step 161935  [4.059 sec/step, loss=0.08545, avg_loss=0.08669, mel_loss=0.03672, linear_loss=0.04874]
[2020-05-12 14:18:34.483]  Step 161936  [4.068 sec/step, loss=0.08725, avg_loss=0.08678, mel_loss=0.03771, linear_loss=0.04954]
[2020-05-12 14:20:00.560]  Generated 32 batches of size 32 in 104.629 sec
[2020-05-12 14:20:02.846]  Step 161937  [4.910 sec/step, loss=0.08739, avg_loss=0.08673, mel_loss=0.03806, linear_loss=0.04933]
[2020-05-12 14:20:04.618]  Step 161938  [4.903 sec/step, loss=0.08557, avg_loss=0.08670, mel_loss=0.03686, linear_loss=0.04870]
[2020-05-12 14:20:06.605]  Step 161939  [4.886 sec/step, loss=0.08495, avg_loss=0.08661, mel_loss=0.03685, linear_loss=0.04810]
[2020-05-12 14:20:08.541]  Step 161940  [4.870 sec/step, loss=0.08467, avg_loss=0.08652, mel_loss=0.03640, linear_loss=0.04827]
[2020-05-12 14:20:09.673]  Step 161941  [4.859 sec/step, loss=0.07828, avg_loss=0.08644, mel_loss=0.03318, linear_loss=0.04510]
[2020-05-12 14:20:13.933]  Step 161942  [4.844 sec/step, loss=0.09326, avg_loss=0.08643, mel_loss=0.04154, linear_loss=0.05172]
[2020-05-12 14:20:17.299]  Step 161943  [4.864 sec/step, loss=0.09112, avg_loss=0.08652, mel_loss=0.04009, linear_loss=0.05104]
[2020-05-12 14:20:18.621]  Step 161944  [4.834 sec/step, loss=0.08615, avg_loss=0.08644, mel_loss=0.03684, linear_loss=0.04931]
[2020-05-12 14:20:20.319]  Step 161945  [4.548 sec/step, loss=0.08564, avg_loss=0.08640, mel_loss=0.03687, linear_loss=0.04877]
[2020-05-12 14:20:24.868]  Step 161946  [4.582 sec/step, loss=0.09513, avg_loss=0.08654, mel_loss=0.04237, linear_loss=0.05275]
[2020-05-12 14:20:33.078]  Step 161947  [4.658 sec/step, loss=0.09357, avg_loss=0.08679, mel_loss=0.04240, linear_loss=0.05116]
[2020-05-12 14:20:34.489]  Step 161948  [4.650 sec/step, loss=0.08200, avg_loss=0.08673, mel_loss=0.03512, linear_loss=0.04687]
[2020-05-12 14:20:41.487]  Step 161949  [4.648 sec/step, loss=0.09593, avg_loss=0.08672, mel_loss=0.04340, linear_loss=0.05253]
[2020-05-12 14:20:42.737]  Step 161950  [4.605 sec/step, loss=0.08141, avg_loss=0.08661, mel_loss=0.03474, linear_loss=0.04668]
[2020-05-12 14:20:42.737]  Writing summary at step: 161950
[2020-05-12 14:20:43.542]  Saving checkpoint to: ./logs-tacotron/model.ckpt-161950
[2020-05-12 14:20:45.208]  Saving audio and alignment...
[2020-05-12 14:20:47.105]  Input: 쳐다볼 때가~_________
[2020-05-12 14:20:47.856]  Step 161951  [4.532 sec/step, loss=0.07627, avg_loss=0.08645, mel_loss=0.03230, linear_loss=0.04396]
[2020-05-12 14:20:51.600]  Step 161952  [4.549 sec/step, loss=0.09222, avg_loss=0.08650, mel_loss=0.04077, linear_loss=0.05145]
[2020-05-12 14:20:56.769]  Step 161953  [4.583 sec/step, loss=0.09426, avg_loss=0.08656, mel_loss=0.04211, linear_loss=0.05215]
[2020-05-12 14:21:09.739]  Step 161954  [4.700 sec/step, loss=0.07735, avg_loss=0.08649, mel_loss=0.03582, linear_loss=0.04154]
[2020-05-12 14:21:10.290]  Step 161955  [4.658 sec/step, loss=0.06889, avg_loss=0.08625, mel_loss=0.02997, linear_loss=0.03892]
[2020-05-12 14:21:12.424]  Step 161956  [4.668 sec/step, loss=0.08870, avg_loss=0.08632, mel_loss=0.03839, linear_loss=0.05031]
[2020-05-12 14:21:16.072]  Step 161957  [4.680 sec/step, loss=0.09332, avg_loss=0.08636, mel_loss=0.04113, linear_loss=0.05219]
[2020-05-12 14:21:17.131]  Step 161958  [4.552 sec/step, loss=0.07668, avg_loss=0.08641, mel_loss=0.03296, linear_loss=0.04372]
[2020-05-12 14:21:18.740]  Step 161959  [4.559 sec/step, loss=0.08631, avg_loss=0.08648, mel_loss=0.03732, linear_loss=0.04899]
[2020-05-12 14:21:24.210]  Step 161960  [4.580 sec/step, loss=0.09417, avg_loss=0.08650, mel_loss=0.04215, linear_loss=0.05202]
[2020-05-12 14:21:30.482]  Step 161961  [4.601 sec/step, loss=0.09211, avg_loss=0.08648, mel_loss=0.04156, linear_loss=0.05056]
[2020-05-12 14:21:32.922]  Step 161962  [4.592 sec/step, loss=0.08965, avg_loss=0.08646, mel_loss=0.03897, linear_loss=0.05068]
[2020-05-12 14:21:35.884]  Step 161963  [4.585 sec/step, loss=0.09171, avg_loss=0.08644, mel_loss=0.04023, linear_loss=0.05148]
[2020-05-12 14:21:38.721]  Step 161964  [4.594 sec/step, loss=0.09005, avg_loss=0.08646, mel_loss=0.03977, linear_loss=0.05028]
[2020-05-12 14:21:41.953]  Step 161965  [4.596 sec/step, loss=0.09171, avg_loss=0.08645, mel_loss=0.04020, linear_loss=0.05151]
[2020-05-12 14:21:44.523]  Step 161966  [4.604 sec/step, loss=0.08831, avg_loss=0.08649, mel_loss=0.03851, linear_loss=0.04980]
[2020-05-12 14:21:50.239]  Generated 32 batches of size 32 in 34.162 sec
[2020-05-12 14:21:52.167]  Step 161967  [4.655 sec/step, loss=0.08630, avg_loss=0.08646, mel_loss=0.03713, linear_loss=0.04917]
[2020-05-12 14:21:54.962]  Step 161968  [4.667 sec/step, loss=0.09149, avg_loss=0.08652, mel_loss=0.04013, linear_loss=0.05135]
[2020-05-12 14:21:56.081]  Step 161969  [4.619 sec/step, loss=0.08146, avg_loss=0.08641, mel_loss=0.03483, linear_loss=0.04663]
[2020-05-12 14:21:56.881]  Step 161970  [4.618 sec/step, loss=0.07355, avg_loss=0.08642, mel_loss=0.03073, linear_loss=0.04282]
[2020-05-12 14:22:02.075]  Step 161971  [4.655 sec/step, loss=0.09308, avg_loss=0.08649, mel_loss=0.04167, linear_loss=0.05141]
[2020-05-12 14:22:03.677]  Step 161972  [4.640 sec/step, loss=0.08603, avg_loss=0.08641, mel_loss=0.03704, linear_loss=0.04899]
[2020-05-12 14:22:18.026]  Step 161973  [4.771 sec/step, loss=0.07197, avg_loss=0.08630, mel_loss=0.03360, linear_loss=0.03837]
[2020-05-12 14:22:19.088]  Step 161974  [4.774 sec/step, loss=0.07589, avg_loss=0.08629, mel_loss=0.03217, linear_loss=0.04372]
[2020-05-12 14:22:21.266]  Step 161975  [4.132 sec/step, loss=0.08896, avg_loss=0.08622, mel_loss=0.03842, linear_loss=0.05054]
[2020-05-12 14:22:23.558]  Step 161976  [4.091 sec/step, loss=0.08807, avg_loss=0.08615, mel_loss=0.03828, linear_loss=0.04979]
[2020-05-12 14:22:26.068]  Step 161977  [4.094 sec/step, loss=0.08785, avg_loss=0.08614, mel_loss=0.03810, linear_loss=0.04975]
[2020-05-12 14:22:26.625]  Step 161978  [4.085 sec/step, loss=0.06637, avg_loss=0.08598, mel_loss=0.02872, linear_loss=0.03765]
[2020-05-12 14:22:30.102]  Step 161979  [4.073 sec/step, loss=0.09088, avg_loss=0.08595, mel_loss=0.03999, linear_loss=0.05089]
[2020-05-12 14:22:31.896]  Step 161980  [4.049 sec/step, loss=0.08609, avg_loss=0.08590, mel_loss=0.03678, linear_loss=0.04931]
[2020-05-12 14:22:35.519]  Step 161981  [4.061 sec/step, loss=0.09062, avg_loss=0.08591, mel_loss=0.03978, linear_loss=0.05084]
[2020-05-12 14:22:39.405]  Step 161982  [4.064 sec/step, loss=0.09282, avg_loss=0.08590, mel_loss=0.04089, linear_loss=0.05192]
[2020-05-12 14:22:40.374]  Step 161983  [4.042 sec/step, loss=0.07756, avg_loss=0.08576, mel_loss=0.03270, linear_loss=0.04486]
[2020-05-12 14:22:42.051]  Step 161984  [4.049 sec/step, loss=0.08382, avg_loss=0.08586, mel_loss=0.03585, linear_loss=0.04797]
[2020-05-12 14:22:46.525]  Step 161985  [4.083 sec/step, loss=0.09312, avg_loss=0.08603, mel_loss=0.04144, linear_loss=0.05168]
[2020-05-12 14:22:49.603]  Step 161986  [4.085 sec/step, loss=0.09162, avg_loss=0.08604, mel_loss=0.04028, linear_loss=0.05134]
[2020-05-12 14:22:52.330]  Step 161987  [4.099 sec/step, loss=0.08926, avg_loss=0.08612, mel_loss=0.03925, linear_loss=0.05001]
[2020-05-12 14:22:53.195]  Step 161988  [4.087 sec/step, loss=0.06945, avg_loss=0.08592, mel_loss=0.02955, linear_loss=0.03989]
[2020-05-12 14:22:54.483]  Step 161989  [4.024 sec/step, loss=0.08222, avg_loss=0.08578, mel_loss=0.03503, linear_loss=0.04719]
[2020-05-12 14:22:58.542]  Step 161990  [4.037 sec/step, loss=0.09307, avg_loss=0.08583, mel_loss=0.04099, linear_loss=0.05208]
[2020-05-12 14:23:04.126]  Step 161991  [4.030 sec/step, loss=0.09388, avg_loss=0.08584, mel_loss=0.04216, linear_loss=0.05172]
[2020-05-12 14:23:12.388]  Step 161992  [4.092 sec/step, loss=0.09287, avg_loss=0.08592, mel_loss=0.04221, linear_loss=0.05066]
[2020-05-12 14:23:14.421]  Step 161993  [4.091 sec/step, loss=0.08711, avg_loss=0.08594, mel_loss=0.03765, linear_loss=0.04946]
[2020-05-12 14:23:15.800]  Step 161994  [4.013 sec/step, loss=0.08370, avg_loss=0.08582, mel_loss=0.03585, linear_loss=0.04786]
[2020-05-12 14:23:22.165]  Step 161995  [4.019 sec/step, loss=0.09200, avg_loss=0.08579, mel_loss=0.04144, linear_loss=0.05056]
[2020-05-12 14:23:23.278]  Step 161996  [4.011 sec/step, loss=0.08128, avg_loss=0.08572, mel_loss=0.03439, linear_loss=0.04689]
[2020-05-12 14:23:27.986]  Step 161997  [4.051 sec/step, loss=0.09299, avg_loss=0.08589, mel_loss=0.04126, linear_loss=0.05173]
[2020-05-12 14:23:35.467]  Step 161998  [4.119 sec/step, loss=0.09398, avg_loss=0.08611, mel_loss=0.04242, linear_loss=0.05156]
[2020-05-12 14:23:59.042]  Generated 32 batches of size 32 in 64.554 sec
[2020-05-12 14:23:59.889]  Step 161999  [4.348 sec/step, loss=0.07546, avg_loss=0.08604, mel_loss=0.03206, linear_loss=0.04340]
[2020-05-12 14:24:00.688]  Step 162000  [4.322 sec/step, loss=0.07129, avg_loss=0.08584, mel_loss=0.03005, linear_loss=0.04124]
[2020-05-12 14:24:00.688]  Writing summary at step: 162000
[2020-05-12 14:24:02.187]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162000
[2020-05-12 14:24:03.848]  Saving audio and alignment...
[2020-05-12 14:24:06.492]  Input: 이런 거 끝까지 한번 더~________
[2020-05-12 14:24:08.329]  Step 162001  [4.334 sec/step, loss=0.08462, avg_loss=0.08600, mel_loss=0.03639, linear_loss=0.04823]
[2020-05-12 14:24:09.393]  Step 162002  [4.333 sec/step, loss=0.08010, avg_loss=0.08599, mel_loss=0.03371, linear_loss=0.04639]
[2020-05-12 14:24:11.141]  Step 162003  [4.329 sec/step, loss=0.08502, avg_loss=0.08597, mel_loss=0.03668, linear_loss=0.04833]
[2020-05-12 14:24:13.736]  Step 162004  [4.344 sec/step, loss=0.08981, avg_loss=0.08608, mel_loss=0.03906, linear_loss=0.05075]
[2020-05-12 14:24:15.356]  Step 162005  [4.331 sec/step, loss=0.08629, avg_loss=0.08605, mel_loss=0.03748, linear_loss=0.04881]
[2020-05-12 14:24:28.572]  Step 162006  [4.450 sec/step, loss=0.08337, avg_loss=0.08606, mel_loss=0.03894, linear_loss=0.04443]
[2020-05-12 14:24:31.054]  Step 162007  [4.419 sec/step, loss=0.08891, avg_loss=0.08602, mel_loss=0.03828, linear_loss=0.05063]
[2020-05-12 14:24:33.037]  Step 162008  [4.351 sec/step, loss=0.08868, avg_loss=0.08598, mel_loss=0.03861, linear_loss=0.05008]
[2020-05-12 14:24:34.016]  Step 162009  [4.326 sec/step, loss=0.08140, avg_loss=0.08585, mel_loss=0.03458, linear_loss=0.04682]
[2020-05-12 14:24:37.291]  Step 162010  [4.293 sec/step, loss=0.09257, avg_loss=0.08584, mel_loss=0.04083, linear_loss=0.05173]
[2020-05-12 14:24:41.371]  Step 162011  [4.317 sec/step, loss=0.09345, avg_loss=0.08593, mel_loss=0.04134, linear_loss=0.05211]
[2020-05-12 14:24:42.581]  Step 162012  [4.282 sec/step, loss=0.07955, avg_loss=0.08578, mel_loss=0.03396, linear_loss=0.04559]
[2020-05-12 14:24:49.762]  Step 162013  [4.322 sec/step, loss=0.09557, avg_loss=0.08580, mel_loss=0.04342, linear_loss=0.05216]
[2020-05-12 14:24:54.334]  Step 162014  [4.359 sec/step, loss=0.09283, avg_loss=0.08598, mel_loss=0.04104, linear_loss=0.05179]
[2020-05-12 14:24:59.946]  Step 162015  [4.268 sec/step, loss=0.09461, avg_loss=0.08617, mel_loss=0.04223, linear_loss=0.05237]
[2020-05-12 14:25:03.383]  Step 162016  [4.289 sec/step, loss=0.09049, avg_loss=0.08624, mel_loss=0.03984, linear_loss=0.05065]
[2020-05-12 14:25:12.234]  Step 162017  [4.329 sec/step, loss=0.09349, avg_loss=0.08626, mel_loss=0.04285, linear_loss=0.05064]
[2020-05-12 14:25:12.795]  Step 162018  [4.316 sec/step, loss=0.07015, avg_loss=0.08609, mel_loss=0.03031, linear_loss=0.03985]
[2020-05-12 14:25:17.980]  Step 162019  [4.343 sec/step, loss=0.09182, avg_loss=0.08614, mel_loss=0.04097, linear_loss=0.05084]
[2020-05-12 14:25:21.048]  Step 162020  [4.336 sec/step, loss=0.09202, avg_loss=0.08613, mel_loss=0.04042, linear_loss=0.05160]
[2020-05-12 14:25:22.046]  Step 162021  [4.270 sec/step, loss=0.07803, avg_loss=0.08598, mel_loss=0.03271, linear_loss=0.04532]
[2020-05-12 14:25:28.681]  Step 162022  [4.314 sec/step, loss=0.09519, avg_loss=0.08605, mel_loss=0.04290, linear_loss=0.05229]
[2020-05-12 14:25:31.032]  Step 162023  [4.316 sec/step, loss=0.09078, avg_loss=0.08607, mel_loss=0.03933, linear_loss=0.05145]
[2020-05-12 14:25:33.933]  Step 162024  [4.336 sec/step, loss=0.08998, avg_loss=0.08629, mel_loss=0.03930, linear_loss=0.05067]
[2020-05-12 14:25:35.895]  Step 162025  [4.344 sec/step, loss=0.08673, avg_loss=0.08635, mel_loss=0.03743, linear_loss=0.04930]
[2020-05-12 14:25:38.038]  Step 162026  [4.356 sec/step, loss=0.08915, avg_loss=0.08644, mel_loss=0.03868, linear_loss=0.05047]
[2020-05-12 14:25:41.662]  Step 162027  [4.355 sec/step, loss=0.09372, avg_loss=0.08643, mel_loss=0.04148, linear_loss=0.05223]
[2020-05-12 14:25:45.960]  Step 162028  [4.393 sec/step, loss=0.09411, avg_loss=0.08670, mel_loss=0.04159, linear_loss=0.05253]
[2020-05-12 14:26:11.995]  Generated 32 batches of size 32 in 54.010 sec
[2020-05-12 14:26:13.389]  Step 162029  [4.656 sec/step, loss=0.07975, avg_loss=0.08674, mel_loss=0.03418, linear_loss=0.04557]
[2020-05-12 14:26:13.919]  Step 162030  [4.644 sec/step, loss=0.06851, avg_loss=0.08657, mel_loss=0.03020, linear_loss=0.03831]
[2020-05-12 14:26:16.148]  Step 162031  [4.624 sec/step, loss=0.08634, avg_loss=0.08651, mel_loss=0.03763, linear_loss=0.04872]
[2020-05-12 14:26:16.953]  Step 162032  [4.604 sec/step, loss=0.07256, avg_loss=0.08634, mel_loss=0.03090, linear_loss=0.04166]
[2020-05-12 14:26:18.457]  Step 162033  [4.608 sec/step, loss=0.08387, avg_loss=0.08639, mel_loss=0.03591, linear_loss=0.04796]
[2020-05-12 14:26:31.676]  Step 162034  [4.705 sec/step, loss=0.07800, avg_loss=0.08627, mel_loss=0.03613, linear_loss=0.04187]
[2020-05-12 14:26:35.968]  Step 162035  [4.733 sec/step, loss=0.09533, avg_loss=0.08637, mel_loss=0.04267, linear_loss=0.05266]
[2020-05-12 14:26:39.050]  Step 162036  [4.744 sec/step, loss=0.09314, avg_loss=0.08643, mel_loss=0.04077, linear_loss=0.05237]
[2020-05-12 14:26:42.703]  Step 162037  [3.897 sec/step, loss=0.09394, avg_loss=0.08649, mel_loss=0.04146, linear_loss=0.05248]
[2020-05-12 14:26:44.512]  Step 162038  [3.897 sec/step, loss=0.08690, avg_loss=0.08651, mel_loss=0.03721, linear_loss=0.04969]
[2020-05-12 14:26:48.450]  Step 162039  [3.916 sec/step, loss=0.09213, avg_loss=0.08658, mel_loss=0.04074, linear_loss=0.05139]
[2020-05-12 14:26:53.900]  Step 162040  [3.952 sec/step, loss=0.09390, avg_loss=0.08667, mel_loss=0.04233, linear_loss=0.05157]
[2020-05-12 14:26:57.209]  Step 162041  [3.973 sec/step, loss=0.09356, avg_loss=0.08682, mel_loss=0.04106, linear_loss=0.05250]
[2020-05-12 14:26:58.040]  Step 162042  [3.939 sec/step, loss=0.07359, avg_loss=0.08663, mel_loss=0.03146, linear_loss=0.04213]
[2020-05-12 14:26:59.030]  Step 162043  [3.915 sec/step, loss=0.07478, avg_loss=0.08646, mel_loss=0.03153, linear_loss=0.04325]
[2020-05-12 14:26:59.983]  Step 162044  [3.912 sec/step, loss=0.08036, avg_loss=0.08641, mel_loss=0.03398, linear_loss=0.04638]
[2020-05-12 14:27:03.454]  Step 162045  [3.929 sec/step, loss=0.09024, avg_loss=0.08645, mel_loss=0.04002, linear_loss=0.05022]
[2020-05-12 14:27:11.560]  Step 162046  [3.965 sec/step, loss=0.09109, avg_loss=0.08641, mel_loss=0.04130, linear_loss=0.04979]
[2020-05-12 14:27:12.785]  Step 162047  [3.895 sec/step, loss=0.07939, avg_loss=0.08627, mel_loss=0.03396, linear_loss=0.04544]
[2020-05-12 14:27:20.003]  Step 162048  [3.953 sec/step, loss=0.09551, avg_loss=0.08640, mel_loss=0.04316, linear_loss=0.05235]
[2020-05-12 14:27:21.974]  Step 162049  [3.903 sec/step, loss=0.08684, avg_loss=0.08631, mel_loss=0.03747, linear_loss=0.04937]
[2020-05-12 14:27:25.378]  Step 162050  [3.924 sec/step, loss=0.09339, avg_loss=0.08643, mel_loss=0.04106, linear_loss=0.05233]
[2020-05-12 14:27:25.378]  Writing summary at step: 162050
[2020-05-12 14:27:28.002]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162050
[2020-05-12 14:27:29.696]  Saving audio and alignment...
[2020-05-12 14:27:32.574]  Input: 얼마 전 우리 인류가~___________
[2020-05-12 14:27:35.434]  Step 162051  [3.946 sec/step, loss=0.09049, avg_loss=0.08658, mel_loss=0.03974, linear_loss=0.05075]
[2020-05-12 14:27:41.367]  Step 162052  [3.967 sec/step, loss=0.09248, avg_loss=0.08658, mel_loss=0.04171, linear_loss=0.05077]
[2020-05-12 14:27:43.514]  Step 162053  [3.937 sec/step, loss=0.08846, avg_loss=0.08652, mel_loss=0.03815, linear_loss=0.05031]
[2020-05-12 14:27:48.754]  Step 162054  [3.860 sec/step, loss=0.09292, avg_loss=0.08668, mel_loss=0.04112, linear_loss=0.05179]
[2020-05-12 14:27:50.044]  Step 162055  [3.867 sec/step, loss=0.07911, avg_loss=0.08678, mel_loss=0.03353, linear_loss=0.04558]
[2020-05-12 14:27:51.914]  Step 162056  [3.865 sec/step, loss=0.08604, avg_loss=0.08675, mel_loss=0.03678, linear_loss=0.04926]
[2020-05-12 14:27:53.764]  Step 162057  [3.847 sec/step, loss=0.08516, avg_loss=0.08667, mel_loss=0.03644, linear_loss=0.04872]
[2020-05-12 14:27:56.148]  Step 162058  [3.860 sec/step, loss=0.08839, avg_loss=0.08679, mel_loss=0.03850, linear_loss=0.04989]
[2020-05-12 14:28:10.280]  Generated 32 batches of size 32 in 39.962 sec
[2020-05-12 14:28:11.394]  Step 162059  [3.996 sec/step, loss=0.08027, avg_loss=0.08673, mel_loss=0.03374, linear_loss=0.04653]
[2020-05-12 14:28:12.677]  Step 162060  [3.954 sec/step, loss=0.08060, avg_loss=0.08659, mel_loss=0.03449, linear_loss=0.04611]
[2020-05-12 14:28:15.102]  Step 162061  [3.916 sec/step, loss=0.08772, avg_loss=0.08655, mel_loss=0.03795, linear_loss=0.04977]
[2020-05-12 14:28:19.492]  Step 162062  [3.935 sec/step, loss=0.09412, avg_loss=0.08659, mel_loss=0.04178, linear_loss=0.05234]
[2020-05-12 14:28:33.553]  Step 162063  [4.046 sec/step, loss=0.07479, avg_loss=0.08642, mel_loss=0.03485, linear_loss=0.03994]
[2020-05-12 14:28:35.473]  Step 162064  [4.037 sec/step, loss=0.08643, avg_loss=0.08639, mel_loss=0.03738, linear_loss=0.04905]
[2020-05-12 14:28:37.815]  Step 162065  [4.028 sec/step, loss=0.09017, avg_loss=0.08637, mel_loss=0.03935, linear_loss=0.05081]
[2020-05-12 14:28:38.625]  Step 162066  [4.011 sec/step, loss=0.07226, avg_loss=0.08621, mel_loss=0.03052, linear_loss=0.04175]
[2020-05-12 14:28:40.771]  Step 162067  [3.956 sec/step, loss=0.08604, avg_loss=0.08621, mel_loss=0.03740, linear_loss=0.04864]
[2020-05-12 14:28:46.224]  Step 162068  [3.982 sec/step, loss=0.09512, avg_loss=0.08624, mel_loss=0.04249, linear_loss=0.05263]
[2020-05-12 14:28:47.826]  Step 162069  [3.987 sec/step, loss=0.08673, avg_loss=0.08630, mel_loss=0.03771, linear_loss=0.04902]
[2020-05-12 14:28:51.189]  Step 162070  [4.013 sec/step, loss=0.09025, avg_loss=0.08646, mel_loss=0.03982, linear_loss=0.05043]
[2020-05-12 14:28:54.196]  Step 162071  [3.991 sec/step, loss=0.09388, avg_loss=0.08647, mel_loss=0.04115, linear_loss=0.05273]
[2020-05-12 14:28:58.991]  Step 162072  [4.023 sec/step, loss=0.09335, avg_loss=0.08655, mel_loss=0.04158, linear_loss=0.05177]
[2020-05-12 14:29:04.809]  Step 162073  [3.938 sec/step, loss=0.09608, avg_loss=0.08679, mel_loss=0.04300, linear_loss=0.05307]
[2020-05-12 14:29:07.681]  Step 162074  [3.956 sec/step, loss=0.09069, avg_loss=0.08693, mel_loss=0.03970, linear_loss=0.05098]
[2020-05-12 14:29:11.373]  Step 162075  [3.971 sec/step, loss=0.09423, avg_loss=0.08699, mel_loss=0.04175, linear_loss=0.05248]
[2020-05-12 14:29:19.969]  Step 162076  [4.034 sec/step, loss=0.09339, avg_loss=0.08704, mel_loss=0.04265, linear_loss=0.05074]
[2020-05-12 14:29:20.964]  Step 162077  [4.019 sec/step, loss=0.07444, avg_loss=0.08691, mel_loss=0.03123, linear_loss=0.04321]
[2020-05-12 14:29:28.390]  Step 162078  [4.087 sec/step, loss=0.09477, avg_loss=0.08719, mel_loss=0.04292, linear_loss=0.05185]
[2020-05-12 14:29:29.968]  Step 162079  [4.068 sec/step, loss=0.08266, avg_loss=0.08711, mel_loss=0.03581, linear_loss=0.04685]
[2020-05-12 14:29:32.700]  Step 162080  [4.078 sec/step, loss=0.08825, avg_loss=0.08713, mel_loss=0.03854, linear_loss=0.04970]
[2020-05-12 14:29:33.678]  Step 162081  [4.051 sec/step, loss=0.07965, avg_loss=0.08702, mel_loss=0.03387, linear_loss=0.04578]
[2020-05-12 14:29:40.036]  Step 162082  [4.076 sec/step, loss=0.09670, avg_loss=0.08706, mel_loss=0.04366, linear_loss=0.05304]
[2020-05-12 14:29:41.214]  Step 162083  [4.078 sec/step, loss=0.08091, avg_loss=0.08709, mel_loss=0.03433, linear_loss=0.04657]
[2020-05-12 14:29:41.928]  Step 162084  [4.069 sec/step, loss=0.07320, avg_loss=0.08699, mel_loss=0.03118, linear_loss=0.04201]
[2020-05-12 14:29:42.445]  Step 162085  [4.029 sec/step, loss=0.07349, avg_loss=0.08679, mel_loss=0.03129, linear_loss=0.04220]
[2020-05-12 14:29:46.490]  Step 162086  [4.039 sec/step, loss=0.09250, avg_loss=0.08680, mel_loss=0.04094, linear_loss=0.05156]
[2020-05-12 14:29:50.037]  Step 162087  [4.047 sec/step, loss=0.09107, avg_loss=0.08682, mel_loss=0.04023, linear_loss=0.05084]
[2020-05-12 14:29:51.804]  Step 162088  [4.056 sec/step, loss=0.08610, avg_loss=0.08698, mel_loss=0.03683, linear_loss=0.04927]
[2020-05-12 14:29:53.841]  Step 162089  [4.063 sec/step, loss=0.08806, avg_loss=0.08704, mel_loss=0.03807, linear_loss=0.04999]
[2020-05-12 14:29:55.181]  Step 162090  [4.036 sec/step, loss=0.08349, avg_loss=0.08695, mel_loss=0.03565, linear_loss=0.04784]
[2020-05-12 14:30:49.180]  Generated 32 batches of size 32 in 75.497 sec
[2020-05-12 14:30:51.737]  Step 162091  [4.546 sec/step, loss=0.08830, avg_loss=0.08689, mel_loss=0.03838, linear_loss=0.04992]
[2020-05-12 14:30:52.639]  Step 162092  [4.472 sec/step, loss=0.07720, avg_loss=0.08673, mel_loss=0.03246, linear_loss=0.04474]
[2020-05-12 14:30:54.992]  Step 162093  [4.475 sec/step, loss=0.08912, avg_loss=0.08675, mel_loss=0.03885, linear_loss=0.05027]
[2020-05-12 14:30:57.884]  Step 162094  [4.491 sec/step, loss=0.09160, avg_loss=0.08683, mel_loss=0.04035, linear_loss=0.05124]
[2020-05-12 14:31:02.160]  Step 162095  [4.470 sec/step, loss=0.09322, avg_loss=0.08684, mel_loss=0.04137, linear_loss=0.05185]
[2020-05-12 14:31:03.360]  Step 162096  [4.471 sec/step, loss=0.08169, avg_loss=0.08685, mel_loss=0.03486, linear_loss=0.04683]
[2020-05-12 14:31:05.526]  Step 162097  [4.445 sec/step, loss=0.08813, avg_loss=0.08680, mel_loss=0.03844, linear_loss=0.04969]
[2020-05-12 14:31:07.245]  Step 162098  [4.388 sec/step, loss=0.08713, avg_loss=0.08673, mel_loss=0.03720, linear_loss=0.04993]
[2020-05-12 14:31:10.882]  Step 162099  [4.180 sec/step, loss=0.09444, avg_loss=0.08692, mel_loss=0.04185, linear_loss=0.05259]
[2020-05-12 14:31:13.478]  Step 162100  [4.198 sec/step, loss=0.08976, avg_loss=0.08711, mel_loss=0.03945, linear_loss=0.05031]
[2020-05-12 14:31:13.478]  Writing summary at step: 162100
[2020-05-12 14:31:16.795]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162100
[2020-05-12 14:31:18.406]  Saving audio and alignment...
[2020-05-12 14:31:23.944]  Input: 언어의 경제적 사용도 중요합니다 같은 메시지를 전달할 때~______
[2020-05-12 14:31:30.520]  Step 162101  [4.245 sec/step, loss=0.09302, avg_loss=0.08719, mel_loss=0.04199, linear_loss=0.05104]
[2020-05-12 14:31:31.610]  Step 162102  [4.245 sec/step, loss=0.08255, avg_loss=0.08721, mel_loss=0.03505, linear_loss=0.04750]
[2020-05-12 14:31:32.615]  Step 162103  [4.238 sec/step, loss=0.08074, avg_loss=0.08717, mel_loss=0.03428, linear_loss=0.04646]
[2020-05-12 14:31:33.395]  Step 162104  [4.220 sec/step, loss=0.06969, avg_loss=0.08697, mel_loss=0.02976, linear_loss=0.03992]
[2020-05-12 14:31:34.690]  Step 162105  [4.216 sec/step, loss=0.08459, avg_loss=0.08695, mel_loss=0.03596, linear_loss=0.04863]
[2020-05-12 14:31:49.026]  Step 162106  [4.228 sec/step, loss=0.07266, avg_loss=0.08685, mel_loss=0.03409, linear_loss=0.03857]
[2020-05-12 14:31:50.944]  Step 162107  [4.222 sec/step, loss=0.08504, avg_loss=0.08681, mel_loss=0.03671, linear_loss=0.04833]
[2020-05-12 14:31:59.675]  Step 162108  [4.290 sec/step, loss=0.09325, avg_loss=0.08685, mel_loss=0.04247, linear_loss=0.05078]
[2020-05-12 14:32:01.211]  Step 162109  [4.295 sec/step, loss=0.08478, avg_loss=0.08689, mel_loss=0.03638, linear_loss=0.04840]
[2020-05-12 14:32:03.241]  Step 162110  [4.283 sec/step, loss=0.08630, avg_loss=0.08682, mel_loss=0.03723, linear_loss=0.04907]
[2020-05-12 14:32:08.332]  Step 162111  [4.293 sec/step, loss=0.09371, avg_loss=0.08683, mel_loss=0.04191, linear_loss=0.05180]
[2020-05-12 14:32:15.904]  Step 162112  [4.356 sec/step, loss=0.09428, avg_loss=0.08697, mel_loss=0.04280, linear_loss=0.05148]
[2020-05-12 14:32:17.288]  Step 162113  [4.298 sec/step, loss=0.08372, avg_loss=0.08686, mel_loss=0.03578, linear_loss=0.04795]
[2020-05-12 14:32:20.327]  Step 162114  [4.283 sec/step, loss=0.09220, avg_loss=0.08685, mel_loss=0.04047, linear_loss=0.05172]
[2020-05-12 14:32:21.944]  Step 162115  [4.243 sec/step, loss=0.08637, avg_loss=0.08677, mel_loss=0.03708, linear_loss=0.04929]
[2020-05-12 14:32:22.698]  Step 162116  [4.216 sec/step, loss=0.07055, avg_loss=0.08657, mel_loss=0.03060, linear_loss=0.03995]
[2020-05-12 14:32:28.030]  Step 162117  [4.181 sec/step, loss=0.09426, avg_loss=0.08658, mel_loss=0.04256, linear_loss=0.05170]
[2020-05-12 14:32:32.131]  Step 162118  [4.216 sec/step, loss=0.09368, avg_loss=0.08681, mel_loss=0.04142, linear_loss=0.05226]
[2020-05-12 14:32:36.763]  Step 162119  [4.211 sec/step, loss=0.09417, avg_loss=0.08683, mel_loss=0.04187, linear_loss=0.05231]
[2020-05-12 14:32:37.574]  Step 162120  [4.188 sec/step, loss=0.07501, avg_loss=0.08666, mel_loss=0.03155, linear_loss=0.04346]
[2020-05-12 14:33:11.969]  Generated 32 batches of size 32 in 63.632 sec
[2020-05-12 14:33:15.346]  Step 162121  [4.556 sec/step, loss=0.09254, avg_loss=0.08681, mel_loss=0.04087, linear_loss=0.05167]
[2020-05-12 14:33:18.674]  Step 162122  [4.523 sec/step, loss=0.09157, avg_loss=0.08677, mel_loss=0.04067, linear_loss=0.05089]
[2020-05-12 14:33:21.255]  Step 162123  [4.525 sec/step, loss=0.08832, avg_loss=0.08675, mel_loss=0.03846, linear_loss=0.04986]
[2020-05-12 14:33:22.089]  Step 162124  [4.505 sec/step, loss=0.07321, avg_loss=0.08658, mel_loss=0.03098, linear_loss=0.04223]
[2020-05-12 14:33:26.980]  Step 162125  [4.534 sec/step, loss=0.09267, avg_loss=0.08664, mel_loss=0.04121, linear_loss=0.05146]
[2020-05-12 14:33:28.325]  Step 162126  [4.526 sec/step, loss=0.08059, avg_loss=0.08655, mel_loss=0.03465, linear_loss=0.04594]
[2020-05-12 14:33:31.992]  Step 162127  [4.526 sec/step, loss=0.09372, avg_loss=0.08655, mel_loss=0.04126, linear_loss=0.05247]
[2020-05-12 14:33:38.059]  Step 162128  [4.544 sec/step, loss=0.09288, avg_loss=0.08654, mel_loss=0.04188, linear_loss=0.05100]
[2020-05-12 14:33:40.252]  Step 162129  [4.292 sec/step, loss=0.08735, avg_loss=0.08662, mel_loss=0.03799, linear_loss=0.04935]
[2020-05-12 14:33:42.293]  Step 162130  [4.307 sec/step, loss=0.08849, avg_loss=0.08682, mel_loss=0.03838, linear_loss=0.05011]
[2020-05-12 14:33:44.033]  Step 162131  [4.302 sec/step, loss=0.08542, avg_loss=0.08681, mel_loss=0.03679, linear_loss=0.04863]
[2020-05-12 14:33:45.421]  Step 162132  [4.308 sec/step, loss=0.08340, avg_loss=0.08692, mel_loss=0.03584, linear_loss=0.04756]
[2020-05-12 14:33:47.023]  Step 162133  [4.309 sec/step, loss=0.08643, avg_loss=0.08694, mel_loss=0.03717, linear_loss=0.04926]
[2020-05-12 14:33:47.925]  Step 162134  [4.186 sec/step, loss=0.08094, avg_loss=0.08697, mel_loss=0.03471, linear_loss=0.04623]
[2020-05-12 14:33:52.196]  Step 162135  [4.185 sec/step, loss=0.09384, avg_loss=0.08696, mel_loss=0.04193, linear_loss=0.05191]
[2020-05-12 14:33:57.715]  Step 162136  [4.210 sec/step, loss=0.09452, avg_loss=0.08697, mel_loss=0.04239, linear_loss=0.05213]
[2020-05-12 14:34:00.036]  Step 162137  [4.196 sec/step, loss=0.08986, avg_loss=0.08693, mel_loss=0.03867, linear_loss=0.05119]
[2020-05-12 14:34:06.833]  Step 162138  [4.246 sec/step, loss=0.09647, avg_loss=0.08703, mel_loss=0.04366, linear_loss=0.05281]
[2020-05-12 14:34:08.640]  Step 162139  [4.225 sec/step, loss=0.08756, avg_loss=0.08698, mel_loss=0.03763, linear_loss=0.04993]
[2020-05-12 14:34:10.626]  Step 162140  [4.190 sec/step, loss=0.08786, avg_loss=0.08692, mel_loss=0.03803, linear_loss=0.04983]
[2020-05-12 14:34:19.078]  Step 162141  [4.242 sec/step, loss=0.09191, avg_loss=0.08690, mel_loss=0.04172, linear_loss=0.05020]
[2020-05-12 14:34:20.147]  Step 162142  [4.244 sec/step, loss=0.08073, avg_loss=0.08697, mel_loss=0.03409, linear_loss=0.04664]
[2020-05-12 14:34:23.213]  Step 162143  [4.265 sec/step, loss=0.09294, avg_loss=0.08716, mel_loss=0.04094, linear_loss=0.05199]
[2020-05-12 14:34:24.715]  Step 162144  [4.270 sec/step, loss=0.08402, avg_loss=0.08719, mel_loss=0.03597, linear_loss=0.04805]
[2020-05-12 14:34:25.881]  Step 162145  [4.247 sec/step, loss=0.07959, avg_loss=0.08709, mel_loss=0.03383, linear_loss=0.04576]
[2020-05-12 14:34:26.752]  Step 162146  [4.175 sec/step, loss=0.07701, avg_loss=0.08695, mel_loss=0.03218, linear_loss=0.04483]
[2020-05-12 14:34:27.283]  Step 162147  [4.168 sec/step, loss=0.06891, avg_loss=0.08684, mel_loss=0.03064, linear_loss=0.03826]
[2020-05-12 14:34:30.823]  Step 162148  [4.131 sec/step, loss=0.09346, avg_loss=0.08682, mel_loss=0.04135, linear_loss=0.05211]
[2020-05-12 14:34:33.672]  Step 162149  [4.140 sec/step, loss=0.08910, avg_loss=0.08684, mel_loss=0.03917, linear_loss=0.04993]
[2020-05-12 14:34:45.480]  Step 162150  [4.224 sec/step, loss=0.08731, avg_loss=0.08678, mel_loss=0.04064, linear_loss=0.04667]
[2020-05-12 14:34:45.480]  Writing summary at step: 162150
[2020-05-12 14:34:46.262]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162150
[2020-05-12 14:34:47.934]  Saving audio and alignment...
[2020-05-12 14:34:54.078]  Input: 따라서 보통의 말과 가장 먼 거리에 떨어져 있고~_________________________________________
[2020-05-12 14:35:11.438]  Generated 32 batches of size 32 in 48.219 sec
[2020-05-12 14:35:19.154]  Step 162151  [4.446 sec/step, loss=0.09548, avg_loss=0.08683, mel_loss=0.04344, linear_loss=0.05203]
[2020-05-12 14:35:19.946]  Step 162152  [4.395 sec/step, loss=0.06889, avg_loss=0.08660, mel_loss=0.02958, linear_loss=0.03931]
[2020-05-12 14:35:23.337]  Step 162153  [4.407 sec/step, loss=0.09176, avg_loss=0.08663, mel_loss=0.04049, linear_loss=0.05127]
[2020-05-12 14:35:25.044]  Step 162154  [4.372 sec/step, loss=0.08711, avg_loss=0.08657, mel_loss=0.03737, linear_loss=0.04974]
[2020-05-12 14:35:30.237]  Step 162155  [4.411 sec/step, loss=0.09456, avg_loss=0.08673, mel_loss=0.04230, linear_loss=0.05226]
[2020-05-12 14:35:32.011]  Step 162156  [4.410 sec/step, loss=0.08475, avg_loss=0.08671, mel_loss=0.03651, linear_loss=0.04825]
[2020-05-12 14:35:32.531]  Step 162157  [4.397 sec/step, loss=0.07220, avg_loss=0.08658, mel_loss=0.03081, linear_loss=0.04139]
[2020-05-12 14:35:35.920]  Step 162158  [4.407 sec/step, loss=0.09092, avg_loss=0.08661, mel_loss=0.04000, linear_loss=0.05092]
[2020-05-12 14:35:38.850]  Step 162159  [4.284 sec/step, loss=0.09131, avg_loss=0.08672, mel_loss=0.03994, linear_loss=0.05137]
[2020-05-12 14:35:40.980]  Step 162160  [4.292 sec/step, loss=0.09010, avg_loss=0.08681, mel_loss=0.03911, linear_loss=0.05099]
[2020-05-12 14:35:44.684]  Step 162161  [4.305 sec/step, loss=0.09432, avg_loss=0.08688, mel_loss=0.04174, linear_loss=0.05259]
[2020-05-12 14:35:46.668]  Step 162162  [4.281 sec/step, loss=0.08766, avg_loss=0.08682, mel_loss=0.03816, linear_loss=0.04950]
[2020-05-12 14:35:48.609]  Step 162163  [4.160 sec/step, loss=0.08665, avg_loss=0.08693, mel_loss=0.03731, linear_loss=0.04934]
[2020-05-12 14:35:57.361]  Step 162164  [4.228 sec/step, loss=0.09546, avg_loss=0.08702, mel_loss=0.04364, linear_loss=0.05183]
[2020-05-12 14:36:00.533]  Step 162165  [4.236 sec/step, loss=0.09232, avg_loss=0.08705, mel_loss=0.04040, linear_loss=0.05192]
[2020-05-12 14:36:07.271]  Step 162166  [4.296 sec/step, loss=0.09442, avg_loss=0.08727, mel_loss=0.04233, linear_loss=0.05209]
[2020-05-12 14:36:11.937]  Step 162167  [4.321 sec/step, loss=0.09357, avg_loss=0.08734, mel_loss=0.04146, linear_loss=0.05211]
[2020-05-12 14:36:16.059]  Step 162168  [4.307 sec/step, loss=0.09237, avg_loss=0.08732, mel_loss=0.04068, linear_loss=0.05169]
[2020-05-12 14:36:20.460]  Step 162169  [4.335 sec/step, loss=0.09452, avg_loss=0.08739, mel_loss=0.04207, linear_loss=0.05245]
[2020-05-12 14:36:26.173]  Step 162170  [4.359 sec/step, loss=0.09446, avg_loss=0.08744, mel_loss=0.04255, linear_loss=0.05191]
[2020-05-12 14:36:28.697]  Step 162171  [4.354 sec/step, loss=0.08934, avg_loss=0.08739, mel_loss=0.03897, linear_loss=0.05037]
[2020-05-12 14:36:29.498]  Step 162172  [4.314 sec/step, loss=0.07701, avg_loss=0.08723, mel_loss=0.03243, linear_loss=0.04458]
[2020-05-12 14:36:43.904]  Step 162173  [4.400 sec/step, loss=0.07580, avg_loss=0.08702, mel_loss=0.03538, linear_loss=0.04042]
[2020-05-12 14:36:46.333]  Step 162174  [4.396 sec/step, loss=0.08848, avg_loss=0.08700, mel_loss=0.03858, linear_loss=0.04990]
[2020-05-12 14:36:47.337]  Step 162175  [4.369 sec/step, loss=0.08000, avg_loss=0.08686, mel_loss=0.03365, linear_loss=0.04635]
[2020-05-12 14:36:48.710]  Step 162176  [4.297 sec/step, loss=0.08301, avg_loss=0.08676, mel_loss=0.03520, linear_loss=0.04781]
[2020-05-12 14:36:50.135]  Step 162177  [4.301 sec/step, loss=0.08097, avg_loss=0.08682, mel_loss=0.03482, linear_loss=0.04615]
[2020-05-12 14:36:51.329]  Step 162178  [4.239 sec/step, loss=0.08221, avg_loss=0.08670, mel_loss=0.03532, linear_loss=0.04689]
[2020-05-12 14:36:54.145]  Step 162179  [4.251 sec/step, loss=0.08878, avg_loss=0.08676, mel_loss=0.03890, linear_loss=0.04988]
[2020-05-12 14:36:55.778]  Step 162180  [4.240 sec/step, loss=0.08462, avg_loss=0.08672, mel_loss=0.03652, linear_loss=0.04810]
[2020-05-12 14:36:56.849]  Step 162181  [4.241 sec/step, loss=0.08295, avg_loss=0.08675, mel_loss=0.03514, linear_loss=0.04781]
[2020-05-12 14:36:57.875]  Step 162182  [4.188 sec/step, loss=0.07848, avg_loss=0.08657, mel_loss=0.03317, linear_loss=0.04531]
[2020-05-12 14:37:42.530]  Generated 32 batches of size 32 in 58.621 sec
[2020-05-12 14:37:44.303]  Step 162183  [4.640 sec/step, loss=0.08705, avg_loss=0.08663, mel_loss=0.03725, linear_loss=0.04980]
[2020-05-12 14:37:46.560]  Step 162184  [4.655 sec/step, loss=0.08732, avg_loss=0.08677, mel_loss=0.03792, linear_loss=0.04939]
[2020-05-12 14:37:49.436]  Step 162185  [4.679 sec/step, loss=0.09052, avg_loss=0.08694, mel_loss=0.03958, linear_loss=0.05094]
[2020-05-12 14:37:55.863]  Step 162186  [4.703 sec/step, loss=0.09377, avg_loss=0.08696, mel_loss=0.04216, linear_loss=0.05160]
[2020-05-12 14:37:57.200]  Step 162187  [4.681 sec/step, loss=0.08225, avg_loss=0.08687, mel_loss=0.03511, linear_loss=0.04714]
[2020-05-12 14:37:58.289]  Step 162188  [4.674 sec/step, loss=0.07951, avg_loss=0.08680, mel_loss=0.03348, linear_loss=0.04603]
[2020-05-12 14:38:07.121]  Step 162189  [4.742 sec/step, loss=0.09339, avg_loss=0.08686, mel_loss=0.04257, linear_loss=0.05082]
[2020-05-12 14:38:07.922]  Step 162190  [4.737 sec/step, loss=0.07061, avg_loss=0.08673, mel_loss=0.03067, linear_loss=0.03993]
[2020-05-12 14:38:08.781]  Step 162191  [4.180 sec/step, loss=0.07335, avg_loss=0.08658, mel_loss=0.03069, linear_loss=0.04266]
[2020-05-12 14:38:10.514]  Step 162192  [4.188 sec/step, loss=0.08724, avg_loss=0.08668, mel_loss=0.03754, linear_loss=0.04969]
[2020-05-12 14:38:11.481]  Step 162193  [4.174 sec/step, loss=0.07516, avg_loss=0.08654, mel_loss=0.03137, linear_loss=0.04379]
[2020-05-12 14:38:15.091]  Step 162194  [4.181 sec/step, loss=0.09251, avg_loss=0.08655, mel_loss=0.04090, linear_loss=0.05161]
[2020-05-12 14:38:17.111]  Step 162195  [4.159 sec/step, loss=0.08683, avg_loss=0.08648, mel_loss=0.03763, linear_loss=0.04920]
[2020-05-12 14:38:19.002]  Step 162196  [4.166 sec/step, loss=0.08841, avg_loss=0.08655, mel_loss=0.03817, linear_loss=0.05023]
[2020-05-12 14:38:22.096]  Step 162197  [4.175 sec/step, loss=0.09300, avg_loss=0.08660, mel_loss=0.04087, linear_loss=0.05213]
[2020-05-12 14:38:26.792]  Step 162198  [4.205 sec/step, loss=0.09340, avg_loss=0.08666, mel_loss=0.04151, linear_loss=0.05189]
[2020-05-12 14:38:32.238]  Step 162199  [4.223 sec/step, loss=0.09284, avg_loss=0.08665, mel_loss=0.04152, linear_loss=0.05132]
[2020-05-12 14:38:35.156]  Step 162200  [4.226 sec/step, loss=0.08901, avg_loss=0.08664, mel_loss=0.03890, linear_loss=0.05011]
[2020-05-12 14:38:35.156]  Writing summary at step: 162200
[2020-05-12 14:38:39.050]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162200
[2020-05-12 14:38:40.708]  Saving audio and alignment...
[2020-05-12 14:38:43.131]  Input: 특별한 시간인만큼~______
[2020-05-12 14:38:45.383]  Step 162201  [4.183 sec/step, loss=0.08849, avg_loss=0.08659, mel_loss=0.03829, linear_loss=0.05020]
[2020-05-12 14:38:46.205]  Step 162202  [4.180 sec/step, loss=0.07291, avg_loss=0.08650, mel_loss=0.03084, linear_loss=0.04207]
[2020-05-12 14:38:49.772]  Step 162203  [4.206 sec/step, loss=0.09242, avg_loss=0.08661, mel_loss=0.04075, linear_loss=0.05167]
[2020-05-12 14:38:51.216]  Step 162204  [4.212 sec/step, loss=0.08353, avg_loss=0.08675, mel_loss=0.03582, linear_loss=0.04771]
[2020-05-12 14:39:05.840]  Step 162205  [4.346 sec/step, loss=0.07411, avg_loss=0.08665, mel_loss=0.03454, linear_loss=0.03957]
[2020-05-12 14:39:10.106]  Step 162206  [4.245 sec/step, loss=0.09247, avg_loss=0.08684, mel_loss=0.04118, linear_loss=0.05130]
[2020-05-12 14:39:11.707]  Step 162207  [4.242 sec/step, loss=0.08562, avg_loss=0.08685, mel_loss=0.03685, linear_loss=0.04877]
[2020-05-12 14:39:15.990]  Step 162208  [4.197 sec/step, loss=0.09223, avg_loss=0.08684, mel_loss=0.04072, linear_loss=0.05151]
[2020-05-12 14:39:18.571]  Step 162209  [4.208 sec/step, loss=0.08874, avg_loss=0.08688, mel_loss=0.03862, linear_loss=0.05012]
[2020-05-12 14:39:26.344]  Step 162210  [4.265 sec/step, loss=0.09406, avg_loss=0.08696, mel_loss=0.04244, linear_loss=0.05162]
[2020-05-12 14:39:32.393]  Step 162211  [4.275 sec/step, loss=0.09274, avg_loss=0.08695, mel_loss=0.04150, linear_loss=0.05124]
[2020-05-12 14:39:33.470]  Step 162212  [4.210 sec/step, loss=0.07764, avg_loss=0.08678, mel_loss=0.03299, linear_loss=0.04465]
[2020-05-12 14:40:22.690]  Generated 32 batches of size 32 in 92.913 sec
[2020-05-12 14:40:25.578]  Step 162213  [4.717 sec/step, loss=0.08920, avg_loss=0.08684, mel_loss=0.03909, linear_loss=0.05011]
[2020-05-12 14:40:29.277]  Step 162214  [4.724 sec/step, loss=0.09353, avg_loss=0.08685, mel_loss=0.04153, linear_loss=0.05200]
[2020-05-12 14:40:30.097]  Step 162215  [4.716 sec/step, loss=0.07278, avg_loss=0.08671, mel_loss=0.03081, linear_loss=0.04196]
[2020-05-12 14:40:32.574]  Step 162216  [4.733 sec/step, loss=0.08824, avg_loss=0.08689, mel_loss=0.03800, linear_loss=0.05024]
[2020-05-12 14:40:34.559]  Step 162217  [4.699 sec/step, loss=0.08495, avg_loss=0.08680, mel_loss=0.03668, linear_loss=0.04826]
[2020-05-12 14:40:35.214]  Step 162218  [4.665 sec/step, loss=0.07450, avg_loss=0.08661, mel_loss=0.03206, linear_loss=0.04244]
[2020-05-12 14:40:35.800]  Step 162219  [4.624 sec/step, loss=0.06635, avg_loss=0.08633, mel_loss=0.02865, linear_loss=0.03770]
[2020-05-12 14:40:45.003]  Step 162220  [4.708 sec/step, loss=0.09300, avg_loss=0.08651, mel_loss=0.04249, linear_loss=0.05051]
[2020-05-12 14:40:46.059]  Step 162221  [4.341 sec/step, loss=0.07704, avg_loss=0.08635, mel_loss=0.03265, linear_loss=0.04439]
[2020-05-12 14:40:47.642]  Step 162222  [4.324 sec/step, loss=0.08453, avg_loss=0.08628, mel_loss=0.03631, linear_loss=0.04821]
[2020-05-12 14:40:48.679]  Step 162223  [4.308 sec/step, loss=0.07698, avg_loss=0.08617, mel_loss=0.03250, linear_loss=0.04448]
[2020-05-12 14:40:51.386]  Step 162224  [4.327 sec/step, loss=0.08915, avg_loss=0.08633, mel_loss=0.03908, linear_loss=0.05006]
[2020-05-12 14:41:06.113]  Step 162225  [4.425 sec/step, loss=0.07482, avg_loss=0.08615, mel_loss=0.03529, linear_loss=0.03953]
[2020-05-12 14:41:09.593]  Step 162226  [4.447 sec/step, loss=0.09120, avg_loss=0.08626, mel_loss=0.04046, linear_loss=0.05074]
[2020-05-12 14:41:11.757]  Step 162227  [4.432 sec/step, loss=0.08817, avg_loss=0.08620, mel_loss=0.03833, linear_loss=0.04984]
[2020-05-12 14:41:17.070]  Step 162228  [4.424 sec/step, loss=0.09399, avg_loss=0.08621, mel_loss=0.04197, linear_loss=0.05202]
[2020-05-12 14:41:21.698]  Step 162229  [4.448 sec/step, loss=0.09289, avg_loss=0.08627, mel_loss=0.04132, linear_loss=0.05157]
[2020-05-12 14:41:25.129]  Step 162230  [4.462 sec/step, loss=0.09211, avg_loss=0.08630, mel_loss=0.04068, linear_loss=0.05143]
[2020-05-12 14:41:27.538]  Step 162231  [4.469 sec/step, loss=0.08864, avg_loss=0.08634, mel_loss=0.03884, linear_loss=0.04980]
[2020-05-12 14:41:28.780]  Step 162232  [4.468 sec/step, loss=0.08096, avg_loss=0.08631, mel_loss=0.03479, linear_loss=0.04617]
[2020-05-12 14:41:30.134]  Step 162233  [4.465 sec/step, loss=0.08475, avg_loss=0.08629, mel_loss=0.03637, linear_loss=0.04838]
[2020-05-12 14:41:36.827]  Step 162234  [4.523 sec/step, loss=0.09537, avg_loss=0.08644, mel_loss=0.04325, linear_loss=0.05212]
[2020-05-12 14:41:40.009]  Step 162235  [4.512 sec/step, loss=0.09232, avg_loss=0.08642, mel_loss=0.04075, linear_loss=0.05156]
[2020-05-12 14:41:43.041]  Step 162236  [4.487 sec/step, loss=0.09120, avg_loss=0.08639, mel_loss=0.04018, linear_loss=0.05102]
[2020-05-12 14:41:44.718]  Step 162237  [4.481 sec/step, loss=0.08764, avg_loss=0.08637, mel_loss=0.03793, linear_loss=0.04971]
[2020-05-12 14:41:50.429]  Step 162238  [4.470 sec/step, loss=0.09733, avg_loss=0.08638, mel_loss=0.04400, linear_loss=0.05333]
[2020-05-12 14:41:52.205]  Step 162239  [4.470 sec/step, loss=0.08703, avg_loss=0.08637, mel_loss=0.03742, linear_loss=0.04960]
[2020-05-12 14:41:56.286]  Step 162240  [4.491 sec/step, loss=0.09387, avg_loss=0.08643, mel_loss=0.04169, linear_loss=0.05218]
[2020-05-12 14:42:03.898]  Step 162241  [4.482 sec/step, loss=0.09582, avg_loss=0.08647, mel_loss=0.04362, linear_loss=0.05219]
[2020-05-12 14:42:05.030]  Step 162242  [4.483 sec/step, loss=0.08156, avg_loss=0.08648, mel_loss=0.03499, linear_loss=0.04657]
[2020-05-12 14:42:07.022]  Step 162243  [4.472 sec/step, loss=0.08843, avg_loss=0.08643, mel_loss=0.03839, linear_loss=0.05003]
[2020-05-12 14:42:08.346]  Step 162244  [4.470 sec/step, loss=0.08457, avg_loss=0.08644, mel_loss=0.03626, linear_loss=0.04830]
[2020-05-12 14:42:59.226]  Generated 32 batches of size 32 in 79.212 sec
[2020-05-12 14:43:02.166]  Step 162245  [4.997 sec/step, loss=0.09172, avg_loss=0.08656, mel_loss=0.04048, linear_loss=0.05123]
[2020-05-12 14:43:03.906]  Step 162246  [5.006 sec/step, loss=0.08721, avg_loss=0.08666, mel_loss=0.03738, linear_loss=0.04983]
[2020-05-12 14:43:12.835]  Step 162247  [5.090 sec/step, loss=0.09212, avg_loss=0.08689, mel_loss=0.04199, linear_loss=0.05013]
[2020-05-12 14:43:16.995]  Step 162248  [5.096 sec/step, loss=0.09256, avg_loss=0.08689, mel_loss=0.04103, linear_loss=0.05153]
[2020-05-12 14:43:18.053]  Step 162249  [5.078 sec/step, loss=0.07677, avg_loss=0.08676, mel_loss=0.03257, linear_loss=0.04420]
[2020-05-12 14:43:20.312]  Step 162250  [4.982 sec/step, loss=0.08934, avg_loss=0.08678, mel_loss=0.03892, linear_loss=0.05041]
[2020-05-12 14:43:20.312]  Writing summary at step: 162250
[2020-05-12 14:43:25.848]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162250
[2020-05-12 14:43:27.479]  Saving audio and alignment...
[2020-05-12 14:43:42.980]  Input: 녹십자라는 그룹의 씨아이 로고가 바로 녹색이 잖아요 따라서 임직원들이 가장 선호하고 친숙하게 느껴지는 색상이기 때문이에요~_______________________________
[2020-05-12 14:43:44.529]  Step 162251  [4.747 sec/step, loss=0.08513, avg_loss=0.08668, mel_loss=0.03677, linear_loss=0.04836]
[2020-05-12 14:43:45.913]  Step 162252  [4.753 sec/step, loss=0.08375, avg_loss=0.08683, mel_loss=0.03631, linear_loss=0.04744]
[2020-05-12 14:43:49.040]  Step 162253  [4.750 sec/step, loss=0.09224, avg_loss=0.08683, mel_loss=0.04088, linear_loss=0.05136]
[2020-05-12 14:43:51.068]  Step 162254  [4.754 sec/step, loss=0.08750, avg_loss=0.08684, mel_loss=0.03788, linear_loss=0.04962]
[2020-05-12 14:43:56.571]  Step 162255  [4.757 sec/step, loss=0.09450, avg_loss=0.08684, mel_loss=0.04252, linear_loss=0.05198]
[2020-05-12 14:43:58.219]  Step 162256  [4.755 sec/step, loss=0.08735, avg_loss=0.08686, mel_loss=0.03771, linear_loss=0.04964]
[2020-05-12 14:43:59.176]  Step 162257  [4.760 sec/step, loss=0.08159, avg_loss=0.08696, mel_loss=0.03484, linear_loss=0.04676]
[2020-05-12 14:44:02.830]  Step 162258  [4.762 sec/step, loss=0.09447, avg_loss=0.08699, mel_loss=0.04200, linear_loss=0.05247]
[2020-05-12 14:44:04.163]  Step 162259  [4.746 sec/step, loss=0.08190, avg_loss=0.08690, mel_loss=0.03495, linear_loss=0.04694]
[2020-05-12 14:44:11.479]  Step 162260  [4.798 sec/step, loss=0.09482, avg_loss=0.08694, mel_loss=0.04308, linear_loss=0.05173]
[2020-05-12 14:44:16.052]  Step 162261  [4.807 sec/step, loss=0.09398, avg_loss=0.08694, mel_loss=0.04153, linear_loss=0.05245]
[2020-05-12 14:44:18.566]  Step 162262  [4.812 sec/step, loss=0.08738, avg_loss=0.08694, mel_loss=0.03804, linear_loss=0.04934]
[2020-05-12 14:44:21.833]  Step 162263  [4.826 sec/step, loss=0.09434, avg_loss=0.08701, mel_loss=0.04195, linear_loss=0.05239]
[2020-05-12 14:44:27.817]  Step 162264  [4.798 sec/step, loss=0.09333, avg_loss=0.08699, mel_loss=0.04207, linear_loss=0.05127]
[2020-05-12 14:44:28.599]  Step 162265  [4.774 sec/step, loss=0.07230, avg_loss=0.08679, mel_loss=0.03044, linear_loss=0.04186]
[2020-05-12 14:44:30.504]  Step 162266  [4.726 sec/step, loss=0.08447, avg_loss=0.08669, mel_loss=0.03640, linear_loss=0.04808]
[2020-05-12 14:44:33.107]  Step 162267  [4.705 sec/step, loss=0.08926, avg_loss=0.08665, mel_loss=0.03908, linear_loss=0.05018]
[2020-05-12 14:44:35.329]  Step 162268  [4.686 sec/step, loss=0.09023, avg_loss=0.08663, mel_loss=0.03948, linear_loss=0.05076]
[2020-05-12 14:44:39.671]  Step 162269  [4.685 sec/step, loss=0.09338, avg_loss=0.08662, mel_loss=0.04167, linear_loss=0.05171]
[2020-05-12 14:44:40.838]  Step 162270  [4.640 sec/step, loss=0.08118, avg_loss=0.08648, mel_loss=0.03453, linear_loss=0.04665]
[2020-05-12 14:44:44.234]  Step 162271  [4.649 sec/step, loss=0.09230, avg_loss=0.08651, mel_loss=0.04068, linear_loss=0.05162]
[2020-05-12 14:44:44.787]  Step 162272  [4.646 sec/step, loss=0.06653, avg_loss=0.08641, mel_loss=0.02907, linear_loss=0.03746]
[2020-05-12 14:44:45.833]  Step 162273  [4.513 sec/step, loss=0.08070, avg_loss=0.08646, mel_loss=0.03429, linear_loss=0.04640]
[2020-05-12 14:44:46.672]  Step 162274  [4.497 sec/step, loss=0.07204, avg_loss=0.08629, mel_loss=0.03081, linear_loss=0.04124]
[2020-05-12 14:45:04.620]  Generated 32 batches of size 32 in 36.015 sec
[2020-05-12 14:45:06.023]  Step 162275  [4.680 sec/step, loss=0.08263, avg_loss=0.08632, mel_loss=0.03534, linear_loss=0.04729]
[2020-05-12 14:45:13.882]  Step 162276  [4.745 sec/step, loss=0.09477, avg_loss=0.08644, mel_loss=0.04305, linear_loss=0.05172]
[2020-05-12 14:45:18.102]  Step 162277  [4.773 sec/step, loss=0.09313, avg_loss=0.08656, mel_loss=0.04108, linear_loss=0.05205]
[2020-05-12 14:45:23.444]  Step 162278  [4.814 sec/step, loss=0.09403, avg_loss=0.08668, mel_loss=0.04201, linear_loss=0.05202]
[2020-05-12 14:45:25.677]  Step 162279  [4.809 sec/step, loss=0.08879, avg_loss=0.08668, mel_loss=0.03864, linear_loss=0.05015]
[2020-05-12 14:45:28.178]  Step 162280  [4.817 sec/step, loss=0.08843, avg_loss=0.08672, mel_loss=0.03857, linear_loss=0.04986]
[2020-05-12 14:45:29.916]  Step 162281  [4.824 sec/step, loss=0.08588, avg_loss=0.08675, mel_loss=0.03666, linear_loss=0.04922]
[2020-05-12 14:45:33.330]  Step 162282  [4.848 sec/step, loss=0.09261, avg_loss=0.08689, mel_loss=0.04072, linear_loss=0.05189]
[2020-05-12 14:45:36.044]  Step 162283  [4.411 sec/step, loss=0.08857, avg_loss=0.08690, mel_loss=0.03884, linear_loss=0.04974]
[2020-05-12 14:45:42.690]  Step 162284  [4.455 sec/step, loss=0.09374, avg_loss=0.08697, mel_loss=0.04226, linear_loss=0.05148]
[2020-05-12 14:45:47.984]  Step 162285  [4.479 sec/step, loss=0.09410, avg_loss=0.08700, mel_loss=0.04208, linear_loss=0.05202]
[2020-05-12 14:45:49.316]  Step 162286  [4.428 sec/step, loss=0.08438, avg_loss=0.08691, mel_loss=0.03662, linear_loss=0.04777]
[2020-05-12 14:45:52.797]  Step 162287  [4.449 sec/step, loss=0.09121, avg_loss=0.08700, mel_loss=0.04004, linear_loss=0.05117]
[2020-05-12 14:45:55.672]  Step 162288  [4.467 sec/step, loss=0.09071, avg_loss=0.08711, mel_loss=0.03967, linear_loss=0.05104]
[2020-05-12 14:45:56.800]  Step 162289  [4.390 sec/step, loss=0.07976, avg_loss=0.08697, mel_loss=0.03396, linear_loss=0.04580]
[2020-05-12 14:45:57.462]  Step 162290  [4.389 sec/step, loss=0.07046, avg_loss=0.08697, mel_loss=0.03077, linear_loss=0.03969]
[2020-05-12 14:45:59.064]  Step 162291  [4.396 sec/step, loss=0.08377, avg_loss=0.08708, mel_loss=0.03603, linear_loss=0.04774]
[2020-05-12 14:45:59.960]  Step 162292  [4.388 sec/step, loss=0.08064, avg_loss=0.08701, mel_loss=0.03429, linear_loss=0.04634]
[2020-05-12 14:46:01.002]  Step 162293  [4.389 sec/step, loss=0.07587, avg_loss=0.08702, mel_loss=0.03228, linear_loss=0.04359]
[2020-05-12 14:46:02.704]  Step 162294  [4.369 sec/step, loss=0.08617, avg_loss=0.08695, mel_loss=0.03675, linear_loss=0.04942]
[2020-05-12 14:46:03.501]  Step 162295  [4.357 sec/step, loss=0.07625, avg_loss=0.08685, mel_loss=0.03263, linear_loss=0.04362]
[2020-05-12 14:46:05.414]  Step 162296  [4.357 sec/step, loss=0.08777, avg_loss=0.08684, mel_loss=0.03793, linear_loss=0.04984]
[2020-05-12 14:46:07.388]  Step 162297  [4.346 sec/step, loss=0.08722, avg_loss=0.08678, mel_loss=0.03755, linear_loss=0.04967]
[2020-05-12 14:46:09.036]  Generated 32 batches of size 32 in 1.643 sec
[2020-05-12 14:46:16.051]  Step 162298  [4.386 sec/step, loss=0.09440, avg_loss=0.08679, mel_loss=0.04309, linear_loss=0.05131]
[2020-05-12 14:46:21.066]  Step 162299  [4.382 sec/step, loss=0.09392, avg_loss=0.08680, mel_loss=0.04183, linear_loss=0.05209]
[2020-05-12 14:46:23.427]  Step 162300  [4.376 sec/step, loss=0.08881, avg_loss=0.08680, mel_loss=0.03876, linear_loss=0.05004]
[2020-05-12 14:46:23.427]  Writing summary at step: 162300
[2020-05-12 14:46:27.572]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162300
[2020-05-12 14:46:29.235]  Saving audio and alignment...
[2020-05-12 14:46:31.894]  Input: 온도에서 습도까지~________________
[2020-05-12 14:46:35.519]  Step 162301  [4.390 sec/step, loss=0.09340, avg_loss=0.08685, mel_loss=0.04123, linear_loss=0.05217]
[2020-05-12 14:46:36.024]  Step 162302  [4.387 sec/step, loss=0.06781, avg_loss=0.08680, mel_loss=0.02953, linear_loss=0.03829]
[2020-05-12 14:46:39.068]  Step 162303  [4.381 sec/step, loss=0.09319, avg_loss=0.08681, mel_loss=0.04123, linear_loss=0.05195]
[2020-05-12 14:46:52.272]  Step 162304  [4.499 sec/step, loss=0.08094, avg_loss=0.08678, mel_loss=0.03744, linear_loss=0.04351]
[2020-05-12 14:46:56.827]  Step 162305  [4.398 sec/step, loss=0.09604, avg_loss=0.08700, mel_loss=0.04284, linear_loss=0.05320]
[2020-05-12 14:46:57.936]  Step 162306  [4.367 sec/step, loss=0.08036, avg_loss=0.08688, mel_loss=0.03393, linear_loss=0.04644]
[2020-05-12 14:47:00.004]  Step 162307  [4.371 sec/step, loss=0.08652, avg_loss=0.08689, mel_loss=0.03751, linear_loss=0.04901]
[2020-05-12 14:47:01.172]  Step 162308  [4.340 sec/step, loss=0.08106, avg_loss=0.08678, mel_loss=0.03451, linear_loss=0.04655]
[2020-05-12 14:47:06.757]  Step 162309  [4.370 sec/step, loss=0.09405, avg_loss=0.08683, mel_loss=0.04217, linear_loss=0.05189]
[2020-05-12 14:47:08.050]  Step 162310  [4.305 sec/step, loss=0.08124, avg_loss=0.08670, mel_loss=0.03458, linear_loss=0.04666]
[2020-05-12 14:47:09.643]  Step 162311  [4.261 sec/step, loss=0.08796, avg_loss=0.08666, mel_loss=0.03813, linear_loss=0.04983]
[2020-05-12 14:47:16.027]  Step 162312  [4.314 sec/step, loss=0.09347, avg_loss=0.08681, mel_loss=0.04219, linear_loss=0.05128]
[2020-05-12 14:47:17.608]  Step 162313  [3.809 sec/step, loss=0.08491, avg_loss=0.08677, mel_loss=0.03633, linear_loss=0.04858]
[2020-05-12 14:47:20.136]  Step 162314  [3.797 sec/step, loss=0.08700, avg_loss=0.08671, mel_loss=0.03761, linear_loss=0.04939]
[2020-05-12 14:47:21.552]  Step 162315  [3.803 sec/step, loss=0.08306, avg_loss=0.08681, mel_loss=0.03567, linear_loss=0.04740]
[2020-05-12 14:47:22.127]  Step 162316  [3.784 sec/step, loss=0.06843, avg_loss=0.08661, mel_loss=0.02995, linear_loss=0.03848]
[2020-05-12 14:47:24.487]  Step 162317  [3.788 sec/step, loss=0.08770, avg_loss=0.08664, mel_loss=0.03846, linear_loss=0.04924]
[2020-05-12 14:47:27.726]  Step 162318  [3.814 sec/step, loss=0.09086, avg_loss=0.08680, mel_loss=0.04001, linear_loss=0.05084]
[2020-05-12 14:47:35.153]  Step 162319  [3.882 sec/step, loss=0.09528, avg_loss=0.08709, mel_loss=0.04320, linear_loss=0.05209]
[2020-05-12 14:47:36.969]  Step 162320  [3.808 sec/step, loss=0.08385, avg_loss=0.08700, mel_loss=0.03613, linear_loss=0.04772]
[2020-05-12 14:47:40.541]  Step 162321  [3.833 sec/step, loss=0.09103, avg_loss=0.08714, mel_loss=0.04011, linear_loss=0.05092]
[2020-05-12 14:47:43.420]  Step 162322  [3.846 sec/step, loss=0.08971, avg_loss=0.08719, mel_loss=0.03938, linear_loss=0.05032]
[2020-05-12 14:47:45.664]  Step 162323  [3.858 sec/step, loss=0.08954, avg_loss=0.08732, mel_loss=0.03892, linear_loss=0.05062]
[2020-05-12 14:47:48.681]  Step 162324  [3.861 sec/step, loss=0.09040, avg_loss=0.08733, mel_loss=0.03956, linear_loss=0.05083]
[2020-05-12 14:47:57.785]  Step 162325  [3.805 sec/step, loss=0.09316, avg_loss=0.08751, mel_loss=0.04240, linear_loss=0.05076]
[2020-05-12 14:48:02.085]  Step 162326  [3.813 sec/step, loss=0.09170, avg_loss=0.08752, mel_loss=0.04064, linear_loss=0.05106]
[2020-05-12 14:48:02.893]  Step 162327  [3.800 sec/step, loss=0.07357, avg_loss=0.08737, mel_loss=0.03113, linear_loss=0.04245]
[2020-05-12 14:48:06.308]  Step 162328  [3.781 sec/step, loss=0.09191, avg_loss=0.08735, mel_loss=0.04052, linear_loss=0.05139]
[2020-05-12 14:48:07.186]  Step 162329  [3.743 sec/step, loss=0.07600, avg_loss=0.08718, mel_loss=0.03197, linear_loss=0.04403]
[2020-05-12 14:48:11.253]  Step 162330  [3.750 sec/step, loss=0.09321, avg_loss=0.08719, mel_loss=0.04129, linear_loss=0.05191]
[2020-05-12 14:48:15.064]  Step 162331  [3.764 sec/step, loss=0.09440, avg_loss=0.08725, mel_loss=0.04175, linear_loss=0.05265]
[2020-05-12 14:48:27.591]  Step 162332  [3.877 sec/step, loss=0.08292, avg_loss=0.08727, mel_loss=0.03838, linear_loss=0.04454]
[2020-05-12 14:48:33.247]  Step 162333  [3.920 sec/step, loss=0.09150, avg_loss=0.08734, mel_loss=0.04084, linear_loss=0.05067]
[2020-05-12 14:48:34.327]  Step 162334  [3.863 sec/step, loss=0.07914, avg_loss=0.08717, mel_loss=0.03358, linear_loss=0.04556]
[2020-05-12 14:48:36.432]  Step 162335  [3.853 sec/step, loss=0.08581, avg_loss=0.08711, mel_loss=0.03701, linear_loss=0.04880]
[2020-05-12 14:48:37.311]  Step 162336  [3.831 sec/step, loss=0.07224, avg_loss=0.08692, mel_loss=0.03049, linear_loss=0.04175]
[2020-05-12 14:48:47.529]  Generated 32 batches of size 32 in 44.631 sec
[2020-05-12 14:48:49.549]  Step 162337  [3.937 sec/step, loss=0.08698, avg_loss=0.08691, mel_loss=0.03791, linear_loss=0.04907]
[2020-05-12 14:48:50.272]  Step 162338  [3.887 sec/step, loss=0.07701, avg_loss=0.08671, mel_loss=0.03249, linear_loss=0.04452]
[2020-05-12 14:48:57.849]  Step 162339  [3.945 sec/step, loss=0.09584, avg_loss=0.08680, mel_loss=0.04351, linear_loss=0.05233]
[2020-05-12 14:49:01.316]  Step 162340  [3.939 sec/step, loss=0.09179, avg_loss=0.08678, mel_loss=0.04063, linear_loss=0.05115]
[2020-05-12 14:49:07.639]  Step 162341  [3.926 sec/step, loss=0.09377, avg_loss=0.08676, mel_loss=0.04205, linear_loss=0.05172]
[2020-05-12 14:49:09.101]  Step 162342  [3.929 sec/step, loss=0.08594, avg_loss=0.08680, mel_loss=0.03709, linear_loss=0.04885]
[2020-05-12 14:49:11.815]  Step 162343  [3.936 sec/step, loss=0.08866, avg_loss=0.08680, mel_loss=0.03846, linear_loss=0.05020]
[2020-05-12 14:49:12.924]  Step 162344  [3.934 sec/step, loss=0.07891, avg_loss=0.08675, mel_loss=0.03330, linear_loss=0.04560]
[2020-05-12 14:49:17.655]  Step 162345  [3.443 sec/step, loss=0.09558, avg_loss=0.08679, mel_loss=0.04279, linear_loss=0.05279]
[2020-05-12 14:49:19.981]  Step 162346  [3.449 sec/step, loss=0.08740, avg_loss=0.08679, mel_loss=0.03794, linear_loss=0.04946]
[2020-05-12 14:49:23.028]  Step 162347  [3.390 sec/step, loss=0.08896, avg_loss=0.08676, mel_loss=0.03914, linear_loss=0.04981]
[2020-05-12 14:49:26.658]  Step 162348  [3.385 sec/step, loss=0.09356, avg_loss=0.08677, mel_loss=0.04145, linear_loss=0.05210]
[2020-05-12 14:49:30.633]  Step 162349  [3.414 sec/step, loss=0.09348, avg_loss=0.08693, mel_loss=0.04105, linear_loss=0.05243]
[2020-05-12 14:49:32.321]  Step 162350  [3.408 sec/step, loss=0.08509, avg_loss=0.08689, mel_loss=0.03659, linear_loss=0.04850]
[2020-05-12 14:49:32.321]  Writing summary at step: 162350
[2020-05-12 14:49:33.600]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162350
[2020-05-12 14:49:35.265]  Saving audio and alignment...
[2020-05-12 14:49:37.112]  Input: 이렇게 읽어 주시~__
[2020-05-12 14:49:40.429]  Step 162351  [3.426 sec/step, loss=0.09179, avg_loss=0.08696, mel_loss=0.04041, linear_loss=0.05138]
[2020-05-12 14:49:42.247]  Step 162352  [3.431 sec/step, loss=0.08475, avg_loss=0.08697, mel_loss=0.03660, linear_loss=0.04815]
[2020-05-12 14:49:43.217]  Step 162353  [3.409 sec/step, loss=0.07990, avg_loss=0.08684, mel_loss=0.03332, linear_loss=0.04659]
[2020-05-12 14:49:52.010]  Step 162354  [3.477 sec/step, loss=0.09435, avg_loss=0.08691, mel_loss=0.04311, linear_loss=0.05124]
[2020-05-12 14:49:52.771]  Step 162355  [3.429 sec/step, loss=0.06921, avg_loss=0.08666, mel_loss=0.02980, linear_loss=0.03941]
[2020-05-12 14:49:54.582]  Step 162356  [3.431 sec/step, loss=0.08609, avg_loss=0.08665, mel_loss=0.03736, linear_loss=0.04873]
[2020-05-12 14:49:55.882]  Step 162357  [3.434 sec/step, loss=0.08373, avg_loss=0.08667, mel_loss=0.03577, linear_loss=0.04796]
[2020-05-12 14:49:57.212]  Step 162358  [3.411 sec/step, loss=0.08341, avg_loss=0.08656, mel_loss=0.03560, linear_loss=0.04781]
[2020-05-12 14:50:00.451]  Step 162359  [3.430 sec/step, loss=0.09258, avg_loss=0.08666, mel_loss=0.04077, linear_loss=0.05181]
[2020-05-12 14:50:05.711]  Step 162360  [3.409 sec/step, loss=0.09291, avg_loss=0.08664, mel_loss=0.04154, linear_loss=0.05137]
[2020-05-12 14:50:07.733]  Step 162361  [3.384 sec/step, loss=0.08851, avg_loss=0.08659, mel_loss=0.03832, linear_loss=0.05019]
[2020-05-12 14:50:12.037]  Step 162362  [3.402 sec/step, loss=0.09293, avg_loss=0.08665, mel_loss=0.04128, linear_loss=0.05165]
[2020-05-12 14:50:13.092]  Step 162363  [3.380 sec/step, loss=0.07588, avg_loss=0.08646, mel_loss=0.03213, linear_loss=0.04375]
[2020-05-12 14:50:15.724]  Step 162364  [3.346 sec/step, loss=0.08916, avg_loss=0.08642, mel_loss=0.03881, linear_loss=0.05035]
[2020-05-12 14:50:28.229]  Generated 32 batches of size 32 in 32.342 sec
[2020-05-12 14:50:30.575]  Step 162365  [3.487 sec/step, loss=0.07577, avg_loss=0.08645, mel_loss=0.03558, linear_loss=0.04019]
[2020-05-12 14:50:36.587]  Step 162366  [3.528 sec/step, loss=0.09470, avg_loss=0.08656, mel_loss=0.04264, linear_loss=0.05206]
[2020-05-12 14:50:38.495]  Step 162367  [3.521 sec/step, loss=0.08550, avg_loss=0.08652, mel_loss=0.03670, linear_loss=0.04880]
[2020-05-12 14:50:39.089]  Step 162368  [3.505 sec/step, loss=0.06759, avg_loss=0.08629, mel_loss=0.02944, linear_loss=0.03815]
[2020-05-12 14:50:41.783]  Step 162369  [3.488 sec/step, loss=0.08661, avg_loss=0.08622, mel_loss=0.03758, linear_loss=0.04903]
[2020-05-12 14:50:45.446]  Step 162370  [3.513 sec/step, loss=0.09206, avg_loss=0.08633, mel_loss=0.04038, linear_loss=0.05168]
[2020-05-12 14:50:47.954]  Step 162371  [3.504 sec/step, loss=0.08998, avg_loss=0.08631, mel_loss=0.03909, linear_loss=0.05088]
[2020-05-12 14:50:49.254]  Step 162372  [3.512 sec/step, loss=0.08170, avg_loss=0.08646, mel_loss=0.03488, linear_loss=0.04681]
[2020-05-12 14:50:56.274]  Step 162373  [3.572 sec/step, loss=0.09455, avg_loss=0.08660, mel_loss=0.04259, linear_loss=0.05196]
[2020-05-12 14:51:03.618]  Step 162374  [3.637 sec/step, loss=0.09636, avg_loss=0.08684, mel_loss=0.04352, linear_loss=0.05284]
[2020-05-12 14:51:07.915]  Step 162375  [3.486 sec/step, loss=0.09374, avg_loss=0.08695, mel_loss=0.04143, linear_loss=0.05231]
[2020-05-12 14:51:09.969]  Step 162376  [3.428 sec/step, loss=0.08682, avg_loss=0.08688, mel_loss=0.03727, linear_loss=0.04955]
[2020-05-12 14:51:11.137]  Step 162377  [3.398 sec/step, loss=0.08120, avg_loss=0.08676, mel_loss=0.03439, linear_loss=0.04681]
[2020-05-12 14:51:13.036]  Step 162378  [3.363 sec/step, loss=0.08553, avg_loss=0.08667, mel_loss=0.03660, linear_loss=0.04892]
[2020-05-12 14:51:21.776]  Step 162379  [3.428 sec/step, loss=0.09349, avg_loss=0.08672, mel_loss=0.04258, linear_loss=0.05092]
[2020-05-12 14:51:27.354]  Step 162380  [3.459 sec/step, loss=0.09339, avg_loss=0.08677, mel_loss=0.04179, linear_loss=0.05160]
[2020-05-12 14:51:32.301]  Step 162381  [3.491 sec/step, loss=0.09293, avg_loss=0.08684, mel_loss=0.04114, linear_loss=0.05179]
[2020-05-12 14:51:36.168]  Step 162382  [3.496 sec/step, loss=0.09400, avg_loss=0.08685, mel_loss=0.04151, linear_loss=0.05249]
[2020-05-12 14:51:38.380]  Step 162383  [3.491 sec/step, loss=0.08843, avg_loss=0.08685, mel_loss=0.03851, linear_loss=0.04992]
[2020-05-12 14:51:39.186]  Step 162384  [3.432 sec/step, loss=0.06916, avg_loss=0.08660, mel_loss=0.02989, linear_loss=0.03927]
[2020-05-12 14:51:40.593]  Step 162385  [3.393 sec/step, loss=0.08332, avg_loss=0.08650, mel_loss=0.03585, linear_loss=0.04748]
[2020-05-12 14:51:41.591]  Step 162386  [3.390 sec/step, loss=0.07844, avg_loss=0.08644, mel_loss=0.03286, linear_loss=0.04558]
[2020-05-12 14:51:44.491]  Step 162387  [3.384 sec/step, loss=0.09492, avg_loss=0.08647, mel_loss=0.04160, linear_loss=0.05332]
[2020-05-12 14:51:46.516]  Step 162388  [3.376 sec/step, loss=0.08816, avg_loss=0.08645, mel_loss=0.03796, linear_loss=0.05020]
[2020-05-12 14:51:49.138]  Step 162389  [3.391 sec/step, loss=0.08964, avg_loss=0.08655, mel_loss=0.03927, linear_loss=0.05037]
[2020-05-12 14:51:50.771]  Step 162390  [3.400 sec/step, loss=0.08697, avg_loss=0.08671, mel_loss=0.03743, linear_loss=0.04954]
[2020-05-12 14:51:53.761]  Step 162391  [3.414 sec/step, loss=0.09378, avg_loss=0.08681, mel_loss=0.04118, linear_loss=0.05259]
[2020-05-12 14:51:57.305]  Step 162392  [3.441 sec/step, loss=0.09054, avg_loss=0.08691, mel_loss=0.03988, linear_loss=0.05066]
[2020-05-12 14:52:11.695]  Step 162393  [3.574 sec/step, loss=0.07257, avg_loss=0.08688, mel_loss=0.03385, linear_loss=0.03872]
[2020-05-12 14:52:13.094]  Step 162394  [3.571 sec/step, loss=0.08053, avg_loss=0.08682, mel_loss=0.03458, linear_loss=0.04595]
[2020-05-12 14:52:18.391]  Step 162395  [3.616 sec/step, loss=0.09464, avg_loss=0.08701, mel_loss=0.04231, linear_loss=0.05232]
[2020-05-12 14:52:19.403]  Step 162396  [3.607 sec/step, loss=0.07797, avg_loss=0.08691, mel_loss=0.03324, linear_loss=0.04473]
[2020-05-12 14:52:23.922]  Step 162397  [3.633 sec/step, loss=0.09490, avg_loss=0.08699, mel_loss=0.04225, linear_loss=0.05266]
[2020-05-12 14:52:24.763]  Step 162398  [3.554 sec/step, loss=0.07563, avg_loss=0.08680, mel_loss=0.03225, linear_loss=0.04339]
[2020-05-12 14:53:11.930]  Generated 32 batches of size 32 in 82.787 sec
[2020-05-12 14:53:13.195]  Step 162399  [3.988 sec/step, loss=0.07893, avg_loss=0.08665, mel_loss=0.03345, linear_loss=0.04549]
[2020-05-12 14:53:14.864]  Step 162400  [3.982 sec/step, loss=0.08488, avg_loss=0.08661, mel_loss=0.03669, linear_loss=0.04819]
[2020-05-12 14:53:14.864]  Writing summary at step: 162400
[2020-05-12 14:53:16.897]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162400
[2020-05-12 14:53:18.600]  Saving audio and alignment...
[2020-05-12 14:53:20.443]  Input: 저라면 이렇게 할거에엿~________
[2020-05-12 14:53:21.905]  Step 162401  [3.960 sec/step, loss=0.08252, avg_loss=0.08650, mel_loss=0.03514, linear_loss=0.04739]
[2020-05-12 14:53:23.015]  Step 162402  [3.966 sec/step, loss=0.07751, avg_loss=0.08660, mel_loss=0.03225, linear_loss=0.04527]
[2020-05-12 14:53:24.038]  Step 162403  [3.946 sec/step, loss=0.08062, avg_loss=0.08647, mel_loss=0.03402, linear_loss=0.04660]
[2020-05-12 14:53:25.456]  Step 162404  [3.828 sec/step, loss=0.08364, avg_loss=0.08650, mel_loss=0.03554, linear_loss=0.04810]
[2020-05-12 14:53:31.940]  Step 162405  [3.847 sec/step, loss=0.09408, avg_loss=0.08648, mel_loss=0.04238, linear_loss=0.05170]
[2020-05-12 14:53:34.227]  Step 162406  [3.859 sec/step, loss=0.08887, avg_loss=0.08656, mel_loss=0.03864, linear_loss=0.05023]
[2020-05-12 14:53:37.920]  Step 162407  [3.875 sec/step, loss=0.09100, avg_loss=0.08661, mel_loss=0.04014, linear_loss=0.05086]
[2020-05-12 14:53:42.275]  Step 162408  [3.907 sec/step, loss=0.09239, avg_loss=0.08672, mel_loss=0.04077, linear_loss=0.05162]
[2020-05-12 14:53:44.088]  Step 162409  [3.869 sec/step, loss=0.08577, avg_loss=0.08664, mel_loss=0.03691, linear_loss=0.04887]
[2020-05-12 14:53:57.297]  Step 162410  [3.989 sec/step, loss=0.07950, avg_loss=0.08662, mel_loss=0.03673, linear_loss=0.04277]
[2020-05-12 14:54:00.468]  Step 162411  [4.004 sec/step, loss=0.09215, avg_loss=0.08666, mel_loss=0.04055, linear_loss=0.05159]
[2020-05-12 14:54:02.277]  Step 162412  [3.959 sec/step, loss=0.08446, avg_loss=0.08657, mel_loss=0.03619, linear_loss=0.04827]
[2020-05-12 14:54:04.788]  Step 162413  [3.968 sec/step, loss=0.08915, avg_loss=0.08662, mel_loss=0.03867, linear_loss=0.05048]
[2020-05-12 14:54:09.425]  Step 162414  [3.989 sec/step, loss=0.09445, avg_loss=0.08669, mel_loss=0.04196, linear_loss=0.05249]
[2020-05-12 14:54:12.319]  Step 162415  [4.004 sec/step, loss=0.09123, avg_loss=0.08677, mel_loss=0.04005, linear_loss=0.05118]
[2020-05-12 14:54:13.370]  Step 162416  [4.008 sec/step, loss=0.08183, avg_loss=0.08691, mel_loss=0.03445, linear_loss=0.04737]
[2020-05-12 14:54:15.376]  Step 162417  [4.005 sec/step, loss=0.08716, avg_loss=0.08690, mel_loss=0.03769, linear_loss=0.04947]
[2020-05-12 14:54:22.477]  Step 162418  [4.044 sec/step, loss=0.09446, avg_loss=0.08694, mel_loss=0.04269, linear_loss=0.05177]
[2020-05-12 14:54:23.318]  Step 162419  [3.978 sec/step, loss=0.07296, avg_loss=0.08671, mel_loss=0.03070, linear_loss=0.04225]
[2020-05-12 14:54:27.739]  Step 162420  [4.004 sec/step, loss=0.09303, avg_loss=0.08680, mel_loss=0.04123, linear_loss=0.05180]
[2020-05-12 14:54:33.356]  Step 162421  [4.024 sec/step, loss=0.09265, avg_loss=0.08682, mel_loss=0.04155, linear_loss=0.05109]
[2020-05-12 14:54:37.181]  Step 162422  [4.034 sec/step, loss=0.09394, avg_loss=0.08686, mel_loss=0.04157, linear_loss=0.05236]
[2020-05-12 14:54:46.424]  Step 162423  [4.104 sec/step, loss=0.09347, avg_loss=0.08690, mel_loss=0.04260, linear_loss=0.05087]
[2020-05-12 14:54:48.954]  Step 162424  [4.099 sec/step, loss=0.08831, avg_loss=0.08688, mel_loss=0.03839, linear_loss=0.04992]
[2020-05-12 14:54:52.594]  Step 162425  [4.044 sec/step, loss=0.09312, avg_loss=0.08688, mel_loss=0.04088, linear_loss=0.05223]
[2020-05-12 14:54:53.186]  Step 162426  [4.007 sec/step, loss=0.07028, avg_loss=0.08667, mel_loss=0.03014, linear_loss=0.04014]
[2020-05-12 14:54:56.175]  Step 162427  [4.029 sec/step, loss=0.08998, avg_loss=0.08683, mel_loss=0.03954, linear_loss=0.05044]
[2020-05-12 14:55:02.056]  Step 162428  [4.054 sec/step, loss=0.09390, avg_loss=0.08685, mel_loss=0.04201, linear_loss=0.05189]
[2020-05-12 14:55:22.999]  Generated 32 batches of size 32 in 59.675 sec
[2020-05-12 14:55:24.581]  Step 162429  [4.270 sec/step, loss=0.08401, avg_loss=0.08693, mel_loss=0.03603, linear_loss=0.04798]
[2020-05-12 14:55:33.968]  Step 162430  [4.323 sec/step, loss=0.09281, avg_loss=0.08693, mel_loss=0.04229, linear_loss=0.05052]
[2020-05-12 14:55:38.445]  Step 162431  [4.330 sec/step, loss=0.09373, avg_loss=0.08692, mel_loss=0.04195, linear_loss=0.05178]
[2020-05-12 14:55:40.091]  Step 162432  [4.221 sec/step, loss=0.08401, avg_loss=0.08693, mel_loss=0.03614, linear_loss=0.04787]
[2020-05-12 14:55:42.480]  Step 162433  [4.188 sec/step, loss=0.08745, avg_loss=0.08689, mel_loss=0.03809, linear_loss=0.04936]
[2020-05-12 14:55:43.946]  Step 162434  [4.192 sec/step, loss=0.08284, avg_loss=0.08693, mel_loss=0.03558, linear_loss=0.04726]
[2020-05-12 14:55:46.222]  Step 162435  [4.194 sec/step, loss=0.08751, avg_loss=0.08695, mel_loss=0.03786, linear_loss=0.04964]
[2020-05-12 14:55:47.392]  Step 162436  [4.197 sec/step, loss=0.08130, avg_loss=0.08704, mel_loss=0.03450, linear_loss=0.04681]
[2020-05-12 14:55:49.095]  Step 162437  [4.092 sec/step, loss=0.08672, avg_loss=0.08703, mel_loss=0.03758, linear_loss=0.04914]
[2020-05-12 14:55:52.302]  Step 162438  [4.116 sec/step, loss=0.09296, avg_loss=0.08719, mel_loss=0.04101, linear_loss=0.05194]
[2020-05-12 14:55:55.080]  Step 162439  [4.068 sec/step, loss=0.08793, avg_loss=0.08711, mel_loss=0.03839, linear_loss=0.04954]
[2020-05-12 14:55:56.146]  Step 162440  [4.044 sec/step, loss=0.07926, avg_loss=0.08699, mel_loss=0.03408, linear_loss=0.04518]
[2020-05-12 14:55:56.985]  Step 162441  [3.990 sec/step, loss=0.07712, avg_loss=0.08682, mel_loss=0.03256, linear_loss=0.04456]
[2020-05-12 14:55:59.099]  Step 162442  [3.996 sec/step, loss=0.08655, avg_loss=0.08683, mel_loss=0.03748, linear_loss=0.04907]
[2020-05-12 14:56:03.031]  Step 162443  [4.008 sec/step, loss=0.09330, avg_loss=0.08687, mel_loss=0.04111, linear_loss=0.05219]
[2020-05-12 14:56:11.043]  Step 162444  [4.077 sec/step, loss=0.09598, avg_loss=0.08705, mel_loss=0.04342, linear_loss=0.05256]
[2020-05-12 14:56:11.575]  Step 162445  [4.035 sec/step, loss=0.07295, avg_loss=0.08682, mel_loss=0.03186, linear_loss=0.04108]
[2020-05-12 14:56:14.980]  Step 162446  [4.046 sec/step, loss=0.09197, avg_loss=0.08686, mel_loss=0.04042, linear_loss=0.05155]
[2020-05-12 14:56:16.938]  Step 162447  [4.035 sec/step, loss=0.08580, avg_loss=0.08683, mel_loss=0.03693, linear_loss=0.04887]
[2020-05-12 14:56:21.742]  Step 162448  [4.047 sec/step, loss=0.09330, avg_loss=0.08683, mel_loss=0.04137, linear_loss=0.05193]
[2020-05-12 14:56:23.010]  Step 162449  [4.020 sec/step, loss=0.08249, avg_loss=0.08672, mel_loss=0.03518, linear_loss=0.04731]
[2020-05-12 14:56:23.962]  Step 162450  [4.012 sec/step, loss=0.07411, avg_loss=0.08661, mel_loss=0.03144, linear_loss=0.04267]
[2020-05-12 14:56:23.962]  Writing summary at step: 162450
[2020-05-12 14:56:29.347]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162450
[2020-05-12 14:56:31.004]  Saving audio and alignment...
[2020-05-12 14:56:34.137]  Input: 자신이 한 것이 말이 아니라~_____________
[2020-05-12 14:56:38.331]  Step 162451  [4.021 sec/step, loss=0.09256, avg_loss=0.08662, mel_loss=0.04094, linear_loss=0.05162]
[2020-05-12 14:56:45.179]  Step 162452  [4.072 sec/step, loss=0.09503, avg_loss=0.08672, mel_loss=0.04284, linear_loss=0.05219]
[2020-05-12 14:56:50.894]  Step 162453  [4.119 sec/step, loss=0.09549, avg_loss=0.08688, mel_loss=0.04314, linear_loss=0.05235]
[2020-05-12 14:57:05.032]  Step 162454  [4.172 sec/step, loss=0.07493, avg_loss=0.08668, mel_loss=0.03505, linear_loss=0.03988]
[2020-05-12 14:57:07.561]  Step 162455  [4.190 sec/step, loss=0.08746, avg_loss=0.08687, mel_loss=0.03810, linear_loss=0.04936]
[2020-05-12 14:57:10.470]  Step 162456  [4.201 sec/step, loss=0.09186, avg_loss=0.08692, mel_loss=0.04018, linear_loss=0.05168]
[2020-05-12 14:57:13.773]  Step 162457  [4.221 sec/step, loss=0.09226, avg_loss=0.08701, mel_loss=0.04085, linear_loss=0.05141]
[2020-05-12 14:57:14.481]  Step 162458  [4.215 sec/step, loss=0.07261, avg_loss=0.08690, mel_loss=0.03131, linear_loss=0.04131]
[2020-05-12 14:57:45.677]  Generated 32 batches of size 32 in 74.064 sec
[2020-05-12 14:57:46.556]  Step 162459  [4.503 sec/step, loss=0.07207, avg_loss=0.08670, mel_loss=0.03085, linear_loss=0.04123]
[2020-05-12 14:57:47.781]  Step 162460  [4.463 sec/step, loss=0.08058, avg_loss=0.08657, mel_loss=0.03452, linear_loss=0.04606]
[2020-05-12 14:57:49.386]  Step 162461  [4.459 sec/step, loss=0.08522, avg_loss=0.08654, mel_loss=0.03661, linear_loss=0.04861]
[2020-05-12 14:57:50.296]  Step 162462  [4.425 sec/step, loss=0.07660, avg_loss=0.08638, mel_loss=0.03208, linear_loss=0.04452]
[2020-05-12 14:57:53.673]  Step 162463  [4.448 sec/step, loss=0.09238, avg_loss=0.08654, mel_loss=0.04048, linear_loss=0.05190]
[2020-05-12 14:57:55.644]  Step 162464  [4.441 sec/step, loss=0.08547, avg_loss=0.08650, mel_loss=0.03700, linear_loss=0.04848]
[2020-05-12 14:58:01.268]  Step 162465  [4.349 sec/step, loss=0.09454, avg_loss=0.08669, mel_loss=0.04265, linear_loss=0.05189]
[2020-05-12 14:58:02.303]  Step 162466  [4.299 sec/step, loss=0.07813, avg_loss=0.08653, mel_loss=0.03308, linear_loss=0.04505]
[2020-05-12 14:58:09.870]  Step 162467  [4.356 sec/step, loss=0.09328, avg_loss=0.08660, mel_loss=0.04226, linear_loss=0.05102]
[2020-05-12 14:58:12.280]  Step 162468  [4.374 sec/step, loss=0.08885, avg_loss=0.08682, mel_loss=0.03872, linear_loss=0.05013]
[2020-05-12 14:58:13.097]  Step 162469  [4.355 sec/step, loss=0.07394, avg_loss=0.08669, mel_loss=0.03144, linear_loss=0.04249]
[2020-05-12 14:58:17.741]  Step 162470  [4.365 sec/step, loss=0.09295, avg_loss=0.08670, mel_loss=0.04134, linear_loss=0.05161]
[2020-05-12 14:58:21.243]  Step 162471  [4.375 sec/step, loss=0.09213, avg_loss=0.08672, mel_loss=0.04074, linear_loss=0.05139]
[2020-05-12 14:58:23.018]  Step 162472  [4.380 sec/step, loss=0.08699, avg_loss=0.08677, mel_loss=0.03723, linear_loss=0.04975]
[2020-05-12 14:58:37.968]  Step 162473  [4.459 sec/step, loss=0.07433, avg_loss=0.08657, mel_loss=0.03468, linear_loss=0.03965]
[2020-05-12 14:58:41.121]  Step 162474  [4.417 sec/step, loss=0.09267, avg_loss=0.08653, mel_loss=0.04075, linear_loss=0.05192]
[2020-05-12 14:58:41.692]  Step 162475  [4.380 sec/step, loss=0.06808, avg_loss=0.08628, mel_loss=0.02940, linear_loss=0.03868]
[2020-05-12 14:58:43.113]  Step 162476  [4.374 sec/step, loss=0.08233, avg_loss=0.08623, mel_loss=0.03520, linear_loss=0.04713]
[2020-05-12 14:58:47.270]  Step 162477  [4.404 sec/step, loss=0.09320, avg_loss=0.08635, mel_loss=0.04118, linear_loss=0.05202]
[2020-05-12 14:58:51.184]  Step 162478  [4.424 sec/step, loss=0.09428, avg_loss=0.08644, mel_loss=0.04166, linear_loss=0.05262]
[2020-05-12 14:58:53.388]  Step 162479  [4.358 sec/step, loss=0.08774, avg_loss=0.08638, mel_loss=0.03783, linear_loss=0.04991]
[2020-05-12 14:58:56.205]  Step 162480  [4.331 sec/step, loss=0.08915, avg_loss=0.08634, mel_loss=0.03885, linear_loss=0.05030]
[2020-05-12 14:58:57.426]  Step 162481  [4.293 sec/step, loss=0.07995, avg_loss=0.08621, mel_loss=0.03378, linear_loss=0.04616]
[2020-05-12 14:58:59.746]  Step 162482  [4.278 sec/step, loss=0.09035, avg_loss=0.08617, mel_loss=0.03931, linear_loss=0.05104]
[2020-05-12 14:59:06.197]  Step 162483  [4.320 sec/step, loss=0.09215, avg_loss=0.08621, mel_loss=0.04151, linear_loss=0.05063]
[2020-05-12 14:59:09.828]  Step 162484  [4.349 sec/step, loss=0.09440, avg_loss=0.08646, mel_loss=0.04171, linear_loss=0.05269]
[2020-05-12 14:59:12.336]  Step 162485  [4.360 sec/step, loss=0.08912, avg_loss=0.08652, mel_loss=0.03841, linear_loss=0.05071]
[2020-05-12 14:59:17.618]  Step 162486  [4.402 sec/step, loss=0.09248, avg_loss=0.08666, mel_loss=0.04127, linear_loss=0.05121]
[2020-05-12 14:59:18.999]  Step 162487  [4.387 sec/step, loss=0.08153, avg_loss=0.08653, mel_loss=0.03483, linear_loss=0.04670]
[2020-05-12 14:59:21.905]  Step 162488  [4.396 sec/step, loss=0.08920, avg_loss=0.08654, mel_loss=0.03909, linear_loss=0.05011]
[2020-05-12 14:59:23.583]  Step 162489  [4.387 sec/step, loss=0.08431, avg_loss=0.08648, mel_loss=0.03625, linear_loss=0.04805]
[2020-05-12 14:59:32.694]  Step 162490  [4.461 sec/step, loss=0.09407, avg_loss=0.08656, mel_loss=0.04293, linear_loss=0.05115]
[2020-05-12 15:00:14.040]  Generated 32 batches of size 32 in 76.608 sec
[2020-05-12 15:00:15.249]  Step 162491  [4.857 sec/step, loss=0.08102, avg_loss=0.08643, mel_loss=0.03417, linear_loss=0.04685]
[2020-05-12 15:00:22.514]  Step 162492  [4.894 sec/step, loss=0.09607, avg_loss=0.08648, mel_loss=0.04345, linear_loss=0.05262]
[2020-05-12 15:00:23.489]  Step 162493  [4.760 sec/step, loss=0.07907, avg_loss=0.08655, mel_loss=0.03303, linear_loss=0.04604]
[2020-05-12 15:00:26.358]  Step 162494  [4.775 sec/step, loss=0.09136, avg_loss=0.08666, mel_loss=0.04006, linear_loss=0.05129]
[2020-05-12 15:00:28.373]  Step 162495  [4.742 sec/step, loss=0.08533, avg_loss=0.08656, mel_loss=0.03711, linear_loss=0.04821]
[2020-05-12 15:00:40.542]  Step 162496  [4.854 sec/step, loss=0.08159, avg_loss=0.08660, mel_loss=0.03783, linear_loss=0.04376]
[2020-05-12 15:00:44.923]  Step 162497  [4.852 sec/step, loss=0.09298, avg_loss=0.08658, mel_loss=0.04118, linear_loss=0.05180]
[2020-05-12 15:00:47.090]  Step 162498  [4.865 sec/step, loss=0.08606, avg_loss=0.08668, mel_loss=0.03721, linear_loss=0.04885]
[2020-05-12 15:00:53.337]  Step 162499  [4.444 sec/step, loss=0.09281, avg_loss=0.08682, mel_loss=0.04161, linear_loss=0.05120]
[2020-05-12 15:00:54.176]  Step 162500  [4.435 sec/step, loss=0.07338, avg_loss=0.08671, mel_loss=0.03107, linear_loss=0.04231]
[2020-05-12 15:00:54.176]  Writing summary at step: 162500
[2020-05-12 15:01:02.456]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162500
[2020-05-12 15:01:04.159]  Saving audio and alignment...
[2020-05-12 15:01:11.766]  Input: 그런데 방금 이 아카펠라 들으면서 저는 그 답을 찾은 것만 같은 느낌이 들었는데요~__
[2020-05-12 15:01:12.857]  Step 162501  [4.432 sec/step, loss=0.07932, avg_loss=0.08668, mel_loss=0.03371, linear_loss=0.04562]
[2020-05-12 15:01:14.795]  Step 162502  [4.440 sec/step, loss=0.08717, avg_loss=0.08677, mel_loss=0.03750, linear_loss=0.04968]
[2020-05-12 15:01:16.314]  Step 162503  [4.445 sec/step, loss=0.08521, avg_loss=0.08682, mel_loss=0.03659, linear_loss=0.04862]
[2020-05-12 15:01:18.886]  Step 162504  [4.456 sec/step, loss=0.09015, avg_loss=0.08688, mel_loss=0.03922, linear_loss=0.05093]
[2020-05-12 15:01:22.280]  Step 162505  [4.425 sec/step, loss=0.09161, avg_loss=0.08686, mel_loss=0.04045, linear_loss=0.05116]
[2020-05-12 15:01:25.147]  Step 162506  [4.431 sec/step, loss=0.08821, avg_loss=0.08685, mel_loss=0.03881, linear_loss=0.04940]
[2020-05-12 15:01:27.528]  Step 162507  [4.418 sec/step, loss=0.08696, avg_loss=0.08681, mel_loss=0.03770, linear_loss=0.04926]
[2020-05-12 15:01:31.283]  Step 162508  [4.412 sec/step, loss=0.08929, avg_loss=0.08678, mel_loss=0.03926, linear_loss=0.05003]
[2020-05-12 15:01:32.715]  Step 162509  [4.408 sec/step, loss=0.08414, avg_loss=0.08677, mel_loss=0.03627, linear_loss=0.04787]
[2020-05-12 15:01:36.698]  Step 162510  [4.316 sec/step, loss=0.09343, avg_loss=0.08690, mel_loss=0.04144, linear_loss=0.05199]
[2020-05-12 15:01:38.046]  Step 162511  [4.298 sec/step, loss=0.08253, avg_loss=0.08681, mel_loss=0.03522, linear_loss=0.04731]
[2020-05-12 15:01:39.162]  Step 162512  [4.291 sec/step, loss=0.08004, avg_loss=0.08676, mel_loss=0.03406, linear_loss=0.04598]
[2020-05-12 15:01:44.810]  Step 162513  [4.322 sec/step, loss=0.09536, avg_loss=0.08683, mel_loss=0.04236, linear_loss=0.05300]
[2020-05-12 15:01:45.707]  Step 162514  [4.285 sec/step, loss=0.07437, avg_loss=0.08663, mel_loss=0.03174, linear_loss=0.04263]
[2020-05-12 15:01:47.610]  Step 162515  [4.275 sec/step, loss=0.08568, avg_loss=0.08657, mel_loss=0.03675, linear_loss=0.04892]
[2020-05-12 15:01:49.339]  Step 162516  [4.282 sec/step, loss=0.08563, avg_loss=0.08661, mel_loss=0.03690, linear_loss=0.04873]
[2020-05-12 15:01:54.229]  Step 162517  [4.311 sec/step, loss=0.09502, avg_loss=0.08669, mel_loss=0.04225, linear_loss=0.05277]
[2020-05-12 15:01:57.442]  Step 162518  [4.272 sec/step, loss=0.09232, avg_loss=0.08667, mel_loss=0.04053, linear_loss=0.05179]
[2020-05-12 15:02:01.804]  Step 162519  [4.307 sec/step, loss=0.09347, avg_loss=0.08687, mel_loss=0.04124, linear_loss=0.05223]
[2020-05-12 15:02:02.401]  Step 162520  [4.269 sec/step, loss=0.06752, avg_loss=0.08662, mel_loss=0.02901, linear_loss=0.03852]
[2020-05-12 15:02:36.325]  Generated 32 batches of size 32 in 58.274 sec
[2020-05-12 15:02:38.293]  Step 162521  [4.571 sec/step, loss=0.08657, avg_loss=0.08655, mel_loss=0.03728, linear_loss=0.04928]
[2020-05-12 15:02:40.654]  Step 162522  [4.557 sec/step, loss=0.08830, avg_loss=0.08650, mel_loss=0.03856, linear_loss=0.04974]
[2020-05-12 15:02:42.528]  Step 162523  [4.483 sec/step, loss=0.08571, avg_loss=0.08642, mel_loss=0.03695, linear_loss=0.04876]
[2020-05-12 15:02:43.483]  Step 162524  [4.467 sec/step, loss=0.07441, avg_loss=0.08628, mel_loss=0.03148, linear_loss=0.04293]
[2020-05-12 15:02:45.716]  Step 162525  [4.453 sec/step, loss=0.08735, avg_loss=0.08622, mel_loss=0.03814, linear_loss=0.04921]
[2020-05-12 15:02:46.534]  Step 162526  [4.456 sec/step, loss=0.06978, avg_loss=0.08622, mel_loss=0.02989, linear_loss=0.03989]
[2020-05-12 15:02:49.689]  Step 162527  [4.457 sec/step, loss=0.09276, avg_loss=0.08625, mel_loss=0.04091, linear_loss=0.05185]
[2020-05-12 15:02:52.439]  Step 162528  [4.426 sec/step, loss=0.09066, avg_loss=0.08621, mel_loss=0.03970, linear_loss=0.05096]
[2020-05-12 15:02:53.912]  Step 162529  [4.215 sec/step, loss=0.08336, avg_loss=0.08621, mel_loss=0.03593, linear_loss=0.04743]
[2020-05-12 15:02:55.966]  Step 162530  [4.142 sec/step, loss=0.08705, avg_loss=0.08615, mel_loss=0.03761, linear_loss=0.04943]
[2020-05-12 15:03:04.950]  Step 162531  [4.187 sec/step, loss=0.09570, avg_loss=0.08617, mel_loss=0.04367, linear_loss=0.05202]
[2020-05-12 15:03:10.758]  Step 162532  [4.229 sec/step, loss=0.09461, avg_loss=0.08628, mel_loss=0.04252, linear_loss=0.05208]
[2020-05-12 15:03:18.556]  Step 162533  [4.283 sec/step, loss=0.09550, avg_loss=0.08636, mel_loss=0.04351, linear_loss=0.05199]
[2020-05-12 15:03:19.961]  Step 162534  [4.282 sec/step, loss=0.08163, avg_loss=0.08634, mel_loss=0.03491, linear_loss=0.04672]
[2020-05-12 15:03:25.207]  Step 162535  [4.312 sec/step, loss=0.09249, avg_loss=0.08639, mel_loss=0.04149, linear_loss=0.05100]
[2020-05-12 15:03:26.852]  Step 162536  [4.317 sec/step, loss=0.08459, avg_loss=0.08643, mel_loss=0.03637, linear_loss=0.04822]
[2020-05-12 15:03:29.780]  Step 162537  [4.329 sec/step, loss=0.08880, avg_loss=0.08645, mel_loss=0.03885, linear_loss=0.04996]
[2020-05-12 15:03:34.584]  Step 162538  [4.345 sec/step, loss=0.09470, avg_loss=0.08646, mel_loss=0.04221, linear_loss=0.05249]
[2020-05-12 15:03:38.744]  Step 162539  [4.359 sec/step, loss=0.09340, avg_loss=0.08652, mel_loss=0.04119, linear_loss=0.05221]
[2020-05-12 15:03:39.894]  Step 162540  [4.360 sec/step, loss=0.07984, avg_loss=0.08653, mel_loss=0.03381, linear_loss=0.04603]
[2020-05-12 15:03:40.919]  Step 162541  [4.361 sec/step, loss=0.07940, avg_loss=0.08655, mel_loss=0.03398, linear_loss=0.04542]
[2020-05-12 15:03:43.378]  Step 162542  [4.365 sec/step, loss=0.08889, avg_loss=0.08657, mel_loss=0.03842, linear_loss=0.05047]
[2020-05-12 15:03:46.581]  Step 162543  [4.358 sec/step, loss=0.09371, avg_loss=0.08658, mel_loss=0.04114, linear_loss=0.05257]
[2020-05-12 15:04:01.979]  Step 162544  [4.431 sec/step, loss=0.07460, avg_loss=0.08636, mel_loss=0.03483, linear_loss=0.03977]
[2020-05-12 15:04:03.443]  Step 162545  [4.441 sec/step, loss=0.08029, avg_loss=0.08644, mel_loss=0.03446, linear_loss=0.04583]
[2020-05-12 15:04:04.377]  Step 162546  [4.416 sec/step, loss=0.07417, avg_loss=0.08626, mel_loss=0.03152, linear_loss=0.04265]
[2020-05-12 15:04:11.531]  Step 162547  [4.468 sec/step, loss=0.09511, avg_loss=0.08635, mel_loss=0.04304, linear_loss=0.05207]
[2020-05-12 15:04:13.308]  Step 162548  [4.438 sec/step, loss=0.08586, avg_loss=0.08628, mel_loss=0.03705, linear_loss=0.04880]
[2020-05-12 15:04:17.213]  Step 162549  [4.464 sec/step, loss=0.09424, avg_loss=0.08639, mel_loss=0.04161, linear_loss=0.05263]
[2020-05-12 15:04:20.925]  Step 162550  [4.492 sec/step, loss=0.09229, avg_loss=0.08658, mel_loss=0.04086, linear_loss=0.05143]
[2020-05-12 15:04:20.925]  Writing summary at step: 162550
[2020-05-12 15:04:25.595]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162550
[2020-05-12 15:04:27.331]  Saving audio and alignment...
[2020-05-12 15:04:28.940]  Input: 됐습니다~___
[2020-05-12 15:05:21.201]  Generated 32 batches of size 32 in 94.615 sec
[2020-05-12 15:05:23.046]  Step 162551  [4.991 sec/step, loss=0.08618, avg_loss=0.08651, mel_loss=0.03676, linear_loss=0.04942]
[2020-05-12 15:05:24.333]  Step 162552  [4.935 sec/step, loss=0.07840, avg_loss=0.08635, mel_loss=0.03345, linear_loss=0.04495]
[2020-05-12 15:05:26.666]  Step 162553  [4.901 sec/step, loss=0.08557, avg_loss=0.08625, mel_loss=0.03726, linear_loss=0.04831]
[2020-05-12 15:05:30.138]  Step 162554  [4.794 sec/step, loss=0.09253, avg_loss=0.08642, mel_loss=0.04075, linear_loss=0.05178]
[2020-05-12 15:05:31.125]  Step 162555  [4.779 sec/step, loss=0.08169, avg_loss=0.08636, mel_loss=0.03480, linear_loss=0.04689]
[2020-05-12 15:05:31.907]  Step 162556  [4.758 sec/step, loss=0.07564, avg_loss=0.08620, mel_loss=0.03167, linear_loss=0.04397]
[2020-05-12 15:05:36.289]  Step 162557  [4.769 sec/step, loss=0.09433, avg_loss=0.08622, mel_loss=0.04211, linear_loss=0.05222]
[2020-05-12 15:05:41.656]  Step 162558  [4.815 sec/step, loss=0.09500, avg_loss=0.08645, mel_loss=0.04255, linear_loss=0.05245]
[2020-05-12 15:05:56.324]  Step 162559  [4.641 sec/step, loss=0.07353, avg_loss=0.08646, mel_loss=0.03460, linear_loss=0.03893]
[2020-05-12 15:05:56.897]  Step 162560  [4.635 sec/step, loss=0.06872, avg_loss=0.08634, mel_loss=0.02967, linear_loss=0.03904]
[2020-05-12 15:05:58.013]  Step 162561  [4.630 sec/step, loss=0.07834, avg_loss=0.08627, mel_loss=0.03310, linear_loss=0.04524]
[2020-05-12 15:05:59.442]  Step 162562  [4.635 sec/step, loss=0.08319, avg_loss=0.08634, mel_loss=0.03580, linear_loss=0.04739]
[2020-05-12 15:06:01.036]  Step 162563  [4.617 sec/step, loss=0.08670, avg_loss=0.08628, mel_loss=0.03739, linear_loss=0.04930]
[2020-05-12 15:06:03.995]  Step 162564  [4.627 sec/step, loss=0.09082, avg_loss=0.08634, mel_loss=0.03982, linear_loss=0.05100]
[2020-05-12 15:06:06.050]  Step 162565  [4.591 sec/step, loss=0.08800, avg_loss=0.08627, mel_loss=0.03820, linear_loss=0.04980]
[2020-05-12 15:06:08.847]  Step 162566  [4.609 sec/step, loss=0.08984, avg_loss=0.08639, mel_loss=0.03946, linear_loss=0.05038]
[2020-05-12 15:06:10.226]  Step 162567  [4.547 sec/step, loss=0.08221, avg_loss=0.08628, mel_loss=0.03537, linear_loss=0.04683]
[2020-05-12 15:06:12.408]  Step 162568  [4.545 sec/step, loss=0.08710, avg_loss=0.08626, mel_loss=0.03777, linear_loss=0.04933]
[2020-05-12 15:06:13.206]  Step 162569  [4.545 sec/step, loss=0.07279, avg_loss=0.08625, mel_loss=0.03050, linear_loss=0.04229]
[2020-05-12 15:06:14.119]  Step 162570  [4.507 sec/step, loss=0.07642, avg_loss=0.08608, mel_loss=0.03203, linear_loss=0.04440]
[2020-05-12 15:06:21.458]  Step 162571  [4.546 sec/step, loss=0.09664, avg_loss=0.08613, mel_loss=0.04376, linear_loss=0.05288]
[2020-05-12 15:06:29.712]  Step 162572  [4.610 sec/step, loss=0.09210, avg_loss=0.08618, mel_loss=0.04201, linear_loss=0.05009]
[2020-05-12 15:06:36.359]  Step 162573  [4.527 sec/step, loss=0.09464, avg_loss=0.08638, mel_loss=0.04267, linear_loss=0.05196]
[2020-05-12 15:06:39.518]  Step 162574  [4.527 sec/step, loss=0.09288, avg_loss=0.08638, mel_loss=0.04113, linear_loss=0.05175]
[2020-05-12 15:06:43.087]  Step 162575  [4.557 sec/step, loss=0.09098, avg_loss=0.08661, mel_loss=0.04016, linear_loss=0.05081]
[2020-05-12 15:06:45.019]  Step 162576  [4.562 sec/step, loss=0.08813, avg_loss=0.08667, mel_loss=0.03818, linear_loss=0.04995]
[2020-05-12 15:06:50.685]  Step 162577  [4.578 sec/step, loss=0.09488, avg_loss=0.08669, mel_loss=0.04274, linear_loss=0.05214]
[2020-05-12 15:06:53.253]  Step 162578  [4.564 sec/step, loss=0.08880, avg_loss=0.08663, mel_loss=0.03835, linear_loss=0.05044]
[2020-05-12 15:06:56.927]  Step 162579  [4.579 sec/step, loss=0.09391, avg_loss=0.08669, mel_loss=0.04141, linear_loss=0.05250]
[2020-05-12 15:07:01.700]  Step 162580  [4.598 sec/step, loss=0.09376, avg_loss=0.08674, mel_loss=0.04149, linear_loss=0.05226]
[2020-05-12 15:07:03.344]  Step 162581  [4.603 sec/step, loss=0.08575, avg_loss=0.08680, mel_loss=0.03716, linear_loss=0.04859]
[2020-05-12 15:07:07.517]  Step 162582  [4.621 sec/step, loss=0.09207, avg_loss=0.08682, mel_loss=0.04079, linear_loss=0.05129]
[2020-05-12 15:08:34.531]  Generated 32 batches of size 32 in 118.166 sec
[2020-05-12 15:08:35.752]  Step 162583  [5.439 sec/step, loss=0.08075, avg_loss=0.08670, mel_loss=0.03435, linear_loss=0.04640]
[2020-05-12 15:08:36.885]  Step 162584  [5.414 sec/step, loss=0.07619, avg_loss=0.08652, mel_loss=0.03229, linear_loss=0.04390]
[2020-05-12 15:08:39.818]  Step 162585  [5.418 sec/step, loss=0.08883, avg_loss=0.08652, mel_loss=0.03884, linear_loss=0.04999]
[2020-05-12 15:08:46.834]  Step 162586  [5.436 sec/step, loss=0.09307, avg_loss=0.08652, mel_loss=0.04205, linear_loss=0.05102]
[2020-05-12 15:08:51.202]  Step 162587  [5.465 sec/step, loss=0.09316, avg_loss=0.08664, mel_loss=0.04137, linear_loss=0.05179]
[2020-05-12 15:08:51.802]  Step 162588  [5.442 sec/step, loss=0.06666, avg_loss=0.08641, mel_loss=0.02871, linear_loss=0.03795]
[2020-05-12 15:08:52.674]  Step 162589  [5.434 sec/step, loss=0.07180, avg_loss=0.08629, mel_loss=0.03033, linear_loss=0.04147]
[2020-05-12 15:09:02.325]  Step 162590  [5.440 sec/step, loss=0.09274, avg_loss=0.08628, mel_loss=0.04243, linear_loss=0.05031]
[2020-05-12 15:09:05.435]  Step 162591  [5.045 sec/step, loss=0.09017, avg_loss=0.08637, mel_loss=0.03952, linear_loss=0.05065]
[2020-05-12 15:09:08.685]  Step 162592  [5.005 sec/step, loss=0.09100, avg_loss=0.08632, mel_loss=0.03991, linear_loss=0.05110]
[2020-05-12 15:09:10.340]  Step 162593  [5.012 sec/step, loss=0.08514, avg_loss=0.08638, mel_loss=0.03656, linear_loss=0.04859]
[2020-05-12 15:09:16.006]  Step 162594  [5.040 sec/step, loss=0.09368, avg_loss=0.08640, mel_loss=0.04176, linear_loss=0.05192]
[2020-05-12 15:09:16.926]  Step 162595  [5.029 sec/step, loss=0.07335, avg_loss=0.08628, mel_loss=0.03111, linear_loss=0.04224]
[2020-05-12 15:09:20.791]  Step 162596  [4.946 sec/step, loss=0.09077, avg_loss=0.08637, mel_loss=0.04000, linear_loss=0.05077]
[2020-05-12 15:09:24.352]  Step 162597  [4.938 sec/step, loss=0.09206, avg_loss=0.08636, mel_loss=0.04042, linear_loss=0.05164]
[2020-05-12 15:09:25.649]  Step 162598  [4.929 sec/step, loss=0.08205, avg_loss=0.08632, mel_loss=0.03485, linear_loss=0.04719]
[2020-05-12 15:09:27.042]  Step 162599  [4.880 sec/step, loss=0.08318, avg_loss=0.08623, mel_loss=0.03551, linear_loss=0.04766]
[2020-05-12 15:09:28.100]  Step 162600  [4.883 sec/step, loss=0.07558, avg_loss=0.08625, mel_loss=0.03184, linear_loss=0.04374]
[2020-05-12 15:09:28.100]  Writing summary at step: 162600
[2020-05-12 15:09:34.135]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162600
[2020-05-12 15:09:35.810]  Saving audio and alignment...
[2020-05-12 15:09:46.186]  Input: 기출이 진립니다 그것이 오로지 기출 대본만을 다루는이 강의를 만들게 된 이유이기도 해요오~____________________________
[2020-05-12 15:09:47.957]  Step 162601  [4.889 sec/step, loss=0.08716, avg_loss=0.08633, mel_loss=0.03751, linear_loss=0.04965]
[2020-05-12 15:09:50.389]  Step 162602  [4.894 sec/step, loss=0.08862, avg_loss=0.08634, mel_loss=0.03856, linear_loss=0.05005]
[2020-05-12 15:09:54.947]  Step 162603  [4.925 sec/step, loss=0.09321, avg_loss=0.08642, mel_loss=0.04141, linear_loss=0.05180]
[2020-05-12 15:10:07.456]  Step 162604  [5.024 sec/step, loss=0.08469, avg_loss=0.08637, mel_loss=0.03929, linear_loss=0.04540]
[2020-05-12 15:10:11.134]  Step 162605  [5.027 sec/step, loss=0.09287, avg_loss=0.08638, mel_loss=0.04095, linear_loss=0.05192]
[2020-05-12 15:10:15.256]  Step 162606  [5.040 sec/step, loss=0.09274, avg_loss=0.08643, mel_loss=0.04084, linear_loss=0.05191]
[2020-05-12 15:10:17.205]  Step 162607  [5.035 sec/step, loss=0.08581, avg_loss=0.08641, mel_loss=0.03704, linear_loss=0.04877]
[2020-05-12 15:10:19.361]  Step 162608  [5.019 sec/step, loss=0.08982, avg_loss=0.08642, mel_loss=0.03897, linear_loss=0.05086]
[2020-05-12 15:10:20.773]  Step 162609  [5.019 sec/step, loss=0.08221, avg_loss=0.08640, mel_loss=0.03511, linear_loss=0.04710]
[2020-05-12 15:10:23.142]  Step 162610  [5.003 sec/step, loss=0.08857, avg_loss=0.08635, mel_loss=0.03869, linear_loss=0.04988]
[2020-05-12 15:10:25.188]  Step 162611  [5.010 sec/step, loss=0.08693, avg_loss=0.08640, mel_loss=0.03749, linear_loss=0.04945]
[2020-05-12 15:10:26.855]  Step 162612  [5.015 sec/step, loss=0.08518, avg_loss=0.08645, mel_loss=0.03664, linear_loss=0.04853]
[2020-05-12 15:10:46.175]  Generated 32 batches of size 32 in 51.223 sec
[2020-05-12 15:10:47.889]  Step 162613  [5.169 sec/step, loss=0.08494, avg_loss=0.08634, mel_loss=0.03653, linear_loss=0.04841]
[2020-05-12 15:10:49.646]  Step 162614  [5.178 sec/step, loss=0.08565, avg_loss=0.08646, mel_loss=0.03662, linear_loss=0.04903]
[2020-05-12 15:10:51.490]  Step 162615  [5.177 sec/step, loss=0.08453, avg_loss=0.08644, mel_loss=0.03643, linear_loss=0.04810]
[2020-05-12 15:10:58.299]  Step 162616  [5.228 sec/step, loss=0.09468, avg_loss=0.08653, mel_loss=0.04280, linear_loss=0.05188]
[2020-05-12 15:11:01.987]  Step 162617  [5.216 sec/step, loss=0.09429, avg_loss=0.08653, mel_loss=0.04162, linear_loss=0.05268]
[2020-05-12 15:11:03.329]  Step 162618  [5.197 sec/step, loss=0.08367, avg_loss=0.08644, mel_loss=0.03570, linear_loss=0.04798]
[2020-05-12 15:11:04.649]  Step 162619  [5.167 sec/step, loss=0.08170, avg_loss=0.08632, mel_loss=0.03509, linear_loss=0.04661]
[2020-05-12 15:11:05.659]  Step 162620  [5.171 sec/step, loss=0.07785, avg_loss=0.08643, mel_loss=0.03284, linear_loss=0.04500]
[2020-05-12 15:11:06.532]  Step 162621  [4.821 sec/step, loss=0.07046, avg_loss=0.08626, mel_loss=0.03009, linear_loss=0.04037]
[2020-05-12 15:11:08.559]  Step 162622  [4.818 sec/step, loss=0.08780, avg_loss=0.08626, mel_loss=0.03777, linear_loss=0.05002]
[2020-05-12 15:11:11.822]  Step 162623  [4.831 sec/step, loss=0.09138, avg_loss=0.08632, mel_loss=0.04012, linear_loss=0.05126]
[2020-05-12 15:11:16.018]  Step 162624  [4.864 sec/step, loss=0.09156, avg_loss=0.08649, mel_loss=0.04039, linear_loss=0.05117]
[2020-05-12 15:11:18.403]  Step 162625  [4.865 sec/step, loss=0.08973, avg_loss=0.08651, mel_loss=0.03886, linear_loss=0.05086]
[2020-05-12 15:11:19.579]  Step 162626  [4.869 sec/step, loss=0.08027, avg_loss=0.08662, mel_loss=0.03422, linear_loss=0.04604]
[2020-05-12 15:11:24.360]  Step 162627  [4.885 sec/step, loss=0.09288, avg_loss=0.08662, mel_loss=0.04123, linear_loss=0.05166]
[2020-05-12 15:11:27.443]  Step 162628  [4.889 sec/step, loss=0.09166, avg_loss=0.08663, mel_loss=0.04029, linear_loss=0.05137]
[2020-05-12 15:11:28.989]  Step 162629  [4.889 sec/step, loss=0.08619, avg_loss=0.08666, mel_loss=0.03691, linear_loss=0.04928]
[2020-05-12 15:11:34.156]  Step 162630  [4.920 sec/step, loss=0.09378, avg_loss=0.08672, mel_loss=0.04194, linear_loss=0.05184]
[2020-05-12 15:11:41.718]  Step 162631  [4.906 sec/step, loss=0.09582, avg_loss=0.08673, mel_loss=0.04333, linear_loss=0.05249]
[2020-05-12 15:11:42.738]  Step 162632  [4.858 sec/step, loss=0.07835, avg_loss=0.08656, mel_loss=0.03329, linear_loss=0.04506]
[2020-05-12 15:11:48.441]  Step 162633  [4.837 sec/step, loss=0.09583, avg_loss=0.08657, mel_loss=0.04310, linear_loss=0.05273]
[2020-05-12 15:11:51.337]  Step 162634  [4.852 sec/step, loss=0.08880, avg_loss=0.08664, mel_loss=0.03902, linear_loss=0.04978]
[2020-05-12 15:11:53.476]  Step 162635  [4.821 sec/step, loss=0.08903, avg_loss=0.08660, mel_loss=0.03869, linear_loss=0.05034]
[2020-05-12 15:11:57.037]  Step 162636  [4.840 sec/step, loss=0.09016, avg_loss=0.08666, mel_loss=0.03976, linear_loss=0.05040]
[2020-05-12 15:12:11.729]  Step 162637  [4.958 sec/step, loss=0.07350, avg_loss=0.08651, mel_loss=0.03428, linear_loss=0.03922]
[2020-05-12 15:12:12.302]  Step 162638  [4.916 sec/step, loss=0.06715, avg_loss=0.08623, mel_loss=0.02914, linear_loss=0.03800]
[2020-05-12 15:12:21.338]  Step 162639  [4.964 sec/step, loss=0.09309, avg_loss=0.08623, mel_loss=0.04240, linear_loss=0.05069]
[2020-05-12 15:12:25.834]  Step 162640  [4.998 sec/step, loss=0.09432, avg_loss=0.08637, mel_loss=0.04195, linear_loss=0.05237]
[2020-05-12 15:12:28.350]  Step 162641  [5.013 sec/step, loss=0.08826, avg_loss=0.08646, mel_loss=0.03812, linear_loss=0.05015]
[2020-05-12 15:12:29.165]  Step 162642  [4.996 sec/step, loss=0.07587, avg_loss=0.08633, mel_loss=0.03193, linear_loss=0.04393]
[2020-05-12 15:12:30.297]  Step 162643  [4.976 sec/step, loss=0.08015, avg_loss=0.08619, mel_loss=0.03370, linear_loss=0.04645]
[2020-05-12 15:12:33.064]  Step 162644  [4.849 sec/step, loss=0.08889, avg_loss=0.08634, mel_loss=0.03880, linear_loss=0.05008]
[2020-05-12 15:13:28.129]  Generated 32 batches of size 32 in 94.648 sec
[2020-05-12 15:13:30.301]  Step 162645  [5.407 sec/step, loss=0.08528, avg_loss=0.08639, mel_loss=0.03701, linear_loss=0.04826]
[2020-05-12 15:13:37.931]  Step 162646  [5.474 sec/step, loss=0.09469, avg_loss=0.08659, mel_loss=0.04287, linear_loss=0.05182]
[2020-05-12 15:13:41.227]  Step 162647  [5.435 sec/step, loss=0.09320, avg_loss=0.08657, mel_loss=0.04073, linear_loss=0.05246]
[2020-05-12 15:13:45.271]  Step 162648  [5.458 sec/step, loss=0.09387, avg_loss=0.08665, mel_loss=0.04158, linear_loss=0.05229]
[2020-05-12 15:13:47.028]  Step 162649  [5.437 sec/step, loss=0.08335, avg_loss=0.08654, mel_loss=0.03572, linear_loss=0.04762]
[2020-05-12 15:13:48.222]  Step 162650  [5.411 sec/step, loss=0.07996, avg_loss=0.08642, mel_loss=0.03393, linear_loss=0.04603]
[2020-05-12 15:13:48.222]  Writing summary at step: 162650
[2020-05-12 15:13:49.159]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162650
[2020-05-12 15:13:50.857]  Saving audio and alignment...
[2020-05-12 15:13:52.718]  Input: 그렇다면~________________
[2020-05-12 15:13:55.488]  Step 162651  [4.898 sec/step, loss=0.09031, avg_loss=0.08646, mel_loss=0.03926, linear_loss=0.05105]
[2020-05-12 15:13:59.983]  Step 162652  [4.930 sec/step, loss=0.09206, avg_loss=0.08660, mel_loss=0.04068, linear_loss=0.05138]
[2020-05-12 15:14:01.702]  Step 162653  [4.924 sec/step, loss=0.08686, avg_loss=0.08661, mel_loss=0.03741, linear_loss=0.04944]
[2020-05-12 15:14:05.520]  Step 162654  [4.928 sec/step, loss=0.09155, avg_loss=0.08660, mel_loss=0.04037, linear_loss=0.05119]
[2020-05-12 15:14:06.090]  Step 162655  [4.924 sec/step, loss=0.07388, avg_loss=0.08652, mel_loss=0.03137, linear_loss=0.04251]
[2020-05-12 15:14:09.718]  Step 162656  [4.952 sec/step, loss=0.09216, avg_loss=0.08669, mel_loss=0.04063, linear_loss=0.05153]
[2020-05-12 15:14:16.180]  Step 162657  [4.973 sec/step, loss=0.09401, avg_loss=0.08669, mel_loss=0.04208, linear_loss=0.05192]
[2020-05-12 15:14:17.213]  Step 162658  [4.929 sec/step, loss=0.08010, avg_loss=0.08654, mel_loss=0.03392, linear_loss=0.04618]
[2020-05-12 15:14:19.586]  Step 162659  [4.807 sec/step, loss=0.08678, avg_loss=0.08667, mel_loss=0.03763, linear_loss=0.04914]
[2020-05-12 15:14:28.647]  Step 162660  [4.891 sec/step, loss=0.09328, avg_loss=0.08691, mel_loss=0.04240, linear_loss=0.05087]
[2020-05-12 15:14:31.719]  Step 162661  [4.911 sec/step, loss=0.09067, avg_loss=0.08704, mel_loss=0.03982, linear_loss=0.05085]
[2020-05-12 15:14:33.615]  Step 162662  [4.916 sec/step, loss=0.08478, avg_loss=0.08705, mel_loss=0.03643, linear_loss=0.04835]
[2020-05-12 15:14:34.962]  Step 162663  [4.913 sec/step, loss=0.08192, avg_loss=0.08701, mel_loss=0.03475, linear_loss=0.04717]
[2020-05-12 15:14:36.190]  Step 162664  [4.896 sec/step, loss=0.07875, avg_loss=0.08689, mel_loss=0.03363, linear_loss=0.04513]
[2020-05-12 15:14:38.318]  Step 162665  [4.897 sec/step, loss=0.08764, avg_loss=0.08688, mel_loss=0.03820, linear_loss=0.04944]
[2020-05-12 15:14:38.945]  Step 162666  [4.875 sec/step, loss=0.07201, avg_loss=0.08670, mel_loss=0.03107, linear_loss=0.04094]
[2020-05-12 15:14:40.352]  Step 162667  [4.875 sec/step, loss=0.08325, avg_loss=0.08671, mel_loss=0.03579, linear_loss=0.04746]
[2020-05-12 15:14:42.289]  Step 162668  [4.873 sec/step, loss=0.08700, avg_loss=0.08671, mel_loss=0.03713, linear_loss=0.04986]
[2020-05-12 15:14:47.200]  Step 162669  [4.914 sec/step, loss=0.09300, avg_loss=0.08692, mel_loss=0.04143, linear_loss=0.05157]
[2020-05-12 15:14:52.746]  Step 162670  [4.960 sec/step, loss=0.09422, avg_loss=0.08709, mel_loss=0.04245, linear_loss=0.05177]
[2020-05-12 15:15:07.660]  Step 162671  [5.036 sec/step, loss=0.07459, avg_loss=0.08687, mel_loss=0.03503, linear_loss=0.03956]
[2020-05-12 15:15:10.212]  Step 162672  [4.979 sec/step, loss=0.08898, avg_loss=0.08684, mel_loss=0.03907, linear_loss=0.04992]
[2020-05-12 15:15:13.826]  Step 162673  [4.949 sec/step, loss=0.09188, avg_loss=0.08681, mel_loss=0.04053, linear_loss=0.05135]
[2020-05-12 15:15:18.525]  Step 162674  [4.964 sec/step, loss=0.09356, avg_loss=0.08682, mel_loss=0.04163, linear_loss=0.05193]
[2020-05-12 15:16:02.594]  Generated 32 batches of size 32 in 84.270 sec
[2020-05-12 15:16:04.497]  Step 162675  [5.388 sec/step, loss=0.08605, avg_loss=0.08677, mel_loss=0.03681, linear_loss=0.04924]
[2020-05-12 15:16:05.495]  Step 162676  [5.379 sec/step, loss=0.07893, avg_loss=0.08668, mel_loss=0.03334, linear_loss=0.04559]
[2020-05-12 15:16:07.040]  Step 162677  [5.337 sec/step, loss=0.08442, avg_loss=0.08657, mel_loss=0.03595, linear_loss=0.04847]
[2020-05-12 15:16:10.421]  Step 162678  [5.346 sec/step, loss=0.09310, avg_loss=0.08662, mel_loss=0.04102, linear_loss=0.05208]
[2020-05-12 15:16:12.548]  Step 162679  [5.330 sec/step, loss=0.08719, avg_loss=0.08655, mel_loss=0.03758, linear_loss=0.04961]
[2020-05-12 15:16:16.175]  Step 162680  [5.319 sec/step, loss=0.09142, avg_loss=0.08653, mel_loss=0.04054, linear_loss=0.05088]
[2020-05-12 15:16:22.799]  Step 162681  [5.368 sec/step, loss=0.09373, avg_loss=0.08661, mel_loss=0.04231, linear_loss=0.05142]
[2020-05-12 15:16:36.030]  Step 162682  [5.459 sec/step, loss=0.07979, avg_loss=0.08648, mel_loss=0.03719, linear_loss=0.04260]
[2020-05-12 15:16:38.540]  Step 162683  [4.602 sec/step, loss=0.08921, avg_loss=0.08657, mel_loss=0.03865, linear_loss=0.05056]
[2020-05-12 15:16:40.811]  Step 162684  [4.613 sec/step, loss=0.08853, avg_loss=0.08669, mel_loss=0.03867, linear_loss=0.04986]
[2020-05-12 15:16:49.594]  Step 162685  [4.672 sec/step, loss=0.09383, avg_loss=0.08674, mel_loss=0.04273, linear_loss=0.05110]
[2020-05-12 15:16:55.119]  Step 162686  [4.657 sec/step, loss=0.09412, avg_loss=0.08675, mel_loss=0.04195, linear_loss=0.05217]
[2020-05-12 15:17:00.345]  Step 162687  [4.665 sec/step, loss=0.09282, avg_loss=0.08675, mel_loss=0.04133, linear_loss=0.05149]
[2020-05-12 15:17:04.661]  Step 162688  [4.702 sec/step, loss=0.09413, avg_loss=0.08702, mel_loss=0.04188, linear_loss=0.05225]
[2020-05-12 15:17:05.227]  Step 162689  [4.699 sec/step, loss=0.06802, avg_loss=0.08699, mel_loss=0.02945, linear_loss=0.03857]
[2020-05-12 15:17:06.100]  Step 162690  [4.612 sec/step, loss=0.07902, avg_loss=0.08685, mel_loss=0.03334, linear_loss=0.04568]
[2020-05-12 15:17:13.661]  Step 162691  [4.656 sec/step, loss=0.09440, avg_loss=0.08689, mel_loss=0.04296, linear_loss=0.05145]
[2020-05-12 15:17:17.845]  Step 162692  [4.665 sec/step, loss=0.09108, avg_loss=0.08689, mel_loss=0.04030, linear_loss=0.05079]
[2020-05-12 15:17:18.629]  Step 162693  [4.657 sec/step, loss=0.07374, avg_loss=0.08678, mel_loss=0.03100, linear_loss=0.04274]
[2020-05-12 15:17:21.235]  Step 162694  [4.626 sec/step, loss=0.08891, avg_loss=0.08673, mel_loss=0.03878, linear_loss=0.05012]
[2020-05-12 15:17:24.316]  Step 162695  [4.648 sec/step, loss=0.09104, avg_loss=0.08691, mel_loss=0.03974, linear_loss=0.05130]
[2020-05-12 15:17:26.198]  Step 162696  [4.628 sec/step, loss=0.08459, avg_loss=0.08685, mel_loss=0.03652, linear_loss=0.04808]
[2020-05-12 15:17:29.075]  Step 162697  [4.621 sec/step, loss=0.08984, avg_loss=0.08682, mel_loss=0.03940, linear_loss=0.05045]
[2020-05-12 15:17:30.391]  Step 162698  [4.621 sec/step, loss=0.08217, avg_loss=0.08682, mel_loss=0.03506, linear_loss=0.04711]
[2020-05-12 15:17:31.749]  Step 162699  [4.621 sec/step, loss=0.08327, avg_loss=0.08683, mel_loss=0.03555, linear_loss=0.04772]
[2020-05-12 15:17:35.606]  Step 162700  [4.649 sec/step, loss=0.09345, avg_loss=0.08700, mel_loss=0.04131, linear_loss=0.05214]
[2020-05-12 15:17:35.606]  Writing summary at step: 162700
[2020-05-12 15:17:36.956]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162700
[2020-05-12 15:17:39.451]  Saving audio and alignment...
[2020-05-12 15:17:44.512]  Input: 항상 처음이 가장 힘든 법이라 했어요~________
[2020-05-12 15:17:46.151]  Step 162701  [4.648 sec/step, loss=0.08566, avg_loss=0.08699, mel_loss=0.03677, linear_loss=0.04888]
[2020-05-12 15:17:50.820]  Step 162702  [4.670 sec/step, loss=0.09453, avg_loss=0.08705, mel_loss=0.04186, linear_loss=0.05267]
[2020-05-12 15:17:51.664]  Step 162703  [4.633 sec/step, loss=0.07319, avg_loss=0.08685, mel_loss=0.03115, linear_loss=0.04204]
[2020-05-12 15:17:52.849]  Step 162704  [4.520 sec/step, loss=0.07784, avg_loss=0.08678, mel_loss=0.03280, linear_loss=0.04504]
[2020-05-12 15:18:45.248]  Generated 32 batches of size 32 in 76.168 sec
[2020-05-12 15:18:48.173]  Step 162705  [5.036 sec/step, loss=0.08946, avg_loss=0.08675, mel_loss=0.03931, linear_loss=0.05016]
[2020-05-12 15:18:49.277]  Step 162706  [5.006 sec/step, loss=0.07498, avg_loss=0.08657, mel_loss=0.03168, linear_loss=0.04330]
[2020-05-12 15:18:49.885]  Step 162707  [4.992 sec/step, loss=0.06886, avg_loss=0.08640, mel_loss=0.02980, linear_loss=0.03906]
[2020-05-12 15:18:50.800]  Step 162708  [4.980 sec/step, loss=0.07346, avg_loss=0.08623, mel_loss=0.03073, linear_loss=0.04273]
[2020-05-12 15:18:58.647]  Step 162709  [5.044 sec/step, loss=0.09626, avg_loss=0.08638, mel_loss=0.04367, linear_loss=0.05259]
[2020-05-12 15:19:02.536]  Step 162710  [5.060 sec/step, loss=0.09349, avg_loss=0.08642, mel_loss=0.04123, linear_loss=0.05226]
[2020-05-12 15:19:05.959]  Step 162711  [5.073 sec/step, loss=0.09137, avg_loss=0.08647, mel_loss=0.04013, linear_loss=0.05124]
[2020-05-12 15:19:07.783]  Step 162712  [5.075 sec/step, loss=0.08473, avg_loss=0.08646, mel_loss=0.03652, linear_loss=0.04821]
[2020-05-12 15:19:10.933]  Step 162713  [4.896 sec/step, loss=0.09253, avg_loss=0.08654, mel_loss=0.04056, linear_loss=0.05197]
[2020-05-12 15:19:12.903]  Step 162714  [4.898 sec/step, loss=0.08816, avg_loss=0.08657, mel_loss=0.03815, linear_loss=0.05002]
[2020-05-12 15:19:16.569]  Step 162715  [4.916 sec/step, loss=0.09441, avg_loss=0.08666, mel_loss=0.04188, linear_loss=0.05254]
[2020-05-12 15:19:21.896]  Step 162716  [4.902 sec/step, loss=0.09334, avg_loss=0.08665, mel_loss=0.04172, linear_loss=0.05163]
[2020-05-12 15:19:23.278]  Step 162717  [4.879 sec/step, loss=0.08401, avg_loss=0.08655, mel_loss=0.03616, linear_loss=0.04785]
[2020-05-12 15:19:29.672]  Step 162718  [4.929 sec/step, loss=0.09528, avg_loss=0.08666, mel_loss=0.04306, linear_loss=0.05222]
[2020-05-12 15:19:30.890]  Step 162719  [4.928 sec/step, loss=0.08094, avg_loss=0.08666, mel_loss=0.03485, linear_loss=0.04609]
[2020-05-12 15:19:31.604]  Step 162720  [4.925 sec/step, loss=0.07478, avg_loss=0.08663, mel_loss=0.03232, linear_loss=0.04247]
[2020-05-12 15:19:37.658]  Step 162721  [4.977 sec/step, loss=0.09499, avg_loss=0.08687, mel_loss=0.04266, linear_loss=0.05233]
[2020-05-12 15:19:50.641]  Step 162722  [5.086 sec/step, loss=0.08565, avg_loss=0.08685, mel_loss=0.03972, linear_loss=0.04593]
[2020-05-12 15:19:59.322]  Step 162723  [5.141 sec/step, loss=0.09343, avg_loss=0.08687, mel_loss=0.04245, linear_loss=0.05097]
[2020-05-12 15:20:00.349]  Step 162724  [5.109 sec/step, loss=0.08249, avg_loss=0.08678, mel_loss=0.03497, linear_loss=0.04752]
[2020-05-12 15:20:01.829]  Step 162725  [5.100 sec/step, loss=0.08475, avg_loss=0.08673, mel_loss=0.03653, linear_loss=0.04822]
[2020-05-12 15:20:04.290]  Step 162726  [5.113 sec/step, loss=0.08826, avg_loss=0.08681, mel_loss=0.03845, linear_loss=0.04981]
[2020-05-12 15:20:07.341]  Step 162727  [5.095 sec/step, loss=0.09267, avg_loss=0.08681, mel_loss=0.04084, linear_loss=0.05183]
[2020-05-12 15:20:10.075]  Step 162728  [5.092 sec/step, loss=0.08888, avg_loss=0.08678, mel_loss=0.03880, linear_loss=0.05008]
[2020-05-12 15:20:12.228]  Step 162729  [5.098 sec/step, loss=0.08681, avg_loss=0.08679, mel_loss=0.03774, linear_loss=0.04906]
[2020-05-12 15:20:16.553]  Step 162730  [5.090 sec/step, loss=0.09289, avg_loss=0.08678, mel_loss=0.04113, linear_loss=0.05176]
[2020-05-12 15:20:18.844]  Step 162731  [5.037 sec/step, loss=0.08832, avg_loss=0.08670, mel_loss=0.03849, linear_loss=0.04983]
[2020-05-12 15:20:22.492]  Step 162732  [5.063 sec/step, loss=0.09132, avg_loss=0.08683, mel_loss=0.04021, linear_loss=0.05111]
[2020-05-12 15:20:24.305]  Step 162733  [5.024 sec/step, loss=0.08496, avg_loss=0.08672, mel_loss=0.03672, linear_loss=0.04824]
[2020-05-12 15:20:29.270]  Step 162734  [5.045 sec/step, loss=0.09239, avg_loss=0.08676, mel_loss=0.04089, linear_loss=0.05149]
[2020-05-12 15:20:30.439]  Step 162735  [5.035 sec/step, loss=0.08092, avg_loss=0.08668, mel_loss=0.03439, linear_loss=0.04652]
[2020-05-12 15:20:32.188]  Step 162736  [5.017 sec/step, loss=0.08345, avg_loss=0.08661, mel_loss=0.03613, linear_loss=0.04732]
[2020-05-12 15:21:21.883]  Generated 32 batches of size 32 in 74.538 sec
[2020-05-12 15:21:22.696]  Step 162737  [5.375 sec/step, loss=0.06917, avg_loss=0.08657, mel_loss=0.02943, linear_loss=0.03973]
[2020-05-12 15:21:23.522]  Step 162738  [5.378 sec/step, loss=0.07923, avg_loss=0.08669, mel_loss=0.03315, linear_loss=0.04609]
[2020-05-12 15:21:25.388]  Step 162739  [5.306 sec/step, loss=0.08494, avg_loss=0.08661, mel_loss=0.03621, linear_loss=0.04873]
[2020-05-12 15:21:34.341]  Step 162740  [5.351 sec/step, loss=0.09241, avg_loss=0.08659, mel_loss=0.04209, linear_loss=0.05032]
[2020-05-12 15:21:35.979]  Step 162741  [5.342 sec/step, loss=0.08599, avg_loss=0.08657, mel_loss=0.03725, linear_loss=0.04874]
[2020-05-12 15:21:39.711]  Step 162742  [5.371 sec/step, loss=0.09259, avg_loss=0.08673, mel_loss=0.04079, linear_loss=0.05180]
[2020-05-12 15:21:41.720]  Step 162743  [5.380 sec/step, loss=0.08689, avg_loss=0.08680, mel_loss=0.03760, linear_loss=0.04928]
[2020-05-12 15:21:43.862]  Step 162744  [5.374 sec/step, loss=0.08891, avg_loss=0.08680, mel_loss=0.03835, linear_loss=0.05056]
[2020-05-12 15:21:45.483]  Step 162745  [4.817 sec/step, loss=0.08314, avg_loss=0.08678, mel_loss=0.03557, linear_loss=0.04758]
[2020-05-12 15:21:46.787]  Step 162746  [4.754 sec/step, loss=0.08232, avg_loss=0.08665, mel_loss=0.03515, linear_loss=0.04717]
[2020-05-12 15:22:01.462]  Step 162747  [4.868 sec/step, loss=0.07133, avg_loss=0.08644, mel_loss=0.03329, linear_loss=0.03804]
[2020-05-12 15:22:05.150]  Step 162748  [4.864 sec/step, loss=0.09405, avg_loss=0.08644, mel_loss=0.04151, linear_loss=0.05254]
[2020-05-12 15:22:06.158]  Step 162749  [4.857 sec/step, loss=0.07951, avg_loss=0.08640, mel_loss=0.03370, linear_loss=0.04581]
[2020-05-12 15:22:13.633]  Step 162750  [4.920 sec/step, loss=0.09581, avg_loss=0.08656, mel_loss=0.04329, linear_loss=0.05253]
[2020-05-12 15:22:13.633]  Writing summary at step: 162750
[2020-05-12 15:22:14.773]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162750
[2020-05-12 15:22:16.507]  Saving audio and alignment...
[2020-05-12 15:22:21.375]  Input: 일곱 살 어린 아들을 가슴에 묻어야 했던 수녕씨~_________
[2020-05-12 15:22:21.939]  Step 162751  [4.898 sec/step, loss=0.06632, avg_loss=0.08632, mel_loss=0.02868, linear_loss=0.03763]
[2020-05-12 15:22:24.814]  Step 162752  [4.881 sec/step, loss=0.08873, avg_loss=0.08628, mel_loss=0.03874, linear_loss=0.05000]
[2020-05-12 15:22:29.850]  Step 162753  [4.915 sec/step, loss=0.09248, avg_loss=0.08634, mel_loss=0.04126, linear_loss=0.05122]
[2020-05-12 15:22:35.509]  Step 162754  [4.933 sec/step, loss=0.09402, avg_loss=0.08637, mel_loss=0.04203, linear_loss=0.05199]
[2020-05-12 15:22:42.199]  Step 162755  [4.994 sec/step, loss=0.09246, avg_loss=0.08655, mel_loss=0.04146, linear_loss=0.05100]
[2020-05-12 15:22:44.460]  Step 162756  [4.981 sec/step, loss=0.08775, avg_loss=0.08651, mel_loss=0.03814, linear_loss=0.04961]
[2020-05-12 15:22:45.687]  Step 162757  [4.928 sec/step, loss=0.07959, avg_loss=0.08636, mel_loss=0.03390, linear_loss=0.04569]
[2020-05-12 15:22:47.532]  Step 162758  [4.936 sec/step, loss=0.08612, avg_loss=0.08642, mel_loss=0.03689, linear_loss=0.04923]
[2020-05-12 15:22:52.168]  Step 162759  [4.959 sec/step, loss=0.09401, avg_loss=0.08650, mel_loss=0.04194, linear_loss=0.05207]
[2020-05-12 15:22:55.402]  Step 162760  [4.901 sec/step, loss=0.09158, avg_loss=0.08648, mel_loss=0.04024, linear_loss=0.05134]
[2020-05-12 15:22:57.900]  Step 162761  [4.895 sec/step, loss=0.08851, avg_loss=0.08646, mel_loss=0.03834, linear_loss=0.05017]
[2020-05-12 15:23:00.516]  Step 162762  [4.902 sec/step, loss=0.08814, avg_loss=0.08649, mel_loss=0.03826, linear_loss=0.04988]
[2020-05-12 15:23:01.933]  Step 162763  [4.903 sec/step, loss=0.08169, avg_loss=0.08649, mel_loss=0.03464, linear_loss=0.04705]
[2020-05-12 15:23:05.402]  Step 162764  [4.925 sec/step, loss=0.08917, avg_loss=0.08659, mel_loss=0.03930, linear_loss=0.04987]
[2020-05-12 15:23:09.767]  Step 162765  [4.948 sec/step, loss=0.09240, avg_loss=0.08664, mel_loss=0.04095, linear_loss=0.05145]
[2020-05-12 15:23:10.656]  Step 162766  [4.950 sec/step, loss=0.07850, avg_loss=0.08671, mel_loss=0.03303, linear_loss=0.04546]
[2020-05-12 15:24:09.944]  Generated 32 batches of size 32 in 84.252 sec
[2020-05-12 15:24:15.690]  Step 162767  [5.587 sec/step, loss=0.09393, avg_loss=0.08681, mel_loss=0.04221, linear_loss=0.05172]
[2020-05-12 15:24:17.047]  Step 162768  [5.581 sec/step, loss=0.07998, avg_loss=0.08674, mel_loss=0.03420, linear_loss=0.04579]
[2020-05-12 15:24:20.254]  Step 162769  [5.564 sec/step, loss=0.09316, avg_loss=0.08674, mel_loss=0.04064, linear_loss=0.05252]
[2020-05-12 15:24:21.675]  Step 162770  [5.522 sec/step, loss=0.08287, avg_loss=0.08663, mel_loss=0.03575, linear_loss=0.04712]
[2020-05-12 15:24:22.607]  Step 162771  [5.383 sec/step, loss=0.07994, avg_loss=0.08668, mel_loss=0.03400, linear_loss=0.04594]
[2020-05-12 15:24:23.454]  Step 162772  [5.366 sec/step, loss=0.07170, avg_loss=0.08651, mel_loss=0.03043, linear_loss=0.04127]
[2020-05-12 15:24:24.293]  Step 162773  [5.338 sec/step, loss=0.07408, avg_loss=0.08633, mel_loss=0.03091, linear_loss=0.04317]
[2020-05-12 15:24:27.827]  Step 162774  [5.326 sec/step, loss=0.08930, avg_loss=0.08629, mel_loss=0.03948, linear_loss=0.04982]
[2020-05-12 15:24:28.368]  Step 162775  [4.872 sec/step, loss=0.06934, avg_loss=0.08612, mel_loss=0.02983, linear_loss=0.03951]
[2020-05-12 15:24:30.399]  Step 162776  [4.882 sec/step, loss=0.08816, avg_loss=0.08622, mel_loss=0.03826, linear_loss=0.04990]
[2020-05-12 15:24:32.080]  Step 162777  [4.884 sec/step, loss=0.08318, avg_loss=0.08620, mel_loss=0.03575, linear_loss=0.04742]
[2020-05-12 15:24:35.109]  Step 162778  [4.880 sec/step, loss=0.08955, avg_loss=0.08617, mel_loss=0.03932, linear_loss=0.05023]
[2020-05-12 15:24:49.597]  Step 162779  [5.004 sec/step, loss=0.07564, avg_loss=0.08605, mel_loss=0.03544, linear_loss=0.04020]
[2020-05-12 15:24:51.759]  Step 162780  [4.989 sec/step, loss=0.08676, avg_loss=0.08601, mel_loss=0.03728, linear_loss=0.04948]
[2020-05-12 15:24:53.015]  Step 162781  [4.935 sec/step, loss=0.08211, avg_loss=0.08589, mel_loss=0.03477, linear_loss=0.04734]
[2020-05-12 15:24:56.919]  Step 162782  [4.842 sec/step, loss=0.09391, avg_loss=0.08603, mel_loss=0.04157, linear_loss=0.05234]
[2020-05-12 15:25:00.434]  Step 162783  [4.852 sec/step, loss=0.09367, avg_loss=0.08607, mel_loss=0.04147, linear_loss=0.05220]
[2020-05-12 15:25:02.870]  Step 162784  [4.854 sec/step, loss=0.08891, avg_loss=0.08608, mel_loss=0.03865, linear_loss=0.05026]
[2020-05-12 15:25:09.217]  Step 162785  [4.829 sec/step, loss=0.09218, avg_loss=0.08606, mel_loss=0.04153, linear_loss=0.05064]
[2020-05-12 15:25:18.367]  Step 162786  [4.866 sec/step, loss=0.09171, avg_loss=0.08604, mel_loss=0.04182, linear_loss=0.04989]
[2020-05-12 15:25:21.173]  Step 162787  [4.842 sec/step, loss=0.08928, avg_loss=0.08600, mel_loss=0.03908, linear_loss=0.05020]
[2020-05-12 15:25:28.300]  Step 162788  [4.870 sec/step, loss=0.09477, avg_loss=0.08601, mel_loss=0.04307, linear_loss=0.05170]
[2020-05-12 15:25:29.393]  Step 162789  [4.875 sec/step, loss=0.08142, avg_loss=0.08614, mel_loss=0.03438, linear_loss=0.04704]
[2020-05-12 15:25:31.231]  Step 162790  [4.885 sec/step, loss=0.08531, avg_loss=0.08621, mel_loss=0.03674, linear_loss=0.04856]
[2020-05-12 15:25:33.787]  Step 162791  [4.835 sec/step, loss=0.08891, avg_loss=0.08615, mel_loss=0.03863, linear_loss=0.05028]
[2020-05-12 15:25:37.772]  Step 162792  [4.833 sec/step, loss=0.09157, avg_loss=0.08616, mel_loss=0.04042, linear_loss=0.05115]
[2020-05-12 15:25:39.995]  Step 162793  [4.847 sec/step, loss=0.08540, avg_loss=0.08627, mel_loss=0.03716, linear_loss=0.04824]
[2020-05-12 15:25:41.485]  Step 162794  [4.836 sec/step, loss=0.08560, avg_loss=0.08624, mel_loss=0.03676, linear_loss=0.04884]
[2020-05-12 15:25:46.021]  Step 162795  [4.850 sec/step, loss=0.09447, avg_loss=0.08627, mel_loss=0.04198, linear_loss=0.05249]
[2020-05-12 15:25:50.423]  Step 162796  [4.875 sec/step, loss=0.09307, avg_loss=0.08636, mel_loss=0.04110, linear_loss=0.05198]
[2020-05-12 15:25:55.606]  Step 162797  [4.898 sec/step, loss=0.09346, avg_loss=0.08639, mel_loss=0.04167, linear_loss=0.05179]
[2020-05-12 15:25:56.491]  Step 162798  [4.894 sec/step, loss=0.07477, avg_loss=0.08632, mel_loss=0.03176, linear_loss=0.04301]
[2020-05-12 15:27:24.695]  Generated 32 batches of size 32 in 115.297 sec
[2020-05-12 15:27:33.174]  Step 162799  [5.847 sec/step, loss=0.09257, avg_loss=0.08641, mel_loss=0.04196, linear_loss=0.05061]
[2020-05-12 15:27:33.930]  Step 162800  [5.816 sec/step, loss=0.07256, avg_loss=0.08620, mel_loss=0.03077, linear_loss=0.04179]
[2020-05-12 15:27:33.930]  Writing summary at step: 162800
[2020-05-12 15:27:36.681]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162800
[2020-05-12 15:27:38.351]  Saving audio and alignment...
[2020-05-12 15:27:44.133]  Input: 마음속에 가장 깊은 곳을 들여다보는 시간 마음의 길을 따라~________
[2020-05-12 15:27:47.475]  Step 162801  [5.833 sec/step, loss=0.09298, avg_loss=0.08628, mel_loss=0.04073, linear_loss=0.05225]
[2020-05-12 15:27:48.258]  Step 162802  [5.794 sec/step, loss=0.07509, avg_loss=0.08608, mel_loss=0.03144, linear_loss=0.04364]
[2020-05-12 15:27:53.897]  Step 162803  [5.842 sec/step, loss=0.09467, avg_loss=0.08630, mel_loss=0.04231, linear_loss=0.05236]
[2020-05-12 15:27:57.343]  Step 162804  [5.865 sec/step, loss=0.09082, avg_loss=0.08643, mel_loss=0.04002, linear_loss=0.05080]
[2020-05-12 15:27:58.382]  Step 162805  [5.322 sec/step, loss=0.07851, avg_loss=0.08632, mel_loss=0.03338, linear_loss=0.04513]
[2020-05-12 15:28:00.513]  Step 162806  [5.332 sec/step, loss=0.08973, avg_loss=0.08647, mel_loss=0.03878, linear_loss=0.05096]
[2020-05-12 15:28:01.624]  Step 162807  [5.337 sec/step, loss=0.07963, avg_loss=0.08657, mel_loss=0.03353, linear_loss=0.04609]
[2020-05-12 15:28:02.841]  Step 162808  [5.340 sec/step, loss=0.08322, avg_loss=0.08667, mel_loss=0.03529, linear_loss=0.04793]
[2020-05-12 15:28:03.596]  Step 162809  [5.269 sec/step, loss=0.06759, avg_loss=0.08638, mel_loss=0.02994, linear_loss=0.03765]
[2020-05-12 15:28:05.928]  Step 162810  [5.254 sec/step, loss=0.08852, avg_loss=0.08633, mel_loss=0.03840, linear_loss=0.05012]
[2020-05-12 15:28:07.341]  Step 162811  [5.234 sec/step, loss=0.08431, avg_loss=0.08626, mel_loss=0.03598, linear_loss=0.04834]
[2020-05-12 15:28:09.353]  Step 162812  [5.236 sec/step, loss=0.08533, avg_loss=0.08627, mel_loss=0.03691, linear_loss=0.04842]
[2020-05-12 15:28:12.393]  Step 162813  [5.235 sec/step, loss=0.08949, avg_loss=0.08624, mel_loss=0.03922, linear_loss=0.05027]
[2020-05-12 15:28:14.213]  Step 162814  [5.233 sec/step, loss=0.08662, avg_loss=0.08622, mel_loss=0.03687, linear_loss=0.04974]
[2020-05-12 15:28:17.433]  Step 162815  [5.229 sec/step, loss=0.09190, avg_loss=0.08620, mel_loss=0.04044, linear_loss=0.05146]
[2020-05-12 15:28:22.802]  Step 162816  [5.229 sec/step, loss=0.09372, avg_loss=0.08620, mel_loss=0.04189, linear_loss=0.05184]
[2020-05-12 15:28:24.794]  Step 162817  [5.235 sec/step, loss=0.08547, avg_loss=0.08622, mel_loss=0.03653, linear_loss=0.04893]
[2020-05-12 15:28:25.845]  Step 162818  [5.182 sec/step, loss=0.07950, avg_loss=0.08606, mel_loss=0.03334, linear_loss=0.04616]
[2020-05-12 15:28:30.890]  Step 162819  [5.220 sec/step, loss=0.09317, avg_loss=0.08618, mel_loss=0.04107, linear_loss=0.05210]
[2020-05-12 15:28:32.599]  Step 162820  [5.230 sec/step, loss=0.08386, avg_loss=0.08627, mel_loss=0.03608, linear_loss=0.04778]
[2020-05-12 15:28:37.131]  Step 162821  [5.215 sec/step, loss=0.09085, avg_loss=0.08623, mel_loss=0.04044, linear_loss=0.05040]
[2020-05-12 15:28:38.936]  Step 162822  [5.103 sec/step, loss=0.08592, avg_loss=0.08623, mel_loss=0.03696, linear_loss=0.04896]
[2020-05-12 15:28:46.304]  Step 162823  [5.090 sec/step, loss=0.09401, avg_loss=0.08624, mel_loss=0.04227, linear_loss=0.05174]
[2020-05-12 15:28:59.001]  Generated 32 batches of size 32 in 28.105 sec
[2020-05-12 15:29:00.604]  Step 162824  [5.222 sec/step, loss=0.07854, avg_loss=0.08620, mel_loss=0.03640, linear_loss=0.04214]
[2020-05-12 15:29:08.945]  Step 162825  [5.291 sec/step, loss=0.09320, avg_loss=0.08628, mel_loss=0.04203, linear_loss=0.05117]
[2020-05-12 15:29:13.278]  Step 162826  [5.310 sec/step, loss=0.09320, avg_loss=0.08633, mel_loss=0.04104, linear_loss=0.05216]
[2020-05-12 15:29:14.714]  Step 162827  [5.294 sec/step, loss=0.08525, avg_loss=0.08626, mel_loss=0.03639, linear_loss=0.04886]
[2020-05-12 15:29:17.369]  Step 162828  [5.293 sec/step, loss=0.08702, avg_loss=0.08624, mel_loss=0.03774, linear_loss=0.04927]
[2020-05-12 15:29:31.374]  Step 162829  [5.411 sec/step, loss=0.07846, avg_loss=0.08616, mel_loss=0.03626, linear_loss=0.04219]
[2020-05-12 15:29:35.388]  Step 162830  [5.408 sec/step, loss=0.09351, avg_loss=0.08616, mel_loss=0.04109, linear_loss=0.05242]
[2020-05-12 15:29:37.655]  Step 162831  [5.408 sec/step, loss=0.08524, avg_loss=0.08613, mel_loss=0.03687, linear_loss=0.04837]
[2020-05-12 15:29:40.710]  Step 162832  [5.402 sec/step, loss=0.09089, avg_loss=0.08613, mel_loss=0.03991, linear_loss=0.05098]
[2020-05-12 15:29:44.960]  Step 162833  [5.427 sec/step, loss=0.09270, avg_loss=0.08621, mel_loss=0.04072, linear_loss=0.05198]
[2020-05-12 15:29:46.751]  Step 162834  [5.395 sec/step, loss=0.08470, avg_loss=0.08613, mel_loss=0.03632, linear_loss=0.04839]
[2020-05-12 15:29:48.443]  Step 162835  [5.400 sec/step, loss=0.08382, avg_loss=0.08616, mel_loss=0.03630, linear_loss=0.04752]
[2020-05-12 15:29:49.335]  Step 162836  [5.391 sec/step, loss=0.07001, avg_loss=0.08602, mel_loss=0.03004, linear_loss=0.03996]
[2020-05-12 15:29:51.298]  Step 162837  [4.906 sec/step, loss=0.08712, avg_loss=0.08620, mel_loss=0.03761, linear_loss=0.04951]
[2020-05-12 15:29:51.877]  Step 162838  [4.903 sec/step, loss=0.06665, avg_loss=0.08608, mel_loss=0.02886, linear_loss=0.03780]
[2020-05-12 15:29:56.827]  Step 162839  [4.934 sec/step, loss=0.09360, avg_loss=0.08616, mel_loss=0.04145, linear_loss=0.05215]
[2020-05-12 15:29:57.885]  Step 162840  [4.855 sec/step, loss=0.07975, avg_loss=0.08604, mel_loss=0.03360, linear_loss=0.04615]
[2020-05-12 15:29:59.473]  Step 162841  [4.855 sec/step, loss=0.08313, avg_loss=0.08601, mel_loss=0.03561, linear_loss=0.04751]
[2020-05-12 15:30:05.719]  Step 162842  [4.880 sec/step, loss=0.09339, avg_loss=0.08602, mel_loss=0.04189, linear_loss=0.05151]
[2020-05-12 15:30:06.952]  Step 162843  [4.872 sec/step, loss=0.07959, avg_loss=0.08594, mel_loss=0.03357, linear_loss=0.04602]
[2020-05-12 15:30:09.888]  Step 162844  [4.880 sec/step, loss=0.08906, avg_loss=0.08595, mel_loss=0.03891, linear_loss=0.05016]
[2020-05-12 15:30:15.532]  Step 162845  [4.920 sec/step, loss=0.09250, avg_loss=0.08604, mel_loss=0.04118, linear_loss=0.05133]
[2020-05-12 15:30:17.460]  Step 162846  [4.927 sec/step, loss=0.08453, avg_loss=0.08606, mel_loss=0.03643, linear_loss=0.04809]
[2020-05-12 15:30:20.813]  Step 162847  [4.813 sec/step, loss=0.09126, avg_loss=0.08626, mel_loss=0.03976, linear_loss=0.05151]
[2020-05-12 15:30:25.815]  Step 162848  [4.827 sec/step, loss=0.09341, avg_loss=0.08625, mel_loss=0.04156, linear_loss=0.05185]
[2020-05-12 15:30:28.577]  Step 162849  [4.844 sec/step, loss=0.08760, avg_loss=0.08634, mel_loss=0.03811, linear_loss=0.04949]
[2020-05-12 15:30:30.916]  Step 162850  [4.793 sec/step, loss=0.08519, avg_loss=0.08623, mel_loss=0.03672, linear_loss=0.04847]
[2020-05-12 15:30:30.916]  Writing summary at step: 162850
[2020-05-12 15:30:32.039]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162850
[2020-05-12 15:30:33.756]  Saving audio and alignment...
[2020-05-12 15:30:45.471]  Input: 우리 인류가 라고 했는데 한 미국인 배행사가 똑같이 처리하면 이것도 역시 반복되서 좋지 않은 쬬가 됩니다~__________________________
[2020-05-12 15:30:48.061]  Step 162851  [4.813 sec/step, loss=0.08787, avg_loss=0.08644, mel_loss=0.03814, linear_loss=0.04973]
[2020-05-12 15:30:49.458]  Step 162852  [4.798 sec/step, loss=0.08076, avg_loss=0.08637, mel_loss=0.03456, linear_loss=0.04621]
[2020-05-12 15:30:53.144]  Step 162853  [4.785 sec/step, loss=0.09008, avg_loss=0.08634, mel_loss=0.03960, linear_loss=0.05048]
[2020-05-12 15:31:00.659]  Step 162854  [4.803 sec/step, loss=0.09239, avg_loss=0.08632, mel_loss=0.04146, linear_loss=0.05094]
[2020-05-12 15:31:02.079]  Step 162855  [4.750 sec/step, loss=0.08230, avg_loss=0.08622, mel_loss=0.03513, linear_loss=0.04718]
[2020-05-12 15:31:05.737]  Step 162856  [4.764 sec/step, loss=0.09269, avg_loss=0.08627, mel_loss=0.04082, linear_loss=0.05188]
[2020-05-12 15:31:06.660]  Step 162857  [4.761 sec/step, loss=0.07923, avg_loss=0.08627, mel_loss=0.03294, linear_loss=0.04628]
[2020-05-12 15:31:07.520]  Step 162858  [4.752 sec/step, loss=0.07463, avg_loss=0.08615, mel_loss=0.03136, linear_loss=0.04328]
[2020-05-12 15:32:21.827]  Generated 32 batches of size 32 in 107.442 sec
[2020-05-12 15:32:25.927]  Step 162859  [5.489 sec/step, loss=0.09042, avg_loss=0.08612, mel_loss=0.03984, linear_loss=0.05058]
[2020-05-12 15:32:26.726]  Step 162860  [5.465 sec/step, loss=0.07467, avg_loss=0.08595, mel_loss=0.03119, linear_loss=0.04348]
[2020-05-12 15:32:32.237]  Step 162861  [5.495 sec/step, loss=0.09441, avg_loss=0.08601, mel_loss=0.04227, linear_loss=0.05214]
[2020-05-12 15:32:35.241]  Step 162862  [5.499 sec/step, loss=0.09040, avg_loss=0.08603, mel_loss=0.03967, linear_loss=0.05072]
[2020-05-12 15:32:37.442]  Step 162863  [5.507 sec/step, loss=0.08787, avg_loss=0.08609, mel_loss=0.03816, linear_loss=0.04971]
[2020-05-12 15:32:41.159]  Step 162864  [5.509 sec/step, loss=0.09370, avg_loss=0.08614, mel_loss=0.04155, linear_loss=0.05215]
[2020-05-12 15:32:42.430]  Step 162865  [5.478 sec/step, loss=0.07894, avg_loss=0.08600, mel_loss=0.03379, linear_loss=0.04516]
[2020-05-12 15:32:44.231]  Step 162866  [5.487 sec/step, loss=0.08560, avg_loss=0.08607, mel_loss=0.03635, linear_loss=0.04925]
[2020-05-12 15:32:45.277]  Step 162867  [4.848 sec/step, loss=0.07499, avg_loss=0.08588, mel_loss=0.03206, linear_loss=0.04293]
[2020-05-12 15:32:46.131]  Step 162868  [4.843 sec/step, loss=0.07095, avg_loss=0.08579, mel_loss=0.03004, linear_loss=0.04092]
[2020-05-12 15:32:47.748]  Step 162869  [4.827 sec/step, loss=0.08464, avg_loss=0.08571, mel_loss=0.03625, linear_loss=0.04839]
[2020-05-12 15:32:49.247]  Step 162870  [4.827 sec/step, loss=0.08405, avg_loss=0.08572, mel_loss=0.03575, linear_loss=0.04830]
[2020-05-12 15:32:51.563]  Step 162871  [4.841 sec/step, loss=0.08935, avg_loss=0.08582, mel_loss=0.03881, linear_loss=0.05054]
[2020-05-12 15:32:57.464]  Step 162872  [4.892 sec/step, loss=0.09645, avg_loss=0.08606, mel_loss=0.04342, linear_loss=0.05303]
[2020-05-12 15:32:59.439]  Step 162873  [4.903 sec/step, loss=0.08593, avg_loss=0.08618, mel_loss=0.03695, linear_loss=0.04898]
[2020-05-12 15:33:02.287]  Step 162874  [4.896 sec/step, loss=0.08800, avg_loss=0.08617, mel_loss=0.03865, linear_loss=0.04936]
[2020-05-12 15:33:02.845]  Step 162875  [4.896 sec/step, loss=0.06709, avg_loss=0.08615, mel_loss=0.02867, linear_loss=0.03842]
[2020-05-12 15:33:03.841]  Step 162876  [4.886 sec/step, loss=0.07670, avg_loss=0.08603, mel_loss=0.03240, linear_loss=0.04431]
[2020-05-12 15:33:18.542]  Step 162877  [5.016 sec/step, loss=0.07466, avg_loss=0.08595, mel_loss=0.03473, linear_loss=0.03993]
[2020-05-12 15:33:22.090]  Step 162878  [5.021 sec/step, loss=0.09148, avg_loss=0.08597, mel_loss=0.04040, linear_loss=0.05108]
[2020-05-12 15:33:23.871]  Step 162879  [4.894 sec/step, loss=0.08446, avg_loss=0.08605, mel_loss=0.03608, linear_loss=0.04837]
[2020-05-12 15:33:26.511]  Step 162880  [4.899 sec/step, loss=0.08760, avg_loss=0.08606, mel_loss=0.03789, linear_loss=0.04971]
[2020-05-12 15:33:29.606]  Step 162881  [4.918 sec/step, loss=0.09480, avg_loss=0.08619, mel_loss=0.04169, linear_loss=0.05312]
[2020-05-12 15:33:33.104]  Step 162882  [4.914 sec/step, loss=0.09226, avg_loss=0.08617, mel_loss=0.04052, linear_loss=0.05174]
[2020-05-12 15:33:40.925]  Step 162883  [4.957 sec/step, loss=0.09540, avg_loss=0.08619, mel_loss=0.04308, linear_loss=0.05232]
[2020-05-12 15:33:42.954]  Step 162884  [4.953 sec/step, loss=0.08954, avg_loss=0.08620, mel_loss=0.03854, linear_loss=0.05100]
[2020-05-12 15:33:47.990]  Step 162885  [4.939 sec/step, loss=0.09338, avg_loss=0.08621, mel_loss=0.04164, linear_loss=0.05174]
[2020-05-12 15:33:49.146]  Step 162886  [4.859 sec/step, loss=0.07975, avg_loss=0.08609, mel_loss=0.03376, linear_loss=0.04598]
[2020-05-12 15:33:53.442]  Step 162887  [4.874 sec/step, loss=0.09527, avg_loss=0.08615, mel_loss=0.04250, linear_loss=0.05277]
[2020-05-12 15:33:54.850]  Step 162888  [4.817 sec/step, loss=0.08397, avg_loss=0.08604, mel_loss=0.03587, linear_loss=0.04810]
[2020-05-12 15:34:01.604]  Step 162889  [4.874 sec/step, loss=0.09585, avg_loss=0.08618, mel_loss=0.04336, linear_loss=0.05250]
[2020-05-12 15:34:10.595]  Step 162890  [4.945 sec/step, loss=0.09500, avg_loss=0.08628, mel_loss=0.04344, linear_loss=0.05156]
[2020-05-12 15:35:23.712]  Generated 32 batches of size 32 in 114.101 sec
[2020-05-12 15:35:24.396]  Step 162891  [5.658 sec/step, loss=0.07296, avg_loss=0.08612, mel_loss=0.03118, linear_loss=0.04177]
[2020-05-12 15:35:25.357]  Step 162892  [5.628 sec/step, loss=0.07861, avg_loss=0.08599, mel_loss=0.03302, linear_loss=0.04559]
[2020-05-12 15:35:32.844]  Step 162893  [5.680 sec/step, loss=0.09422, avg_loss=0.08608, mel_loss=0.04261, linear_loss=0.05162]
[2020-05-12 15:35:39.502]  Step 162894  [5.732 sec/step, loss=0.09367, avg_loss=0.08616, mel_loss=0.04212, linear_loss=0.05155]
[2020-05-12 15:35:40.881]  Step 162895  [5.700 sec/step, loss=0.08093, avg_loss=0.08603, mel_loss=0.03453, linear_loss=0.04640]
[2020-05-12 15:35:44.531]  Step 162896  [5.693 sec/step, loss=0.09029, avg_loss=0.08600, mel_loss=0.03973, linear_loss=0.05056]
[2020-05-12 15:35:48.339]  Step 162897  [5.679 sec/step, loss=0.09444, avg_loss=0.08601, mel_loss=0.04164, linear_loss=0.05279]
[2020-05-12 15:35:50.249]  Step 162898  [5.690 sec/step, loss=0.08445, avg_loss=0.08610, mel_loss=0.03626, linear_loss=0.04819]
[2020-05-12 15:35:53.542]  Step 162899  [4.756 sec/step, loss=0.09013, avg_loss=0.08608, mel_loss=0.03966, linear_loss=0.05047]
[2020-05-12 15:36:02.189]  Step 162900  [4.835 sec/step, loss=0.09134, avg_loss=0.08627, mel_loss=0.04164, linear_loss=0.04970]
[2020-05-12 15:36:02.189]  Writing summary at step: 162900
[2020-05-12 15:36:07.126]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162900
[2020-05-12 15:36:08.826]  Saving audio and alignment...
[2020-05-12 15:36:17.231]  Input: 그냥 이 사람 무미건조게 읽으시기 보다는 이 사람 하고 살짝 올려 주시면~_________________________________
[2020-05-12 15:36:21.373]  Step 162901  [4.843 sec/step, loss=0.09285, avg_loss=0.08627, mel_loss=0.04089, linear_loss=0.05196]
[2020-05-12 15:36:21.989]  Step 162902  [4.841 sec/step, loss=0.06809, avg_loss=0.08620, mel_loss=0.02962, linear_loss=0.03847]
[2020-05-12 15:36:27.660]  Step 162903  [4.841 sec/step, loss=0.09190, avg_loss=0.08617, mel_loss=0.04094, linear_loss=0.05096]
[2020-05-12 15:36:29.383]  Step 162904  [4.824 sec/step, loss=0.08430, avg_loss=0.08610, mel_loss=0.03651, linear_loss=0.04779]
[2020-05-12 15:36:42.931]  Step 162905  [4.949 sec/step, loss=0.08360, avg_loss=0.08615, mel_loss=0.03889, linear_loss=0.04471]
[2020-05-12 15:36:47.552]  Step 162906  [4.974 sec/step, loss=0.09101, avg_loss=0.08617, mel_loss=0.04031, linear_loss=0.05070]
[2020-05-12 15:36:48.491]  Step 162907  [4.972 sec/step, loss=0.07622, avg_loss=0.08613, mel_loss=0.03205, linear_loss=0.04417]
[2020-05-12 15:36:51.571]  Step 162908  [4.991 sec/step, loss=0.08956, avg_loss=0.08620, mel_loss=0.03927, linear_loss=0.05029]
[2020-05-12 15:36:53.953]  Step 162909  [5.007 sec/step, loss=0.08634, avg_loss=0.08638, mel_loss=0.03763, linear_loss=0.04871]
[2020-05-12 15:36:56.573]  Step 162910  [5.010 sec/step, loss=0.08819, avg_loss=0.08638, mel_loss=0.03821, linear_loss=0.04998]
[2020-05-12 15:37:00.023]  Step 162911  [5.030 sec/step, loss=0.09253, avg_loss=0.08646, mel_loss=0.04070, linear_loss=0.05183]
[2020-05-12 15:37:01.166]  Step 162912  [5.022 sec/step, loss=0.08062, avg_loss=0.08642, mel_loss=0.03418, linear_loss=0.04643]
[2020-05-12 15:37:02.996]  Step 162913  [5.010 sec/step, loss=0.08724, avg_loss=0.08639, mel_loss=0.03752, linear_loss=0.04972]
[2020-05-12 15:37:04.601]  Step 162914  [5.008 sec/step, loss=0.08265, avg_loss=0.08635, mel_loss=0.03563, linear_loss=0.04702]
[2020-05-12 15:37:05.451]  Step 162915  [4.984 sec/step, loss=0.07520, avg_loss=0.08619, mel_loss=0.03167, linear_loss=0.04352]
[2020-05-12 15:37:07.659]  Step 162916  [4.952 sec/step, loss=0.08757, avg_loss=0.08613, mel_loss=0.03783, linear_loss=0.04973]
[2020-05-12 15:37:09.804]  Step 162917  [4.954 sec/step, loss=0.08610, avg_loss=0.08613, mel_loss=0.03727, linear_loss=0.04883]
[2020-05-12 15:37:12.748]  Step 162918  [4.973 sec/step, loss=0.08807, avg_loss=0.08622, mel_loss=0.03843, linear_loss=0.04964]
[2020-05-12 15:37:14.124]  Step 162919  [4.936 sec/step, loss=0.08211, avg_loss=0.08611, mel_loss=0.03512, linear_loss=0.04698]
[2020-05-12 15:37:15.382]  Step 162920  [4.931 sec/step, loss=0.07892, avg_loss=0.08606, mel_loss=0.03312, linear_loss=0.04580]
[2020-05-12 15:38:33.078]  Generated 32 batches of size 32 in 93.049 sec
[2020-05-12 15:38:36.103]  Step 162921  [5.693 sec/step, loss=0.09207, avg_loss=0.08607, mel_loss=0.04017, linear_loss=0.05191]
[2020-05-12 15:38:36.915]  Step 162922  [5.683 sec/step, loss=0.06464, avg_loss=0.08586, mel_loss=0.02791, linear_loss=0.03673]
[2020-05-12 15:38:38.700]  Step 162923  [5.628 sec/step, loss=0.08686, avg_loss=0.08579, mel_loss=0.03743, linear_loss=0.04943]
[2020-05-12 15:38:44.030]  Step 162924  [5.538 sec/step, loss=0.09444, avg_loss=0.08594, mel_loss=0.04219, linear_loss=0.05225]
[2020-05-12 15:38:51.364]  Step 162925  [5.528 sec/step, loss=0.09518, avg_loss=0.08596, mel_loss=0.04296, linear_loss=0.05223]
[2020-05-12 15:38:52.579]  Step 162926  [5.497 sec/step, loss=0.08124, avg_loss=0.08584, mel_loss=0.03472, linear_loss=0.04651]
[2020-05-12 15:38:53.951]  Step 162927  [5.496 sec/step, loss=0.08527, avg_loss=0.08585, mel_loss=0.03656, linear_loss=0.04871]
[2020-05-12 15:38:56.495]  Step 162928  [5.495 sec/step, loss=0.08761, avg_loss=0.08585, mel_loss=0.03790, linear_loss=0.04972]
[2020-05-12 15:39:00.252]  Step 162929  [5.392 sec/step, loss=0.09457, avg_loss=0.08601, mel_loss=0.04177, linear_loss=0.05281]
[2020-05-12 15:39:01.661]  Step 162930  [5.366 sec/step, loss=0.08377, avg_loss=0.08591, mel_loss=0.03584, linear_loss=0.04793]
[2020-05-12 15:39:04.753]  Step 162931  [5.375 sec/step, loss=0.09202, avg_loss=0.08598, mel_loss=0.04007, linear_loss=0.05195]
[2020-05-12 15:39:05.804]  Step 162932  [5.355 sec/step, loss=0.07568, avg_loss=0.08583, mel_loss=0.03181, linear_loss=0.04387]
[2020-05-12 15:39:10.069]  Step 162933  [5.355 sec/step, loss=0.09270, avg_loss=0.08583, mel_loss=0.04074, linear_loss=0.05196]
[2020-05-12 15:39:11.699]  Step 162934  [5.353 sec/step, loss=0.08787, avg_loss=0.08586, mel_loss=0.03775, linear_loss=0.05013]
[2020-05-12 15:39:12.549]  Step 162935  [5.345 sec/step, loss=0.07055, avg_loss=0.08573, mel_loss=0.03006, linear_loss=0.04049]
[2020-05-12 15:39:14.869]  Step 162936  [5.359 sec/step, loss=0.08696, avg_loss=0.08590, mel_loss=0.03763, linear_loss=0.04933]
[2020-05-12 15:39:17.463]  Step 162937  [5.365 sec/step, loss=0.08927, avg_loss=0.08592, mel_loss=0.03893, linear_loss=0.05034]
[2020-05-12 15:39:22.315]  Step 162938  [5.408 sec/step, loss=0.09304, avg_loss=0.08618, mel_loss=0.04137, linear_loss=0.05167]
[2020-05-12 15:39:23.912]  Step 162939  [5.374 sec/step, loss=0.08309, avg_loss=0.08608, mel_loss=0.03570, linear_loss=0.04739]
[2020-05-12 15:39:30.798]  Step 162940  [5.433 sec/step, loss=0.09421, avg_loss=0.08622, mel_loss=0.04241, linear_loss=0.05180]
[2020-05-12 15:39:36.550]  Step 162941  [5.474 sec/step, loss=0.09455, avg_loss=0.08634, mel_loss=0.04233, linear_loss=0.05221]
[2020-05-12 15:39:45.563]  Step 162942  [5.502 sec/step, loss=0.09526, avg_loss=0.08636, mel_loss=0.04354, linear_loss=0.05172]
[2020-05-12 15:39:46.425]  Step 162943  [5.498 sec/step, loss=0.07202, avg_loss=0.08628, mel_loss=0.03010, linear_loss=0.04192]
[2020-05-12 15:39:47.499]  Step 162944  [5.480 sec/step, loss=0.07688, avg_loss=0.08616, mel_loss=0.03281, linear_loss=0.04407]
[2020-05-12 15:39:49.469]  Step 162945  [5.443 sec/step, loss=0.08701, avg_loss=0.08610, mel_loss=0.03743, linear_loss=0.04957]
[2020-05-12 15:39:53.756]  Step 162946  [5.467 sec/step, loss=0.09430, avg_loss=0.08620, mel_loss=0.04206, linear_loss=0.05225]
[2020-05-12 15:39:54.897]  Step 162947  [5.444 sec/step, loss=0.07799, avg_loss=0.08607, mel_loss=0.03309, linear_loss=0.04490]
[2020-05-12 15:39:57.112]  Step 162948  [5.417 sec/step, loss=0.08846, avg_loss=0.08602, mel_loss=0.03842, linear_loss=0.05004]
[2020-05-12 15:40:00.616]  Step 162949  [5.424 sec/step, loss=0.09197, avg_loss=0.08606, mel_loss=0.04053, linear_loss=0.05143]
[2020-05-12 15:40:04.102]  Step 162950  [5.435 sec/step, loss=0.09121, avg_loss=0.08612, mel_loss=0.04042, linear_loss=0.05079]
[2020-05-12 15:40:04.102]  Writing summary at step: 162950
[2020-05-12 15:40:18.477]  Saving checkpoint to: ./logs-tacotron/model.ckpt-162950
[2020-05-12 15:40:20.225]  Saving audio and alignment...
[2020-05-12 15:40:24.882]  Input: 문제에 현미밥만 원망스럽게 바라본다~_____________________
[2020-05-12 15:41:10.306]  Generated 32 batches of size 32 in 83.876 sec
[2020-05-12 15:41:10.901]  Step 162951  [5.870 sec/step, loss=0.06731, avg_loss=0.08592, mel_loss=0.02884, linear_loss=0.03848]
[2020-05-12 15:41:11.791]  Step 162952  [5.865 sec/step, loss=0.07816, avg_loss=0.08589, mel_loss=0.03301, linear_loss=0.04516]
[2020-05-12 15:41:14.948]  Step 162953  [5.860 sec/step, loss=0.09249, avg_loss=0.08592, mel_loss=0.04072, linear_loss=0.05177]
[2020-05-12 15:41:16.204]  Step 162954  [5.797 sec/step, loss=0.07934, avg_loss=0.08579, mel_loss=0.03398, linear_loss=0.04536]
[2020-05-12 15:41:17.816]  Step 162955  [5.799 sec/step, loss=0.08486, avg_loss=0.08581, mel_loss=0.03650, linear_loss=0.04836]
[2020-05-12 15:41:21.936]  Step 162956  [5.804 sec/step, loss=0.09151, avg_loss=0.08580, mel_loss=0.04064, linear_loss=0.05087]
[2020-05-12 15:41:27.471]  Step 162957  [5.850 sec/step, loss=0.09442, avg_loss=0.08595, mel_loss=0.04244, linear_loss=0.05198]
[2020-05-12 15:41:29.491]  Step 162958  [5.861 sec/step, loss=0.08754, avg_loss=0.08608, mel_loss=0.03797, linear_loss=0.04957]
[2020-05-12 15:41:34.477]  Step 162959  [5.127 sec/step, loss=0.09346, avg_loss=0.08611, mel_loss=0.04169, linear_loss=0.05177]
[2020-05-12 15:41:35.591]  Step 162960  [5.130 sec/step, loss=0.08106, avg_loss=0.08617, mel_loss=0.03430, linear_loss=0.04676]
[2020-05-12 15:41:44.273]  Step 162961  [5.162 sec/step, loss=0.09364, avg_loss=0.08617, mel_loss=0.04259, linear_loss=0.05105]
[2020-05-12 15:41:47.727]  Step 162962  [5.166 sec/step, loss=0.09049, avg_loss=0.08617, mel_loss=0.03985, linear_loss=0.05064]
[2020-05-12 15:41:48.746]  Step 162963  [5.155 sec/step, loss=0.07736, avg_loss=0.08606, mel_loss=0.03294, linear_loss=0.04441]
[2020-05-12 15:41:52.391]  Step 162964  [5.154 sec/step, loss=0.09341, avg_loss=0.08606, mel_loss=0.04127, linear_loss=0.05214]
[2020-05-12 15:41:54.823]  Step 162965  [5.165 sec/step, loss=0.08953, avg_loss=0.08617, mel_loss=0.03885, linear_loss=0.05067]
[2020-05-12 15:41:56.549]  Step 162966  [5.165 sec/step, loss=0.08641, avg_loss=0.08617, mel_loss=0.03715, linear_loss=0.04926]
[2020-05-12 15:41:59.191]  Step 162967  [5.181 sec/step, loss=0.08973, avg_loss=0.08632, mel_loss=0.03919, linear_loss=0.05054]
[2020-05-12 15:42:05.329]  Step 162968  [5.233 sec/step, loss=0.09349, avg_loss=0.08655, mel_loss=0.04210, linear_loss=0.05139]
[2020-05-12 15:42:05.949]  Step 162969  [5.224 sec/step, loss=0.07194, avg_loss=0.08642, mel_loss=0.03129, linear_loss=0.04066]
[2020-05-12 15:42:08.512]  Step 162970  [5.234 sec/step, loss=0.08651, avg_loss=0.08644, mel_loss=0.03775, linear_loss=0.04877]
[2020-05-12 15:42:09.322]  Step 162971  [5.219 sec/step, loss=0.07286, avg_loss=0.08628, mel_loss=0.03099, linear_loss=0.04187]
[2020-05-12 15:42:11.149]  Step 162972  [5.178 sec/step, loss=0.08470, avg_loss=0.08616, mel_loss=0.03636, linear_loss=0.04834]
[2020-05-12 15:42:12.620]  Step 162973  [5.173 sec/step, loss=0.08261, avg_loss=0.08613, mel_loss=0.03541, linear_loss=0.04721]
[2020-05-12 15:42:26.437]  Step 162974  [5.283 sec/step, loss=0.07905, avg_loss=0.08604, mel_loss=0.03653, linear_loss=0.04252]
[2020-05-12 15:42:29.887]  Step 162975  [5.312 sec/step, loss=0.09161, avg_loss=0.08628, mel_loss=0.04023, linear_loss=0.05139]
[2020-05-12 15:42:37.471]  Step 162976  [5.378 sec/step, loss=0.09442, avg_loss=0.08646, mel_loss=0.04281, linear_loss=0.05161]
[2020-05-12 15:42:41.550]  Step 162977  [5.272 sec/step, loss=0.09331, avg_loss=0.08665, mel_loss=0.04110, linear_loss=0.05221]
[2020-05-12 15:42:42.949]  Step 162978  [5.250 sec/step, loss=0.08075, avg_loss=0.08654, mel_loss=0.03464, linear_loss=0.04611]
[2020-05-12 15:42:45.951]  Step 162979  [5.262 sec/step, loss=0.09029, avg_loss=0.08660, mel_loss=0.03936, linear_loss=0.05093]
[2020-05-12 15:42:48.215]  Step 162980  [5.259 sec/step, loss=0.08861, avg_loss=0.08661, mel_loss=0.03832, linear_loss=0.05029]
[2020-05-12 15:42:50.239]  Step 162981  [5.248 sec/step, loss=0.08518, avg_loss=0.08651, mel_loss=0.03702, linear_loss=0.04816]
[2020-05-12 15:42:54.902]  Step 162982  [5.259 sec/step, loss=0.09334, avg_loss=0.08652, mel_loss=0.04138, linear_loss=0.05196]
[2020-05-12 15:43:18.723]  Generated 32 batches of size 32 in 66.097 sec
[2020-05-12 15:43:23.711]  Step 162983  [5.469 sec/step, loss=0.09347, avg_loss=0.08650, mel_loss=0.04159, linear_loss=0.05188]
[2020-05-12 15:43:26.288]  Step 162984  [5.475 sec/step, loss=0.08847, avg_loss=0.08649, mel_loss=0.03840, linear_loss=0.05007]
[2020-05-12 15:43:29.832]  Step 162985  [5.460 sec/step, loss=0.09115, avg_loss=0.08647, mel_loss=0.04013, linear_loss=0.05103]
[2020-05-12 15:43:31.675]  Step 162986  [5.467 sec/step, loss=0.08512, avg_loss=0.08652, mel_loss=0.03630, linear_loss=0.04882]
[2020-05-12 15:43:33.727]  Step 162987  [5.444 sec/step, loss=0.08709, avg_loss=0.08644, mel_loss=0.03787, linear_loss=0.04922]
[2020-05-12 15:43:36.662]  Step 162988  [5.460 sec/step, loss=0.09219, avg_loss=0.08653, mel_loss=0.04055, linear_loss=0.05164]
[2020-05-12 15:43:41.187]  Step 162989  [5.437 sec/step, loss=0.09459, avg_loss=0.08651, mel_loss=0.04198, linear_loss=0.05261]
[2020-05-12 15:43:42.733]  Step 162990  [5.363 sec/step, loss=0.08443, avg_loss=0.08641, mel_loss=0.03619, linear_loss=0.04824]
[2020-05-12 15:43:47.028]  Step 162991  [4.668 sec/step, loss=0.09139, avg_loss=0.08659, mel_loss=0.04037, linear_loss=0.05102]
[2020-05-12 15:43:48.513]  Step 162992  [4.673 sec/step, loss=0.08003, avg_loss=0.08661, mel_loss=0.03431, linear_loss=0.04573]
[2020-05-12 15:43:50.970]  Step 162993  [4.623 sec/step, loss=0.08869, avg_loss=0.08655, mel_loss=0.03837, linear_loss=0.05031]
[2020-05-12 15:43:51.805]  Step 162994  [4.565 sec/step, loss=0.07493, avg_loss=0.08636, mel_loss=0.03168, linear_loss=0.04324]
[2020-05-12 15:43:53.729]  Step 162995  [4.570 sec/step, loss=0.08570, avg_loss=0.08641, mel_loss=0.03682, linear_loss=0.04889]
[2020-05-12 15:43:57.406]  Step 162996  [4.570 sec/step, loss=0.09381, avg_loss=0.08645, mel_loss=0.04155, linear_loss=0.05226]
[2020-05-12 15:44:00.020]  Step 162997  [4.558 sec/step, loss=0.09175, avg_loss=0.08642, mel_loss=0.04045, linear_loss=0.05130]
[2020-05-12 15:44:06.396]  Step 162998  [4.603 sec/step, loss=0.09408, avg_loss=0.08652, mel_loss=0.04238, linear_loss=0.05171]
[2020-05-12 15:44:08.160]  Step 162999  [4.588 sec/step, loss=0.08483, avg_loss=0.08646, mel_loss=0.03629, linear_loss=0.04854]
[2020-05-12 15:44:11.505]  Step 163000  [4.535 sec/step, loss=0.09247, avg_loss=0.08647, mel_loss=0.04102, linear_loss=0.05145]
[2020-05-12 15:44:11.506]  Writing summary at step: 163000
[2020-05-12 15:44:26.427]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163000
[2020-05-12 15:44:28.176]  Saving audio and alignment...
[2020-05-12 15:44:30.375]  Input: 아니라요~___________________
[2020-05-12 15:44:30.939]  Step 163001  [4.499 sec/step, loss=0.07006, avg_loss=0.08625, mel_loss=0.03046, linear_loss=0.03961]
[2020-05-12 15:44:32.091]  Step 163002  [4.504 sec/step, loss=0.07910, avg_loss=0.08636, mel_loss=0.03336, linear_loss=0.04574]
[2020-05-12 15:44:33.469]  Step 163003  [4.461 sec/step, loss=0.08377, avg_loss=0.08627, mel_loss=0.03565, linear_loss=0.04812]
[2020-05-12 15:44:35.723]  Step 163004  [4.467 sec/step, loss=0.08766, avg_loss=0.08631, mel_loss=0.03811, linear_loss=0.04956]
[2020-05-12 15:44:44.609]  Step 163005  [4.420 sec/step, loss=0.09369, avg_loss=0.08641, mel_loss=0.04255, linear_loss=0.05114]
[2020-05-12 15:44:50.397]  Step 163006  [4.432 sec/step, loss=0.09246, avg_loss=0.08642, mel_loss=0.04142, linear_loss=0.05104]
[2020-05-12 15:44:57.983]  Step 163007  [4.498 sec/step, loss=0.09528, avg_loss=0.08661, mel_loss=0.04312, linear_loss=0.05216]
[2020-05-12 15:45:01.017]  Step 163008  [4.498 sec/step, loss=0.09298, avg_loss=0.08665, mel_loss=0.04055, linear_loss=0.05242]
[2020-05-12 15:45:01.845]  Step 163009  [4.482 sec/step, loss=0.07602, avg_loss=0.08655, mel_loss=0.03209, linear_loss=0.04393]
[2020-05-12 15:45:03.090]  Step 163010  [4.468 sec/step, loss=0.08109, avg_loss=0.08647, mel_loss=0.03459, linear_loss=0.04650]
[2020-05-12 15:45:04.101]  Step 163011  [4.444 sec/step, loss=0.07853, avg_loss=0.08633, mel_loss=0.03322, linear_loss=0.04531]
[2020-05-12 15:45:05.800]  Step 163012  [4.450 sec/step, loss=0.08541, avg_loss=0.08638, mel_loss=0.03687, linear_loss=0.04854]
[2020-05-12 15:46:27.575]  Generated 32 batches of size 32 in 114.100 sec
[2020-05-12 15:46:30.340]  Step 163013  [5.277 sec/step, loss=0.08763, avg_loss=0.08639, mel_loss=0.03800, linear_loss=0.04964]
[2020-05-12 15:46:37.733]  Step 163014  [5.335 sec/step, loss=0.09398, avg_loss=0.08650, mel_loss=0.04269, linear_loss=0.05129]
[2020-05-12 15:46:39.054]  Step 163015  [5.339 sec/step, loss=0.08384, avg_loss=0.08659, mel_loss=0.03570, linear_loss=0.04814]
[2020-05-12 15:46:40.722]  Step 163016  [5.334 sec/step, loss=0.08768, avg_loss=0.08659, mel_loss=0.03748, linear_loss=0.05020]
[2020-05-12 15:46:42.736]  Step 163017  [5.333 sec/step, loss=0.08745, avg_loss=0.08660, mel_loss=0.03756, linear_loss=0.04989]
[2020-05-12 15:46:44.350]  Step 163018  [5.319 sec/step, loss=0.08271, avg_loss=0.08655, mel_loss=0.03559, linear_loss=0.04711]
[2020-05-12 15:46:49.976]  Step 163019  [5.362 sec/step, loss=0.09412, avg_loss=0.08667, mel_loss=0.04225, linear_loss=0.05186]
[2020-05-12 15:47:04.386]  Step 163020  [5.493 sec/step, loss=0.07313, avg_loss=0.08661, mel_loss=0.03398, linear_loss=0.03915]
[2020-05-12 15:47:07.888]  Step 163021  [4.721 sec/step, loss=0.09313, avg_loss=0.08662, mel_loss=0.04099, linear_loss=0.05214]
[2020-05-12 15:47:10.952]  Step 163022  [4.744 sec/step, loss=0.09151, avg_loss=0.08689, mel_loss=0.04009, linear_loss=0.05142]
[2020-05-12 15:47:11.527]  Step 163023  [4.732 sec/step, loss=0.06596, avg_loss=0.08668, mel_loss=0.02858, linear_loss=0.03738]
[2020-05-12 15:47:15.293]  Step 163024  [4.716 sec/step, loss=0.09295, avg_loss=0.08666, mel_loss=0.04089, linear_loss=0.05207]
[2020-05-12 15:47:19.716]  Step 163025  [4.687 sec/step, loss=0.09305, avg_loss=0.08664, mel_loss=0.04154, linear_loss=0.05151]
[2020-05-12 15:47:21.115]  Step 163026  [4.689 sec/step, loss=0.08278, avg_loss=0.08666, mel_loss=0.03542, linear_loss=0.04736]
[2020-05-12 15:47:22.107]  Step 163027  [4.685 sec/step, loss=0.08046, avg_loss=0.08661, mel_loss=0.03432, linear_loss=0.04615]
[2020-05-12 15:47:25.631]  Step 163028  [4.695 sec/step, loss=0.09111, avg_loss=0.08665, mel_loss=0.04009, linear_loss=0.05103]
[2020-05-12 15:47:26.555]  Step 163029  [4.666 sec/step, loss=0.07653, avg_loss=0.08646, mel_loss=0.03198, linear_loss=0.04455]
[2020-05-12 15:47:28.548]  Step 163030  [4.672 sec/step, loss=0.08788, avg_loss=0.08651, mel_loss=0.03799, linear_loss=0.04988]
[2020-05-12 15:47:32.718]  Step 163031  [4.683 sec/step, loss=0.09291, avg_loss=0.08651, mel_loss=0.04093, linear_loss=0.05198]
[2020-05-12 15:47:41.546]  Step 163032  [4.760 sec/step, loss=0.09313, avg_loss=0.08669, mel_loss=0.04237, linear_loss=0.05077]
[2020-05-12 15:47:48.284]  Step 163033  [4.785 sec/step, loss=0.09419, avg_loss=0.08670, mel_loss=0.04236, linear_loss=0.05183]
[2020-05-12 15:47:53.625]  Step 163034  [4.822 sec/step, loss=0.09325, avg_loss=0.08676, mel_loss=0.04164, linear_loss=0.05161]
[2020-05-12 15:47:56.490]  Step 163035  [4.842 sec/step, loss=0.08810, avg_loss=0.08693, mel_loss=0.03851, linear_loss=0.04959]
[2020-05-12 15:47:57.311]  Step 163036  [4.827 sec/step, loss=0.07379, avg_loss=0.08680, mel_loss=0.03085, linear_loss=0.04294]
[2020-05-12 15:47:58.394]  Step 163037  [4.812 sec/step, loss=0.08165, avg_loss=0.08673, mel_loss=0.03445, linear_loss=0.04721]
[2020-05-12 15:48:00.247]  Step 163038  [4.782 sec/step, loss=0.08474, avg_loss=0.08664, mel_loss=0.03661, linear_loss=0.04813]
[2020-05-12 15:48:01.490]  Step 163039  [4.778 sec/step, loss=0.08011, avg_loss=0.08661, mel_loss=0.03407, linear_loss=0.04604]
[2020-05-12 15:48:04.747]  Step 163040  [4.742 sec/step, loss=0.09307, avg_loss=0.08660, mel_loss=0.04105, linear_loss=0.05202]
[2020-05-12 15:48:07.139]  Step 163041  [4.709 sec/step, loss=0.08569, avg_loss=0.08651, mel_loss=0.03719, linear_loss=0.04850]
[2020-05-12 15:48:09.387]  Step 163042  [4.641 sec/step, loss=0.08772, avg_loss=0.08644, mel_loss=0.03813, linear_loss=0.04959]
[2020-05-12 15:48:14.165]  Step 163043  [4.680 sec/step, loss=0.09435, avg_loss=0.08666, mel_loss=0.04179, linear_loss=0.05256]
[2020-05-12 15:48:14.944]  Step 163044  [4.677 sec/step, loss=0.07115, avg_loss=0.08660, mel_loss=0.03036, linear_loss=0.04079]
[2020-05-12 15:48:56.726]  Generated 32 batches of size 32 in 60.232 sec
[2020-05-12 15:48:59.671]  Step 163045  [5.105 sec/step, loss=0.09106, avg_loss=0.08664, mel_loss=0.03967, linear_loss=0.05139]
[2020-05-12 15:49:00.430]  Step 163046  [5.069 sec/step, loss=0.07580, avg_loss=0.08646, mel_loss=0.03178, linear_loss=0.04402]
[2020-05-12 15:49:05.021]  Step 163047  [5.104 sec/step, loss=0.09319, avg_loss=0.08661, mel_loss=0.04132, linear_loss=0.05188]
[2020-05-12 15:49:06.772]  Step 163048  [5.099 sec/step, loss=0.08525, avg_loss=0.08658, mel_loss=0.03639, linear_loss=0.04886]
[2020-05-12 15:49:07.610]  Step 163049  [5.073 sec/step, loss=0.07392, avg_loss=0.08640, mel_loss=0.03138, linear_loss=0.04254]
[2020-05-12 15:49:16.272]  Step 163050  [5.124 sec/step, loss=0.09123, avg_loss=0.08640, mel_loss=0.04152, linear_loss=0.04971]
[2020-05-12 15:49:16.273]  Writing summary at step: 163050
[2020-05-12 15:49:17.737]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163050
[2020-05-12 15:49:19.434]  Saving audio and alignment...
[2020-05-12 15:49:24.695]  Input: 친다면 어디서 내가 쳐야 될지 우왕좌왕하게 되시겠죠~_________________________
[2020-05-12 15:49:25.721]  Step 163051  [4.674 sec/step, loss=0.08132, avg_loss=0.08654, mel_loss=0.03443, linear_loss=0.04690]
[2020-05-12 15:49:31.502]  Step 163052  [4.723 sec/step, loss=0.09392, avg_loss=0.08670, mel_loss=0.04181, linear_loss=0.05211]
[2020-05-12 15:49:33.062]  Step 163053  [4.707 sec/step, loss=0.08474, avg_loss=0.08662, mel_loss=0.03635, linear_loss=0.04839]
[2020-05-12 15:49:38.097]  Step 163054  [4.745 sec/step, loss=0.09017, avg_loss=0.08673, mel_loss=0.04008, linear_loss=0.05009]
[2020-05-12 15:49:39.304]  Step 163055  [4.741 sec/step, loss=0.07729, avg_loss=0.08665, mel_loss=0.03281, linear_loss=0.04447]
[2020-05-12 15:49:42.970]  Step 163056  [4.737 sec/step, loss=0.09364, avg_loss=0.08667, mel_loss=0.04137, linear_loss=0.05227]
[2020-05-12 15:49:45.735]  Step 163057  [4.709 sec/step, loss=0.08945, avg_loss=0.08662, mel_loss=0.03904, linear_loss=0.05042]
[2020-05-12 15:49:46.301]  Step 163058  [4.694 sec/step, loss=0.06738, avg_loss=0.08642, mel_loss=0.02936, linear_loss=0.03803]
[2020-05-12 15:49:52.937]  Step 163059  [4.711 sec/step, loss=0.09264, avg_loss=0.08641, mel_loss=0.04164, linear_loss=0.05100]
[2020-05-12 15:49:54.991]  Step 163060  [4.720 sec/step, loss=0.08569, avg_loss=0.08646, mel_loss=0.03720, linear_loss=0.04849]
[2020-05-12 15:49:57.526]  Step 163061  [4.659 sec/step, loss=0.08797, avg_loss=0.08640, mel_loss=0.03824, linear_loss=0.04973]
[2020-05-12 15:49:59.439]  Step 163062  [4.643 sec/step, loss=0.08716, avg_loss=0.08637, mel_loss=0.03765, linear_loss=0.04951]
[2020-05-12 15:50:02.550]  Step 163063  [4.664 sec/step, loss=0.09247, avg_loss=0.08652, mel_loss=0.04061, linear_loss=0.05185]
[2020-05-12 15:50:04.968]  Step 163064  [4.652 sec/step, loss=0.08863, avg_loss=0.08647, mel_loss=0.03856, linear_loss=0.05007]
[2020-05-12 15:50:16.887]  Step 163065  [4.747 sec/step, loss=0.08793, avg_loss=0.08646, mel_loss=0.04005, linear_loss=0.04787]
[2020-05-12 15:50:18.243]  Step 163066  [4.743 sec/step, loss=0.08350, avg_loss=0.08643, mel_loss=0.03580, linear_loss=0.04770]
[2020-05-12 15:50:19.915]  Step 163067  [4.733 sec/step, loss=0.08393, avg_loss=0.08637, mel_loss=0.03599, linear_loss=0.04794]
[2020-05-12 15:50:22.031]  Step 163068  [4.693 sec/step, loss=0.08820, avg_loss=0.08632, mel_loss=0.03819, linear_loss=0.05000]
[2020-05-12 15:50:26.360]  Step 163069  [4.730 sec/step, loss=0.09241, avg_loss=0.08652, mel_loss=0.04080, linear_loss=0.05161]
[2020-05-12 15:50:33.463]  Step 163070  [4.776 sec/step, loss=0.09577, avg_loss=0.08661, mel_loss=0.04322, linear_loss=0.05255]
[2020-05-12 15:50:34.561]  Step 163071  [4.779 sec/step, loss=0.08014, avg_loss=0.08669, mel_loss=0.03409, linear_loss=0.04604]
[2020-05-12 15:50:35.529]  Step 163072  [4.770 sec/step, loss=0.07697, avg_loss=0.08661, mel_loss=0.03225, linear_loss=0.04472]
[2020-05-12 15:50:39.270]  Step 163073  [4.793 sec/step, loss=0.09423, avg_loss=0.08673, mel_loss=0.04160, linear_loss=0.05263]
[2020-05-12 15:50:42.814]  Step 163074  [4.690 sec/step, loss=0.09060, avg_loss=0.08684, mel_loss=0.03993, linear_loss=0.05067]
[2020-05-12 15:51:00.555]  Generated 32 batches of size 32 in 43.662 sec
[2020-05-12 15:51:01.927]  Step 163075  [4.847 sec/step, loss=0.08415, avg_loss=0.08677, mel_loss=0.03581, linear_loss=0.04834]
[2020-05-12 15:51:05.967]  Step 163076  [4.811 sec/step, loss=0.09336, avg_loss=0.08676, mel_loss=0.04106, linear_loss=0.05230]
[2020-05-12 15:51:06.790]  Step 163077  [4.779 sec/step, loss=0.07414, avg_loss=0.08656, mel_loss=0.03143, linear_loss=0.04271]
[2020-05-12 15:51:12.054]  Step 163078  [4.817 sec/step, loss=0.09435, avg_loss=0.08670, mel_loss=0.04242, linear_loss=0.05193]
[2020-05-12 15:51:15.057]  Step 163079  [4.817 sec/step, loss=0.09191, avg_loss=0.08672, mel_loss=0.04030, linear_loss=0.05160]
[2020-05-12 15:51:17.014]  Step 163080  [4.814 sec/step, loss=0.08671, avg_loss=0.08670, mel_loss=0.03738, linear_loss=0.04933]
[2020-05-12 15:51:19.325]  Step 163081  [4.817 sec/step, loss=0.08961, avg_loss=0.08674, mel_loss=0.03878, linear_loss=0.05082]
[2020-05-12 15:51:21.871]  Step 163082  [4.796 sec/step, loss=0.08863, avg_loss=0.08669, mel_loss=0.03859, linear_loss=0.05004]
[2020-05-12 15:51:24.037]  Step 163083  [4.530 sec/step, loss=0.08681, avg_loss=0.08663, mel_loss=0.03756, linear_loss=0.04925]
[2020-05-12 15:51:25.642]  Step 163084  [4.520 sec/step, loss=0.08537, avg_loss=0.08660, mel_loss=0.03691, linear_loss=0.04846]
[2020-05-12 15:51:27.394]  Step 163085  [4.502 sec/step, loss=0.08595, avg_loss=0.08655, mel_loss=0.03666, linear_loss=0.04928]
[2020-05-12 15:51:27.968]  Step 163086  [4.489 sec/step, loss=0.06599, avg_loss=0.08635, mel_loss=0.02829, linear_loss=0.03771]
[2020-05-12 15:51:28.999]  Step 163087  [4.479 sec/step, loss=0.07525, avg_loss=0.08624, mel_loss=0.03166, linear_loss=0.04359]
[2020-05-12 15:51:29.762]  Step 163088  [4.457 sec/step, loss=0.07245, avg_loss=0.08604, mel_loss=0.03054, linear_loss=0.04191]
[2020-05-12 15:51:31.980]  Step 163089  [4.434 sec/step, loss=0.08806, avg_loss=0.08597, mel_loss=0.03828, linear_loss=0.04978]
[2020-05-12 15:51:33.098]  Step 163090  [4.430 sec/step, loss=0.08113, avg_loss=0.08594, mel_loss=0.03432, linear_loss=0.04680]
[2020-05-12 15:51:36.734]  Step 163091  [4.423 sec/step, loss=0.09232, avg_loss=0.08595, mel_loss=0.04072, linear_loss=0.05160]
[2020-05-12 15:51:39.936]  Step 163092  [4.440 sec/step, loss=0.09236, avg_loss=0.08607, mel_loss=0.04051, linear_loss=0.05186]
[2020-05-12 15:51:44.625]  Step 163093  [4.463 sec/step, loss=0.09437, avg_loss=0.08613, mel_loss=0.04175, linear_loss=0.05262]
[2020-05-12 15:51:46.495]  Step 163094  [4.473 sec/step, loss=0.08467, avg_loss=0.08623, mel_loss=0.03648, linear_loss=0.04819]
[2020-05-12 15:51:47.866]  Step 163095  [4.468 sec/step, loss=0.08076, avg_loss=0.08618, mel_loss=0.03464, linear_loss=0.04612]
[2020-05-12 15:51:50.725]  Step 163096  [4.459 sec/step, loss=0.08906, avg_loss=0.08613, mel_loss=0.03903, linear_loss=0.05003]
[2020-05-12 15:51:59.640]  Step 163097  [4.522 sec/step, loss=0.09354, avg_loss=0.08615, mel_loss=0.04254, linear_loss=0.05100]
[2020-05-12 15:52:01.305]  Generated 32 batches of size 32 in 1.660 sec
[2020-05-12 15:52:03.882]  Step 163098  [4.501 sec/step, loss=0.09278, avg_loss=0.08613, mel_loss=0.04130, linear_loss=0.05148]
[2020-05-12 15:52:09.508]  Step 163099  [4.540 sec/step, loss=0.09409, avg_loss=0.08623, mel_loss=0.04215, linear_loss=0.05194]
[2020-05-12 15:52:12.990]  Step 163100  [4.541 sec/step, loss=0.09193, avg_loss=0.08622, mel_loss=0.04053, linear_loss=0.05140]
[2020-05-12 15:52:12.990]  Writing summary at step: 163100
[2020-05-12 15:52:14.006]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163100
[2020-05-12 15:52:18.045]  Saving audio and alignment...
[2020-05-12 15:52:27.083]  Input: 리포터와 클럽에이스 어린이 사이의 불꽃 튀는 진검승부가 펼쳐지는데요 자 그다음 확 낮춰서~____________
[2020-05-12 15:52:28.310]  Step 163101  [4.548 sec/step, loss=0.08112, avg_loss=0.08633, mel_loss=0.03469, linear_loss=0.04643]
[2020-05-12 15:52:42.926]  Step 163102  [4.682 sec/step, loss=0.07374, avg_loss=0.08628, mel_loss=0.03423, linear_loss=0.03951]
[2020-05-12 15:52:50.593]  Step 163103  [4.745 sec/step, loss=0.09386, avg_loss=0.08638, mel_loss=0.04258, linear_loss=0.05128]
[2020-05-12 15:52:52.165]  Step 163104  [4.738 sec/step, loss=0.08508, avg_loss=0.08635, mel_loss=0.03622, linear_loss=0.04886]
[2020-05-12 15:52:52.982]  Step 163105  [4.658 sec/step, loss=0.07258, avg_loss=0.08614, mel_loss=0.03051, linear_loss=0.04207]
[2020-05-12 15:52:54.052]  Step 163106  [4.611 sec/step, loss=0.08207, avg_loss=0.08604, mel_loss=0.03459, linear_loss=0.04748]
[2020-05-12 15:52:55.691]  Step 163107  [4.551 sec/step, loss=0.08586, avg_loss=0.08594, mel_loss=0.03683, linear_loss=0.04903]
[2020-05-12 15:52:56.357]  Step 163108  [4.527 sec/step, loss=0.06868, avg_loss=0.08570, mel_loss=0.02916, linear_loss=0.03952]
[2020-05-12 15:53:00.686]  Step 163109  [4.562 sec/step, loss=0.09360, avg_loss=0.08588, mel_loss=0.04151, linear_loss=0.05209]
[2020-05-12 15:53:07.458]  Step 163110  [4.618 sec/step, loss=0.09468, avg_loss=0.08601, mel_loss=0.04272, linear_loss=0.05196]
[2020-05-12 15:53:10.514]  Step 163111  [4.638 sec/step, loss=0.09097, avg_loss=0.08614, mel_loss=0.03979, linear_loss=0.05118]
[2020-05-12 15:53:12.546]  Step 163112  [4.641 sec/step, loss=0.08525, avg_loss=0.08614, mel_loss=0.03672, linear_loss=0.04853]
[2020-05-12 15:53:14.324]  Step 163113  [3.814 sec/step, loss=0.08622, avg_loss=0.08612, mel_loss=0.03687, linear_loss=0.04934]
[2020-05-12 15:53:15.649]  Step 163114  [3.753 sec/step, loss=0.07934, avg_loss=0.08598, mel_loss=0.03387, linear_loss=0.04547]
[2020-05-12 15:53:18.411]  Step 163115  [3.768 sec/step, loss=0.08703, avg_loss=0.08601, mel_loss=0.03776, linear_loss=0.04926]
[2020-05-12 15:53:19.336]  Step 163116  [3.760 sec/step, loss=0.07606, avg_loss=0.08589, mel_loss=0.03213, linear_loss=0.04393]
[2020-05-12 15:53:23.024]  Step 163117  [3.777 sec/step, loss=0.09291, avg_loss=0.08595, mel_loss=0.04103, linear_loss=0.05188]
[2020-05-12 15:53:28.682]  Step 163118  [3.817 sec/step, loss=0.09453, avg_loss=0.08606, mel_loss=0.04252, linear_loss=0.05201]
[2020-05-12 15:53:30.924]  Step 163119  [3.783 sec/step, loss=0.08658, avg_loss=0.08599, mel_loss=0.03757, linear_loss=0.04901]
[2020-05-12 15:53:31.482]  Step 163120  [3.645 sec/step, loss=0.06754, avg_loss=0.08593, mel_loss=0.02927, linear_loss=0.03827]
[2020-05-12 15:53:33.357]  Step 163121  [3.629 sec/step, loss=0.08613, avg_loss=0.08586, mel_loss=0.03659, linear_loss=0.04954]
[2020-05-12 15:53:35.508]  Step 163122  [3.620 sec/step, loss=0.08792, avg_loss=0.08583, mel_loss=0.03802, linear_loss=0.04990]
[2020-05-12 15:53:39.653]  Step 163123  [3.655 sec/step, loss=0.09349, avg_loss=0.08610, mel_loss=0.04117, linear_loss=0.05232]
[2020-05-12 15:53:44.361]  Step 163124  [3.665 sec/step, loss=0.09264, avg_loss=0.08610, mel_loss=0.04126, linear_loss=0.05137]
[2020-05-12 15:53:53.060]  Step 163125  [3.707 sec/step, loss=0.09324, avg_loss=0.08610, mel_loss=0.04227, linear_loss=0.05097]
[2020-05-12 15:53:56.585]  Step 163126  [3.729 sec/step, loss=0.09122, avg_loss=0.08619, mel_loss=0.04030, linear_loss=0.05092]
[2020-05-12 15:53:59.479]  Step 163127  [3.748 sec/step, loss=0.08883, avg_loss=0.08627, mel_loss=0.03890, linear_loss=0.04994]
[2020-05-12 15:54:00.820]  Step 163128  [3.726 sec/step, loss=0.08356, avg_loss=0.08619, mel_loss=0.03555, linear_loss=0.04801]
[2020-05-12 15:54:01.818]  Step 163129  [3.727 sec/step, loss=0.07852, avg_loss=0.08621, mel_loss=0.03326, linear_loss=0.04526]
[2020-05-12 15:54:03.320]  Step 163130  [3.722 sec/step, loss=0.08401, avg_loss=0.08618, mel_loss=0.03630, linear_loss=0.04771]
[2020-05-12 15:54:06.735]  Step 163131  [3.714 sec/step, loss=0.09243, avg_loss=0.08617, mel_loss=0.04052, linear_loss=0.05191]
[2020-05-12 15:54:09.205]  Step 163132  [3.651 sec/step, loss=0.08921, avg_loss=0.08613, mel_loss=0.03863, linear_loss=0.05057]
[2020-05-12 15:54:23.447]  Step 163133  [3.726 sec/step, loss=0.07443, avg_loss=0.08593, mel_loss=0.03472, linear_loss=0.03971]
[2020-05-12 15:54:28.720]  Step 163134  [3.726 sec/step, loss=0.09392, avg_loss=0.08594, mel_loss=0.04202, linear_loss=0.05190]
[2020-05-12 15:54:29.837]  Step 163135  [3.708 sec/step, loss=0.08229, avg_loss=0.08588, mel_loss=0.03489, linear_loss=0.04739]
[2020-05-12 15:54:37.742]  Step 163136  [3.779 sec/step, loss=0.09529, avg_loss=0.08610, mel_loss=0.04308, linear_loss=0.05221]
[2020-05-12 15:55:36.923]  Generated 32 batches of size 32 in 97.439 sec
[2020-05-12 15:55:37.767]  Step 163137  [4.368 sec/step, loss=0.07419, avg_loss=0.08602, mel_loss=0.03156, linear_loss=0.04263]
[2020-05-12 15:55:40.632]  Step 163138  [4.378 sec/step, loss=0.09022, avg_loss=0.08608, mel_loss=0.03967, linear_loss=0.05055]
[2020-05-12 15:55:41.503]  Step 163139  [4.375 sec/step, loss=0.07713, avg_loss=0.08605, mel_loss=0.03239, linear_loss=0.04474]
[2020-05-12 15:55:49.240]  Step 163140  [4.420 sec/step, loss=0.09401, avg_loss=0.08606, mel_loss=0.04258, linear_loss=0.05143]
[2020-05-12 15:55:51.886]  Step 163141  [4.422 sec/step, loss=0.09051, avg_loss=0.08610, mel_loss=0.03965, linear_loss=0.05085]
[2020-05-12 15:55:53.084]  Step 163142  [4.412 sec/step, loss=0.08017, avg_loss=0.08603, mel_loss=0.03392, linear_loss=0.04625]
[2020-05-12 15:55:56.476]  Step 163143  [4.398 sec/step, loss=0.09346, avg_loss=0.08602, mel_loss=0.04118, linear_loss=0.05228]
[2020-05-12 15:55:57.784]  Step 163144  [4.403 sec/step, loss=0.07969, avg_loss=0.08611, mel_loss=0.03402, linear_loss=0.04567]
[2020-05-12 15:56:01.819]  Step 163145  [3.996 sec/step, loss=0.09285, avg_loss=0.08612, mel_loss=0.04109, linear_loss=0.05175]
[2020-05-12 15:56:02.837]  Step 163146  [3.999 sec/step, loss=0.07694, avg_loss=0.08614, mel_loss=0.03276, linear_loss=0.04418]
[2020-05-12 15:56:06.257]  Step 163147  [3.987 sec/step, loss=0.08932, avg_loss=0.08610, mel_loss=0.03930, linear_loss=0.05002]
[2020-05-12 15:56:07.103]  Step 163148  [3.978 sec/step, loss=0.07479, avg_loss=0.08599, mel_loss=0.03183, linear_loss=0.04297]
[2020-05-12 15:56:09.424]  Step 163149  [3.993 sec/step, loss=0.08903, avg_loss=0.08614, mel_loss=0.03891, linear_loss=0.05012]
[2020-05-12 15:56:11.170]  Step 163150  [3.924 sec/step, loss=0.08640, avg_loss=0.08609, mel_loss=0.03727, linear_loss=0.04913]
[2020-05-12 15:56:11.191]  Writing summary at step: 163150
[2020-05-12 15:56:14.841]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163150
[2020-05-12 15:56:16.527]  Saving audio and alignment...
[2020-05-12 15:56:22.762]  Input: 들어가 볼까요 이렇게 끼를 좀 부려 보세요~_____________________________________
[2020-05-12 15:56:28.914]  Step 163151  [3.975 sec/step, loss=0.09309, avg_loss=0.08621, mel_loss=0.04197, linear_loss=0.05112]
[2020-05-12 15:56:33.830]  Step 163152  [3.966 sec/step, loss=0.09264, avg_loss=0.08620, mel_loss=0.04116, linear_loss=0.05148]
[2020-05-12 15:56:35.432]  Step 163153  [3.967 sec/step, loss=0.08517, avg_loss=0.08620, mel_loss=0.03652, linear_loss=0.04864]
[2020-05-12 15:56:37.458]  Step 163154  [3.937 sec/step, loss=0.08632, avg_loss=0.08617, mel_loss=0.03756, linear_loss=0.04876]
[2020-05-12 15:56:39.624]  Step 163155  [3.946 sec/step, loss=0.08751, avg_loss=0.08627, mel_loss=0.03792, linear_loss=0.04959]
[2020-05-12 15:56:41.240]  Step 163156  [3.926 sec/step, loss=0.08774, avg_loss=0.08621, mel_loss=0.03785, linear_loss=0.04988]
[2020-05-12 15:56:44.377]  Step 163157  [3.929 sec/step, loss=0.09157, avg_loss=0.08623, mel_loss=0.04023, linear_loss=0.05135]
[2020-05-12 15:56:46.359]  Step 163158  [3.943 sec/step, loss=0.08574, avg_loss=0.08641, mel_loss=0.03712, linear_loss=0.04862]
[2020-05-12 15:56:47.797]  Step 163159  [3.892 sec/step, loss=0.08344, avg_loss=0.08632, mel_loss=0.03585, linear_loss=0.04759]
[2020-05-12 15:56:54.640]  Step 163160  [3.939 sec/step, loss=0.09685, avg_loss=0.08643, mel_loss=0.04395, linear_loss=0.05289]
[2020-05-12 15:56:56.012]  Step 163161  [3.928 sec/step, loss=0.08453, avg_loss=0.08640, mel_loss=0.03641, linear_loss=0.04812]
[2020-05-12 15:57:00.528]  Step 163162  [3.954 sec/step, loss=0.09469, avg_loss=0.08647, mel_loss=0.04206, linear_loss=0.05263]
[2020-05-12 15:57:06.084]  Step 163163  [3.978 sec/step, loss=0.09469, avg_loss=0.08650, mel_loss=0.04232, linear_loss=0.05237]
[2020-05-12 15:57:08.573]  Step 163164  [3.979 sec/step, loss=0.08953, avg_loss=0.08650, mel_loss=0.03889, linear_loss=0.05065]
[2020-05-12 15:57:09.337]  Step 163165  [3.867 sec/step, loss=0.06969, avg_loss=0.08632, mel_loss=0.03054, linear_loss=0.03915]
[2020-05-12 15:57:23.936]  Step 163166  [4.000 sec/step, loss=0.07212, avg_loss=0.08621, mel_loss=0.03369, linear_loss=0.03842]
[2020-05-12 15:58:11.273]  Generated 32 batches of size 32 in 86.890 sec
[2020-05-12 15:58:12.548]  Step 163167  [4.469 sec/step, loss=0.08179, avg_loss=0.08619, mel_loss=0.03489, linear_loss=0.04690]
[2020-05-12 15:58:15.071]  Step 163168  [4.473 sec/step, loss=0.08819, avg_loss=0.08619, mel_loss=0.03841, linear_loss=0.04978]
[2020-05-12 15:58:15.631]  Step 163169  [4.436 sec/step, loss=0.06764, avg_loss=0.08594, mel_loss=0.02932, linear_loss=0.03832]
[2020-05-12 15:58:16.684]  Step 163170  [4.375 sec/step, loss=0.07581, avg_loss=0.08574, mel_loss=0.03217, linear_loss=0.04364]
[2020-05-12 15:58:18.240]  Step 163171  [4.380 sec/step, loss=0.08274, avg_loss=0.08577, mel_loss=0.03545, linear_loss=0.04729]
[2020-05-12 15:58:19.044]  Step 163172  [4.378 sec/step, loss=0.07383, avg_loss=0.08573, mel_loss=0.03090, linear_loss=0.04293]
[2020-05-12 15:58:32.191]  Step 163173  [4.472 sec/step, loss=0.08277, avg_loss=0.08562, mel_loss=0.03848, linear_loss=0.04430]
[2020-05-12 15:58:35.904]  Step 163174  [4.474 sec/step, loss=0.09448, avg_loss=0.08566, mel_loss=0.04189, linear_loss=0.05259]
[2020-05-12 15:58:37.287]  Step 163175  [4.297 sec/step, loss=0.08143, avg_loss=0.08563, mel_loss=0.03489, linear_loss=0.04654]
[2020-05-12 15:58:38.894]  Step 163176  [4.272 sec/step, loss=0.08452, avg_loss=0.08554, mel_loss=0.03652, linear_loss=0.04800]
[2020-05-12 15:58:43.329]  Step 163177  [4.308 sec/step, loss=0.09392, avg_loss=0.08574, mel_loss=0.04182, linear_loss=0.05210]
[2020-05-12 15:58:48.671]  Step 163178  [4.309 sec/step, loss=0.09478, avg_loss=0.08575, mel_loss=0.04217, linear_loss=0.05261]
[2020-05-12 15:58:51.434]  Step 163179  [4.307 sec/step, loss=0.08995, avg_loss=0.08573, mel_loss=0.03953, linear_loss=0.05041]
[2020-05-12 15:58:56.171]  Step 163180  [4.334 sec/step, loss=0.09183, avg_loss=0.08578, mel_loss=0.04060, linear_loss=0.05123]
[2020-05-12 15:58:57.897]  Step 163181  [4.329 sec/step, loss=0.08681, avg_loss=0.08575, mel_loss=0.03679, linear_loss=0.05002]
[2020-05-12 15:58:59.905]  Step 163182  [4.323 sec/step, loss=0.08473, avg_loss=0.08571, mel_loss=0.03673, linear_loss=0.04800]
[2020-05-12 15:59:03.290]  Step 163183  [4.335 sec/step, loss=0.09015, avg_loss=0.08574, mel_loss=0.03979, linear_loss=0.05036]
[2020-05-12 15:59:05.079]  Step 163184  [4.337 sec/step, loss=0.08596, avg_loss=0.08575, mel_loss=0.03682, linear_loss=0.04914]
[2020-05-12 15:59:05.698]  Step 163185  [4.326 sec/step, loss=0.07364, avg_loss=0.08563, mel_loss=0.03134, linear_loss=0.04230]
[2020-05-12 15:59:07.914]  Step 163186  [4.342 sec/step, loss=0.08735, avg_loss=0.08584, mel_loss=0.03788, linear_loss=0.04947]
[2020-05-12 15:59:10.345]  Step 163187  [4.356 sec/step, loss=0.08644, avg_loss=0.08595, mel_loss=0.03754, linear_loss=0.04890]
[2020-05-12 15:59:12.337]  Step 163188  [4.369 sec/step, loss=0.08886, avg_loss=0.08612, mel_loss=0.03829, linear_loss=0.05057]
[2020-05-12 15:59:15.375]  Step 163189  [4.377 sec/step, loss=0.09353, avg_loss=0.08617, mel_loss=0.04097, linear_loss=0.05256]
[2020-05-12 15:59:19.385]  Step 163190  [4.406 sec/step, loss=0.09106, avg_loss=0.08627, mel_loss=0.04004, linear_loss=0.05103]
[2020-05-12 15:59:27.027]  Step 163191  [4.446 sec/step, loss=0.09517, avg_loss=0.08630, mel_loss=0.04306, linear_loss=0.05211]
[2020-05-12 15:59:27.940]  Step 163192  [4.423 sec/step, loss=0.07820, avg_loss=0.08616, mel_loss=0.03299, linear_loss=0.04520]
[2020-05-12 15:59:30.890]  Step 163193  [4.406 sec/step, loss=0.09288, avg_loss=0.08614, mel_loss=0.04063, linear_loss=0.05225]
[2020-05-12 15:59:36.559]  Step 163194  [4.444 sec/step, loss=0.09424, avg_loss=0.08624, mel_loss=0.04218, linear_loss=0.05206]
[2020-05-12 15:59:43.602]  Step 163195  [4.500 sec/step, loss=0.09346, avg_loss=0.08636, mel_loss=0.04192, linear_loss=0.05154]
[2020-05-12 15:59:44.752]  Step 163196  [4.483 sec/step, loss=0.07895, avg_loss=0.08626, mel_loss=0.03363, linear_loss=0.04532]
[2020-05-12 15:59:48.339]  Step 163197  [4.430 sec/step, loss=0.09189, avg_loss=0.08625, mel_loss=0.04055, linear_loss=0.05134]
[2020-05-12 15:59:57.574]  Step 163198  [4.480 sec/step, loss=0.09242, avg_loss=0.08624, mel_loss=0.04222, linear_loss=0.05021]
[2020-05-12 16:00:23.066]  Generated 32 batches of size 32 in 67.685 sec
[2020-05-12 16:00:24.704]  Step 163199  [4.695 sec/step, loss=0.08300, avg_loss=0.08613, mel_loss=0.03557, linear_loss=0.04743]
[2020-05-12 16:00:27.354]  Step 163200  [4.687 sec/step, loss=0.08843, avg_loss=0.08610, mel_loss=0.03851, linear_loss=0.04992]
[2020-05-12 16:00:27.354]  Writing summary at step: 163200
[2020-05-12 16:00:34.876]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163200
[2020-05-12 16:00:36.555]  Saving audio and alignment...
[2020-05-12 16:00:38.501]  Input: 이렇게 처리~____________________
[2020-05-12 16:00:40.347]  Step 163201  [4.693 sec/step, loss=0.08509, avg_loss=0.08614, mel_loss=0.03652, linear_loss=0.04857]
[2020-05-12 16:00:41.686]  Step 163202  [4.560 sec/step, loss=0.08398, avg_loss=0.08624, mel_loss=0.03577, linear_loss=0.04821]
[2020-05-12 16:00:45.128]  Step 163203  [4.518 sec/step, loss=0.09049, avg_loss=0.08621, mel_loss=0.03990, linear_loss=0.05059]
[2020-05-12 16:00:48.532]  Step 163204  [4.536 sec/step, loss=0.09172, avg_loss=0.08627, mel_loss=0.04019, linear_loss=0.05153]
[2020-05-12 16:00:51.655]  Step 163205  [4.559 sec/step, loss=0.08946, avg_loss=0.08644, mel_loss=0.03932, linear_loss=0.05014]
[2020-05-12 16:00:55.109]  Step 163206  [4.583 sec/step, loss=0.09266, avg_loss=0.08655, mel_loss=0.04106, linear_loss=0.05160]
[2020-05-12 16:00:57.095]  Step 163207  [4.586 sec/step, loss=0.08645, avg_loss=0.08655, mel_loss=0.03754, linear_loss=0.04892]
[2020-05-12 16:00:57.621]  Step 163208  [4.585 sec/step, loss=0.07114, avg_loss=0.08658, mel_loss=0.03051, linear_loss=0.04063]
[2020-05-12 16:00:58.345]  Step 163209  [4.549 sec/step, loss=0.07073, avg_loss=0.08635, mel_loss=0.03002, linear_loss=0.04071]
[2020-05-12 16:01:03.563]  Step 163210  [4.533 sec/step, loss=0.09174, avg_loss=0.08632, mel_loss=0.04093, linear_loss=0.05081]
[2020-05-12 16:01:04.384]  Step 163211  [4.511 sec/step, loss=0.07593, avg_loss=0.08617, mel_loss=0.03192, linear_loss=0.04401]
[2020-05-12 16:01:05.421]  Step 163212  [4.501 sec/step, loss=0.07770, avg_loss=0.08609, mel_loss=0.03279, linear_loss=0.04490]
[2020-05-12 16:01:06.943]  Step 163213  [4.499 sec/step, loss=0.08532, avg_loss=0.08608, mel_loss=0.03661, linear_loss=0.04871]
[2020-05-12 16:01:11.698]  Step 163214  [4.533 sec/step, loss=0.09476, avg_loss=0.08624, mel_loss=0.04217, linear_loss=0.05259]
[2020-05-12 16:01:20.424]  Step 163215  [4.592 sec/step, loss=0.09423, avg_loss=0.08631, mel_loss=0.04278, linear_loss=0.05144]
[2020-05-12 16:01:27.132]  Step 163216  [4.650 sec/step, loss=0.09339, avg_loss=0.08648, mel_loss=0.04218, linear_loss=0.05120]
[2020-05-12 16:01:29.545]  Step 163217  [4.638 sec/step, loss=0.08696, avg_loss=0.08642, mel_loss=0.03768, linear_loss=0.04928]
[2020-05-12 16:01:33.784]  Step 163218  [4.623 sec/step, loss=0.09179, avg_loss=0.08640, mel_loss=0.04049, linear_loss=0.05131]
[2020-05-12 16:01:35.546]  Step 163219  [4.619 sec/step, loss=0.08504, avg_loss=0.08638, mel_loss=0.03666, linear_loss=0.04839]
[2020-05-12 16:01:39.256]  Step 163220  [4.650 sec/step, loss=0.09403, avg_loss=0.08665, mel_loss=0.04149, linear_loss=0.05254]
[2020-05-12 16:01:40.406]  Step 163221  [4.643 sec/step, loss=0.08091, avg_loss=0.08659, mel_loss=0.03413, linear_loss=0.04678]
[2020-05-12 16:01:42.857]  Step 163222  [4.646 sec/step, loss=0.08847, avg_loss=0.08660, mel_loss=0.03828, linear_loss=0.05019]
[2020-05-12 16:01:44.176]  Step 163223  [4.618 sec/step, loss=0.08298, avg_loss=0.08649, mel_loss=0.03544, linear_loss=0.04754]
[2020-05-12 16:01:49.665]  Step 163224  [4.625 sec/step, loss=0.09561, avg_loss=0.08652, mel_loss=0.04275, linear_loss=0.05285]
[2020-05-12 16:01:52.505]  Step 163225  [4.567 sec/step, loss=0.09245, avg_loss=0.08652, mel_loss=0.04068, linear_loss=0.05178]
[2020-05-12 16:02:04.062]  Step 163226  [4.647 sec/step, loss=0.08883, avg_loss=0.08649, mel_loss=0.04118, linear_loss=0.04765]
[2020-05-12 16:02:05.106]  Step 163227  [4.629 sec/step, loss=0.08133, avg_loss=0.08642, mel_loss=0.03462, linear_loss=0.04670]
[2020-05-12 16:02:06.543]  Generated 32 batches of size 32 in 30.992 sec
[2020-05-12 16:02:07.304]  Step 163228  [4.637 sec/step, loss=0.08802, avg_loss=0.08646, mel_loss=0.03832, linear_loss=0.04970]
[2020-05-12 16:02:10.755]  Step 163229  [4.662 sec/step, loss=0.09198, avg_loss=0.08660, mel_loss=0.04073, linear_loss=0.05126]
[2020-05-12 16:02:15.998]  Step 163230  [4.699 sec/step, loss=0.09474, avg_loss=0.08670, mel_loss=0.04275, linear_loss=0.05200]
[2020-05-12 16:02:19.691]  Step 163231  [4.702 sec/step, loss=0.09358, avg_loss=0.08672, mel_loss=0.04163, linear_loss=0.05195]
[2020-05-12 16:02:21.031]  Step 163232  [4.691 sec/step, loss=0.08105, avg_loss=0.08663, mel_loss=0.03471, linear_loss=0.04634]
[2020-05-12 16:02:24.063]  Step 163233  [4.579 sec/step, loss=0.09351, avg_loss=0.08682, mel_loss=0.04124, linear_loss=0.05227]
[2020-05-12 16:02:33.477]  Step 163234  [4.620 sec/step, loss=0.09632, avg_loss=0.08685, mel_loss=0.04432, linear_loss=0.05200]
[2020-05-12 16:02:41.079]  Step 163235  [4.685 sec/step, loss=0.09627, avg_loss=0.08699, mel_loss=0.04415, linear_loss=0.05211]
[2020-05-12 16:02:44.003]  Step 163236  [4.635 sec/step, loss=0.09099, avg_loss=0.08695, mel_loss=0.04014, linear_loss=0.05085]
[2020-05-12 16:02:45.888]  Step 163237  [4.054 sec/step, loss=0.08500, avg_loss=0.08705, mel_loss=0.03643, linear_loss=0.04857]
[2020-05-12 16:02:50.096]  Step 163238  [4.067 sec/step, loss=0.09522, avg_loss=0.08710, mel_loss=0.04272, linear_loss=0.05250]
[2020-05-12 16:02:50.904]  Step 163239  [4.066 sec/step, loss=0.07605, avg_loss=0.08709, mel_loss=0.03228, linear_loss=0.04378]
[2020-05-12 16:02:52.907]  Step 163240  [4.009 sec/step, loss=0.08809, avg_loss=0.08703, mel_loss=0.03801, linear_loss=0.05008]
[2020-05-12 16:02:53.665]  Step 163241  [3.990 sec/step, loss=0.07265, avg_loss=0.08686, mel_loss=0.03194, linear_loss=0.04072]
[2020-05-12 16:02:55.872]  Step 163242  [4.000 sec/step, loss=0.08958, avg_loss=0.08695, mel_loss=0.03922, linear_loss=0.05036]
[2020-05-12 16:02:56.782]  Step 163243  [3.975 sec/step, loss=0.07850, avg_loss=0.08680, mel_loss=0.03323, linear_loss=0.04527]
[2020-05-12 16:02:58.490]  Step 163244  [3.979 sec/step, loss=0.08722, avg_loss=0.08687, mel_loss=0.03765, linear_loss=0.04958]
[2020-05-12 16:03:10.958]  Step 163245  [4.064 sec/step, loss=0.08388, avg_loss=0.08679, mel_loss=0.03917, linear_loss=0.04471]
[2020-05-12 16:03:17.175]  Step 163246  [4.116 sec/step, loss=0.09522, avg_loss=0.08697, mel_loss=0.04318, linear_loss=0.05204]
[2020-05-12 16:03:19.288]  Step 163247  [4.103 sec/step, loss=0.09070, avg_loss=0.08698, mel_loss=0.03935, linear_loss=0.05135]
[2020-05-12 16:03:20.908]  Step 163248  [4.110 sec/step, loss=0.08609, avg_loss=0.08709, mel_loss=0.03725, linear_loss=0.04884]
[2020-05-12 16:03:22.031]  Step 163249  [4.098 sec/step, loss=0.08149, avg_loss=0.08702, mel_loss=0.03467, linear_loss=0.04682]
[2020-05-12 16:03:26.222]  Step 163250  [4.123 sec/step, loss=0.09258, avg_loss=0.08708, mel_loss=0.04125, linear_loss=0.05133]
[2020-05-12 16:03:26.222]  Writing summary at step: 163250
[2020-05-12 16:03:27.481]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163250
[2020-05-12 16:03:29.213]  Saving audio and alignment...
[2020-05-12 16:03:37.446]  Input: 엠씨나 기타 장르에서 감정이 부족하세요 그렇다면 고개를 활용해 보세요 즉~______________________________
[2020-05-12 16:03:38.251]  Step 163251  [4.069 sec/step, loss=0.07332, avg_loss=0.08688, mel_loss=0.03108, linear_loss=0.04224]
[2020-05-12 16:03:41.015]  Step 163252  [4.048 sec/step, loss=0.08964, avg_loss=0.08685, mel_loss=0.03943, linear_loss=0.05021]
[2020-05-12 16:03:44.433]  Step 163253  [4.066 sec/step, loss=0.09394, avg_loss=0.08694, mel_loss=0.04162, linear_loss=0.05231]
[2020-05-12 16:03:46.045]  Step 163254  [4.062 sec/step, loss=0.08608, avg_loss=0.08694, mel_loss=0.03725, linear_loss=0.04884]
[2020-05-12 16:03:47.076]  Step 163255  [4.051 sec/step, loss=0.07858, avg_loss=0.08685, mel_loss=0.03345, linear_loss=0.04512]
[2020-05-12 16:03:51.823]  Step 163256  [4.082 sec/step, loss=0.09443, avg_loss=0.08692, mel_loss=0.04197, linear_loss=0.05246]
[2020-05-12 16:03:53.249]  Step 163257  [4.065 sec/step, loss=0.08321, avg_loss=0.08683, mel_loss=0.03580, linear_loss=0.04741]
[2020-05-12 16:03:55.772]  Step 163258  [4.070 sec/step, loss=0.08991, avg_loss=0.08687, mel_loss=0.03914, linear_loss=0.05076]
[2020-05-12 16:04:09.850]  Generated 32 batches of size 32 in 39.987 sec
[2020-05-12 16:04:11.228]  Step 163259  [4.210 sec/step, loss=0.08435, avg_loss=0.08688, mel_loss=0.03601, linear_loss=0.04834]
[2020-05-12 16:04:11.755]  Step 163260  [4.147 sec/step, loss=0.06778, avg_loss=0.08659, mel_loss=0.02967, linear_loss=0.03811]
[2020-05-12 16:04:15.384]  Step 163261  [4.170 sec/step, loss=0.09453, avg_loss=0.08669, mel_loss=0.04183, linear_loss=0.05271]
[2020-05-12 16:04:18.823]  Step 163262  [4.159 sec/step, loss=0.09049, avg_loss=0.08665, mel_loss=0.04011, linear_loss=0.05038]
[2020-05-12 16:04:19.871]  Step 163263  [4.114 sec/step, loss=0.08196, avg_loss=0.08652, mel_loss=0.03500, linear_loss=0.04696]
[2020-05-12 16:04:23.221]  Step 163264  [4.123 sec/step, loss=0.09360, avg_loss=0.08656, mel_loss=0.04119, linear_loss=0.05241]
[2020-05-12 16:04:37.924]  Step 163265  [4.262 sec/step, loss=0.07707, avg_loss=0.08664, mel_loss=0.03676, linear_loss=0.04031]
[2020-05-12 16:04:40.863]  Step 163266  [4.145 sec/step, loss=0.08817, avg_loss=0.08680, mel_loss=0.03852, linear_loss=0.04966]
[2020-05-12 16:04:42.813]  Step 163267  [3.679 sec/step, loss=0.08612, avg_loss=0.08684, mel_loss=0.03726, linear_loss=0.04886]
[2020-05-12 16:04:44.711]  Step 163268  [3.672 sec/step, loss=0.08628, avg_loss=0.08682, mel_loss=0.03698, linear_loss=0.04929]
[2020-05-12 16:04:45.524]  Step 163269  [3.675 sec/step, loss=0.07753, avg_loss=0.08692, mel_loss=0.03253, linear_loss=0.04500]
[2020-05-12 16:04:48.267]  Step 163270  [3.692 sec/step, loss=0.08798, avg_loss=0.08704, mel_loss=0.03830, linear_loss=0.04968]
[2020-05-12 16:04:56.573]  Step 163271  [3.759 sec/step, loss=0.09405, avg_loss=0.08716, mel_loss=0.04295, linear_loss=0.05110]
[2020-05-12 16:04:58.719]  Step 163272  [3.773 sec/step, loss=0.08675, avg_loss=0.08729, mel_loss=0.03783, linear_loss=0.04893]
[2020-05-12 16:04:59.629]  Step 163273  [3.650 sec/step, loss=0.07381, avg_loss=0.08720, mel_loss=0.03129, linear_loss=0.04252]
[2020-05-12 16:05:01.259]  Step 163274  [3.630 sec/step, loss=0.08825, avg_loss=0.08713, mel_loss=0.03798, linear_loss=0.05027]
[2020-05-12 16:05:04.203]  Step 163275  [3.645 sec/step, loss=0.09205, avg_loss=0.08724, mel_loss=0.04026, linear_loss=0.05179]
[2020-05-12 16:05:06.391]  Step 163276  [3.651 sec/step, loss=0.08885, avg_loss=0.08728, mel_loss=0.03862, linear_loss=0.05022]
[2020-05-12 16:05:13.403]  Step 163277  [3.677 sec/step, loss=0.09580, avg_loss=0.08730, mel_loss=0.04338, linear_loss=0.05242]
[2020-05-12 16:05:17.679]  Step 163278  [3.666 sec/step, loss=0.09180, avg_loss=0.08727, mel_loss=0.04057, linear_loss=0.05122]
[2020-05-12 16:05:19.056]  Step 163279  [3.652 sec/step, loss=0.08228, avg_loss=0.08720, mel_loss=0.03508, linear_loss=0.04719]
[2020-05-12 16:05:23.969]  Step 163280  [3.654 sec/step, loss=0.09270, avg_loss=0.08720, mel_loss=0.04155, linear_loss=0.05116]
[2020-05-12 16:05:25.973]  Step 163281  [3.657 sec/step, loss=0.08688, avg_loss=0.08720, mel_loss=0.03787, linear_loss=0.04901]
[2020-05-12 16:05:29.710]  Step 163282  [3.674 sec/step, loss=0.09379, avg_loss=0.08730, mel_loss=0.04135, linear_loss=0.05244]
[2020-05-12 16:05:36.381]  Step 163283  [3.707 sec/step, loss=0.09411, avg_loss=0.08734, mel_loss=0.04253, linear_loss=0.05158]
[2020-05-12 16:05:37.226]  Step 163284  [3.698 sec/step, loss=0.07416, avg_loss=0.08722, mel_loss=0.03195, linear_loss=0.04221]
[2020-05-12 16:05:39.715]  Step 163285  [3.716 sec/step, loss=0.08684, avg_loss=0.08735, mel_loss=0.03771, linear_loss=0.04913]
[2020-05-12 16:05:44.230]  Step 163286  [3.739 sec/step, loss=0.09413, avg_loss=0.08742, mel_loss=0.04178, linear_loss=0.05235]
[2020-05-12 16:05:45.712]  Step 163287  [3.730 sec/step, loss=0.08344, avg_loss=0.08739, mel_loss=0.03569, linear_loss=0.04775]
[2020-05-12 16:05:46.686]  Step 163288  [3.720 sec/step, loss=0.08023, avg_loss=0.08730, mel_loss=0.03407, linear_loss=0.04616]
[2020-05-12 16:05:52.313]  Step 163289  [3.745 sec/step, loss=0.09321, avg_loss=0.08730, mel_loss=0.04173, linear_loss=0.05148]
[2020-05-12 16:05:53.475]  Step 163290  [3.717 sec/step, loss=0.08051, avg_loss=0.08719, mel_loss=0.03415, linear_loss=0.04636]
[2020-05-12 16:07:12.302]  Generated 32 batches of size 32 in 106.324 sec
[2020-05-12 16:07:15.630]  Step 163291  [4.462 sec/step, loss=0.09205, avg_loss=0.08716, mel_loss=0.04048, linear_loss=0.05156]
[2020-05-12 16:07:16.907]  Step 163292  [4.466 sec/step, loss=0.08027, avg_loss=0.08718, mel_loss=0.03466, linear_loss=0.04561]
[2020-05-12 16:07:19.100]  Step 163293  [4.458 sec/step, loss=0.08820, avg_loss=0.08713, mel_loss=0.03822, linear_loss=0.04998]
[2020-05-12 16:07:20.895]  Step 163294  [4.419 sec/step, loss=0.08566, avg_loss=0.08705, mel_loss=0.03683, linear_loss=0.04883]
[2020-05-12 16:07:34.325]  Step 163295  [4.483 sec/step, loss=0.08145, avg_loss=0.08693, mel_loss=0.03790, linear_loss=0.04355]
[2020-05-12 16:07:37.431]  Step 163296  [4.503 sec/step, loss=0.09104, avg_loss=0.08705, mel_loss=0.04000, linear_loss=0.05104]
[2020-05-12 16:07:39.875]  Step 163297  [4.491 sec/step, loss=0.08967, avg_loss=0.08703, mel_loss=0.03907, linear_loss=0.05060]
[2020-05-12 16:07:44.356]  Step 163298  [4.444 sec/step, loss=0.09477, avg_loss=0.08705, mel_loss=0.04220, linear_loss=0.05257]
[2020-05-12 16:07:48.708]  Step 163299  [4.216 sec/step, loss=0.09122, avg_loss=0.08713, mel_loss=0.04045, linear_loss=0.05077]
[2020-05-12 16:07:52.211]  Step 163300  [4.225 sec/step, loss=0.09060, avg_loss=0.08715, mel_loss=0.03983, linear_loss=0.05077]
[2020-05-12 16:07:52.211]  Writing summary at step: 163300
[2020-05-12 16:07:54.289]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163300
[2020-05-12 16:07:56.060]  Saving audio and alignment...
[2020-05-12 16:08:06.707]  Input: 이 습도가 조금만 높아도 곰팡이가 생겼고요 이렇게 그 다음 다시 좋은 내용으로 마무리할 때는 어떻게 해야 될까요~_____________________
[2020-05-12 16:08:08.477]  Step 163301  [4.224 sec/step, loss=0.08537, avg_loss=0.08716, mel_loss=0.03653, linear_loss=0.04884]
[2020-05-12 16:08:09.052]  Step 163302  [4.216 sec/step, loss=0.06908, avg_loss=0.08701, mel_loss=0.03015, linear_loss=0.03892]
[2020-05-12 16:08:17.734]  Step 163303  [4.269 sec/step, loss=0.09269, avg_loss=0.08703, mel_loss=0.04226, linear_loss=0.05043]
[2020-05-12 16:08:18.808]  Step 163304  [4.245 sec/step, loss=0.07816, avg_loss=0.08689, mel_loss=0.03332, linear_loss=0.04484]
[2020-05-12 16:08:22.623]  Step 163305  [4.252 sec/step, loss=0.09353, avg_loss=0.08694, mel_loss=0.04138, linear_loss=0.05215]
[2020-05-12 16:08:24.009]  Step 163306  [4.232 sec/step, loss=0.08405, avg_loss=0.08685, mel_loss=0.03613, linear_loss=0.04792]
[2020-05-12 16:08:27.563]  Step 163307  [4.247 sec/step, loss=0.09058, avg_loss=0.08689, mel_loss=0.03986, linear_loss=0.05072]
[2020-05-12 16:08:28.379]  Step 163308  [4.250 sec/step, loss=0.07658, avg_loss=0.08695, mel_loss=0.03236, linear_loss=0.04421]
[2020-05-12 16:08:33.830]  Step 163309  [4.297 sec/step, loss=0.09306, avg_loss=0.08717, mel_loss=0.04158, linear_loss=0.05148]
[2020-05-12 16:08:35.903]  Step 163310  [4.266 sec/step, loss=0.08871, avg_loss=0.08714, mel_loss=0.03825, linear_loss=0.05046]
[2020-05-12 16:08:41.606]  Step 163311  [4.315 sec/step, loss=0.09479, avg_loss=0.08733, mel_loss=0.04257, linear_loss=0.05223]
[2020-05-12 16:08:48.194]  Step 163312  [4.370 sec/step, loss=0.09401, avg_loss=0.08749, mel_loss=0.04228, linear_loss=0.05172]
[2020-05-12 16:08:49.253]  Step 163313  [4.366 sec/step, loss=0.07714, avg_loss=0.08741, mel_loss=0.03241, linear_loss=0.04473]
[2020-05-12 16:08:50.433]  Step 163314  [4.330 sec/step, loss=0.07816, avg_loss=0.08724, mel_loss=0.03287, linear_loss=0.04529]
[2020-05-12 16:08:52.136]  Step 163315  [4.260 sec/step, loss=0.08489, avg_loss=0.08715, mel_loss=0.03671, linear_loss=0.04818]
[2020-05-12 16:08:54.976]  Step 163316  [4.221 sec/step, loss=0.09034, avg_loss=0.08712, mel_loss=0.03972, linear_loss=0.05062]
[2020-05-12 16:08:57.564]  Step 163317  [4.223 sec/step, loss=0.08853, avg_loss=0.08713, mel_loss=0.03818, linear_loss=0.05035]
[2020-05-12 16:09:02.413]  Step 163318  [4.229 sec/step, loss=0.09410, avg_loss=0.08716, mel_loss=0.04171, linear_loss=0.05239]
[2020-05-12 16:09:03.181]  Step 163319  [4.219 sec/step, loss=0.06908, avg_loss=0.08700, mel_loss=0.02914, linear_loss=0.03995]
[2020-05-12 16:09:04.685]  Step 163320  [4.197 sec/step, loss=0.08269, avg_loss=0.08688, mel_loss=0.03559, linear_loss=0.04710]
[2020-05-12 16:09:48.914]  Generated 32 batches of size 32 in 67.302 sec
[2020-05-12 16:09:50.761]  Step 163321  [4.646 sec/step, loss=0.08595, avg_loss=0.08693, mel_loss=0.03685, linear_loss=0.04910]
[2020-05-12 16:09:56.682]  Step 163322  [4.681 sec/step, loss=0.09539, avg_loss=0.08700, mel_loss=0.04294, linear_loss=0.05245]
[2020-05-12 16:10:00.200]  Step 163323  [4.703 sec/step, loss=0.09122, avg_loss=0.08709, mel_loss=0.04019, linear_loss=0.05103]
[2020-05-12 16:10:01.048]  Step 163324  [4.656 sec/step, loss=0.07345, avg_loss=0.08686, mel_loss=0.03127, linear_loss=0.04218]
[2020-05-12 16:10:02.067]  Step 163325  [4.638 sec/step, loss=0.07824, avg_loss=0.08672, mel_loss=0.03314, linear_loss=0.04510]
[2020-05-12 16:10:03.350]  Step 163326  [4.535 sec/step, loss=0.07909, avg_loss=0.08662, mel_loss=0.03396, linear_loss=0.04513]
[2020-05-12 16:10:05.548]  Step 163327  [4.547 sec/step, loss=0.08726, avg_loss=0.08668, mel_loss=0.03778, linear_loss=0.04948]
[2020-05-12 16:10:07.142]  Step 163328  [4.541 sec/step, loss=0.08399, avg_loss=0.08664, mel_loss=0.03621, linear_loss=0.04778]
[2020-05-12 16:10:11.915]  Step 163329  [4.554 sec/step, loss=0.09205, avg_loss=0.08664, mel_loss=0.04083, linear_loss=0.05123]
[2020-05-12 16:10:14.588]  Step 163330  [4.528 sec/step, loss=0.08950, avg_loss=0.08659, mel_loss=0.03903, linear_loss=0.05047]
[2020-05-12 16:10:15.716]  Step 163331  [4.503 sec/step, loss=0.08015, avg_loss=0.08646, mel_loss=0.03385, linear_loss=0.04629]
[2020-05-12 16:10:17.214]  Step 163332  [4.504 sec/step, loss=0.08106, avg_loss=0.08646, mel_loss=0.03465, linear_loss=0.04641]
[2020-05-12 16:10:20.296]  Step 163333  [4.505 sec/step, loss=0.09295, avg_loss=0.08645, mel_loss=0.04094, linear_loss=0.05201]
[2020-05-12 16:10:21.656]  Step 163334  [4.424 sec/step, loss=0.08076, avg_loss=0.08630, mel_loss=0.03455, linear_loss=0.04621]
[2020-05-12 16:10:24.143]  Step 163335  [4.373 sec/step, loss=0.08717, avg_loss=0.08621, mel_loss=0.03774, linear_loss=0.04943]
[2020-05-12 16:10:26.533]  Step 163336  [4.368 sec/step, loss=0.08733, avg_loss=0.08617, mel_loss=0.03775, linear_loss=0.04958]
[2020-05-12 16:10:27.545]  Step 163337  [4.359 sec/step, loss=0.07623, avg_loss=0.08608, mel_loss=0.03231, linear_loss=0.04393]
[2020-05-12 16:10:30.965]  Step 163338  [4.351 sec/step, loss=0.09160, avg_loss=0.08605, mel_loss=0.04008, linear_loss=0.05152]
[2020-05-12 16:10:33.900]  Step 163339  [4.372 sec/step, loss=0.09097, avg_loss=0.08619, mel_loss=0.03975, linear_loss=0.05121]
[2020-05-12 16:10:38.025]  Step 163340  [4.394 sec/step, loss=0.09171, avg_loss=0.08623, mel_loss=0.04045, linear_loss=0.05126]
[2020-05-12 16:10:39.918]  Step 163341  [4.405 sec/step, loss=0.08585, avg_loss=0.08636, mel_loss=0.03705, linear_loss=0.04879]
[2020-05-12 16:10:41.954]  Step 163342  [4.403 sec/step, loss=0.08695, avg_loss=0.08634, mel_loss=0.03757, linear_loss=0.04938]
[2020-05-12 16:10:42.529]  Step 163343  [4.400 sec/step, loss=0.06648, avg_loss=0.08622, mel_loss=0.02911, linear_loss=0.03738]
[2020-05-12 16:10:46.924]  Step 163344  [4.427 sec/step, loss=0.09360, avg_loss=0.08628, mel_loss=0.04142, linear_loss=0.05218]
[2020-05-12 16:10:47.737]  Step 163345  [4.310 sec/step, loss=0.07339, avg_loss=0.08617, mel_loss=0.03110, linear_loss=0.04229]
[2020-05-12 16:10:49.548]  Step 163346  [4.266 sec/step, loss=0.08331, avg_loss=0.08606, mel_loss=0.03554, linear_loss=0.04778]
[2020-05-12 16:10:57.115]  Step 163347  [4.321 sec/step, loss=0.09611, avg_loss=0.08611, mel_loss=0.04350, linear_loss=0.05260]
[2020-05-12 16:11:10.511]  Step 163348  [4.439 sec/step, loss=0.07951, avg_loss=0.08604, mel_loss=0.03683, linear_loss=0.04268]
[2020-05-12 16:11:17.037]  Step 163349  [4.493 sec/step, loss=0.09389, avg_loss=0.08617, mel_loss=0.04216, linear_loss=0.05173]
[2020-05-12 16:11:20.738]  Step 163350  [4.488 sec/step, loss=0.09330, avg_loss=0.08618, mel_loss=0.04131, linear_loss=0.05199]
[2020-05-12 16:11:20.738]  Writing summary at step: 163350
[2020-05-12 16:11:29.432]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163350
[2020-05-12 16:11:31.182]  Saving audio and alignment...
[2020-05-12 16:11:39.115]  Input: 누구나 악보만 그대로 지키면 멋진 음악을 만들어 낼 수 있는 것처럼~______________________________
[2020-05-12 16:11:59.006]  Generated 32 batches of size 32 in 76.472 sec
[2020-05-12 16:12:02.836]  Step 163351  [4.717 sec/step, loss=0.09252, avg_loss=0.08637, mel_loss=0.04078, linear_loss=0.05174]
[2020-05-12 16:12:03.756]  Step 163352  [4.698 sec/step, loss=0.07697, avg_loss=0.08624, mel_loss=0.03225, linear_loss=0.04472]
[2020-05-12 16:12:04.573]  Step 163353  [4.672 sec/step, loss=0.07063, avg_loss=0.08601, mel_loss=0.02956, linear_loss=0.04107]
[2020-05-12 16:12:05.987]  Step 163354  [4.670 sec/step, loss=0.08373, avg_loss=0.08598, mel_loss=0.03586, linear_loss=0.04787]
[2020-05-12 16:12:06.808]  Step 163355  [4.668 sec/step, loss=0.07549, avg_loss=0.08595, mel_loss=0.03181, linear_loss=0.04368]
[2020-05-12 16:12:09.626]  Step 163356  [4.649 sec/step, loss=0.08895, avg_loss=0.08590, mel_loss=0.03878, linear_loss=0.05017]
[2020-05-12 16:12:13.192]  Step 163357  [4.670 sec/step, loss=0.09123, avg_loss=0.08598, mel_loss=0.04015, linear_loss=0.05108]
[2020-05-12 16:12:17.548]  Step 163358  [4.689 sec/step, loss=0.09344, avg_loss=0.08601, mel_loss=0.04121, linear_loss=0.05223]
[2020-05-12 16:12:19.198]  Step 163359  [4.551 sec/step, loss=0.08463, avg_loss=0.08602, mel_loss=0.03644, linear_loss=0.04820]
[2020-05-12 16:12:22.145]  Step 163360  [4.575 sec/step, loss=0.09064, avg_loss=0.08625, mel_loss=0.03965, linear_loss=0.05099]
[2020-05-12 16:12:26.682]  Step 163361  [4.584 sec/step, loss=0.09437, avg_loss=0.08624, mel_loss=0.04211, linear_loss=0.05226]
[2020-05-12 16:12:28.473]  Step 163362  [4.568 sec/step, loss=0.08591, avg_loss=0.08620, mel_loss=0.03686, linear_loss=0.04905]
[2020-05-12 16:12:29.815]  Step 163363  [4.570 sec/step, loss=0.08140, avg_loss=0.08619, mel_loss=0.03467, linear_loss=0.04673]
[2020-05-12 16:12:33.093]  Step 163364  [4.570 sec/step, loss=0.09326, avg_loss=0.08619, mel_loss=0.04122, linear_loss=0.05204]
[2020-05-12 16:12:47.740]  Step 163365  [4.569 sec/step, loss=0.07685, avg_loss=0.08619, mel_loss=0.03597, linear_loss=0.04089]
[2020-05-12 16:12:49.736]  Step 163366  [4.560 sec/step, loss=0.08547, avg_loss=0.08616, mel_loss=0.03687, linear_loss=0.04860]
[2020-05-12 16:12:52.873]  Step 163367  [4.572 sec/step, loss=0.09013, avg_loss=0.08620, mel_loss=0.03948, linear_loss=0.05065]
[2020-05-12 16:12:55.004]  Step 163368  [4.574 sec/step, loss=0.08569, avg_loss=0.08619, mel_loss=0.03683, linear_loss=0.04885]
[2020-05-12 16:12:59.971]  Step 163369  [4.615 sec/step, loss=0.09341, avg_loss=0.08635, mel_loss=0.04142, linear_loss=0.05200]
[2020-05-12 16:13:02.516]  Step 163370  [4.614 sec/step, loss=0.08756, avg_loss=0.08635, mel_loss=0.03778, linear_loss=0.04978]
[2020-05-12 16:13:04.120]  Step 163371  [4.546 sec/step, loss=0.08514, avg_loss=0.08626, mel_loss=0.03642, linear_loss=0.04872]
[2020-05-12 16:13:09.865]  Step 163372  [4.582 sec/step, loss=0.09186, avg_loss=0.08631, mel_loss=0.04094, linear_loss=0.05092]
[2020-05-12 16:13:11.078]  Step 163373  [4.586 sec/step, loss=0.08037, avg_loss=0.08638, mel_loss=0.03394, linear_loss=0.04643]
[2020-05-12 16:13:12.102]  Step 163374  [4.579 sec/step, loss=0.07861, avg_loss=0.08628, mel_loss=0.03320, linear_loss=0.04541]
[2020-05-12 16:13:21.546]  Step 163375  [4.644 sec/step, loss=0.09390, avg_loss=0.08630, mel_loss=0.04288, linear_loss=0.05101]
[2020-05-12 16:13:23.731]  Step 163376  [4.644 sec/step, loss=0.08807, avg_loss=0.08629, mel_loss=0.03801, linear_loss=0.05006]
[2020-05-12 16:13:27.928]  Step 163377  [4.616 sec/step, loss=0.09344, avg_loss=0.08627, mel_loss=0.04115, linear_loss=0.05229]
[2020-05-12 16:13:34.856]  Step 163378  [4.643 sec/step, loss=0.09117, avg_loss=0.08626, mel_loss=0.04101, linear_loss=0.05016]
[2020-05-12 16:13:35.430]  Step 163379  [4.635 sec/step, loss=0.06864, avg_loss=0.08612, mel_loss=0.02933, linear_loss=0.03932]
[2020-05-12 16:13:36.525]  Step 163380  [4.597 sec/step, loss=0.07920, avg_loss=0.08599, mel_loss=0.03347, linear_loss=0.04573]
[2020-05-12 16:13:38.910]  Step 163381  [4.600 sec/step, loss=0.08762, avg_loss=0.08600, mel_loss=0.03846, linear_loss=0.04917]
[2020-05-12 16:13:46.795]  Step 163382  [4.642 sec/step, loss=0.09282, avg_loss=0.08599, mel_loss=0.04202, linear_loss=0.05079]
[2020-05-12 16:14:35.492]  Generated 32 batches of size 32 in 84.408 sec
[2020-05-12 16:14:38.087]  Step 163383  [5.088 sec/step, loss=0.08707, avg_loss=0.08592, mel_loss=0.03768, linear_loss=0.04939]
[2020-05-12 16:14:44.844]  Step 163384  [5.147 sec/step, loss=0.09409, avg_loss=0.08612, mel_loss=0.04222, linear_loss=0.05188]
[2020-05-12 16:14:50.087]  Step 163385  [5.175 sec/step, loss=0.09302, avg_loss=0.08618, mel_loss=0.04146, linear_loss=0.05157]
[2020-05-12 16:15:03.569]  Step 163386  [5.264 sec/step, loss=0.07971, avg_loss=0.08603, mel_loss=0.03708, linear_loss=0.04263]
[2020-05-12 16:15:08.336]  Step 163387  [5.297 sec/step, loss=0.09351, avg_loss=0.08613, mel_loss=0.04149, linear_loss=0.05202]
[2020-05-12 16:15:10.149]  Step 163388  [5.306 sec/step, loss=0.08440, avg_loss=0.08618, mel_loss=0.03609, linear_loss=0.04831]
[2020-05-12 16:15:17.639]  Step 163389  [5.324 sec/step, loss=0.09459, avg_loss=0.08619, mel_loss=0.04280, linear_loss=0.05178]
[2020-05-12 16:15:20.055]  Step 163390  [5.337 sec/step, loss=0.08780, avg_loss=0.08626, mel_loss=0.03819, linear_loss=0.04961]
[2020-05-12 16:15:23.234]  Step 163391  [4.547 sec/step, loss=0.09120, avg_loss=0.08625, mel_loss=0.04013, linear_loss=0.05107]
[2020-05-12 16:15:25.153]  Step 163392  [4.553 sec/step, loss=0.08738, avg_loss=0.08632, mel_loss=0.03769, linear_loss=0.04969]
[2020-05-12 16:15:29.089]  Step 163393  [4.571 sec/step, loss=0.09108, avg_loss=0.08635, mel_loss=0.04011, linear_loss=0.05098]
[2020-05-12 16:15:32.754]  Step 163394  [4.590 sec/step, loss=0.09320, avg_loss=0.08643, mel_loss=0.04108, linear_loss=0.05212]
[2020-05-12 16:15:35.650]  Step 163395  [4.484 sec/step, loss=0.08925, avg_loss=0.08651, mel_loss=0.03909, linear_loss=0.05015]
[2020-05-12 16:15:41.393]  Step 163396  [4.511 sec/step, loss=0.09327, avg_loss=0.08653, mel_loss=0.04185, linear_loss=0.05142]
[2020-05-12 16:15:42.395]  Step 163397  [4.496 sec/step, loss=0.07664, avg_loss=0.08640, mel_loss=0.03233, linear_loss=0.04431]
[2020-05-12 16:15:46.612]  Step 163398  [4.494 sec/step, loss=0.09342, avg_loss=0.08639, mel_loss=0.04169, linear_loss=0.05173]
[2020-05-12 16:15:55.435]  Step 163399  [4.538 sec/step, loss=0.09334, avg_loss=0.08641, mel_loss=0.04241, linear_loss=0.05093]
[2020-05-12 16:15:57.178]  Step 163400  [4.521 sec/step, loss=0.08580, avg_loss=0.08636, mel_loss=0.03686, linear_loss=0.04894]
[2020-05-12 16:15:57.179]  Writing summary at step: 163400
[2020-05-12 16:15:58.198]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163400
[2020-05-12 16:15:59.894]  Saving audio and alignment...
[2020-05-12 16:16:04.556]  Input: 예컨대 이런 대본이 있다면 성우들은 어떻게 하나요~_______
[2020-05-12 16:16:07.990]  Step 163401  [4.537 sec/step, loss=0.09245, avg_loss=0.08643, mel_loss=0.04054, linear_loss=0.05192]
[2020-05-12 16:16:09.103]  Step 163402  [4.543 sec/step, loss=0.08132, avg_loss=0.08655, mel_loss=0.03467, linear_loss=0.04665]
[2020-05-12 16:16:10.460]  Step 163403  [4.469 sec/step, loss=0.08334, avg_loss=0.08646, mel_loss=0.03559, linear_loss=0.04775]
[2020-05-12 16:16:12.660]  Step 163404  [4.481 sec/step, loss=0.08819, avg_loss=0.08656, mel_loss=0.03815, linear_loss=0.05004]
[2020-05-12 16:16:13.510]  Step 163405  [4.451 sec/step, loss=0.06872, avg_loss=0.08631, mel_loss=0.02940, linear_loss=0.03931]
[2020-05-12 16:16:14.311]  Step 163406  [4.445 sec/step, loss=0.07454, avg_loss=0.08622, mel_loss=0.03125, linear_loss=0.04329]
[2020-05-12 16:16:14.818]  Step 163407  [4.415 sec/step, loss=0.07095, avg_loss=0.08602, mel_loss=0.03036, linear_loss=0.04059]
[2020-05-12 16:16:16.081]  Step 163408  [4.419 sec/step, loss=0.07886, avg_loss=0.08604, mel_loss=0.03359, linear_loss=0.04527]
[2020-05-12 16:16:17.715]  Step 163409  [4.381 sec/step, loss=0.08410, avg_loss=0.08595, mel_loss=0.03608, linear_loss=0.04802]
[2020-05-12 16:16:21.150]  Step 163410  [4.395 sec/step, loss=0.09062, avg_loss=0.08597, mel_loss=0.03984, linear_loss=0.05079]
[2020-05-12 16:16:22.593]  Step 163411  [4.352 sec/step, loss=0.08354, avg_loss=0.08586, mel_loss=0.03579, linear_loss=0.04774]
[2020-05-12 16:16:24.647]  Step 163412  [4.307 sec/step, loss=0.08597, avg_loss=0.08578, mel_loss=0.03722, linear_loss=0.04875]
[2020-05-12 16:17:14.701]  Generated 32 batches of size 32 in 64.236 sec
[2020-05-12 16:17:16.145]  Step 163413  [4.811 sec/step, loss=0.08050, avg_loss=0.08581, mel_loss=0.03423, linear_loss=0.04627]
[2020-05-12 16:17:16.680]  Step 163414  [4.805 sec/step, loss=0.06667, avg_loss=0.08570, mel_loss=0.02912, linear_loss=0.03756]
[2020-05-12 16:17:18.321]  Step 163415  [4.804 sec/step, loss=0.08468, avg_loss=0.08570, mel_loss=0.03610, linear_loss=0.04858]
[2020-05-12 16:17:20.427]  Step 163416  [4.797 sec/step, loss=0.08746, avg_loss=0.08567, mel_loss=0.03782, linear_loss=0.04963]
[2020-05-12 16:17:23.568]  Step 163417  [4.802 sec/step, loss=0.09214, avg_loss=0.08570, mel_loss=0.04038, linear_loss=0.05176]
[2020-05-12 16:17:26.786]  Step 163418  [4.786 sec/step, loss=0.09248, avg_loss=0.08569, mel_loss=0.04053, linear_loss=0.05195]
[2020-05-12 16:17:30.397]  Step 163419  [4.814 sec/step, loss=0.09243, avg_loss=0.08592, mel_loss=0.04071, linear_loss=0.05172]
[2020-05-12 16:17:32.177]  Step 163420  [4.817 sec/step, loss=0.08494, avg_loss=0.08594, mel_loss=0.03640, linear_loss=0.04854]
[2020-05-12 16:17:33.408]  Step 163421  [4.369 sec/step, loss=0.07933, avg_loss=0.08588, mel_loss=0.03388, linear_loss=0.04545]
[2020-05-12 16:17:38.242]  Step 163422  [4.358 sec/step, loss=0.09291, avg_loss=0.08585, mel_loss=0.04143, linear_loss=0.05148]
[2020-05-12 16:17:39.918]  Step 163423  [4.339 sec/step, loss=0.08462, avg_loss=0.08579, mel_loss=0.03628, linear_loss=0.04834]
[2020-05-12 16:17:43.672]  Step 163424  [4.368 sec/step, loss=0.09336, avg_loss=0.08598, mel_loss=0.04112, linear_loss=0.05224]
[2020-05-12 16:17:44.595]  Step 163425  [4.367 sec/step, loss=0.07871, avg_loss=0.08599, mel_loss=0.03309, linear_loss=0.04562]
[2020-05-12 16:17:45.645]  Step 163426  [4.365 sec/step, loss=0.07915, avg_loss=0.08599, mel_loss=0.03347, linear_loss=0.04568]
[2020-05-12 16:17:48.607]  Step 163427  [4.373 sec/step, loss=0.08760, avg_loss=0.08599, mel_loss=0.03818, linear_loss=0.04942]
[2020-05-12 16:17:49.415]  Step 163428  [4.365 sec/step, loss=0.07597, avg_loss=0.08591, mel_loss=0.03175, linear_loss=0.04422]
[2020-05-12 16:17:52.066]  Step 163429  [4.344 sec/step, loss=0.08680, avg_loss=0.08586, mel_loss=0.03778, linear_loss=0.04903]
[2020-05-12 16:17:54.083]  Step 163430  [4.337 sec/step, loss=0.08686, avg_loss=0.08583, mel_loss=0.03741, linear_loss=0.04945]
[2020-05-12 16:18:01.181]  Step 163431  [4.397 sec/step, loss=0.09724, avg_loss=0.08601, mel_loss=0.04394, linear_loss=0.05330]
[2020-05-12 16:18:07.254]  Step 163432  [4.443 sec/step, loss=0.09304, avg_loss=0.08612, mel_loss=0.04180, linear_loss=0.05124]
[2020-05-12 16:18:15.390]  Step 163433  [4.493 sec/step, loss=0.09332, avg_loss=0.08613, mel_loss=0.04256, linear_loss=0.05076]
[2020-05-12 16:18:19.848]  Step 163434  [4.524 sec/step, loss=0.09334, avg_loss=0.08625, mel_loss=0.04135, linear_loss=0.05199]
[2020-05-12 16:18:34.644]  Step 163435  [4.647 sec/step, loss=0.07393, avg_loss=0.08612, mel_loss=0.03451, linear_loss=0.03942]
[2020-05-12 16:18:36.583]  Step 163436  [4.643 sec/step, loss=0.08665, avg_loss=0.08612, mel_loss=0.03732, linear_loss=0.04933]
[2020-05-12 16:18:38.851]  Step 163437  [4.655 sec/step, loss=0.08814, avg_loss=0.08623, mel_loss=0.03886, linear_loss=0.04928]
[2020-05-12 16:18:41.330]  Step 163438  [4.646 sec/step, loss=0.09378, avg_loss=0.08626, mel_loss=0.04172, linear_loss=0.05206]
[2020-05-12 16:18:44.799]  Step 163439  [4.651 sec/step, loss=0.09711, avg_loss=0.08632, mel_loss=0.04459, linear_loss=0.05253]
[2020-05-12 16:18:49.093]  Step 163440  [4.653 sec/step, loss=0.09965, avg_loss=0.08640, mel_loss=0.04567, linear_loss=0.05397]
[2020-05-12 16:18:50.530]  Step 163441  [4.648 sec/step, loss=0.08696, avg_loss=0.08641, mel_loss=0.03816, linear_loss=0.04880]
[2020-05-12 16:18:51.195]  Step 163442  [4.635 sec/step, loss=0.07756, avg_loss=0.08631, mel_loss=0.03439, linear_loss=0.04317]
[2020-05-12 16:18:52.326]  Step 163443  [4.640 sec/step, loss=0.09129, avg_loss=0.08656, mel_loss=0.04019, linear_loss=0.05110]
[2020-05-12 16:18:57.815]  Step 163444  [4.651 sec/step, loss=0.12290, avg_loss=0.08686, mel_loss=0.06005, linear_loss=0.06284]
[2020-05-12 16:19:52.483]  Generated 32 batches of size 32 in 77.833 sec
[2020-05-12 16:19:54.123]  Step 163445  [5.206 sec/step, loss=0.09923, avg_loss=0.08711, mel_loss=0.04586, linear_loss=0.05337]
[2020-05-12 16:19:57.160]  Step 163446  [5.218 sec/step, loss=0.11165, avg_loss=0.08740, mel_loss=0.05237, linear_loss=0.05928]
[2020-05-12 16:19:58.208]  Step 163447  [5.153 sec/step, loss=0.08912, avg_loss=0.08733, mel_loss=0.04043, linear_loss=0.04869]
[2020-05-12 16:19:59.720]  Step 163448  [5.034 sec/step, loss=0.09818, avg_loss=0.08751, mel_loss=0.04499, linear_loss=0.05319]
[2020-05-12 16:20:06.438]  Step 163449  [5.036 sec/step, loss=0.11693, avg_loss=0.08774, mel_loss=0.05776, linear_loss=0.05917]
[2020-05-12 16:20:11.819]  Step 163450  [5.053 sec/step, loss=0.11468, avg_loss=0.08796, mel_loss=0.05617, linear_loss=0.05851]
[2020-05-12 16:20:11.819]  Writing summary at step: 163450
[2020-05-12 16:20:19.526]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163450
[2020-05-12 16:20:21.255]  Saving audio and alignment...
[2020-05-12 16:20:23.482]  Input: 저음 중음~_________________
[2020-05-12 16:20:26.876]  Step 163451  [4.850 sec/step, loss=0.10913, avg_loss=0.08812, mel_loss=0.05233, linear_loss=0.05680]
[2020-05-12 16:20:29.019]  Step 163452  [4.862 sec/step, loss=0.10514, avg_loss=0.08841, mel_loss=0.04894, linear_loss=0.05620]
[2020-05-12 16:20:33.098]  Step 163453  [4.895 sec/step, loss=0.10823, avg_loss=0.08878, mel_loss=0.05159, linear_loss=0.05664]
[2020-05-12 16:20:36.787]  Step 163454  [4.917 sec/step, loss=0.11163, avg_loss=0.08906, mel_loss=0.05362, linear_loss=0.05801]
[2020-05-12 16:20:37.774]  Step 163455  [4.919 sec/step, loss=0.09473, avg_loss=0.08925, mel_loss=0.04326, linear_loss=0.05147]
[2020-05-12 16:20:40.361]  Step 163456  [4.917 sec/step, loss=0.10791, avg_loss=0.08944, mel_loss=0.05068, linear_loss=0.05722]
[2020-05-12 16:20:41.575]  Step 163457  [4.893 sec/step, loss=0.09762, avg_loss=0.08951, mel_loss=0.04525, linear_loss=0.05236]
[2020-05-12 16:20:50.234]  Step 163458  [4.936 sec/step, loss=0.12878, avg_loss=0.08986, mel_loss=0.06659, linear_loss=0.06219]
[2020-05-12 16:20:51.509]  Step 163459  [4.932 sec/step, loss=0.09444, avg_loss=0.08996, mel_loss=0.04360, linear_loss=0.05085]
[2020-05-12 16:20:53.897]  Step 163460  [4.927 sec/step, loss=0.10382, avg_loss=0.09009, mel_loss=0.04861, linear_loss=0.05522]
[2020-05-12 16:20:58.299]  Step 163461  [4.925 sec/step, loss=0.11237, avg_loss=0.09027, mel_loss=0.05363, linear_loss=0.05874]
[2020-05-12 16:20:59.680]  Step 163462  [4.921 sec/step, loss=0.09659, avg_loss=0.09038, mel_loss=0.04444, linear_loss=0.05215]
[2020-05-12 16:21:12.806]  Step 163463  [5.039 sec/step, loss=0.09397, avg_loss=0.09050, mel_loss=0.04711, linear_loss=0.04685]
[2020-05-12 16:21:14.725]  Step 163464  [5.026 sec/step, loss=0.10073, avg_loss=0.09058, mel_loss=0.04639, linear_loss=0.05434]
[2020-05-12 16:21:15.281]  Step 163465  [4.885 sec/step, loss=0.08089, avg_loss=0.09062, mel_loss=0.03691, linear_loss=0.04398]
[2020-05-12 16:21:21.052]  Step 163466  [4.922 sec/step, loss=0.11731, avg_loss=0.09094, mel_loss=0.05770, linear_loss=0.05961]
[2020-05-12 16:21:21.859]  Step 163467  [4.899 sec/step, loss=0.08492, avg_loss=0.09088, mel_loss=0.03828, linear_loss=0.04663]
[2020-05-12 16:21:22.696]  Step 163468  [4.886 sec/step, loss=0.08352, avg_loss=0.09086, mel_loss=0.03720, linear_loss=0.04632]
[2020-05-12 16:21:24.444]  Step 163469  [4.854 sec/step, loss=0.11128, avg_loss=0.09104, mel_loss=0.05320, linear_loss=0.05808]
[2020-05-12 16:21:29.308]  Step 163470  [4.877 sec/step, loss=0.13843, avg_loss=0.09155, mel_loss=0.07189, linear_loss=0.06654]
[2020-05-12 16:21:31.979]  Step 163471  [4.888 sec/step, loss=0.11174, avg_loss=0.09182, mel_loss=0.05369, linear_loss=0.05806]
[2020-05-12 16:21:34.020]  Step 163472  [4.851 sec/step, loss=0.10449, avg_loss=0.09194, mel_loss=0.04932, linear_loss=0.05516]
[2020-05-12 16:21:36.927]  Step 163473  [4.868 sec/step, loss=0.11222, avg_loss=0.09226, mel_loss=0.05236, linear_loss=0.05986]
[2020-05-12 16:21:40.256]  Step 163474  [4.891 sec/step, loss=0.10944, avg_loss=0.09257, mel_loss=0.05168, linear_loss=0.05776]
[2020-05-12 16:22:03.153]  Generated 32 batches of size 32 in 47.866 sec
[2020-05-12 16:22:04.771]  Step 163475  [5.042 sec/step, loss=0.10079, avg_loss=0.09264, mel_loss=0.04641, linear_loss=0.05439]
[2020-05-12 16:22:08.218]  Step 163476  [5.054 sec/step, loss=0.10826, avg_loss=0.09284, mel_loss=0.05117, linear_loss=0.05710]
[2020-05-12 16:22:11.350]  Step 163477  [5.044 sec/step, loss=0.10875, avg_loss=0.09299, mel_loss=0.05127, linear_loss=0.05748]
[2020-05-12 16:22:12.106]  Step 163478  [4.982 sec/step, loss=0.09025, avg_loss=0.09298, mel_loss=0.04029, linear_loss=0.04996]
[2020-05-12 16:22:16.178]  Step 163479  [5.017 sec/step, loss=0.11149, avg_loss=0.09341, mel_loss=0.05370, linear_loss=0.05779]
[2020-05-12 16:22:21.532]  Step 163480  [5.059 sec/step, loss=0.11407, avg_loss=0.09376, mel_loss=0.05503, linear_loss=0.05904]
[2020-05-12 16:22:23.277]  Step 163481  [5.053 sec/step, loss=0.09890, avg_loss=0.09387, mel_loss=0.04521, linear_loss=0.05368]
[2020-05-12 16:22:26.765]  Step 163482  [5.009 sec/step, loss=0.10229, avg_loss=0.09397, mel_loss=0.04734, linear_loss=0.05494]
[2020-05-12 16:22:27.321]  Step 163483  [4.502 sec/step, loss=0.07692, avg_loss=0.09387, mel_loss=0.03450, linear_loss=0.04241]
[2020-05-12 16:22:28.709]  Step 163484  [4.448 sec/step, loss=0.09353, avg_loss=0.09386, mel_loss=0.04221, linear_loss=0.05132]
[2020-05-12 16:22:34.438]  Step 163485  [4.453 sec/step, loss=0.11597, avg_loss=0.09409, mel_loss=0.05677, linear_loss=0.05920]
[2020-05-12 16:22:38.091]  Step 163486  [4.355 sec/step, loss=0.10588, avg_loss=0.09435, mel_loss=0.04954, linear_loss=0.05634]
[2020-05-12 16:22:39.196]  Step 163487  [4.318 sec/step, loss=0.09025, avg_loss=0.09432, mel_loss=0.04011, linear_loss=0.05014]
[2020-05-12 16:22:40.527]  Step 163488  [4.313 sec/step, loss=0.09184, avg_loss=0.09439, mel_loss=0.04100, linear_loss=0.05084]
[2020-05-12 16:22:43.119]  Step 163489  [4.264 sec/step, loss=0.09944, avg_loss=0.09444, mel_loss=0.04587, linear_loss=0.05357]
[2020-05-12 16:22:47.942]  Step 163490  [4.288 sec/step, loss=0.10878, avg_loss=0.09465, mel_loss=0.05210, linear_loss=0.05668]
[2020-05-12 16:22:50.098]  Step 163491  [4.278 sec/step, loss=0.09930, avg_loss=0.09473, mel_loss=0.04543, linear_loss=0.05387]
[2020-05-12 16:22:51.728]  Step 163492  [4.275 sec/step, loss=0.09861, avg_loss=0.09485, mel_loss=0.04468, linear_loss=0.05393]
[2020-05-12 16:22:54.603]  Step 163493  [4.264 sec/step, loss=0.10289, avg_loss=0.09496, mel_loss=0.04794, linear_loss=0.05495]
[2020-05-12 16:22:55.357]  Step 163494  [4.235 sec/step, loss=0.08666, avg_loss=0.09490, mel_loss=0.03819, linear_loss=0.04847]
[2020-05-12 16:22:59.768]  Step 163495  [4.251 sec/step, loss=0.10565, avg_loss=0.09506, mel_loss=0.04998, linear_loss=0.05567]
[2020-05-12 16:23:02.183]  Step 163496  [4.217 sec/step, loss=0.10305, avg_loss=0.09516, mel_loss=0.04799, linear_loss=0.05505]
[2020-05-12 16:23:04.172]  Step 163497  [4.227 sec/step, loss=0.09618, avg_loss=0.09536, mel_loss=0.04357, linear_loss=0.05261]
[2020-05-12 16:23:11.915]  Step 163498  [4.262 sec/step, loss=0.11221, avg_loss=0.09554, mel_loss=0.05516, linear_loss=0.05705]
[2020-05-12 16:23:13.728]  Step 163499  [4.192 sec/step, loss=0.09528, avg_loss=0.09556, mel_loss=0.04324, linear_loss=0.05204]
[2020-05-12 16:23:14.944]  Step 163500  [4.187 sec/step, loss=0.09215, avg_loss=0.09563, mel_loss=0.04140, linear_loss=0.05075]
[2020-05-12 16:23:14.945]  Writing summary at step: 163500
[2020-05-12 16:23:29.655]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163500
[2020-05-12 16:23:31.395]  Saving audio and alignment...
[2020-05-12 16:23:33.359]  Input: 어머님 나는~_______
[2020-05-12 16:23:39.805]  Step 163501  [4.217 sec/step, loss=0.11315, avg_loss=0.09583, mel_loss=0.05521, linear_loss=0.05794]
[2020-05-12 16:23:48.750]  Step 163502  [4.295 sec/step, loss=0.11854, avg_loss=0.09620, mel_loss=0.06001, linear_loss=0.05853]
[2020-05-12 16:23:51.035]  Step 163503  [4.305 sec/step, loss=0.09920, avg_loss=0.09636, mel_loss=0.04550, linear_loss=0.05370]
[2020-05-12 16:23:52.085]  Step 163504  [4.293 sec/step, loss=0.08688, avg_loss=0.09635, mel_loss=0.03864, linear_loss=0.04824]
[2020-05-12 16:24:18.851]  Generated 32 batches of size 32 in 74.674 sec
[2020-05-12 16:24:23.840]  Step 163505  [4.602 sec/step, loss=0.10642, avg_loss=0.09673, mel_loss=0.05013, linear_loss=0.05629]
[2020-05-12 16:24:28.126]  Step 163506  [4.637 sec/step, loss=0.10411, avg_loss=0.09702, mel_loss=0.04815, linear_loss=0.05596]
[2020-05-12 16:24:31.400]  Step 163507  [4.665 sec/step, loss=0.09949, avg_loss=0.09731, mel_loss=0.04554, linear_loss=0.05395]
[2020-05-12 16:24:35.042]  Step 163508  [4.688 sec/step, loss=0.10202, avg_loss=0.09754, mel_loss=0.04709, linear_loss=0.05494]
[2020-05-12 16:24:37.060]  Step 163509  [4.692 sec/step, loss=0.09774, avg_loss=0.09768, mel_loss=0.04420, linear_loss=0.05354]
[2020-05-12 16:24:40.089]  Step 163510  [4.688 sec/step, loss=0.10250, avg_loss=0.09780, mel_loss=0.04673, linear_loss=0.05576]
[2020-05-12 16:24:42.251]  Step 163511  [4.695 sec/step, loss=0.09634, avg_loss=0.09792, mel_loss=0.04369, linear_loss=0.05266]
[2020-05-12 16:24:49.541]  Step 163512  [4.748 sec/step, loss=0.10312, avg_loss=0.09810, mel_loss=0.04903, linear_loss=0.05409]
[2020-05-12 16:24:52.324]  Step 163513  [4.261 sec/step, loss=0.09704, avg_loss=0.09826, mel_loss=0.04376, linear_loss=0.05329]
[2020-05-12 16:24:53.385]  Step 163514  [4.266 sec/step, loss=0.08555, avg_loss=0.09845, mel_loss=0.03785, linear_loss=0.04770]
[2020-05-12 16:24:54.205]  Step 163515  [4.258 sec/step, loss=0.07920, avg_loss=0.09839, mel_loss=0.03472, linear_loss=0.04449]
[2020-05-12 16:25:06.771]  Step 163516  [4.362 sec/step, loss=0.09621, avg_loss=0.09848, mel_loss=0.04769, linear_loss=0.04852]
[2020-05-12 16:25:08.660]  Step 163517  [4.350 sec/step, loss=0.09470, avg_loss=0.09851, mel_loss=0.04216, linear_loss=0.05254]
[2020-05-12 16:25:09.807]  Step 163518  [4.329 sec/step, loss=0.08804, avg_loss=0.09846, mel_loss=0.03898, linear_loss=0.04906]
[2020-05-12 16:25:10.737]  Step 163519  [4.302 sec/step, loss=0.08374, avg_loss=0.09838, mel_loss=0.03629, linear_loss=0.04746]
[2020-05-12 16:25:12.305]  Step 163520  [4.300 sec/step, loss=0.09313, avg_loss=0.09846, mel_loss=0.04152, linear_loss=0.05160]
[2020-05-12 16:25:12.874]  Step 163521  [4.294 sec/step, loss=0.07235, avg_loss=0.09839, mel_loss=0.03261, linear_loss=0.03974]
[2020-05-12 16:25:15.126]  Step 163522  [4.268 sec/step, loss=0.09464, avg_loss=0.09841, mel_loss=0.04269, linear_loss=0.05195]
[2020-05-12 16:25:23.703]  Step 163523  [4.337 sec/step, loss=0.10230, avg_loss=0.09858, mel_loss=0.04939, linear_loss=0.05291]
[2020-05-12 16:25:26.183]  Step 163524  [4.324 sec/step, loss=0.09693, avg_loss=0.09862, mel_loss=0.04356, linear_loss=0.05337]
[2020-05-12 16:25:32.162]  Step 163525  [4.375 sec/step, loss=0.10423, avg_loss=0.09887, mel_loss=0.04930, linear_loss=0.05493]
[2020-05-12 16:25:33.811]  Step 163526  [4.381 sec/step, loss=0.09160, avg_loss=0.09900, mel_loss=0.04092, linear_loss=0.05068]
[2020-05-12 16:25:36.725]  Step 163527  [4.380 sec/step, loss=0.09627, avg_loss=0.09908, mel_loss=0.04378, linear_loss=0.05249]
[2020-05-12 16:25:42.299]  Step 163528  [4.428 sec/step, loss=0.10149, avg_loss=0.09934, mel_loss=0.04726, linear_loss=0.05424]
[2020-05-12 16:25:46.115]  Step 163529  [4.439 sec/step, loss=0.10012, avg_loss=0.09947, mel_loss=0.04556, linear_loss=0.05456]
[2020-05-12 16:25:49.584]  Step 163530  [4.454 sec/step, loss=0.09926, avg_loss=0.09960, mel_loss=0.04549, linear_loss=0.05376]
[2020-05-12 16:25:50.950]  Step 163531  [4.397 sec/step, loss=0.09026, avg_loss=0.09953, mel_loss=0.03989, linear_loss=0.05037]
[2020-05-12 16:25:52.109]  Step 163532  [4.347 sec/step, loss=0.08666, avg_loss=0.09946, mel_loss=0.03793, linear_loss=0.04873]
[2020-05-12 16:25:52.963]  Step 163533  [4.275 sec/step, loss=0.07583, avg_loss=0.09929, mel_loss=0.03302, linear_loss=0.04281]
[2020-05-12 16:25:57.516]  Step 163534  [4.276 sec/step, loss=0.10170, avg_loss=0.09937, mel_loss=0.04701, linear_loss=0.05469]
[2020-05-12 16:25:59.471]  Step 163535  [4.147 sec/step, loss=0.09174, avg_loss=0.09955, mel_loss=0.04054, linear_loss=0.05120]
[2020-05-12 16:26:00.780]  Step 163536  [4.141 sec/step, loss=0.08582, avg_loss=0.09954, mel_loss=0.03760, linear_loss=0.04822]
[2020-05-12 16:26:31.105]  Generated 32 batches of size 32 in 54.375 sec
[2020-05-12 16:26:34.838]  Step 163537  [4.459 sec/step, loss=0.09880, avg_loss=0.09965, mel_loss=0.04500, linear_loss=0.05380]
[2020-05-12 16:26:35.820]  Step 163538  [4.444 sec/step, loss=0.08372, avg_loss=0.09955, mel_loss=0.03627, linear_loss=0.04745]
[2020-05-12 16:26:38.766]  Step 163539  [4.439 sec/step, loss=0.09320, avg_loss=0.09951, mel_loss=0.04201, linear_loss=0.05119]
[2020-05-12 16:26:40.814]  Step 163540  [4.416 sec/step, loss=0.09202, avg_loss=0.09943, mel_loss=0.04073, linear_loss=0.05129]
[2020-05-12 16:26:43.455]  Step 163541  [4.428 sec/step, loss=0.09457, avg_loss=0.09951, mel_loss=0.04255, linear_loss=0.05202]
[2020-05-12 16:26:48.442]  Step 163542  [4.471 sec/step, loss=0.09941, avg_loss=0.09973, mel_loss=0.04553, linear_loss=0.05388]
[2020-05-12 16:26:54.174]  Step 163543  [4.517 sec/step, loss=0.09859, avg_loss=0.09980, mel_loss=0.04550, linear_loss=0.05309]
[2020-05-12 16:26:55.749]  Step 163544  [4.478 sec/step, loss=0.09014, avg_loss=0.09947, mel_loss=0.03944, linear_loss=0.05071]
[2020-05-12 16:26:59.216]  Step 163545  [3.950 sec/step, loss=0.09683, avg_loss=0.09945, mel_loss=0.04363, linear_loss=0.05320]
[2020-05-12 16:27:00.040]  Step 163546  [3.928 sec/step, loss=0.07567, avg_loss=0.09909, mel_loss=0.03284, linear_loss=0.04283]
[2020-05-12 16:27:02.403]  Step 163547  [3.941 sec/step, loss=0.09225, avg_loss=0.09912, mel_loss=0.04094, linear_loss=0.05131]
[2020-05-12 16:27:09.559]  Step 163548  [3.997 sec/step, loss=0.10012, avg_loss=0.09914, mel_loss=0.04660, linear_loss=0.05352]
[2020-05-12 16:27:14.216]  Step 163549  [3.977 sec/step, loss=0.09875, avg_loss=0.09896, mel_loss=0.04502, linear_loss=0.05373]
[2020-05-12 16:27:22.796]  Step 163550  [4.009 sec/step, loss=0.10041, avg_loss=0.09882, mel_loss=0.04760, linear_loss=0.05281]
[2020-05-12 16:27:22.796]  Writing summary at step: 163550
[2020-05-12 16:27:30.530]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163550
[2020-05-12 16:27:32.184]  Saving audio and alignment...
[2020-05-12 16:27:34.067]  Input: 잠깐 쉬시고~_______
[2020-05-12 16:27:36.025]  Step 163551  [3.994 sec/step, loss=0.09013, avg_loss=0.09863, mel_loss=0.03966, linear_loss=0.05047]
[2020-05-12 16:27:39.442]  Step 163552  [4.007 sec/step, loss=0.09548, avg_loss=0.09853, mel_loss=0.04322, linear_loss=0.05226]
[2020-05-12 16:27:40.798]  Step 163553  [3.980 sec/step, loss=0.08559, avg_loss=0.09830, mel_loss=0.03744, linear_loss=0.04814]
[2020-05-12 16:27:55.391]  Step 163554  [4.089 sec/step, loss=0.07971, avg_loss=0.09798, mel_loss=0.03835, linear_loss=0.04136]
[2020-05-12 16:27:56.637]  Step 163555  [4.091 sec/step, loss=0.08447, avg_loss=0.09788, mel_loss=0.03672, linear_loss=0.04775]
[2020-05-12 16:27:59.183]  Step 163556  [4.091 sec/step, loss=0.09010, avg_loss=0.09770, mel_loss=0.03989, linear_loss=0.05022]
[2020-05-12 16:28:02.294]  Step 163557  [4.110 sec/step, loss=0.09793, avg_loss=0.09771, mel_loss=0.04410, linear_loss=0.05383]
[2020-05-12 16:28:04.127]  Step 163558  [4.042 sec/step, loss=0.09145, avg_loss=0.09733, mel_loss=0.04064, linear_loss=0.05081]
[2020-05-12 16:28:04.898]  Step 163559  [4.037 sec/step, loss=0.07097, avg_loss=0.09710, mel_loss=0.03139, linear_loss=0.03958]
[2020-05-12 16:28:06.655]  Step 163560  [4.030 sec/step, loss=0.09091, avg_loss=0.09697, mel_loss=0.03971, linear_loss=0.05120]
[2020-05-12 16:28:09.067]  Step 163561  [4.010 sec/step, loss=0.09216, avg_loss=0.09677, mel_loss=0.04099, linear_loss=0.05118]
[2020-05-12 16:28:09.990]  Step 163562  [4.006 sec/step, loss=0.07824, avg_loss=0.09658, mel_loss=0.03354, linear_loss=0.04470]
[2020-05-12 16:28:14.139]  Step 163563  [3.916 sec/step, loss=0.09622, avg_loss=0.09661, mel_loss=0.04342, linear_loss=0.05281]
[2020-05-12 16:28:15.641]  Step 163564  [3.912 sec/step, loss=0.08604, avg_loss=0.09646, mel_loss=0.03759, linear_loss=0.04846]
[2020-05-12 16:28:19.843]  Step 163565  [3.948 sec/step, loss=0.09676, avg_loss=0.09662, mel_loss=0.04374, linear_loss=0.05302]
[2020-05-12 16:28:20.906]  Step 163566  [3.901 sec/step, loss=0.08197, avg_loss=0.09626, mel_loss=0.03544, linear_loss=0.04654]
[2020-05-12 16:29:31.872]  Generated 32 batches of size 32 in 89.573 sec
[2020-05-12 16:29:32.984]  Step 163567  [4.614 sec/step, loss=0.08582, avg_loss=0.09627, mel_loss=0.03687, linear_loss=0.04895]
[2020-05-12 16:29:33.992]  Step 163568  [4.616 sec/step, loss=0.07859, avg_loss=0.09622, mel_loss=0.03375, linear_loss=0.04484]
[2020-05-12 16:29:36.896]  Step 163569  [4.627 sec/step, loss=0.09422, avg_loss=0.09605, mel_loss=0.04203, linear_loss=0.05219]
[2020-05-12 16:29:40.984]  Step 163570  [4.620 sec/step, loss=0.09708, avg_loss=0.09564, mel_loss=0.04382, linear_loss=0.05326]
[2020-05-12 16:29:43.729]  Step 163571  [4.620 sec/step, loss=0.09302, avg_loss=0.09545, mel_loss=0.04133, linear_loss=0.05169]
[2020-05-12 16:29:49.401]  Step 163572  [4.657 sec/step, loss=0.10086, avg_loss=0.09542, mel_loss=0.04683, linear_loss=0.05403]
[2020-05-12 16:29:51.387]  Step 163573  [4.647 sec/step, loss=0.09110, avg_loss=0.09520, mel_loss=0.03991, linear_loss=0.05118]
[2020-05-12 16:29:58.562]  Step 163574  [4.686 sec/step, loss=0.09867, avg_loss=0.09510, mel_loss=0.04573, linear_loss=0.05294]
[2020-05-12 16:30:01.943]  Step 163575  [4.474 sec/step, loss=0.09670, avg_loss=0.09506, mel_loss=0.04368, linear_loss=0.05302]
[2020-05-12 16:30:08.650]  Step 163576  [4.507 sec/step, loss=0.09947, avg_loss=0.09497, mel_loss=0.04596, linear_loss=0.05351]
[2020-05-12 16:30:09.414]  Step 163577  [4.483 sec/step, loss=0.06980, avg_loss=0.09458, mel_loss=0.03016, linear_loss=0.03964]
[2020-05-12 16:30:10.573]  Step 163578  [4.487 sec/step, loss=0.08563, avg_loss=0.09453, mel_loss=0.03680, linear_loss=0.04883]
[2020-05-12 16:30:12.218]  Step 163579  [4.463 sec/step, loss=0.08674, avg_loss=0.09429, mel_loss=0.03823, linear_loss=0.04851]
[2020-05-12 16:30:16.859]  Step 163580  [4.456 sec/step, loss=0.09542, avg_loss=0.09410, mel_loss=0.04314, linear_loss=0.05228]
[2020-05-12 16:30:17.731]  Step 163581  [4.447 sec/step, loss=0.07671, avg_loss=0.09388, mel_loss=0.03323, linear_loss=0.04348]
[2020-05-12 16:30:20.088]  Step 163582  [4.436 sec/step, loss=0.09303, avg_loss=0.09378, mel_loss=0.04123, linear_loss=0.05180]
[2020-05-12 16:30:21.466]  Step 163583  [4.444 sec/step, loss=0.08718, avg_loss=0.09389, mel_loss=0.03826, linear_loss=0.04892]
[2020-05-12 16:30:23.694]  Step 163584  [4.453 sec/step, loss=0.09163, avg_loss=0.09387, mel_loss=0.04048, linear_loss=0.05114]
[2020-05-12 16:30:29.750]  Step 163585  [4.456 sec/step, loss=0.09906, avg_loss=0.09370, mel_loss=0.04539, linear_loss=0.05367]
[2020-05-12 16:30:32.917]  Step 163586  [4.451 sec/step, loss=0.09500, avg_loss=0.09359, mel_loss=0.04239, linear_loss=0.05261]
[2020-05-12 16:30:34.324]  Step 163587  [4.454 sec/step, loss=0.08427, avg_loss=0.09353, mel_loss=0.03655, linear_loss=0.04771]
[2020-05-12 16:30:35.548]  Step 163588  [4.453 sec/step, loss=0.08596, avg_loss=0.09347, mel_loss=0.03706, linear_loss=0.04890]
[2020-05-12 16:30:37.355]  Step 163589  [4.445 sec/step, loss=0.08868, avg_loss=0.09336, mel_loss=0.03893, linear_loss=0.04975]
[2020-05-12 16:30:39.083]  Step 163590  [4.414 sec/step, loss=0.08748, avg_loss=0.09315, mel_loss=0.03858, linear_loss=0.04890]
[2020-05-12 16:30:42.651]  Step 163591  [4.428 sec/step, loss=0.09449, avg_loss=0.09310, mel_loss=0.04218, linear_loss=0.05231]
[2020-05-12 16:30:51.670]  Step 163592  [4.502 sec/step, loss=0.09702, avg_loss=0.09309, mel_loss=0.04520, linear_loss=0.05182]
[2020-05-12 16:30:53.761]  Step 163593  [4.494 sec/step, loss=0.08889, avg_loss=0.09295, mel_loss=0.03909, linear_loss=0.04979]
[2020-05-12 16:30:54.796]  Step 163594  [4.497 sec/step, loss=0.07911, avg_loss=0.09287, mel_loss=0.03421, linear_loss=0.04490]
[2020-05-12 16:30:58.542]  Step 163595  [4.491 sec/step, loss=0.09708, avg_loss=0.09279, mel_loss=0.04340, linear_loss=0.05367]
[2020-05-12 16:30:58.995]  Generated 32 batches of size 32 in 21.634 sec
[2020-05-12 16:31:10.437]  Step 163596  [4.585 sec/step, loss=0.09112, avg_loss=0.09267, mel_loss=0.04319, linear_loss=0.04793]
[2020-05-12 16:31:11.001]  Step 163597  [4.571 sec/step, loss=0.06879, avg_loss=0.09239, mel_loss=0.03047, linear_loss=0.03831]
[2020-05-12 16:31:15.739]  Step 163598  [4.541 sec/step, loss=0.09720, avg_loss=0.09224, mel_loss=0.04407, linear_loss=0.05313]
[2020-05-12 16:31:19.444]  Step 163599  [4.560 sec/step, loss=0.09713, avg_loss=0.09226, mel_loss=0.04353, linear_loss=0.05360]
[2020-05-12 16:31:25.120]  Step 163600  [4.605 sec/step, loss=0.09859, avg_loss=0.09232, mel_loss=0.04524, linear_loss=0.05335]
[2020-05-12 16:31:25.120]  Writing summary at step: 163600
[2020-05-12 16:31:25.961]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163600
[2020-05-12 16:31:27.669]  Saving audio and alignment...
[2020-05-12 16:31:34.253]  Input: 또 쉽표 있는 데서 쉴까요 비슷한 구문인데 거기서 쉬지 않고여~______________
[2020-05-12 16:31:38.408]  Step 163601  [4.582 sec/step, loss=0.09511, avg_loss=0.09214, mel_loss=0.04263, linear_loss=0.05248]
[2020-05-12 16:31:41.376]  Step 163602  [4.522 sec/step, loss=0.09352, avg_loss=0.09189, mel_loss=0.04163, linear_loss=0.05189]
[2020-05-12 16:31:47.816]  Step 163603  [4.563 sec/step, loss=0.09794, avg_loss=0.09188, mel_loss=0.04527, linear_loss=0.05267]
[2020-05-12 16:31:49.895]  Step 163604  [4.574 sec/step, loss=0.09038, avg_loss=0.09192, mel_loss=0.03958, linear_loss=0.05080]
[2020-05-12 16:31:52.319]  Step 163605  [4.280 sec/step, loss=0.09255, avg_loss=0.09178, mel_loss=0.04100, linear_loss=0.05155]
[2020-05-12 16:31:54.047]  Step 163606  [4.255 sec/step, loss=0.08875, avg_loss=0.09162, mel_loss=0.03841, linear_loss=0.05035]
[2020-05-12 16:31:56.228]  Step 163607  [4.244 sec/step, loss=0.08944, avg_loss=0.09152, mel_loss=0.03914, linear_loss=0.05030]
[2020-05-12 16:32:07.968]  Step 163608  [4.325 sec/step, loss=0.09364, avg_loss=0.09144, mel_loss=0.04443, linear_loss=0.04921]
[2020-05-12 16:32:09.486]  Step 163609  [4.320 sec/step, loss=0.08736, avg_loss=0.09134, mel_loss=0.03796, linear_loss=0.04940]
[2020-05-12 16:32:11.575]  Step 163610  [4.311 sec/step, loss=0.08963, avg_loss=0.09121, mel_loss=0.03926, linear_loss=0.05037]
[2020-05-12 16:32:12.401]  Step 163611  [4.297 sec/step, loss=0.07571, avg_loss=0.09100, mel_loss=0.03230, linear_loss=0.04341]
[2020-05-12 16:32:13.396]  Step 163612  [4.234 sec/step, loss=0.07914, avg_loss=0.09076, mel_loss=0.03363, linear_loss=0.04551]
[2020-05-12 16:32:22.721]  Step 163613  [4.300 sec/step, loss=0.09563, avg_loss=0.09075, mel_loss=0.04423, linear_loss=0.05140]
[2020-05-12 16:32:30.272]  Step 163614  [4.365 sec/step, loss=0.09898, avg_loss=0.09088, mel_loss=0.04545, linear_loss=0.05353]
[2020-05-12 16:32:33.820]  Step 163615  [4.392 sec/step, loss=0.09541, avg_loss=0.09104, mel_loss=0.04279, linear_loss=0.05262]
[2020-05-12 16:32:39.162]  Step 163616  [4.320 sec/step, loss=0.09628, avg_loss=0.09104, mel_loss=0.04360, linear_loss=0.05268]
[2020-05-12 16:32:39.739]  Step 163617  [4.306 sec/step, loss=0.06771, avg_loss=0.09077, mel_loss=0.02965, linear_loss=0.03806]
[2020-05-12 16:32:41.090]  Step 163618  [4.309 sec/step, loss=0.08008, avg_loss=0.09070, mel_loss=0.03481, linear_loss=0.04527]
[2020-05-12 16:32:43.690]  Step 163619  [4.325 sec/step, loss=0.09021, avg_loss=0.09076, mel_loss=0.03955, linear_loss=0.05067]
[2020-05-12 16:32:46.407]  Step 163620  [4.337 sec/step, loss=0.09203, avg_loss=0.09075, mel_loss=0.04103, linear_loss=0.05100]
[2020-05-12 16:32:49.643]  Step 163621  [4.363 sec/step, loss=0.09532, avg_loss=0.09098, mel_loss=0.04228, linear_loss=0.05304]
[2020-05-12 16:32:51.293]  Step 163622  [4.357 sec/step, loss=0.08800, avg_loss=0.09091, mel_loss=0.03857, linear_loss=0.04943]
[2020-05-12 16:32:55.993]  Step 163623  [4.319 sec/step, loss=0.09707, avg_loss=0.09086, mel_loss=0.04368, linear_loss=0.05338]
[2020-05-12 16:32:57.075]  Step 163624  [4.305 sec/step, loss=0.07700, avg_loss=0.09066, mel_loss=0.03312, linear_loss=0.04388]
[2020-05-12 16:32:58.484]  Step 163625  [4.259 sec/step, loss=0.08573, avg_loss=0.09048, mel_loss=0.03702, linear_loss=0.04871]
[2020-05-12 16:33:02.085]  Step 163626  [4.278 sec/step, loss=0.09367, avg_loss=0.09050, mel_loss=0.04199, linear_loss=0.05168]
[2020-05-12 16:33:03.252]  Step 163627  [4.261 sec/step, loss=0.07967, avg_loss=0.09033, mel_loss=0.03399, linear_loss=0.04568]
[2020-05-12 16:33:05.086]  Step 163628  [4.224 sec/step, loss=0.08760, avg_loss=0.09019, mel_loss=0.03813, linear_loss=0.04947]
[2020-05-12 16:33:35.061]  Generated 32 batches of size 32 in 51.365 sec
[2020-05-12 16:33:38.539]  Step 163629  [4.520 sec/step, loss=0.09370, avg_loss=0.09013, mel_loss=0.04173, linear_loss=0.05198]
[2020-05-12 16:33:41.407]  Step 163630  [4.514 sec/step, loss=0.09142, avg_loss=0.09005, mel_loss=0.04055, linear_loss=0.05087]
[2020-05-12 16:33:43.147]  Step 163631  [4.518 sec/step, loss=0.08455, avg_loss=0.08999, mel_loss=0.03718, linear_loss=0.04737]
[2020-05-12 16:33:45.425]  Step 163632  [4.529 sec/step, loss=0.08899, avg_loss=0.09002, mel_loss=0.03914, linear_loss=0.04985]
[2020-05-12 16:33:46.711]  Step 163633  [4.533 sec/step, loss=0.08171, avg_loss=0.09007, mel_loss=0.03544, linear_loss=0.04627]
[2020-05-12 16:33:47.543]  Step 163634  [4.496 sec/step, loss=0.07671, avg_loss=0.08982, mel_loss=0.03256, linear_loss=0.04415]
[2020-05-12 16:33:48.116]  Step 163635  [4.482 sec/step, loss=0.06853, avg_loss=0.08959, mel_loss=0.02995, linear_loss=0.03859]
[2020-05-12 16:33:49.530]  Step 163636  [4.483 sec/step, loss=0.08423, avg_loss=0.08958, mel_loss=0.03661, linear_loss=0.04761]
[2020-05-12 16:33:50.441]  Step 163637  [4.152 sec/step, loss=0.08084, avg_loss=0.08940, mel_loss=0.03444, linear_loss=0.04640]
[2020-05-12 16:33:56.065]  Step 163638  [4.198 sec/step, loss=0.09674, avg_loss=0.08953, mel_loss=0.04394, linear_loss=0.05279]
[2020-05-12 16:33:58.092]  Step 163639  [4.189 sec/step, loss=0.08892, avg_loss=0.08948, mel_loss=0.03878, linear_loss=0.05014]
[2020-05-12 16:34:00.279]  Step 163640  [4.190 sec/step, loss=0.08798, avg_loss=0.08944, mel_loss=0.03851, linear_loss=0.04947]
[2020-05-12 16:34:01.857]  Step 163641  [4.180 sec/step, loss=0.08466, avg_loss=0.08934, mel_loss=0.03675, linear_loss=0.04791]
[2020-05-12 16:34:03.000]  Step 163642  [4.141 sec/step, loss=0.07975, avg_loss=0.08915, mel_loss=0.03412, linear_loss=0.04563]
[2020-05-12 16:34:07.076]  Step 163643  [4.125 sec/step, loss=0.09714, avg_loss=0.08913, mel_loss=0.04344, linear_loss=0.05369]
[2020-05-12 16:34:11.417]  Step 163644  [4.152 sec/step, loss=0.09577, avg_loss=0.08919, mel_loss=0.04310, linear_loss=0.05267]
[2020-05-12 16:34:15.101]  Step 163645  [4.155 sec/step, loss=0.09585, avg_loss=0.08918, mel_loss=0.04275, linear_loss=0.05310]
[2020-05-12 16:34:29.728]  Step 163646  [4.293 sec/step, loss=0.07489, avg_loss=0.08917, mel_loss=0.03534, linear_loss=0.03954]
[2020-05-12 16:34:37.190]  Step 163647  [4.344 sec/step, loss=0.09899, avg_loss=0.08924, mel_loss=0.04549, linear_loss=0.05350]
[2020-05-12 16:34:41.972]  Step 163648  [4.320 sec/step, loss=0.09741, avg_loss=0.08921, mel_loss=0.04420, linear_loss=0.05321]
[2020-05-12 16:34:48.307]  Step 163649  [4.337 sec/step, loss=0.09526, avg_loss=0.08918, mel_loss=0.04340, linear_loss=0.05186]
[2020-05-12 16:34:53.725]  Step 163650  [4.305 sec/step, loss=0.09593, avg_loss=0.08913, mel_loss=0.04350, linear_loss=0.05243]
[2020-05-12 16:34:53.726]  Writing summary at step: 163650
[2020-05-12 16:34:56.254]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163650
[2020-05-12 16:34:57.969]  Saving audio and alignment...
[2020-05-12 16:35:00.648]  Input: 이런 거 끝까지 한번 더~________
[2020-05-12 16:35:02.553]  Step 163651  [4.304 sec/step, loss=0.08584, avg_loss=0.08909, mel_loss=0.03724, linear_loss=0.04860]
[2020-05-12 16:35:03.565]  Step 163652  [4.280 sec/step, loss=0.08173, avg_loss=0.08895, mel_loss=0.03521, linear_loss=0.04651]
[2020-05-12 16:35:06.599]  Step 163653  [4.297 sec/step, loss=0.09281, avg_loss=0.08902, mel_loss=0.04091, linear_loss=0.05190]
[2020-05-12 16:35:07.487]  Step 163654  [4.160 sec/step, loss=0.07131, avg_loss=0.08894, mel_loss=0.03043, linear_loss=0.04088]
[2020-05-12 16:35:15.962]  Step 163655  [4.232 sec/step, loss=0.09446, avg_loss=0.08904, mel_loss=0.04350, linear_loss=0.05096]
[2020-05-12 16:35:19.103]  Step 163656  [4.238 sec/step, loss=0.09476, avg_loss=0.08909, mel_loss=0.04212, linear_loss=0.05264]
[2020-05-12 16:35:22.921]  Step 163657  [4.245 sec/step, loss=0.09265, avg_loss=0.08903, mel_loss=0.04127, linear_loss=0.05138]
[2020-05-12 16:35:25.723]  Step 163658  [4.255 sec/step, loss=0.09047, avg_loss=0.08902, mel_loss=0.03979, linear_loss=0.05068]
[2020-05-12 16:36:55.495]  Generated 32 batches of size 32 in 116.863 sec
[2020-05-12 16:36:56.106]  Step 163659  [5.151 sec/step, loss=0.06784, avg_loss=0.08899, mel_loss=0.02956, linear_loss=0.03828]
[2020-05-12 16:37:01.999]  Step 163660  [5.193 sec/step, loss=0.09894, avg_loss=0.08907, mel_loss=0.04535, linear_loss=0.05359]
[2020-05-12 16:37:05.437]  Step 163661  [5.203 sec/step, loss=0.09582, avg_loss=0.08911, mel_loss=0.04268, linear_loss=0.05313]
[2020-05-12 16:37:06.524]  Step 163662  [5.205 sec/step, loss=0.08051, avg_loss=0.08913, mel_loss=0.03433, linear_loss=0.04618]
[2020-05-12 16:37:13.434]  Step 163663  [5.232 sec/step, loss=0.09682, avg_loss=0.08914, mel_loss=0.04417, linear_loss=0.05265]
[2020-05-12 16:37:15.361]  Step 163664  [5.236 sec/step, loss=0.08848, avg_loss=0.08916, mel_loss=0.03836, linear_loss=0.05012]
[2020-05-12 16:37:16.386]  Step 163665  [5.205 sec/step, loss=0.07670, avg_loss=0.08896, mel_loss=0.03270, linear_loss=0.04400]
[2020-05-12 16:37:18.575]  Step 163666  [5.216 sec/step, loss=0.09014, avg_loss=0.08904, mel_loss=0.03936, linear_loss=0.05078]
[2020-05-12 16:37:19.345]  Step 163667  [4.503 sec/step, loss=0.07321, avg_loss=0.08892, mel_loss=0.03126, linear_loss=0.04195]
[2020-05-12 16:37:24.035]  Step 163668  [4.540 sec/step, loss=0.09385, avg_loss=0.08907, mel_loss=0.04217, linear_loss=0.05167]
[2020-05-12 16:37:28.564]  Step 163669  [4.556 sec/step, loss=0.09304, avg_loss=0.08906, mel_loss=0.04148, linear_loss=0.05155]
[2020-05-12 16:37:31.118]  Step 163670  [4.541 sec/step, loss=0.08883, avg_loss=0.08898, mel_loss=0.03881, linear_loss=0.05002]
[2020-05-12 16:37:33.622]  Step 163671  [4.538 sec/step, loss=0.08947, avg_loss=0.08894, mel_loss=0.03924, linear_loss=0.05023]
[2020-05-12 16:37:38.531]  Step 163672  [4.530 sec/step, loss=0.09433, avg_loss=0.08887, mel_loss=0.04230, linear_loss=0.05202]
[2020-05-12 16:37:40.261]  Step 163673  [4.528 sec/step, loss=0.08755, avg_loss=0.08884, mel_loss=0.03762, linear_loss=0.04993]
[2020-05-12 16:37:49.365]  Step 163674  [4.547 sec/step, loss=0.09627, avg_loss=0.08882, mel_loss=0.04471, linear_loss=0.05156]
[2020-05-12 16:37:50.576]  Step 163675  [4.526 sec/step, loss=0.08029, avg_loss=0.08865, mel_loss=0.03447, linear_loss=0.04582]
[2020-05-12 16:37:53.196]  Step 163676  [4.485 sec/step, loss=0.08921, avg_loss=0.08855, mel_loss=0.03918, linear_loss=0.05003]
[2020-05-12 16:37:58.675]  Step 163677  [4.532 sec/step, loss=0.09473, avg_loss=0.08880, mel_loss=0.04284, linear_loss=0.05190]
[2020-05-12 16:38:13.587]  Step 163678  [4.669 sec/step, loss=0.07796, avg_loss=0.08872, mel_loss=0.03678, linear_loss=0.04118]
[2020-05-12 16:38:16.626]  Step 163679  [4.683 sec/step, loss=0.09171, avg_loss=0.08877, mel_loss=0.04060, linear_loss=0.05111]
[2020-05-12 16:38:19.953]  Step 163680  [4.670 sec/step, loss=0.09457, avg_loss=0.08876, mel_loss=0.04208, linear_loss=0.05249]
[2020-05-12 16:38:22.084]  Step 163681  [4.683 sec/step, loss=0.08776, avg_loss=0.08887, mel_loss=0.03836, linear_loss=0.04940]
[2020-05-12 16:38:23.602]  Step 163682  [4.674 sec/step, loss=0.08424, avg_loss=0.08878, mel_loss=0.03625, linear_loss=0.04799]
[2020-05-12 16:38:27.444]  Step 163683  [4.699 sec/step, loss=0.09374, avg_loss=0.08885, mel_loss=0.04162, linear_loss=0.05212]
[2020-05-12 16:38:28.827]  Step 163684  [4.691 sec/step, loss=0.08273, avg_loss=0.08876, mel_loss=0.03586, linear_loss=0.04688]
[2020-05-12 16:38:30.498]  Step 163685  [4.647 sec/step, loss=0.08704, avg_loss=0.08864, mel_loss=0.03770, linear_loss=0.04934]
[2020-05-12 16:38:38.259]  Step 163686  [4.693 sec/step, loss=0.09783, avg_loss=0.08867, mel_loss=0.04482, linear_loss=0.05301]
[2020-05-12 16:38:39.312]  Step 163687  [4.689 sec/step, loss=0.07761, avg_loss=0.08860, mel_loss=0.03315, linear_loss=0.04446]
[2020-05-12 16:38:42.865]  Step 163688  [4.712 sec/step, loss=0.09258, avg_loss=0.08867, mel_loss=0.04105, linear_loss=0.05153]
[2020-05-12 16:38:44.720]  Step 163689  [4.713 sec/step, loss=0.08635, avg_loss=0.08865, mel_loss=0.03778, linear_loss=0.04858]
[2020-05-12 16:38:45.517]  Step 163690  [4.704 sec/step, loss=0.07632, avg_loss=0.08853, mel_loss=0.03225, linear_loss=0.04408]
[2020-05-12 16:40:05.995]  Generated 32 batches of size 32 in 103.905 sec
[2020-05-12 16:40:07.019]  Step 163691  [5.483 sec/step, loss=0.07886, avg_loss=0.08838, mel_loss=0.03367, linear_loss=0.04520]
[2020-05-12 16:40:12.602]  Step 163692  [5.448 sec/step, loss=0.09559, avg_loss=0.08836, mel_loss=0.04335, linear_loss=0.05224]
[2020-05-12 16:40:13.768]  Step 163693  [5.439 sec/step, loss=0.08021, avg_loss=0.08828, mel_loss=0.03386, linear_loss=0.04635]
[2020-05-12 16:40:15.456]  Step 163694  [5.446 sec/step, loss=0.08728, avg_loss=0.08836, mel_loss=0.03791, linear_loss=0.04938]
[2020-05-12 16:40:16.529]  Step 163695  [5.419 sec/step, loss=0.08094, avg_loss=0.08820, mel_loss=0.03471, linear_loss=0.04623]
[2020-05-12 16:40:17.431]  Step 163696  [5.309 sec/step, loss=0.06949, avg_loss=0.08798, mel_loss=0.02937, linear_loss=0.04011]
[2020-05-12 16:40:18.219]  Step 163697  [5.311 sec/step, loss=0.07755, avg_loss=0.08807, mel_loss=0.03258, linear_loss=0.04497]
[2020-05-12 16:40:22.729]  Step 163698  [5.309 sec/step, loss=0.09755, avg_loss=0.08807, mel_loss=0.04404, linear_loss=0.05351]
[2020-05-12 16:40:29.374]  Step 163699  [5.338 sec/step, loss=0.09442, avg_loss=0.08805, mel_loss=0.04278, linear_loss=0.05165]
[2020-05-12 16:40:31.749]  Step 163700  [5.305 sec/step, loss=0.08922, avg_loss=0.08795, mel_loss=0.03899, linear_loss=0.05023]
[2020-05-12 16:40:31.749]  Writing summary at step: 163700
[2020-05-12 16:40:33.174]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163700
[2020-05-12 16:40:34.909]  Saving audio and alignment...
[2020-05-12 16:40:38.607]  Input: 십년전 전 이금희 아나운서의 조언을~______
[2020-05-12 16:40:43.489]  Step 163701  [5.313 sec/step, loss=0.09300, avg_loss=0.08793, mel_loss=0.04160, linear_loss=0.05140]
[2020-05-12 16:40:47.039]  Step 163702  [5.319 sec/step, loss=0.09238, avg_loss=0.08792, mel_loss=0.04095, linear_loss=0.05144]
[2020-05-12 16:40:47.902]  Step 163703  [5.263 sec/step, loss=0.07949, avg_loss=0.08773, mel_loss=0.03363, linear_loss=0.04586]
[2020-05-12 16:41:02.446]  Step 163704  [5.387 sec/step, loss=0.07568, avg_loss=0.08759, mel_loss=0.03573, linear_loss=0.03995]
[2020-05-12 16:41:05.281]  Step 163705  [5.392 sec/step, loss=0.08913, avg_loss=0.08755, mel_loss=0.03932, linear_loss=0.04981]
[2020-05-12 16:41:08.932]  Step 163706  [5.411 sec/step, loss=0.09568, avg_loss=0.08762, mel_loss=0.04258, linear_loss=0.05310]
[2020-05-12 16:41:10.905]  Step 163707  [5.409 sec/step, loss=0.08631, avg_loss=0.08759, mel_loss=0.03744, linear_loss=0.04887]
[2020-05-12 16:41:12.735]  Step 163708  [5.310 sec/step, loss=0.08567, avg_loss=0.08751, mel_loss=0.03653, linear_loss=0.04914]
[2020-05-12 16:41:14.913]  Step 163709  [5.316 sec/step, loss=0.08835, avg_loss=0.08752, mel_loss=0.03851, linear_loss=0.04984]
[2020-05-12 16:41:18.165]  Step 163710  [5.328 sec/step, loss=0.09250, avg_loss=0.08755, mel_loss=0.04081, linear_loss=0.05168]
[2020-05-12 16:41:27.042]  Step 163711  [5.408 sec/step, loss=0.09503, avg_loss=0.08774, mel_loss=0.04345, linear_loss=0.05158]
[2020-05-12 16:41:30.047]  Step 163712  [5.428 sec/step, loss=0.09179, avg_loss=0.08787, mel_loss=0.04047, linear_loss=0.05132]
[2020-05-12 16:41:33.521]  Step 163713  [5.370 sec/step, loss=0.09349, avg_loss=0.08785, mel_loss=0.04144, linear_loss=0.05205]
[2020-05-12 16:41:37.812]  Step 163714  [5.337 sec/step, loss=0.09345, avg_loss=0.08779, mel_loss=0.04174, linear_loss=0.05171]
[2020-05-12 16:41:39.062]  Step 163715  [5.314 sec/step, loss=0.08102, avg_loss=0.08765, mel_loss=0.03460, linear_loss=0.04642]
[2020-05-12 16:41:39.625]  Step 163716  [5.267 sec/step, loss=0.06601, avg_loss=0.08735, mel_loss=0.02815, linear_loss=0.03787]
[2020-05-12 16:41:42.345]  Step 163717  [5.288 sec/step, loss=0.08857, avg_loss=0.08756, mel_loss=0.03883, linear_loss=0.04973]
[2020-05-12 16:41:43.979]  Step 163718  [5.291 sec/step, loss=0.08307, avg_loss=0.08758, mel_loss=0.03582, linear_loss=0.04725]
[2020-05-12 16:41:51.602]  Step 163719  [5.341 sec/step, loss=0.09647, avg_loss=0.08765, mel_loss=0.04426, linear_loss=0.05221]
[2020-05-12 16:41:52.967]  Step 163720  [5.328 sec/step, loss=0.08257, avg_loss=0.08755, mel_loss=0.03515, linear_loss=0.04742]
[2020-05-12 16:43:09.620]  Generated 32 batches of size 32 in 102.573 sec
[2020-05-12 16:43:10.466]  Step 163721  [6.070 sec/step, loss=0.07553, avg_loss=0.08735, mel_loss=0.03205, linear_loss=0.04348]
[2020-05-12 16:43:11.035]  Step 163722  [6.059 sec/step, loss=0.06968, avg_loss=0.08717, mel_loss=0.03046, linear_loss=0.03922]
[2020-05-12 16:43:12.842]  Step 163723  [6.030 sec/step, loss=0.08683, avg_loss=0.08707, mel_loss=0.03802, linear_loss=0.04881]
[2020-05-12 16:43:13.862]  Step 163724  [6.030 sec/step, loss=0.07664, avg_loss=0.08707, mel_loss=0.03264, linear_loss=0.04400]
[2020-05-12 16:43:15.448]  Step 163725  [6.032 sec/step, loss=0.08665, avg_loss=0.08707, mel_loss=0.03725, linear_loss=0.04940]
[2020-05-12 16:43:16.601]  Step 163726  [6.007 sec/step, loss=0.07872, avg_loss=0.08693, mel_loss=0.03343, linear_loss=0.04529]
[2020-05-12 16:43:17.392]  Step 163727  [6.003 sec/step, loss=0.06968, avg_loss=0.08683, mel_loss=0.02987, linear_loss=0.03982]
[2020-05-12 16:43:19.805]  Step 163728  [6.009 sec/step, loss=0.08997, avg_loss=0.08685, mel_loss=0.03928, linear_loss=0.05069]
[2020-05-12 16:43:22.448]  Step 163729  [5.701 sec/step, loss=0.09019, avg_loss=0.08681, mel_loss=0.03963, linear_loss=0.05056]
[2020-05-12 16:43:23.927]  Step 163730  [5.687 sec/step, loss=0.08323, avg_loss=0.08673, mel_loss=0.03580, linear_loss=0.04743]
[2020-05-12 16:43:26.166]  Step 163731  [5.692 sec/step, loss=0.08855, avg_loss=0.08677, mel_loss=0.03876, linear_loss=0.04980]
[2020-05-12 16:43:28.212]  Step 163732  [5.690 sec/step, loss=0.08787, avg_loss=0.08676, mel_loss=0.03814, linear_loss=0.04973]
[2020-05-12 16:43:29.935]  Step 163733  [5.694 sec/step, loss=0.08612, avg_loss=0.08681, mel_loss=0.03735, linear_loss=0.04878]
[2020-05-12 16:43:34.615]  Step 163734  [5.733 sec/step, loss=0.09524, avg_loss=0.08699, mel_loss=0.04245, linear_loss=0.05279]
[2020-05-12 16:43:37.102]  Step 163735  [5.752 sec/step, loss=0.08947, avg_loss=0.08720, mel_loss=0.03888, linear_loss=0.05059]
[2020-05-12 16:43:38.427]  Step 163736  [5.751 sec/step, loss=0.07994, avg_loss=0.08716, mel_loss=0.03448, linear_loss=0.04545]
[2020-05-12 16:43:42.562]  Step 163737  [5.783 sec/step, loss=0.09307, avg_loss=0.08728, mel_loss=0.04142, linear_loss=0.05165]
[2020-05-12 16:43:45.966]  Step 163738  [5.761 sec/step, loss=0.09351, avg_loss=0.08725, mel_loss=0.04166, linear_loss=0.05185]
[2020-05-12 16:43:47.901]  Step 163739  [5.760 sec/step, loss=0.08849, avg_loss=0.08724, mel_loss=0.03824, linear_loss=0.05026]
[2020-05-12 16:44:00.625]  Step 163740  [5.865 sec/step, loss=0.08484, avg_loss=0.08721, mel_loss=0.03979, linear_loss=0.04505]
[2020-05-12 16:44:07.430]  Step 163741  [5.918 sec/step, loss=0.09555, avg_loss=0.08732, mel_loss=0.04357, linear_loss=0.05198]
[2020-05-12 16:44:10.579]  Step 163742  [5.938 sec/step, loss=0.09346, avg_loss=0.08746, mel_loss=0.04155, linear_loss=0.05192]
[2020-05-12 16:44:11.595]  Step 163743  [5.907 sec/step, loss=0.07822, avg_loss=0.08727, mel_loss=0.03300, linear_loss=0.04522]
[2020-05-12 16:44:18.799]  Step 163744  [5.936 sec/step, loss=0.09686, avg_loss=0.08728, mel_loss=0.04406, linear_loss=0.05281]
[2020-05-12 16:44:24.556]  Step 163745  [5.956 sec/step, loss=0.09586, avg_loss=0.08728, mel_loss=0.04355, linear_loss=0.05231]
[2020-05-12 16:44:28.201]  Step 163746  [5.847 sec/step, loss=0.09298, avg_loss=0.08746, mel_loss=0.04132, linear_loss=0.05166]
[2020-05-12 16:44:37.201]  Step 163747  [5.862 sec/step, loss=0.09490, avg_loss=0.08742, mel_loss=0.04367, linear_loss=0.05124]
[2020-05-12 16:44:41.696]  Step 163748  [5.859 sec/step, loss=0.09470, avg_loss=0.08739, mel_loss=0.04254, linear_loss=0.05216]
[2020-05-12 16:44:43.105]  Step 163749  [5.810 sec/step, loss=0.08430, avg_loss=0.08728, mel_loss=0.03647, linear_loss=0.04783]
[2020-05-12 16:44:46.878]  Step 163750  [5.793 sec/step, loss=0.09485, avg_loss=0.08727, mel_loss=0.04216, linear_loss=0.05269]
[2020-05-12 16:44:46.878]  Writing summary at step: 163750
[2020-05-12 16:44:52.378]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163750
[2020-05-12 16:44:54.162]  Saving audio and alignment...
[2020-05-12 16:44:58.913]  Input: 내 아이디어를 내고 좀 적극적으로 참여~_______________________
[2020-05-12 16:45:43.843]  Generated 32 batches of size 32 in 92.242 sec
[2020-05-12 16:45:45.715]  Step 163751  [6.242 sec/step, loss=0.08591, avg_loss=0.08727, mel_loss=0.03695, linear_loss=0.04896]
[2020-05-12 16:45:47.652]  Step 163752  [6.252 sec/step, loss=0.08851, avg_loss=0.08734, mel_loss=0.03816, linear_loss=0.05034]
[2020-05-12 16:45:48.496]  Step 163753  [6.230 sec/step, loss=0.07369, avg_loss=0.08715, mel_loss=0.03123, linear_loss=0.04246]
[2020-05-12 16:45:50.676]  Step 163754  [6.243 sec/step, loss=0.08988, avg_loss=0.08733, mel_loss=0.03946, linear_loss=0.05042]
[2020-05-12 16:45:51.257]  Step 163755  [6.164 sec/step, loss=0.06685, avg_loss=0.08706, mel_loss=0.02876, linear_loss=0.03808]
[2020-05-12 16:45:52.982]  Step 163756  [6.150 sec/step, loss=0.08493, avg_loss=0.08696, mel_loss=0.03663, linear_loss=0.04830]
[2020-05-12 16:45:57.612]  Step 163757  [6.158 sec/step, loss=0.09489, avg_loss=0.08698, mel_loss=0.04257, linear_loss=0.05233]
[2020-05-12 16:46:00.258]  Step 163758  [6.156 sec/step, loss=0.09085, avg_loss=0.08699, mel_loss=0.04016, linear_loss=0.05070]
[2020-05-12 16:46:03.159]  Step 163759  [5.281 sec/step, loss=0.09217, avg_loss=0.08723, mel_loss=0.04037, linear_loss=0.05180]
[2020-05-12 16:46:17.807]  Step 163760  [5.369 sec/step, loss=0.07487, avg_loss=0.08699, mel_loss=0.03539, linear_loss=0.03947]
[2020-05-12 16:46:26.661]  Step 163761  [5.423 sec/step, loss=0.09238, avg_loss=0.08695, mel_loss=0.04223, linear_loss=0.05015]
[2020-05-12 16:46:30.107]  Step 163762  [5.447 sec/step, loss=0.09384, avg_loss=0.08709, mel_loss=0.04157, linear_loss=0.05228]
[2020-05-12 16:46:33.285]  Step 163763  [5.409 sec/step, loss=0.09416, avg_loss=0.08706, mel_loss=0.04157, linear_loss=0.05259]
[2020-05-12 16:46:40.592]  Step 163764  [5.463 sec/step, loss=0.09868, avg_loss=0.08716, mel_loss=0.04500, linear_loss=0.05368]
[2020-05-12 16:46:45.881]  Step 163765  [5.506 sec/step, loss=0.09436, avg_loss=0.08734, mel_loss=0.04264, linear_loss=0.05172]
[2020-05-12 16:46:46.800]  Step 163766  [5.493 sec/step, loss=0.07498, avg_loss=0.08719, mel_loss=0.03173, linear_loss=0.04325]
[2020-05-12 16:46:52.446]  Step 163767  [5.542 sec/step, loss=0.09609, avg_loss=0.08742, mel_loss=0.04341, linear_loss=0.05267]
[2020-05-12 16:46:54.086]  Step 163768  [5.511 sec/step, loss=0.08311, avg_loss=0.08731, mel_loss=0.03594, linear_loss=0.04717]
[2020-05-12 16:46:57.531]  Step 163769  [5.500 sec/step, loss=0.09169, avg_loss=0.08730, mel_loss=0.04081, linear_loss=0.05089]
[2020-05-12 16:46:58.930]  Step 163770  [5.489 sec/step, loss=0.08412, avg_loss=0.08725, mel_loss=0.03630, linear_loss=0.04782]
[2020-05-12 16:47:00.075]  Step 163771  [5.475 sec/step, loss=0.08180, avg_loss=0.08717, mel_loss=0.03504, linear_loss=0.04676]
[2020-05-12 16:47:06.706]  Step 163772  [5.493 sec/step, loss=0.09601, avg_loss=0.08719, mel_loss=0.04381, linear_loss=0.05220]
[2020-05-12 16:47:10.837]  Step 163773  [5.517 sec/step, loss=0.09341, avg_loss=0.08725, mel_loss=0.04129, linear_loss=0.05212]
[2020-05-12 16:47:11.967]  Step 163774  [5.437 sec/step, loss=0.08114, avg_loss=0.08710, mel_loss=0.03403, linear_loss=0.04711]
[2020-05-12 16:47:16.393]  Step 163775  [5.469 sec/step, loss=0.09329, avg_loss=0.08723, mel_loss=0.04156, linear_loss=0.05173]
[2020-05-12 16:47:18.444]  Step 163776  [5.463 sec/step, loss=0.08681, avg_loss=0.08720, mel_loss=0.03775, linear_loss=0.04906]
[2020-05-12 16:47:20.741]  Step 163777  [5.431 sec/step, loss=0.08712, avg_loss=0.08713, mel_loss=0.03825, linear_loss=0.04887]
[2020-05-12 16:47:21.705]  Step 163778  [5.292 sec/step, loss=0.07792, avg_loss=0.08713, mel_loss=0.03334, linear_loss=0.04457]
[2020-05-12 16:47:23.067]  Step 163779  [5.275 sec/step, loss=0.08168, avg_loss=0.08703, mel_loss=0.03492, linear_loss=0.04676]
[2020-05-12 16:47:23.834]  Step 163780  [5.250 sec/step, loss=0.07667, avg_loss=0.08685, mel_loss=0.03218, linear_loss=0.04449]
[2020-05-12 16:47:26.351]  Step 163781  [5.253 sec/step, loss=0.09034, avg_loss=0.08687, mel_loss=0.03921, linear_loss=0.05113]
[2020-05-12 16:47:30.011]  Step 163782  [5.275 sec/step, loss=0.09467, avg_loss=0.08698, mel_loss=0.04202, linear_loss=0.05265]
[2020-05-12 16:48:51.194]  Generated 32 batches of size 32 in 100.352 sec
[2020-05-12 16:48:53.936]  Step 163783  [6.076 sec/step, loss=0.08777, avg_loss=0.08692, mel_loss=0.03842, linear_loss=0.04935]
[2020-05-12 16:48:55.155]  Step 163784  [6.074 sec/step, loss=0.08061, avg_loss=0.08690, mel_loss=0.03455, linear_loss=0.04606]
[2020-05-12 16:48:55.715]  Step 163785  [6.063 sec/step, loss=0.06842, avg_loss=0.08671, mel_loss=0.03014, linear_loss=0.03828]
[2020-05-12 16:49:03.164]  Step 163786  [6.060 sec/step, loss=0.09661, avg_loss=0.08670, mel_loss=0.04414, linear_loss=0.05247]
[2020-05-12 16:49:04.219]  Step 163787  [6.060 sec/step, loss=0.07719, avg_loss=0.08669, mel_loss=0.03274, linear_loss=0.04445]
[2020-05-12 16:49:06.428]  Step 163788  [6.046 sec/step, loss=0.08830, avg_loss=0.08665, mel_loss=0.03831, linear_loss=0.05000]
[2020-05-12 16:49:07.805]  Step 163789  [6.042 sec/step, loss=0.08227, avg_loss=0.08661, mel_loss=0.03528, linear_loss=0.04699]
[2020-05-12 16:49:08.488]  Step 163790  [6.041 sec/step, loss=0.06867, avg_loss=0.08653, mel_loss=0.02921, linear_loss=0.03945]
[2020-05-12 16:49:11.954]  Step 163791  [5.260 sec/step, loss=0.09010, avg_loss=0.08665, mel_loss=0.03995, linear_loss=0.05015]
[2020-05-12 16:49:17.093]  Step 163792  [5.256 sec/step, loss=0.09301, avg_loss=0.08662, mel_loss=0.04178, linear_loss=0.05122]
[2020-05-12 16:49:19.901]  Step 163793  [5.272 sec/step, loss=0.08994, avg_loss=0.08672, mel_loss=0.03974, linear_loss=0.05021]
[2020-05-12 16:49:25.537]  Step 163794  [5.312 sec/step, loss=0.10111, avg_loss=0.08686, mel_loss=0.04702, linear_loss=0.05410]
[2020-05-12 16:49:37.702]  Step 163795  [5.423 sec/step, loss=0.09949, avg_loss=0.08704, mel_loss=0.04898, linear_loss=0.05051]
[2020-05-12 16:49:41.428]  Step 163796  [5.451 sec/step, loss=0.10133, avg_loss=0.08736, mel_loss=0.04635, linear_loss=0.05498]
[2020-05-12 16:49:43.417]  Step 163797  [5.463 sec/step, loss=0.08942, avg_loss=0.08748, mel_loss=0.03951, linear_loss=0.04990]
[2020-05-12 16:49:44.715]  Step 163798  [5.431 sec/step, loss=0.08843, avg_loss=0.08739, mel_loss=0.03882, linear_loss=0.04960]
[2020-05-12 16:49:46.180]  Step 163799  [5.379 sec/step, loss=0.08460, avg_loss=0.08729, mel_loss=0.03668, linear_loss=0.04792]
[2020-05-12 16:49:49.694]  Step 163800  [5.390 sec/step, loss=0.09622, avg_loss=0.08736, mel_loss=0.04291, linear_loss=0.05331]
[2020-05-12 16:49:49.694]  Writing summary at step: 163800
[2020-05-12 16:49:58.495]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163800
[2020-05-12 16:50:00.174]  Saving audio and alignment...
[2020-05-12 16:50:03.217]  Input: 제가 약속 드립니다~____________________
[2020-05-12 16:50:04.818]  Step 163801  [5.357 sec/step, loss=0.08793, avg_loss=0.08731, mel_loss=0.03834, linear_loss=0.04959]
[2020-05-12 16:50:09.338]  Step 163802  [5.367 sec/step, loss=0.09760, avg_loss=0.08736, mel_loss=0.04411, linear_loss=0.05349]
[2020-05-12 16:50:10.127]  Step 163803  [5.366 sec/step, loss=0.07634, avg_loss=0.08733, mel_loss=0.03255, linear_loss=0.04379]
[2020-05-12 16:50:14.205]  Step 163804  [5.262 sec/step, loss=0.09574, avg_loss=0.08753, mel_loss=0.04319, linear_loss=0.05255]
[2020-05-12 16:50:16.342]  Step 163805  [5.255 sec/step, loss=0.08961, avg_loss=0.08753, mel_loss=0.03914, linear_loss=0.05048]
[2020-05-12 16:50:18.782]  Step 163806  [5.243 sec/step, loss=0.09142, avg_loss=0.08749, mel_loss=0.04017, linear_loss=0.05125]
[2020-05-12 16:50:19.880]  Step 163807  [5.234 sec/step, loss=0.08109, avg_loss=0.08744, mel_loss=0.03476, linear_loss=0.04634]
[2020-05-12 16:50:21.701]  Step 163808  [5.234 sec/step, loss=0.08602, avg_loss=0.08744, mel_loss=0.03745, linear_loss=0.04857]
[2020-05-12 16:50:24.823]  Step 163809  [5.243 sec/step, loss=0.09700, avg_loss=0.08753, mel_loss=0.04335, linear_loss=0.05366]
[2020-05-12 16:50:31.285]  Step 163810  [5.275 sec/step, loss=0.10219, avg_loss=0.08763, mel_loss=0.04795, linear_loss=0.05424]
[2020-05-12 16:50:32.289]  Step 163811  [5.197 sec/step, loss=0.07788, avg_loss=0.08746, mel_loss=0.03305, linear_loss=0.04483]
[2020-05-12 16:50:35.269]  Step 163812  [5.196 sec/step, loss=0.09306, avg_loss=0.08747, mel_loss=0.04127, linear_loss=0.05179]
[2020-05-12 16:50:42.978]  Generated 32 batches of size 32 in 32.846 sec
[2020-05-12 16:50:44.472]  Step 163813  [5.254 sec/step, loss=0.08276, avg_loss=0.08736, mel_loss=0.03577, linear_loss=0.04700]
[2020-05-12 16:50:45.273]  Step 163814  [5.219 sec/step, loss=0.07560, avg_loss=0.08718, mel_loss=0.03214, linear_loss=0.04346]
[2020-05-12 16:50:50.865]  Step 163815  [5.262 sec/step, loss=0.09928, avg_loss=0.08736, mel_loss=0.04565, linear_loss=0.05362]
[2020-05-12 16:50:52.794]  Step 163816  [5.276 sec/step, loss=0.08875, avg_loss=0.08759, mel_loss=0.03872, linear_loss=0.05003]
[2020-05-12 16:50:57.398]  Step 163817  [5.295 sec/step, loss=0.09681, avg_loss=0.08767, mel_loss=0.04351, linear_loss=0.05330]
[2020-05-12 16:51:00.723]  Step 163818  [5.312 sec/step, loss=0.09290, avg_loss=0.08777, mel_loss=0.04121, linear_loss=0.05168]
[2020-05-12 16:51:02.459]  Step 163819  [5.253 sec/step, loss=0.08711, avg_loss=0.08768, mel_loss=0.03762, linear_loss=0.04949]
[2020-05-12 16:51:03.203]  Step 163820  [5.247 sec/step, loss=0.06838, avg_loss=0.08754, mel_loss=0.02915, linear_loss=0.03922]
[2020-05-12 16:51:08.350]  Step 163821  [4.523 sec/step, loss=0.09550, avg_loss=0.08774, mel_loss=0.04328, linear_loss=0.05222]
[2020-05-12 16:51:10.975]  Step 163822  [4.544 sec/step, loss=0.08839, avg_loss=0.08792, mel_loss=0.03853, linear_loss=0.04986]
[2020-05-12 16:51:12.304]  Step 163823  [4.539 sec/step, loss=0.08588, avg_loss=0.08791, mel_loss=0.03697, linear_loss=0.04892]
[2020-05-12 16:51:14.004]  Step 163824  [4.546 sec/step, loss=0.08749, avg_loss=0.08802, mel_loss=0.03792, linear_loss=0.04957]
[2020-05-12 16:51:16.935]  Step 163825  [4.559 sec/step, loss=0.09406, avg_loss=0.08810, mel_loss=0.04166, linear_loss=0.05239]
[2020-05-12 16:51:18.544]  Step 163826  [4.564 sec/step, loss=0.08734, avg_loss=0.08818, mel_loss=0.03779, linear_loss=0.04955]
[2020-05-12 16:51:22.911]  Step 163827  [4.599 sec/step, loss=0.09652, avg_loss=0.08845, mel_loss=0.04356, linear_loss=0.05296]
[2020-05-12 16:51:31.206]  Step 163828  [4.658 sec/step, loss=0.09582, avg_loss=0.08851, mel_loss=0.04405, linear_loss=0.05177]
[2020-05-12 16:51:33.233]  Step 163829  [4.652 sec/step, loss=0.09054, avg_loss=0.08851, mel_loss=0.03961, linear_loss=0.05093]
[2020-05-12 16:51:35.440]  Step 163830  [4.659 sec/step, loss=0.08859, avg_loss=0.08857, mel_loss=0.03859, linear_loss=0.04999]
[2020-05-12 16:51:39.593]  Step 163831  [4.678 sec/step, loss=0.09712, avg_loss=0.08865, mel_loss=0.04369, linear_loss=0.05343]
[2020-05-12 16:51:42.244]  Step 163832  [4.684 sec/step, loss=0.09044, avg_loss=0.08868, mel_loss=0.03990, linear_loss=0.05054]
[2020-05-12 16:51:43.124]  Step 163833  [4.676 sec/step, loss=0.07725, avg_loss=0.08859, mel_loss=0.03256, linear_loss=0.04469]
[2020-05-12 16:51:45.509]  Step 163834  [4.653 sec/step, loss=0.08993, avg_loss=0.08854, mel_loss=0.03959, linear_loss=0.05034]
[2020-05-12 16:51:46.523]  Step 163835  [4.638 sec/step, loss=0.07941, avg_loss=0.08844, mel_loss=0.03402, linear_loss=0.04539]
[2020-05-12 16:51:50.093]  Step 163836  [4.661 sec/step, loss=0.09567, avg_loss=0.08859, mel_loss=0.04273, linear_loss=0.05294]
[2020-05-12 16:51:53.470]  Step 163837  [4.653 sec/step, loss=0.09370, avg_loss=0.08860, mel_loss=0.04215, linear_loss=0.05155]
[2020-05-12 16:52:00.209]  Step 163838  [4.687 sec/step, loss=0.09664, avg_loss=0.08863, mel_loss=0.04414, linear_loss=0.05250]
[2020-05-12 16:52:02.013]  Generated 32 batches of size 32 in 15.486 sec
[2020-05-12 16:52:12.875]  Step 163839  [4.794 sec/step, loss=0.09007, avg_loss=0.08865, mel_loss=0.04318, linear_loss=0.04690]
[2020-05-12 16:52:14.147]  Step 163840  [4.679 sec/step, loss=0.08056, avg_loss=0.08860, mel_loss=0.03469, linear_loss=0.04587]
[2020-05-12 16:52:21.752]  Step 163841  [4.687 sec/step, loss=0.09795, avg_loss=0.08863, mel_loss=0.04500, linear_loss=0.05295]
[2020-05-12 16:52:22.547]  Step 163842  [4.664 sec/step, loss=0.07162, avg_loss=0.08841, mel_loss=0.03069, linear_loss=0.04093]
[2020-05-12 16:52:26.270]  Step 163843  [4.691 sec/step, loss=0.09605, avg_loss=0.08859, mel_loss=0.04295, linear_loss=0.05310]
[2020-05-12 16:52:27.391]  Step 163844  [4.630 sec/step, loss=0.08272, avg_loss=0.08845, mel_loss=0.03520, linear_loss=0.04752]
[2020-05-12 16:52:29.197]  Step 163845  [4.591 sec/step, loss=0.08636, avg_loss=0.08835, mel_loss=0.03733, linear_loss=0.04903]
[2020-05-12 16:52:34.819]  Step 163846  [4.610 sec/step, loss=0.09549, avg_loss=0.08838, mel_loss=0.04331, linear_loss=0.05218]
[2020-05-12 16:52:36.143]  Step 163847  [4.534 sec/step, loss=0.08289, avg_loss=0.08826, mel_loss=0.03559, linear_loss=0.04730]
[2020-05-12 16:52:38.663]  Step 163848  [4.514 sec/step, loss=0.09017, avg_loss=0.08821, mel_loss=0.03955, linear_loss=0.05062]
[2020-05-12 16:52:44.787]  Step 163849  [4.561 sec/step, loss=0.09618, avg_loss=0.08833, mel_loss=0.04374, linear_loss=0.05244]
[2020-05-12 16:52:47.004]  Step 163850  [4.545 sec/step, loss=0.08802, avg_loss=0.08826, mel_loss=0.03853, linear_loss=0.04949]
[2020-05-12 16:52:47.004]  Writing summary at step: 163850
[2020-05-12 16:52:48.070]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163850
[2020-05-12 16:52:49.764]  Saving audio and alignment...
[2020-05-12 16:52:55.522]  Input: 안녕하세요 하루만에 목소리가 좋아지는 책의 저자이자~___________________
[2020-05-12 16:52:56.358]  Step 163851  [4.086 sec/step, loss=0.07178, avg_loss=0.08812, mel_loss=0.03097, linear_loss=0.04081]
[2020-05-12 16:52:56.937]  Step 163852  [4.072 sec/step, loss=0.07106, avg_loss=0.08795, mel_loss=0.03062, linear_loss=0.04044]
[2020-05-12 16:53:00.029]  Step 163853  [4.095 sec/step, loss=0.09347, avg_loss=0.08814, mel_loss=0.04152, linear_loss=0.05195]
[2020-05-12 16:53:08.796]  Step 163854  [4.161 sec/step, loss=0.09300, avg_loss=0.08818, mel_loss=0.04301, linear_loss=0.04999]
[2020-05-12 16:53:11.463]  Step 163855  [4.181 sec/step, loss=0.09055, avg_loss=0.08841, mel_loss=0.03985, linear_loss=0.05071]
[2020-05-12 16:53:12.467]  Step 163856  [4.174 sec/step, loss=0.07780, avg_loss=0.08834, mel_loss=0.03318, linear_loss=0.04462]
[2020-05-12 16:53:13.610]  Step 163857  [4.139 sec/step, loss=0.08013, avg_loss=0.08819, mel_loss=0.03424, linear_loss=0.04589]
[2020-05-12 16:53:15.286]  Step 163858  [4.130 sec/step, loss=0.08467, avg_loss=0.08813, mel_loss=0.03674, linear_loss=0.04793]
[2020-05-12 16:53:19.125]  Step 163859  [4.139 sec/step, loss=0.09244, avg_loss=0.08813, mel_loss=0.04108, linear_loss=0.05136]
[2020-05-12 16:53:25.882]  Step 163860  [4.060 sec/step, loss=0.09853, avg_loss=0.08837, mel_loss=0.04521, linear_loss=0.05332]
[2020-05-12 16:53:26.675]  Step 163861  [3.979 sec/step, loss=0.07785, avg_loss=0.08823, mel_loss=0.03301, linear_loss=0.04484]
[2020-05-12 16:53:28.717]  Step 163862  [3.965 sec/step, loss=0.08728, avg_loss=0.08816, mel_loss=0.03778, linear_loss=0.04950]
[2020-05-12 16:53:30.057]  Step 163863  [3.947 sec/step, loss=0.08574, avg_loss=0.08808, mel_loss=0.03707, linear_loss=0.04867]
[2020-05-12 16:53:35.299]  Step 163864  [3.926 sec/step, loss=0.09587, avg_loss=0.08805, mel_loss=0.04325, linear_loss=0.05263]
[2020-05-12 16:53:39.902]  Step 163865  [3.920 sec/step, loss=0.09491, avg_loss=0.08805, mel_loss=0.04258, linear_loss=0.05233]
[2020-05-12 16:53:44.031]  Step 163866  [3.952 sec/step, loss=0.09380, avg_loss=0.08824, mel_loss=0.04195, linear_loss=0.05184]
[2020-05-12 16:53:46.354]  Step 163867  [3.918 sec/step, loss=0.08915, avg_loss=0.08817, mel_loss=0.03899, linear_loss=0.05016]
[2020-05-12 16:53:49.620]  Step 163868  [3.935 sec/step, loss=0.09361, avg_loss=0.08828, mel_loss=0.04154, linear_loss=0.05207]
[2020-05-12 16:53:50.568]  Step 163869  [3.910 sec/step, loss=0.07992, avg_loss=0.08816, mel_loss=0.03390, linear_loss=0.04602]
[2020-05-12 16:53:52.480]  Step 163870  [3.915 sec/step, loss=0.08824, avg_loss=0.08820, mel_loss=0.03819, linear_loss=0.05005]
[2020-05-12 16:53:55.586]  Step 163871  [3.934 sec/step, loss=0.09571, avg_loss=0.08834, mel_loss=0.04266, linear_loss=0.05305]
[2020-05-12 16:53:57.116]  Step 163872  [3.883 sec/step, loss=0.08458, avg_loss=0.08823, mel_loss=0.03666, linear_loss=0.04793]
[2020-05-12 16:54:00.606]  Step 163873  [3.877 sec/step, loss=0.09301, avg_loss=0.08822, mel_loss=0.04170, linear_loss=0.05132]
[2020-05-12 16:54:14.936]  Step 163874  [4.009 sec/step, loss=0.07514, avg_loss=0.08816, mel_loss=0.03560, linear_loss=0.03954]
[2020-05-12 16:54:54.820]  Generated 32 batches of size 32 in 74.913 sec
[2020-05-12 16:54:57.314]  Step 163875  [4.389 sec/step, loss=0.08914, avg_loss=0.08812, mel_loss=0.03883, linear_loss=0.05031]
[2020-05-12 16:55:00.930]  Step 163876  [4.404 sec/step, loss=0.09490, avg_loss=0.08820, mel_loss=0.04205, linear_loss=0.05285]
[2020-05-12 16:55:03.754]  Step 163877  [4.409 sec/step, loss=0.09130, avg_loss=0.08824, mel_loss=0.04023, linear_loss=0.05107]
[2020-05-12 16:55:12.514]  Step 163878  [4.487 sec/step, loss=0.09655, avg_loss=0.08843, mel_loss=0.04439, linear_loss=0.05216]
[2020-05-12 16:55:15.889]  Step 163879  [4.508 sec/step, loss=0.09162, avg_loss=0.08853, mel_loss=0.04062, linear_loss=0.05100]
[2020-05-12 16:55:17.242]  Step 163880  [4.513 sec/step, loss=0.08050, avg_loss=0.08857, mel_loss=0.03463, linear_loss=0.04587]
[2020-05-12 16:55:19.969]  Step 163881  [4.516 sec/step, loss=0.08956, avg_loss=0.08856, mel_loss=0.03927, linear_loss=0.05028]
[2020-05-12 16:55:20.727]  Step 163882  [4.486 sec/step, loss=0.06951, avg_loss=0.08831, mel_loss=0.02967, linear_loss=0.03983]
[2020-05-12 16:55:27.529]  Step 163883  [3.715 sec/step, loss=0.09338, avg_loss=0.08836, mel_loss=0.04244, linear_loss=0.05094]
[2020-05-12 16:55:31.574]  Step 163884  [3.744 sec/step, loss=0.09521, avg_loss=0.08851, mel_loss=0.04223, linear_loss=0.05298]
[2020-05-12 16:55:33.169]  Step 163885  [3.754 sec/step, loss=0.08540, avg_loss=0.08868, mel_loss=0.03684, linear_loss=0.04856]
[2020-05-12 16:55:35.038]  Step 163886  [3.698 sec/step, loss=0.08460, avg_loss=0.08856, mel_loss=0.03658, linear_loss=0.04802]
[2020-05-12 16:55:42.740]  Step 163887  [3.765 sec/step, loss=0.09573, avg_loss=0.08874, mel_loss=0.04372, linear_loss=0.05200]
[2020-05-12 16:55:45.230]  Step 163888  [3.767 sec/step, loss=0.08815, avg_loss=0.08874, mel_loss=0.03847, linear_loss=0.04968]
[2020-05-12 16:55:46.952]  Step 163889  [3.771 sec/step, loss=0.08746, avg_loss=0.08879, mel_loss=0.03781, linear_loss=0.04965]
[2020-05-12 16:55:48.001]  Step 163890  [3.774 sec/step, loss=0.07757, avg_loss=0.08888, mel_loss=0.03279, linear_loss=0.04478]
[2020-05-12 16:55:49.986]  Step 163891  [3.760 sec/step, loss=0.08946, avg_loss=0.08888, mel_loss=0.03913, linear_loss=0.05033]
[2020-05-12 16:56:03.294]  Step 163892  [3.841 sec/step, loss=0.08231, avg_loss=0.08877, mel_loss=0.03851, linear_loss=0.04380]
[2020-05-12 16:56:04.101]  Step 163893  [3.821 sec/step, loss=0.07530, avg_loss=0.08862, mel_loss=0.03178, linear_loss=0.04352]
[2020-05-12 16:56:07.270]  Step 163894  [3.797 sec/step, loss=0.09081, avg_loss=0.08852, mel_loss=0.03993, linear_loss=0.05088]
[2020-05-12 16:56:08.031]  Step 163895  [3.683 sec/step, loss=0.06841, avg_loss=0.08821, mel_loss=0.02948, linear_loss=0.03893]
[2020-05-12 16:56:10.182]  Step 163896  [3.667 sec/step, loss=0.08835, avg_loss=0.08808, mel_loss=0.03839, linear_loss=0.04996]
[2020-05-12 16:56:13.604]  Step 163897  [3.681 sec/step, loss=0.09329, avg_loss=0.08812, mel_loss=0.04120, linear_loss=0.05210]
[2020-05-12 16:56:15.342]  Step 163898  [3.686 sec/step, loss=0.08700, avg_loss=0.08810, mel_loss=0.03748, linear_loss=0.04952]
[2020-05-12 16:56:16.391]  Step 163899  [3.681 sec/step, loss=0.07718, avg_loss=0.08803, mel_loss=0.03301, linear_loss=0.04417]
[2020-05-12 16:56:17.515]  Step 163900  [3.658 sec/step, loss=0.08220, avg_loss=0.08789, mel_loss=0.03460, linear_loss=0.04760]
[2020-05-12 16:56:17.515]  Writing summary at step: 163900
[2020-05-12 16:56:18.965]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163900
[2020-05-12 16:56:20.669]  Saving audio and alignment...
[2020-05-12 16:56:27.253]  Input: 사랑은 쟁취하기 더 어렵지만 지켜가기는 더 어렵다는 생각을~_________________________
[2020-05-12 16:56:32.972]  Step 163901  [3.699 sec/step, loss=0.09366, avg_loss=0.08795, mel_loss=0.04192, linear_loss=0.05175]
[2020-05-12 16:56:34.198]  Step 163902  [3.666 sec/step, loss=0.08337, avg_loss=0.08780, mel_loss=0.03561, linear_loss=0.04776]
[2020-05-12 16:56:39.373]  Step 163903  [3.710 sec/step, loss=0.09383, avg_loss=0.08798, mel_loss=0.04217, linear_loss=0.05166]
[2020-05-12 16:56:43.976]  Step 163904  [3.715 sec/step, loss=0.09593, avg_loss=0.08798, mel_loss=0.04317, linear_loss=0.05276]
[2020-05-12 16:56:56.267]  Generated 32 batches of size 32 in 42.657 sec
[2020-05-12 16:56:57.568]  Step 163905  [3.829 sec/step, loss=0.08260, avg_loss=0.08791, mel_loss=0.03522, linear_loss=0.04739]
[2020-05-12 16:57:01.853]  Step 163906  [3.848 sec/step, loss=0.09328, avg_loss=0.08793, mel_loss=0.04172, linear_loss=0.05157]
[2020-05-12 16:57:15.841]  Step 163907  [3.977 sec/step, loss=0.07653, avg_loss=0.08788, mel_loss=0.03628, linear_loss=0.04025]
[2020-05-12 16:57:18.019]  Step 163908  [3.980 sec/step, loss=0.08819, avg_loss=0.08791, mel_loss=0.03828, linear_loss=0.04991]
[2020-05-12 16:57:21.505]  Step 163909  [3.984 sec/step, loss=0.09240, avg_loss=0.08786, mel_loss=0.04081, linear_loss=0.05159]
[2020-05-12 16:57:22.309]  Step 163910  [3.927 sec/step, loss=0.07467, avg_loss=0.08759, mel_loss=0.03186, linear_loss=0.04281]
[2020-05-12 16:57:24.492]  Step 163911  [3.939 sec/step, loss=0.08821, avg_loss=0.08769, mel_loss=0.03879, linear_loss=0.04942]
[2020-05-12 16:57:27.559]  Step 163912  [3.940 sec/step, loss=0.09212, avg_loss=0.08768, mel_loss=0.04046, linear_loss=0.05166]
[2020-05-12 16:57:32.916]  Step 163913  [3.902 sec/step, loss=0.09666, avg_loss=0.08782, mel_loss=0.04434, linear_loss=0.05232]
[2020-05-12 16:57:37.040]  Step 163914  [3.935 sec/step, loss=0.09132, avg_loss=0.08798, mel_loss=0.04037, linear_loss=0.05095]
[2020-05-12 16:57:38.423]  Step 163915  [3.893 sec/step, loss=0.08349, avg_loss=0.08782, mel_loss=0.03585, linear_loss=0.04764]
[2020-05-12 16:57:43.548]  Step 163916  [3.925 sec/step, loss=0.09410, avg_loss=0.08787, mel_loss=0.04225, linear_loss=0.05185]
[2020-05-12 16:57:44.682]  Step 163917  [3.890 sec/step, loss=0.07899, avg_loss=0.08769, mel_loss=0.03336, linear_loss=0.04563]
[2020-05-12 16:57:47.155]  Step 163918  [3.881 sec/step, loss=0.08841, avg_loss=0.08765, mel_loss=0.03862, linear_loss=0.04979]
[2020-05-12 16:57:50.334]  Step 163919  [3.896 sec/step, loss=0.09302, avg_loss=0.08771, mel_loss=0.04108, linear_loss=0.05194]
[2020-05-12 16:57:51.336]  Step 163920  [3.898 sec/step, loss=0.07818, avg_loss=0.08780, mel_loss=0.03302, linear_loss=0.04516]
[2020-05-12 16:57:52.895]  Step 163921  [3.863 sec/step, loss=0.08607, avg_loss=0.08771, mel_loss=0.03696, linear_loss=0.04911]
[2020-05-12 16:57:54.686]  Step 163922  [3.854 sec/step, loss=0.08576, avg_loss=0.08768, mel_loss=0.03719, linear_loss=0.04857]
[2020-05-12 16:57:59.268]  Step 163923  [3.887 sec/step, loss=0.09421, avg_loss=0.08777, mel_loss=0.04195, linear_loss=0.05226]
[2020-05-12 16:58:00.991]  Step 163924  [3.887 sec/step, loss=0.08557, avg_loss=0.08775, mel_loss=0.03699, linear_loss=0.04858]
[2020-05-12 16:58:02.357]  Step 163925  [3.871 sec/step, loss=0.08617, avg_loss=0.08767, mel_loss=0.03693, linear_loss=0.04924]
[2020-05-12 16:58:06.013]  Step 163926  [3.892 sec/step, loss=0.09388, avg_loss=0.08773, mel_loss=0.04155, linear_loss=0.05234]
[2020-05-12 16:58:08.172]  Step 163927  [3.870 sec/step, loss=0.08604, avg_loss=0.08763, mel_loss=0.03749, linear_loss=0.04854]
[2020-05-12 16:58:16.073]  Step 163928  [3.866 sec/step, loss=0.09679, avg_loss=0.08764, mel_loss=0.04411, linear_loss=0.05268]
[2020-05-12 16:58:18.686]  Step 163929  [3.871 sec/step, loss=0.08896, avg_loss=0.08762, mel_loss=0.03905, linear_loss=0.04991]
[2020-05-12 16:58:19.450]  Step 163930  [3.857 sec/step, loss=0.07012, avg_loss=0.08744, mel_loss=0.03087, linear_loss=0.03925]
[2020-05-12 16:58:22.163]  Step 163931  [3.843 sec/step, loss=0.08967, avg_loss=0.08736, mel_loss=0.03943, linear_loss=0.05024]
[2020-05-12 16:58:23.212]  Step 163932  [3.827 sec/step, loss=0.07602, avg_loss=0.08722, mel_loss=0.03239, linear_loss=0.04363]
[2020-05-12 16:58:25.057]  Step 163933  [3.836 sec/step, loss=0.08735, avg_loss=0.08732, mel_loss=0.03749, linear_loss=0.04986]
[2020-05-12 16:58:33.686]  Step 163934  [3.899 sec/step, loss=0.09313, avg_loss=0.08735, mel_loss=0.04247, linear_loss=0.05066]
[2020-05-12 16:58:39.985]  Step 163935  [3.952 sec/step, loss=0.09472, avg_loss=0.08751, mel_loss=0.04285, linear_loss=0.05187]
[2020-05-12 16:58:40.772]  Step 163936  [3.924 sec/step, loss=0.07182, avg_loss=0.08727, mel_loss=0.03031, linear_loss=0.04152]
[2020-05-12 17:00:00.131]  Generated 32 batches of size 32 in 111.954 sec
[2020-05-12 17:00:02.081]  Step 163937  [4.703 sec/step, loss=0.08756, avg_loss=0.08721, mel_loss=0.03793, linear_loss=0.04963]
[2020-05-12 17:00:05.703]  Step 163938  [4.672 sec/step, loss=0.09369, avg_loss=0.08718, mel_loss=0.04171, linear_loss=0.05198]
[2020-05-12 17:00:07.031]  Step 163939  [4.559 sec/step, loss=0.08003, avg_loss=0.08708, mel_loss=0.03413, linear_loss=0.04590]
[2020-05-12 17:00:09.752]  Step 163940  [4.573 sec/step, loss=0.09037, avg_loss=0.08718, mel_loss=0.03972, linear_loss=0.05065]
[2020-05-12 17:00:11.133]  Step 163941  [4.511 sec/step, loss=0.08429, avg_loss=0.08704, mel_loss=0.03635, linear_loss=0.04795]
[2020-05-12 17:00:14.016]  Step 163942  [4.532 sec/step, loss=0.09303, avg_loss=0.08725, mel_loss=0.04081, linear_loss=0.05222]
[2020-05-12 17:00:15.057]  Step 163943  [4.505 sec/step, loss=0.08205, avg_loss=0.08711, mel_loss=0.03482, linear_loss=0.04723]
[2020-05-12 17:00:17.466]  Step 163944  [4.518 sec/step, loss=0.09029, avg_loss=0.08719, mel_loss=0.03922, linear_loss=0.05108]
[2020-05-12 17:00:24.090]  Step 163945  [4.566 sec/step, loss=0.09454, avg_loss=0.08727, mel_loss=0.04268, linear_loss=0.05186]
[2020-05-12 17:00:26.589]  Step 163946  [4.535 sec/step, loss=0.08891, avg_loss=0.08720, mel_loss=0.03863, linear_loss=0.05028]
[2020-05-12 17:00:30.640]  Step 163947  [4.562 sec/step, loss=0.09348, avg_loss=0.08731, mel_loss=0.04132, linear_loss=0.05216]
[2020-05-12 17:00:33.665]  Step 163948  [4.567 sec/step, loss=0.09401, avg_loss=0.08735, mel_loss=0.04156, linear_loss=0.05246]
[2020-05-12 17:00:37.083]  Step 163949  [4.540 sec/step, loss=0.09091, avg_loss=0.08730, mel_loss=0.04025, linear_loss=0.05066]
[2020-05-12 17:00:38.042]  Step 163950  [4.527 sec/step, loss=0.07953, avg_loss=0.08721, mel_loss=0.03368, linear_loss=0.04586]
[2020-05-12 17:00:38.042]  Writing summary at step: 163950
[2020-05-12 17:00:43.335]  Saving checkpoint to: ./logs-tacotron/model.ckpt-163950
[2020-05-12 17:00:44.980]  Saving audio and alignment...
[2020-05-12 17:00:46.568]  Input: 그 행사~______________
[2020-05-12 17:00:47.126]  Step 163951  [4.525 sec/step, loss=0.06583, avg_loss=0.08715, mel_loss=0.02833, linear_loss=0.03750]
[2020-05-12 17:00:49.316]  Step 163952  [4.541 sec/step, loss=0.08593, avg_loss=0.08730, mel_loss=0.03742, linear_loss=0.04851]
[2020-05-12 17:00:55.063]  Step 163953  [4.567 sec/step, loss=0.09557, avg_loss=0.08732, mel_loss=0.04293, linear_loss=0.05264]
[2020-05-12 17:01:09.520]  Step 163954  [4.624 sec/step, loss=0.07444, avg_loss=0.08714, mel_loss=0.03473, linear_loss=0.03972]
[2020-05-12 17:01:12.938]  Step 163955  [4.632 sec/step, loss=0.09344, avg_loss=0.08716, mel_loss=0.04148, linear_loss=0.05196]
[2020-05-12 17:01:21.926]  Step 163956  [4.711 sec/step, loss=0.09433, avg_loss=0.08733, mel_loss=0.04357, linear_loss=0.05075]
[2020-05-12 17:01:29.359]  Step 163957  [4.774 sec/step, loss=0.09412, avg_loss=0.08747, mel_loss=0.04277, linear_loss=0.05134]
[2020-05-12 17:01:31.421]  Step 163958  [4.778 sec/step, loss=0.08872, avg_loss=0.08751, mel_loss=0.03863, linear_loss=0.05009]
[2020-05-12 17:01:36.160]  Step 163959  [4.787 sec/step, loss=0.09406, avg_loss=0.08753, mel_loss=0.04198, linear_loss=0.05208]
[2020-05-12 17:01:40.390]  Step 163960  [4.762 sec/step, loss=0.09479, avg_loss=0.08749, mel_loss=0.04224, linear_loss=0.05254]
[2020-05-12 17:01:41.309]  Step 163961  [4.763 sec/step, loss=0.07388, avg_loss=0.08745, mel_loss=0.03095, linear_loss=0.04293]
[2020-05-12 17:01:42.960]  Step 163962  [4.759 sec/step, loss=0.08599, avg_loss=0.08744, mel_loss=0.03697, linear_loss=0.04901]
[2020-05-12 17:01:44.162]  Step 163963  [4.758 sec/step, loss=0.07802, avg_loss=0.08736, mel_loss=0.03330, linear_loss=0.04473]
[2020-05-12 17:01:44.919]  Step 163964  [4.713 sec/step, loss=0.07729, avg_loss=0.08717, mel_loss=0.03212, linear_loss=0.04517]
[2020-05-12 17:01:46.460]  Step 163965  [4.682 sec/step, loss=0.08383, avg_loss=0.08706, mel_loss=0.03603, linear_loss=0.04780]
[2020-05-12 17:01:48.282]  Step 163966  [4.659 sec/step, loss=0.08496, avg_loss=0.08697, mel_loss=0.03631, linear_loss=0.04865]
[2020-05-12 17:02:43.687]  Generated 32 batches of size 32 in 74.323 sec
[2020-05-12 17:02:48.184]  Step 163967  [5.235 sec/step, loss=0.09309, avg_loss=0.08701, mel_loss=0.04145, linear_loss=0.05164]
[2020-05-12 17:02:52.924]  Step 163968  [5.250 sec/step, loss=0.09406, avg_loss=0.08702, mel_loss=0.04189, linear_loss=0.05217]
[2020-05-12 17:03:06.176]  Step 163969  [5.373 sec/step, loss=0.08058, avg_loss=0.08702, mel_loss=0.03770, linear_loss=0.04289]
[2020-05-12 17:03:08.429]  Step 163970  [5.376 sec/step, loss=0.08687, avg_loss=0.08701, mel_loss=0.03785, linear_loss=0.04901]
[2020-05-12 17:03:09.854]  Step 163971  [5.360 sec/step, loss=0.08228, avg_loss=0.08688, mel_loss=0.03520, linear_loss=0.04708]
[2020-05-12 17:03:11.593]  Step 163972  [5.362 sec/step, loss=0.08670, avg_loss=0.08690, mel_loss=0.03726, linear_loss=0.04945]
[2020-05-12 17:03:14.291]  Step 163973  [5.354 sec/step, loss=0.08786, avg_loss=0.08685, mel_loss=0.03826, linear_loss=0.04960]
[2020-05-12 17:03:19.912]  Step 163974  [5.267 sec/step, loss=0.09439, avg_loss=0.08704, mel_loss=0.04241, linear_loss=0.05198]
[2020-05-12 17:03:23.309]  Step 163975  [4.877 sec/step, loss=0.08952, avg_loss=0.08704, mel_loss=0.03926, linear_loss=0.05026]
[2020-05-12 17:03:24.211]  Step 163976  [4.850 sec/step, loss=0.07593, avg_loss=0.08685, mel_loss=0.03194, linear_loss=0.04398]
[2020-05-12 17:03:28.595]  Step 163977  [4.865 sec/step, loss=0.09289, avg_loss=0.08687, mel_loss=0.04114, linear_loss=0.05175]
[2020-05-12 17:03:35.001]  Step 163978  [4.842 sec/step, loss=0.09398, avg_loss=0.08684, mel_loss=0.04247, linear_loss=0.05151]
[2020-05-12 17:03:36.010]  Step 163979  [4.818 sec/step, loss=0.07323, avg_loss=0.08666, mel_loss=0.03064, linear_loss=0.04260]
[2020-05-12 17:03:37.297]  Step 163980  [4.817 sec/step, loss=0.07882, avg_loss=0.08664, mel_loss=0.03365, linear_loss=0.04517]
[2020-05-12 17:03:46.232]  Step 163981  [4.880 sec/step, loss=0.09395, avg_loss=0.08669, mel_loss=0.04290, linear_loss=0.05104]
[2020-05-12 17:03:53.968]  Step 163982  [4.949 sec/step, loss=0.09382, avg_loss=0.08693, mel_loss=0.04269, linear_loss=0.05113]
[2020-05-12 17:03:57.579]  Step 163983  [4.917 sec/step, loss=0.09312, avg_loss=0.08693, mel_loss=0.04116, linear_loss=0.05196]
[2020-05-12 17:04:00.797]  Step 163984  [4.909 sec/step, loss=0.09142, avg_loss=0.08689, mel_loss=0.04019, linear_loss=0.05123]
[2020-05-12 17:04:01.883]  Step 163985  [4.904 sec/step, loss=0.08090, avg_loss=0.08684, mel_loss=0.03411, linear_loss=0.04679]
[2020-05-12 17:04:03.848]  Step 163986  [4.905 sec/step, loss=0.08464, avg_loss=0.08684, mel_loss=0.03673, linear_loss=0.04791]
[2020-05-12 17:04:07.372]  Step 163987  [4.863 sec/step, loss=0.08953, avg_loss=0.08678, mel_loss=0.03962, linear_loss=0.04991]
[2020-05-12 17:04:09.017]  Step 163988  [4.855 sec/step, loss=0.08424, avg_loss=0.08674, mel_loss=0.03613, linear_loss=0.04811]
[2020-05-12 17:04:11.891]  Step 163989  [4.866 sec/step, loss=0.08947, avg_loss=0.08676, mel_loss=0.03927, linear_loss=0.05020]
[2020-05-12 17:04:12.484]  Step 163990  [4.862 sec/step, loss=0.06570, avg_loss=0.08664, mel_loss=0.02806, linear_loss=0.03764]
[2020-05-12 17:04:16.228]  Step 163991  [4.879 sec/step, loss=0.09371, avg_loss=0.08669, mel_loss=0.04161, linear_loss=0.05210]
[2020-05-12 17:04:18.389]  Step 163992  [4.768 sec/step, loss=0.08762, avg_loss=0.08674, mel_loss=0.03833, linear_loss=0.04929]
[2020-05-12 17:04:19.419]  Step 163993  [4.770 sec/step, loss=0.07742, avg_loss=0.08676, mel_loss=0.03295, linear_loss=0.04447]
[2020-05-12 17:04:21.885]  Step 163994  [4.763 sec/step, loss=0.08814, avg_loss=0.08673, mel_loss=0.03826, linear_loss=0.04988]
[2020-05-12 17:04:23.704]  Step 163995  [4.773 sec/step, loss=0.08572, avg_loss=0.08691, mel_loss=0.03713, linear_loss=0.04859]
[2020-05-12 17:04:29.456]  Step 163996  [4.809 sec/step, loss=0.09571, avg_loss=0.08698, mel_loss=0.04340, linear_loss=0.05231]
[2020-05-12 17:04:30.303]  Step 163997  [4.784 sec/step, loss=0.07172, avg_loss=0.08677, mel_loss=0.03073, linear_loss=0.04099]
[2020-05-12 17:04:31.677]  Step 163998  [4.780 sec/step, loss=0.08286, avg_loss=0.08672, mel_loss=0.03541, linear_loss=0.04745]
[2020-05-12 17:05:08.482]  Generated 32 batches of size 32 in 56.567 sec
[2020-05-12 17:05:09.440]  Step 163999  [5.147 sec/step, loss=0.07862, avg_loss=0.08674, mel_loss=0.03324, linear_loss=0.04537]
[2020-05-12 17:05:14.017]  Step 164000  [5.182 sec/step, loss=0.09382, avg_loss=0.08686, mel_loss=0.04162, linear_loss=0.05220]
[2020-05-12 17:05:14.017]  Writing summary at step: 164000
[2020-05-12 17:05:18.080]  Saving checkpoint to: ./logs-tacotron/model.ckpt-164000
[2020-05-12 17:05:19.807]  Saving audio and alignment...
[2020-05-12 17:05:22.169]  Input: 자 여기서 중요한 거~________
[2020-05-12 17:05:22.725]  Step 164001  [5.130 sec/step, loss=0.06814, avg_loss=0.08660, mel_loss=0.02978, linear_loss=0.03835]
[2020-05-12 17:05:25.151]  Step 164002  [5.142 sec/step, loss=0.08870, avg_loss=0.08665, mel_loss=0.03870, linear_loss=0.05001]
[2020-05-12 17:05:31.836]  Step 164003  [5.157 sec/step, loss=0.09338, avg_loss=0.08665, mel_loss=0.04219, linear_loss=0.05119]
[2020-05-12 17:05:33.813]  Step 164004  [5.131 sec/step, loss=0.08767, avg_loss=0.08657, mel_loss=0.03811, linear_loss=0.04956]
[2020-05-12 17:05:42.222]  Step 164005  [5.079 sec/step, loss=0.09405, avg_loss=0.08668, mel_loss=0.04290, linear_loss=0.05115]
[2020-05-12 17:05:47.511]  Step 164006  [5.089 sec/step, loss=0.09346, avg_loss=0.08668, mel_loss=0.04185, linear_loss=0.05161]
[2020-05-12 17:05:50.223]  Step 164007  [4.976 sec/step, loss=0.08802, avg_loss=0.08680, mel_loss=0.03874, linear_loss=0.04929]
[2020-05-12 17:05:55.919]  Step 164008  [5.012 sec/step, loss=0.09387, avg_loss=0.08685, mel_loss=0.04219, linear_loss=0.05168]
[2020-05-12 17:06:10.587]  Step 164009  [5.123 sec/step, loss=0.07367, avg_loss=0.08667, mel_loss=0.03450, linear_loss=0.03917]
[2020-05-12 17:06:11.418]  Step 164010  [5.124 sec/step, loss=0.07611, avg_loss=0.08668, mel_loss=0.03226, linear_loss=0.04385]
[2020-05-12 17:06:14.457]  Step 164011  [5.132 sec/step, loss=0.09198, avg_loss=0.08672, mel_loss=0.04035, linear_loss=0.05163]
[2020-05-12 17:06:17.586]  Step 164012  [5.133 sec/step, loss=0.09427, avg_loss=0.08674, mel_loss=0.04170, linear_loss=0.05257]
[2020-05-12 17:06:19.869]  Step 164013  [5.102 sec/step, loss=0.08711, avg_loss=0.08664, mel_loss=0.03773, linear_loss=0.04938]
[2020-05-12 17:06:21.674]  Step 164014  [5.079 sec/step, loss=0.08426, avg_loss=0.08657, mel_loss=0.03628, linear_loss=0.04798]
[2020-05-12 17:06:25.478]  Step 164015  [5.103 sec/step, loss=0.09046, avg_loss=0.08664, mel_loss=0.03994, linear_loss=0.05052]
[2020-05-12 17:06:26.991]  Step 164016  [5.067 sec/step, loss=0.08519, avg_loss=0.08655, mel_loss=0.03646, linear_loss=0.04873]
[2020-05-12 17:06:30.624]  Step 164017  [5.092 sec/step, loss=0.09170, avg_loss=0.08668, mel_loss=0.04076, linear_loss=0.05094]
[2020-05-12 17:06:32.834]  Step 164018  [5.089 sec/step, loss=0.08826, avg_loss=0.08668, mel_loss=0.03803, linear_loss=0.05023]
[2020-05-12 17:06:40.476]  Step 164019  [5.134 sec/step, loss=0.09516, avg_loss=0.08670, mel_loss=0.04311, linear_loss=0.05205]
[2020-05-12 17:06:42.363]  Step 164020  [5.143 sec/step, loss=0.08444, avg_loss=0.08676, mel_loss=0.03607, linear_loss=0.04837]
[2020-05-12 17:06:43.460]  Step 164021  [5.138 sec/step, loss=0.07802, avg_loss=0.08668, mel_loss=0.03322, linear_loss=0.04480]
[2020-05-12 17:06:46.081]  Step 164022  [5.146 sec/step, loss=0.09015, avg_loss=0.08673, mel_loss=0.03926, linear_loss=0.05089]
[2020-05-12 17:06:47.271]  Step 164023  [5.113 sec/step, loss=0.08169, avg_loss=0.08660, mel_loss=0.03511, linear_loss=0.04658]
[2020-05-12 17:06:48.715]  Step 164024  [5.110 sec/step, loss=0.08168, avg_loss=0.08656, mel_loss=0.03493, linear_loss=0.04676]
[2020-05-12 17:06:50.057]  Step 164025  [5.110 sec/step, loss=0.08422, avg_loss=0.08654, mel_loss=0.03584, linear_loss=0.04838]
[2020-05-12 17:06:50.838]  Step 164026  [5.081 sec/step, loss=0.07089, avg_loss=0.08631, mel_loss=0.03004, linear_loss=0.04085]
[2020-05-12 17:06:55.154]  Step 164027  [5.102 sec/step, loss=0.09342, avg_loss=0.08639, mel_loss=0.04151, linear_loss=0.05191]
[2020-05-12 17:06:56.932]  Step 164028  [5.041 sec/step, loss=0.08409, avg_loss=0.08626, mel_loss=0.03637, linear_loss=0.04772]
[2020-05-12 17:08:13.339]  Generated 32 batches of size 32 in 92.857 sec
[2020-05-12 17:08:15.819]  Step 164029  [5.804 sec/step, loss=0.08803, avg_loss=0.08625, mel_loss=0.03814, linear_loss=0.04989]
[2020-05-12 17:08:21.985]  Step 164030  [5.858 sec/step, loss=0.09278, avg_loss=0.08648, mel_loss=0.04215, linear_loss=0.05064]
[2020-05-12 17:08:25.516]  Step 164031  [5.866 sec/step, loss=0.09242, avg_loss=0.08651, mel_loss=0.04123, linear_loss=0.05119]
[2020-05-12 17:08:29.072]  Step 164032  [5.891 sec/step, loss=0.09210, avg_loss=0.08667, mel_loss=0.04063, linear_loss=0.05146]
[2020-05-12 17:08:30.069]  Step 164033  [5.883 sec/step, loss=0.07439, avg_loss=0.08654, mel_loss=0.03146, linear_loss=0.04293]
[2020-05-12 17:08:31.505]  Step 164034  [5.811 sec/step, loss=0.08250, avg_loss=0.08643, mel_loss=0.03520, linear_loss=0.04730]
[2020-05-12 17:08:33.501]  Step 164035  [5.768 sec/step, loss=0.08488, avg_loss=0.08633, mel_loss=0.03641, linear_loss=0.04847]
[2020-05-12 17:08:34.658]  Step 164036  [5.772 sec/step, loss=0.08103, avg_loss=0.08642, mel_loss=0.03440, linear_loss=0.04662]
[2020-05-12 17:08:40.314]  Step 164037  [5.015 sec/step, loss=0.09513, avg_loss=0.08650, mel_loss=0.04268, linear_loss=0.05245]
[2020-05-12 17:08:43.550]  Step 164038  [5.011 sec/step, loss=0.09132, avg_loss=0.08648, mel_loss=0.03999, linear_loss=0.05133]
[2020-05-12 17:08:44.321]  Step 164039  [5.006 sec/step, loss=0.07122, avg_loss=0.08639, mel_loss=0.03016, linear_loss=0.04107]
[2020-05-12 17:08:46.388]  Step 164040  [4.999 sec/step, loss=0.08861, avg_loss=0.08637, mel_loss=0.03857, linear_loss=0.05005]
[2020-05-12 17:08:49.143]  Step 164041  [5.013 sec/step, loss=0.08930, avg_loss=0.08642, mel_loss=0.03900, linear_loss=0.05031]
[2020-05-12 17:08:57.860]  Step 164042  [5.071 sec/step, loss=0.09279, avg_loss=0.08642, mel_loss=0.04241, linear_loss=0.05039]
[2020-05-12 17:09:12.491]  Step 164043  [5.207 sec/step, loss=0.07433, avg_loss=0.08634, mel_loss=0.03497, linear_loss=0.03936]
[2020-05-12 17:09:13.265]  Step 164044  [5.191 sec/step, loss=0.07744, avg_loss=0.08621, mel_loss=0.03247, linear_loss=0.04497]
[2020-05-12 17:09:15.499]  Step 164045  [5.147 sec/step, loss=0.08867, avg_loss=0.08615, mel_loss=0.03855, linear_loss=0.05012]
[2020-05-12 17:09:20.018]  Step 164046  [5.167 sec/step, loss=0.09667, avg_loss=0.08623, mel_loss=0.04334, linear_loss=0.05333]
[2020-05-12 17:09:21.675]  Step 164047  [5.143 sec/step, loss=0.08496, avg_loss=0.08615, mel_loss=0.03642, linear_loss=0.04854]
[2020-05-12 17:09:29.256]  Step 164048  [5.189 sec/step, loss=0.09461, avg_loss=0.08615, mel_loss=0.04298, linear_loss=0.05164]
[2020-05-12 17:09:31.852]  Step 164049  [5.180 sec/step, loss=0.08839, avg_loss=0.08613, mel_loss=0.03825, linear_loss=0.05014]
[2020-05-12 17:09:34.882]  Step 164050  [5.201 sec/step, loss=0.09112, avg_loss=0.08624, mel_loss=0.03994, linear_loss=0.05118]
[2020-05-12 17:09:34.897]  Writing summary at step: 164050
[2020-05-12 17:09:35.530]  Saving checkpoint to: ./logs-tacotron/model.ckpt-164050
[2020-05-12 17:09:37.321]  Saving audio and alignment...
[2020-05-12 17:09:40.253]  Input: 몇 시간까지도 필요 없고~______________
[2020-05-12 17:09:41.240]  Step 164051  [5.205 sec/step, loss=0.07899, avg_loss=0.08637, mel_loss=0.03331, linear_loss=0.04568]
[2020-05-12 17:09:43.271]  Step 164052  [5.204 sec/step, loss=0.08591, avg_loss=0.08637, mel_loss=0.03717, linear_loss=0.04874]
[2020-05-12 17:09:48.254]  Step 164053  [5.196 sec/step, loss=0.09183, avg_loss=0.08634, mel_loss=0.04073, linear_loss=0.05110]
[2020-05-12 17:09:52.059]  Step 164054  [5.090 sec/step, loss=0.09304, avg_loss=0.08652, mel_loss=0.04123, linear_loss=0.05181]
[2020-05-12 17:09:53.237]  Step 164055  [5.067 sec/step, loss=0.08123, avg_loss=0.08640, mel_loss=0.03459, linear_loss=0.04664]
[2020-05-12 17:09:54.983]  Step 164056  [4.995 sec/step, loss=0.08420, avg_loss=0.08630, mel_loss=0.03624, linear_loss=0.04796]
[2020-05-12 17:09:59.038]  Step 164057  [4.961 sec/step, loss=0.09247, avg_loss=0.08628, mel_loss=0.04099, linear_loss=0.05148]
[2020-05-12 17:10:00.422]  Step 164058  [4.954 sec/step, loss=0.08435, avg_loss=0.08624, mel_loss=0.03610, linear_loss=0.04825]
[2020-05-12 17:10:56.188]  Generated 32 batches of size 32 in 78.188 sec
[2020-05-12 17:10:59.279]  Step 164059  [5.496 sec/step, loss=0.09425, avg_loss=0.08624, mel_loss=0.04162, linear_loss=0.05263]
[2020-05-12 17:11:06.091]  Step 164060  [5.521 sec/step, loss=0.09658, avg_loss=0.08626, mel_loss=0.04362, linear_loss=0.05296]
[2020-05-12 17:11:07.500]  Step 164061  [5.526 sec/step, loss=0.08297, avg_loss=0.08635, mel_loss=0.03556, linear_loss=0.04741]
[2020-05-12 17:11:09.425]  Step 164062  [5.529 sec/step, loss=0.08466, avg_loss=0.08634, mel_loss=0.03629, linear_loss=0.04837]
[2020-05-12 17:11:18.425]  Step 164063  [5.607 sec/step, loss=0.09622, avg_loss=0.08652, mel_loss=0.04397, linear_loss=0.05225]
[2020-05-12 17:11:20.442]  Step 164064  [5.620 sec/step, loss=0.08775, avg_loss=0.08662, mel_loss=0.03805, linear_loss=0.04970]
[2020-05-12 17:11:24.007]  Step 164065  [5.640 sec/step, loss=0.08897, avg_loss=0.08668, mel_loss=0.03907, linear_loss=0.04990]
[2020-05-12 17:11:29.481]  Step 164066  [5.676 sec/step, loss=0.09553, avg_loss=0.08678, mel_loss=0.04276, linear_loss=0.05277]
[2020-05-12 17:11:35.338]  Step 164067  [5.136 sec/step, loss=0.09582, avg_loss=0.08681, mel_loss=0.04302, linear_loss=0.05280]
[2020-05-12 17:11:36.959]  Step 164068  [5.105 sec/step, loss=0.08436, avg_loss=0.08671, mel_loss=0.03647, linear_loss=0.04789]
[2020-05-12 17:11:37.722]  Step 164069  [4.980 sec/step, loss=0.06593, avg_loss=0.08656, mel_loss=0.02807, linear_loss=0.03786]
[2020-05-12 17:11:40.837]  Step 164070  [4.988 sec/step, loss=0.09419, avg_loss=0.08664, mel_loss=0.04146, linear_loss=0.05273]
[2020-05-12 17:11:44.477]  Step 164071  [5.011 sec/step, loss=0.09355, avg_loss=0.08675, mel_loss=0.04127, linear_loss=0.05228]
[2020-05-12 17:11:45.318]  Step 164072  [5.002 sec/step, loss=0.07237, avg_loss=0.08661, mel_loss=0.03041, linear_loss=0.04196]
[2020-05-12 17:11:46.109]  Step 164073  [4.983 sec/step, loss=0.07181, avg_loss=0.08645, mel_loss=0.03071, linear_loss=0.04110]
[2020-05-12 17:11:47.164]  Step 164074  [4.937 sec/step, loss=0.07535, avg_loss=0.08626, mel_loss=0.03174, linear_loss=0.04362]
[2020-05-12 17:11:51.667]  Step 164075  [4.948 sec/step, loss=0.09438, avg_loss=0.08630, mel_loss=0.04172, linear_loss=0.05266]
[2020-05-12 17:11:52.782]  Step 164076  [4.950 sec/step, loss=0.08273, avg_loss=0.08637, mel_loss=0.03485, linear_loss=0.04788]
[2020-05-12 17:11:54.090]  Step 164077  [4.919 sec/step, loss=0.07847, avg_loss=0.08623, mel_loss=0.03373, linear_loss=0.04474]
[2020-05-12 17:11:58.315]  Step 164078  [4.897 sec/step, loss=0.09298, avg_loss=0.08622, mel_loss=0.04122, linear_loss=0.05176]
[2020-05-12 17:12:00.491]  Step 164079  [4.909 sec/step, loss=0.08589, avg_loss=0.08635, mel_loss=0.03727, linear_loss=0.04862]
[2020-05-12 17:12:03.119]  Step 164080  [4.923 sec/step, loss=0.08883, avg_loss=0.08645, mel_loss=0.03890, linear_loss=0.04992]
[2020-05-12 17:12:04.610]  Step 164081  [4.848 sec/step, loss=0.08331, avg_loss=0.08634, mel_loss=0.03585, linear_loss=0.04746]
[2020-05-12 17:12:19.401]  Step 164082  [4.919 sec/step, loss=0.07530, avg_loss=0.08615, mel_loss=0.03519, linear_loss=0.04011]
[2020-05-12 17:12:21.931]  Step 164083  [4.908 sec/step, loss=0.08886, avg_loss=0.08611, mel_loss=0.03855, linear_loss=0.05031]
[2020-05-12 17:12:29.794]  Step 164084  [4.954 sec/step, loss=0.09540, avg_loss=0.08615, mel_loss=0.04322, linear_loss=0.05218]
[2020-05-12 17:12:32.717]  Step 164085  [4.973 sec/step, loss=0.09087, avg_loss=0.08625, mel_loss=0.04016, linear_loss=0.05070]
[2020-05-12 17:12:36.561]  Step 164086  [4.991 sec/step, loss=0.09426, avg_loss=0.08635, mel_loss=0.04160, linear_loss=0.05267]
[2020-05-12 17:12:38.359]  Step 164087  [4.974 sec/step, loss=0.08605, avg_loss=0.08631, mel_loss=0.03666, linear_loss=0.04939]
[2020-05-12 17:12:40.761]  Step 164088  [4.982 sec/step, loss=0.08834, avg_loss=0.08635, mel_loss=0.03868, linear_loss=0.04967]
[2020-05-12 17:12:41.804]  Step 164089  [4.963 sec/step, loss=0.07797, avg_loss=0.08624, mel_loss=0.03306, linear_loss=0.04490]
[2020-05-12 17:12:46.741]  Step 164090  [5.007 sec/step, loss=0.09344, avg_loss=0.08652, mel_loss=0.04157, linear_loss=0.05187]
[2020-05-12 17:13:25.699]  Generated 32 batches of size 32 in 81.084 sec
[2020-05-12 17:13:27.390]  Step 164091  [5.376 sec/step, loss=0.08686, avg_loss=0.08645, mel_loss=0.03747, linear_loss=0.04939]
[2020-05-12 17:13:31.673]  Step 164092  [5.397 sec/step, loss=0.09326, avg_loss=0.08650, mel_loss=0.04139, linear_loss=0.05186]
[2020-05-12 17:13:35.179]  Step 164093  [5.422 sec/step, loss=0.09080, avg_loss=0.08664, mel_loss=0.04039, linear_loss=0.05040]
[2020-05-12 17:13:38.443]  Step 164094  [5.430 sec/step, loss=0.09376, avg_loss=0.08669, mel_loss=0.04142, linear_loss=0.05234]
[2020-05-12 17:13:51.618]  Step 164095  [5.544 sec/step, loss=0.08355, avg_loss=0.08667, mel_loss=0.03927, linear_loss=0.04428]
[2020-05-12 17:13:52.803]  Step 164096  [5.498 sec/step, loss=0.07835, avg_loss=0.08650, mel_loss=0.03323, linear_loss=0.04512]
[2020-05-12 17:13:57.358]  Step 164097  [5.535 sec/step, loss=0.09453, avg_loss=0.08673, mel_loss=0.04240, linear_loss=0.05213]
[2020-05-12 17:13:58.767]  Step 164098  [5.535 sec/step, loss=0.08359, avg_loss=0.08673, mel_loss=0.03571, linear_loss=0.04787]
[2020-05-12 17:14:07.560]  Step 164099  [5.246 sec/step, loss=0.09112, avg_loss=0.08686, mel_loss=0.04166, linear_loss=0.04946]
[2020-05-12 17:14:14.244]  Step 164100  [5.267 sec/step, loss=0.09304, avg_loss=0.08685, mel_loss=0.04187, linear_loss=0.05117]
[2020-05-12 17:14:14.244]  Writing summary at step: 164100
[2020-05-12 17:14:17.003]  Saving checkpoint to: ./logs-tacotron/model.ckpt-164100
[2020-05-12 17:14:18.738]  Saving audio and alignment...
[2020-05-12 17:14:28.884]  Input: 정규직 아나운서는 여수 엠비씨 가 수 십년간 일할 곳이게 또 프리랜서는 당장 내일이 마지막이 될 수도 있기에~______
[2020-05-12 17:14:33.899]  Step 164101  [5.311 sec/step, loss=0.09208, avg_loss=0.08709, mel_loss=0.04111, linear_loss=0.05096]
[2020-05-12 17:14:34.662]  Step 164102  [5.295 sec/step, loss=0.07568, avg_loss=0.08696, mel_loss=0.03175, linear_loss=0.04393]
[2020-05-12 17:14:35.218]  Step 164103  [5.233 sec/step, loss=0.06672, avg_loss=0.08669, mel_loss=0.02863, linear_loss=0.03810]
[2020-05-12 17:14:37.574]  Step 164104  [5.237 sec/step, loss=0.08722, avg_loss=0.08669, mel_loss=0.03784, linear_loss=0.04938]
[2020-05-12 17:14:39.536]  Step 164105  [5.173 sec/step, loss=0.08827, avg_loss=0.08663, mel_loss=0.03838, linear_loss=0.04990]
[2020-05-12 17:14:40.416]  Step 164106  [5.129 sec/step, loss=0.07474, avg_loss=0.08644, mel_loss=0.03144, linear_loss=0.04330]
[2020-05-12 17:14:44.416]  Step 164107  [5.141 sec/step, loss=0.09310, avg_loss=0.08649, mel_loss=0.04120, linear_loss=0.05190]
[2020-05-12 17:14:45.179]  Step 164108  [5.092 sec/step, loss=0.07316, avg_loss=0.08629, mel_loss=0.03088, linear_loss=0.04228]
[2020-05-12 17:14:46.526]  Step 164109  [4.959 sec/step, loss=0.07920, avg_loss=0.08634, mel_loss=0.03384, linear_loss=0.04536]
[2020-05-12 17:14:48.268]  Step 164110  [4.968 sec/step, loss=0.08532, avg_loss=0.08643, mel_loss=0.03668, linear_loss=0.04864]
[2020-05-12 17:14:50.403]  Step 164111  [4.959 sec/step, loss=0.08753, avg_loss=0.08639, mel_loss=0.03785, linear_loss=0.04968]
[2020-05-12 17:14:51.418]  Step 164112  [4.938 sec/step, loss=0.07654, avg_loss=0.08621, mel_loss=0.03258, linear_loss=0.04396]
[2020-05-12 17:14:53.300]  Step 164113  [4.934 sec/step, loss=0.08542, avg_loss=0.08620, mel_loss=0.03697, linear_loss=0.04845]
[2020-05-12 17:14:56.161]  Step 164114  [4.944 sec/step, loss=0.08966, avg_loss=0.08625, mel_loss=0.03928, linear_loss=0.05038]
[2020-05-12 17:14:57.259]  Step 164115  [4.917 sec/step, loss=0.07815, avg_loss=0.08613, mel_loss=0.03291, linear_loss=0.04524]
[2020-05-12 17:14:59.646]  Step 164116  [4.926 sec/step, loss=0.08807, avg_loss=0.08616, mel_loss=0.03842, linear_loss=0.04964]
[2020-05-12 17:15:05.465]  Step 164117  [4.948 sec/step, loss=0.09331, avg_loss=0.08617, mel_loss=0.04202, linear_loss=0.05129]
[2020-05-12 17:15:08.641]  Step 164118  [4.958 sec/step, loss=0.09115, avg_loss=0.08620, mel_loss=0.03981, linear_loss=0.05134]
[2020-05-12 17:15:12.344]  Step 164119  [4.918 sec/step, loss=0.09440, avg_loss=0.08619, mel_loss=0.04188, linear_loss=0.05252]
[2020-05-12 17:15:13.986]  Step 164120  [4.916 sec/step, loss=0.08387, avg_loss=0.08619, mel_loss=0.03604, linear_loss=0.04784]
[2020-05-12 17:15:24.924]  Generated 32 batches of size 32 in 34.517 sec
[2020-05-12 17:15:27.069]  Step 164121  [5.036 sec/step, loss=0.08665, avg_loss=0.08627, mel_loss=0.03777, linear_loss=0.04888]
[2020-05-12 17:15:29.323]  Step 164122  [5.032 sec/step, loss=0.08812, avg_loss=0.08625, mel_loss=0.03821, linear_loss=0.04991]
[2020-05-12 17:15:30.853]  Step 164123  [5.035 sec/step, loss=0.08390, avg_loss=0.08628, mel_loss=0.03613, linear_loss=0.04777]
[2020-05-12 17:15:33.589]  Step 164124  [5.048 sec/step, loss=0.08962, avg_loss=0.08635, mel_loss=0.03950, linear_loss=0.05012]
[2020-05-12 17:15:34.574]  Step 164125  [5.045 sec/step, loss=0.07446, avg_loss=0.08626, mel_loss=0.03134, linear_loss=0.04312]
[2020-05-12 17:15:38.117]  Step 164126  [5.072 sec/step, loss=0.09344, avg_loss=0.08648, mel_loss=0.04112, linear_loss=0.05231]
[2020-05-12 17:15:40.647]  Step 164127  [5.054 sec/step, loss=0.08679, avg_loss=0.08642, mel_loss=0.03766, linear_loss=0.04913]
[2020-05-12 17:15:42.534]  Step 164128  [5.055 sec/step, loss=0.08615, avg_loss=0.08644, mel_loss=0.03716, linear_loss=0.04899]
[2020-05-12 17:15:43.854]  Step 164129  [4.280 sec/step, loss=0.07939, avg_loss=0.08635, mel_loss=0.03400, linear_loss=0.04540]
[2020-05-12 17:15:44.599]  Step 164130  [4.226 sec/step, loss=0.07321, avg_loss=0.08615, mel_loss=0.03058, linear_loss=0.04263]
[2020-05-12 17:15:45.956]  Step 164131  [4.204 sec/step, loss=0.08398, avg_loss=0.08607, mel_loss=0.03592, linear_loss=0.04805]
[2020-05-12 17:15:48.996]  Step 164132  [4.199 sec/step, loss=0.09199, avg_loss=0.08607, mel_loss=0.04052, linear_loss=0.05147]
[2020-05-12 17:15:52.150]  Step 164133  [4.220 sec/step, loss=0.09201, avg_loss=0.08625, mel_loss=0.04051, linear_loss=0.05151]
[2020-05-12 17:15:55.014]  Step 164134  [4.235 sec/step, loss=0.09004, avg_loss=0.08632, mel_loss=0.03942, linear_loss=0.05062]
[2020-05-12 17:16:01.536]  Step 164135  [4.280 sec/step, loss=0.09427, avg_loss=0.08641, mel_loss=0.04255, linear_loss=0.05173]
[2020-05-12 17:16:04.960]  Step 164136  [4.302 sec/step, loss=0.09019, avg_loss=0.08651, mel_loss=0.03973, linear_loss=0.05046]
[2020-05-12 17:16:06.093]  Step 164137  [4.257 sec/step, loss=0.07930, avg_loss=0.08635, mel_loss=0.03359, linear_loss=0.04571]
[2020-05-12 17:16:13.677]  Step 164138  [4.301 sec/step, loss=0.09543, avg_loss=0.08639, mel_loss=0.04319, linear_loss=0.05224]
[2020-05-12 17:16:14.656]  Step 164139  [4.303 sec/step, loss=0.07914, avg_loss=0.08647, mel_loss=0.03352, linear_loss=0.04562]
[2020-05-12 17:16:19.844]  Step 164140  [4.334 sec/step, loss=0.09393, avg_loss=0.08652, mel_loss=0.04220, linear_loss=0.05173]
[2020-05-12 17:16:20.598]  Step 164141  [4.314 sec/step, loss=0.07070, avg_loss=0.08634, mel_loss=0.03067, linear_loss=0.04003]
[2020-05-12 17:16:24.885]  Step 164142  [4.270 sec/step, loss=0.09191, avg_loss=0.08633, mel_loss=0.04068, linear_loss=0.05123]
[2020-05-12 17:16:25.670]  Step 164143  [4.131 sec/step, loss=0.07266, avg_loss=0.08631, mel_loss=0.03076, linear_loss=0.04190]
[2020-05-12 17:16:27.444]  Step 164144  [4.141 sec/step, loss=0.08497, avg_loss=0.08639, mel_loss=0.03636, linear_loss=0.04862]
[2020-05-12 17:16:27.480]  Generated 32 batches of size 32 in 1.804 sec
[2020-05-12 17:16:32.961]  Step 164145  [4.174 sec/step, loss=0.09618, avg_loss=0.08646, mel_loss=0.04349, linear_loss=0.05269]
[2020-05-12 17:16:40.884]  Step 164146  [4.208 sec/step, loss=0.09362, avg_loss=0.08643, mel_loss=0.04264, linear_loss=0.05098]
[2020-05-12 17:16:45.450]  Step 164147  [4.237 sec/step, loss=0.09539, avg_loss=0.08653, mel_loss=0.04278, linear_loss=0.05261]
[2020-05-12 17:16:49.198]  Step 164148  [4.199 sec/step, loss=0.09294, avg_loss=0.08652, mel_loss=0.04107, linear_loss=0.05187]
[2020-05-12 17:16:50.262]  Step 164149  [4.184 sec/step, loss=0.08096, avg_loss=0.08644, mel_loss=0.03413, linear_loss=0.04683]
[2020-05-12 17:16:52.241]  Step 164150  [4.173 sec/step, loss=0.08898, avg_loss=0.08642, mel_loss=0.03858, linear_loss=0.05039]
[2020-05-12 17:16:52.241]  Writing summary at step: 164150
[2020-05-12 17:17:04.463]  Saving checkpoint to: ./logs-tacotron/model.ckpt-164150
[2020-05-12 17:17:06.220]  Saving audio and alignment...
[2020-05-12 17:17:09.421]  Input: 단음인 단어를 찾으라고 했죠~________
[2020-05-12 17:17:15.154]  Step 164151  [4.221 sec/step, loss=0.09393, avg_loss=0.08657, mel_loss=0.04221, linear_loss=0.05172]
[2020-05-12 17:17:16.392]  Step 164152  [4.213 sec/step, loss=0.08153, avg_loss=0.08653, mel_loss=0.03474, linear_loss=0.04679]
[2020-05-12 17:17:17.510]  Step 164153  [4.174 sec/step, loss=0.08062, avg_loss=0.08642, mel_loss=0.03381, linear_loss=0.04681]
[2020-05-12 17:17:21.666]  Step 164154  [4.177 sec/step, loss=0.09367, avg_loss=0.08642, mel_loss=0.04159, linear_loss=0.05208]
[2020-05-12 17:17:26.704]  Step 164155  [4.216 sec/step, loss=0.09311, avg_loss=0.08654, mel_loss=0.04159, linear_loss=0.05151]
[2020-05-12 17:17:28.480]  Step 164156  [4.216 sec/step, loss=0.08533, avg_loss=0.08655, mel_loss=0.03660, linear_loss=0.04873]
[2020-05-12 17:17:30.547]  Step 164157  [4.196 sec/step, loss=0.08570, avg_loss=0.08648, mel_loss=0.03702, linear_loss=0.04867]
[2020-05-12 17:17:32.855]  Step 164158  [4.206 sec/step, loss=0.08619, avg_loss=0.08650, mel_loss=0.03745, linear_loss=0.04875]
[2020-05-12 17:17:33.420]  Step 164159  [3.623 sec/step, loss=0.06553, avg_loss=0.08621, mel_loss=0.02820, linear_loss=0.03733]
[2020-05-12 17:17:37.349]  Step 164160  [3.594 sec/step, loss=0.09165, avg_loss=0.08617, mel_loss=0.04043, linear_loss=0.05122]
[2020-05-12 17:17:38.979]  Step 164161  [3.596 sec/step, loss=0.08624, avg_loss=0.08620, mel_loss=0.03705, linear_loss=0.04919]
[2020-05-12 17:17:41.476]  Step 164162  [3.602 sec/step, loss=0.08763, avg_loss=0.08623, mel_loss=0.03805, linear_loss=0.04958]
[2020-05-12 17:17:43.080]  Step 164163  [3.528 sec/step, loss=0.08199, avg_loss=0.08609, mel_loss=0.03508, linear_loss=0.04691]
[2020-05-12 17:17:45.674]  Step 164164  [3.534 sec/step, loss=0.08910, avg_loss=0.08610, mel_loss=0.03863, linear_loss=0.05048]
[2020-05-12 17:17:48.558]  Step 164165  [3.527 sec/step, loss=0.08871, avg_loss=0.08610, mel_loss=0.03899, linear_loss=0.04972]
[2020-05-12 17:17:49.970]  Step 164166  [3.486 sec/step, loss=0.08153, avg_loss=0.08596, mel_loss=0.03487, linear_loss=0.04667]
[2020-05-12 17:18:04.591]  Step 164167  [3.574 sec/step, loss=0.07539, avg_loss=0.08575, mel_loss=0.03520, linear_loss=0.04019]
[2020-05-12 17:18:05.643]  Step 164168  [3.568 sec/step, loss=0.07642, avg_loss=0.08567, mel_loss=0.03212, linear_loss=0.04430]
[2020-05-12 17:18:07.599]  Step 164169  [3.580 sec/step, loss=0.08620, avg_loss=0.08588, mel_loss=0.03700, linear_loss=0.04921]
[2020-05-12 17:18:16.778]  Step 164170  [3.641 sec/step, loss=0.09412, avg_loss=0.08588, mel_loss=0.04319, linear_loss=0.05093]
[2020-05-12 17:18:17.618]  Step 164171  [3.613 sec/step, loss=0.07189, avg_loss=0.08566, mel_loss=0.03060, linear_loss=0.04129]
[2020-05-12 17:18:19.831]  Step 164172  [3.626 sec/step, loss=0.08674, avg_loss=0.08580, mel_loss=0.03743, linear_loss=0.04931]
[2020-05-12 17:18:23.376]  Step 164173  [3.654 sec/step, loss=0.09106, avg_loss=0.08599, mel_loss=0.04002, linear_loss=0.05104]
[2020-05-12 17:18:28.091]  Step 164174  [3.691 sec/step, loss=0.09416, avg_loss=0.08618, mel_loss=0.04183, linear_loss=0.05233]
[2020-05-12 17:18:34.642]  Step 164175  [3.711 sec/step, loss=0.09362, avg_loss=0.08618, mel_loss=0.04207, linear_loss=0.05155]
[2020-05-12 17:18:35.998]  Step 164176  [3.713 sec/step, loss=0.08176, avg_loss=0.08617, mel_loss=0.03484, linear_loss=0.04692]
[2020-05-12 17:18:36.815]  Step 164177  [3.709 sec/step, loss=0.07268, avg_loss=0.08611, mel_loss=0.03066, linear_loss=0.04202]
[2020-05-12 17:18:37.835]  Step 164178  [3.676 sec/step, loss=0.07423, avg_loss=0.08592, mel_loss=0.03120, linear_loss=0.04303]
[2020-05-12 17:18:41.592]  Step 164179  [3.692 sec/step, loss=0.09308, avg_loss=0.08599, mel_loss=0.04120, linear_loss=0.05188]
[2020-05-12 17:18:44.754]  Step 164180  [3.698 sec/step, loss=0.09182, avg_loss=0.08602, mel_loss=0.04006, linear_loss=0.05176]
[2020-05-12 17:18:48.258]  Step 164181  [3.718 sec/step, loss=0.09225, avg_loss=0.08611, mel_loss=0.04079, linear_loss=0.05146]
[2020-05-12 17:18:55.891]  Step 164182  [3.646 sec/step, loss=0.09390, avg_loss=0.08630, mel_loss=0.04257, linear_loss=0.05132]
[2020-05-12 17:19:53.431]  Generated 32 batches of size 32 in 90.049 sec
[2020-05-12 17:19:58.066]  Step 164183  [4.243 sec/step, loss=0.09342, avg_loss=0.08634, mel_loss=0.04141, linear_loss=0.05201]
[2020-05-12 17:20:07.199]  Step 164184  [4.255 sec/step, loss=0.09429, avg_loss=0.08633, mel_loss=0.04329, linear_loss=0.05100]
[2020-05-12 17:20:07.965]  Step 164185  [4.234 sec/step, loss=0.06922, avg_loss=0.08612, mel_loss=0.02928, linear_loss=0.03994]
[2020-05-12 17:20:09.746]  Step 164186  [4.213 sec/step, loss=0.08585, avg_loss=0.08603, mel_loss=0.03671, linear_loss=0.04914]
[2020-05-12 17:20:13.185]  Step 164187  [4.230 sec/step, loss=0.09042, avg_loss=0.08607, mel_loss=0.03996, linear_loss=0.05047]
[2020-05-12 17:20:15.937]  Step 164188  [4.233 sec/step, loss=0.08953, avg_loss=0.08609, mel_loss=0.03933, linear_loss=0.05020]
[2020-05-12 17:20:18.835]  Step 164189  [4.252 sec/step, loss=0.08957, avg_loss=0.08620, mel_loss=0.03916, linear_loss=0.05041]
[2020-05-12 17:20:19.640]  Step 164190  [4.210 sec/step, loss=0.07500, avg_loss=0.08602, mel_loss=0.03152, linear_loss=0.04347]
[2020-05-12 17:20:22.027]  Step 164191  [3.828 sec/step, loss=0.08724, avg_loss=0.08602, mel_loss=0.03791, linear_loss=0.04932]
[2020-05-12 17:20:23.148]  Step 164192  [3.796 sec/step, loss=0.08233, avg_loss=0.08591, mel_loss=0.03473, linear_loss=0.04760]
[2020-05-12 17:20:25.013]  Step 164193  [3.780 sec/step, loss=0.08556, avg_loss=0.08586, mel_loss=0.03672, linear_loss=0.04884]
[2020-05-12 17:20:26.606]  Step 164194  [3.763 sec/step, loss=0.08281, avg_loss=0.08575, mel_loss=0.03518, linear_loss=0.04763]
[2020-05-12 17:20:28.767]  Step 164195  [3.653 sec/step, loss=0.08672, avg_loss=0.08578, mel_loss=0.03767, linear_loss=0.04904]
[2020-05-12 17:20:31.805]  Step 164196  [3.671 sec/step, loss=0.09173, avg_loss=0.08592, mel_loss=0.04061, linear_loss=0.05112]
[2020-05-12 17:20:35.096]  Step 164197  [3.659 sec/step, loss=0.09281, avg_loss=0.08590, mel_loss=0.04108, linear_loss=0.05174]
[2020-05-12 17:20:39.126]  Step 164198  [3.685 sec/step, loss=0.09348, avg_loss=0.08600, mel_loss=0.04127, linear_loss=0.05220]
[2020-05-12 17:20:39.901]  Step 164199  [3.605 sec/step, loss=0.07130, avg_loss=0.08580, mel_loss=0.03079, linear_loss=0.04051]
[2020-05-12 17:20:45.503]  Step 164200  [3.594 sec/step, loss=0.09522, avg_loss=0.08582, mel_loss=0.04314, linear_loss=0.05209]
[2020-05-12 17:20:45.503]  Writing summary at step: 164200
[2020-05-12 17:20:52.785]  Saving checkpoint to: ./logs-tacotron/model.ckpt-164200
[2020-05-12 17:20:54.499]  Saving audio and alignment...
[2020-05-12 17:21:00.441]  Input: 이분들의 마음을 얻어야만 그것이 성공적인 진행이라 할 수 있고요~
[2020-05-12 17:21:01.860]  Step 164201  [3.558 sec/step, loss=0.08330, avg_loss=0.08573, mel_loss=0.03565, linear_loss=0.04766]
[2020-05-12 17:21:03.927]  Step 164202  [3.571 sec/step, loss=0.08736, avg_loss=0.08585, mel_loss=0.03791, linear_loss=0.04945]
[2020-05-12 17:21:08.936]  Step 164203  [3.615 sec/step, loss=0.09332, avg_loss=0.08612, mel_loss=0.04141, linear_loss=0.05191]
[2020-05-12 17:21:11.415]  Step 164204  [3.617 sec/step, loss=0.08778, avg_loss=0.08612, mel_loss=0.03789, linear_loss=0.04989]
[2020-05-12 17:21:13.081]  Step 164205  [3.614 sec/step, loss=0.08564, avg_loss=0.08610, mel_loss=0.03696, linear_loss=0.04868]
[2020-05-12 17:21:27.974]  Step 164206  [3.754 sec/step, loss=0.07575, avg_loss=0.08611, mel_loss=0.03540, linear_loss=0.04035]
[2020-05-12 17:21:29.010]  Step 164207  [3.724 sec/step, loss=0.07676, avg_loss=0.08594, mel_loss=0.03247, linear_loss=0.04429]
[2020-05-12 17:21:30.023]  Step 164208  [3.727 sec/step, loss=0.07764, avg_loss=0.08599, mel_loss=0.03254, linear_loss=0.04510]
[2020-05-12 17:21:31.401]  Step 164209  [3.727 sec/step, loss=0.08150, avg_loss=0.08601, mel_loss=0.03469, linear_loss=0.04680]
[2020-05-12 17:21:32.579]  Step 164210  [3.722 sec/step, loss=0.08231, avg_loss=0.08598, mel_loss=0.03510, linear_loss=0.04721]
[2020-05-12 17:21:36.779]  Step 164211  [3.742 sec/step, loss=0.09290, avg_loss=0.08603, mel_loss=0.04119, linear_loss=0.05172]
[2020-05-12 17:21:43.467]  Step 164212  [3.799 sec/step, loss=0.09303, avg_loss=0.08620, mel_loss=0.04186, linear_loss=0.05117]
[2020-05-12 17:22:52.099]  Generated 32 batches of size 32 in 103.158 sec
[2020-05-12 17:22:55.831]  Step 164213  [4.504 sec/step, loss=0.09408, avg_loss=0.08629, mel_loss=0.04160, linear_loss=0.05248]
[2020-05-12 17:22:58.696]  Step 164214  [4.504 sec/step, loss=0.09143, avg_loss=0.08630, mel_loss=0.03982, linear_loss=0.05161]
[2020-05-12 17:23:00.491]  Step 164215  [4.511 sec/step, loss=0.08337, avg_loss=0.08636, mel_loss=0.03590, linear_loss=0.04746]
[2020-05-12 17:23:02.164]  Step 164216  [4.504 sec/step, loss=0.08599, avg_loss=0.08633, mel_loss=0.03674, linear_loss=0.04925]
[2020-05-12 17:23:08.567]  Step 164217  [4.509 sec/step, loss=0.09446, avg_loss=0.08635, mel_loss=0.04272, linear_loss=0.05173]
[2020-05-12 17:23:11.958]  Step 164218  [4.512 sec/step, loss=0.09188, avg_loss=0.08635, mel_loss=0.04036, linear_loss=0.05153]
[2020-05-12 17:23:12.706]  Step 164219  [4.482 sec/step, loss=0.07201, avg_loss=0.08613, mel_loss=0.03071, linear_loss=0.04129]
[2020-05-12 17:23:14.228]  Step 164220  [4.481 sec/step, loss=0.08542, avg_loss=0.08614, mel_loss=0.03661, linear_loss=0.04881]
[2020-05-12 17:23:17.743]  Step 164221  [4.385 sec/step, loss=0.09012, avg_loss=0.08618, mel_loss=0.03973, linear_loss=0.05039]
[2020-05-12 17:23:21.858]  Step 164222  [4.404 sec/step, loss=0.09243, avg_loss=0.08622, mel_loss=0.04081, linear_loss=0.05162]
[2020-05-12 17:23:23.765]  Step 164223  [4.408 sec/step, loss=0.08690, avg_loss=0.08625, mel_loss=0.03700, linear_loss=0.04990]
[2020-05-12 17:23:26.866]  Step 164224  [4.411 sec/step, loss=0.09284, avg_loss=0.08628, mel_loss=0.04086, linear_loss=0.05197]
[2020-05-12 17:23:34.374]  Step 164225  [4.476 sec/step, loss=0.09500, avg_loss=0.08649, mel_loss=0.04300, linear_loss=0.05200]
[2020-05-12 17:23:36.822]  Step 164226  [4.465 sec/step, loss=0.08887, avg_loss=0.08644, mel_loss=0.03863, linear_loss=0.05024]
[2020-05-12 17:23:37.362]  Step 164227  [4.446 sec/step, loss=0.06457, avg_loss=0.08622, mel_loss=0.02785, linear_loss=0.03671]
[2020-05-12 17:23:38.437]  Step 164228  [4.437 sec/step, loss=0.07974, avg_loss=0.08616, mel_loss=0.03366, linear_loss=0.04608]
[2020-05-12 17:23:41.209]  Step 164229  [4.452 sec/step, loss=0.08801, avg_loss=0.08624, mel_loss=0.03834, linear_loss=0.04967]
[2020-05-12 17:23:46.158]  Step 164230  [4.494 sec/step, loss=0.09209, avg_loss=0.08643, mel_loss=0.04108, linear_loss=0.05101]
[2020-05-12 17:23:47.162]  Step 164231  [4.490 sec/step, loss=0.08082, avg_loss=0.08640, mel_loss=0.03431, linear_loss=0.04651]
[2020-05-12 17:23:49.476]  Step 164232  [4.483 sec/step, loss=0.08846, avg_loss=0.08637, mel_loss=0.03825, linear_loss=0.05021]
[2020-05-12 17:23:53.968]  Step 164233  [4.497 sec/step, loss=0.09408, avg_loss=0.08639, mel_loss=0.04176, linear_loss=0.05232]
[2020-05-12 17:23:55.317]  Step 164234  [4.481 sec/step, loss=0.07966, avg_loss=0.08628, mel_loss=0.03410, linear_loss=0.04557]
[2020-05-12 17:24:03.711]  Step 164235  [4.500 sec/step, loss=0.09345, avg_loss=0.08628, mel_loss=0.04254, linear_loss=0.05091]
[2020-05-12 17:24:09.700]  Step 164236  [4.526 sec/step, loss=0.09538, avg_loss=0.08633, mel_loss=0.04268, linear_loss=0.05270]
[2020-05-12 17:24:11.965]  Step 164237  [4.537 sec/step, loss=0.08623, avg_loss=0.08640, mel_loss=0.03738, linear_loss=0.04885]
[2020-05-12 17:24:13.194]  Step 164238  [4.474 sec/step, loss=0.07781, avg_loss=0.08622, mel_loss=0.03329, linear_loss=0.04453]
[2020-05-12 17:24:15.612]  Step 164239  [4.488 sec/step, loss=0.08784, avg_loss=0.08631, mel_loss=0.03832, linear_loss=0.04952]
[2020-05-12 17:24:16.554]  Step 164240  [4.446 sec/step, loss=0.07291, avg_loss=0.08610, mel_loss=0.03022, linear_loss=0.04269]
[2020-05-12 17:24:17.246]  Generated 32 batches of size 32 in 13.530 sec
[2020-05-12 17:24:17.374]  Step 164241  [4.446 sec/step, loss=0.07641, avg_loss=0.08615, mel_loss=0.03191, linear_loss=0.04450]
[2020-05-12 17:24:30.492]  Step 164242  [4.535 sec/step, loss=0.08472, avg_loss=0.08608, mel_loss=0.03962, linear_loss=0.04510]
[2020-05-12 17:24:36.480]  Step 164243  [4.587 sec/step, loss=0.09402, avg_loss=0.08630, mel_loss=0.04201, linear_loss=0.05202]
[2020-05-12 17:24:38.002]  Step 164244  [4.584 sec/step, loss=0.08295, avg_loss=0.08628, mel_loss=0.03582, linear_loss=0.04713]
[2020-05-12 17:24:40.312]  Step 164245  [4.552 sec/step, loss=0.08531, avg_loss=0.08617, mel_loss=0.03678, linear_loss=0.04853]
[2020-05-12 17:24:41.999]  Step 164246  [4.490 sec/step, loss=0.08558, avg_loss=0.08609, mel_loss=0.03670, linear_loss=0.04889]
[2020-05-12 17:24:44.140]  Step 164247  [4.465 sec/step, loss=0.08858, avg_loss=0.08602, mel_loss=0.03853, linear_loss=0.05005]
[2020-05-12 17:24:47.637]  Step 164248  [4.463 sec/step, loss=0.09146, avg_loss=0.08600, mel_loss=0.03997, linear_loss=0.05148]
[2020-05-12 17:24:48.527]  Step 164249  [4.461 sec/step, loss=0.07026, avg_loss=0.08590, mel_loss=0.02957, linear_loss=0.04070]
[2020-05-12 17:24:49.957]  Step 164250  [4.456 sec/step, loss=0.08088, avg_loss=0.08582, mel_loss=0.03447, linear_loss=0.04641]
[2020-05-12 17:24:49.957]  Writing summary at step: 164250
[2020-05-12 17:24:57.040]  Saving checkpoint to: ./logs-tacotron/model.ckpt-164250
[2020-05-12 17:24:58.833]  Saving audio and alignment...
[2020-05-12 17:25:03.761]  Input: 음 여러분 일단 오프닝부터 점검을 해 볼게요~________________
[2020-05-12 17:25:07.368]  Step 164251  [4.434 sec/step, loss=0.08966, avg_loss=0.08577, mel_loss=0.03932, linear_loss=0.05033]
[2020-05-12 17:25:07.974]  Step 164252  [4.428 sec/step, loss=0.06645, avg_loss=0.08562, mel_loss=0.02855, linear_loss=0.03789]
[2020-05-12 17:25:10.054]  Step 164253  [4.438 sec/step, loss=0.08745, avg_loss=0.08569, mel_loss=0.03782, linear_loss=0.04962]
[2020-05-12 17:25:14.732]  Step 164254  [4.443 sec/step, loss=0.09406, avg_loss=0.08569, mel_loss=0.04185, linear_loss=0.05221]
[2020-05-12 17:25:16.657]  Step 164255  [4.412 sec/step, loss=0.08431, avg_loss=0.08561, mel_loss=0.03620, linear_loss=0.04810]
[2020-05-12 17:25:17.827]  Step 164256  [4.406 sec/step, loss=0.07904, avg_loss=0.08554, mel_loss=0.03309, linear_loss=0.04595]
[2020-05-12 17:25:18.905]  Step 164257  [4.396 sec/step, loss=0.07529, avg_loss=0.08544, mel_loss=0.03167, linear_loss=0.04362]
[2020-05-12 17:25:19.832]  Step 164258  [4.382 sec/step, loss=0.07202, avg_loss=0.08530, mel_loss=0.03016, linear_loss=0.04187]
[2020-05-12 17:25:21.670]  Step 164259  [4.395 sec/step, loss=0.08542, avg_loss=0.08550, mel_loss=0.03655, linear_loss=0.04887]
[2020-05-12 17:25:29.659]  Step 164260  [4.435 sec/step, loss=0.09402, avg_loss=0.08552, mel_loss=0.04257, linear_loss=0.05145]
[2020-05-12 17:25:44.354]  Step 164261  [4.566 sec/step, loss=0.07456, avg_loss=0.08540, mel_loss=0.03478, linear_loss=0.03978]
[2020-05-12 17:25:48.450]  Step 164262  [4.582 sec/step, loss=0.09237, avg_loss=0.08545, mel_loss=0.04087, linear_loss=0.05151]
[2020-05-12 17:25:51.315]  Step 164263  [4.595 sec/step, loss=0.08845, avg_loss=0.08552, mel_loss=0.03864, linear_loss=0.04982]
[2020-05-12 17:25:54.974]  Step 164264  [4.605 sec/step, loss=0.09328, avg_loss=0.08556, mel_loss=0.04124, linear_loss=0.05204]
[2020-05-12 17:25:59.955]  Step 164265  [4.626 sec/step, loss=0.09210, avg_loss=0.08559, mel_loss=0.04107, linear_loss=0.05103]
[2020-05-12 17:26:01.184]  Step 164266  [4.624 sec/step, loss=0.07849, avg_loss=0.08556, mel_loss=0.03349, linear_loss=0.04500]
[2020-05-12 17:26:03.880]  Step 164267  [4.505 sec/step, loss=0.08945, avg_loss=0.08570, mel_loss=0.03885, linear_loss=0.05060]
[2020-05-12 17:26:05.268]  Step 164268  [4.509 sec/step, loss=0.08304, avg_loss=0.08577, mel_loss=0.03555, linear_loss=0.04748]
[2020-05-12 17:26:07.726]  Step 164269  [4.514 sec/step, loss=0.08810, avg_loss=0.08579, mel_loss=0.03805, linear_loss=0.05005]
[2020-05-12 17:26:08.483]  Step 164270  [4.429 sec/step, loss=0.07604, avg_loss=0.08561, mel_loss=0.03166, linear_loss=0.04439]
[2020-05-12 17:26:17.309]  Step 164271  [4.509 sec/step, loss=0.09365, avg_loss=0.08582, mel_loss=0.04263, linear_loss=0.05101]
[2020-05-12 17:26:21.125]  Step 164272  [4.525 sec/step, loss=0.09369, avg_loss=0.08589, mel_loss=0.04128, linear_loss=0.05241]
[2020-05-12 17:26:22.808]  Step 164273  [4.507 sec/step, loss=0.08368, avg_loss=0.08582, mel_loss=0.03565, linear_loss=0.04802]
[2020-05-12 17:26:28.356]  Step 164274  [4.515 sec/step, loss=0.09307, avg_loss=0.08581, mel_loss=0.04161, linear_loss=0.05146]
[2020-05-12 17:27:42.877]  Generated 32 batches of size 32 in 102.918 sec
[2020-05-12 17:27:45.079]  Step 164275  [5.217 sec/step, loss=0.08711, avg_loss=0.08574, mel_loss=0.03774, linear_loss=0.04936]
[2020-05-12 17:27:50.401]  Step 164276  [5.256 sec/step, loss=0.09583, avg_loss=0.08588, mel_loss=0.04316, linear_loss=0.05266]
[2020-05-12 17:27:51.869]  Step 164277  [5.263 sec/step, loss=0.08095, avg_loss=0.08597, mel_loss=0.03475, linear_loss=0.04620]
[2020-05-12 17:27:53.467]  Step 164278  [5.269 sec/step, loss=0.08390, avg_loss=0.08606, mel_loss=0.03634, linear_loss=0.04756]
[2020-05-12 17:28:00.554]  Step 164279  [5.302 sec/step, loss=0.09555, avg_loss=0.08609, mel_loss=0.04322, linear_loss=0.05233]
[2020-05-12 17:28:01.112]  Step 164280  [5.276 sec/step, loss=0.06437, avg_loss=0.08581, mel_loss=0.02812, linear_loss=0.03624]
[2020-05-12 17:28:14.310]  Step 164281  [5.373 sec/step, loss=0.07885, avg_loss=0.08568, mel_loss=0.03671, linear_loss=0.04214]
[2020-05-12 17:28:17.531]  Step 164282  [5.329 sec/step, loss=0.09275, avg_loss=0.08567, mel_loss=0.04072, linear_loss=0.05203]
[2020-05-12 17:28:19.569]  Step 164283  [4.727 sec/step, loss=0.08692, avg_loss=0.08560, mel_loss=0.03735, linear_loss=0.04956]
[2020-05-12 17:28:22.009]  Step 164284  [4.660 sec/step, loss=0.09003, avg_loss=0.08556, mel_loss=0.03898, linear_loss=0.05105]
[2020-05-12 17:28:24.691]  Step 164285  [4.680 sec/step, loss=0.08914, avg_loss=0.08576, mel_loss=0.03942, linear_loss=0.04972]
[2020-05-12 17:28:29.222]  Step 164286  [4.707 sec/step, loss=0.09477, avg_loss=0.08585, mel_loss=0.04225, linear_loss=0.05252]
[2020-05-12 17:28:34.125]  Step 164287  [4.722 sec/step, loss=0.09407, avg_loss=0.08589, mel_loss=0.04185, linear_loss=0.05223]
[2020-05-12 17:28:35.382]  Step 164288  [4.706 sec/step, loss=0.08296, avg_loss=0.08582, mel_loss=0.03539, linear_loss=0.04757]
[2020-05-12 17:28:37.628]  Step 164289  [4.700 sec/step, loss=0.08667, avg_loss=0.08579, mel_loss=0.03788, linear_loss=0.04879]
[2020-05-12 17:28:43.368]  Step 164290  [4.749 sec/step, loss=0.09705, avg_loss=0.08601, mel_loss=0.04398, linear_loss=0.05307]
[2020-05-12 17:28:45.994]  Step 164291  [4.752 sec/step, loss=0.08739, avg_loss=0.08601, mel_loss=0.03822, linear_loss=0.04918]
[2020-05-12 17:28:49.613]  Step 164292  [4.777 sec/step, loss=0.09226, avg_loss=0.08611, mel_loss=0.04075, linear_loss=0.05150]
[2020-05-12 17:28:52.720]  Step 164293  [4.789 sec/step, loss=0.09355, avg_loss=0.08619, mel_loss=0.04111, linear_loss=0.05245]
[2020-05-12 17:28:53.869]  Step 164294  [4.785 sec/step, loss=0.07856, avg_loss=0.08615, mel_loss=0.03299, linear_loss=0.04557]
[2020-05-12 17:28:55.641]  Step 164295  [4.781 sec/step, loss=0.08489, avg_loss=0.08613, mel_loss=0.03653, linear_loss=0.04836]
[2020-05-12 17:29:04.303]  Step 164296  [4.837 sec/step, loss=0.09240, avg_loss=0.08614, mel_loss=0.04198, linear_loss=0.05042]
[2020-05-12 17:29:07.773]  Step 164297  [4.839 sec/step, loss=0.09249, avg_loss=0.08613, mel_loss=0.04120, linear_loss=0.05129]
[2020-05-12 17:29:09.131]  Step 164298  [4.812 sec/step, loss=0.08180, avg_loss=0.08602, mel_loss=0.03472, linear_loss=0.04708]
[2020-05-12 17:29:09.982]  Step 164299  [4.813 sec/step, loss=0.07387, avg_loss=0.08604, mel_loss=0.03137, linear_loss=0.04250]
[2020-05-12 17:29:10.724]  Step 164300  [4.764 sec/step, loss=0.06904, avg_loss=0.08578, mel_loss=0.03006, linear_loss=0.03898]
[2020-05-12 17:29:10.724]  Writing summary at step: 164300
[2020-05-12 17:29:11.749]  Saving checkpoint to: ./logs-tacotron/model.ckpt-164300
[2020-05-12 17:29:13.542]  Saving audio and alignment...
[2020-05-12 17:29:15.862]  Input: 지킬앤하이드 중~_________
[2020-05-12 17:29:22.731]  Step 164301  [4.819 sec/step, loss=0.09350, avg_loss=0.08588, mel_loss=0.04200, linear_loss=0.05150]
[2020-05-12 17:29:24.686]  Step 164302  [4.818 sec/step, loss=0.08559, avg_loss=0.08587, mel_loss=0.03670, linear_loss=0.04889]
[2020-05-12 17:29:29.000]  Step 164303  [4.811 sec/step, loss=0.09271, avg_loss=0.08586, mel_loss=0.04110, linear_loss=0.05161]
[2020-05-12 17:29:32.816]  Step 164304  [4.824 sec/step, loss=0.09211, avg_loss=0.08590, mel_loss=0.04072, linear_loss=0.05139]
[2020-05-12 17:30:35.937]  Generated 32 batches of size 32 in 88.159 sec
[2020-05-12 17:30:38.652]  Step 164305  [5.466 sec/step, loss=0.08824, avg_loss=0.08593, mel_loss=0.03808, linear_loss=0.05016]
[2020-05-12 17:30:43.301]  Step 164306  [5.363 sec/step, loss=0.09366, avg_loss=0.08611, mel_loss=0.04168, linear_loss=0.05198]
[2020-05-12 17:30:49.039]  Step 164307  [5.410 sec/step, loss=0.09244, avg_loss=0.08627, mel_loss=0.04150, linear_loss=0.05095]
[2020-05-12 17:30:53.105]  Step 164308  [5.441 sec/step, loss=0.09331, avg_loss=0.08642, mel_loss=0.04128, linear_loss=0.05203]
[2020-05-12 17:30:53.914]  Step 164309  [5.435 sec/step, loss=0.07325, avg_loss=0.08634, mel_loss=0.03104, linear_loss=0.04221]
[2020-05-12 17:30:54.589]  Step 164310  [5.430 sec/step, loss=0.06941, avg_loss=0.08621, mel_loss=0.02944, linear_loss=0.03997]
[2020-05-12 17:30:56.774]  Step 164311  [5.410 sec/step, loss=0.08847, avg_loss=0.08617, mel_loss=0.03845, linear_loss=0.05003]
[2020-05-12 17:30:58.799]  Step 164312  [5.363 sec/step, loss=0.08752, avg_loss=0.08611, mel_loss=0.03790, linear_loss=0.04961]
[2020-05-12 17:30:59.924]  Step 164313  [4.651 sec/step, loss=0.07943, avg_loss=0.08596, mel_loss=0.03392, linear_loss=0.04551]
[2020-05-12 17:31:07.595]  Step 164314  [4.699 sec/step, loss=0.09559, avg_loss=0.08601, mel_loss=0.04335, linear_loss=0.05223]
[2020-05-12 17:31:14.047]  Step 164315  [4.746 sec/step, loss=0.09267, avg_loss=0.08610, mel_loss=0.04169, linear_loss=0.05098]
[2020-05-12 17:31:17.505]  Step 164316  [4.763 sec/step, loss=0.09024, avg_loss=0.08614, mel_loss=0.03983, linear_loss=0.05041]
[2020-05-12 17:31:21.316]  Step 164317  [4.738 sec/step, loss=0.09297, avg_loss=0.08613, mel_loss=0.04084, linear_loss=0.05213]
[2020-05-12 17:31:23.739]  Step 164318  [4.728 sec/step, loss=0.08659, avg_loss=0.08607, mel_loss=0.03744, linear_loss=0.04915]
[2020-05-12 17:31:25.603]  Step 164319  [4.739 sec/step, loss=0.08488, avg_loss=0.08620, mel_loss=0.03624, linear_loss=0.04864]
[2020-05-12 17:31:29.455]  Step 164320  [4.762 sec/step, loss=0.09151, avg_loss=0.08626, mel_loss=0.04048, linear_loss=0.05103]
[2020-05-12 17:31:32.390]  Step 164321  [4.757 sec/step, loss=0.08904, avg_loss=0.08625, mel_loss=0.03885, linear_loss=0.05019]
[2020-05-12 17:31:41.217]  Step 164322  [4.804 sec/step, loss=0.09389, avg_loss=0.08627, mel_loss=0.04283, linear_loss=0.05106]
[2020-05-12 17:31:54.596]  Step 164323  [4.918 sec/step, loss=0.08099, avg_loss=0.08621, mel_loss=0.03771, linear_loss=0.04328]
[2020-05-12 17:31:58.057]  Step 164324  [4.922 sec/step, loss=0.09179, avg_loss=0.08620, mel_loss=0.04031, linear_loss=0.05147]
[2020-05-12 17:31:59.960]  Step 164325  [4.866 sec/step, loss=0.08605, avg_loss=0.08611, mel_loss=0.03705, linear_loss=0.04900]
[2020-05-12 17:32:02.809]  Step 164326  [4.870 sec/step, loss=0.08885, avg_loss=0.08611, mel_loss=0.03891, linear_loss=0.04994]
[2020-05-12 17:32:04.508]  Step 164327  [4.881 sec/step, loss=0.08381, avg_loss=0.08630, mel_loss=0.03603, linear_loss=0.04777]
[2020-05-12 17:32:05.276]  Step 164328  [4.878 sec/step, loss=0.06947, avg_loss=0.08620, mel_loss=0.02978, linear_loss=0.03969]
[2020-05-12 17:32:06.652]  Step 164329  [4.864 sec/step, loss=0.08181, avg_loss=0.08614, mel_loss=0.03483, linear_loss=0.04698]
[2020-05-12 17:32:07.654]  Step 164330  [4.825 sec/step, loss=0.08056, avg_loss=0.08602, mel_loss=0.03406, linear_loss=0.04650]
[2020-05-12 17:32:10.812]  Step 164331  [4.847 sec/step, loss=0.09208, avg_loss=0.08613, mel_loss=0.04038, linear_loss=0.05170]
[2020-05-12 17:32:12.389]  Step 164332  [4.839 sec/step, loss=0.08236, avg_loss=0.08607, mel_loss=0.03538, linear_loss=0.04697]
[2020-05-12 17:32:13.809]  Step 164333  [4.808 sec/step, loss=0.08374, avg_loss=0.08597, mel_loss=0.03583, linear_loss=0.04791]
[2020-05-12 17:32:14.992]  Step 164334  [4.807 sec/step, loss=0.08107, avg_loss=0.08598, mel_loss=0.03435, linear_loss=0.04672]
[2020-05-12 17:32:20.036]  Step 164335  [4.773 sec/step, loss=0.09282, avg_loss=0.08598, mel_loss=0.04126, linear_loss=0.05155]
[2020-05-12 17:32:20.935]  Step 164336  [4.722 sec/step, loss=0.07599, avg_loss=0.08578, mel_loss=0.03175, linear_loss=0.04424]
[2020-05-12 17:33:00.557]  Generated 32 batches of size 32 in 56.043 sec
[2020-05-12 17:33:02.140]  Step 164337  [5.112 sec/step, loss=0.08330, avg_loss=0.08575, mel_loss=0.03554, linear_loss=0.04776]
[2020-05-12 17:33:04.578]  Step 164338  [5.124 sec/step, loss=0.08826, avg_loss=0.08586, mel_loss=0.03847, linear_loss=0.04979]
[2020-05-12 17:33:05.419]  Step 164339  [5.108 sec/step, loss=0.07074, avg_loss=0.08569, mel_loss=0.02966, linear_loss=0.04108]
[2020-05-12 17:33:07.223]  Step 164340  [5.117 sec/step, loss=0.08592, avg_loss=0.08582, mel_loss=0.03682, linear_loss=0.04910]
[2020-05-12 17:33:08.397]  Step 164341  [5.120 sec/step, loss=0.07631, avg_loss=0.08582, mel_loss=0.03236, linear_loss=0.04396]
[2020-05-12 17:33:09.483]  Step 164342  [5.000 sec/step, loss=0.07575, avg_loss=0.08573, mel_loss=0.03224, linear_loss=0.04350]
[2020-05-12 17:33:12.930]  Step 164343  [4.975 sec/step, loss=0.09184, avg_loss=0.08570, mel_loss=0.04027, linear_loss=0.05157]
[2020-05-12 17:33:13.753]  Step 164344  [4.968 sec/step, loss=0.07179, avg_loss=0.08559, mel_loss=0.03015, linear_loss=0.04164]
[2020-05-12 17:33:15.352]  Step 164345  [4.960 sec/step, loss=0.08517, avg_loss=0.08559, mel_loss=0.03640, linear_loss=0.04877]
[2020-05-12 17:33:15.891]  Step 164346  [4.949 sec/step, loss=0.07139, avg_loss=0.08545, mel_loss=0.03056, linear_loss=0.04084]
[2020-05-12 17:33:20.089]  Step 164347  [4.970 sec/step, loss=0.09179, avg_loss=0.08548, mel_loss=0.04066, linear_loss=0.05113]
[2020-05-12 17:33:23.007]  Step 164348  [4.964 sec/step, loss=0.08869, avg_loss=0.08545, mel_loss=0.03883, linear_loss=0.04985]
